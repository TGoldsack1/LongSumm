{
  "sections": [{
    "heading": "1 INTRODUCTION",
    "text": "In this paper, we focus on reading comprehension style question answering which aims to answer questions given a passage or document. We mainly focus on the Stanford Question Answering Dataset (SQuAD) (Rajpurkar et al., 2016) and Microsoft MAchine Reading COmprehension (MS-MARCO) dataset, two large-scale datasets for reading comprehension and question answering which are both manually created through crowdsourcing. SQuAD requires to answer questions given a passage. It constrains answers to the space of all possible spans within the reference passage, which is different from cloze-style reading comprehension datasets (Hermann et al., 2015; Hill et al., 2016) in which answers are single words or entities. Moreover, SQuAD requires different forms of logical reasoning to infer the answer (Rajpurkar et al., 2016). Another real dataset, MS-MARCO provides several related documents collected from Bing Index for a question. The answer to the question in MS-MARCO is generated by human and the answer words can not only come from the given text.\nRapid progress has been made since the release of the SQuAD dataset. Wang & Jiang (2016b) build question-aware passage representation with match-LSTM (Wang & Jiang, 2016a), and predict answer boundaries in the passage with pointer networks (Vinyals et al., 2015). Seo et al. (2016) introduce bi-directional attention flow networks to model question-passage pairs at multiple levels of granularity. Xiong et al. (2016) propose dynamic co-attention networks which attend the question and passage simultaneously and iteratively refine answer predictions. Lee et al. (2016) and Yu et al. (2016) predict answers by ranking continuous text spans within passages.\nInspired by Wang & Jiang (2016b), we introduce R-NET, illustrated in Figure 1, an end-to-end neural network model for reading comprehension and question answering. Our model consists of four parts: 1) the recurrent network encoder to build representation for questions and passages separately, 2) the gated matching layer to match the question and passage, 3) the self-matching layer to aggregate information from the whole passage, and 4) the pointer-network based answer boundary prediction layer. The key contributions of this work are three-fold.\n∗ This is the work-in-progress technical report of our system and algorithm, namely R-NET, for the machine reading comprehension task. We will update this technical report when there are significant improvements of R-NET on the SQuAD leaderboard. An early version of this technical report, namely “Gated Self-Matching Networks for Reading Comprehension and Question Answering. Wenhui Wang, Nan Yang, Furu Wei, Baobao Chang and Ming Zhou”, has been accepted by and will be presented in ACL 2017.\n† Please contact Furu Wei and Ming Zhou for the machine reading comprehension research in Microsoft Research Asia.\nFirst, we propose a gated attention-based recurrent network, which adds an additional gate to the attention-based recurrent networks (Bahdanau et al., 2014; Rocktäschel et al., 2015; Wang & Jiang, 2016a), to account for the fact that words in the passage are of different importance to answer a particular question for reading comprehension and question answering. In Wang & Jiang (2016a), words in a passage with their corresponding attention-weighted question context are encoded together to produce question-aware passage representation. By introducing a gating mechanism, our gated attention-based recurrent network assigns different levels of importance to passage parts depending on their relevance to the question, masking out irrelevant passage parts and emphasizing the important ones.\nSecond, we introduce a self-matching mechanism, which can effectively aggregate evidence from the whole passage to infer the answer. Through a gated matching layer, the resulting question-aware passage representation effectively encodes question information for each passage word. However, recurrent networks can only memorize limited passage context in practice despite its theoretical capability. One answer candidate is often unaware of the clues in other parts of the passage. To address this problem, we propose a self-matching layer to dynamically refine passage representation with information from the whole passage. Based on question-aware passage representation, we employ gated attention-based recurrent networks on passage against passage itself, aggregating evidence relevant to the current passage word from every word in the passage. A gated attention-based recurrent network layer and self-matching layer dynamically enrich each passage representation with information aggregated from both question and passage, enabling subsequent network to better predict answers.\nLastly, the proposed method yields state-of-the-art results against strong baselines. Our single model achieves 72.3% exact match accuracy on the hidden SQuAD test set, while the ensemble model further boosts the result to 76.9%, which currently1 holds the first place on the SQuAD leaderboard. Besides, our model also achieves the best published results on MS-MARCO dataset (Nguyen et al., 2016)."
  }, {
    "heading": "2 TASK DESCRIPTION",
    "text": "For reading comprehension style question answering, a passage P and question Q are given, our task is to predict an answer A to question Q based on information found in P. The SQuAD dataset further constrains answer A to be a continuous sub-span of passage P. Answer A often includes non-entities and can be much longer phrases. This setup challenges us to understand and reason about both the question and passage in order to infer the answer. Table 1 shows a simple example from the SQuAD dataset. As for MS-MARCO dataset, several related passages P from Bing Index are provided for a question Q. Besides, the answer A in MS-MARCO is generated by human which can not be a continuous sub-span of the passage."
  }, {
    "heading": "3 R-NET STRUCTURE",
    "text": "Figure 1 gives an overview of R-NET. First, the question and passage are processed by a bidirectional recurrent network (Mikolov et al., 2010) separately. We then match the question and passage with gated attention-based recurrent networks, obtaining question-aware representation for\n1On May. 6, 2017\nthe passage. On top of that, we apply self-matching attention to aggregate evidence from the whole passage and refine the passage representation, which is then fed into the output layer to predict the boundary of the answer span."
  }, {
    "heading": "3.1 QUESTION AND PASSAGE ENCODER",
    "text": "Consider a question Q = {wQt }mt=1 and a passage P = {wPt }nt=1. We first convert the words to their respective word-level embeddings ({eQt }mt=1 and {ePt }nt=1) and character-level embeddings ({cQt }mt=1 and {cPt }nt=1). The character-level embeddings are generated by taking the final hidden states of a bi-directional recurrent neural network (RNN) applied to embeddings of characters in the token. Such character-level embeddings have been shown to be helpful to deal with out-of-vocab (OOV) tokens. We then use a bi-directional RNN to produce new representation uQ1 , . . . , u Q m and uP1 , . . . , u P n of all words in the question and passage respectively:\nuQt = BiRNNQ(u Q t−1, [e Q t , c Q t ]) (1)\nuPt = BiRNNP (u P t−1, [e P t , c P t ]) (2)\nWe choose to use Gated Recurrent Unit (GRU) (Cho et al., 2014) in our experiment since it performs similarly to LSTM (Hochreiter & Schmidhuber, 1997) but is computationally cheaper."
  }, {
    "heading": "3.2 GATED ATTENTION-BASED RECURRENT NETWORKS",
    "text": "We propose a gated attention-based recurrent network to incorporate question information into passage representation. It is a variant of attention-based recurrent networks, with an additional gate to determine the importance of information in the passage regarding a question. Given question and passage representation {uQt }mt=1 and {uPt }nt=1, Rocktäschel et al. (2015) propose generating sentence-pair representation {vPt }nt=1 via soft-alignment of words in the question and passage as follows:\nvPt = RNN(v P t−1, ct) (3)\nwhere ct = att(uQ, [uPt , v P t−1]) is an attention-pooling vector of the whole question (u Q):\nstj = v Ttanh(WQu u Q j +W P u u P t +W P v v P t−1)\nati = exp(s t i)/Σ m j=1exp(s t j)\nct = Σ m i=1a t iu Q i (4)\nEach passage representation vPt dynamically incorporates aggregated matching information from the whole question.\nWang & Jiang (2016a) introduce match-LSTM, which takes uPt as an additional input into the recurrent network:\nvPt = RNN(v P t−1, [u P t , ct]) (5)\nTo determine the importance of passage parts and attend to the ones relevant to the question, we add another gate to the input ([uPt , ct]) of RNN:\ngt = sigmoid(Wg[u P t , ct])\n[uPt , ct] ∗ = gt [uPt , ct] (6)\nDifferent from the gates in LSTM or GRU, the additional gate is based on the current passage word and its attention-pooling vector of the question, which focuses on the relation between the question and current passage word. The gate effectively model the phenomenon that only parts of the passage are relevant to the question in reading comprehension and question answering. [uPt , ct]\n∗ is utilized in subsequent calculations instead of [uPt , ct]. We call this gated attention-based recurrent networks."
  }, {
    "heading": "3.3 SELF-MATCHING ATTENTION",
    "text": "Through gated attention-based recurrent networks, question-aware passage representation {vPt }nt=1 is generated to pinpoint important parts in the passage. One problem with such representation is that it has very limited knowledge of context. One answer candidate is often oblivious to important cues in the passage outside its surrounding window. Moreover, there exists some sort of lexical or syntactic divergence between the question and passage in the majority of SQuAD dataset (Rajpurkar et al., 2016). Passage context is necessary to infer the answer. To address this problem, we propose directly matching the question-aware passage representation against itself. It dynamically collects evidence from the whole passage for words in passage and encodes the evidence relevant to the current passage word and its matching question information into the passage representation hPt :\nhPt = BiRNN(h P t−1, [v P t , ct]) (7)\nwhere ct = att(vP , vPt ) is an attention-pooling vector of the whole passage (v P ):\nstj = v Ttanh(WPv v P j +W P̃ v v P t )\nati = exp(s t i)/Σ n j=1exp(s t j)\nct = Σ n i=1a t iv P i (8)\nAn additional gate as in gated attention-based recurrent networks is applied to [vPt , ct] to adaptively control the input of RNN.\nSelf-matching extracts evidence from the whole passage according to the current passage word and question information."
  }, {
    "heading": "3.4 OUTPUT LAYER",
    "text": "We follow Wang & Jiang (2016b) and use pointer networks (Vinyals et al., 2015) to predict the start and end position of the answer. In addition, we use an attention-pooling over the question representation to generate the initial hidden vector for the pointer network. Given the passage representation {hPt }nt=1, the attention mechanism is utilized as a pointer to select the start position (p1) and end position (p2) from the passage, which can be formulated as follows:\nstj = v Ttanh(WPh h P j +W a h h a t−1)\nati = exp(s t i)/Σ n j=1exp(s t j)\npt = argmax(at1, . . . , a t n) (9)\nHere hat−1 represents the last hidden state of the answer recurrent network (pointer network). The input of the answer recurrent network is the attention-pooling vector based on current predicted probability at:\nct = Σ n i=1a t ih P i\nhat = RNN(h a t−1, ct) (10)\nWhen predicting the start position, hat−1 represents the initial hidden state of the answer recurrent network. We utilize the question vector rQ as the initial state of the answer recurrent network. rQ = att(uQ, V Qr ) is an attention-pooling vector of the question based on the parameter V Q r :\nsj = v Ttanh(WQu u Q j +W Q v V Q r )\nai = exp(si)/Σ m j=1exp(sj)\nrQ = Σmi=1aiu Q i (11)\nTo train the network, we minimize the sum of the negative log probabilities of the ground truth start and end position by the predicted distributions."
  }, {
    "heading": "4 EXPERIMENT",
    "text": ""
  }, {
    "heading": "4.1 IMPLEMENTATION DETAILS",
    "text": "We mainly focus on the SQuAD dataset to train and evaluate our model, which has garnered a huge attention over the past few months. SQuAD is composed of 100,000+ questions posed by crowd workers on 536 Wikipedia articles. The dataset is randomly partitioned into a training set (80%), a development set (10%), and a test set (10%). The answer to every question is a segment of the corresponding passage.\nWe use the tokenizer from Stanford CoreNLP (Manning et al., 2014) to preprocess each passage and question. The Gated Recurrent Unit (Cho et al., 2014) variant of LSTM is used throughout our model. For word embedding, we use pre-trained case-sensitive GloVe embeddings2 (Pennington et al., 2014) for both questions and passages, and it is fixed during training; We use zero vectors to represent all out-of-vocab words. We utilize 1 layer of bi-directional GRU to compute characterlevel embeddings and 3 layers of bi-directional GRU to encode questions and passages, the gated attention-based recurrent network for question and passage matching is also encoded bidirectionally in our experiment. The hidden vector length is set to 75 for all layers. The hidden size used to compute attention scores is also 75. We also apply dropout (Srivastava et al., 2014) between layers with a dropout rate of 0.2. The model is optimized with AdaDelta (Zeiler, 2012) with an initial learning rate of 1. The ρ and used in AdaDelta are 0.95 and 1e−6 respectively."
  }, {
    "heading": "4.2 MAIN RESULTS",
    "text": "Two metrics are utilized to evaluate model performance of SQuAD: Exact Match (EM) and F1 score. EM measures the percentage of the prediction that matches one of the ground truth answers exactly. F1 measures the overlap between the prediction and ground truth answers which takes the maximum F1 over all of the ground truth answers. The scores on dev set are evaluated by the official script3. Since the test set is hidden, we are required to submit the model to Stanford NLP group to obtain the test scores.\nTable 2 shows exact match and F1 scores on the dev and test set of our model and competing approaches4. The ensemble model consists of 18 training runs with the identical architecture and hyper-parameters. At test time, we choose the answer with the highest sum of confidence scores amongst the 18 runs for each question. As we can see, our method clearly outperforms the baseline and several strong state-of-the-art systems for both single model and ensembles. R-NET (March, 2017) entry refers to results obtained with our improvement after ACL submission. After the original self-matching layer of the passage, we utilize bi-directional GRU to deeply integrate the matching results before feeding them into answer pointer layer. It helps to further propagate the information aggregated by self-matching of the passage.\n2Downloaded from http://nlp.stanford.edu/data/glove.840B.300d.zip. 3Downloaded from http://stanford-qa.com 4Extracted from SQuAD leaderboard http://stanford-qa.com on May. 6, 2017."
  }, {
    "heading": "4.3 MS-MARCO RESULT",
    "text": "We also apply our method to MS-MARCO dataset (Nguyen et al., 2016). MS-MARCO is another machine comprehension dataset, with two key differences from SQuAD. In MS-MARCO, every question has several corresponding passages, so we simply concatenate all passages of one question in the order that given in the dataset. Secondly, the answers in MS-MARCO are not necessarily subspans of the passages so that the metrics in the official tool of MS-MARCO evaluation are BLEU and ROUGE-L, which are widely used in many domains. In this regard, we choose the span with the highest ROUGE-L score with the reference answer as the gold span in the training, and predict the highest scoring span as answer during prediction. We train our model on MS-MARCO dataset, and the results (Table 3) show that our method out-performs other competitive baselines5."
  }, {
    "heading": "4.4 DISCUSSIONS",
    "text": "In this section, we report and discuss some efforts that failed to bring improvements in our experiments. As with all empirical findings on SQuAD, results reported here only apply to our exact settings. The findings do not necessarily indicate the effectiveness of the discussed methods when used to other datasets or combined with baseline models different from ours. We believe these directions are valuable research topics and we are experimenting these ideas with different models and implementations.\n1. Sentence Ranking In SQuAD, the passage consists of several sentences and the answer span always falls into one sentence. It is natural to consider whether ranking sentence would help locate the final answer. We have tried two ways to integrate sentence ranking information: (a) we trained a separate sentence ranking model, and combined this model with the span prediction model; (b) we treat span prediction and sentence prediction as two related task, and trained a multi-task model. Both methods failed to improve the final results. Analysis shows that the sentence models consistently under-perform the span prediction model even on sentence prediction task. Our best sentence model achieves accuracy of 86%, while our span prediction model has over 92% accuracy predicting the answer sentence. This indicates that the exact span information is in fact critical in selecting the correct answer sentence.\n2. Syntax Information We have tried three methods to integrate syntax information into our model. Firstly, we have tried to add some syntax features as input in encoding layers. These syntax features include POS tags, NER results, linearized PCFG tree tags and dependency labels. Secondly, we have tried to integrate a tree-LSTM style module after our encoding layer. We use a multi-input LSTM to build hidden states following dependency tree paths in both top-down and bottom-up passes. Lastly, we tried to use dependency parsing as an additional task in a multi-task setting. All the above failed to bring any benefit to our model on SQuAD dataset.\n3. Multi-hop Inference We have tried to add multi-hop inference modules in the answer pointer layer, but failed to get improvements on the final results in the context of the current R-NET network structure. One reason might be that the questions which require such inference are too complex to learn effectively under current settings, especially considering there are no annotations about explicit inference process in SQuAD.\n5Results except ours are extracted from MS-MARCO leaderboard http://www.msmarco.org/ leaders.aspx on May. 6, 2017.\n4. Question Generation For data-driven approach, labeled data might become the bottleneck for better performance. While texts are abundant, it is not easy to find question-passage pairs that match the style of SQuAD. To generate more data, we trained a sequence-tosequence question generation model using SQuAD dataset (Zhou et al., 2017), and produced a large amount of pseudo question-passage pairs from English Wikipedia. We trained a R-NET model on this pseudo corpus together with SQuAD training data, and we assigned a smaller weight to auto-generated samples so that the total weights of pseudo corpus and real corpus are about equal. So far, such approach failed to make any gains in the final results. Analysis shows that the quality of generated questions needs improvement."
  }, {
    "heading": "5 RELATED WORK",
    "text": "Reading Comprehension and Question Answering Dataset Benchmark datasets play an important role in recent progress in reading comprehension and question answering research. Existing datasets can be classified into two categories according to whether they are manually labeled. Those that are labeled by humans are always in high quality (Richardson et al., 2013; Berant et al., 2014; Yang et al., 2015), but are too small for training modern data-intensive models. Those that are automatically generated from natural occurring data can be very large (Hill et al., 2016; Hermann et al., 2015), which allow the training of more expressive models. However, they are in cloze style, in which the goal is to predict the missing word (often a named entity) in a passage. Moreover, Chen et al. (2016) have shown that the CNN / Daily News dataset (Hermann et al., 2015) requires less reasoning than previously thought, and conclude that performance is almost saturated.\nDifferent from above datasets, the SQuAD provides a large and high-quality dataset. The answers in SQuAD often include non-entities and can be much longer phrase, which is more challenging than cloze-style datasets. Moreover, Rajpurkar et al. (2016) show that the dataset retains a diverse set of answers and requires different forms of logical reasoning, including multi-sentence reasoning. MS MARCO (Nguyen et al., 2016) is also a large-scale dataset. The questions in the dataset are real anonymized queries issued through Bing or Cortana and the passages are related web pages. For each question in the dataset, several related passages are provided. However, the answers are human generated, which is different from SQuAD where answers must be a span of the passage.\nEnd-to-end Neural Networks for Reading Comprehension Along with cloze-style datasets, several powerful deep learning models (Hermann et al., 2015; Hill et al., 2016; Chen et al., 2016; Kadlec et al., 2016; Sordoni et al., 2016; Cui et al., 2016; Trischler et al., 2016; Dhingra et al., 2016; Shen et al., 2016) have been introduced to solve this problem. Hermann et al. (2015) first introduce attention mechanism into reading comprehension. Hill et al. (2016) propose a window-based memory network for CBT dataset. Kadlec et al. (2016) introduce pointer networks with one attention step to predict the blanking out entities. Sordoni et al. (2016) propose an iterative alternating attention mechanism to better model the links between question and passage. Trischler et al. (2016) solve cloze-style question answering task by combining an attentive model with a reranking model. Dhingra et al. (2016) propose iteratively selecting important parts of the passage by a multiplying gating function with the question representation. Cui et al. (2016) propose a two-way attention mechanism to encode the passage and question mutually. Shen et al. (2016) propose iteratively inferring the answer with a dynamic number of reasoning steps and is trained with reinforcement learning.\nNeural network-based models demonstrate the effectiveness on the SQuAD dataset. Wang & Jiang (2016b) combine match-LSTM and pointer networks to produce the boundary of the answer. Xiong et al. (2016) and Seo et al. (2016) employ variant coattention mechanism to match the question and passage mutually. Xiong et al. (2016) propose a dynamic pointer network to iteratively infer the answer. Yu et al. (2016) and Lee et al. (2016) solve SQuAD by ranking continuous text spans within passage. Yang et al. (2016) present a fine-grained gating mechanism to dynamically combine word-level and character-level representation and model the interaction between questions and passages. Wang et al. (2016) propose matching the context of passage with the question from multiple perspectives.\nDifferent from the above models, we introduce self-matching attention in our model. It dynamically refines the passage representation by looking over the whole passage and aggregating evidence relevant to the current passage word and question, allowing our model make full use of passage information. Weightedly attending to word context has been proposed in several works. Ling et al.\n(2015) propose considering window-based contextual words differently depending on the word and its relative position. Cheng et al. (2016) propose a novel LSTM network to encode words in a sentence which considers the relation between the current token being processed and its past tokens in the memory. Parikh et al. (2016) apply this method to encode words in a sentence according to word form and its distance. Since passage information relevant to question is more helpful to infer the answer in reading comprehension, we apply self-matching based on question-aware representation and gated attention-based recurrent networks. It helps our model mainly focus on question-relevant evidence in the passage and dynamically look over the whole passage to aggregate evidence.\nAnother key component of our model is the attention-based recurrent network, which has demonstrated success in a wide range of tasks. Bahdanau et al. (2014) first propose attention-based recurrent networks to infer word-level alignment when generating the target word. Hermann et al. (2015) introduce word-level attention into reading comprehension to model the interaction between questions and passages. Rocktäschel et al. (2015) and Wang & Jiang (2016a) propose determining entailment via word-by-word matching. The gated attention-based recurrent network is a variant of attention-based recurrent network with an additional gate to model the fact that passage parts are of different importance to the particular question for reading comprehension and question answering."
  }, {
    "heading": "6 CONCLUSION",
    "text": "In this technical report, we present R-NET for reading comprehension and question answering. We introduce the gated attention-based recurrent networks and self-matching attention mechanism to obtain representation for the question and passage, and then use the pointer-networks to locate answer boundaries. Our model achieves state-of-the-art results on both SQuAD and MS-MARCO datasets, outperforming several strong competing systems. For future work, we will try to use syntax and knowledge base information into our system. Besides, we are also working on designing new network structures to handle questions that require complex inferences."
  }, {
    "heading": "ACKNOWLEDGEMENT",
    "text": "We thank Pranav Samir Rajpurkar and Percy Liang for help in SQuAD submissions."
  }],
  "year": 2017,
  "references": [{
    "title": "Neural machine translation by jointly learning to align and translate",
    "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"],
    "year": 2014
  }, {
    "title": "Modeling biological processes for reading comprehension",
    "authors": ["Jonathan Berant", "Vivek Srikumar", "Pei-Chun Chen", "Abby Vander Linden", "Brittany Harding", "Brad Huang", "Peter Clark", "Christopher D. Manning"],
    "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2014
  }, {
    "title": "A thorough examination of the cnn/daily mail reading comprehension task",
    "authors": ["Danqi Chen", "Jason Bolton", "Christopher D. Manning"],
    "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics,",
    "year": 2016
  }, {
    "title": "Reading wikipedia to answer opendomain questions",
    "authors": ["Danqi Chen", "Adam Fisch", "Jason Weston", "Antoine Bordes"],
    "venue": "In Association for Computational Linguistics (ACL),",
    "year": 2017
  }, {
    "title": "Long short-term memory-networks for machine reading",
    "authors": ["Jianpeng Cheng", "Li Dong", "Mirella Lapata"],
    "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2016
  }, {
    "title": "Learning phrase representations using RNN encoder-decoder for statistical machine translation",
    "authors": ["Kyunghyun Cho", "Bart van Merrienboer", "Çaglar Gülçehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"],
    "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2014
  }, {
    "title": "Attention-overattention neural networks for reading comprehension",
    "authors": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu"],
    "year": 2016
  }, {
    "title": "Gated-attention readers for text comprehension",
    "authors": ["Bhuwan Dhingra", "Hanxiao Liu", "William W. Cohen", "Ruslan Salakhutdinov"],
    "year": 2016
  }, {
    "title": "Ruminating reader: Reasoning with gated multi-hop attention",
    "authors": ["Yichen Gong", "Samuel R Bowman"],
    "venue": "arXiv preprint arXiv:1704.07415,",
    "year": 2017
  }, {
    "title": "Teaching machines to read and comprehend",
    "authors": ["Karl Moritz Hermann", "Tomás Kociský", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom"],
    "venue": "In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "The goldilocks principle: Reading children’s books with explicit memory representations",
    "authors": ["Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston"],
    "venue": "In Proceedings of the International Conference on Learning Representations,",
    "year": 2016
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber"],
    "venue": "Neural Computation,",
    "year": 1997
  }, {
    "title": "Text understanding with the attention sum reader network",
    "authors": ["Rudolf Kadlec", "Martin Schmid", "Ondrej Bajgar", "Jan Kleindienst"],
    "venue": "In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics,",
    "year": 2016
  }, {
    "title": "Learning recurrent span representations for extractive question answering",
    "authors": ["Kenton Lee", "Tom Kwiatkowski", "Ankur Parikh", "Dipanjan Das"],
    "venue": "arXiv preprint arXiv:1611.01436,",
    "year": 2016
  }, {
    "title": "Not all contexts are created equal: Better word representations with variable attention",
    "authors": ["Wang Ling", "Yulia Tsvetkov", "Silvio Amir", "Ramon Fermandez", "Chris Dyer", "Alan W. Black", "Isabel Trancoso", "Chu-Cheng Lin"],
    "venue": "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2015
  }, {
    "title": "Structural embedding of syntactic trees for machine comprehension",
    "authors": ["Rui Liu", "Junjie Hu", "Wei Wei", "Zi Yang", "Eric Nyberg"],
    "venue": "arXiv preprint arXiv:1703.00572,",
    "year": 2017
  }, {
    "title": "The stanford corenlp natural language processing toolkit",
    "authors": ["Christopher D Manning", "Mihai Surdeanu", "John Bauer", "Jenny Rose Finkel", "Steven Bethard", "David McClosky"],
    "venue": "In ACL (System Demonstrations),",
    "year": 2014
  }, {
    "title": "Recurrent neural network based language model",
    "authors": ["Tomas Mikolov", "Martin Karafiát", "Lukas Burget", "Jan Cernockỳ", "Sanjeev Khudanpur"],
    "venue": "In Interspeech,",
    "year": 2010
  }, {
    "title": "MS MARCO: A human generated machine reading comprehension",
    "authors": ["Tri Nguyen", "Mir Rosenberg", "Xia Song", "Jianfeng Gao", "Saurabh Tiwary", "Rangan Majumder", "Li Deng"],
    "venue": "dataset. CoRR,",
    "year": 2016
  }, {
    "title": "A decomposable attention model for natural language inference",
    "authors": ["Ankur P. Parikh", "Oscar Täckström", "Dipanjan Das", "Jakob Uszkoreit"],
    "venue": "In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2016
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning"],
    "venue": "In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2014
  }, {
    "title": "Squad: 100,000+ questions for machine comprehension of text",
    "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang"],
    "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,",
    "year": 2016
  }, {
    "title": "Mctest: A challenge dataset for the open-domain machine comprehension of text",
    "authors": ["Matthew Richardson", "Christopher J.C. Burges", "Erin Renshaw"],
    "venue": "In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,",
    "year": 2013
  }, {
    "title": "Reasoning about entailment with neural attention",
    "authors": ["Tim Rocktäschel", "Edward Grefenstette", "Karl Moritz Hermann", "Tomás Kociský", "Phil Blunsom"],
    "year": 2015
  }, {
    "title": "Bidirectional attention flow for machine comprehension",
    "authors": ["Minjoon Seo", "Aniruddha Kembhavi", "Ali Farhadi", "Hannaneh Hajishirzi"],
    "venue": "arXiv preprint arXiv:1611.01603,",
    "year": 2016
  }, {
    "title": "Iterative alternating neural attention for machine",
    "authors": ["Alessandro Sordoni", "Phillip Bachman", "Yoshua Bengio"],
    "venue": "reading. CoRR,",
    "year": 2016
  }, {
    "title": "Dropout: a simple way to prevent neural networks from overfitting",
    "authors": ["Nitish Srivastava", "Geoffrey E. Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Natural language comprehension with the epireader",
    "authors": ["Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Kaheer Suleman"],
    "venue": "In Proceedings of the Conference on Empirical Methods in Natural Language Processing,",
    "year": 2016
  }, {
    "title": "Pointer networks. In Advances in Neural Information Processing Systems",
    "authors": ["Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly"],
    "venue": "Annual Conference on Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "Learning natural language inference with LSTM",
    "authors": ["Shuohang Wang", "Jing Jiang"],
    "venue": "In NAACL HLT",
    "year": 2016
  }, {
    "title": "Machine comprehension using match-lstm and answer pointer",
    "authors": ["Shuohang Wang", "Jing Jiang"],
    "venue": "arXiv preprint arXiv:1608.07905,",
    "year": 2016
  }, {
    "title": "Gated self-matching networks for reading comprehension and question answering",
    "authors": ["Wenhui Wang", "Nan Yang", "Furu Wei", "Baobao Chang", "Ming Zhou"],
    "venue": "In Association for Computational Linguistics (ACL),",
    "year": 2017
  }, {
    "title": "Multi-perspective context matching for machine comprehension",
    "authors": ["Zhiguo Wang", "Haitao Mi", "Wael Hamza", "Radu Florian"],
    "venue": "arXiv preprint arXiv:1612.04211,",
    "year": 2016
  }, {
    "title": "Fastqa: A simple and efficient neural architecture for question answering",
    "authors": ["Dirk Weissenborn", "Georg Wiese", "Laura Seiffe"],
    "venue": "arXiv preprint arXiv:1703.04816,",
    "year": 2017
  }, {
    "title": "Dynamic coattention networks for question answering",
    "authors": ["Caiming Xiong", "Victor Zhong", "Richard Socher"],
    "venue": "arXiv preprint arXiv:1611.01604,",
    "year": 2016
  }, {
    "title": "Wikiqa: A challenge dataset for open-domain question answering",
    "authors": ["Yi Yang", "Wen-tau Yih", "Christopher Meek"],
    "venue": "In Proceedings of EMNLP,",
    "year": 2015
  }, {
    "title": "Words or characters? fine-grained gating for reading",
    "authors": ["Zhilin Yang", "Bhuwan Dhingra", "Ye Yuan", "Junjie Hu", "William W. Cohen", "Ruslan Salakhutdinov"],
    "venue": "comprehension. CoRR,",
    "year": 2016
  }, {
    "title": "End-to-end reading comprehension with dynamic answer chunk ranking",
    "authors": ["Yang Yu", "Wei Zhang", "Kazi Hasan", "Mo Yu", "Bing Xiang", "Bowen Zhou"],
    "venue": "arXiv preprint arXiv:1610.09996,",
    "year": 2016
  }, {
    "title": "ADADELTA: an adaptive learning rate method",
    "authors": ["Matthew D. Zeiler"],
    "venue": "CoRR, abs/1212.5701,",
    "year": 2012
  }, {
    "title": "Exploring question understanding and adaptation in neural-network-based question answering",
    "authors": ["Junbei Zhang", "Xiaodan Zhu", "Qian Chen", "Lirong Dai", "Hui Jiang"],
    "venue": "arXiv preprint arXiv:1703.04617,",
    "year": 2017
  }, {
    "title": "Neural question generation from text: A preliminary study",
    "authors": ["Qingyu Zhou", "Nan Yang", "Furu Wei", "Chuanqi Tan", "Hangbo Bao", "Ming Zhou"],
    "venue": "arXiv preprint arXiv:1704.01792,",
    "year": 2017
  }],
  "id": "SP:222d908535d67563709bb72de7aed4739133ee3e",
  "authors": [{
    "name": "SELF-MATCHING NETWORKS",
    "affiliations": []
  }],
  "abstractText": "In this paper, we introduce R-NET, an end-to-end neural networks model for reading comprehension style question answering, which aims to answer questions from a given passage. We first match the question and passage with gated attention-based recurrent networks to obtain the question-aware passage representation. Then we propose a self-matching attention mechanism to refine the representation by matching the passage against itself, which effectively encodes information from the whole passage. We finally employ the pointer networks to locate the positions of answers from the passages. We conduct extensive experiments on the SQuAD and MS-MARCO datasets, and our model achieves the best results on both datasets among all published results.",
  "title": "R-NET: MACHINE READING COMPREHENSION WITH"
}