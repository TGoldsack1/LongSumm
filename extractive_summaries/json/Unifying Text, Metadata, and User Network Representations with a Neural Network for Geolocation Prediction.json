{
  "sections": [{
    "text": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 1260–1272 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1116"
  }, {
    "heading": "1 Introduction",
    "text": "Social media sites have become a popular source of information to analyze current opinions of numerous people. Many researchers have worked to realize various automated analytical methods for social media because manual analysis of such vast amounts of data is difficult. Geolocation prediction is one such analytical method that has been studied widely to predict a user location or a document location. Location information is crucially important information for analyses such as disaster analysis (Sakaki et al., 2010), disease analysis (Culotta, 2010), and political analysis (Tumasjan et al., 2010). Such information is also useful for analyses such as sentiment analysis (Martı́nez-Cámara et al., 2014) and user attribute analysis (Rao et al., 2010) to undertake detailed region-specific analyses.\nGeolocation prediction has been performed for Wikipedia (Overell, 2009), Flickr (Serdyukov et al., 2009; Crandall et al., 2009), Facebook (Backstrom et al., 2010), and Twitter (Cheng et al., 2010; Eisenstein et al., 2010).\nAmong these sources, Twitter is often preferred because of its characteristics, which are suited for geolocation prediction. First, some tweets include geotags, which are useful as ground truth locations. Secondly, tweets include metadata such as timezones and self-declared locations that can facilitate geolocation prediction. Thirdly, a user network is obtainable by consideration of the interaction between two users as a network link.\nHerein, we propose a neural network model to tackle geolocation prediction in Twitter. Past studies have combined text, metadata, and user network information with ensemble approaches (Han et al., 2013, 2014; Rahimi et al., 2015a; Jayasinghe et al., 2016) to achieve state-of-the-art performance. Our model combines text, metadata, and user network information using a complex neural network. Neural networks have recently shown effectiveness to capture complex representations combining simpler representations from large-scale datasets (Goodfellow et al., 2016). We intend to obtain unified text, metadata, and user network representations with an attention mechanism (Bahdanau et al., 2014) that is superior to the earlier ensemble approaches. The contributions of this paper are the following:\n1. We propose a neural network model that learns unified text, metadata, and user network representations with an attention mechanism.\n2. We show that the proposed model outperforms the previous ensemble approaches in two open datasets.\n3. We analyze some components of the proposed model to gain insight into the unification processes of the model.\nOur model specifically emphasizes geolocation prediction in Twitter to use benefits derived from the characteristics described above. However, our\n1260\nmodel can be readily extended to other social media analyses such as user attribute analysis and political analysis, which can benefit from metadata and user network information.\nIn subsequent sections of this paper, we explain the related works in four perspectives in Section 2. The proposed neural network model is described in Section 3 along with two open datasets that we used for evaluations in Section 4. Details of an evaluation are reported in Section 5 with discussions in Section 6. Finally, Section 7 concludes the paper with some future directions."
  }, {
    "heading": "2 Related Works",
    "text": ""
  }, {
    "heading": "2.1 Text-based Approach",
    "text": "Probability distributions of words over locations have been used to estimate the geolocations of users. Maximum likelihood estimation approaches (Cheng et al., 2010, 2013) and language modeling approaches minimizing KL-divergence (Wing and Baldridge, 2011; Kinsella et al., 2011; Roller et al., 2012) have succeeded in predicting user locations using word distributions. Topic modeling approaches to extract latent topics with geographical regions (Eisenstein et al., 2010, 2011; Hong et al., 2012; Ahmed et al., 2013) have also been explored considering word distributions.\nSupervised machine learning methods with word features are also popular in text-based geolocation prediction. Multinomial Naive Bayes (Han et al., 2012, 2014; Wing and Baldridge, 2011), logistic regression (Wing and Baldridge, 2014; Han et al., 2014), hierarchical logistic regression (Wing and Baldridge, 2014), and a multilayer neural network with stacked denoising autoencoder (Liu and Inkpen, 2015) have realized geolocation prediction from text. A semi-supervised machine learning approach by Cha et al. (2015) has also been produced using a sparse-coding and dictionary learning."
  }, {
    "heading": "2.2 User-network-based Approach",
    "text": "Social media often include interactions of several kinds among users. These interactions can be regarded as links that form a network among users. Several studies have used such user network information to predict geolocation. Backstrom et al. (2010) introduced a probabilistic model to predict the location of a user using friendship information in Facebook. Friend and follower information in Twitter were used to predict user locations with a most frequent friend algorithm\n(Davis Jr. et al., 2011), a unified descriptive model (Li et al., 2012b), location-based generative models (Li et al., 2012a), dynamic Bayesian networks (Sadilek et al., 2012), a support vector machine (Rout et al., 2013), and maximum likelihood estimation (McGee et al., 2013). Mention information in Twitter is also used with label propagation models (Jurgens, 2013; Compton et al., 2014) and an energy and social local coefficient model (Kong et al., 2014). Jurgens et al. (2015) compared nine user-network-based approaches targeting Twitter, controlling data conditions."
  }, {
    "heading": "2.3 Metadata-based Approach",
    "text": "Metadata such as location fields are useful as effective clues to predict geolocation. Hecht et al. (2011) reported that decent accuracy of geolocation prediction can be achieved using location fields. Approaches to combine metadata with texts are also proposed to extend text-based approaches. Combinatory approaches such as a dynamically weighted ensemble method (Mahmud et al., 2012), polygon stacking (Schulz et al., 2013), stacking (Han et al., 2013, 2014), and average pooling with a neural network (Miura et al., 2016) have strengthened geolocation prediction."
  }, {
    "heading": "2.4 Combinatory Approach Extending User-network-based Approach",
    "text": "Several attempts have been made to combine usernetwork-based approaches with other approaches. A text-based approach with logistic regression was combined with label propagation approaches to enhance geolocation prediction (Rahimi et al., 2015a,b, 2016). Jayasinghe et al. (2016) combined nine components including text-based approaches, metadata-based approaches, and a usernetwork-based approach with a cascade ensemble method."
  }, {
    "heading": "2.5 Comparisons with Proposed Model",
    "text": "A model we propose in Section 3 which combines text, metadata, and user network information with a neural network, can be regarded as an alternative to approaches using text and metadata (Mahmud et al., 2012; Schulz et al., 2013; Han et al., 2013, 2014; Miura et al., 2016), approaches with text and user network information (Rahimi et al., 2015a,b), and an approach with text, metadata, and user network information (Jayasinghe et al., 2016). In Section 5, we demonstrate that our model outperforms earlier models.\nIn terms of machine learning methods, our model is a neural network model that shares some similarity with previous neural network models (Liu and Inkpen, 2015; Miura et al., 2016). Our model and these previous models have two key differences. First, our model integrates user network information along with other information. Secondly, our model combines text and metadata with an attention mechanism (Bahdanau et al., 2014)."
  }, {
    "heading": "3 Model",
    "text": ""
  }, {
    "heading": "3.1 Proposed Model",
    "text": "Figure 1 presents an overview of our model: a complex neural network for classification with a city as a label. For each user, the model accepts inputs of messages, a location field, a description field, a timezone, linked users, and the cities of linked users.\nUser network information is incorporated by city embeddings and user embeddings of linked users. User embeddings are introduced along with city embeddings because linked users with city information1 are limited. We chose to let the model learn geolocation representations of linked users directly via user embeddings. The model can be\n1City information are provided by a dataset. The detail of the city information is explained in Section 4.\nbroken down to several components, details of which are described in Section 3.1.1–3.1.4."
  }, {
    "heading": "3.1.1 Text Component",
    "text": "We describe the text component of the model, which is the “TEXT” section in Figure 1. Figure 2 presents an overview of the text component. The component consists of a recurrent neural network (RNN) (Graves, 2012) layer and attention layers. An input of the component is a timeline of a user, which consists of messages in a time sequence.\nAs an implementation of RNN, we used Gated Recurrent Unit (GRU) (Cho et al., 2014) with a bidirectional setting. In the RNN layer, word embeddings x of a message are processed with the following transition functions:\nzt = σ (W zxt + U zht−1 + bz) (1)\nrt = σ (W rxt + U rht−1 + br) (2)\nh̃t = tanh (W hxt + Uh (rt ⊙ ht−1) + bh) (3)\nht = (1− zt)⊙ ht−1 + zt ⊙ h̃t (4)\nwhere zt is an update gate, rt is a reset gate, h̃t is a candidate state, ht is a state, W z,W r,W h, U z, U r, Uh are weight matrices, bz, br, bh are bias vectors, σ is a logistic sigmoid function, and ⊙ is an element-wise multiplication operator. The bi-directional GRU outputs −→ h\nand ←− h are concatenated to form g where gt =−→\nht∥ ←− ht and are passed to the first attention layer AttentionM. AttentionM computes a message representation m as a weighted sum of gt with weight αt:\nm = ∑\nt\nαtgt (5)\nαt = exp\n( vTαut ) ∑\nt exp (v T αut)\n(6)\nut = tanh (W αgt + bα) (7)\nwhere vα is a weight vector, W α is a weight matrix, and bα a bias vector. ut is an attention context vector calculated from gt with a single fullyconnected layer (Eq. 7). ut is normalized with softmax to obtain αt as a probability (Eq. 6). The message representation m is passed to the second attention layer AttentionTL to obtain a timeline representation from message representations."
  }, {
    "heading": "3.1.2 Text and Metadata Component",
    "text": "We describe text and metadata components of the model, which is the “TEXT&META” section in Figure 1. This component considers the following three types of metadata along with text: location a text field in which a user is allowed to write the user location freely, description a text field a user can use for self-description, and timezone a selective field from which a user can choose a timezone. Note that certain percentages of these fields are not available2, and unknown tokens are used for inputs in such cases.\n2Han et al. (2014) reported missing percentages of 19% for location, 24% for description, and 25%for timezone.\nWe process location fields and description fields similarly to messages using an RNN layer and an attention layer. Because there is only one location and one description per user, a second attention layer is not required, as it is in the text component. We also chose to share word embeddings among the messages, the location, and the description processes because these inputs are all textual information. For the timezone, an embedding is assigned for each timezone value. A processed timeline representation, a location representation, and a description representation are then passed to the attention layer AttentionU with a timezone representation. AttentionU combines these four representations and outputs a user representation. This combination is done as in AttentionTL with four representations as g1 . . . g4 in Eq. 5."
  }, {
    "heading": "3.1.3 User Network Component",
    "text": "We describe the user network component of the model, which is the “USERNET” section in Figure 1. Figure 3 presents an overview of the user network component. The model has two inputs linked cities and linked users. Users connected with a user network are extracted as linked users. We treat their cities3 as linked cities. Linked cities and linked users are assigned with city embeddings c and user embeddings a respectively. c and a are then processed to output p = c ⊕ a, where ⊕ is an element-wise addition operator. p is then passed to the subsequent attention layer AttentionN to obtain a user network representa-\n3A user with city information implies that the user is included in a training set.\ntion as in AttentionU."
  }, {
    "heading": "3.1.4 Model Output",
    "text": "An output of the text and metadata component and an output of the mention network component are further passed to the final attention layer AttentionUN to obtain a merged user representation as in AttentionU. The merged user representation is then connected to labels with a fully connected layer FCUN."
  }, {
    "heading": "3.2 Sub-models of the Proposed Model",
    "text": "SUB-NN-TEXT We prepare a sub-model SUBNN-TEXT by adding FCU and FCUN to the text component. This sub-model can be considered as a variant of a neural network model by Yang et al. (2016), which learns a representation of hierarchical text.\nSUB-NN-UNET We prepare a sub-model SUBNN-UNET by connecting the text component and the user network component with FCU, AttentionUN, and FCUN. This model can be regarded as a model that uses text and user network information.\nSUB-NN-META We prepare a sub-model SUBNN-META by adding FCU and FCUN to the metadata component. This model is a text-metabased model that uses text and metadata."
  }, {
    "heading": "4 Data",
    "text": ""
  }, {
    "heading": "4.1 Dataset Specifications",
    "text": "TwitterUS The first dataset we used is TwitterUS assembled by Roller et al. (2012), which consists of 429K training users, 10K development users, and 10K test users in a North American region. The ground truth location of a user is set to the first geotag of the user in the dataset. We\ncollected TwitterUS tweets using TwitterAPI to reconstruct TwitterUS to obtain metadata along with text. Up to date versions in November–December 2016 were used for the metadata4. We additionally assigned city centers to ground truth geotags using the city category of Han et al. (2012) to make city prediction possible in this dataset. TwitterUS (train) in Table 1 presents some properties related to the TwitterUS training set.\nW-NUT The second dataset we used is W-NUT, a user-level dataset of the geolocation prediction shared task of W-NUT 2016 (Han et al., 2016). The dataset consists of 1M training users, 10K development users, and 10K test users. The ground truth location of a user is decided by majority voting of the closest city center. Like in TwitterUS, we obtained metadata and texts using TwitterAPI. Up to date versions in August–September 2016 were used for the metadata. W-NUT (train) in Table 1 presents some properties related to the WNUT training set."
  }, {
    "heading": "4.2 Construction of the User Network",
    "text": "We construct mention networks (Jurgens, 2013; Compton et al., 2014; Rahimi et al., 2015a,b) from datasets as user networks. To do so, we follow the approach of Rahimi et al. (2015a) and Rahimi et al. (2015b) who use uni-directional mention to set edges of a mention network. An edge is set between the two users nodes if a user mentions another user. The number of unidirectional mention edges for TwitterUS and WNUT can be found in Table 1.\nThe uni-directional setting results to large numbers of edges, which often are computationally expensive to process. We restricted edges to satisfy one of the following conditions to reduce the size: (1) both users have ground truth locations or (2) one user has a ground truth location and another user is mentioned 5 times or more in a training set. The number of reduced-edges with these conditions in TwitterUS and W-NUT can be confirmed in Table 1."
  }, {
    "heading": "5 Evaluation",
    "text": ""
  }, {
    "heading": "5.1 Implemented Baselines",
    "text": ""
  }, {
    "heading": "5.1.1 LR",
    "text": "LR is an l1-regularized logistic regression model with k-d tree regions (Roller et al., 2012) used\n4TwitterAPI returns the current version of metadata even for an old tweet.\nin Rahimi et al. (2015a). The model uses tfidf weighted bag-of-words unigrams for features. This model is simple, but it has shown state-ofthe-art performance in cases when only text is available."
  }, {
    "heading": "5.1.2 MADCEL-B-LR",
    "text": "MADCEL-B-LR, a model presented by (Rahimi et al., 2015a), combines LR with Modified Adsorption (MAD) (Talukdar and Crammer, 2009). MAD is a graph-based label propagation algorithm that optimizes an objective with a prior term, a smoothness term, and an uninformativeness term. LR is combined with MAD by introducing LR results as dongle nodes to MAD.\nThis model includes an algorithm for the construction of a mention network. The algorithm removes celebrity users5 and collapses a mention network6. We use binary edges for user network edges because they performed slightly better than weighted edges by accuracy@161 metric in Rahimi et al. (2015a)."
  }, {
    "heading": "5.1.3 LR-STACK",
    "text": "LR-STACK is an ensemble learning model that combines four LR classifiers (LR-MSG, LR-LOC, LR-DESC, LR-TZ) with an l2-regularized logistic regression meta-classifier (LR-2ND). LR-MSG, LR-LOC, LR-DESC, and LR-TZ respectively use messages, location fields, description fields, and timezones as their inputs. This model is similar to the stacking (Wolpert, 1992) approach taken in Han et al. (2013) and Han et al. (2014), which showed superior performance compared to a feature concatenation approach.\nThe model takes the following three steps to combine text and metadata: Step 1 LR-MSG, LRLOC, LR-DESC, and LR-TZ are trained using a training set, Step 2 the outputs of the four classifiers on the training set are obtained with 10-fold cross validation, and Step 3 LR-2ND is trained using the outputs of the four classifiers."
  }, {
    "heading": "5.1.4 MADCEL-B-LR-STACK",
    "text": "MADCEL-B-LR-STACK is a combined model of MADCEL-B-LR and LR-STACK. LR-STACK results are introduced as dongle nodes to MAD instead of LR results to combine text, metadata, and network information.\n5Users with more than t unique mentions. 6Users not included in training users or test users are removed and disconnected edges with the removals are converted to direct edges."
  }, {
    "heading": "5.2 Model Configurations",
    "text": ""
  }, {
    "heading": "5.2.1 Text Processor",
    "text": "We applied a lower case conversion, a unicode normalization, a Twitter user name normalization, and a URL normalization for text pre-processing. The pre-processed text is then segmented using Twokenizer (Owoputi et al., 2013) to obtain words."
  }, {
    "heading": "5.2.2 Pre-training of Embeddings",
    "text": "We pre-trained word embeddings using messages, location fields, and description fields of a training set using fastText (Bojanowski et al., 2016) with the skip-gram algorithm. We also pre-trained user embeddings using the non-reduced mention network described in Section 4.2 of a training set with LINE (Tang et al., 2015). The detail of pre-training parameters are described in Appendix A.1."
  }, {
    "heading": "5.2.3 Neural Network Optimization",
    "text": "We chose an objective function of our models to cross-entropy loss. l2 regularization was applied to the RNN layers, the attention context vectors, and the FC layers of our models to avoid overfitting. The objective function was minimized through stochastic gradient descent over shuffled mini-batches with Adam (Kingma and Ba, 2014)."
  }, {
    "heading": "5.2.4 Model Parameters",
    "text": "The layers and the embeddings in our models have unit size and embedding dimension parameters. Our models and the baseline models have regularization parameter α, which is sensitive to a dataset. The baseline models have additional k-d tree bucket size c, celebrity threshold t, and MAD parameters µ1, µ2, and µ3, which are also data sensitive.\nWe chose optimal values for these parameters in terms of accuracy with a grid search using the development sets of TwitterUS and W-NUT. Details of the parameter selection strategies and the selected values are described in Appendix A.2."
  }, {
    "heading": "5.2.5 Metrics",
    "text": "We evaluate the models in the following four commonly used metrics in geolocation prediction: accuracy the percentage of correctly predicted cities, accuracy@161 a relaxed accuracy that takes prediction errors within 161 km as correct predictions, median error distance median value of error distances in predictions, and mean error distance mean value of error distances in predictions."
  }, {
    "heading": "5.3 Result Performance on TwitterUS",
    "text": "Table 2 presents results of our models and the implemented baseline models on TwitterUS. We also list values from earlier reports (Han et al., 2012; Wing and Baldridge, 2014; Rahimi et al., 2015a,b, 2016) to make our results readily comparable with past reported values.\nWe performed some statistical significance tests among model pairs that share the same inputs. The values in the Sign. Test ID column of Table 2 represent the IDs of these pairs. As a preparation of statistical significance tests, accuracies, accuracy@161s, and error distances of each test user were calculated for each model pair. Twosided Fisher-Pittman Permutation tests were used for testing accuracy and accuracy@161. Mood’s median test was used for testing error distance in terms of median. Paired t-tests were used for testing error distance in terms of mean.\nWe confirmed the significance of improvements\nin accuracy@161 and mean distance error for all of our models. Three of our models also improved in terms of accuracy. Especially, the proposed model achieved a 2.8% increase in accuracy and a 2.4% increase in accuracy@161 against the counterpart baseline model MADCEL-B-LRSTACK. One negative result we found was the median error distance between SUB-NN-META and LR-STACK. The baseline model LR-STACK performed 4.5 km significantly better than our model.\nPerformance on W-NUT Table 3 presents the results of our models and the implemented baseline models on W-NUT. As for TwitterUS, we listed values from Miura et al. (2016) and Jayasinghe et al. (2016). We tested the significance of these results in the same way as we did for TwitterUS.\nWe confirmed significant improvement in the four metrics for all of our models. The proposed model achieved a 4.8% increase in accuracy and a\n6.6% increase in accuracy@161 against the counterpart baseline model MADCEL-B-LR-STACK. The accuracy is 3.8% higher against the previously reported best value (Jayasinghe et al., 2016) which combined texts, metadata, and user network information with an ensemble method."
  }, {
    "heading": "6 Discussion",
    "text": ""
  }, {
    "heading": "6.1 Analyses of Attention Probabilities",
    "text": ""
  }, {
    "heading": "6.1.1 Unification Strategies",
    "text": "In the evaluation, the proposed model has implicitly shown effectiveness at unifying text, metadata, and user network representations through improvements in the four metrics. However, details of the unification processes are not clear from the model outputs because they are merely the probabilities of estimated locations. To gain insight into the unification processes, we analyzed the states of two attention layers: AttentionU and AttentionUN in Figure 1.\nFigure 4 presents the estimated probability density functions (PDFs) of the four input representations for AttentionU. These PDFs are estimated with kernel density estimation from the development sets of TwitterUS and W-NUT, where all four representations are available. From the PDFs, it is apparent that the model assigns higher probabilities to time line representations than to other three representations in TwitterUS compared to W-NUT. This finding is reasonable because timelines in TwitterUS consist of more tweets (tweet/user in Table 1) and are likely to be more informative than in W-NUT.\nFigure 5 presents the estimated PDFs of user network representations for AttentionUN. These\nPDFs are estimated from the development sets of TwitterUS and W-NUT, where both input representations are available. Strong preference of network representation for TwitterUS against WNUT is found in the PDFs. This finding is intuitive because TwitterUS has substantially more user network edges (reduced-edge/user in Table 1) than W-NUT, which is likely to benefit more from user network information."
  }, {
    "heading": "6.1.2 Attention Patterns",
    "text": "We further analyzed the proposed model by clustering attention probabilities to capture typical attention patterns. For each user, we assigned six attention probabilities of AttentionU and AttentionUN as features for a clustering. A kmeans clustering was performed over these users with 9 clusters. The clustering clearly separated the users to 5 clusters for TwitterUS users and 4 clusters for W-NUT users. We extracted typical users of each cluster by selecting the closest users of the cluster centroids. Figure 6 shows a clustering result and the attention probabilities of these users.\nThese attention probabilities can be considered as typical attention patterns of the proposed model and match with the previously estimated PDFs. For example, cluster 2 and 3 represent an attention pattern that processes users by balancing the representations of locations along with the representations of timelines. Additionally, the location probabilities in this pattern are in the right tail region of the location PDF."
  }, {
    "heading": "6.2 Limitations of Proposed Model",
    "text": ""
  }, {
    "heading": "6.2.1 City Prediction",
    "text": "The evaluation produced improvements in most of our models in the four metrics. One exception we found was the median distance error between SUB-NN-META and LR-STACKING in TwitterUS. Because the median distance error of SUB-NN-META was quite low (46.8 km), we\nmeasured the performance of an oracle model where city predictions are all correct (accuracy of 100%) in the test set.\nTable 4 denotes this oracle performance. The oracle mean error distance is 31.4 km. Its standard deviation is 30.1. Note that ground truth locations of TwitterUS are geotags and will not exactly match the oracle city centers. These oracle values imply that the current median error distances are close to the lower bound of the city classification approach and that they are difficult to improve."
  }, {
    "heading": "6.2.2 Errors with High Confidences",
    "text": "The proposed model still contains 28–30% errors even in accuracy@161. A qualitative analysis of errors with high confidences was performed to investigate cases that the model fails. We found two common types of error in the error analysis. The first is a case when a location field is incorrect due to a reason such as a house move. For example, the model predicted “Hong Kong” for a user with a location field of “Hong Kong” but has the gold location of “Toronto”. The second is a case when a user tweets a place name of a travel. For example, the model predicted “San Francisco” for a user who tweeted about a travel to “San Francisco” but has the gold location of “Boston”.\nThese two types of error are difficult to handle with the current architecture of the proposed model. The architecture only supports single location field which disables the model to track location changes. The architecture also treats each\ntweet independently which forbids the model to express a temporal state like traveling."
  }, {
    "heading": "7 Conclusion",
    "text": "As described in this paper, we proposed a complex neural network model for geolocation prediction. The model unifies text, metadata, and user network information. The model achieved the maximum of a 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy@161 against several previous state-of-the-art models. We further analyzed the states of several attention layers, which revealed that the probabilities assigned to timeline representations and user network representations match to some statistical characteristics of datasets.\nAs future works of this study, we are planning to expand the proposed model to handle multiple locations and a temporal state to capture location changes and states like traveling. Additionally, we plan to apply the proposed model to other social media analyses such as gender analysis and age analysis. In these analyses, metadata like location fields and timezones may not be effective like in geolocation prediction. However, a user network is known to include various user attributes information including gender and age (McPherson et al., 2001) which suggests the unification of text and user network information to result in a success as in geolocation prediction."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to thank the members of Okumura– Takamura Group at Tokyo Institute of Technology for having insightful discussions about user profiling models in social media. We would also like to thank the anonymous reviewer for their comments to improve this paper."
  }, {
    "heading": "A Supplemental Materials",
    "text": "A.1 Parameters of Embedding Pre-training Word embeddings were pre-trained with the parameters of learning rate=0.025, window size=5, negative sample size=5, and epoch=5. User embeddings were pre-trained with the parameters of initial learning rate=0.025, order=2, negative sample size=5, and training sample size=100M.\nA.2 Model Parameters and Parameter Selection Strategies\nUnit Sizes, Embedding Dimensions, and a Max Tweet Number The layers and the embeddings in our models have unit size and embedding dimension parameters. We also restricted the maximum number of tweets per user for TwitterUS to reduce memory footprints. Table 5 shows the values for these parameters. Smaller values were set for TwitterUS because TwitterUS is approximately 2.6 times larger in terms of tweet number. It was computationally expensive to process TwiiterUS in the same settings as W-NUT.\nRegularization Parameters and Bucket Sizes We chose optimal values of α using a grid search with the development sets of TwitterUS and WNUT. The range of α was set as the following: α ∈ {1e−4, 5e−5, 1e−5, 5e−6, 1e−6, 5e−7, 1e−7, 5e−8, 1e−8}.\nWe also chose optimal values of c using grid search with the development sets of TwitterUS and W-NUT for the baseline models. The range of c was set as the following for TwitterUS: c ∈ {50, 100, 150, 200, 250, 300, 339}. The following was set for W-NUT: c ∈ {100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000, 2500, 3000, 3028}. Table 6 presents selected values of α and c. For LR-STACK and MADCEl-B-LR-STACK, different parameters of α and c were selected for each logistic regression classifier.\nMAD Parameters and Celebrity Threshold The MAD parameters µ1, µ2, and µ3 and celebrity threshold t were also chosen using grid search with the development sets of TwitterUS and WNUT. The ranges of µ1, µ2, and µ3 were set as the following: µ1 ∈ {1.0}, µ2 ∈ {0.001, 0.01, 0.1, 1.0, 10.0}, µ3 ∈ {0.0, 0.001, 0.01, 0.1, 1.0, 10.0}. The range of t for TwitterUS was set as t ∈ {2, . . . , 16}. The range of t for W-NUT was set\nas t ∈ {2, . . . , 6}. Table 6 presents selected values of µ1, µ2, µ3, and t."
  }],
  "year": 2017,
  "references": [{
    "title": "Hierarchical geographical modeling of user locations from social media posts",
    "authors": ["Amr Ahmed", "Liangjie Hong", "Alexander J. Smola."],
    "venue": "Proceedings of the 22nd International Conference on World Wide Web. pages 25–36.",
    "year": 2013
  }, {
    "title": "Find me if you can: Improving geographical prediction with social and spatial proximity",
    "authors": ["Lars Backstrom", "Eric Sun", "Cameron Marlow."],
    "venue": "Proceedings of the 19th International Conference on World Wide Web. pages 61–70.",
    "year": 2010
  }, {
    "title": "Neural machine translation by jointly learning to align and translate",
    "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."],
    "venue": "Computing Research Repository abs/1409.0473. http://arxiv.org/abs/1409.0473.",
    "year": 2014
  }, {
    "title": "Enriching word vectors with subword information",
    "authors": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov."],
    "venue": "arXiv preprint arXiv:1607.04606 .",
    "year": 2016
  }, {
    "title": "Twitter geolocation and regional classification via sparse coding",
    "authors": ["Miriam Cha", "Youngjune Gwon", "H.T. Kung."],
    "venue": "Proceedings of the Ninth International AAAI Conference on Web and Social Media.",
    "year": 2015
  }, {
    "title": "You are where you tweet: A content-based approach to geo-locating Twitter users",
    "authors": ["Zhiyuan Cheng", "James Caverlee", "Kyumin Lee."],
    "venue": "Proceedings of the 19th ACM International Conference on Information and Knowledge Management. pages 759–",
    "year": 2010
  }, {
    "title": "A content-driven framework for geolocating microblog users",
    "authors": ["Zhiyuan Cheng", "James Caverlee", "Kyumin Lee."],
    "venue": "ACM Transactions on Intelligent Systems and Technology 4(1):1–27. Article 2.",
    "year": 2013
  }, {
    "title": "Learning phrase representations using RNN encoder–decoder for statistical machine translation",
    "authors": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."],
    "venue": "Proceedings of",
    "year": 2014
  }, {
    "title": "Geotagging one hundred million Twitter accounts with total variation minimization",
    "authors": ["Ryan Compton", "David Jurgens", "David Allen."],
    "venue": "Proceedings of the 2014 IEEE International Conference on BigData. pages 393–401.",
    "year": 2014
  }, {
    "title": "Mapping the world’s photos",
    "authors": ["David J. Crandall", "Lars Backstrom", "Daniel Huttenlocher", "Jon Kleinberg."],
    "venue": "Proceedings of the 18th International Conference on World Wide Web. pages 761– 770.",
    "year": 2009
  }, {
    "title": "Towards detecting influenza epidemics by analyzing Twitter messages",
    "authors": ["Aron Culotta."],
    "venue": "Proceedings of the First Workshop on Social Media Analytics. pages 115–122.",
    "year": 2010
  }, {
    "title": "Inferring the location of Twitter messages based on user relationships",
    "authors": ["Clodoveu A. Davis Jr.", "Gisele L. Pappa", "Diogo Rennó Rocha de Oliveira", "Filipe de L. Arcanjo."],
    "venue": "Transactions in GIS 15(6):735–751.",
    "year": 2011
  }, {
    "title": "Sparse additive generative models of text",
    "authors": ["Jacob Eisenstein", "Amr Ahmed", "Eric P. Xing."],
    "venue": "Proceedings of the 28th International Conference on Machine Learning. pages 1041–1048.",
    "year": 2011
  }, {
    "title": "A latent variable model for geographic lexical variation",
    "authors": ["Jacob Eisenstein", "Brendan O’Connor", "Noah A. Smith", "Eric P. Xing"],
    "venue": "In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing",
    "year": 2010
  }, {
    "title": "Deep Learning",
    "authors": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville."],
    "venue": "MIT Press.",
    "year": 2016
  }, {
    "title": "Supervised Sequence Labelling with Recurrent Neural Networks, volume 385 of Studies in Computational Intelligence",
    "authors": ["Alex Graves."],
    "venue": "SpringerVerlag Berlin Heidelberg.",
    "year": 2012
  }, {
    "title": "Geolocation prediction in social media data by finding location indicative words",
    "authors": ["Bo Han", "Paul Cook", "Timothy Baldwin."],
    "venue": "Proceedings of COLING 2012. pages 1045–1062.",
    "year": 2012
  }, {
    "title": "A stacking-based approach to twitter user geolocation prediction",
    "authors": ["Bo Han", "Paul Cook", "Timothy Baldwin."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations. pages 7–12.",
    "year": 2013
  }, {
    "title": "Textbased Twitter user geolocation prediction",
    "authors": ["Bo Han", "Paul Cook", "Timothy Baldwin."],
    "venue": "Journal of Artificial Intelligence Research 49(1):451–500.",
    "year": 2014
  }, {
    "title": "Twitter geolocation prediction shared task of the 2016 workshop on noisy usergenerated text",
    "authors": ["Bo Han", "Afshin Rahimi", "Leon Derczynski", "Timothy Baldwin."],
    "venue": "Proceedings of the Second Workshop on Noisy User-generated Text. pages 213–217.",
    "year": 2016
  }, {
    "title": "Tweets from Justin Bieber’s heart: the dynamics of the location field in user profiles",
    "authors": ["Brent Hecht", "Lichan Hong", "Bongwon Suh", "Ed H. Chi."],
    "venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. pages 237–246.",
    "year": 2011
  }, {
    "title": "Discovering geographical topics in the Twitter stream",
    "authors": ["Liangjie Hong", "Amr Ahmed", "Siva Gurumurthy", "Alexander J. Smola", "Kostas Tsioutsiouliklis."],
    "venue": "Proceedings of the 21st International Conference on World Wide Web. pages 769–778.",
    "year": 2012
  }, {
    "title": "CSIRO Data61 at the WNUT geo shared task",
    "authors": ["Gaya Jayasinghe", "Brian Jin", "James Mchugh", "Bella Robinson", "Stephen Wan."],
    "venue": "Proceedings of the Second Workshop on Noisy User-generated Text. pages 218–226.",
    "year": 2016
  }, {
    "title": "That’s what friends are for: Inferring location in online social media platforms based on social relationships",
    "authors": ["David Jurgens."],
    "venue": "Proceedings of the Seventh International AAAI Conference on Web and Social Media.",
    "year": 2013
  }, {
    "title": "Geolocation prediction in Twitter using social networks: A critical analysis and review of current practice",
    "authors": ["David Jurgens", "Tyler Finethy", "James McCorriston", "Yi Xu", "Derek Ruths."],
    "venue": "Proceedings of the Ninth International AAAI Conference on",
    "year": 2015
  }, {
    "title": "Adam: A method for stochastic optimization",
    "authors": ["Diederik P. Kingma", "Jimmy Ba."],
    "venue": "arXiv preprint arXiv:1412.6980 .",
    "year": 2014
  }, {
    "title": "I’m eating a sandwich in Glasgow”: Modeling locations with tweets",
    "authors": ["Sheila Kinsella", "Vanessa Murdock", "Neil O’Hare"],
    "venue": "In Proceedings of the Third International Workshop on Search and Mining User-generated Contents",
    "year": 2011
  }, {
    "title": "SPOT: Locating social media users based on social network context",
    "authors": ["Longbo Kong", "Zhi Liu", "Yan Huang."],
    "venue": "Proceedings of the VLDB Endowment 7(13):1681–1684.",
    "year": 2014
  }, {
    "title": "Multiple location profiling for users and relationships from social network and content",
    "authors": ["Rui Li", "Shengjie Wang", "Kevin Chen-Chuan Chang."],
    "venue": "Proceedings of the VLDB Endowment 5(11):1603–1614.",
    "year": 2012
  }, {
    "title": "Towards social user profiling: Unified and discriminative influence model for inferring home locations",
    "authors": ["Rui Li", "Shengjie Wang", "Hongbo Deng", "Rui Wang", "Kevin Chen-Chuan Chang."],
    "venue": "Proceedings of the 18th ACM SIGKDD International Conference",
    "year": 2012
  }, {
    "title": "Estimating user location in social media with stacked denoising autoencoders",
    "authors": ["Ji Liu", "Diana Inkpen."],
    "venue": "Proceedings of the First Workshop on Vector Space Modeling for Natural Language Processing. pages 201–210.",
    "year": 2015
  }, {
    "title": "Where is this tweet from? Inferring home locations of Twitter users",
    "authors": ["Jalal Mahmud", "Jeffrey Nichols", "Clemens Drews."],
    "venue": "Proceedings of the Sixth International AAAI Conference on Weblogs and Social Media.",
    "year": 2012
  }, {
    "title": "Sentiment analysis in Twitter",
    "authors": ["Eugenio Martı́nez-Cámara", "Maria Teresa Martı́nValdivia", "Luis Alfonso Ureña López", "Arturo Montejo Raéz"],
    "venue": "Natural Language Engineering",
    "year": 2014
  }, {
    "title": "Location prediction in social media based on tie strength",
    "authors": ["Jeffrey McGee", "James Caverlee", "Zhiyuan Cheng."],
    "venue": "Proceedings of the 22nd ACM International Conference on Information & Knowledge Management. pages 459–468.",
    "year": 2013
  }, {
    "title": "Birds of a feather: Homophily in social networks",
    "authors": ["Miller McPherson", "Lynn Smith-Lovin", "James M Cook."],
    "venue": "Annual review of sociology 27(1):415– 444.",
    "year": 2001
  }, {
    "title": "A simple scalable neural networks based model for geolocation prediction in Twitter",
    "authors": ["Yasuhide Miura", "Motoki Taniguchi", "Tomoki Taniguchi", "Tomoko Ohkuma."],
    "venue": "Proceedings of the Second Workshop on Noisy User-generated Text. pages 235–239.",
    "year": 2016
  }, {
    "title": "Geographic Information Retrieval: Classification, Disambiguation, and Modeling",
    "authors": ["Simon E. Overell."],
    "venue": "Ph.D. thesis, Imperial College London.",
    "year": 2009
  }, {
    "title": "Improved part-of-speech tagging for online conversational text with word clusters",
    "authors": ["Olutobi Owoputi", "Brendan O’Connor", "Chris Dyer", "Kevin Gimpel", "Nathan Schneider", "Noah A. Smith"],
    "venue": "In Proceedings of the 2013 Conference of the North",
    "year": 2013
  }, {
    "title": "Twitter user geolocation using a unified text and network prediction model",
    "authors": ["Afshin Rahimi", "Trevor Cohn", "Timothy Baldwin."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint",
    "year": 2015
  }, {
    "title": "pigeo: A python geotagging tool",
    "authors": ["Afshin Rahimi", "Trevor Cohn", "Timothy Baldwin."],
    "venue": "Proceedings of ACL-2016 System Demonstrations. pages 127–132.",
    "year": 2016
  }, {
    "title": "Exploiting text and network context for geolocation of social media users",
    "authors": ["Afshin Rahimi", "Duy Vu", "Trevor Cohn", "Timothy Baldwin."],
    "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational",
    "year": 2015
  }, {
    "title": "Classifying latent user attributes in Twitter",
    "authors": ["Delip Rao", "David Yarowsky", "Abhishek Shreevats", "Manaswi Gupta."],
    "venue": "Proceedings of the Second International Workshop on Search and Mining Usergenerated Contents. pages 37–44.",
    "year": 2010
  }, {
    "title": "Supervised text-based geolocation using language models on an adaptive grid",
    "authors": ["Stephen Roller", "Michael Speriosu", "Sarat Rallapalli", "Benjamin Wing", "Jason Baldridge."],
    "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Lan-",
    "year": 2012
  }, {
    "title": "Where’s @wally?: A classification approach to geolocating users based on their social ties",
    "authors": ["Dominic Rout", "Kalina Bontcheva", "Daniel PreoţiucPietro", "Trevor Cohn."],
    "venue": "Proceedings of the 24th ACM Conference on Hypertext and Social Media. pages",
    "year": 2013
  }, {
    "title": "Finding your friends and following them to where you are",
    "authors": ["Adam Sadilek", "Henry Kautz", "Jeffrey P. Bigham."],
    "venue": "Proceedings of the Fifth ACM International Conference on Web Search and Data Mining. pages 723–732.",
    "year": 2012
  }, {
    "title": "Earthquake shakes Twitter users: Real-time event detection by social sensors",
    "authors": ["Takeshi Sakaki", "Makoto Okazaki", "Yutaka Matsuo."],
    "venue": "Proceedings of the 19th International Conference on World Wide Web. pages 851–860.",
    "year": 2010
  }, {
    "title": "A multi-indicator approach for geolocalization of tweets",
    "authors": ["Axel Schulz", "Aristotelis Hadjakos", "Heiko Paulheim", "Johannes Nachtwey", "Max Mühlhäuser."],
    "venue": "Proceedings of the Seventh International AAAI Conference on Web and Social Media.",
    "year": 2013
  }, {
    "title": "Placing Flickr photos on a map",
    "authors": ["Pavel Serdyukov", "Vanessa Murdock", "Roelof van Zwol."],
    "venue": "Proceedings of the 32nd International ACM SIGIR Conference on Research and Development in Information Retrieval. pages 484–491.",
    "year": 2009
  }, {
    "title": "New regularized algorithms for transductive learning",
    "authors": ["Partha Pratim Talukdar", "Koby Crammer."],
    "venue": "Proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases: Part II. pages 442–457.",
    "year": 2009
  }, {
    "title": "LINE: Large-scale information network embedding",
    "authors": ["Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei."],
    "venue": "Proceedings of the 24th International Conference on World Wide Web. pages 1067–1077.",
    "year": 2015
  }, {
    "title": "Predicting elections with Twitter: What 140 characters reveal about political sentiment",
    "authors": ["Andranik Tumasjan", "Timm O. Sprenger", "Philipp G. Sandner", "Isabell M. Welpe."],
    "venue": "Proceedings of the Fourth International AAAI Conference on Weblogs",
    "year": 2010
  }, {
    "title": "Simple supervised document geolocation with geodesic grids",
    "authors": ["Benjamin Wing", "Jason Baldridge."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. pages 955–964.",
    "year": 2011
  }, {
    "title": "Hierarchical discriminative classification for text-based geolocation",
    "authors": ["Benjamin Wing", "Jason Baldridge."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. pages 336–348.",
    "year": 2014
  }, {
    "title": "Stacked generalization",
    "authors": ["David H. Wolpert."],
    "venue": "Neural Networks 5(2):241–259.",
    "year": 1992
  }, {
    "title": "Hierarchical attention networks for document classification",
    "authors": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."],
    "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
    "year": 2016
  }],
  "id": "SP:6347c16cd2fd766d7ec6044524a2c126c199c2aa",
  "authors": [{
    "name": "Yasuhide Miura",
    "affiliations": []
  }, {
    "name": "Motoki Taniguchi",
    "affiliations": []
  }, {
    "name": "Tomoki Taniguchi",
    "affiliations": []
  }, {
    "name": "Tomoko Ohkuma",
    "affiliations": []
  }],
  "abstractText": "We propose a novel geolocation prediction model using a complex neural network. Our model unifies text, metadata, and user network representations with an attention mechanism to overcome previous ensemble approaches. In an evaluation using two open datasets, the proposed model exhibited a maximum 3.8% increase in accuracy and a maximum of 6.6% increase in accuracy@161 against previous models. We further analyzed several intermediate layers of our model, which revealed that their states capture some statistical characteristics of the datasets.",
  "title": "Unifying Text, Metadata, and User Network Representations with a Neural Network for Geolocation Prediction"
}