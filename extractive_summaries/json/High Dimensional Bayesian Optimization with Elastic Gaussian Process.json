{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Bayesian optimization method has established itself as an efficient way to optimize black-box functions (Jones et al.,\n*Equal contribution 1Centre for Pattern Recognition and Data Analytics (PRaDA), Deakin University, Australia. Correspondence to: Santu Rana <santu.rana@deakin.edu.au>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\n1998) which are also expensive to evaluate. Examples include experimental design to optimize the quality of a physical product (Brochu et al., 2010) or hyperparameter tuning of machine learning algorithms (Bardenet et al., 2013). In both cases the response functions are unknown and each evaluation of either making the product to test the quality or training a model from large data can be time-consuming. Likewise, it has found applications in a variety of domains including computer vision (Denil et al., 2012) and sensor set selection (Garnett et al., 2010).\nBayesian optimization is a sequential procedure where a probabilistic form of the unknown function is maintained using a Gaussian process (GP). A GP is specified by a mean function and a covariance function. A popular choice of covariance function is the squared exponential kernel (Rasmussen and Williams, 2005). A crucial parameter of the kernel is the length-scale which dictates prior belief about the smoothness of the objective function. The posterior of a Gaussian process is analytically tractable and is used to estimate both the mean and the variance of the estimation at unobserved locations. Next, a cheap surrogate function is built that seeks the location where lies the highest possibility of obtaining a higher response. The possibility is expressed through a variety of acquisition functions which trade-off exploitation of the predicted best mean and exploration around high predicted variance. Typical acquisition functions include Expected Improvement (EI) (Mockus, 1994) and GP-UCB (Srinivas et al., 2010).\nAcquisition functions are continuous functions, yet they may be extremely sharp functions at higher dimensions, especially when the size of observed data is small. Generally, they have some peaks and a large area of mostly flat surface. For this reason, the global optimization of high-dimensional acquisition functions is hard and can be prohibitively expensive. This makes it difficult to scale Bayesian optimization to high dimensions. Generic global optimization algorithms such as DIRECT (Jones et al., 1993) or simplex-based methods such as Nelder-Mead (Olsson and Nelson, 1975) or genetic algorithm based methods (Runarsson and Yao, 2005; Beyer and Schwefel, 2002) perform reasonably when the dimension is low, but at higher dimensions they can become extremely inefficient and actually become infeasible within the practical limitation of resource and time. Multi-start based method start\nfrom multiple initializations to achieve local maxima and then choose the best one. However, the multi-start method may not be able to find the non-flat portion of the acquisition function by random search. A related discussion for high dimensional Bayesian optimization concerns with the usefulness of Gaussian process for high dimensional modeling. Fortunately, Srinivas et al. (2010) showed that Gaussian process (GP) can handle “curse of dimensionality” to a good extent.\nLimited work has addressed the issue of highdimensionality in Bayesian optimization. Nearly all the existing work assumes that the objective function only depends on a limited number of “active” features (Chen et al., 2012; Wang et al., 2013; Djolonga et al., 2013). For example, Wang et al. (2013) projected the high-dimensional space into a low-dimensional subspace by random embedding and then optimized the acquisition function in a low-dimensional subspace assuming that many dimensions are correlated. This assumption seems too restrictive in real applications (Kandasamy et al., 2015; Li et al., 2017). The Add-GP-UCB model (Kandasamy et al., 2015) allows the objective function to vary along the entire feature domain. The objective function is assumed to be the sum of a set of low-dimensional functions with disjoint feature dimensions. Thus the optimization of acquisition function is performed in the low-dimensional space. Li et al. (2016a) further generalized the AddGP-UCB by eliminating an axis-aligned representation. However, none of them are not applicable if the underlying function does not have assumed structure, that is, if the dimensions are not correlated or if the function is not decomposable in some predefined forms. Thus efficient Bayesian optimization for high dimensional functions is still an open problem.\nTo address that we propose an efficient algorithm to optimize the acquisition function in high dimension without requiring any assumption on the structure of the underlying function. We recall a key characteristic of the acquisition function that they are mostly flat functions with only a few peaks. Gradients on the large mostly flat surfaces of the high-dimensional acquisition functions would be close to zero. Thus gradient-dependent methods would fail to work since a random initialization would most likely fall in the large flat region. However, we theoretically prove that for a location where the gradient is currently insignificant it is possible to find a large enough kernel length-scale which when used to build a new GP can make the derivative of the new acquisition function becomes significant. Different locations may need different length-scales above which the derivative at that location becomes significant. We prove it for both the Expected Improvement (EI) and Upper Confidence Bound (UCB) acquisition functions. Next, we theoretically prove that the difference in the acquisition func-\ntions is smooth with respect to the change in length-scales, which implies that the extremums of the consecutive acquisition functions are close if the difference in the lengthscales is small. Based on these two observations we build a novel optimization algorithm for acquisition functions. In the first part of our algorithm we search for a large enough length-scale for which a randomly selected location in the domain starts to have significant gradients. Next, we gradually reduce the length scale to move from a gross to a finer function approximation, controlling this transition by slowly reducing the length-scale of the Gaussian process kernel. We solve a sequence of local optimization problems wherein we begin with a very gross approximation of the function and then the extrema of this approximation is used as the initial point for the optimization of the next approximation which is a little bit finer. Following this sequence we reach to the extrema of the acquisition function for the Gaussian process with the target length-scale. The target length-scale is either pre-specified by the user or estimated for some covariance functions. It may seem to the reader that the problem can be avoided if a large length scale is chosen for the original GP model itself, however, as it shows in Figure 1 the right length-scale actually lies at a smaller value, especially for high dimensional functions. Since in our algorithm we use Gaussian processes with large to small length-scales akin to fitting an elastic function, we denote our method as Elastic Gaussian Process (EGP) method. We note that EGP is a meta-algorithm that enables a gradient-dependent local optimization algorithm to perform by removing the problem associated with flat surface. Newton’s gradient based method is used as a local optimization tool for our algorithm. It is to be noted that our algorithm EGP can easily be converted to pursue a global solution by employing multiple starts with different random initializations.\nWe demonstrate our algorithm on two synthetic examples and two real-world applications involving one of training\ncascaded classifier and the other involving optimization of an alloy based on thermodynamic simulation. We compare with the the state-of-the-art additive model (Kandasamy et al., 2015), high dimensional optimization using random embedding (Wang et al., 2013), a vanilla multi-start method and 2x random search. All the methods are given equal computational budget to have a fair comparison. In all experiments our proposed method outperforms the baselines. In summary, our main contributions are:\n• Proposal of a new method to handle high dimensional Bayesian optimization without any assumptions about the underlying structure in the objective function;\n• Derivation of theoretical guarantees that underpins our proposed algorithm;\n• Validation on both synthetic and real-world applications to demonstrate the usefulness of our method."
  }, {
    "heading": "2. Background",
    "text": ""
  }, {
    "heading": "2.1. Gaussian Process",
    "text": "We briefly review Gaussian process (Rasmussen and Williams, 2005) here. Gaussian process (GP) is a distribution over functions specified by its mean m(.) and covariance kernel function k(., .). Give a set of observations x1:t, the probability of any finite set of f is Gaussian\nf(x1:t) ∼ N (m(x1:t),K(x1:t,x1:t)) (2.1)\nwhere f(x1:t) is a vector of response values of x1:t and K(x1:t,x1:t) is a covariance matrix presented by\nK(x1:t,x1:t) =  k(x1,x1) · · · k(x1,xt)... . . . ... k(xt,x1) · · · k(xt,xt)  (2.2) where k is a kernel function. If the observations are contaminated with noise, K should include the noise variance. The choice of the kernel depends on prior beliefs about smoothness properties of the objective function. A popular kernel function is the squared exponential (SE) function, which is defined as\nk(xi,xj) = exp\n( − 1\n2l2 ||xi − xj ||2 ) where the kernel length-scale l reflects the smoothness of the objective function.\nThe predictive distribution of GP is tractable analytically. For a new point xt+1, the joint probability distribution of the known values f1:t = f(x1:t) and the predicted function value ft+1 is given by(\nf1:t ft+1\n) ∼ N ([ m(x1:t) m(xt+1) ] , [ K(x,x) k kT k(xt+1,xt+1) ])\nwhere k = [k(xt+1,x1) · · · k(xt+1,xt)]T and K(x,x) = K(x1:t,x1:t). We simplify the problem by using m(x1:t) = 0. The predictive distribution of ft+1 can be represented by\nft+1 | f1:t ∼ N (µt+1(xt+1 | x1:t, f1:t), σ2t+1(xt+1 | x1:t, f1:t)) (2.3) with µt+1(.) = kTK−1f1:t and σ2t+1(.) = k(xt+1,xt+1)− kTK−1k."
  }, {
    "heading": "2.2. Bayesian Optimization",
    "text": "A traditional optimization problem is to find the maximum or minimum of a function f(x) over a compact domain X . In real applications such as hyperparameter tuning for a machine learning model or experiments involving making of physical products, f(x) is unknown in advance and expensive to evaluate. Bayesian optimization (BO) is a powerful tool to optimize such expensive black-box functions. A common method to model the unknown function is using a Gaussian process as a prior. The posterior is maintained based on observations and allows prediction for expected function values at unseen locations (Eq.2.3). A acquisition function a(x | x1:t, f1:t) is constructed to guide the search for the optimum. Some examples about acquisition functions include Expected Improvement (EI) and UCB (Srinivas et al., 2010).\nThe EI-based acquisition function is to compute the expected improvement with respect to the current maximum f(x+). The improvement function is written as\nI(x) = max{0, ft+1(x)− f(x+)}\nft+1(x) is Gaussian distributed with the mean µ(x) and variance σ2(x), as per the predictive distribution of GP (2.3). Thus the expected improvement is the expectation over these Gaussian variables. In closed form (Mockus et al., 1978; Jones et al., 1998),\nEI(x) = { (µ(x)− f(x+))Φ(Z) + σ(x)φ(Z) σ(x) > 0 0 σ(x) = 0\n(2.4) where Z = µ(x)−f(x\n+) σ(x) . Φ(Z) and φ(Z) are the CDF and\nPDF of standard normal distribution.\nThe UCB (Srinivas et al., 2010) acquisition function is defined as\nUCB(x) = µ(x) + νσ(x) (2.5)\nwhere ν is a sequence of increasing positive numbers.\nIn each iteration of Bayesian optimization, the most promising xt+1 is found by maximizing the acquisition function and then yt+1 is evaluated. The new observation is augmented to update the GP and in turn is used to construct a new acquisition function. These steps are repeated till a satisfactory outcome is reached or the iteration budget is exhausted."
  }, {
    "heading": "2.2.1. OPTIMIZATION OF ACQUISITION FUNCTIONS",
    "text": "In Bayesian optimization, the objective function is expensive to evaluate while the acquisition function is tractable analytically. Our task is to maximize the acquisition function a(x | D1:t) over a compact region or with constraints. Global optimization heuristics are often used to find the extremum of a function. The gradient-based and derivativefree approaches are two main types. Gradients for the EI acquisition function can be computed as in (Frean and Boyle, 2008). DIRECT (Jones et al., 1993) is a popular choice to globally optimize the acquisition function. It is a deterministic and derivative-free algorithm which divides the search space into smaller and smaller hyperrectangles and leverages the Lipschitizian-continuity of the acquisition function. However. it takes time exponential to dimension and becomes practically infeasible beyond 10 dimensions. The multi-start gradient based approach is potentially attractive in high dimension but it mostly fails in high-dimensional scenario as a random initialization may not be able to escape from the large flat region that acquisition functions generally have. Our proposed method utilizes properties of the acquisition function to derive a meta-algorithm that enables the gradient-based optimizer to move even when initialized in a seemingly flat region."
  }, {
    "heading": "3. High-dimensional Bayesian Optimization with Elastic Gaussian Process",
    "text": "We would like to employ Bayesian optimization to solve a high-dimensional maximization problem maxx∈X f(x) in a compact subset X ⊆ R. To model f(x), we use a Gaussian process with zero mean as a prior and the SE kernel as the covariance function with a target length-scale lτ . The target length-scale can be set by the user or can be separately inferred by using the maximum likelihood-based estimation method (Snoek et al., 2012). The SE kernel although a simple kernel, is versatile and popular. Hence we choose to use it in our framework. Acquisition functions, such as EI (Mockus, 1994) and UCB (Srinivas et al., 2010), depend on the predictive mean µ(x) and variance σ2(x) of GP\nµ(x) = kTK−1y\nσ2(x) = 1− kTK−1k\nHence, the acquisition function is also associated with the GP kernel length-scale l and we denote it as a(x | D1:t, l). The core task of Bayesian optimization is to find the most promising point xt+1 for the next function evaluation by globally maximizing acquisition function.\nFigure 2 serves as an inspired example for our approach. We plot the acquisition function for different length-scales. As can be seen when the length-scale is low, some portions of the parameter space are flat. This is especially remark-\nable in high-dimensional problems. For example, the acquisition function with length-scale 0.1 is extremely flat. However when the length-scale is above 0.2, the acquisition functions starts to have significant gradients. Additionally, we also show that the optimal solutions for different length-scales are close.\nWe construct our method based on the above observations. Specifically in Lemma 1 we theoretically guarantee that it is possible to find a large enough length-scale for which the derivative of the acquisition function becomes non-insignificant at any location in the domain. Proof for both the Expected Improvement (EI) and Upper Confidence Bound (UCB) based acquisition functions are derived. Relying on this guarantee, we search for a large enough length-scale for which a randomly selected location in the domain starts to have significant gradients. Next in Lemma 2, we theoretically guarantee that the difference in the acquisition function is smooth with respect to the change in length-scale. This implies that the extrema of the consecutive acquisition functions are close but different only due to a small difference in the length-scales. The details of these lemmas are provided later. However, we can now conceive that an algorithm to overcome flat region can be constructed by first finding a large enough length-scale to solve for the optima at that length-scale and then gradually reduce the length-scale and solve a sequence of local optimization problems wherein the optimum of a larger length-scale is used as the initialization for the optimization of the acquisition function based on the Gaussian process with a smaller length-scale. This is continued till the optimum at the target length-scale lτ is reached. We denote our method as Elastic GP (EGP) method. The whole proposed algorithms are presented in Alg.1 and Alg. 2.\nAlgorithm 1 High Dimensional Bayesian Optimization with Elastic Gaussian Process\n1: for t = 1, 2 · · · do 2: Sample the next point xt+1←argmaxxt+1∈X a(x | D1:t, l) using Alg. 2 3: Evaluate the value yt+1 4: Augment the data D1:t+1 = {D1:t, {xt+1, yt+1}} 5: Update the kernel matrix K 6: end for"
  }, {
    "heading": "3.1. Theoretical Analysis",
    "text": "In the first step of our algorithm (seen in Step 1 of Alg.2) , we want to show that gradient of the acquisition functions becomes significant beyond a certain l so that our algorithm can find an optimal solution compared to any start point.\nLemma 1. ∃l : ∥∥∥∥∂a(x)∂x ∥∥∥∥\n2\n≥ ε for lτ ≤ l ≤ lmax.\nProof. The Lemma can be proved if we prove that∣∣∣∂a(x)∂xi ∣∣∣ ≥ ε, ∀i. We consider both forms: UCB and EI. • For the UCB acquisition function (Eq. 2.5),\nthe partial derivative of UCB can be written as\n∂a(x)\n∂xi =\n∂µ(x)\n∂xi + ν\n∂σ(x)\n∂xi\n= ∂kT\n∂xi K−1y +\nν σ(x) (−∂k\nT\n∂xi K−1k)\nThe ∂k T\n∂xi is dependent on the form of the covariance func-\ntion: it is 1× t matrix whose (1, j)th element is ∂cov(x,xj)∂xi . For the SE kernel\n∂cov(x,xj)\n∂xi = exp\n( −||x− xj || 2\n2l2\n)( − (xi − xji)\nl2 ) = −dji\nl2 cov(x,xj) (3.1)\nwhere dji = xi − xji.\nTo simplify the proof, we assume that we have the worst case that only one observation x0 exists and thus\n∂a(x)\n∂xi\n= y0∂cov(x,x0) ∂xi − vcov(x,x0)√ 1− cov2(x,x0) ∂cov(x,x0) ∂xi\n= −d0i l2 cov(x,x0)y0 + vcov(x,x0)√ 1− cov2(x,x0) d0i l2 cov(x,x0)\n= d0i l2 ( vcov2(x,x0)√ 1− cov2(x,x0) − cov(x,x0)y0 ) (3.2)\nAlgorithm 2 Optimizing acquistion function using EGP Input: a random start point xinit ∈ χ, the length-scale\ninterval4l, l = lτ .\n1: Step 1: 2: while l ≤ lmax do 3: Sample x∗ ← argmaxx∗∈Xa(x | D1:t, l) starting with xinit; 4: if ||xinit − x∗|| = 0 then 5: l = l +4l 6: else 7: xinit = x∗, break; 8: end if 9: end while\n10: Step 2: 11: while l ≥ lτ do 12: l = l −4l 13: Sample x∗ ← argmaxx∗∈Xa(x | D1:t, l) starting with xinit; 14: if ||xinit − x∗|| = 0 then 15: 4l=4l/2 16: else 17: xinit = x∗ 18: end if 19: end while\nOutput: the optimal point xt+1 = x∗ to be used in Alg.1\nThe cov(x,x0) is a small value due to ||x − x0|| 0 and then the first term in the fourth line of the Eq.(3.2) can be ignored compared to its second term. Therefore we have\n∂a(x) ∂xi = −d0i l2 cov(x,x0)y0\n= −d0iy0 l2 exp\n( −||x− x0|| 2\n2l2\n) (3.3)\nWe rewrite it as∣∣∣∣∂a(x)∂xi ∣∣∣∣ = α1l2 exp(−α2l2 )\nwhere α1 = |d0iy0| and α2 = ||x− x0||2/2. To have ∣∣∣∂a(x)∂xi ∣∣∣ ≥ ε, the equation exp (−α2l2 ) ≥ εl2α1 must hold for a l between lτ ≤ l ≤ lmax. In fact, we can find a l to hold the inequality since exp ( −α2l2 ) is a decreasing function with the range (0, 1] whilst εl 2\nα1 is an increasing\nfunction with the range (0,+∞) by considering lτ can approach to 0 and lmax can approach to infinity in theory. Therefore Lemma 1 has been proved for the UCB acquisition function.\n• For the EI acquisition function (Eq. 2.4),\nthe partial derivative can be written as\n∂a(x)\n∂xi = [ZΦ(Z) + φ(Z)]\n∂σ(x)\n∂xi + σ(x)Φ(Z)\n∂Z\n∂xi\nwhere Z = µ(x)−f(x +)\nσ(x) and\n∂σ(x)\n∂xi = −\n( ∂kT\n∂xi K−1k\n) /σ(x)\n∂Z ∂xi =\n( ∂kT\n∂xi K−1y − Z ∂σ(x) ∂xi\n) /σ(x)\ntherefore,\n∂a(x)\n∂xi = −φ(Z)\n( ∂kT\n∂xi K−1k\n) /σ(x)+Φ(Z) ∂kT\n∂xi K−1y\n(3.4) We substitute Eq.(3.1) into Eq. (3.4) and make the similar assumption within the proof at the UCB acquisition function. The Eq. (3.4) then becomes as\n∂a(x)\n∂xi\n= y0Φ(Z)∂cov(x,x0) ∂xi − φ(Z)cov(x,x0)√ 1− cov2(x,x0) ∂cov(x,x0) ∂xi\n= d0i l2\n( φ(Z)cov2(x,x0)√\n1− cov2(x,x0) − cov(x,xj)y0Φ(Z)\n)\nSince φ(Z) lies 0-1, we can ignore the first term. The equation above is further written as\n∂a(x) ∂xi = −d0i l2 exp\n( −||x− x0|| 2\n2l2\n) y0Φ(\nµ(x)− f(x+) σ(x) )\nAs l increasing, µ(x) becomes smaller and σ(x) becomes larger and then Φ(·) → 1. The equation above becomes similar with Eq.(3.3). Therefore Lemma 1 is proved for EI.\nIn the second step of our algorithm (seen in Step 2 of Alg.2), our purpose is to find 4l which makes the start point of the local optimizer move to a finer region. We need to show that∣∣∣∣∣∂a(x)∂xi ∣∣∣∣ l=l∗ − ∂a(x) ∂xi ∣∣∣∣ l=l∗+4l\n∣∣∣∣∣ ≤ ε, for4l < δ It is directly related to∂a(x|D1:t,l)∂x being smooth. The following lemma guarantees that.\nLemma 2. g(x, l) is a smooth function with respect to l, where g(x, l) = ∂a(x|D1:t,l)∂x .\nFor the UCB, we compute the derivative of g(x, l) with respect to l based on Eq.(3.3)\n∂g(xi, l)\n∂l = 2d0iy0 l3 exp\n( −||x− x0|| 2\n2l2 ) + d0iy0 l2 exp ( −||x− x0|| 2 2l2 ) ||x− x0||2 l3\nApparently, ∂g(xi,l)∂l is continuous in the domain of l. Therefore, g(x, l) is a smooth function with respect to l. The similar proof can be done for EI."
  }, {
    "heading": "4. Experiments",
    "text": "We evaluate our method on three different benchmark test functions and two real-world applications including training cascaded classifiers and for alloy composition optimization. We use low memory BFGS implementation in NLopt (Johnson, 2014) as the local optimization algorithm, and a variant of DIRECT (GN DIRECT L) for global optimization1. Our comparators are:\n• Global optimization using DIRECT (Global)\n• Multi-start local optimization (Multi-start)\n• High-dimensional Bayesian optimization via additive models (Kandasamy et al., 2015) (Add-d′, where d′ is the dimensionality in each group)\n• Bayesian optimization using random embedding (Wang et al., 2013) (REMBO-d′, where d′ is the projected dimensionality)\n• Best of 2 x Random search, which has shown competitiveness over many algorithms(Li et al., 2016b).\nGlobal optimization with DIRECT is used only at dimension d ≤ 10 as it consistently returns erroneous results at higher dimension. For the additive model variables are divided into a set of additive clusters by maximizing the marginal likelihood (Kandasamy et al., 2015). In all experiments, we use EI as the acquisition function and the SE kernel as the covariance function. The search bounds are rescaled to [0, 1]. We use the target length-scale lτ = 0.1, lmax = √ d and 4lmin = 10−5. In Figure 1 we plot the simple regret vs iteration for three different choices of scale l = 0.1, 0.3 and 0.5. Out of them l = 0.1 provides the fastest convergence, justifying our choice for the lengthscale. In our experience any smaller length-scale slows down the convergence and surprisingly, in most of the cases lτ = 0.1 turns out to be a good choice. The number of initial observations are set at d + 1. All the algorithms are\n1The code is available on request.\ngiven the same fixed time duration per iteration (Topt). The computer used is a Xeon Quad-core PC running at 2.6 GHz, with 16 GB of RAM. Bayesian optimization has been implemented in Matlab with mex interface to a C-based acquisition function optimizer that uses NLOPT library. We run each algorithm 20 trials with different initializations and report the average results and standard errors ."
  }, {
    "heading": "4.1. Benchmark Test Functions",
    "text": "In this study we demonstrate the application of Bayesian optimization on three different benchmark test functions\n1. Hertmann6d in [0, 1] for all dimensions.\n2. Unnormalized Gaussian PDF with a maximum of 1 in [−1, 1]d for d=20 and [−0.5, 0.5]d for d=50.\n3. Generalized Rosenbrock function (Picheny et al., 2013) in [−5, 10]d.\nWe set the covariance matrix of the Gaussian PDF to be\na block diagonal matrix Σ =  A · · · 0... . . . ... 0 · · · A , where A = [ 1 0.9 0.9 1 ] . In this case, variables are partially correlated and, therefore, the function does not admit additive decomposition with high probability. The function is further scaled such that the maximum value of the function\nremains at 1 irrespective of the number of variables (dimensions). Since, for all these test functions neither the assumptions of additive decomposition based method or the assumptions of REMBO (many dimensions are correlated) are true, they perform poorly on these. Hence, we do not include them in our comparison for benchmark functions.\nWe first demonstrate the efficiency of our EGP based optimization given limited amount of time. In Figure 3 we show how the three algorithms perform when given two different amounts of optimization time per iteration (Topt = 0.001×d and Topt = 0.01×d) on both Hertmann6 and Gaussian PDF functions. The plot shows that when Topt is small then Multi-start performs the worst, even performing lower than the 2x Random search. However, both EGP and the DIRECT perform much better and almost perform similarly. When Topt is increased then all the methods start to perform almost similarly with EGP providing slightly better performance. This demonstrates two things: a) EGP is more efficient in using time than the Multi-start, and b) EGP being gradient-based is more numerically precise than the grid-based DIRECT algorithm. In Figure 4 we demonstrate our method on both Rosenbrock and Gaussian PDF functions at high dimensions. The optimization time for all these high-dimensional optimization problem is set as Topt = 0.1×d sec. EGP clearly beats all the comparators for these benchmark test functions. Then UCB acquisition function has the similar behaviour with EI for our model although no result shown here."
  }, {
    "heading": "4.2. Training cascade classifier",
    "text": "Here we evaluate our method by training a cascade classifier on three real datasets from UCI repository (Blake and Merz, 1998): Ionosphere, German and IJCNN1. A K-cascade classifier consists of K stages and each stage has a weak classifier, a one-level decision stump. Instances are re-weighted after each stage. Generally, independently computing the thresholds are not an optimal strategy and thus we seek to find an optimal set of thresholds by maximizing the training AUC. Features in all datesets are scaled between [0, 1]. The number of stages is set same with the number of features in the dataset. Therefore, simultaneously optimizing thresholds in multiple stages is a difficult task and thus being used as a challenging test case for highdimensional Bayesian optimization. We create the additive model with 10 dimensions per group and 10 dimensions for random embedding in REMBO. The results are plotted in Figure 5 (a)-(c). In all three cases EGP provides the best performance. REMBO performs the worst of all. Surprisingly, for IJCNN1 the Random Search turned out to be competitive to EGP. However, in the other two datasets it performs much worse than EGP."
  }, {
    "heading": "4.3. Optimizing alloy for aeronautic applications",
    "text": "AA-2050 is a low density high corrosion resistant alloy and is used for aerospace applications. The current alloy has been designed decades ago and is considered by our metallurgist collaborator as a prime candidate for further improvement. ThermoCalc, a software based thermodynamic simulator (Andersson et al., 2002), is used to compute the utility of a composition by looking at the occurrences of different phases at different temperatures. Some phases are beneficial for mechanical properties whereas some are not. Guided by our metallurgist partners a weighted combination of phase fractions is used as the utility function The alloy consists of 9 elements (Al, Cu, Mg, Zn, Cr, Mn, Ti, Zr, and Sc) and along with that we have 4 operational pa-\nrameters that have to be optimized together. In all we have a 13-dimensional optimization problem. The result is given in Figure 5(d). Since, the simulations are expensive we run only upto 30 iterations and compare with only the additive model and the REMBO. We ran only once after starting from expert-specified starting points. Clearly, EGP is quicker in reaching better value and always remained better than both the baselines."
  }, {
    "heading": "5. Conclusion",
    "text": "In this paper we propose a novel algorithm for Bayesian optimization in high dimension. At high dimension the acquisition function becomes very flat on a large region of the space rendering gradient-dependent methods to fail at high dimension. We prove a) gradient can be induced by increasing the length-scales of the GP prior and b) acquisition functions which differ only due to small difference in length-scales are close. Based on these we formulate our algorithm that first finds a large enough length-scale to enable the gradient-dependent optimizer to perform, and then the gradually reduces the length-scale while also sequentially using the optimum of the larger length-scale as the initialization for the smaller. In experiments the proposed algorithm clearly performs better than the baselines on a set of test functions and two real applications of training cascade classifiers and alloy composition optimization."
  }, {
    "heading": "Acknowledgement",
    "text": "This work is partially funded by Australian Government through ARC and the Telstra-Deakin Centre of Excellence in Big Data and Machine Learning. Prof Venkatesh is the recipient of an ARC Australian Laureate Fellowship (FL170100006). We thank our metallurgist collaborators Dr.Thomas Dorin from Institute of Frontier Materials Deakin and his team for the alloy case study and anonymous reviewers for their valuable comments."
  }],
  "year": 2017,
  "references": [{
    "title": "Thermo-calc & dictra, computational tools for materials science",
    "authors": ["Jan-Olof Andersson", "Thomas Helander", "Lars Höglund", "Pingfang Shi", "Bo Sundman"],
    "venue": "Calphad,",
    "year": 2002
  }, {
    "title": "Collaborative hyperparameter tuning",
    "authors": ["Rémi Bardenet", "Má ty ás Brendel", "Kégl Balázs"],
    "venue": "In Proceedings of the 30th International Conference on Machine Learning",
    "year": 2013
  }, {
    "title": "Evolution strategies–a comprehensive introduction",
    "authors": ["Hans-Georg Beyer", "Hans-Paul Schwefel"],
    "venue": "Natural computing,",
    "year": 2002
  }, {
    "title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning",
    "authors": ["Eric Brochu", "Vlad M. Cora", "Nando de Freitas"],
    "year": 2010
  }, {
    "title": "Joint optimization and variable selection of high-dimensional gaussian processes",
    "authors": ["Bo Chen", "Rui Castro", "Andreas Krause"],
    "venue": "In Proc. International Conference on Machine Learning (ICML),",
    "year": 2012
  }, {
    "title": "Learning where to attend with deep architectures for image tracking",
    "authors": ["Misha Denil", "Loris Bazzani", "Hugo Larochelle", "Nando de Freitas"],
    "venue": "Neural Comput.,",
    "year": 2012
  }, {
    "title": "Highdimensional gaussian process bandits",
    "authors": ["Josip Djolonga", "Andreas Krause", "Volkan Cevher"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2013
  }, {
    "title": "Using Gaussian Processes to Optimize Expensive Functions, pages 258–267",
    "authors": ["Marcus Frean", "Phillip Boyle"],
    "year": 2008
  }, {
    "title": "Bayesian optimization for sensor set selection",
    "authors": ["Roman Garnett", "Michael A Osborne", "Stephen J Roberts"],
    "venue": "In International Conference on Information Processing in Sensor Networks,",
    "year": 2010
  }, {
    "title": "The nlopt nonlinear-optimization package, 2014. URL http://ab-initio.mit.edu/ nlopt",
    "authors": ["Steven G. Johnson"],
    "year": 2014
  }, {
    "title": "Lipschitzian optimization without the lipschitz constant",
    "authors": ["D.R. Jones", "C.D. Perttunen", "B.E. Stuckman"],
    "venue": "Journal of Optimization Theory and Applications,",
    "year": 1993
  }, {
    "title": "Efficient global optimization of expensive black-box functions",
    "authors": ["Donald R. Jones", "Matthias Schonlau", "William J. Welch"],
    "venue": "Journal of Global Optimization,",
    "year": 1998
  }, {
    "title": "High Dimensional Bayesian Optimisation and Bandits via Additive Models",
    "authors": ["Kirthevasan Kandasamy", "Jeff G. Schneider", "Barnabs Pczos"],
    "venue": "In ICML,",
    "year": 2015
  }, {
    "title": "High dimensional bayesian optimization via restricted projection pursuit models",
    "authors": ["C. Li", "K. Kandasamy", "B. Poczos", "J. Schneider"],
    "venue": "In AISTATS,",
    "year": 2016
  }, {
    "title": "High dimensional bayesian optimisation using dropout",
    "authors": ["Cheng Li", "Sunil Kumar Gupta", "Santu Rana", "Svetha Venkatesh", "Vu Nguyen", "Alistair Shilton"],
    "venue": "In The 26th International Joint Conference on Artificial Intelligence,",
    "year": 2017
  }, {
    "title": "Hyperband:a novel bandit-based approach to hyperparameter optimization",
    "authors": ["L. Li", "K. Jamieson", "G. DeSalvo", "A. Rostamizadeh", "A. Talwalkar"],
    "venue": "In ArXiv e-prints,",
    "year": 2016
  }, {
    "title": "The application of bayesian methods for seeking the extremum",
    "authors": ["J. Mockus", "V. Tiesis", "A. Zilinskas"],
    "venue": "Towards Global Optimisation,",
    "year": 1978
  }, {
    "title": "Application of bayesian approach to numerical methods of global and stochastic optimization",
    "authors": ["Jonas Mockus"],
    "venue": "Journal of Global Optimization,",
    "year": 1994
  }, {
    "title": "The nelder-mead simplex procedure for function minimization",
    "authors": ["Donald M Olsson", "Lloyd S Nelson"],
    "year": 1975
  }, {
    "title": "A benchmark of kriging-based infill criteria for noisy optimization",
    "authors": ["Victor Picheny", "Tobias Wagner", "David Ginsbourger"],
    "venue": "Structural and Multidisciplinary Optimization,",
    "year": 2013
  }, {
    "title": "Gaussian Processes for Machine Learning",
    "authors": ["Carl Edward Rasmussen", "Christopher K.I. Williams"],
    "year": 2005
  }, {
    "title": "Search biases in constrained evolutionary optimization. Systems, Man, and Cybernetics, Part C: Applications and Reviews",
    "authors": ["Thomas Philip Runarsson", "Xin Yao"],
    "venue": "IEEE Transactions on,",
    "year": 2005
  }, {
    "title": "Practical bayesian optimization of machine learning algorithms",
    "authors": ["Jasper Snoek", "Hugo Larochelle", "Ryan P Adams"],
    "venue": "In NIPS,",
    "year": 2012
  }, {
    "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
    "authors": ["Niranjan Srinivas", "Andreas Krause", "Sham Kakade", "Matthias Seeger"],
    "venue": "In ICML,",
    "year": 2010
  }, {
    "title": "Bayesian optimization in high dimensions via random embeddings",
    "authors": ["Ziyu Wang", "Masrour Zoghi", "Frank Hutter", "David Matheson", "Nando De Freitas"],
    "venue": "In IJCAI,",
    "year": 2013
  }],
  "id": "SP:dd76be92fbe574786c4be3f3973482779f17dcaf",
  "authors": [{
    "name": "Santu Rana",
    "affiliations": []
  }, {
    "name": "Cheng Li",
    "affiliations": []
  }, {
    "name": "Sunil Gupta",
    "affiliations": []
  }, {
    "name": "Vu Nguyen",
    "affiliations": []
  }, {
    "name": "Svetha Venkatesh",
    "affiliations": []
  }],
  "abstractText": "Bayesian optimization is an efficient way to optimize expensive black-box functions such as designing a new product with highest quality or tuning hyperparameter of a machine learning algorithm. However, it has a serious limitation when the parameter space is high-dimensional as Bayesian optimization crucially depends on solving a global optimization of a surrogate utility function in the same sized dimensions. The surrogate utility function, known commonly as acquisition function is a continuous function but can be extremely sharp at high dimension having only a few peaks marooned in a large terrain of almost flat surface. Global optimization algorithms such as DIRECT are infeasible at higher dimensions and gradient-dependent methods cannot move if initialized in the flat terrain. We propose an algorithm that enables local gradient-dependent algorithms to move through the flat terrain by using a sequence of gross-tofiner Gaussian process priors on the objective function as we leverage two underlying facts a) there exists a large enough length-scales for which the acquisition function can be made to have a significant gradient at any location in the parameter space, and b) the extrema of the consecutive acquisition functions are close although they are different only due to a small difference in the length-scales. Theoretical guarantees are provided and experiments clearly demonstrate the utility of the proposed method on both benchmark test functions and real-world case studies.",
  "title": "High Dimensional Bayesian Optimization with Elastic Gaussian Process"
}