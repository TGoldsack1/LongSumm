{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Srivastava et al. (2014) proposed dropout as a cheap way of preventing Neural Networks (NN) from overfitting. This work was rather impactful and sparked large interest in studying and extending the algorithm. One strand of this research lead to reinterpretation of dropout as a form of\n1Department of Engineering, University of Cambridge, Cambridge, United Kingdom 2Uber AI Labs, San Francisco, California, USA. Correspondence to: Jiri Hron <jh2084@cam.ac.uk>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\napproximate Bayesian variational inference (Kingma et al., 2015; Gal & Ghahramani, 2016; Gal, 2016).\nThere are two main reasons for attempting reinterpretation of an existing method: 1) providing a principled interpretation of the empirical behaviour; 2) extending the method based on the acquired insights. Variational Bayesian dropout has been arguably successful in meeting the latter criterion (Kingma et al., 2015; Gal, 2016; Molchanov et al., 2017). This paper thus focuses on the former by studying the theoretical soundness of variational Bayesian dropout and the implications for interpretation of the empirical results.\nThe first main contribution of our work is identification of two main sources of issues in current variational Bayesian dropout theory:\n(a) use of improper or pathological prior distributions;\n(b) singularity of the approximate posterior distribution.\nAs we describe in Section 3, the log uniform prior introduced in (Kingma et al., 2015) generally does not induce a proper posterior, and thus the reported sparsification (Molchanov et al., 2017) cannot be explained by the standard Bayesian and the related minimum description length (MDL) arguments. In this sense, sparsification via variational inference with log uniform prior falls into the same category of non-Bayesian approaches as, for example, Lasso (Tibshirani, 1996). Specifically, the approximate uncertainty estimates do not have the usual interpretation, and the model may exhibit overfitting. Consequently, we study the objective from a non-Bayesian perspective, proving that the optimised objective is impervious to some of the described pathologies due to the properties of the variational formulation itself, which might explain why the algorithm can still provide good empirical results.1\nSection 4 shows how mismatch between support of the approximate and the true posterior renders application of the standard Variational Inference (VI) impossible by making the Kullback-Leibler (KL) divergence undefined. As the second main contribution, we address this issue by proving that the remedies to this problem proposed in (Gal & Ghahramani, 2016; Gal, 2016) are special cases of a broader\n1An earlier version of this work was published in (Hron et al., 2017).\nclass of limiting constructions leading to a unique objective which we name Quasi-KL (QKL) divergence.\nSection 5 provides initial discussion of QKL’s properties, uses those to suggest an explanation for the empirically observed difficulty in tuning hyperparameters of the true model (e.g. Gal (2016, p. 119)), and demonstrates the potential of QKL on an illustrative example where we try to approximate a full rank Gaussian distribution with a degenerate one using QKL, only to arrive at the well known Principal Component Analysis (PCA) algorithm."
  }, {
    "heading": "2. Background",
    "text": "Assume we have a discriminative probabilistic model y |x,W ∼ P(y |x,W ) where (x, y) is a single inputoutput pair, and W is the set of model parameters generated from a prior distribution P(W ). In Bayesian inference, we usually observe a set of data points (X,Y ) = {(xn, yn)}Nn=1 and aim to infer the posterior p(W |X,Y ) ∝ p(W ) ∏ n p(yn |xn,W ),2 which can be subsequently used to obtain the posterior predictive density p(Y ′ |X ′,X,Y ) = ∫ p(Y ′ |X ′,W )p(W |X,Y )dW . If p(y |x,W ) is a complicated function ofW like a neural network, both tasks often become computationally infeasible and thus we need to turn to approximations.\nVariational inference approximates the posterior distribution over a set of latent variablesW by maximising the evidence lower bound (ELBO),\nL(q) = E Q(W ) [log p(Y |X,W )]−KL (Q(W )‖P(W )) ,\nwith respect to (w.r.t.) an approximate posterior Q(W ). If Q(W ) is parametrised by ψ and the ELBO is differentiable w.r.t. ψ, VI turns inference into optimisation. We can then approximate the density of posterior predictive distribution using q(Y ′ |X ′,X,Y ) = ∫ p(Y ′ |X ′,W )q(W )dW , usually by Monte Carlo integration.\nA particular discriminative probabilistic model is a Bayesian neural network (BNN). BNN differs from a standard NN by assuming a prior over the weightsW . One of the main advantages of BNNs over standard NNs is that the posterior predictive distribution can be used to quantify uncertainty when predicting on previously unseen data (X ′,Y ′). However, there are at least two challenges in doing so:\n1) difficulty of reasoning about choice of the prior P(W );\n2) intractability of posterior inference.\nFor a subset of architectures and priors, Item 1 can be addressed by studying limit behaviour of increasingly large\n2Throughout the paper, P(W ) refers to the distribution and p(W ) to its density function. Analogously for other distributions.\nnetworks (see, for example, (Neal, 1996; Matthews et al., 2018)); in other cases, sensibility of P(W ) must be assessed individually. Item 2 necessitates approximate inference – a particular type of approximation related to dropout, the topic of this paper, is described below.\nDropout (Srivastava et al., 2014) was originally proposed as a regularisation technique for NNs. The idea is to multiply inputs of a particular layer by a random noise variable which should prevent co-adaptation of individual neurons and thus provide more robust predictions. This is equivalent to multiplying the rows of the subsequent weight matrix by the same random variable. The two proposed noise distributions were Bernoulli(p) and Gaussian N (1, α).\nBernoulli and Gaussian dropout were later respectively reinterpreted by Gal & Ghahramani (2016) and Kingma et al. (2015) as performing VI in a BNN. In both cases, the approximate posterior is chosen to factorise either over rows or individual entries of the weight matrices. The prior usually factorises in the same way, mostly to simplify calculation of KL (Q(W )‖P(W )). It is the choice of the prior and its interaction with the approximating posterior family that is studied in the rest of this paper."
  }, {
    "heading": "3. Improper and pathological posteriors",
    "text": "Both Gal & Ghahramani (2016) and Kingma et al. (2015) propose using a prior distribution factorised over individual weights w ∈ W . While the former opts for a zero mean Gaussian distribution, Kingma et al. (2015) choose to construct a prior for which KL (Q(W )‖P(W )) is independent of the mean parameters θ of their approximate posterior q(w) = φθ,αθ2(w), w ∈W , θ ∈ θ, where φµ,σ2 is the density function of N (µ, σ2). The decision to pursue such independence is motivated by the desire to obtain an algorithm that has no weight shrinkage – that is to say one where Gaussian dropout is the sole regularisation method. Indeed, the authors show that the log uniform prior p(w) := C/|w| is the only one where KL (Q(W )‖P(W )) has this mean parameter independence property. The log uniform prior is equivalent to a uniform prior on log|w|. It is an improper prior (Kingma et al., 2015, p. 12) which means that there is no C ∈ R for which p(w) is a valid probability density.\nImproper priors can sometimes lead to proper posteriors (e.g. normal Jeffreys prior for Gaussian likelihood with unknown mean and variance parameters) if C is treated as a positive finite constant and the usual formula for computation of posterior density is applied. We show this is generally not the case for the log uniform prior, and that any remedies in the form of proper priors that are in some sense close to the log uniform (such as uniform priors over floating point numbers) will lead to severely pathological inferences."
  }, {
    "heading": "3.1. Pathologies of the log uniform prior",
    "text": "For any proper posterior density, the normaliser Z =∫ RD p(Y |X,W )p(W )dW has to be finite (D denotes the total number of weights). We will now show that this requirement is generally not satisfied for the log uniform prior combined with commonly used likelihood functions.\nProposition 1. Assume the log uniform prior is used and that there exists some w ∈ W such that the likelihood function at w = 0 is continuous in w and non-zero. Then the posterior is improper.\nAll proofs can be found in the appendix. Notice that standard architectures with activations like rectified linear or sigmoid, and Gaussian or Categorical likelihood satisfy the above assumptions, and thus the posterior distribution for non-degenerate datasets will generally be improper. See Figure 1 for a visualisation of this case.\nFurthermore, the pathologies are not limited to the region near w = 0, but can also arise in the tails (Figure 2). As an example, we will consider a single variable Bayesian logistic regression problem p(y |x,w) = 1/(1 + exp(−xw)), and again use the log uniform prior forw. For simplicity, assume that we have observed (x = 1, y = 1) and wish to infer the posterior distribution. To show that the right tail has infinite mass, we integrate over [k,∞), k > 0,∫\n[k,∞) p(w)p(y |x,w)dw = ∫ [k,∞) C |w| 1 1 + exp(−w) dw\n> ∫ [k,∞) C |w| 1 1 + exp(−k) dw = C · (∞− log k) 1 + exp(−k) =∞ .\nEquivalently, we could have obtained infinite mass in the left tail, for example by taking the observation to be\n(x = −1, y = 1). Because the sigmoid function is continuous and equal to 1/2 at w = 0, the posterior also has infinite mass around the origin, exemplifying both of the discussed degeneracies. The normalising constant is of course still infinite and thus the posterior is again improper.\nThe practical implication of these pathologies is that even tasks as simple as MAP estimation (Proposition 1 implies unbounded posterior density) or posterior mean estimation will fail as the target is undefined. In general, improper posteriors lead to undefined or incoherent inferences. The above shows that this is the case for the log uniform prior combined with BNNs and related models, making Bayesian inference, exact and approximate, ill-posed."
  }, {
    "heading": "3.2. Pathologies of the truncated log uniform prior",
    "text": "Neklyudov et al. (2017) proposed to swap the log uniform prior on (−∞,∞) for a distribution that is uniform on a sufficiently wide bounded interval in the log|w| space (will be referred to as the log space from now on), i.e. p(log|w|) = 1/(b − a)I[a,b] (w) , a < b where IA is the indicator function of the set A. This prior can be used in place of the log uniform if the induced posteriors in some sense converge to a well-defined limit for any dataset as [a, b] gets wider. If this is not the case, choice of [a, b] becomes a prior assumption and must be justified as such because different choices will lead to sometimes considerably different inferences. We now show that posteriors generally do not converge for the truncated log uniform prior and discuss some of the related pathologies of the induced exact posterior.\nTo illustrate the considerable effect the choice of [a, b] might have, we return to the example of posterior inference in a logistic regression model p(y |x,w) = 1/(1 + e−xw) after observing (x = 1, y = 1), using the prior pn(w) =\nIIn (w) Cn/|w| where In = [−ebn ,−ean ] ∪ [ean , ebn ] (i.e. the appropriate transformation of the closed interval [an, bn] from the log space – see Figure 3). We exemplify the sensitivity of the posterior distribution to the choice of the (In)n∈N sequence by studying the limiting behaviour of the posterior mean and variance. Using the definition of IIn (w) and symmetry, the normaliser of the posterior is,\nZn = ∫ −ean −ebn 1 |w| 1 1 + e−w dw + ∫ ebn ean 1 |w| 1 1 + e−w dw\n= ∫ ebn ean 1 |w| 1 + ew 1 + ew dw = bn − an .\nSimilar ideas can be used to derive the first two moments,\nE Pn (w) =\n∫ ebn ean 1 1+e−w dw − ∫ −ean −ebn 1 1+e−w dw\nbn − an\n= h(ebn) + h(−ebn)− h(ean)− h(−ean)\nbn − an , (1)\nE Pn (w2) = ∫ ebn ean |w| bn − an 1 + ew 1 + ew dw = e2bn − e2an 2(bn − an) ,\n(2)\nwhere h(x) := log(1 + ex), and Pn stands for Pn(w |x, y). To understand sensitivity of the posterior mean to the choice of (In)n∈N, we now construct sequences which respectively lead to convergence of the mean to zero, an arbitrary positive constant, and infinity.3 To emphasise this is not specific to the posterior mean, we show that the variance might equally well be zero, infinite, or undefined.\nTo get limn→∞ EPn(w) = 0, notice that for a fixed bn, the second term in Equation (1) tends to log(4)/∞ = 0.\n3It would be equally possible to get convergence to an arbitrary negative constant, and negative infinity if the observation was (x = −1, y = 1).\nHence we can make the posterior mean converge to zero by making the first term also tend to zero; a way to achieve this is setting bn = log(log|an|), which tends to infinity as an →∞. The limit of Equation (2) for the same sequence, and thus the variance, tends to zero as well.\nFor limn→∞ EPn(w) = c > 0, we again focus on the first term in Equation (1) as the second term tends to zero for any increasing sequence In ↗ R. Simple algebra shows that for any diverging sequence bn →∞, taking an = bn − ebn/c yields the desired result. The same sequence leads to infinite second moment and thus to infinite variance.\nFinally, a choice which results in infinite mean and thus undefined variance is setting an = −bn, for which the mean grows as ebn/bn. We would like to point out that this symmetric growth of an with bn is of particular interest as it corresponds to changing between different precisions of the float format representation on the computer as considered in Kingma et al. (2015, Appendix A)."
  }, {
    "heading": "3.3. Variational Gaussian dropout as penalised maximum likelihood",
    "text": "We have established that optimisation of the ELBO implied by a BNN with log uniform prior over its weights cannot generally be interpreted as a form of approximate Bayesian inference. Nevertheless, the reported empirical results suggest that the objective might possess reasonable properties. We thus investigate if and how the pathologies of the true posterior translate into the variational objective as used in (Kingma et al., 2015; Molchanov et al., 2017).\nFirstly, we derive a new expression for KL (Q(w)‖P(w)), and for its derivative w.r.t. the variational parameters, which will help us with further analysis. Proposition 2. Let q(w) = φµ,σ2(w), and p(w) = C/|w|. Denote u := µ2/(2σ2). Then,\nKL (Q(w)‖P(w))\n= const. + 1\n2\n( log 2 + e−u ∞∑ k=0 uk k! ψ(1/2 + k) ) (3)\n= const.− 1 2 ∂M(a; 1/2;−u) ∂a ∣∣∣∣ a=0 , (4)\nwhere ψ(x) denotes the digamma function, and M(a; b; z) the Kummer’s function of the first kind.\nWe can obtain gradients w.r.t. µ and σ2 using,\n∇uKL (Q(w)‖P(w)) = 1 u = 0D+(√u)√ u u > 0 , (5)\nand the chain rule; D+(x) is the Dawson integral. The derivative is continuous in u on [0,∞).\nBefore proceeding, we note that Equation (5) is sufficient to implement first order gradient-based optimisation, and thus can be used to replace the approximations used in (Kingma et al., 2015; Molchanov et al., 2017). Note that numerically accurate implementations of the D+(x) exist in many programming languages (e.g. (Johnson, 2012)).\nIn VI literature, the term KL (Q(w)‖P(w)) is often interpreted as a regulariser, constraining Q(w) from concentrating at the maximum likelihood estimate which would be optimal w.r.t. the other term EQ(W )[log p(Y |X,W )] in the ELBO. It is thus natural to ask what effect this term has on the variational parameters. Noticing that only the infinite sum in Equation (3) depends on these parameters, and that the first summand is always equal to ψ(1/2), we can focus on terms corresponding to k ≥ 1. Because ψ(1/2 + k) > 0,∀k ≥ 1, all summands are non-negative. Hence the penalty will be minimised if µ2/(2σ2) = 0, i.e. when µ = 0 and/or σ2 → ∞; Corollary 3 is sufficient to establish that this minimum is unique.\nCorollary 3. Under assumptions of Proposition 2, KL (Q(w)‖P(w)) is strictly increasing for u ∈ [0,∞).\nSections 3.1 and 3.2 suggests the pathological behaviour is non-trivial to remove unless we replace the (truncated) log uniform prior.4 An alternative route is to interpret optimisation of the variational objective from above as a type of penalised maximum likelihood estimation.\nProposition 2 and Corollary 3 suggest that the variational formulation cancels the pathologies of the true posterior distribution which both invalidates the Bayesian interpretation, but also means that the algorithm may perform well in terms of accuracy and other metrics of interest. Since the KL (Q(W )‖P(W )) regulariser will force the mean parameters to be small, and the variances to be large, and the EQ(W )[log p(Y |X,W )] will generally push the parameters towards the maximum likelihood solution, the resulting fit might have desirable properties if the right balance between the two is struck. As the Bayesian interpretation no longer applies, the balance can be freely manipulated by reweighing the KL by any positive constant. The strict page limit and desire to discuss the singularity issue lead us to leave exploration of this direction to future work."
  }, {
    "heading": "4. Approximating distribution singularities",
    "text": "Both the Bernoulli and Gaussian dropout can be seen as members of a larger family of algorithms where individual layer inputs are perturbed by elementwise i.i.d. random noise. This is equivalent to multiplying the corresponding row wi of the subsequent weight matrix by the same noise variable. One could thus define wi = siθi, si ∼ Q(si),\n4Louizos et al. (2017) made promising progress there.\nQ(si) being an arbitrary distribution, and treat the induced distribution over wi as an approximate posterior Q(wi).\nAn issue with this approach is that it leads to undefined KL (Q(W )‖P(W |X,Y )) whenever the prior assigns zero mass to the individual directions defined by θ. To understand why, note that KL (Q(W )‖P(W |X,Y )) is defined only if Q(W ) is absolutely continuous w.r.t. P(W |X,Y ) which means that whenever P(W |X,Y ) assigns probability zero to a particular set, Q(W ) does so too. The right-hand side plot in Figure 4 shows a simple example of the case where neither distribution is absolutely continuous w.r.t. the other: the blue Gaussian assigns zero mass to any set with Lebesgue measure zero, such as the line along which the orange distribution places all its mass, and thus the orange Gaussian distribution is not absolutely continuous w.r.t. the blue one. This example is relevant to our problem from above, where Q(wi) always assigns all its mass to along the direction defined by the vector θi. For more details, see for example (Matthews, 2016, Section 2.1). When a measure is not absolutely continuous w.r.t. another measure, it can be shown to have a so called singular component relative to that measure, which we use as a shorthand for referring to this issue. Consequences for variational Bayesian interpretations of dropout are discussed next."
  }, {
    "heading": "4.1. Implications for Bayesian dropout interpretations",
    "text": "Section 3.2 in (Kingma et al., 2015) proposes to use a shared Gaussian random variable for whole rows of the posterior weight matrices. Specifically si ∼ N (1, α) is substituted for Q(si) in the generic algorithm described in the previous section. We call such behaviour in the context of variational inference an approximating distribution singularity. The singularity has two possible negative consequences.\nFirst, if only the si scalars are treated as random variables, θ become parameters of the discriminative model instead of the variational distribution. Optimisation of the ELBO will yield a valid Bayesian posterior approximation for the si. The lack of regularisation of θ might lead to significant overfitting though, as θ represent all weights in the BNN.\nSecond, if the fully factorised log uniform prior is used as before, then the directions defined by θ constitute a measure zero subspace of RD, and thus the KL (Q(W )‖P(W )) and consequently KL (Q(W )‖P(W |X,Y )) are undefined for any configuration of θ. This is an instance of the issue described in the previous section. As a consequence, standard variational inference with this approximating family and target posterior is impossible.\nA similar problem is encountered in (Gal & Ghahramani, 2016; Gal, 2016). The approximate posterior is defined as Q(wi) = p δ0 + (1 − p) δθi for each row in every weight matrix. The assumed prior is a product of independent non-degenerate Gaussian distributions which by definition assigns non-zero mass only to sets of positive Lebesgue measure. Again, the approximate posterior is not absolutely continuous w.r.t. the prior and thus the KL is undefined.\nTo address this issue, Gal & Ghahramani (2016) propose to replace the Dirac deltas in Q(wi) by Gaussian distributions with small but non-zero noise (we call this the convolutional approach). As an alternative, Gal (2016) proposes to instead discretise the Gaussian prior and the approximate posterior so both assign positive mass only to a shared finite set of values. Because the discretised Gaussian assigns non-zero mass to all points in the set, the approximate posterior is absolutely continuous w.r.t. this prior (we refer to this as the discretisation approach).\nStrictly speaking, the two approaches cannot be equivalent because the corresponding random variables take values in distinct measurable spaces (RD and a discrete grid respectively). Notwithstanding, both approaches are claimed to lead to the same optima for the variational parameters.5 The suggested method for addressing this discrepancy is to introduce a continuous relaxation (Gal, 2016, p. 119) of the optimisation problem for the discrete case. The precise details of this relaxation are not given. One could define it as the relaxation that satisfied the required KL-condition (Gal, 2016, Appendix A), but there is of course then a risk of a circular argument. Putting these intuitive arguments on a firmer footing is one motivation for what follows here.\nIn the light of Section 3.2, it is natural to ask whether either of the proposed approaches will tend to a stable objective as the added noise shrinks to zero, and the discretisation becomes increasingly refined, respectively for the convolu-\n5Modulo the Euclidean distance to a closest point in the finite set for the discretisation approach.\ntional and discretisation approaches. Theorem 4 provides an affirmative answer by proving that both approaches lead to the same limit under reasonable assumptions.6\nTheorem 4. Let Q,P be Borel probability measures on RD, P with a continuous density p w.r.t. the D-dimensional Lebesgue measure, and Q supported on an at most countable measurable set S ⊂ QD, with density q w.r.t. the counting measure on QD. If S is infinite, further assume that diam(S) <∞, i.e. supx,y∈S ‖x− y‖2 <∞.\nThen there exists a sequence (s(n)) ⊂ R independent of Q and P s.t. the limit for both the sequences of convolved and discretised distributions {(Q(n),P(n))}n∈N,7\nlim n→∞\n{ KL (Q(n)‖P(n))− s(n) } = E\nQ\n( log qp ) , (6)\ngiven the perturbation noise is Gaussian and eventually shrinks to zero, and that the discretisation creates ever finer grid with equally sized cells as n → ∞. The sequence (s(n)) tends to 0 if Q P and to infinity otherwise.\nThe right-hand side (r.h.s.) of Equation (6) satisfies Gal’s KL condition, i.e. it leads to the same optimisation problem and thus unifies the convolutional and discretisation approach.\nUnlike in (Gal, 2016, Appendix A), our derivation does not make an extraneous assumption on the distribution over any function of the θ parameters nor does it require that the expectation of‖θi‖22 grows without bounds with dim(θi). Neither of these two assumptions is sure to hold in practice as θ are being optimised, and θi in any modern (B)NN is initially scaled by √ dim(S) exactly to achieve approximately constant Euclidean norm irrespective of the dimension.\nWe explored whether Equation (6) holds more generally. Theorem 5 extends the convolutional approach to a considerably larger class of approximating distributions.\nTheorem 5. Let Q,P be Borel probability measures on RD, P with a bounded continuous density p w.r.t. the Lebesgue measure on RD, and Q supported on a measurable linear manifold S ⊂ RD of (Hamel) dimension KS . Assume Q has a continuous bounded density q w.r.t. the Lebesgue measure on S, where the continuity is w.r.t. the trace topology.\nThen there exists a sequence (s(n)) ⊂ R dependent only on KS s.t. the following holds for the convolutional approach,\nlim n→∞ { KL (Q(n)‖P(n))− s(n)KS } = E Q ( log qp ) , (7)\ngiven the perturbation noise is Gaussian and eventually shrinks to zero. The sequence (s(n)KS ) tends to 0 if Q P and to infinity otherwise.\n6We state only the most important assumptions in Theorems 4 and 5. Please see the appendix for the full set of assumptions.\n7P(n) = P , ∀n ∈ N, in the convolutional case.\nA result related to Theorem 5 for the discretisation approach can be derived under assumptions similar to Theorem 4 with one important difference: (s(n)KS ), if it exists, is affected not only by KS , but also by the orientation of S in RD. This is because the dominating Lebesgue measure is different for each affine subspace S and thus, unlike in the countable support case, q cannot be defined w.r.t. a single dominating measure. Implicit in Theorems 4 and 5 is that the same constant can be subtracted from KL (Q(n)‖P(n)) for all distributions Q with the same type of support. Hence if we are optimising over a family of singular approximating distributions, the sequence (s(n)) (resp. (s(n)KS )) does not need to change between updates to obtain the desired limit.\nBefore moving to Section 5 which discusses some of the merits of using Equations (6) and (7) as an objective for approximate Bayesian inference, let us make two comments.\nFirst, taking the limit makes the decision about size of perturbation or coarseness of the discretisation unnecessary. The sequences used do not cause the same instability problems discussed in Section 3.2 because the true posterior is well-defined even in the limit, which we assume in saying that P is a probability measure. The main open question is thus whether optimisation of the r.h.s. of Equation (6) will yield a sensible approximation of this posterior.\nSecond, if there is a family of approximate posterior distributions Q parametrised by ψ ∈ Ψ, the equality,\nargmin ψ∈Ψ E Qψ\n( log\nqψ p ) = lim n→∞ argmin ψ∈Ψ KL (Q (n) ψ ‖P (n)) ,\n(8) need not hold unless stricter conditions are assumed. Equation (8) is of interest in cases when KL (Q(n)ψ ‖P(n)) has some desirable properties (e.g. good predictive performance) which we would like to preserve. However, this is not the case for variational Bernoulli dropout as the objective being used by Gal & Ghahramani (2016) is, in terms of gradients w.r.t. the variational parameters, identical to the limit.\nFurthermore, we can view both the discretisation and convolutional approaches as mere alternative vehicles to derive the same quasi discrepancy measure (cf. Section 5). If this quasi discrepancy possesses favourable properties, the precise details of optima attained along the sequence might be less important. One benefit of this view is in avoiding arguments like the previously mentioned continuous relaxation (Gal, 2016, p. 119)."
  }, {
    "heading": "5. Quasi-KL divergence",
    "text": "The r.h.s. of Equations (6) and (7) is markedly similar to the formula for standard KL divergence. We now make this link explicit. If ZPS := ∫ S p dmS < ∞, mS being either the counting or the Lebesgue measure dominating\nmeasure for q, we can the probability density pS := p/ZPS , and denote the corresponding distribution on (S,BS) by PS . We term Equation (9) the Quasi-KL (QKL) divergence,\nQKL (Q‖P) := E Q\n( log qp ) = KL (Q‖PS)− log ZPS .\n(9) Taking Equation (9) as a loss function says that we would like to find such a Q for which the KL divergence between Q and PS is as small as possible, while making sure that the corresponding set S runs through high density regions of P, preventing Q from collapsing to subspaces where p is easily approximated by q but takes low values. Since p is continuous (c.f. Theorem 4), values of p roughly indicate how much mass P assigns to the region where S is placed.\nStandard KL divergence and QKL are equivalent when Q P and the two distributions have the same support. QKL is not a proper statistical divergence though, as it is lower bounded by − log ZPS instead of zero. The nonnegativity could have been satisfied by defining QKL as KL (Q‖PS), dropping the log ZPS term. However, this would mean losing the above discussed effect of forcing S to lie in a relatively high density region of P, and also the motivation of being a limit of the two sequences considered in Theorem 4.\nNevertheless, QKL inherits some of the attractive properties of KL divergence: the density p need only be known up to a constant, the reparameterisation trick (Kingma & Welling, 2014) and analogical approaches for discrete random variables (Maddison et al., 2017; Jang et al., 2017; Tucker et al., 2017) still apply, and stochastic optimisation and integral approximation techniques can be deployed if desired.\nOn a more cautionary note, we emphasise that EQ(log pq ) is upper bounded by log ZPS and not the log marginal likelihood as is the case for standard KL use in VI. Hence optimisation of this objective w.r.t. hyperparameters of P need not work very well, since the resulting estimates could be biased towards regions where the variational family performs best.8 This might explain why prior hyperparameters usually have to be found by validation error based grid search (Gal, 2016, e.g. p. 119) instead of ELBO optimisation as is common in the sparse Gaussian Process literature (Titsias, 2009).\nWhether and when is QKL an attractive alternative to the more computationally expensive but proper statistical discrepancy measures which are capable of handling singular distributions (e.g. Wasserstein distances) is beyond the scope of this paper. To provide basic intuition of whether QKL might be a sensible objective for inference, Section 5.1 focuses on a simple practical example that yields a well known algorithm as the optimal solution to QKL optimisation, and exemplifies some of the above discussed behaviour.\n8A similar issue for KL was observed by Turner et al. (2010)."
  }, {
    "heading": "5.1. QKL and Principal Component Analysis",
    "text": "Proposition 6 is an application of Theorem 5:\nProposition 6. Assume P = N (0,Σ), Σ a (strictly) positive definite matrix of rank D, with a degenerate Gaussian Q = N (0,AV AT), where A is a D × K matrix with orthonormal columns, and V is a K × K (strictly) positive definite diagonal matrix. Then,\nQKL (Q‖P) = c− 1 2 K∑ k=1 logV kk + 1 2 Tr ( ATΣ−1AV ) where c is constant w.r.t.A,V . The optimal solutionA,V is to set columns of A to the top K eigenvectors of Σ and the diagonal of V to the corresponding eigenvalues.9\nProposition 6 shows that the QKL-optimal way to approximate a full rank Gaussian with a degenerate one is to perform PCA on the covariance matrix. The result is intuitively satisfying as PCA preserves the directions of highest variance; S was thus indeed forced to align with the highest density regions under P as suggested in Section 5. See Figure 5 for a visualisation of this behaviour. Proposition 7 presents a variation of the result of Tipping & Bishop (1999), showing that Equation (8) can hold in practice.\nProposition 7. Assume similar conditions as in Proposition 6, except Q will now be replaced with a series of distributions convolved with Gaussian noise: Q(n) = N (0,A(n)V (n)(A(n))T + τ (n)I). Given τ (n) ↓ 0 as n → 0 and the obvious constraints on A(n),V (n), Equation (8) holds in the sense of shrinking Euclidean/Frobenius norm between {A(n),V (n)} and the PCA solution.\nIt is necessary to mention that both the QKL from Proposition 6 and any of the yet unconverged KL divergences in Proposition 7 have ( D K ) local optima for any combination of the eigenvectors which might lead to potentially problematic behaviour of gradient based optimisation."
  }, {
    "heading": "6. Conclusion",
    "text": "The original intent behind dropout was to provide a simple yet effective regulariser for neural networks. The main value of the subsequent reinterpretation as a form of approximate Bayesian VI thus arguably lies in providing a principled theoretical framework which can explain the empirical behaviour, and guide extensions to the method. We have shown the current theory behind variational Bayesian dropout to have issues stemming from two main sources: 1) use of improper or pathological priors; 2) singular approximating distributions relative to the true posterior.\n9We have assumed both Gaussians are zero mean to simplify the notation. Analogical results holds in the more general case.\nThe former issue pertains to the improper log uniform prior in variational Gaussian dropout. We proved its use leads to irremediably pathological behaviour of the true posterior, and consequently studied properties of the optimisation objective from a non-Bayesian perspective, arguing it is set up in such a way that cancels some of the pathologies and can thus still provide good empirical results, albeit not because of the Bayesian or the related MDL arguments.\nThe singular approximating distribution issue is relevant to both the Bernoulli and Gaussian dropout by making standard VI impossible due to an undefined objective. We have shown that the proposed remedies in (Gal & Ghahramani, 2016; Gal, 2016) can be made rigorous and are special cases of a broader class of limiting constructions leading to a unique objective which we termed quasi-KL divergence. We presented initial observations about QKL’s properties, suggested an explanation for the empirical difficulty of obtaining hyperparameter estimates in dropout-based approximate inference, and motivated future exploration of QKL by showing it naturally yields PCA when approximating a full rank Gaussian with a degenerate one.\nAs use of improper priors and singular distributions is not isolated to the variational Bayesian dropout literature, we hope our work will contribute to avoiding similar pitfalls in future. Since it relaxes the standard KL assumptions, QKL will need further careful study in subsequent work. Nevertheless, based on our observations from Section 5 and the previously reported empirical results of variational Bayesian dropout, we believe QKL inspires a promising future research direction with potential to obtain a general framework for the design of computationally cheap optimisation-based approximate inference algorithms."
  }, {
    "heading": "Acknowledgements",
    "text": "We would like to thank Matej Balog, Diederik P. Kingma, Dmitry Molchanov, Mark Rowland, Richard E. Turner, and the anonymous reviewers for helpful conversations and valuable comments. Jiri Hron holds a Nokia CASE Studentship. Alexander Matthews and Zoubin Ghahramani acknowledge the support of EPSRC Grant EP/N014162/1 and EPSRC Grant EP/N510129/1 (The Alan Turing Institute)."
  }],
  "year": 2018,
  "references": [{
    "title": "Uncertainty in Deep Learning",
    "authors": ["Y. Gal"],
    "venue": "PhD thesis, University of Cambridge,",
    "year": 2016
  }, {
    "title": "Variational Gaussian Dropout is not Bayesian",
    "authors": ["J. Hron", "Matthews", "Alexander G. de G", "Z. Ghahramani"],
    "venue": "In Second workshop on Bayesian Deep Learning (NIPS",
    "year": 2017
  }, {
    "title": "Categorical Reparameterization with Gumbel-Softmax. 2017",
    "authors": ["E. Jang", "S. Gu", "B. Poole"],
    "venue": "URL https: //arxiv.org/abs/1611.01144",
    "year": 2017
  }, {
    "title": "Auto-Encoding Variational Bayes",
    "authors": ["D.P. Kingma", "M. Welling"],
    "venue": "In Proceedings of the Second International Conference on Learning Representations (ICLR",
    "year": 2014
  }, {
    "title": "Scalable Gaussian process inference using variational methods",
    "authors": ["Matthews", "Alexander G. de G"],
    "venue": "PhD thesis, University of Cambridge,",
    "year": 2016
  }, {
    "title": "Variational Dropout Sparsifies Deep Neural Networks",
    "authors": ["D. Molchanov", "A. Ashukha", "D. Vetrov"],
    "venue": "In Proceedings of the 34th International Conference on Machine Learning,",
    "year": 2017
  }, {
    "title": "Bayesian Learning for Neural Networks",
    "authors": ["R.M. Neal"],
    "year": 1996
  }, {
    "title": "Dropout: A Simple Way to Prevent Neural Networks from Overfitting",
    "authors": ["N. Srivastava", "G.E. Hinton", "A. Krizhevsky", "I. Sutskever", "R. Salakhutdinov"],
    "venue": "Journal of Machine Learning Research,",
    "year": 1929
  }, {
    "title": "Regression Shrinkage and Selection via the Lasso",
    "authors": ["R. Tibshirani"],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp",
    "year": 1996
  }, {
    "title": "Probabilistic Principal Component Analysis",
    "authors": ["M.E. Tipping", "C.M. Bishop"],
    "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
    "year": 1999
  }, {
    "title": "Variational learning of inducing variables in sparse Gaussian processes",
    "authors": ["M.K. Titsias"],
    "venue": "In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics,",
    "year": 2009
  }, {
    "title": "Two problems with variational expectation maximisation for time-series models",
    "authors": ["R.E. Turner", "P. Berkes", "M. Sahani"],
    "venue": "Inference and Estimation in Probabilistic TimeSeries Models,",
    "year": 2010
  }],
  "id": "SP:2df85d117cee56b50eef000a18e1a16ab364626c",
  "authors": [{
    "name": "Jiri Hron",
    "affiliations": []
  }, {
    "name": "Alexander G. de G. Matthews",
    "affiliations": []
  }, {
    "name": "Zoubin Ghahramani",
    "affiliations": []
  }],
  "abstractText": "Dropout, a stochastic regularisation technique for training of neural networks, has recently been reinterpreted as a specific type of approximate inference algorithm for Bayesian neural networks. The main contribution of the reinterpretation is in providing a theoretical framework useful for analysing and extending the algorithm. We show that the proposed framework suffers from several issues; from undefined or pathological behaviour of the true posterior related to use of improper priors, to an ill-defined variational objective due to singularity of the approximating distribution relative to the true posterior. Our analysis of the improper log uniform prior used in variational Gaussian dropout suggests the pathologies are generally irredeemable, and that the algorithm still works only because the variational formulation annuls some of the pathologies. To address the singularity issue, we proffer Quasi-KL (QKL) divergence, a new approximate inference objective for approximation of high-dimensional distributions. We show that motivations for variational Bernoulli dropout based on discretisation and noise have QKL as a limit. Properties of QKL are studied both theoretically and on a simple practical example which shows that the QKLoptimal approximation of a full rank Gaussian with a degenerate one naturally leads to the Principal Component Analysis solution.",
  "title": "Variational Bayesian dropout: pitfalls and fixes"
}