{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Data-driven decision-making has become the subject of increased interest and been used in a number of practical applications. One of the most promising approaches is mathematical programming based on predictive models generated by machine learning. Recent advances in machine learning have made it easier to create accurate predictive models, and resulting predictions have been used to build mathematical programming problems (we refer to such approaches as predictive optimization). Predictive optimization is employed in applications for which frequent trial-and-error process are not practical, such as water distribution optimization (Draper et al., 2003), energy generation planning (Baos et al., 2011), retail price optimization (Johnson\n1NEC Corporation. Correspondence to: Shinji Ito <sito@me.jp.nec.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\net al., 2016; Ito & Fujimaki, 2016), supply chain management (Thomas et al., 1996; Jung et al., 2004; Bertsimas & Thiele, 2004), and portfolio optimization (Markowitz, 1952; Chan et al., 1999; Konno & Yamazaki, 1991). Another important use for data-driven decision-making is in reinforcement learning (Kaelbling et al., 1996; Sutton & Barto, 2013). Here it is employed in situations mainly in which frequent trial-and-error operations are possible, except for batch reinforcement learning (Lange et al., 2012). The focus of this paper is on the first approach, i.e., predictive optimization.\nIn many practical applications of predictive optimization, it is essential to estimate the quality of the computed strategy because executing a strategy is often costly and risky. For example, predictive price optimization has been used to estimate revenue functions through regressions of demand as functions of product prices, and then, to optimize pricing strategies by maximizing estimated revenue functions (Johnson et al., 2016; Ito & Fujimaki, 2016; 2017; Yabe et al., 2017). In practice, users need to assess the return for the computed “optimal” strategy before changing prices, in order to prevent unforeseen heavy losses. In a situation in which costs for trial-and-error processes are unrealistically high, a key challenge in predictive optimization is how to assess the quality (or expected return) of the “optimal” solution by means of an estimated objective function.\nPredictive optimization consists of two steps: estimation and optimization. In the estimation step, we construct an estimated objective function f(z, θ̂) for the true objective function f(z, θ∗), where θ is a parameter of f , and z is a decision variable corresponding to the strategy to be optimized. In the optimization step, we compute the estimated optimal strategy ẑ = arg maxz∈Z f(z, θ̂), where Z is the domain of z. Because it would be expensive to observe f(ẑ, θ∗) (i.e., to perform ẑ in a real environment), we usually estimate it by f(ẑ, θ̂), which we call simple evaluation, in order to assess the quality of ẑ.\nIt has been empirically seen, however, that this simple evaluation tends to be too optimistic. For example, in the contexts of algorithmic investment and portfolio optimization, it has been reported (Michaud, 1989; Chapados, 2011; Harvey & Liu, 2015) that f(ẑ, θ̂) is much better than the acutual return. Michaud (Michaud, 1989) argued that this bias ap-\npears because the mean-variance optimizers act as “error maximizers”, i.e., optimizers tend to choose solutions containing large errors. According to (Harvey & Liu, 2015), a common practice in evaluating trading strategies is simple heuristics that discount the estimated objective to 50%, i.e., consider 0.5f(ẑ, θ̂) to be an estimator of f(ẑ, θ∗). Heuristics referred to as portfolio resampling techniques (Michaud, 1998; Scherer, 2002) have been studied for nearly 20 years but have not yet to be theoretically justified. A few recent studies (Bailey & Marcos, 2016; Bailey et al., 2014; Harvey & Liu, 2015) have statistically analyzed and proposed algorithms to mitigate the bias issue, but their algorithms are restricted to particular applications (e.g., algorithmic investment) and, as far as we know, there exists no principled algorithm for an unbiased estimator of f(z, θ∗) in general predictive optimization problems.\nThe goal of this study is to address this optimistic bias issue, and to propose methods for unbiased estimation of true objective values. Our key contributions are summarized as follows.\nFirst, we prove that the estimated optimal value f(ẑ, θ̂) is biased even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗). Further, we correlate the bias issue to overfitting in machine learning, which yields a valuable insight into bias correction methods.\nSecond, we propose two algorithms for estimating the value of true objective functions under mild assumptions. The first algorithm is based on a procedure similar to crossvalidation and has been inspired by the analogy between our problem and overfitting in supervised learning. This algorithm corrects the optimistic bias, but suffers from pessimistic bias, i.e., the estimated value is biased in a direction suggesting a poorer result, similar to that which occurs in cross-validation. The magnitude of this pessimistic bias tends to be larger than that of cross-validation, and hence, it is not negligible in many cases. To mitigate this issue, we propose another algorithm, which we refer to as a parameter perturbation method. This algorithm employs a resampling technique and is theoretically proven here to achieve asymptotically unbiased estimation.\nOur experimental results show that the proposed algorithms are able to estimate the value of a true objective function more accurately than a state-of-the-art hold-out validation technique commonly used in algorithmic investment (Bailey & Marcos, 2016; Bailey et al., 2014). In a simulation experiment with real-world retail datasets for price optimization, we have observed that our evaluation algorithms estimate a 17% increase in the gross profit, which seems to be more realistic and convincing than the value estimated without bias correction.\nThe remainder of this paper is structured as follows. In Section 2, we introduce the framework of the combination of machine learning and mathematical optimization in examples of usage. We also show that such a framework suffers from bias w.r.t. optimal values. Section 4 gives solutions to this problem and theoretical guarantees for them. In Section 5, the empirical performance of our algorithms is demonstrated."
  }, {
    "heading": "2. Predictive Optimization",
    "text": "Suppose we have a sequence of training data x = (x1, . . . , xN ) ∈ XN , where N is the number of data instances. Each xn is generated from a probabilistic model {p(x|θ) : θ ∈ Θ} parameterized by θ ∈ Θ. We further suppose having a set of objective functions {f(z, θ) : θ ∈ Θ} where z ∈ Z is a decision variable that corresponds to strategies to be optimized. The goal of predictive optimization is to find z∗ ∈ arg maxz∈Z f(z, θ∗), where θ∗ is the true parameter. However, such a true parameter is unknown in practice, and therefore we estimate θ∗ by θ̂ from x, and compute the estimated optimal solution ẑ ∈ arg maxz∈Z f(z, θ̂) rather than z∗. This section discusses three examples of predictive optimization problems in order to provide a better picture of the process.\nExample 1 (Coin-Tossing). Suppose that we have a coin coming up heads with probability θ∗ and tails with probability 1− θ∗, where θ∗ ∈ Θ := [0, 1]. Consider predicting heads or tails for this coin. If we predict the subsequent face correctly, we win $1, and, otherwise, nothing. Predicting heads, then, will result in earning $1 with probability θ∗ and $0 with probability 1 − θ∗, and hence, the expectation value of the earnings for predicting heads is f(‘head’, θ∗) = 1 · θ∗+ 0 · (1− θ∗) = θ∗. Similarly, the expected earnings for predicting tails is f(‘tail’, θ∗) = 1− θ∗. If we knew the true parameter θ∗, we could maximize the expected earnings by choosing z∗ ∈ arg maxz∈Z f(z, θ∗), where Z = {‘head’, ‘tail’} stands for a set of feasible strategies. Since we do not know the true parameter θ∗, however, we use, rather, past data x ∈ XN := {‘head’, ‘tail’}N of N tossings, for estimating θ∗.\nTable 1 illustrates how the optimistic bias occurs in predictive optimization. Suppose θ∗ = 1/2 (a) and that there are four cases of the observed pattern for three tossings (b). The estimators of θ∗ might then be obtained as (c), using maximum likelihood estimation. On the basis of θ̂, the “best” strategies are estimated as (d), and the estimated and true optimal values are summarized in (e) and (f). It is worth noting that the expectation of (e) over four cases (bottom middle), which is 3/4, is larger than the true expectation (bottom right), which is 1/2 even if the θ̂ is unbiased, i.e., the expectation of θ̂ matches θ∗ (bottom left).\nExample 2 (Portfolio optimization (Markowitz, 1952)).\nSuppose that there are d assets, and let Rj stand for the return on each component asset for j ∈ {1, . . . , d}. Let µ∗ = (µ∗1, . . . , µ ∗ d) > ∈ Rd be the expected return for each asset, i.e., µ∗j = E[Rj ]. Then the portfolio expressed as Rz = ∑d j=1 zjRj , where zj ≥ 0 is the weighting of the j-th component asset and z = (z1, . . . , zd)> ∈ Rd≥0, has expected return E[Rz] = ∑d j=1 zjµ ∗ j = µ\n∗>z. Variance in the portfolio return can be expressed as var[Rz] = z>Σ∗z, where Σ∗ is the covariance matrix of (R1, . . . , Rd). Denote θ∗ = (µ∗,Σ∗). Then, with a given risk tolerance λ ≥ 0, the optimal portfolio is obtained as the solution of the following problem:\nMaximize f(z, θ∗) := µ∗>z − λz>Σ∗z, (1) subject to d∑ j=1 zj = 1, zj ≥ 0 (j = 1, . . . , d).\nIn practice, however, since θ∗ is never available, we estimate it from historical data x = (x1, . . . , xN ), where xn ∈ Rd is an observation of past returns for individual component assets (Qiu et al., 2015; Agarwal et al., 2006; Li & Hoi, 2012). Under the assumption that xn follow the same distribution,1 the estimators of µ∗ and Σ∗ are obtained by µ̂ = 1N ∑N n=1 xn and Σ̂ = 1 N−1 ∑N n=1(xn− µ̂)(xn− µ̂)>. We obtain the optimal solution by solving (1) with the replacement of µ∗ and Σ∗ by µ̂ and Σ̂, respectively.\nExample 3 (Predictive price optimization(Ito & Fujimaki, 2017; 2016)). Suppose we have d products whose prices are denoted by z = (z1, . . . , zd). Let us denote their sales quantities by q∗(z) = (q∗j (z)) d j=1 ∈ Rd, which are functions of the price z. The gross revenue function is then defined by f(z, θ∗) = q∗(z)>z, and the true optimal solution is obtained by solving the following problem:\nMaximize q∗(z)>z subject to z ∈ Z, (2)\nwhere Z ⊆ Rd is a pre-defined domain of prices (e.g., list price, 3%-off, 5%-off, and so on). However, we can never know the true demand-price relationship q∗(z), and\n1This condition can easily be relaxed.\nthe predictive price optimization approximates q∗(z) by the following regression functions:\nq(z, θ) = K∑ k=1 θkψk(z) + , ∼ N(0,Σ), (3)\nwhere {ψk : Rd → Rd}Kk=1 are fixed basis functions and {θk}Kk=1 ⊆ R are regression coefficients. We estimate θ = (θ1, . . . , θK) as a standard regression problem and then solve (2) after replacing q∗(z) by q(z, θ̂), where θ̂ is the estimator of θ∗."
  }, {
    "heading": "3. Optimistic Bias in the Optimal Value",
    "text": ""
  }, {
    "heading": "3.1. Existence of Optimistic Bias",
    "text": "This section formally proves the existence of optimistic bias in estimated optimal values. In the above examples, the objective functions f(z, θ) w.r.t. θ were affine functions and θ̂ were unbiased estimators of θ∗. Hence, the constructed objective function f(z, θ̂) was an unbiased estimator of the true objective function f(z, θ∗), i.e., it holds that\nEx[f(z, θ̂)] = Ex[f(z, θ∗)], z ∈ Z. (4)\nFrom this equation, one might expect that Ex[f(ẑ, θ̂)] and f(ẑ, θ̂) would be reasonable estimators of Ex[f(ẑ, θ∗)] and f(ẑ, θ∗), respectively. However, the following proposition contradicts this intuition.\nProposition 1 (Optimistic Bias). Suppose (4) holds. For ẑ ∈ arg maxz∈Z f(z, θ̂) and z∗ ∈ arg maxz∈Z f(z, θ∗), it holds that\nEx[f(ẑ, θ̂)] ≥ f(z∗, θ∗) ≥ Ex[f(ẑ, θ∗)]. (5)\nThe right inequality is strict if ẑ is suboptimal w.r.t. the true objective function f(z, θ∗) with non-zero probability.\nProof. By taking the expectation of both sides of f(ẑ, θ̂) ≥ f(z∗, θ̂), we obtain the left inequality of (5) as follows:\nEx[f(ẑ, θ̂)] ≥ Ex[f(z∗, θ̂)] = f(z∗, θ∗),\nwhere the equality comes from (4). Similarly, the right inequality of (5) comes from f(z∗, θ∗) ≥ f(ẑ, θ∗). Further, if ẑ /∈ arg maxz∈Z f(z, θ∗) holds with non-zero probability, then f(z∗, θ∗) > f(ẑ, θ∗) holds with non-zero probability and f(z∗, θ∗) ≥ f(ẑ, θ∗) always holds, which implies f(z∗, θ∗) > E[f(ẑ, θ∗)].\nThis proposition implies that the estimated optimal value f(ẑ, θ̂) is not an unbiased estimator of f(ẑ, θ∗) even if the estimated objective function f(z, θ̂) is an unbiased estimator of the true objective function f(z, θ∗). This optimistic bias\nhas been empirically learned in the context of portfolio optimization (Michaud, 1989). Recently, (Harvey & Liu, 2015; Harvey et al., 2016) have proposed bias correction methods based on statistical tests, though their methods are applicable only to cases in which the objective function is the Sharpe ratio. Other recent studies (Bailey & Marcos, 2016; Bailey et al., 2014) have also focused on the Sharpe ratio and proposed a hold-out validation method. Although their methods apply to general predictive optimization problems, they have not been proven to obtain unbiased estimators. Note that a similar inequality has been discovered in the context of stochastic programs,2 one that corresponds to the left inequality of (5). For the special case in which Z is a finite set, the same inequality as (5) has been shown in the context of decision analysis (Smith & Winkler, 2006)."
  }, {
    "heading": "3.2. Connection to Empirical Risk Minimization",
    "text": "This subsection discusses the connection of the optimistic bias issue to overfitting in machine learning, which connection has led to the ideas underlying our proposed algorithms. In supervised machine learning, we choose the prediction rule ĥ from a hypothesis space H by minimizing the empirical error, i.e., we let ĥ ∈ arg minh∈H 1 n ∑N n=1 `(h, xn), where xn is the observed data generated from a distribution D and ` is a loss function. The empirical error 1N ∑N n=1 `(h, xn) is an unbiased estimator of the generalization error `D(h) := Ex∼D[`(h, x)] for arbitrary fixed prediction rule h, i.e., it holds that Exn∼D[ 1N ∑N n=1 `(h, xn)] = `D(h) for any fixed h. De-\nspite this equation, the empirical error 1N ∑N n=1 `(ĥ, xn) for the computed parameter ĥ is smaller than the generalization error `D(ĥ) in most cases, because ĥ overfits the observed samples, as is well known (Vapnik, 2013). The analogy between the optimistic bias in our setting and the overfitting issue in machine learning suggests the reuse of datasets for estimation of their objective functions and evaluation of objective values.\nA comparison between empirical risk minimization (ERM) and our prediction-based optimization is summarized in Table 2. As is shown in the Table, our problem concerning bias in predictive optimization has a structure similar to that of the problem of overfitting in empirical risk minimization. Typical methods for estimating generalization error in machine learning would be cross-validation and such asymptotic bias correction as AIC (Akaike, 1973). This paper follows the concept of cross-validation in the context of predictive optimization and, in the following section, proposes a more accurate algorithm.\n2 In stochastic programs, the objective is a random function, and it has been shown in, e.g., (Mak et al., 1999), that the expectation of the minimum of the objective is a lower bound of the minimum of the expectation of the objective."
  }, {
    "heading": "4. Bias Correction Algorithms",
    "text": "Our goal is to construct unbiased estimators for the value f(ẑ, θ∗) of the true objective function, i.e., to construct ρ : Xn → R such that Ex[ρ(x)] = Ex[f(ẑ, θ∗)], where ẑ ∈ arg max\nz∈Z f(z, θ̂) is the computed strategy. We assume\nthe following conditions.\nAssumption 2. (i) f(z, θ) is affine in θ, i.e., ∃a : Z → R, ∃b : Z → R, f(z, θ) = θ>a(z) + b(z).\n(ii) The optimal solution z(θ) ∈ arg maxz∈Z f(z, θ) is uniquely determined for almost all θ.\n(iii) One of the following holds: (iii.a) Z is a finite set, or (iii.b) Z is a compact subset of Rd, and z 7→ (a(z), b(z)) is a continuous injective function.\n(iv) θ̂ is an unbiased estimator of θ∗, i.e., we have Ex[θ̂] = θ∗.\nThe assumptions (i)-(iii) are conditions on mathematical programming problems, and such typical ones as (mixedinteger) linear/quadratic/semidefinite programming problems satisfy these conditions. Assumption (iv) is a condition on the machine learning algorithm for estimating the objective function in the optimization problem, and we can employ any standard unbiased estimation algorithm. Note that the examples in Section 3 satisfy all these assumptions. We assume (i) and (iv) in Section 4.1, and assume (i)-(iv) in Section 4.2."
  }, {
    "heading": "4.1. Cross-Validation Method",
    "text": "As noted in Section 3.2, our problem is closely related to the problem of estimating generalization error. Inspired by the cross-validation method, one of the most popular methods for estimating generalization error in machine learning, we propose a cross-validation method for estimating the value of the true objective function in predictive optimization. In the context of algorithmic investment, a similar method, referred to as the hold-out method is mentioned in (Bailey et al., 2014). The method discussed below is essentially an extension of the hold-out method for general predictive optimization problems.\nOne of the reasons that the value f(ẑ, θ̂) contains biases is that ẑ and θ̂ are dependent random variables. Indeed,\nAlgorithm 1 k-fold cross-validation Input: data x ∈ XN , the number K ≥ 2 of partition Divide data x into K parts x1, . . . ,xK . for k = 1 to K do\nCompute θ̂k, θ̃k from xk,x−k respectively, where we define x−k to be all samples in x except for xk, and compute z̃k ∈ arg maxz∈Z f(z, θ̃k).\nend for Output ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k).\nif ẑ and θ̂ are independent, Ex[f(ẑ, θ̂)] = Ex[f(ẑ, θ∗)] straightforwardly holds from assumptions (i) and (iv). The main idea of the cross-validation method (as with the standard cross-validation in machine learning) is to divide the data x ∈ XN into two parts x1 ∈ XN1 ,x2 ∈ XN2 , where N1 + N2 = N . Note that each element in x1 and x2 follows p(x, θ∗) independently, and, hence, x1 and x2 are independent random variables. Let us denote the estimators based on x1 and x2 by θ̂1 and θ̂2, respectively. Also, the optimal strategy on each estimator is denoted by ẑi := arg maxz∈Z f(z, θ̂i) for i = 1, 2. Then ẑ1 and θ̂2 are independent (the opposite also holds), and we have Ex[f(ẑ1, θ̂2)] = Ex1 [f(ẑ1,Ex2 [θ̂2])] = Ex1 [f(ẑ1, θ∗)]. Further, if N1 is sufficiently close to N , Ex1 [f(z̃1, θ∗)] is close to Ex[f(ẑ, θ∗)]. This idea can be extended to k-fold cross-validation, in which we divide data x ∈ RN into K parts x1, . . . ,xK ∈ RN ′ , where KN ′ = N . We compute z̃k from {x1, . . . ,xK} \\ {xk}, and compute θ̂k from xk. Then the value ρCV (x) := 1K ∑K k=1 f(z̃k, θ̂k) satisfies\nEx[ρCV (x)] = Ex′ [f(z̃, θ∗)], (6)\nwhere z̃ stands for the strategy computed from (K − 1)N ′ samples, under assumptions (i) and (iv).\nA major drawback to Algorithm 1 is that it can only estimate the objective value attained byN −N ′ samples, as is shown in (6), even though the value attained by all N samples is desired. In machine learning, to mitigate this gap, a leave-one-out method (i.e., setting N ′ = 1) can be used. In predictive optimization, however, the number N ′ of holdout samples needs to be large enough to compute another estimator, θ̂k, which limits the accuracy of the estimation of f(ẑ, θ∗). The accuracy of Algorithm 1 is considered in Sec. 5 in an empirical evaluation."
  }, {
    "heading": "4.2. Parameter perturbation method",
    "text": "This subsection proposes another algorithm that addresses the drawbacks of Algorithm 1. Denote the error in the estimated parameter by δ := θ̂−θ∗. The error δ depends on the training data x and can be regarded as a random variable when x is considered to be a random variable. For γ ≥ 0,\nlet us first define η(γ) as follows:\nη(γ) = Eδ[f(z(θ∗ + γδ), θ∗)],\nwhere z(θ) := arg maxz∈Z f(z, θ). Since ẑ = z(θ̂) = z(θ∗ + δ), we have η(1) = E[f(ẑ, θ∗)]. Hence, our goal, unbiased estimation of f(ẑ, θ∗), is equivalent to unbiased estimation of η(1). Let us next define φ(γ) as follows:\nφ(γ) = Eδ[f(z(θ∗ + γδ), θ∗ + γδ)]. (7)\nNote that we have φ(1) = E[f(ẑ, θ̂)]. Further, φ(γ) and η(γ) satisfy φ(0) = η(0) = f(z∗, θ∗) and φ(γ) ≥ f(z∗, θ∗) ≥ η(γ) for all γ ≥ 0, which can be proved in a way similar to that of the proof of Proposition 1.\nThe following proposition plays a key role in our second algorithm. Proposition 3. Suppose that assumptions (i)-(iv) hold. For all γ > 0, φ(γ) is differentiable, and its derivative φ′(γ) satisfies\nη(γ) = φ(γ)− γφ′(γ). (8)\nThe proof of this proposition is summarized in the supplementary material.\nLet us explain this proposition using Figure 1, which is based on the simulation experiment for portfolio optimization used in Section 5 and shows how the values of φ and η behave for some γ ≥ 0. The tangent to φ(γ) at γ = γ0 (the blue broken-line) has a y-intercept (the red broken-line) equal to the value of η(γ0), for all γ0 > 0. From this relationship, the derivative φ′(1) of φ(γ) at γ = 1 satisfies φ′(1) = φ(1) − η(1) = E[f(ẑ, θ̂)] − E[f(ẑ, θ∗)], i.e., the value of φ′(1) is equal to the value of the bias in our predictive optimization problem.\nOur problem is now to obtain an unbiased estimator ζ of φ′(1) that will give us an unbiased estimator of f(ẑ, θ∗), i.e. ρ = f(ẑ, θ̂)− ζ. From the definition of the derivative, the value of φ′(1) can be approximated by (φ(1+h)−φ(1))/h for small h. Further, from the definition of φ, the estimated optimal value f(ẑ, θ̂) is an unbiased estimator of φ(1). Also, the value of φ(1 + h) = E[maxz∈Z f(z, θ∗ + (1 + h)δ)] is the expectation of the optimal value for the objective function with a parameter having an “enhanced” error. If we get samples θ̂h following the distribution of θ∗ + (1 + h)δ, we can develop an estimator of φ(1 + h), and accordingly, we can estimate η(1) = E[f(ẑ, θ∗)].\nSuppose that θ̂(1)h , . . . , θ̂ (s) h follows the distribution of θ ∗ + (1 + h)δ, and define\nρh := 1 + h\nh max z∈Z f(z, θ̂)− 1 hs s∑ j=1 max z∈Z f(z, θ̂ (j) h ). (9)\nThe value ρh, then, has the following property.\nAlgorithm 2 Parameter perturbation method Input: data x ∈ Xn, parameters h > 0, s ∈ {1, 2, . . .} Compute θ̂ from x and set v̂0 = maxz∈Z f(z, θ̂). Generate {θ̂(j)h }sj=1 by (i) for asymptotic normal estimators or (ii) for M-estimators.\n(i) Set θ̂(j)h to be the estimator computed from N/(1 + h)2 samples randomly chosen from x without replacement.\n(ii) Generate δ̂j by (10), and set θ̂ (j) h = θ̂ + δ̂j .\nfor j = 1 to s do Set v̂j = maxz∈Z f(z, θ̂ (j) h ). end for Output ρh := 1+hh v̂0 − 1 hs ∑s j=1 v̂j .\nProposition 4. Under assumptions (i)-(iv), the value ρh defined by (9) is an asymptotically unbiased estimator of f(ẑ, θ∗), i.e., it holds that limh→0 E [ρh] = E[f(ẑ, θ∗)].\nProof. From the definition of ρh and φ(γ), we have E[ρh] = ρ(1) − φ(1+h)−φ(1)h . Hence, we have limh→0 E [ρh] = φ(1) − φ′(1). From Proposition 3, this value is equal to η(1) = E[f(ẑ, θ∗)].\nThe remaining problem is how to obtain samples θ̂h, with enhanced errors, from the distribution of θ∗+(1+h)δ. If θ̂ is an asymptotically normal estimator of θ∗, its distribution can be approximated by the normal distribution N (θ∗, 1NΣ\n∗), where Σ∗ is a constant matrix not dependent on N . Further, when we compute an estimator θ̂h fromN/(1+h)2 data, the distribution of θ̂h can be approximated byN (θ∗, (1+h) 2 N Σ ∗). This is an approximation of the distribution of θ∗ + (1 + h)δ. This procedure for generating θ̂h is used in (i) of Algorithm 2.\nIf θ̂ is an M-estimator, an asymptotically normal estimator commonly used in machine learning, we can eliminate repetitive computation in (i) of Algorithm 2. For M-estimators,\nΣ̂ is given in a closed form, as described in (van der Vaart, 1998), such that N (0, 1N Σ̂) approximates the error distribution of the estimator. Once we have computed Σ̂, we generate samples from an approximated distribution of θ∗ + (1 + h)δ, by adding δ̂ to θ̂, which is obtained by\nδ̂ ∼ N (0, (1 + h) 2 − 1\nN Σ̂). (10)\nWe can, in fact, confirm that the distribution of θ̂+ δ̂ approximates that of θ∗+ (1 +h)δ by applying the normal approximation to θ̂− θ∗ = δ. From the normal approximation δ ∼ N (0, 1N Σ̂), we obtain θ ∗+(1+h)δ ∼ N (θ∗, (1+h) 2 N Σ̂) and θ̂+ δ̂ ∼ N (θ∗+0, 1N Σ̂+ (1+h)2−1 N Σ̂) = N (θ ∗, (1+h) 2\nN Σ̂). This procedure corresponds to (ii) in Algorithm 2."
  }, {
    "heading": "5. Experiments",
    "text": "We have compared our Algorithm 1 and Algorithm 2 with the hold-out method (Bailey & Marcos, 2016; Bailey et al., 2014) and the portfolio resampling method (Scherer, 2002) by means of the simulation models of the examples in Section 2. We used GUROBI Optimizer 6.0.43 for portfolio optimization, and the algorithm in (Ito & Fujimaki, 2016) for price optimization."
  }, {
    "heading": "5.1. Predictive Portfolio Optimization",
    "text": "The portfolio optimization problem described in Example 2 of Section 2 was constructed with θ∗ = (µ∗,Σ∗) defined by µ∗ = 1 + and Σ∗ = X>X , where ∈ Rd were generated by N(0, I) and each entry of X ∈ RD×D was drawn from N (0, D−1). We generated datasets {xn}Nn=1 following N (µ∗,Σ∗), from which we computed θ̂, as in Example 2, and solved the optimization problem (1) with θ∗ replaced by θ̂, to obtain ẑ. We chose D = 50, N = 20, and λ = 1.0 for our simulation experiments. When using the portfolio resampling method, we computed z̄ by means of 10 bootstrap resamplings and outputted f(z̄, θ̂) ≤ f(ẑ, θ̂). For details regarding portfolio resampling, see, e.g., (Scherer, 2002). For the hold-out validation, we first divided N data into N ′ and N −N ′, then computed ẑ1 from the former N ′ data and estimated θ̂2 from the letter N −N ′ data, and then calculated f(ẑ1, θ̂2).\nAccuracy Comparisons Figure 2 shows the means and the standard deviations of computed values of f(z∗, θ∗), f(ẑ, θ̂) and f(ẑ, θ∗) for 400 randomly-initialized datasets. We have observed that:\n• f(ẑ, θ̂) was much larger than f(ẑ, θ∗), which is consistent with Proposition 1. • The hold-out method performed much worse than our 3 http://www.gurobi.com/\nCV and perturbation methods, though its performance improved with an increasingN ′. Also, the variance in the proposed methods was much smaller. Note that we could not set N ′ to be larger than N ′ = 18 since the estimation of θ̂1 and θ̂2 would fail. • The portfolio resampling method computed slightly less optimistic value than f(ẑ, θ̂), but a large amount of optimistic bias remained. • The perturbation method corrected bias better than the CV method w.r.t. both bias and variance. Indeed, it almost perfectly corrected the optimistic bias in expectation. Note that K = 10 was the largest possible value because at least two samples are necessary for estimating the covariance matrix. This means that the value of CV (K = 10) achieved the minimum bias for the CV method. • The CV method and the hold-out method produced\nconservative estimates. The pessimistic bias in the CV method came from the difference between ẑ ∈ arg maxz∈Z f(z, θ̂) and z̃ in (6).\nNote that E[f(ẑ, θ∗)] was poorer than E[f(z∗, θ∗)], where the former was the best objective value achieved with the available finite training samples. This negative difference is unavoidable with our bias correction, which appears to raise an interesting open challenge w.r.t. the combination of our bias correction with robust optimization (Bertsimas et al., 2011), i.e., the former mitigates the optimistic bias, and the later mitigates uncertainty in objective functions.\nSensitivity of the Perturbation Method We investigated the sensitivity of the perturbation method w.r.t. h > 0, which is the important trade-off parameter in bias and variance. We applied it to 100 different randomly-initialized datasets, for which we set h = 0.05, 0.10, . . . , 0.50. Because s is not sensitive, we fixed it to s = 10. Figure 3 demonstrates the changes in bias and variance (top figure) and RMSE against f(ẑ, θ∗), over h. As the value\nof h increased, the bias increased though the variance decreased (top figure), as was implied in Proposition 4, and this resulted in significantly larger RMSE values with smaller values of h. This observation indicates that an appropriate balance between bias and variance must be determined, and that a variance-sensitive measure such as RMSE can be used as a guide to determine the trade-off."
  }, {
    "heading": "5.2. Predictive Price Optimization",
    "text": "We applied our algorithms to the predictive price optimization discussed as Example 3 in Section 2. As reported in (Ito & Fujimaki, 2017), the optimal value in this problem contains optimistic bias, which is consistent with Proposition 1. Unlike in the portfolio optimization, the parameter θ̂ is estimated by regression techniques, and the set of feasible strategies Z is discrete.\nSimulation Experiment In this experiment, we investigated the effect of the optimistic bias and our bias correction over parameter dimensionality, i.e., the number of products d. We generated the same simulation data as in (Ito & Fujimaki, 2017). The sales quantity qi of the i-th product was generated from the regression model qi = αi + ∑d j=1 βijpj , where αi and βij were generated by uniform distributions, where αi ∈ [d, 3d], βij ∈ [0, 2] for i 6= j, and βii ∈ [−2d,−d]. The feasible region Z was defined by Z = {0.6, 0.7, . . . , 1.0}d. We chose N = 500 for our experiments.\nFigure 4 shows the change in the objective values normalized by the ideal objective value f(z∗, θ∗) over the number\nof products d. For Algorithm 1 (CV method), we chose K = 2 so that the hold-out samples would be sufficient to estimate parameters {αi} and {βij}. We observed that:\n• f(ẑ, θ∗) degraded against f(z∗, θ∗) with increasing d because the estimation error in machine learning increased. • The optimistic bias, f(ẑ, θ̂)− f(ẑ, θ∗), rapidly increased because f(ẑ, θ̂)− f(z∗, θ∗) also increased in addition to the increase in f(z∗, θ∗)− f(ẑ, θ∗). • The CV method suffered from pessimistic bias, which increased as d increased. • The perturbation method corrected the bias accurately even if the parameter dimensionality, i.e., d, increased.\nThese results confirm the robustness of our proposed method over parameter dimensionality and also its general applicability to a wide range of problems (the portfolio optimization in Section 5.1 is continuous and convex while the price optimization in this section is discrete and non-convex).\nReal-World Retail Dataset The real-world retail dataset used in (Ito & Fujimaki, 2017; 2016) contains sales information for a middle-size supermarket located in Tokyo.4 Using this information, we selected 50 regularly-sold beer products. The data range was approximately the three years from 2012/01 to 2014/11. We used the first 35 months (1063 samples) for training regression models and simulated the best price strategy for the next day 2014/12/1. We estimated parameters in regression models, using the least squares method. The other settings were same as in (Ito & Fujimaki, 2016).\nThe actual (non-optimized) gross profit in the past data was 106, 348 JPY, while the estimated optimal value f(ẑ, θ̂) was 490, 502 JPY, which represents an approximately 361% increase in gross profit, but this value was obviously unreal-\n4 The data were provided by KSP-SP Co., LTD, http:// www.ksp-sp.com.\nistically huge and unreliable (price changes alone could not increase a profit 4.6 by times!). The bias-corrected optimal gross profit with the perturbation method at h = 0.1 and s = 100 was 124, 477 JPY, which represents an approximately 17% increase in the gross profit. Although we were unable to confirm the validity of this value since this experiment was conducted on past historical data, intuitively speaking, a 17% increase in gross profit seems much more realistic than one of 361%, and considering the facts noted in the simulation studies, our result would surely seem more convincing to domain users. One of important remaining issues in real applications is the estimation of the confidence region. As noted above, we can never learn the value of f(ẑ, θ∗) without performing ẑ, but the user has to make a decision as to whether to perform it or not without knowing the value. In such a case, it would be helpful to provide a confidence region w.r.t. the bias-corrected optimal value, which is available with neither the CV method nor the perturbation method."
  }, {
    "heading": "6. Conclusion",
    "text": "In this paper, we have focused on the framework of a combination of mathematical optimization and machine learning with which we solve an optimization problem whose objective is formulated with the aid of predictive models or estimators. We have demonstrated that such a framework suffers from a kind of bias w.r.t. optimal values because of overfitting of the solution to the constructed objective function. We have proposed a solution to this bias problem by means of developed methods that are guaranteed to compute an asymptotically unbiased estimator of the value of the true objective function. Empirical results have demonstrated that the proposed approach results in successful estimates of the value of the true objective function.\nA major open question remaining in this work is how to evaluate and reduce variance in the estimators of objective functions. The variance in estimators, i.e., uncertainty in estimation, is essential information for decision makers in many situations, and reducing variance in the estimator would help them make better decisions."
  }],
  "year": 2018,
  "references": [{
    "title": "Algorithms for portfolio management based on the Newton method",
    "authors": ["A. Agarwal", "E. Hazan", "S. Kale", "R.E. Schapire"],
    "venue": "Proceedings of the 23rd international conference on Machine learning - ICML",
    "year": 2006
  }, {
    "title": "Information theory and an extension of the maximum likelihood principle",
    "authors": ["H. Akaike"],
    "venue": "In International Symposium on Information Theory, pp",
    "year": 1973
  }, {
    "title": "Pseudo-Mathematics and Financial Charlatanism: The Effects of Backtest Overfitting on Out-of-Sample Performance",
    "authors": ["D.H. Bailey", "J.M. Borwein", "M. López de Prado", "Q.J. Zhu"],
    "venue": "Notices of the AMS,",
    "year": 2014
  }, {
    "title": "Optimization methods applied to renewable and sustainable energy: A review",
    "authors": ["R. Baos", "F. Manzano-Agugliaro", "F. Montoya", "C. Gil", "A. Alcayde", "J. Gmez"],
    "venue": "Renewable and Sustainable Energy Reviews,",
    "year": 2011
  }, {
    "title": "A robust optimization approach to supply chain management",
    "authors": ["D. Bertsimas", "A. Thiele"],
    "venue": "Integer programming and combinatorial optimization,",
    "year": 2004
  }, {
    "title": "On portfolio optimization: Forecasting covariances and choosing the risk model",
    "authors": ["L.K.C. Chan", "J. Karceski", "J. Lakonishok"],
    "venue": "Review of Financial Studies,",
    "year": 1999
  }, {
    "title": "Portfolio choice problems: An introductory survey of single and multiperiod models",
    "authors": ["N. Chapados"],
    "venue": "Springer Science & Business Media,",
    "year": 2011
  }, {
    "title": "Economic-Engineering Optimization for California Water Management",
    "authors": ["A.J. Draper", "M.W. Jenkins", "K.W. Kirby", "J.R. Lund", "R.E. Howitt"],
    "venue": "Journal of water resources planning and management,",
    "year": 2003
  }, {
    "title": "..and the Cross-Section of Expected Returns",
    "authors": ["C.R. Harvey", "Y. Liu", "H. Zhu"],
    "venue": "Review of Financial Studies,",
    "year": 2016
  }, {
    "title": "Large-scale price optimization via network flow",
    "authors": ["S. Ito", "R. Fujimaki"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Optimization beyond prediction: Prescriptive price optimization",
    "authors": ["S. Ito", "R. Fujimaki"],
    "venue": "In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2017
  }, {
    "title": "Analytics for an Online Retailer : Demand Forecasting and Price Optimization",
    "authors": ["K. Johnson", "B. Hong", "A. Lee", "D. Simchi-levi"],
    "venue": "Manufacturing & Service Operations Management,",
    "year": 2016
  }, {
    "title": "A simulation based optimization approach to supply chain management under demand uncertainty",
    "authors": ["J.Y. Jung", "G. Blau", "J.F. Pekny", "G.V. Reklaitis", "D. Eversdyk"],
    "venue": "Computers and Chemical Engineering,",
    "year": 2004
  }, {
    "title": "Reinforcement learning: A survey",
    "authors": ["L.P. Kaelbling", "M.L. Littman", "A.W. Moore"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 1996
  }, {
    "title": "Mean-absolute deviation portfolio optimization model and its applications to tokyo stock market",
    "authors": ["H. Konno", "H. Yamazaki"],
    "venue": "Management science,",
    "year": 1991
  }, {
    "title": "Batch reinforcement learning",
    "authors": ["S. Lange", "T. Gabel", "M. Riedmiller"],
    "venue": "In Reinforcement learning,",
    "year": 2012
  }, {
    "title": "On-Line Portfolio Selection with Moving Average Reversion",
    "authors": ["B. Li", "S.C.H. Hoi"],
    "venue": "Proceedings of the 29th International Conference on Machine Learning",
    "year": 2012
  }, {
    "title": "Monte Carlo bounding techniques for determining solution quality in stochastic programs",
    "authors": ["W.K. Mak", "D.P. Morton", "R.K. Wood"],
    "venue": "Operations Research Letters,",
    "year": 1999
  }, {
    "title": "Portfolio Selection",
    "authors": ["H. Markowitz"],
    "venue": "The Journal of Finance,",
    "year": 1952
  }, {
    "title": "Efficient asset management: a practical guide to stock portfolio management and asset allocation. Financial Management Association, Survey and Synthesis Series",
    "authors": ["R. Michaud"],
    "year": 1998
  }, {
    "title": "The markowitz optimization enigma: Is optimized optimal",
    "authors": ["R.O. Michaud"],
    "venue": "ICFA Continuing Education Series,",
    "year": 1989
  }, {
    "title": "Robust portfolio optimization",
    "authors": ["H. Qiu", "F. Han", "H. Liu", "B. Caffo"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Portfolio resampling: Review and critique",
    "authors": ["B. Scherer"],
    "venue": "Financial Analysts Journal, pp",
    "year": 2002
  }, {
    "title": "The optimizers curse: Skepticism and postdecision surprise in decision analysis",
    "authors": ["J.E. Smith", "R.L. Winkler"],
    "venue": "Management Science,",
    "year": 2006
  }, {
    "title": "Draft-2] Reinforcement learning : an introduction",
    "authors": ["R.S. Sutton", "A.G. Barto"],
    "venue": "Neural Networks IEEE Transactions on,",
    "year": 2013
  }, {
    "title": "Coordinated supply chain management",
    "authors": ["D.J. Thomas", "P.M. Griffin"],
    "venue": "European Journal of Operational Research,",
    "year": 1996
  }, {
    "title": "The nature of statistical learning theory",
    "authors": ["V. Vapnik"],
    "venue": "Springer science & business media,",
    "year": 2013
  }, {
    "title": "Robust quadratic programming for price optimization",
    "authors": ["A. Yabe", "S. Ito", "R. Fujimaki"],
    "venue": "In IJCAI ProceedingsInternational Joint Conference on Artificial Intelligence,",
    "year": 2017
  }],
  "id": "SP:409f5b8f5176c7dc9c2ffbea4fc4c0c9c37331c7",
  "authors": [{
    "name": "Shinji Ito",
    "affiliations": []
  }, {
    "name": "Akihiro Yabe",
    "affiliations": []
  }, {
    "name": "Ryohei Fujimaki",
    "affiliations": []
  }],
  "abstractText": "For data-driven decision-making, one promising approach, called predictive optimization, is to solve maximization problems i n which the objective function to be maximized is estimated from data. Predictive optimization, however, suffers from the problem of a calculated optimal solution’s being evaluated too optimistically, i.e., the value of the objective function is overestimated. This paper investigates such optimistic bias and presents two methods for correcting it. The first, which is analogous to cross-validation, successfully corrects the optimistic bias but results in underestimation of the true value. Our second method employs resampling techniques to avoid both overestimation and underestimation. We show that the second method, referred to as the parameter perturbation method, achieves asymptotically unbiased estimation. Empirical results for both artificial and real-world datasets demonstrate that our proposed approach successfully corrects the optimistic bias.",
  "title": "Unbiased Objective Estimation in Predictive Optimization"
}