{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Crowdsourcing has drawn increasing popularity in the field of machine learning by annotating millions of items in a short time with relatively low cost (Howe, 2006; Welinder & Perona; Deng et al., 2013; Jiang et al., 2015). This provides a great opportunity to build up large-scale training sets for complex models, such as deep neural networks (Krizhevsky et al., 2012), and to reach consensus among non-experts, such as peer grading in today’s popular massive open online course (MOOC) systems. However, the quality of the collected results is often unreliable and diverse, and there are spammers who give random labels to make easy money, or even adversaries who deliberately give wrong answers. To address this issue, most crowd-\n1The Chinese University of Hong Kong, Hong Kong, China. 2Shenzhen University, China. 3Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China. Correspondence to: Shengyu Zhang <syzhang@cse.cuhk.edu.hk>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nsourcing systems resort to distributing each item to a number of redundant workers. This raises a challenging question of how to aggregate such noisy and redundant labels.\nAn intuitive and baseline approach for crowdsourcing is to identify each item following the majority voting (MV) result of workers. Unfortunately, this approach is errorprone since it treats each worker equally, and the accuracy severely deteriorates with the fraction of less qualified workers, spammers or adversaries. Weighted majority voting (WMV) (Karger et al., 2011) method tries to address this issue by associating each worker with a weight to characterize his expertise. Specially, max-margin majority voting (M3V) method (Tian & Zhu, 2015) optimizes the associated variables in WMV by maximizing the minimal difference between the aggregated score of the potential true label and the aggregated scores of others.\nIn a different approach, Dawid-Skene (DS) model (Dawid & Skene, 1979) represents each worker’s expertise by a confusion matrix and uses a latent variable model to generate collected labels, which implicitly assumes a worker to perform equally well across all items in a common class. This model can be iteratively inferred by the famous Expectation-Maximization (EM) method (Dempster et al., 1977), and works well in practice. In particular, (Zhang et al., 2016) employs the spectral method (Anandkumar et al., 2012) to initialize the DS model, and obtains an optimal convergence rate up to a logarithmic factor by EM method. Recently, (Zhou et al., 2012; Tian & Zhu, 2015) proposed to improve the aggregating performance by integrating the merits of MV method with DS model. The performance of DS model and its variants often relies on the specially conceived priors with some manually configured hyperparameters.\nAll the above mentioned approaches are for aggregating general multiclass labels. In many practical applications, however, the labels have a natural ordinal structure. For instance, in MOOCs, students are often required to grade their own assignments on an ordinal scale of 5 (excellent), 4 (good), 3 (fair), 2 (pass) and 1 (failure). In medical imaging, doctors are often required to mark images on an ordinal scale of stage 1, stage 2, stage 3, and stage 4. Ordinal label faces an issue of diverse standards. For example, given four assignments whose true grades are 5, 4, 3 and 2, a\nstrict marker may rate them as 4, 3, 2 and 1. If we ignore the ordinal structure, we may identify this marker as an adversary because all his answer labels are considered wrong. But actually this marker grades all assignments in a correct order, which should be incorporated to improve the crowdsourcing performance.\nThis inspires us to transform the K-class ordinal labeling to K − 1 binary classifications. That is, instead of directly using a label answer k ∈ [K] = {1, 2, . . . ,K}, we use it to answer K − 1 questions “Is the label greater than i” for all i ∈ [K − 1]. In this way, the harsh marker’s answer 4 for the first assignment would give three correct answers (on thresholds i = 1, 2, 3) and only one wrong answer (on threshold i = 4), making the marker’s answers highly useful in the aggregation.\nFor each binary problem, we can employ a Gibbs sampler to generate label estimations from the generative model of crowdsourcing. However, these label estimations could be error-prone especially for the difficult items, whose labels may be sampled according to the uniform distribution, and it is well known that the performance of a generative model heavily relies on the specially conceived priors. To address these issues in binary crowdsourcing tasks, we define a separating width to characterize the quality of label estimations, and solve it by optimizing a linear decision boundary. The similar idea has been previously explored in (Cortes & Vapnik, 1995) and found a lot of success for supervising learning problems. By optimizing the separating width among two classes, we can improve the sampling accuracy and update the prior distributions automatically during the learning process. To characterize the quality of aggregating ordinal labels from K classes, we introduce K − 1 decision boundaries to help optimize the separating width. As demonstrated empirically, our method achieves the best performance on the real-world datasets compared to other state-of-the-art methods.\nThe rest of this paper is organized as follows. Sec. 2 introduces some preliminary works for crowdsourcing tasks. Sec. 3 presents the generative model employed in this paper. Sec. 4.1 derives the objective function for binary aggregating problem, which is extended for the ordinal case in Sec. 4.2. The derivations of inference method are discussed in Sec. 5. Sec. 6 evaluates the performance of our method on some real-world datasets, and Sec. 7 concludes this paper."
  }, {
    "heading": "2. Problem Setting and Preliminary Work",
    "text": "In this section, we formalize the problem and survey some preliminary methods. Suppose that there are M workers and N items taken from a total of K classes. For item i, define an M ×K matrix Ri by putting Rijk = 1 if worker\nj labels the item as k, and Rijk = 0 otherwise. Note that Ri is a highly sparse matrix since each item is usually assigned to a small number of workers. The objective of a crowdsourcing problem is to identify the true label zi of item i based on the sparse matrices {R1, . . . , RN}."
  }, {
    "heading": "2.1. Majority Voting Method and its Variants",
    "text": "Majority Voting (MV) has been widely used to find the most likely label for item i by solving the following problem,\nzi = argk max1 T MR iek, (1)\nwhere 1M is a all-one column vector of dimension M and ek is the k-th standard basis. Weighted majority voting (WMV) (Karger et al., 2011) generalizes MV by assigning weight vector η ∈ RM×1 to the workers and solving the following problem\nzi = argk max η TRiek. (2)\nSpecially, max-margin majority voting (M3V) (Tian & Zhu, 2015) defines the crowdsourcing margin as the minimal difference between the aggregated score of the potential true label and aggregated scores of other labels, and solves η by maximizing the sum of the crowdsourcing margins of all items."
  }, {
    "heading": "2.2. Dawid-Skene Model and its Variants",
    "text": "Dawid-Skene (DS) model has been another popular way to aggregate collected labels by capturing the uncertainties of labeling behaviors in a generative model. Compared with WMV and M3V, both of which characterize the expertise of worker j by a scaler variable, DS model characterizes the expertise of worker j with an individual confusion matrix Aj ∈ RK×K , where the (k, d)-th entry denotes the probability that worker j labels a class k sample as class d. Denote A = {Aj}Mj=1. DS model aims to maximize the likelihood of observed samplesR = {Ri}Ni=1 as follows,\nmax A L = N∑ i=1 ln ∫ p(Ri|zi,A)p(zi)dzi, (3)\nwhere p(Ri|zi,A) = ∏M j=1 ∏K d=1(A j zid )R i jd and zi is a latent variable with p(zi) = 1K ,∀i ∈ [N ]. This likelihood function can be optimized iteratively by EM method (Dempster et al., 1977) as,\nE-step: q(zi = k) ∝ exp M∑ j=1 K∑ d=1 Rijd lnA j kd,\nM-step: Ajkd ∝ N∑ i=1 q(zi = k)R i jd.\n(4)\nThus, the collected labels are aggregated following the rule zi = argk max exp ∑M j=1 ∑K d=1R i jd lnA j kd, where the unknown parameters A can be updated in M-step through maximum likelihood estimation (MLE) principle. Recently, spectral methods have been applied to obtain a better initialization of the DS model (Zhang et al., 2016), which achieves an optimal convergence rate up to a logarithmic factor. By assuming some special structures of the confusion matrices A, (Raykar et al., 2010) studies homogeneous DS model, and (Moreno et al., 2015) studies the existence of clusters of workers."
  }, {
    "heading": "2.3. Recent Achievements",
    "text": "Some recent improvements have been achieved by combining MV related methods and DS related methods. (Zhou et al., 2012) assumes labels are generated according to a distribution over workers, items and labels, which can be inferred by minimizing its entropy with constraints developed from MV method and DS model. (Tian & Zhu, 2015) incorporates M3V method with DS model in a regularized Bayesian framework (Zhu et al., 2014), and approximates the posterior distribution over the true labels with a Gibbs sampler. Nowadays, binary and general multi-class crowdsourcing problems have been widely studied in the literature, but the ordinal sibling has not received nearly as much attention yet. The work (Zhou et al., 2014) tries to use the ordinal structure and makes an assumption that workers have difficulty distinguishing between two adjacent ordinal classes whereas it is much easier to distinguish between two far-away classes. In this paper, we will develop a novel objective function to aggregate the ordinal labels, and achieve the best performance on the real-world datasets."
  }, {
    "heading": "3. Generative Model of Crowdsourcing",
    "text": "In this section, we present a fully Bayesian model to generate observed matrices R. First we note that some items may be intrinsically hard to label even for experts (which is not uncommon in, for example, medical imaging). To model such difficulty, we introduce a K-dimensional vector ωi to denote the prior distribution of true label of the item i even for experts. (For items clearly from category k, the vector ωi would be just the standard basis ek.) Denote ω = {ωi}Ni=1. We can obtain a joint distribution as follows.\np(R,z|A,ω) = ∏ i,j,d,k (Ajkd) RijdI(zi=k)ωik I(zi=k) , (5)\nwhereA contains the confusion matrices of all workers like DS model, z is the label vector to be solved and I(·) is an indicator function. Since usually most workers just annotate a few items, we may not have sufficient samples to infer z, A and ω. To overcome this, we formulate a fully\nBayesian framework overA and ω with prior from Dirichlet distributions (Minka, 2000), a family that has found numerous successful applications (such as topic models) to generate prior distributions. We assume that both workers’ expertise A and items’ difficulty ω are random variables from the family of Dirichlet distributions\nD(x|α) = Γ(Kα) ΓK(α) K∏ t=1 xα−1t , (6)\nwhere Γ(·) is the gamma function. As illustrated in Figure 1, the concentration parameter α controls the sparsity preference of random vector. A precisely described item i should have ωi be associated with a small concentration parameter, resulting in a sparse prior vector, while a vaguely described item should be associated with a large concentration parameter. To model the expertise Aj of the worker j, we also prefer that it has a small concentration parameter. We formulate the prior distributions over A and ω as follows.\np(A|α) = ∏ j,k D(Ajk:|αj), p(ω|β) = ∏ i D(ωi|βi), (7)\nwhereα = {αj}Mj=1 and β = {βi}Ni=1. Combining Eq. (5) and (7) gives the following joint distribution,\np(R,A, z,ω|α,β) = p(R,z|A,ω)p(ω|β)p(A|α).\nThe graphical model can be found in Fig. 2.\nGiven the matricesR, we can get the posterior distribution overA,z and ω, which can be formulated as\np(A, z,ω|R,α,β) = p(R,A, z,ω|α,β)∫ p(R,A, z,ω|α,β)dAzω .\n(8) We can obtain a classifier as argz max p(z|R,α,β) = argz max ∫ p(A, z,ω|R,α,β)dAω to label the item,\nparametrized by the hyperparameters α and β. Conventionally, researchers mainly focus on how to approximate the posterior distribution with better accuracy and runningtime performance with the fixed prior distributions, or updating the prior distributions by introducing new priors over α and β (Kim & Ghahramani, 2012; Moreno et al., 2015). However, the performance of the above generative model heavily relies on the specially conceived priors to incorporate domain knowledge, which transmits affects on the posterior estimations through Bayes’ rules. Given a family of prior choices, we prefer the classifier with the more powerful discriminative capability to achieve better generalization performance."
  }, {
    "heading": "4. Maximizing the Separating Distance",
    "text": ""
  }, {
    "heading": "4.1. Binary Crowdsourcing Problem",
    "text": "Before we present the objective function to aggregate ordinal labels, we firstly consider a simple case, the binary crowdsourcing problem with K = 2. As shown in Eq. (8), by varying the hyperparameters α and β, we can obtain a series of posterior approximations to identify unlabeled items via Bayes rule. Moreover, by fixing the hyperparameters α and β, we can get multiple estimations of the true label of one item, which are randomly sampled from the posterior distribution over its true label. Thus, we are motivated to find the most favored set of label estimations over all items.\nFor a better generalization performance, we try to maximize the separation width between two classes. As shown in Fig. 3, the label set 2 is preferred to the set 1, because the set 2 has a larger separation width between two classes. To evaluate the separating width of samples with the label set z = {zi}Ni=1, with zi ∈ {−1, 1},∀i ∈ [N ], we introduce a linear decision boundary f(Ri) = aTRib with a ∈ RM×1 and b ∈ RK×1. Our decision boundary is formulated refer to the formulas in Eq. (1) and (2), where a denote the worker expertise and b transforms worker’s label into a scale variable. Thus, we define an optimization problem as,\nmin a,b\nL(a, b) = ‖a‖22‖b‖22, (9)\ns.t. zia TRib ≥ 1, ∀i ∈ [N ],\nwhere ‖x‖22 = xTx and the minimal value L(a∗, b∗) characterizes the separating width of the label set z. This optimization problem can be understood from the objective function used in support vector machine (SVM) (Cortes & Vapnik, 1995), where the objective function is to maximize the margin width (‖baT ‖F )−1 = (‖a‖22‖b‖22)−1 and the constrains state that all samples lie on the correct side of the margin. (The constraint in the above optimization problem can be viewed as the inner product of Ri and a rank-\n1 matrix baT . One may wonder why confining to rank-1 measurements. Note that MV (Eq.(1)) and WMV (Eq.(2)) are also of the rank-1 form, and our experiments also show that using higher rank measurements actually makes the generalization performance worse; see experiments in Appendix.) Since z is a random variable generated from the posterior distribution (8), we need to reformulate the objective function (9) as follows,\nmin a,b,α,β\nL(a, b,α,β) = ‖a‖22‖b‖22, (10)\ns.t. Ep(zi|Ri,α,β)zia TRib ≥ 1, ∀i ∈ [N ],\np(A, z,ω|R,α,β) ∝ p(R,A, z,ω|α,β).\nPractically, the labeled samples are often linearly inseparable by a single hyperplane; see Set 3 in Fig. 3. To cope with this issue, we relax the hard constrains by introducing non-negative slack variables ξi, one for each sample, and obtain a “soft” model as follows.\nmin a,b,α,β,ξ L(a, b,α,β) = ‖a‖22‖b‖22 + λ2 λ1 N∑ i=1 ξi, (11)\ns.t. Ep(zi|Ri,α,β)zia TRib ≥ 1− ξi, ∀i ∈ [N ],\np(A, z,ω|R,α,β) ∝ p(R,A, z,ω|α,β),\nwhere λ2λ1 is used as a positive regularization parameter for later convenience, and 1 − ξi is the soft-margin for item i. If Ri lies on the correct side of the margin, ξi = 0. For sample on the wrong side, ξi is proportional to the distance to the margin. Thus, the value of ξi reflects the difficulty of identifying item i, or the error allowed to misclassify the item i. The calculation of p(A, z,ω|R,α,β) is intractable because it involves that of the marginal distribution p(R|α,β). To address this issue, we introduce a redundant distribution q(A, z,ω) and rewrite the optimization problem as follows.\nmin a,b,α,β,q,ξ L(a, b, α, β, ξ) = ‖a‖22‖b‖22 + λ2 λ1 N∑ i=1 ξi,\n(12)\ns.t. Eq(zi)zia TRib ≥ 1− ξi, ∀i ∈ [N ],\nKL(q‖p) = 0.\nwhere q and p are shorthand for q(A, z,ω) and p(A,z,ω|R,α,β), respectively, to simplify the presentations in the rest of the paper. Let ζi = 1−ziaTRib, we can turn the optimization problem into the following one with two regularization terms: mina,b,α,β,q,ξ L(a, b,α,β, q), where L is defined by\nL(a, b,α,β, q) = KL(q‖p) + λ1‖a‖22‖b‖22\n+ 2λ2 N∑ i=1 ∑ zi∈{−1,1} q(zi)(ζi)+, (13)\nwhere (ζi)+ = max{0, ζi} is the hinge loss function widely used in training classifiers . The factor 2λ2 is introduced here to simplify the derivations of inference methods later. By optimizing the unknown parameters in the objective function in Eq.(13), we can obtain the estimated labels with the largest separating width."
  }, {
    "heading": "4.2. Ordinal Crowdsourcing Problem",
    "text": "As introduced in Section 1, transforming a K-class ordinal labeling problem (“what is the label of this item?”) to (K−1) binary classification problems (“Is the label of this item greater than k?” for k ∈ [K − 1]) allows us to exploit more useful information from workers. The transform is illustrated in Set 4 of Fig. 3, where we have items coming fromK ordered classes, C1, . . . , CK . We look forK−1 decision boundaries, with boundary t discriminating classes C1 ∪ · · · ∪ Ct and classes Ct+1 ∪ · · · ∪ CK . For the t-th binary question, we introduce a linear decision boundary as ft(Ri) = aTt R\nibt. It is easily verified that all boundaries intersecting at the zero point. With a = {at}K−1t=1 and b = {bt}K−1t=1 , the loss function in Eq. (13) becomes\nL(a, b,α,β, q) =KL(q‖p) + λ1 K−1∑ t=1 ‖at‖22‖bt‖22\n+ 2λ2 N∑ i=1 K∑ zi=1 q(zi) K−1∑ t=1 (ζit)+, (14)\nwhere ζit = 1 − sgnt(zi)aTt Ribt with sgnt(zi) = −1 if zi ≤ t and sgnt(zi) = 1 if zi > t. It is obvious that our ordinal model will degenerate into binary one when K = 2. WhenK ≥ 3, the ordinal label should be estimated by considering the predicted results from K − 1 binary problems."
  }, {
    "heading": "5. Inference Details",
    "text": "In this section, we present the implementation details to infer the true labels and all other unknown parameters involved in ordinal crowdsourcing problems. Our inference method consists of two parts. In the first part, we employ\na Gibbs sampler to approximately sample from the posterior distribution p = p(A,z,ω|R,α,β). In the second part, we update the hyperparameters (α,β) and linear decision boundaries based on the gradient method to achieve the largest separating width.\nTo approximate the intractable posterior distribution p, there are two standard approaches, which are Variational Bayesian (VB) and Gibbs sampling. Compared with the Gibbs sampling method, VB is usually difficult in its functional optimization, especially hard in our case due to the hinge loss function. Moreover, VB often suffers from inaccuracy because of the potentially impractical assumption of independence of variables. Gibbs sampling is applicable here, because it provides numerical approximations to the integration problems in large dimensional spaces by generating an instance from the conditional distribution of each variable in turn. It can be shown that the sequence of samples constitutes a Markov chain, which finally converges to the targeted posterior distribution as the stationary distribution.\nSince the sampling process of the confusion matrices A and the items’ difficulties ω can be developed in the standard way, we leave their derivations in Appendix and mainly discuss the sampling process of true labels z here. The difficulty of sampling z is mainly due to the hinge loss function (ζit)+. We employ data augmented technique (Polson & Scott, 2011) to approximate the hinge loss function. According to the equality (Andrews & Mallows, 1974),\nexp(−2λ2(ζit)+) = ∫ φ(zi, γit|Ri)dγit, (15)\nwith φ(zi, γit|Ri) = (2πγit)− 1 2 exp( −12γit (γit + λ2ζit) 2) and γit as a non-negative augmented variable, we can reformulate the objective function in Eq.(14) as follows.\nL(a, b,α,β, q) ≤ KL(q‖p) + λ1 ∑ t aTt atb T t bt (16)\n+ ∑ i,zi,t ∫ q(zi)q(γit) ln\nq(γit)\nφ(zi, γit|Ri) dγit,\nwhere the inequality comes from Jensen’s inequality with a new distribution q(γit) to help to approximate the hinge loss function exp(−2λ2(ζit)+). Note that the right hand side of the inequality is tractable, minimizing which would give an upper bound of the original optimization problem. Before we sample the true labels of items, we need to first generate augmented variables γ = {γit}N,K−1i=1,t=1. When fixing other random variables, we can generate the (i, t)-th augmented parameter according to the following generalized inverse Gaussian (GIG) distribution,\nγit ∼ 1 Z γ − 12 it exp[− 1 2 (γit +\nλ22ζ 2 it\nγit )], (17)\nwhere Z is the normalization term. It has been shown that 1 γit\ncan be drawn efficiently with O(1) time complexity (Michael et al., 1976).\nHere, we can sample the true labels of all items. Let φ(z, γ|R) = ∏N i=1 ∏K−1 t=1 φ(zi, γit|Ri). Rewrite the objective function shown in Eq. (16) with respect to q(zi) as follows,\nL(q(zi)) ≤ KL(q‖p) + ∑ i,zi,t ∫ q(zi)q(γit) ln\nq(γit)\nφ(zi, γit|Ri) dγit\n= KL(q · q(γ)‖p · φ(z, γ)). (18)\nThus, with all other parameters fixed, we can sample zi ∈ [K] according to the following distribution,\nq(zi) ∝ p(Ri,A, zi, ωi|α,β) K−1∏ t=1 φ(zi, γit|Rit). (19)\nLet us examine the two terms on the right hand side. The first term comes from the generative model of crowdsourcing, while the second term maximizes the separating width of the estimated ordinal labels. For the binary crowdsourcing problem, we have only one decision boundary to measure the separating width, while for the ordinal crowdsourcing problem with K classes, we get K − 1 intersected decision boundaries to measure the separating width. After obtaining a set of random samples to approximate the joint posterior distribution q over all model parameters and augmented variables, the objective function shown in Eq. (14) becomes a parametric function with respect to a, b,α and β. Thus, we can intuitively update these parameters based on the gradient method. The derivations of the updating formulas over a, b,α and β can be found in Appendix.\nLet 〈f(x)〉 = ∫ q(x)f(x)dx denote the expectation of f(x) with respect to the distribution of q(x). Our method is outlined in Algorithm 1, in which each while iteration consists of two for loops, and the source code with demo can be found on the website1. In the first for loop, we employ\n1http://appsrv.cse.cuhk.edu.hk/˜gychen/\nAlgorithm 1 Our Ordinal Crowdsourcing Method 1: Input: R = {Ri}Ni=1, λ1, λ2 and the learning rates η. 2: Initializing z = {zi}Ni=1 by MV, a, b, α and β 3: while not convergence do 4: for i = 1 : N do 5: Ajkd ∼ D(A j kd|αj + ∑N i=1R i jdI(zi = k))\n6: ωik ∼ D(ωik|βi + I(zi = k)) 7: γit ∼ 1Z γ − 12 it exp[− 12 (γit + λ22ζ 2 it γit )]\n8: zi ∼ p(Ri,A, zi, ωi|α,β) ∏K−1 t=1 φ(zi, γit|Rit)\n9: end for 10: for t = 1 : K − 1 do 11: Σat = 2λ1‖bt‖22I + ∑N i=1 λ22 〈γit〉R ibtb T t R iT\n12: at = Σ−1at ( ∑N i=1(λ2 + λ22 〈γit〉 )〈sgnt(zi)〉R ibt)\n13: Σbt = 2λ1‖at‖22I + ∑N i=1 λ22 〈γit〉a T t R iRi T at 14: bt = Σ −1 bt ( ∑N i=1(λ2 + λ22 〈γit〉 )〈sgnt(zi)〉a T t R i) 15: end for 16: αj ← αj − η ∂L(αj)∂αj ,∀j ∈ [M ] 17: βi ← βi − η ∂L(βi)∂βi ,∀i ∈ [N ] 18: end while\na Gibbs sampler to generate the random variables to approximate the posterior distribution. In the second part, we solve the separating width by optimizing K − 1 decision boundaries, and update the prior distributions by gradient method. Compared with the traditional generative model of crowdsourcing, including DS model and its variants, our method introduces an augment variable γit to approximate the hinge loss function, which is further involved in the generation of true labels. This algorithm is iteratively implemented to reach a local optimum."
  }, {
    "heading": "6. Experiments and Discussions",
    "text": "To fully evaluate the ideas employed in this paper, we present empirical studies of our aggregating method in comparison with competitive ones not only on ordinal crowdsourcing tasks, but also binary crowdsourcing tasks. For our method, we configure λ1 = λ2 = 1, α = 1M ,β = 1N , η = 1 × 10−5 and initialize zi by the majority voting result. In each run of our method, we generate 80 samples to approximate the posterior distribution and discard the first 10 samples as burn-in steps. The reported error rate of our method is averaged over 10 runs, and all experiments are conducted in a PC with Intel Core i7 1.8GHz CPU and 8.00GB RAM."
  }, {
    "heading": "6.1. Binary Crowdsourcing Tasks",
    "text": "We first evaluate our method on three binary benchmark datasets shown in Table 1, include labeling bird species\n(Welinder et al., 2010) (Bird dataset), recognizing textual entailment (Snow et al., 2008) (RTE dataset) and accessing the relevance of topic-document pairs with a binary judgment in TREC 2011 crowdsourcing track (Gabriella & Matthew, 2011) (TREC dataset). The competitive methods include the pure majority voting estimator (refereed to as MV), the EM method for DS model initialized by majority voting (refereed to as MV-DS), the EM method for DS model initialized by spectral method (refereed to as Opt-DS) (Zhang et al., 2016), the Gibbs sampler for the Bayesian extension of M3V (Tian & Zhu, 2015) (referred to as G-CrowdSVM), the SVD-based algorithm proposed in (Ghosh et al., 2011) (referred to as Gh-SVD), and the Eigenvalues of Ratio algorithm proposed in (Dalvi et al., 2013) (referred to as Eig-Ratio). The performance of all methods are evaluated by error as l0 = 1 − 1|z|‖z − ẑ‖0, where z contains true labels of items (available in all these datasets) and ẑ contains estimations given by our algorithm (not using any information of z). Noted that the reported error rates of G-CrowdSVM are the average over 10 random runs as our method.\nAs shown in Table 2, our method achieves the best performance among all methods on three benchmark datasets. Without regards to the prior knowledges over workers’ expertise and items’ difficulties, we can degenerate our model into MV-DS model by setting λ2 = λ1 = 0. Comparing with the performance of MV-DS model, especially Opt-DS method, we present a more complicated generative model, leading to better predictive results. Compared with G-CrowdSVM method, our method updates prior distributions and improves the sampling accuracy by optimizing the separating width during the learning process, which leads to the improvements of predictive performance on all datasets."
  }, {
    "heading": "6.2. Ordinal Crowdsourcing Tasks",
    "text": "In this part, we report empirical results of our method on ordinal benchmark datasets in comparison with competitive ones. We consider MV, MV-DS, and G-CrowdSVM as baselines, and compare our method with Entropy(O) (Zhou et al., 2014), which consider the ordinal structures in labels. As shown in Table 1, we have two ordinal datasets. One is to judge the relevance of query-URL pairs with a 5-level rating score (Web dataset), and the other is to identify the age of each subject with a 7-level rating score (Age dataset). To evaluate the performance of aggregating ordinal labels, we define three following error measurements as: l0 = 1 − 1|z|‖z − ẑ‖0, l1 = 1 |z|‖z − ẑ‖1 and l2 = 1 |z|‖z − ẑ‖2. Compared with the error rate l0, the measures l1 and l2 take precision into consideration, and may be preferred for aggregating ordinal labels when one cares about the severity of error.\nTable 3 summarizes the performance of all methods on the ordinal datasets, and shows that our method consistently outperforms the others in predicting the ordinal labels of items. Similar with our method, G-CrowdSVM attempts to maximize the margin between the aggregated score of potential true label and the aggregated score of others, and achieves the better performance in comparison with the state-of-the-art method to aggregate ordinal labels, Entropy(O). Compared with G-CrowdSVM, we treat the problem of aggregating collected labels as the classification problem, and introduce K − 1 decision boundaries to consider the ordinal relationship among categories. As shown in Table 3, on the Web dataset, our method significantly reduces the average l0 error rate from 7.99% to 3.22%. In addition, the average l1 error of our method is 3.69%, which is only slightly larger than the l0 error rate of 3.22%. It means that, even for the incorrect labels ẑi outputted by our algorithm, our ẑi is not far away from its true answer zi, resulting in a relatively small damage.\nThe Web dataset has been widely used in the evaluation of ordinal crowdsourcing problem. On this dataset, our method introduces 4 decision boundaries to measure the separating width of generated true labels. To help to understand the linear decision boundaries learned by our method, we illustrate the average value over 80 samples of {bt}4t=1 as Fig. 4. It can be seen that the absolute value of all entries in bt is approximated to 1. To be more concrete, let us consider the first decision boundary with b1, which calculate Rib1 for the item i. Thus, Rib1 successfully reduces the ordinal problem into a binary one, the j-th entry inRibi would be −1 if worker j ranks item i as 1 and 1 if worker j rank item i as 2, 3, 4 and 5. Note that at characterizes the expertise of all workers for the t-th binary problem. Fig. 5 contains three confusion matrices, including the averaged confusion matrix of all workers, the confusion matrices of\nTable 2. l0 error rate (%) in predicting the latent labels on three binary benchmark datasets.\nBinary Dataset Ours G-CrowdSVM Opt-DS MV-DS MV Gh-SVD Eig-Ratio\nBird 9.25±0.17 10.37±0.41 10.09 11.11 24.07 27.78 27.78 RTE 7.00±0.29 7.72±0.22 7.12 7.12 10.31 49.13 9.00 TREC 29.30±0.11 31.32±0.34 29.80 30.02 34.86 42.99 43.96\nTable 3. Errors in predicting the latent labels on two ordinal benchmark datasets.\nan expert and a spammer. It can be found that the spammer ranks all items randomly to make easy money, while the expert has a confusion matrix similar to the identical matrix. Our method can accurately estimate the confusion matrices of all workers even given the averaged confusion matrix acts like a spammer. Fig. 6 summarizes the training time and error rates after each iteration for all estimators on the Web dataset. It can be found that the proposed method coverages to a lower error rate and all other three methods have error convergence curves all above ours."
  }, {
    "heading": "7. Conclusions",
    "text": "In this paper, we develop a novel method to aggregate ordinal labels by optimizing the separating width among classes. To measure the separating width among ordinal labels, we first investigate a binary case, and then extend our achievements to the ordinal one. With K − 1 decision boundaries, we define an optimization problem for measuring the separating width among ordinal classes. The newly introduced boundaries not only help to optimize the hyperparameters, but also calibrate the estimated labels sampled from the generative model. A Gibbs sampler is adopted to approximate the posterior distribution, while the gradient method is used to calculate the separating width and optimize the hyperparameters.\nAs demonstrated on the ordinal datasets, which is the main focus of this paper, our method consistently achieves the best performance compared with competitive ones, and the improvements on Web dataset are significant. As demonstrated by the experimental results on the binary datasets, our algorithm works slightly better than any previous method. Thus, our algorithm provides a uniform method in both binary and ordinal cases, and can be practically useful for real-world applications."
  }, {
    "heading": "Acknowledgements",
    "text": "We would like to thank anonymous reviewers for their valuable comments to improve the presentation of this paper. This work was supported by the China 973 Program (Project No. 2015CB351706) and a grant from the National Natural Science Foundation of China (Project No. 61233012). Shengyu Zhang was supported by Research Grants Council of the Hong Kong S.A.R. (Project no. CUHK14239416)."
  }],
  "year": 2017,
  "references": [{
    "title": "A spectral algorithm for latent dirichlet allocation",
    "authors": ["A. Anandkumar", "Y.K. Liu", "D.J. Hsu", "D.P. Foster", "S.M. Kakade"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "Scale mixtures of normal distributions",
    "authors": ["D.F. Andrews", "C.L. Mallows"],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp",
    "year": 1974
  }, {
    "title": "Aggregating crowdsourced binary ratings",
    "authors": ["N. Dalvi", "A. Dasgupta", "Kumar", "V. Rastogi"],
    "venue": "In Proceedings of the 22nd international conference on World Wide Web,",
    "year": 2013
  }, {
    "title": "Maximum likelihood estimation of observer error-rates using the em algorithm",
    "authors": ["A.P. Dawid", "A.M. Skene"],
    "venue": "Applied statistics,",
    "year": 1979
  }, {
    "title": "Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society",
    "authors": ["A.P. Dempster", "N.M. Laird", "D.B. Rubin"],
    "venue": "Series B (methodological),",
    "year": 1977
  }, {
    "title": "Fine-grained crowdsourcing for fine-grained recognition",
    "authors": ["J. Deng", "J. Krause", "F.F. Li"],
    "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
    "year": 2013
  }, {
    "title": "Overview of the trec 2011 crowdsourcing track",
    "authors": ["K. Gabriella", "L. Matthew"],
    "venue": "In Proceedings of TREC 2011,",
    "year": 2011
  }, {
    "title": "Who moderates the moderators?: crowdsourcing abuse detection in usergenerated content",
    "authors": ["A. Ghosh", "S. Kale", "P. McAfee"],
    "venue": "In Proceedings of the 12th ACM conference on Electronic commerce,",
    "year": 2011
  }, {
    "title": "The rise of crowdsourcing",
    "authors": ["J. Howe"],
    "venue": "Wired magazine,",
    "year": 2006
  }, {
    "title": "Salicon: Saliency in context",
    "authors": ["M. Jiang", "S. Huang", "J. Duan", "Q. Zhao"],
    "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
    "year": 2015
  }, {
    "title": "Iterative learning for reliable crowdsourcing systems",
    "authors": ["D.R. Karger", "S. Oh", "D. Shah"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 1953
  }, {
    "title": "Bayesian classifier combination",
    "authors": ["H.C. Kim", "Z. Ghahramani"],
    "venue": "In AISTATS, pp",
    "year": 2012
  }, {
    "title": "Imagenet classification with deep convolutional neural networks",
    "authors": ["A. Krizhevsky", "I. Sutskever", "G.E. Hinton"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "Generating random variates using transformations with multiple roots",
    "authors": ["J.R. Michael", "W.R. Schucany", "R.W. Haas"],
    "venue": "The American Statistician,",
    "year": 1976
  }, {
    "title": "Estimating a dirichlet distribution",
    "authors": ["T. Minka"],
    "year": 2000
  }, {
    "title": "Bayesian nonparametric crowdsourcing",
    "authors": ["P.G. Moreno", "A. Artés-Rodrı́guez", "Y.W. Teh", "F. Perez-Cruz"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2015
  }, {
    "title": "Data augmentation for support vector machines",
    "authors": ["N.G. Polson", "S.L. Scott"],
    "venue": "Bayesian Analysis,",
    "year": 2011
  }, {
    "title": "Learning from crowds",
    "authors": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "Max-margin majority voting for learning from crowds",
    "authors": ["T. Tian", "J. Zhu"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Online crowdsourcing: Rating annotators and obtaining cost-effective labels",
    "authors": ["P. Welinder", "P. Perona"],
    "venue": "In 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition-Workshops",
    "year": 2010
  }, {
    "title": "The multidimensional wisdom of crowds",
    "authors": ["P. Welinder", "S. Branson", "P. Perona", "S.J. Belongie"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2010
  }, {
    "title": "Spectral methods meet em: a provably optimal algorithm for crowdsourcing",
    "authors": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Learning from the wisdom of crowds by minimax entropy",
    "authors": ["D. Zhou", "S. Basu", "Y. Mao", "J.C. Platt"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "Aggregating ordinal labels from crowds by minimax conditional entropy",
    "authors": ["D. Zhou", "Q. Liu", "J.C. Platt", "C. Meek"],
    "venue": "In ICML, pp",
    "year": 2014
  }, {
    "title": "Bayesian inference with posterior regularization and applications to infinite latent svms",
    "authors": ["J. Zhu", "N. Chen", "E.P. Xing"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2014
  }],
  "id": "SP:d72fe1900a97da6ae50fd9fe5f13dc995865a3a3",
  "authors": [{
    "name": "Guangyong Chen",
    "affiliations": []
  }, {
    "name": "Shengyu Zhang",
    "affiliations": []
  }, {
    "name": "Di Lin",
    "affiliations": []
  }, {
    "name": "Hui Huang",
    "affiliations": []
  }, {
    "name": "Pheng Ann Heng",
    "affiliations": []
  }],
  "abstractText": "While crowdsourcing has been a cost and time efficient method to label massive samples, one critical issue is quality control, for which the key challenge is to infer the ground truth from noisy or even adversarial data by various users. A large class of crowdsourcing problems, such as those involving age, grade, level, or stage, have an ordinal structure in their labels. Based on a technique of sampling estimated label from the posterior distribution, we define a novel separating width among the labeled observations to characterize the quality of sampled labels, and develop an efficient algorithm to optimize it through solving multiple linear decision boundaries and adjusting prior distributions. Our algorithm is empirically evaluated on several real world datasets, and demonstrates its supremacy over state-ofthe-art methods.",
  "title": "Learning to Aggregate Ordinal Labels by Maximizing Separating Width"
}