{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4316–4327 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n4316"
  }, {
    "heading": "1 Introduction",
    "text": "With the availability of massive online conversational data, there has been a surge of interest in building open-domain chatbots with data-driven approaches. Recently, the neural network based sequence-to-sequence (seq2seq) framework (Sutskever et al., 2014; Cho et al., 2014) has been widely adopted. In such a model, the encoder, which is typically a recurrent neural network (RNN), maps the source tokens into a fixed-sized continuous vector, based on which the decoder estimates the probabilities on the target side word by word. The whole model can be efficiently trained by maximum likelihood (MLE) and has demonstrated state-of-the-art performance in various domains. However, this architecture is not\n∗Indicates equal contribution. X. Shen focuses on algorithm and H. Su is responsible for experiments.\nsuitable for modeling dialogues. Recent research has found that while the seq2seq model generates syntactically well-formed responses, they are prone to being off-context, short, and generic. (e.g., “I dont know” or “I am not sure”) (Li et al., 2016a; Serban et al., 2016). The reason lies in the one-to-many alignments in human conversations, where one dialogue context is open to multiple potential responses. When optimizing with the MLE objective, the model tends to have a strong bias towards safe responses as they can be literally paired with arbitrary dialogue context without semantical or grammatical contradictions. These safe responses break the dialogue flow without bringing any useful information and people will easily lose interest in continuing the conversation.\nIn this paper, we propose NEXUS Network which aims at producing more on-topic responses to maintain an interactive conversation flow. Our assumption is that a good response should serve as a “nexus”: connecting and being informative to both the preceding dialogue context and the follow-up conversations. For example, in Figure 1, the response from B1 is a smooth connection, where the first half indicates the preceding context is a “Do you know” question and the second half informs that the follow-up would be an introduction about Star Wars. We establish this connection by maximizing the mutual information (MMI) of the current utterance with both the past and future contexts. In this way, generic responses can be largely discouraged as they contain no valuable information and thus have only weak correlations\nwith the surrounding context. To enable efficient training, two challenges exist.\nThe first challenge comes from the discrete nature of language tokens, hindering efficient gradient descent. One strategy is to estimate the gradient by methods like Gumbel-Softmax (Maddison et al., 2017; Jang et al., 2017) or REINFORCE algorithm (Williams, 1992), which has been applied in many NLP tasks (He et al., 2016; Shetty et al., 2017; Gu et al., 2018; Paulus et al., 2018), but the trade-off between bias and variance of the estimated gradient is hard to reconcile. The resulting model usually strongly relies on sensitive hyper-parameter tuning, careful pre-train and taskspecific tricks. Li et al. (2016a); Wang et al. (2017) avoid this non-differentiability problem by learning a separate backward model to rerank candidate responses in the testing phase while still adhering to the MLE objective for training. However, the candidate set normally suffers from low diversity and a huge sample size is needed for good performance (Li et al., 2016b).\nThe second challenge relates to the unknown future context in the testing phase. In our framework, both the history and future context need to be explicitly observed in order to compute the mutual information. When applying it to generating tasks where only the history context is given, there is no way to explicitly take into account the future information. Therefore, reranking-based models do not apply here. (Li et al., 2016c) addresses future information by policy learning, but the model suffers from high variance due to the enormous sequential search space. Serban et al. (2017); Zhao et al. (2017); Shen et al. (2017) adopt the variational inference strategy to reduce the training variance by optimizing over latent continuous variables. However, they all stick to the original MLE objective and no connection with the surrounding context is considered.\nIn this work, we address both challenges by introducing an auxiliary continuous code space which is learned from the whole dialogue flow. At each time step, instead of directly optimizing discrete utterances, the current, past and future utterances are all trained to maximize the mutual information with this code space. Furthermore, a learnable prior distribution is simultaneously optimized to predict the corresponding code space, enabling efficient sampling in the testing phase without getting access to the ground-truth future con-\nversation. Extensive experiments have been conducted to validate the superiority of our framework. The generated responses clearly demonstrate better performance with respect to both coherence and diversity."
  }, {
    "heading": "2 Model Structure",
    "text": ""
  }, {
    "heading": "2.1 Motivation",
    "text": "Let ui be the ith utterance within a dialogue flow. The dialogue historyHi−1 contains all the preceding context u1, u2, . . . , ui−1 and Fi+1 denotes the future conversations ui+1, . . . , uT . The objective of our model is to find the decoding probability pθ(ui|Hi−1, Fi+1) that maximizes the mutual information I(Hi−1, ui) and I(ui, Fi+1). Formally, the objective is:\nmax θ λ1I(Hi−1, ui) + λ2I(ui, Fi+1)\nui ∼ pθ(ui|Hi−1, Fi+1) (1)\nλ1 and λ2 adjusts the relative weight. Mutual information is defined over pθ(ui|Hi−1, Fi+1) and the empirical distribution p(Hi−1, Fi+1). Now we assume the future context Fi+1 is known to us when training the decoding probability, we will address the unknown future problem later.\nDirectly optimizing with this objective is unfortunately infeasible because the exact computation of mutual information is intractable, and backpropagating through sampled discrete sequences is notoriously difficult to train. The discontinuity prevents the direct application of the reparameterization trick (Kingma and Welling, 2014). Lowvariance relaxations like Gumbel-Softmax (Jang et al., 2017), semantic hashing (Kaiser et al., 2018) or vector quantization (van den Oord et al., 2017) lead to biased gradient estimations, which are accumulated as the sequence becomes longer. The Monte-Carlo-Simulation is unbiased but suffers from high variances. Designing a reasonable control variate for variance reduction is an extremely tricky task (Mnih and Gregor, 2014; Tucker et al., 2017). For this sake, we propose replacing ui with a continuous code space c learned from the whole dialogue flow."
  }, {
    "heading": "2.2 Continuous Code Space",
    "text": "We define the continuous code space c to follow the Gaussian probability distribution with a diagonal covariance matrix conditioning on the whole\ndialogue:\nc ∼ pφ(c|Hi−1, Fi) = N (µc, σ2c I|Hi−1, Fi) (2)\nThe dialogue history Hi−1 is encoded into vector ˜Hi−1 by a forward hierarchical GRU model Ef as in (Serban et al., 2016). The future conversation, including the current utterance, is encoded into F̃i by a backward hierarchical GRU Eb. ˜Hi−1 and F̃i are concatenated and a multi-layer perceptron is built on top of them to estimate the Gaussian mean and covariance parameters. The code space is trained to infer the encoded history ˜Hi−1 and future ˜Fi+1. The full optimizing objective is:\nL(c) = max φ Epφ(Hi−1,Fi,c)[λ1 log pφ( ˜Hi−1|c)\n+λ2 log pφ( ˜Fi+1|c)] pφ(Hi−1, Fi, c) = p(Hi−1, Fi)pφ(c|Hi−1, Fi)\npφ( ˜Hi−1|c) = N (µHi , σ2HiI|c) pφ( ˜Fi+1|c) = N (µFi+1 , σ2Fi+1I|c)\n(3) where ˜Hi−1 and ˜Fi+1 are also assumed to be Gaussian distributed given c with mean and covariance estimated from multi-layer perceptrons. We infer the encoded vectors instead of the original sequences for three reasons. Firstly, inferring dense vectors is parallelizable and computationally much cheaper than autoregressive decoding, especially when the context sequences could\nbe unlimitedly long. Secondly, sequence vectors can capture more holistic semantic-level similarity than individual tokens. Lastly, It can also help alleviate the posterior collapsing issue (Bowman et al., 2016) when training variational inference models on text (Chen et al., 2017; Shen et al., 2018), which we will use later. It can be shown that the above objective maximizes a lower bound of λ1I(Hi−1, c) + λ2I(c, Fi+1), given the conditional probability pφ(c|Hi−1, Fi). The proof is a direct extension of the derivation in (Chen et al., 2016), followed by the Data Processing Inequality (Beaudry and Renner, 2012) that the encoding function can only reduce the mutual information. As the sampling process contains only Gaussian continuous variables, the above objective can be trained through the reparameterization trick (Kingma and Welling, 2014), which is a low-variance, unbiased gradient estimator (Burda et al., 2015). After training, samples from pφ(c|Hi−1, Fi) hold high mutual information with both the history and future context. The next step is then transferring the continuous code space to reasonable discrete natural language utterances."
  }, {
    "heading": "2.3 Decoding from Continuous Space",
    "text": "Our decoder transfers the code space c into the ground-truth utterance ui by defining the probability distribution p(ui|Hi−1, c), which is imple-\nmented as a GRU decoder going through ui word by word to estimate the output probability. The encoded history ˜Hi−1 and code space c are concatenated as an extra input at each time step. The loss function for the decoder is then:\nL(d) = max φ Epφ(Hi−1,Fi,c) log pφ(ui|Hi−1, c)\npφ(Hi−1, Fi, c) = p(Hi−1, Fi)pφ(c|Hi−1, Fi) (4)\nwhich can be proved to be the lower bound of the conditional mutual information I(ui, c|Hi−1). By maximizing the conditional mutual information, ci is trained to maintain as much information about the target sequence ui as possible.\nCombining Eq. 3 and 4, our model until now can be viewed as optimizing a lower bound of the following objective:\nmax φ\nλ1I(Hi−1, c) + λ2I(c, Fi+1) + I(ui, c|Hi−1)\nc ∼ pφ(c|Hi−1, Fi) (5)\nCompared with the original motivation in Eq. 1, we sidestep the non-differentiability problem by replacing ui with a continuous code space c, then forcing ui to contain the same information as maintained in c by additionally maximizing the mutual information between them.\nNonetheless, Eq. 5 and Eq. 1 might lead to different optimums as mutual information does not satisfy the transitive law. In the extreme case, different dimensions of c could individually maintain information about history, current and future conversations and the conversations themselves do not share any dependency relation. To avoid this issue, we restrict the dimension of c to be smaller than that of the encoded vectors. In this case, optimizing Eq. 5 will favor utterances having stronger correlations with the surrounding context to achieve a higher total mutual information."
  }, {
    "heading": "2.4 Learnable Prior Distribution for Unknown Future",
    "text": "The last problem is the sampling mechanism of c in Eq. 2, which conditions on the ground-truth future conversation. In the testing phase, when we have no access to it, we cannot perform the decoding process as in Eq. 4. To allow for decoding with only the history context, we need to learn an appropriate prior distribution pθ(c|Hi−1) for c. In\nthe ideal case, we would like pθ(c|Hi−1) = ∑ Fi pφ(c|Hi−1, Fi) = pφ(c|Hi−1) (6) However, pφ(c|Hi−1) is intractable as it integrates over all possible future conversations. We apply variational inference on c to maximize the variational lower bound (Jordan et al., 1999):\nL(p) = max θ,φ Epφ(c|Hi−1,Fi) log pθ(F̃i|Hi−1, c)\n−KL(pφ(c|Hi−1, Fi)||pθ(c|Hi−1)) pθ(F̃i|Hi−1, c) ∼ N (µFi , σ2FiI|Hi−1, c) pθ(c|Hi−1) ∼ N (µprior, σ2priorI|Hi−1))\n(7) It can be reformulated as maximizing:\nEpφ(c|Hi−1)KL(pφ(F̃i|Hi−1, c)||pθ(F̃i|Hi−1, c)) −KL(pφ(c|Hi−1)||pθ(c|Hi−1))\n(8) We can see it implicitly matches pφ(c|Hi−1) to a tractable Gaussian distribution pθ(c|Hi−1) by minimizing the KL divergence between them. It also functions as a regularizer to prevent overfitting when learning pφ(c|Hi−1, Fi). In the testing phase, we can sample c from the learned prior distribution pθ(c|Hi−1), then generate a response based on it."
  }, {
    "heading": "2.5 Summary",
    "text": "To sum up, the total objective function of our model is:\nL = L(c) + L(d) + L(p) (9)\nWeighting can be added to individual loss functions for better performance, but we find it enough to maintain equal weights and avoid extra hyperparameters. All the parameters are simultaneously updated by gradient descent except for the encoders Ef and Eb, which only accept gradients from L(d) since otherwise the model can easily learn to encode no information for a lower reconstruction loss in L(c) and L(p). An overview of our training procedure is depicted in Fig. 2."
  }, {
    "heading": "3 Relationship to Existing Methods",
    "text": "MMI decoding MMI decoder was proposed by (Li et al., 2016a) and further extended in (Wang et al., 2017). The basic idea is the same as our model by maximizing the mutual information with\nthe dialogue context. However, the MMI principle is applied only at the testing phase rather than the training phase. As a result, it can only be used to evaluate the quality of a generation by estimating its mutual information with the context. To apply it in a generative task, we have to first sample some candidate responses with the seq2seq model, then rerank them by accounting for the MMI score. Our model differs from it in that we directly estimate the decoding probability thus no post-sampling rerank is needed. Moreover, we further include the future context to strengthen the connection role of the current utterances.\nConditional Variational Autoencoder The idea of learning an appropriate prior distribution in Eq. 7 is essentially a conditional variational autoencoder (Sohn et al., 2015) where the accumulated posterior distribution is trained to stay close to a prior distribution. It has also been applied in dialogue generation (Serban et al., 2017; Zhao et al., 2017). However, all the above methods stick to the MLE objective function and do not optimize with respect to the mutual information. As we will show in the experiment, they fail to learn the correlation between the utterance and its surrounding context. The generation diversity of these models comes more from the sampling randomness of the prior distribution rather than from the correct understanding of context correlation. Moreover, they suffer from the posterior collapsing problem (Bowman et al., 2016) and require special tricks like KL-annealing, BOW loss or word drop-out (Shen et al., 2018). Our model does not have such problems.\nDeep Reinforcement Learning Dialogue Generation (Li et al., 2016c) first considered future success in dialogue generation and applied deep reinforcement learning to encourage more interactive conversations. However, the reward functions are intuitively hand-crafted. The relative weight for each reward needs to be carefully tuned and the training stage is unstable due to the huge search space. In contrast, our model maximizes the mutual information in the continuous space and trains the prior distribution through the reparamaterization trick. As a result, our model can be more easily trained with a lower variance. Throughout our experiment, the training process of NEXUS network is rather stable and much less data-hungry. The MMI objective of our model is theoretically\nmore sound and no manually-defined rules need to be specified."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Dataset and Training Details",
    "text": "We run experiments on the DailyDialog (Li et al., 2017b) and Twitter corpus (Ritter et al., 2011). DailyDialog contains 13118 daily conversations under ten different topics. This dataset is crawled from various websites for English learner to practice English in daily life, which is high-quality, less noisy but relatively smaller. In contrast, the Twitter corpus is significantly larger but contains more noise. We obtain the dataset as used in Serban et al. (2017) and filter out tweets that have already been deleted, resulting in about 750,000 multi-turn dialogues. The contents have more informal, colloquial expressions which makes the generation task harder. These two datasets are randomly separated into training/validation/test sets with the ratio of 10:1:1.\nIn order to keep our model comparable with the state-of-the-art, we keep most parameter values the same as in (Serban et al., 2017). We build our vocabulary dictionary based on the most frequent 20,000 words for both corpus and map other words to a UNK token. The dimensionality of the code space c is 100. We use a learning rate of 0.001 for DailyDialog and 0.0002 for Twitter corpus. The batch size is fixed to 128. The word vector dimension is 300 and is initialized with the public Word2Vec (Mikolov et al., 2013) embeddings trained on the Google News Corpus. The probability estimators for the Gaussian distributions are implemented as 3-layer perceptrons with the hyperbolic tangent activation function. As mentioned above, when training NEXUS models, we block the gradient from L(c) and L(p) with respect to Ef and Eb to encourage more meaningful encodings. The UNK token is prevented from being generated in the test phase. We implemented all the models with the open-sourced Python library Pytorch (Paszke et al., 2017) and optimized using the Adam optimizer (Kingma and Ba, 2015)."
  }, {
    "heading": "4.2 Compared Models",
    "text": "We conduct extensive experiments to compare our model against several representative baselines.\nSeq2Seq: Following the same implementation as in (Vinyals and Le, 2015), the seq2seq model serves as a baseline. We try both greedy decoding\nand beam search (Graves, 2012) with beam size set to 5 when testing.\nMMI: We implemented the bidirectional-MMI decoder as in Li et al. (2016a), which showed better performance over the anti-LM model. The hyperparameter λ is set to 0.5 as suggested. 200 candidates per context are sampled for re-ranking.\nVHRED: The VHRED model is essentially a conditional variational autoencoder with hierarchical encoders (Serban et al., 2017; Zhao et al., 2017). To alleviate the posterior collapsing problem, we apply the KL-annealing trick and early stop with the step set as 12,000 for the DailyDialog and 75,000 for the Twitter corpus.\nRL: Deep reinforcement learning chatbot as in (Li et al., 2016c). We use all the three reward functions mentioned in the paper and keep the relative weights the same as in the original paper. Policy network is initialized with the above-mentioned MMI model.\nNEXUS-H: NEXUS network maximizing mutual information only with the history (λ2 = 0).\nNEXUS-F: NEXUS network maximizing mutual information only with the future (λ1 = 0).\nNEXUS: NEXUS network maximizing mutual information with both the history and future.\nNEXUS-H and NEXUS-F are implemented to help us better analyze the effects of different components in our model. The hyperparameters λ1 and λ2 in NEXUS are set to be 0.5 and 1 respectively as we find history vector is consistently easier to be reconstructed than the future vector (A.6)."
  }, {
    "heading": "4.3 Metric-based Performance",
    "text": "Embedding Score We conducted three embedding-based evaluations (average, greedy\nand extrema) (Liu et al., 2016), which map responses into vector space and compute the cosine similarity (Rus and Lintean, 2012). The embedding-based metrics can to a large extent capture the semantic-level similarity between generated responses and ground truth. We represent words using Word2Vec embeddings trained on the Google News Corpus. We also measure the uncertainty of the score by assuming each data point is independently Gaussian distributed. The standard deviation yields the 95% confidence interval (Barany et al., 2007). Table 1 reports the embedding scores on both datasets. NEXUS network significantly outperforms the best baseline model in most cases. Notably, NEXUS can absorb the advantages from both NEXUS-H and NEXUS-F. The history and future information seem to help the model from different perspectives. Taking into account both of them does not create a conflict and the combination leads to an overall improvement. RL performs rather poorly on this metric, which is understandable as it does not target the ground-truth responses during training (Li et al., 2016c).\nBLEU Score BLEU is a popular metric that measures the geometric mean of the modified ngram precision with a length penalty (Papineni et al., 2002). Table 2 reports the BLEU 1-3 scores. Compared with embedding-based metrics, the BLEU score quantifies the word-overlap between generated responses and the ground-truth. One challenge of evaluating dialogue generation by BLEU score is the difficulty of accessing multiple references for the one-to-many alignment relation. Following Sordoni et al. (2015); Zhao et al.\n(2017); Shen et al. (2018), for each context, 10 more candidate references are acquired by using information retrieval methods (see Appendix A.4 for more details). All candidates are then passed to human annotators to filter unsuitable ones, resulting in 6.74 and 5.13 references for DailyDialog and Twitter dataset respectively. The human annotation is costly, so we evaluate it on 1000 sampled test cases for each dataset. As the BLEU score is not the simple mean of individual sentence scores, we compute the 95% significance interval by bootstrap resampling (Koehn, 2004; Riezler and Maxwell, 2005). As can be seen, NEXUS network achieves best or near-best performances with only greedy decoders. NEXUS-H generally outperforms NEXUS-F as the connection with future context is not explicitly addressed by the BLEU score metric. MMI and VHRED bring minor improvements over the seq2seq model. Even when evaluated on multiple references, RL still performs worse than most models.\nConnecting the preceding We define two metrics to evaluate the model’s capability of “connecting the preceding context”: AdverSuc and NegPMI. AdverSuc measures the coherence of generated responses with the provided context by learning an adversarial discriminator (Li et al., 2017a) on the same corpus to distinguish coherent responses from randomly sampled ones. We encode the context and response separately with two different LSTM neural networks and output a binary signal indicating coherent or not1. The Adver-\n1We apply the same architecture as in Lu et al. (2017). In our experiment, the discriminator performs reasonably well in the 4 scenarios outlined in Li et al. (2017a) and thus can be used as a fair evaluation metric.\nSuc value is reported as the success rate that the model fools the classifier into believing its false generations (p(generated = coherent) > 0.5). Neg-PMI measures the negative pointwise mutual information value − log p(c|r)/p(c) between the generated response r and the dialogue context c. p(c|r) is estimated by training a separate backward seq2seq model. As p(c) is a constant, we ignore it and only report the value of − log p(c|r). A good model should achieve a higher AdverSuc and a lower Neg-PMI. The results are listed in Table 3. We can see there is still a big gap between ground-truth and synthesized responses. As expected, NEXUS-H leads to the most significant improvement. MMI model also performs remarkably well, but it requires post-reranking thus the sampling process is much slower. VHRED and NEXUS-F do not help much here, sometimes even slightly degrade the performance. We also tried removing the history context when computing the posterior distribution in VHRED, the resulting model has similar performance among all metrics, which suggests VHRED itself cannot actually learn the correlation pattern with the preceding context. Surprisingly, though RL explicitly set the coherence score as a reward function, its performance is far from satisfying. We assume RL requires much more data to learn the appropriate policy than other models and the training process suffers from a higher variance. The result is thus hard to be guaranteed.\nConnecting the following We measure the model’s capability of “connecting the following context” from two perspectives: number of the simulated turns and diversity of generated re-\nsponses. We apply all models to generate multiple turns until a generic response is reached. The set of generic responses is manually examined to include all utterances providing only passive dull replies2. The number of generated turns can reflect the time that a model can maintain an interactive conversation. The results are reflected in the #Turns column in Table 3. As in (Li et al., 2016a), we measure the diversity by the percentage of distinct unigrams (Distinct-1) and bigrams (Distinct2) in all generated responses. Intuitively a higher score on these three metrics implies a more interactive generation system that can better connect the future context. Again, NEXUS network dominates most fields. NEXUS-F brings more impact than NEXUS-H as it explicitly encourages more interactive turns. Most seq2seq models fail to provide an informative response in the first turn. The MMI-decoder does not change much, possibly because the sampling space is not large enough, a more diverse sampling mechanism (Vijayakumar et al., 2018) might help. NEXUS network can effectively continue the conversation for 2.8 turns for DailyDialog and 2.5 turns for Twitter, which is closest to the ground truth (4.8 and 4.0 turns respectively). It also achieves the best diversity score in both datasets. It is worth mentioning that NEXUS-H also improves over baselines, though not as significantly as NEXUS-F, so NEXUS is not a trade-off but more like an enhanced version from NEXUS-H and NEXUS-F.\nIn summary, NEXUS network clearly generates higher-quality responses in both coherence and diversity, even in a rather small dataset like DailyDialog. NEXUS-H contributes more to the coher-\n2We use a simple rule matching method (see Appendix A.5). We manually inspect it on a validation subset and find the accuracy is more than 90%. Similar methods are adopted in (Li et al., 2016c).\nence and NEXUS-F more to the diversity."
  }, {
    "heading": "4.4 Human Evaluation",
    "text": "We also employed crowdsourced judges to provide evaluations for a random sample of 500 items in the DailyDialog test dataset. Participants are asked to assign a binary score to each contextresponse pair from three perspectives: whether the response coincides with its preceding context (Pri), whether the response is interesting enough for people to continue (Post) and whether the response itself is a fluent natural sentence (Flu). Each sample gets one point if judged as yes and zero otherwise. Each pair is judged by three participants and the score supported by most people is adopted. We also evaluated the inter-annotator consistency by Fleiss’k score(Fleiss, 1971) and obtained k scores of 0.452 for Pri, 0.459 for Post (moderate agreement) and 0.621 for Flu (substantial agreement), which implies most contextresponse pairs reach a consensus on the evaluation task. We compute the average human score for each model. Unlike metric-based scores, the human evaluation is conducted only on the DailyDialog corpus as it contains less noise and can be more fairly evaluated by human judges. Table 3 shows the result in the last three columns. As can be seen, the pri and post human scores are highly correlated with the automatic evaluation metric “coherence” and “#turns”, verifying the validity of these two metrics. As for fluency, there is no significant difference among most models. As we also manually examined, fluency is not a major problem and all models produce mostly well-formed sentences. Overall, NEXUS network does produce responses that are more acceptable to human judges.\nTable 4 presents some randomly sampled context-response pairs provided by MMI,\nVHRED, RL and NEXUS model. We see NEXUS network does generate more interactive outputs than the other three. Though reranked by the bidirectional language model, the MMI decoder still produces quite a few generic responses. VHRED’s utterances are more diverse, but it only cares about answering to the immediate query and makes no efforts to bring about further topics. Moreover, it also generates more inappropriate responses than the others. RL provides diverse responses but sometimes not fluent or coherent enough. We do observe that NEXUS sometimes generate over-complex questions which are not very natural, as in the second example. But in most cases, it outperforms the others."
  }, {
    "heading": "5 Conclusion",
    "text": "In this paper, we propose “NEXUS Network” to enable more interactive human-computer conversations. The main goal of our model is to strengthen the “nexus” role of the current utterance, connecting both the preceding and the following dialogue context. We compare our model with MMI, reinforcement learning and CVAEbased models. Experiments show that NEXUS network consistently produces higher-quality re-\nsponses. The model is easier to train, requires no special tricks and demonstrates remarkable generalization capability even in a very small dataset.\nOur model can be considered as combining the objective of MMI and CVAE and is compatible with current improving techniques. For example, mutual information can be maximized under a tighter bound using Donsker-Varadhan or f-divergence representation (Donsker and Varadhan, 1983; Nowozin et al., 2016; Belghazi et al., 2018). Extending the code space distribution to more than Gaussian by importance weighted autoencoder (Burda et al., 2015), inverse autoregressive flow (Kingma et al., 2016) or VamPrior (Tomczak and Welling, 2018) should also help with the performance."
  }, {
    "heading": "Acknowledgments",
    "text": "We thank all anonymous reviewers, Gerhard Weikum, Jie Zhou, Cheng Niu and the dialogue system team of Wechat AI for valuable comments. Xiaoyu Shen is supported by IMPRSCS fellowship. This work is partially funded by DFG collaborative research center SFB 1102 and Research Grants Council of Hong Kong (PolyU 152036/17E, 152040/18E)."
  }],
  "references": [{
    "title": "Central limit theorems for gaussian polytopes",
    "authors": ["Imre Barany", "Van Vu"],
    "venue": "The Annals of Probability,",
    "year": 2007
  }, {
    "title": "An intuitive proof of the data processing inequality",
    "authors": ["Normand J Beaudry", "Renato Renner."],
    "venue": "Quantum Information & Computation, 12(5-6):432– 441.",
    "year": 2012
  }, {
    "title": "Mutual information neural estimation",
    "authors": ["Mohamed Ishmael Belghazi", "Aristide Baratin", "Sai Rajeshwar", "Sherjil Ozair", "Yoshua Bengio", "Devon Hjelm", "Aaron Courville."],
    "venue": "Proceedings of the 35th International Conference on Machine Learning, vol-",
    "year": 2018
  }, {
    "title": "Generating sentences from a continuous space",
    "authors": ["Samuel R Bowman", "Luke Vilnis", "Oriol Vinyals", "Andrew Dai", "Rafal Jozefowicz", "Samy Bengio."],
    "venue": "Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning,",
    "year": 2016
  }, {
    "title": "Importance weighted autoencoders",
    "authors": ["Yuri Burda", "Roger B. Grosse", "Ruslan Salakhutdinov."],
    "venue": "CoRR, abs/1509.00519.",
    "year": 2015
  }, {
    "title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
    "authors": ["Xi Chen", "Yan Duan", "Rein Houthooft", "John Schulman", "Ilya Sutskever", "Pieter Abbeel."],
    "venue": "Advances in Neural Information Processing Sys-",
    "year": 2016
  }, {
    "title": "Variational lossy autoencoder",
    "authors": ["Xi Chen", "Diederik P Kingma", "Tim Salimans", "Yan Duan", "Prafulla Dhariwal", "John Schulman", "Ilya Sutskever", "Pieter Abbeel."],
    "venue": "ICLR.",
    "year": 2017
  }, {
    "title": "Learning phrase representations using rnn encoder–decoder for statistical machine translation",
    "authors": ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio."],
    "venue": "Proceedings of",
    "year": 2014
  }, {
    "title": "Asymptotic evaluation of certain markov process expectations for large time",
    "authors": ["Monroe D Donsker", "SR Srinivasa Varadhan."],
    "venue": "iv. Communications on Pure and Applied Mathematics, 36(2):183–212.",
    "year": 1983
  }, {
    "title": "Measuring nominal scale agreement among many raters",
    "authors": ["Joseph L Fleiss."],
    "venue": "Psychological bulletin, 76(5):378.",
    "year": 1971
  }, {
    "title": "Sequence transduction with recurrent neural networks",
    "authors": ["Alex Graves."],
    "venue": "CoRR, abs/1211.3711.",
    "year": 2012
  }, {
    "title": "Neural machine translation with gumbel-greedy decoding",
    "authors": ["Jiatao Gu", "Daniel Jiwoong Im", "Victor OK Li."],
    "venue": "AAAI, pages 5125–5132.",
    "year": 2018
  }, {
    "title": "Dual learning for machine translation",
    "authors": ["Di He", "Yingce Xia", "Tao Qin", "Liwei Wang", "Nenghai Yu", "Tieyan Liu", "Wei-Ying Ma."],
    "venue": "Advances in Neural Information Processing Systems, pages 820–828.",
    "year": 2016
  }, {
    "title": "Categorical reparameterization with gumbel-softmax",
    "authors": ["Eric Jang", "Shixiang Gu", "Ben Poole."],
    "venue": "ICLR.",
    "year": 2017
  }, {
    "title": "An introduction to variational methods for graphical models",
    "authors": ["Michael I Jordan", "Zoubin Ghahramani", "Tommi S Jaakkola", "Lawrence K Saul."],
    "venue": "Machine learning, 37(2):183–233.",
    "year": 1999
  }, {
    "title": "Fast decoding in sequence models using discrete latent variables",
    "authors": ["Lukasz Kaiser", "Samy Bengio", "Aurko Roy", "Ashish Vaswani", "Niki Parmar", "Jakob Uszkoreit", "Noam Shazeer."],
    "venue": "Proceedings of the 35th International Conference on Machine Learn-",
    "year": 2018
  }, {
    "title": "Adam: A method for stochastic optimization",
    "authors": ["Diederik Kingma", "Jimmy Ba."],
    "venue": "ICLR.",
    "year": 2015
  }, {
    "title": "Improved variational inference with inverse autoregressive flow",
    "authors": ["Diederik P Kingma", "Tim Salimans", "Rafal Jozefowicz", "Xi Chen", "Ilya Sutskever", "Max Welling."],
    "venue": "Advances in Neural Information Processing Systems, pages 4743–4751.",
    "year": 2016
  }, {
    "title": "Autoencoding variational bayes",
    "authors": ["Diederik P Kingma", "Max Welling."],
    "venue": "ICLR.",
    "year": 2014
  }, {
    "title": "Statistical significance tests for machine translation evaluation",
    "authors": ["Philipp Koehn."],
    "venue": "Proceedings of the 2004 conference on empirical methods in natural language processing.",
    "year": 2004
  }, {
    "title": "A diversity-promoting objective function for neural conversation models",
    "authors": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan."],
    "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
    "year": 2016
  }, {
    "title": "A simple, fast diverse decoding algorithm for neural generation",
    "authors": ["Jiwei Li", "Will Monroe", "Dan Jurafsky."],
    "venue": "CoRR, abs/1611.08562.",
    "year": 2016
  }, {
    "title": "Deep reinforcement learning for dialogue generation",
    "authors": ["Jiwei Li", "Will Monroe", "Alan Ritter", "Dan Jurafsky", "Michel Galley", "Jianfeng Gao."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1192–",
    "year": 2016
  }, {
    "title": "Adversarial learning for neural dialogue generation",
    "authors": ["Jiwei Li", "Will Monroe", "Tianlin Shi", "Sėbastien Jean", "Alan Ritter", "Dan Jurafsky."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2157–2169.",
    "year": 2017
  }, {
    "title": "Dailydialog: A manually labelled multi-turn dialogue dataset",
    "authors": ["Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu."],
    "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1:",
    "year": 2017
  }, {
    "title": "Orange: a method for evaluating automatic evaluation metrics for machine translation",
    "authors": ["Chin-Yew Lin", "Franz Josef Och."],
    "venue": "Proceedings of the 20th international conference on Computational Linguistics, page 501. Association for Computational Lin-",
    "year": 2004
  }, {
    "title": "How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
    "authors": ["Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Mike Noseworthy", "Laurent Charlin", "Joelle Pineau."],
    "venue": "Proceedings of the",
    "year": 2016
  }, {
    "title": "A practical approach to dialogue response generation in closed domains",
    "authors": ["Yichao Lu", "Phillip Keung", "Shaonan Zhang", "Jason Sun", "Vikas Bhardwaj."],
    "venue": "CoRR, abs/1703.09439.",
    "year": 2017
  }, {
    "title": "The concrete distribution: A continuous relaxation of discrete random variables",
    "authors": ["Chris J Maddison", "Andriy Mnih", "Yee Whye Teh."],
    "venue": "ICLR.",
    "year": 2017
  }, {
    "title": "Efficient estimation of word representations in vector space",
    "authors": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."],
    "venue": "ICLR workshop.",
    "year": 2013
  }, {
    "title": "Neural variational inference and learning in belief networks",
    "authors": ["Andriy Mnih", "Karol Gregor."],
    "venue": "International Conference on Machine Learning, pages 1791–1799.",
    "year": 2014
  }, {
    "title": "f-gan: Training generative neural samplers using variational divergence minimization",
    "authors": ["Sebastian Nowozin", "Botond Cseke", "Ryota Tomioka."],
    "venue": "Advances in Neural Information Processing Systems, pages 271–279.",
    "year": 2016
  }, {
    "title": "Neural discrete representation learning",
    "authors": ["Aaron van den Oord", "Oriol Vinyals"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2017
  }, {
    "title": "Bleu: a method for automatic evaluation of machine translation",
    "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."],
    "venue": "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for",
    "year": 2002
  }, {
    "title": "Automatic differentiation in pytorch",
    "authors": ["Adam Paszke", "Sam Gross", "Soumith Chintala", "Gregory Chanan", "Edward Yang", "Zachary DeVito", "Zeming Lin", "Alban Desmaison", "Luca Antiga", "Adam Lerer."],
    "venue": "NIPS workshop.",
    "year": 2017
  }, {
    "title": "A deep reinforced model for abstractive summarization",
    "authors": ["Romain Paulus", "Caiming Xiong", "Richard Socher."],
    "venue": "ICLR.",
    "year": 2018
  }, {
    "title": "A hierarchical latent variable",
    "authors": ["Yoshua Bengio"],
    "year": 2017
  }, {
    "title": "Sequence to sequence learning with neural networks",
    "authors": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."],
    "venue": "Advances in neural information processing systems, pages 3104–3112.",
    "year": 2014
  }, {
    "title": "Vae with a vampprior",
    "authors": ["Jakub Tomczak", "Max Welling."],
    "venue": "International Conference on Artificial Intelligence and Statistics, pages 1214–1223.",
    "year": 2018
  }, {
    "title": "Rebar: Low-variance, unbiased gradient estimates for discrete latent variable models",
    "authors": ["George Tucker", "Andriy Mnih", "Chris J Maddison", "John Lawson", "Jascha Sohl-Dickstein."],
    "venue": "Advances in Neural Information Processing Systems, pages 2627–2636.",
    "year": 2017
  }, {
    "title": "Diverse beam search for improved description of complex scenes",
    "authors": ["Ashwin K Vijayakumar", "Michael Cogswell", "Ramprasaath R Selvaraju", "Qing Sun", "Stefan Lee", "David J Crandall", "Dhruv Batra."],
    "venue": "AAAI, pages 7371–7379.",
    "year": 2018
  }, {
    "title": "A neural conversational model",
    "authors": ["Oriol Vinyals", "Quoc V. Le."],
    "venue": "CoRR, abs/1506.05869.",
    "year": 2015
  }, {
    "title": "Steering output style and topic in neural response generation",
    "authors": ["Di Wang", "Nebojsa Jojic", "Chris Brockett", "Eric Nyberg."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2140–2150.",
    "year": 2017
  }, {
    "title": "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
    "authors": ["Ronald J Williams."],
    "venue": "Reinforcement Learning, pages 5–32. Springer.",
    "year": 1992
  }, {
    "title": "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
    "authors": ["Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
    "year": 2017
  }],
  "id": "SP:dcf7c5159001838de25b90eddfe3e22fb58f71fd",
  "authors": [{
    "name": "Xiaoyu Shen",
    "affiliations": []
  }, {
    "name": "Hui Su",
    "affiliations": []
  }, {
    "name": "Wenjie Li",
    "affiliations": []
  }, {
    "name": "Dietrich Klakow",
    "affiliations": []
  }],
  "abstractText": "Sequence-to-Sequence (seq2seq) models have become overwhelmingly popular in building end-to-end trainable dialogue systems. Though highly efficient in learning the backbone of human-computer communications, they suffer from the problem of strongly favoring short generic responses. In this paper, we argue that a good response should smoothly connect both the preceding dialogue history and the following conversations. We strengthen this connection through mutual information maximization. To sidestep the nondifferentiability of discrete natural language tokens, we introduce an auxiliary continuous code space and map such code space to a learnable prior distribution for generation purpose. Experiments on two dialogue datasets validate the effectiveness of our model, where the generated responses are closely related to the dialogue context and lead to more interactive conversations.",
  "title": "NEXUS Network: Connecting the Preceding and the Following in Dialogue Generation"
}