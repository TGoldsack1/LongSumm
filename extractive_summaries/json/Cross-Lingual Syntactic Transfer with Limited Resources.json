{
  "sections": [{
    "heading": "1 Introduction",
    "text": "Creating manually-annotated syntactic treebanks is an expensive and time consuming task. Recently there has been a great deal of interest in cross-lingual syntactic transfer, where a parsing model is trained for some language of interest, using only treebanks in other languages. There is a clear motivation for this in building parsing models for languages for which treebank data is unavailable. Methods\n∗On leave at Google Inc. New York.\nfor syntactic transfer include annotation projection methods (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015; Lacroix et al., 2016; Agić et al., 2016), learning of delexicalized models on universal treebanks (Zeman and Resnik, 2008; McDonald et al., 2011; Täckström et al., 2013; Rosa and Zabokrtsky, 2015), treebank translation (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agić, 2016) and methods that leverage cross-lingual representations of word clusters, embeddings or dictionaries (Täckström et al., 2012; Durrett et al., 2012; Duong et al., 2015a; Zhang and Barzilay, 2015; Xiao and Guo, 2015; Guo et al., 2015; Guo et al., 2016; Ammar et al., 2016a).\nThis paper considers the problem of cross-lingual syntactic transfer with limited resources of monolingual and translation data. Specifically, we use the Bible corpus of Christodouloupoulos and Steedman (2014) as a source of translation data, and Wikipedia as a source of monolingual data. We deliberately limit ourselves to the use of Bible translation data because it is available for a very broad set of languages: the data from Christodouloupoulos and Steedman (2014) includes data from 100 languages. The Bible data contains a much smaller set of sentences (around 24,000) than other translation corpora, for example Europarl (Koehn, 2005), which has around 2 million sentences per language pair. This makes it a considerably more challenging corpus to work with. Similarly, our choice of Wikipedia as the source of monolingual data is motivated by the availability of Wikipedia data in a very broad set of languages.\n279\nTransactions of the Association for Computational Linguistics, vol. 5, pp. 279–293, 2017. Action Editor: Yuji Matsumoto. Submission batch: 5/2016; Revision batch: 10/2016; 2/2017; Published 8/2017.\nc©2017 Association for Computational Linguistics. Distributed under a CC-BY 4.0 license.\nWe introduce a set of simple but effective methods for syntactic transfer, as follows:\n• We describe a method for deriving crosslingual clusters, where words from different languages with a similar syntactic or semantic role are grouped in the same cluster. These clusters can then be used as features in a shiftreduce dependency parser.\n• We describe a method for transfer of lexical information from the target language into source language treebanks, using word-to-word translation dictionaries derived from parallel corpora. Lexical features from the target language can then be integrated in parsing.\n• We describe a method that integrates the above two approaches with the density-driven approach to annotation projection described by Rasooli and Collins (2015).\nExperiments show that our model outperforms previous work on a set of European languages from the Google universal treebank (McDonald et al., 2013). We achieve 80.9% average unlabeled attachment score (UAS) on these languages; in comparison the work of Zhang and Barzilay (2015), Guo et al. (2016) and Ammar et al. (2016b) have a UAS of 75.4%, 76.3% and 77.8%, respectively. All of these previous works make use of the much larger Europarl (Koehn, 2005) corpus to derive lexical representations. When using Europarl data instead of the Bible, our approach gives 83.9% accuracy, a 1.7% absolute improvement over Rasooli and Collins (2015). Finally, we conduct experiments on 38 datasets (26 languages) in the universal dependencies v1.3 (Nivre et al., 2016) corpus. Our method has an average unlabeled dependency accuracy of 74.8% for these languages, more than 6% higher than the method of Rasooli and Collins (2015). Thirteen datasets (10 languages) have accuracies higher than 80.0%.1"
  }, {
    "heading": "2 Background",
    "text": "This section gives a description of the underlying parsing models used in our experiments, the data\n1 The parser code is available at https://github. com/rasoolims/YaraParser/tree/transfer.\nsets used, and a baseline approach based on delexicalized parsing models."
  }, {
    "heading": "2.1 The Parsing Model",
    "text": "We assume that the parsing model is a discriminative linear model, where given a sentence x, and a set of candidate parses Y(x), the output from the model is\ny∗(x) = arg max y∈Y(x) θ · φ(x, y)\nwhere θ ∈ Rd is a parameter vector, and φ(x, y) is a feature vector for the pair (x, y). In our experiments we use the shift-reduce dependency parser of Rasooli and Tetreault (2015), which is an extension of the approach in Zhang and Nivre (2011). The parser is trained using the averaged structured perceptron (Collins, 2002).\nWe assume that the feature vector φ(x, y) is the concatenation of three feature vectors:\n• φ(p)(x, y) is an unlexicalized set of features. Each such feature may depend on the part-ofspeech (POS) tag of words in the sentence, but does not depend on the identity of individual words in the sentence.\n• φ(c)(x, y) is a set of cluster features. These features require access to a dictionary that maps each word in the sentence to an underlying cluster identity. Clusters may, for example, be learned using the Brown clustering algorithm (Brown et al., 1992). The features may make use of cluster identities in combination with POS tags.\n• φ(l)(x, y) is a set of lexicalized features. Each such feature may depend directly on word identities in the sentence. These features may also depend on part-of-speech tags or cluster information, in conjunction with lexical information.\nAppendix A has a complete description of the features used in our experiments."
  }, {
    "heading": "2.2 Data Assumptions",
    "text": "Throughout this paper we will assume that we have m source languages L1 . . .Lm, and a single target language Lm+1. We assume the following data sources:\nSource language treebanks. We have a treebank Ti for each language i ∈ {1 . . .m}.\nPart-of-speech (POS) data. We have handannotated POS data for all languages L1 . . .Lm+1. We assume that the data uses a universal POS set that is common across all languages.\nMonolingual data. We have monolingual, raw text for each of the (m+1) languages. We useDi to refer to the monolingual data for the ith language.\nTranslation data. We have translation data for all language pairs. We use Bi,j to refer to translation data for the language pair (i, j) where i, j ∈ {1 . . . (m+ 1)} and i 6= j.\nIn our main experiments we use the Google universal treebank (McDonald et al., 2013) as our source language treebanks2 (this treebank provides universal dependency relations and POS tags), Wikipedia data as our monolingual data, and the Bible from Christodouloupoulos and Steedman (2014) as the source of our translation data. In additional experiments we use the Europarl corpus as a source of translation data, in order to measure the impact of using the smaller Bible corpus."
  }, {
    "heading": "2.3 A Baseline Approach: Delexicalized Parsers with Self-Training",
    "text": "Given the data assumption of a universal POS set, the feature vectors φ(p)(x, y) can be shared across languages. A simple approach is then to simply train a delexicalized parser using treebanks T1 . . . Tm, using the representation φ(x, y) = φ(p)(x, y) (see (McDonald et al., 2013; Täckström et al., 2013)).\nOur baseline approach makes use of a delexicalized parser, with two refinements:\nWALS properties. We use the six properties from the World Atlas of Language Structures (WALS) (Dryer and Haspelmath, 2013) to select a subset of closely related languages for each target language. These properties are shown in Table 1. The model for a target language is trained on treebank data from languages where at least 4 out of 6 WALS properties are common between the source and target\n2We also train our best performing model on the newly released universal treebank v1.3 (Nivre et al., 2016). See §4.3 for more details.\nlanguage.3 This gives a slightly stronger baseline. Our experiments showed an improvement in average labeled dependency accuracy for the languages from 62.52% to 63.18%. Table 2 shows the set of source languages used for each target language. These source languages are used for all experiments in the paper.\nSelf-training. We use self-training (McClosky et al., 2006) to further improve parsing performance. Specifically, we first train a delexicalized model on treebanks T1 . . . Tm; then use the resulting model to parse a dataset Tm+1 that includes target-language sentences which have POS tags but do not have dependency structures. We finally use the automatically parsed data T ′m+1 as the treebank data and retrain the model. This last model is trained using all features (unlexicalized, clusters, and lexicalized). Self-training in this way gives an improvement in labeled accuracy from 63.18% to 63.91%."
  }, {
    "heading": "2.4 Translation Dictionaries",
    "text": "Our only use of the translation data Bi,j for i, j ∈ {1 . . . (m + 1)} is to construct a translation dictionary t(w, i, j). Here i and j are two languages, w is a word in language Li, and the output w′ = t(w, i, j) is a word in language Lj corresponding to the most frequent translation ofw into this language.\nWe define the function t(w, i, j) as follows: We first run the GIZA++ alignment process (Och and Ney, 2003) on the data Bi,j . We then keep intersected alignments between sentences in the two languages. Finally, for each word w in Li, we define\n3There was no effort to optimize this choice; future work may consider more sophisticated sharing schemes.\nw′ = t(w, i, j) to be the target language word most frequently aligned tow in the aligned data. If a word w is never seen aligned to a target language wordw′, we define t(w, i, j) = NULL."
  }, {
    "heading": "3 Our Approach",
    "text": "We now describe an approach that gives significant improvements over the baseline. §3.1 describes a method for deriving cross-lingual clusters, allowing us to add cluster features φ(c)(x, y) to the model. §3.2 describes a method for adding lexical features φ(l)(x, y) to the model. §3.3 describes a method for integrating the approach with the density-driven approach of Rasooli and Collins (2015). Finally, §4 describes experiments. We show that each of the above steps leads to improvements in accuracy."
  }, {
    "heading": "3.1 Learning Cross-Lingual Clusters",
    "text": "We now describe a method for learning crosslingual clusters. This follows previous work on cross-lingual clustering algorithms (Täckström et al., 2012). A clustering is a functionC(w) that maps each word w in a vocabulary to a cluster C(w) ∈ {1 . . .K}, where K is the number of clusters. A hierarchical clustering is a function C(w, l) that maps a word w together with an integer l to a cluster at level l in the hierarchy. As one example, the Brown clustering algorithm (Brown et al., 1992) gives a hierarchical clustering. The level l allows cluster features at different levels of granularity.\nA cross-lingual hierarchical clustering is a function C(w, l) where the clusters are shared across the (m + 1) languages of interest. That is, the word w\nInputs: 1) Monolingual texts Di for i = 1 . . . (m+ 1); 2) a function t(w, i, j) that translates a word w ∈ Li to w′ ∈ Lj ; and 3) a parameter α such that 0 < α < 1.\ncan be from any of the (m + 1) languages. Ideally, a cross-lingual clustering should put words across different languages which have a similar syntactic and/or semantic role in the same cluster. There is a clear motivation for cross-lingual clustering in the parsing context. We can use the cluster-based features φ(c)(x, y) on the source language treebanks T1 . . . Tm, and these features will now generalize beyond these treebanks to the target language Lm+1.\nWe learn a cross-lingual clustering by leveraging the monolingual data setsD1 . . .Dm+1, together with the translation dictionaries t(w, i, j) learned from the translation data. Figure 1 shows the algorithm that learns a cross-lingual clustering. The algorithm first prepares a multilingual corpus, as follows: for each sentence s in the monolingual data Di, for each word in s, with probability α, we replace the word with its translation into some randomly chosen language. Once this data is created, we can easily obtain a cross-lingual clustering. Figure 1 shows the complete algorithm. The intuition behind this method is that by creating the crosslingual data in this way, we bias the clustering al-\ngorithm towards putting words that are translations of each other in the same cluster."
  }, {
    "heading": "3.2 Treebank Lexicalization",
    "text": "We now describe how to introduce lexical representations φ(l)(x, y) to the model. Our approach is simple: we take the treebank data T1 . . . Tm for the m source languages, together with the translation lexicons t(w, i,m + 1). For any word w in the source treebank data, we can look up its translation t(w, i,m+ 1) in the lexicon, and add this translated form to the underlying sentence. Features can now consider lexical identities derived in this way. In many cases the resulting translation will be the NULL word, leading to the absence of lexical features. However, the representations φ(p)(x, y) and φ(c)(x, y) still apply in this case, so the model is robust to some words having a NULL translation.\n3.3 Integration with the Density-Driven Projection Method of Rasooli and Collins (2015)\nIn this section we describe a method for integrating our approach with the cross-lingual transfer method of Rasooli and Collins (2015), which makes use of density-driven projections.\nIn annotation projection methods (Hwa et al., 2005; McDonald et al., 2011), it is assumed that we have translation data Bi,j for a source and target language, and that we have a dependency parser in the source language Li. The translation data consists of pairs (e, f) where e is a source language sentence, and f is a target language sentence. A method such as GIZA++ is used to derive an alignment between the words in e and f , for each sentence pair; the source language parser is used to parse e. Each dependency in e is then potentially transferred through the alignments to create a dependency in the target sentence f . Once dependencies have been transferred in this way, a dependency parser can be trained on the dependencies in the target language.\nThe density-driven approach of Rasooli and Collins (2015) makes use of various definitions of “density” of the projected dependencies. For example, P100 is the set of projected structures where the projected dependencies form a full projective parse tree for the sentence; P80 is the set of projected\nstructures where at least 80% of the words in the projected structure are a modifier in some dependency. An iterative training process is used, where the parsing algorithm is first trained on the set T100 of complete structures, and where progressively less dense structures are introduced in learning.\nWe integrate our approach with the density-driven approach of Rasooli and Collins (2015) as follows: consider the treebanks T1 . . . Tm created using the lexicalization method of §3.2. We add all trees in these treebanks to the set P100 of full trees used to initialize the method of Rasooli and Collins (2015). In addition we make use of the representations φ(p), φ(c) and φ(l), throughout the learning process."
  }, {
    "heading": "4 Experiments",
    "text": "This section first describes the experimental settings, then reports results."
  }, {
    "heading": "4.1 Data and Tools",
    "text": "Data In the first set of experiments, we consider 7 European languages studied in several pieces of previous work (Ma and Xia, 2014; Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016a; Lacroix et al., 2016). More specifically, we use the 7 European languages in the Google universal treebank (v.2; standard data) (McDonald et al., 2013). As in previous work, gold part-of-speech tags are used for evaluation. We use the concatenation of the treebank training sentences, Wikipedia data and the Bible monolingual sentences as our monolingual raw text. Table 3 shows statistics for the monolingual data. We use the Bible from Christodouloupoulos and Steedman (2014), which includes data for 100 languages, as the source of translations. We also conduct experiments with the Europarl data (both with the original set and a subset of it with the same size as the Bible) to study the effects of translation data size and domain shift. The statistics for translation data is shown in Table 4.\nIn a second set of experiments, we run experiments on 38 datasets (26 languages) in the more recent Universal Dependencies v1.3 corpus (Nivre et al., 2016). The full set of languages we use is listed in Table 9.4 We use the Bible as the translation data,\n4We excluded languages that are not completely present in the Bible of Christodouloupoulos and Steedman (2014) (An-\nand Wikipedia as the monolingual text. The standard training, development and test set splits are used in all experiments. The development sets are used for analysis, given in §5 of this paper.\nBrown Clustering Algorithm We use the off-theshelf Brown clustering tool5 (Liang, 2005) to train monolingual Brown clusters with 500 clusters. The monolingual Brown clusters are used as features over lexicalized values created in φ(l), and in selftraining experiments. We train our cross-lingual clustering with the off-the-shelf-tool6 from Stratos et al. (2015). We set the window size to 2 with a cluster size of 500.7\nParsing Model We use the k-beam arc-eager dependency parser of Rasooli and Tetreault (2015), which is similar to the model of Zhang and Nivre (2011). We modify the parser such that it can use both monolingual and cross-lingual word cluster features. The parser is trained using the the maximum violation update strategy (Huang et al., 2012). We use three epochs of training for all experiments. We use the DEPENDABLE Tool (Choi et al., 2015) to calculate significance tests on several of the comparisons (details are given in the captions to tables 5, 6, and 9).\ncient Greek, Basque, Catalan, Galician, Gothic, Irish, Kazakh, Latvian, Old Church Slavonic, and Tamil). We also excluded Arabic, Hebrew, Japanese and Chinese, as these languages have tokenization and/or morphological complexity that goes beyond the scope of this paper. Future work should consider these languages.\n5https://github.com/percyliang/ brown-cluster\n6https://github.com/karlstratos/singular 7Usually the original Brown clusters are better features for parsing but their training procedure does not scale well to large datasets. Therefore we use the more efficient algorithm from Stratos et al. (2015) on the larger cross-lingual datasets to obtain word clusters.\nData Lang. en de es fr it pt sv\nBible tokens 1.5M 665K 657K 732K 613K 670K 696K types 16K 20K 27K 22K 29K 29K 23K\nEU-S tokens 718K 686K 753K 799K 717K 739K 645K types 22K 41K 31K 27K 30K 32K 39K\nEuroparl tokens 56M 50M 57M 62M 55M 56M 46M types 133K 400K 195K 153K 188K 200K 366K\nTable 4: Statistics for the Bible, sampled Europarl (EUS) and Europarl datasets. Each individual Bible text file from Christodouloupoulos and Steedman (2014) consists of 24720 sentences, except for English datasets, where two translations into English are available, giving double the amount of data. Each text file from the sampled Europarl datasets consists of 25K sentences and Europarl has approximately 2 million sentences per language pair.\nL Baseline This paper using the Bible\n§3.1 §3.2 §3.3 LAS UAS LAS UAS LAS UAS LAS UAS en 58.2 65.5 65.0 72.3 66.3 74.0 70.8 76.5 de 49.7 59.1 51.6 59.7 54.9 62.6 65.2 72.8 es 68.3 77.2 73.1 79.6 76.6 81.9 76.7 82.1 fr 67.3 77.7 69.5 79.9 74.4 81.9 75.8 82.2 it 69.7 79.4 71.6 80.0 74.7 82.8 76.1 83.3 pt 71.5 77.5 76.9 81.5 81.0 84.4 81.3 84.7 sv 62.6 74.2 63.5 75.1 68.2 78.7 71.2 80.3 avg 63.9 72.9 67.3 75.5 70.9 78.1 73.9 80.3\nTable 5: Performance of different models in this paper; first the baseline model, then models trained using the methods described in sections §3.1–3.3. All results make use of the Bible as a source of translation data. All differences in UAS and LAS are statistically significant with p < 0.001 using McNemar’s test, with the exception of “de” UAS/LAS Baseline vs. 3.1 (i.e., 49.7 vs 51.6 UAS and 59.1 vs 59.7 LAS are not significant differences).\nWord alignment We use the intersected alignments from GIZA++ (Och and Ney, 2003) on translation data. We exclude sentences in translation data with more than 100 words."
  }, {
    "heading": "4.2 Results on the Google Treebank",
    "text": "Table 5 shows the dependency parsing accuracy for the baseline delexicalized approach, and for models which add 1) cross-lingual clusters (§3.1); 2) lexical features (§3.2); and 3) integration with the densitydriven method of Rasooli and Collins (2015). Each of these three steps gives significant improvements in performance. The final LAS/UAS of 73.9/80.3% is several percentage points higher than the baseline accuracy of 63.9/72.9%.\nComparison to the Density-Driven Approach using Europarl Data Table 6 shows accuracies for the density-driven approach of Rasooli and Collins (2015), first using Europarl data8 and second using the Bible alone (with no cross-lingual clusters or lexicalization). The Bible data is considerably smaller than Europarl (around 100 times smaller), and it can be seen that results using the Bible are several percentage points lower than the results for Europarl (75.7% UAS vs. 81.3% UAS). Integrating clusterbased and lexicalized features described in the current paper with the density-driven approach closes much of this gap in performance (80.3% UAS). Thus we have demonstrated that we can get close to the performance of the Europarl-based models using\n8Rasooli and Collins (2015) do not report results on English. We use the same setting to obtain the English results.\nonly the Bible as a source of translation data. Using our approach on the full Europarl data gives an average UAS of 82.9%, an improvement from the 81.3% UAS of Rasooli and Collins (2015).\nTable 6 also shows results when we use a random subset of the Europarl data, in which the number of sentences (25,000) is chosen to give a very similar size to the Bible. It can be seen that accuracies using the Bible vs. the Europarl-Sample are very similar (80.3% vs. 80.4% UAS), suggesting that the size of the translation corpus is much more important than the genre.\nComparison to Other Previous Work Table 7 compares the accuracy of our method to the following related work: 1) Ma and Xia (2014), who describe an annotation projection method based on entropy regularization; 2) Lacroix et al. (2016), who\ndescribe an annotation projection method based on training on partial trees with dynamic oracles; 3) Zhang and Barzilay (2015), who describe a method that learns cross-lingual embeddings and bilingual dictionaries from Europarl data, and uses these features in a discriminative parsing model; 4) Guo et al. (2016), who describe a method that learns crosslingual embeddings from Europarl data and uses a shift-reduce neural parser with these representations; 5) Ammar et al. (2016b)9, who use the same embeddings as Guo et al. (2016), within an LSTMbased parser; and 6) Rasooli and Collins (2015) who use the density-driven approach on the Europarl data. Our method gives significant improvements over the first three models, in spite of using the Bible translation data rather than Europarl. When using the Europarl data, our method improves the state-ofthe-art model of Rasooli and Collins (2015).\nPerformance with Automatic POS Tags For completeness, Table 8 gives results for our method with automatic part-of-speech tags. The tags are obtained using the model of Collins (2002)10 trained on the training part of the treebank dataset. Future work should study approaches that transfer POS tags in addition to dependencies."
  }, {
    "heading": "4.3 Results on the Universal Dependencies v1.3",
    "text": "Table 9 gives results on 38 datasets (26 languages) from the newly released universal dependencies corpus (Nivre et al., 2016). Given the number of treebanks and to speed up training, we pick source lan-\n9This work was later published under a different title (Ammar et al., 2016a) without including UAS results.\n10https://github.com/rasoolims/ SemiSupervisedPosTagger\nguages that have at least 5 out of 6 common WALS properties with each target language. Our experiments are carried out using the Bible as our transla-\ntion data. As shown in Table 9, our method consistently outperforms the density-driven method of Rasooli and Collins (2015) and for many languages the accuracy of our method gets close to the accuracy of the supervised parser. In all the languages, our method is significantly better than the density-driven method using the McNemar’s test with p < 0.001.\nAccuracy on some languages (e.g., Persian (fa) and Turkish (tr)) is low, suggesting that future work should consider more powerful techniques for these languages. There are two important facts to note. First, the number of fully projected trees in some languages is so low such that the density-driven approach cannot start with a good initialization to fill in partial dependencies. For example Turkish has only one full tree with only six words, Persian with 25 trees, and Dutch with 28 trees. Second, we observe very low accuracies in supervised parsing for some languages in which the number of training sentences is very low (for example, Latin has only 1326 projective trees in the training data)."
  }, {
    "heading": "5 Analysis",
    "text": "We conclude with some analysis of the accuracy of the method on different dependency types, across the different languages. Table 10 shows precision and recall on different dependency types in English (using the Google treebank). The improvements in accuracy when moving from the delexicalized model to the Bible or Europarl model apply quite uniformly across all dependency types, with all dependency labels showing an improvement.\nTable 11 shows the dependency accuracy sorted by part-of-speech tag of the modifier in the dependency. We break the results into three groups: G1 languages, where UAS is at least 80% overall; G2 languages, where UAS is between 70% and 80%; and G3 languages, where UAS is less than 70%. There are some quite significant differences in accuracy depending on the POS of the modifier word. In the G1 languages, for example, ADP, DET, ADJ, PRON and AUX all have over 85% accuracy; in contrast NOUN, VERB, PROPN, ADV all have accuracy that is less than 80%. A very similar pattern is seen for the G2 languages, with ADP, DET, ADJ, and AUX again having greater than 85% accuracy, but NOUN, VERB, PROPN and ADV having lower\naccuracies. These results suggest that difficulty varies quite significantly depending on the modifier POS, and different languages show the same patterns of difficulty with respect to the modifier POS.\nTable 12 shows accuracy sorted by the POS tag of the head word of the dependency. By far the most frequent head POS tags are NOUN, VERB, and PROPN (accounting for 85% of all dependencies). The table also shows that for all language groups G1, G2, and G3, the f1 scores for NOUN, VERB and PROPN are generally higher than the f1 scores for other head POS tags.\nFinally, Table 13 shows precision and recall for different dependency labels for the G1, G2 and G3 languages. We again see quite large differences in accuracy between different dependency labels. The G1 language dependencies, with the most frequent label nmod, has an F-score of 75.2. In contrast, the second most frequent label, case, has 93.7 F-score. Other frequent labels with low accuracy in the G1 languages are advmod, conj, and cc."
  }, {
    "heading": "6 Related Work",
    "text": "There has recently been a great deal of work on syntactic transfer. A number of methods (Zeman and Resnik, 2008; McDonald et al., 2011; Cohen et al., 2011; Naseem et al., 2012; Täckström et al., 2013; Rosa and Zabokrtsky, 2015) directly learn delexicalized models that can be trained on universal treebank data from one or more source languages, then applied to the target language. More recent work has introduced cross-lingual representations— for example cross-lingual word-embeddings—that can be used to improve performance (Zhang and Barzilay, 2015; Guo et al., 2015; Duong et al., 2015a; Duong et al., 2015b; Guo et al., 2016; Ammar et al., 2016b). These cross-lingual representations are usually learned from parallel translation data. We show results of several methods (Zhang and Barzilay, 2015; Guo et al., 2016; Ammar et al., 2016b) in Table 7 of this paper.\nThe annotation projection approach, where dependencies from one language are transferred through translation alignments to another language, has been considered by several authors (Hwa et al., 2005; Ganchev et al., 2009; McDonald et al., 2011; Ma and Xia, 2014; Rasooli and Collins, 2015;\nLacroix et al., 2016; Agić et al., 2016; Schlichtkrull and Søgaard, 2017).\nOther recent work (Tiedemann et al., 2014; Tiedemann, 2015; Tiedemann and Agić, 2016) has considered treebank translation, where a statistical machine translation system (e.g., MOSES (Koehn et al., 2007)) is used to translate a source language treebank into the target language, complete with reordering of the input sentence. The lexicalization\napproach described in this paper is a simple form of treebank translation, where we use a word-to-word translation model. In spite of its simplicity, it is an effective approach.\nA number of authors have considered incorporating universal syntactic properties, such as dependency order, by selectively learning syntactic attributes from similar source languages (Naseem et al., 2012; Täckström et al., 2013; Zhang and Barzilay, 2015; Ammar et al., 2016a). Selective sharing of syntactic properties is complementary to our work. We used a very limited form of selective sharing, through the WALS properties, in our baseline approach. More recently, Wang and Eisner (2016) have developed a synthetic treebank as a universal treebank to help learn parsers for new languages. Martı́nez Alonso et al. (2017) try a very different approach in cross-lingual transfer by using a ranking approach.\nA number of authors (Täckström et al., 2012; Guo et al., 2015; Guo et al., 2016) have introduced methods that learn cross-lingual representations that are then used in syntactic transfer. Most of these approaches introduce constraints to a clustering or embedding algorithm that encourage words that are translations of each other to have similar representations. Our method of deriving a cross-lingual cor-\npus (see Figure 1) is closely related to Duong et al. (2015a); Gouws and Søgaard (2015); and Wick et al. (2015).\nOur work has made use of dictionaries that are automatically extracted from bilingual corpora. An alternative approach would be to use hand-crafted translation lexicons, for example, PanLex (Baldwin et al., 2010) (e.g. see Duong et al. (2015b)), which covers 1253 language varieties, Google translate (e.g., see Ammar et al. (2016c)), or Wiktionary (e.g., see Durrett et al. (2012) for an approach that uses Wiktionary for cross-lingual transfer). These resources are potentially very rich sources of information. Future work should investigate whether they can give improvements in performance."
  }, {
    "heading": "7 Conclusions",
    "text": "We have described a method for cross-lingual syntactic transfer that is effective in a scenario where a large amount of translation data is not available. We have introduced a simple, direct method for deriving cross-lingual clusters, and for transferring lexical information across treebanks for different languages. Experiments with this method show that the method gives improved performance over previous work that makes use of Europarl, a much larger translation corpus."
  }, {
    "heading": "Acknowledgement",
    "text": "We thank the anonymous reviewers for their valuable feedback. We also thank Ryan McDonald, Karl Stratos and Oscar Täckström for their comments on the first draft."
  }, {
    "heading": "Appendix A Parsing Features",
    "text": "We used all features in Zhang and Nivre (2011, Table 1 and 2), which describes features based on the word and part-of-speech at various positions on the stack and buffer of the transition system. In addition, we expand the Zhang and Nivre (2011, Table 1) features to include clusters, as follows: whenever a feature tests the part-of-speech for a word in position 0 of the stack or buffer, we introduce features that replace the part-of-speech with the Brown clustering bit-string of length 4 and 6. Whenever a feature tests for the word identity at position 0 of the stack or buffer, we introduce a cluster feature that replaces the word with the full cluster feature. We take the cross product of all features corresponding to the choice of 4 or 6 length bit string for part-ofspeech features."
  }],
  "year": 2017,
  "references": [{
    "title": "Multilingual projection for",
    "authors": ["Željko Agić", "Anders Johannsen", "Barbara Plank", "Héctor Alonso Martı́nez", "Natalie Schluter", "Anders Søgaard"],
    "year": 2016
  }, {
    "title": "Many languages, one parser",
    "authors": ["Waleed Ammar", "George Mulcaire", "Miguel Ballesteros", "Chris Dyer", "Noah Smith."],
    "venue": "Transactions of the Association for Computational Linguistics, 4:431–444.",
    "year": 2016
  }, {
    "title": "One parser, many languages",
    "authors": ["Waleed Ammar", "George Mulcaire", "Miguel Ballesteros", "Chris Dyer", "Noah A. Smith."],
    "venue": "arXiv preprint arXiv:1602.01595v1.",
    "year": 2016
  }, {
    "title": "Massively multilingual word embeddings",
    "authors": ["Waleed Ammar", "George Mulcaire", "Yulia Tsvetkov", "Guillaume Lample", "Chris Dyer", "Noah A. Smith."],
    "venue": "arXiv preprint arXiv:1602.01925.",
    "year": 2016
  }, {
    "title": "Panlex and LEXTRACT: Translating all",
    "authors": ["Timothy Baldwin", "Jonathan Pool", "Susan M Colowick"],
    "year": 2010
  }, {
    "title": "A massively parallel corpus: The Bible in 100 languages",
    "authors": ["Christos Christodouloupoulos", "Mark Steedman."],
    "venue": "Language Resources and Evaluation, pages 1–21.",
    "year": 2014
  }, {
    "title": "Unsupervised structure prediction with non-parallel multilingual guidance",
    "authors": ["Shay B. Cohen", "Dipanjan Das", "Noah A. Smith."],
    "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 50–61, Edinburgh, Scotland,",
    "year": 2011
  }, {
    "title": "Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms",
    "authors": ["Michael Collins."],
    "venue": "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1–8. Association for",
    "year": 2002
  }, {
    "title": "Cross-lingual transfer for unsupervised dependency parsing without parallel data",
    "authors": ["Long Duong", "Trevor Cohn", "Steven Bird", "Paul Cook."],
    "venue": "Proceedings of the Nineteenth Conference on Computational Natural Language Learning, pages 113–122, Beijing, China,",
    "year": 2015
  }, {
    "title": "A neural network model for low-resource universal dependency parsing",
    "authors": ["Long Duong", "Trevor Cohn", "Steven Bird", "Paul Cook."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 339–348, Lisbon, Por-",
    "year": 2015
  }, {
    "title": "Syntactic transfer using a bilingual lexicon",
    "authors": ["Greg Durrett", "Adam Pauls", "Dan Klein."],
    "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1–11, Jeju Island,",
    "year": 2012
  }, {
    "title": "Dependency grammar induction via bitext projection constraints",
    "authors": ["Kuzman Ganchev", "Jennifer Gillenwater", "Ben Taskar."],
    "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-",
    "year": 2009
  }, {
    "title": "Simple taskspecific bilingual word embeddings",
    "authors": ["Stephan Gouws", "Anders Søgaard."],
    "venue": "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1386–1390, Den-",
    "year": 2015
  }, {
    "title": "Cross-lingual dependency parsing based on distributed representations",
    "authors": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th Inter-",
    "year": 2015
  }, {
    "title": "A representation learning framework for multi-source transfer parsing",
    "authors": ["Jiang Guo", "Wanxiang Che", "David Yarowsky", "Haifeng Wang", "Ting Liu."],
    "venue": "The Thirtieth AAAI Conference on Artificial Intelligence (AAAI-16), Phoenix, Arizona, USA.",
    "year": 2016
  }, {
    "title": "Structured perceptron with inexact search",
    "authors": ["Liang Huang", "Suphan Fayong", "Yang Guo."],
    "venue": "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142–",
    "year": 2012
  }, {
    "title": "Bootstrapping parsers via syntactic projection across parallel texts",
    "authors": ["Rebecca Hwa", "Philip Resnik", "Amy Weinberg", "Clara Cabezas", "Okan Kolak."],
    "venue": "Natural language engineering, 11(03):311–325.",
    "year": 2005
  }, {
    "title": "Moses: Open source toolkit for statistical machine translation",
    "authors": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico"],
    "venue": "In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstra-",
    "year": 2007
  }, {
    "title": "Europarl: A parallel corpus for statistical machine translation",
    "authors": ["Philipp Koehn."],
    "venue": "MT summit, volume 5, pages 79–86.",
    "year": 2005
  }, {
    "title": "Frustratingly easy cross-lingual transfer for transition-based dependency parsing",
    "authors": ["Ophélie Lacroix", "Lauriane Aufrant", "Guillaume Wisniewski", "François Yvon."],
    "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Com-",
    "year": 2016
  }, {
    "title": "Semi-supervised learning for natural language",
    "authors": ["Percy Liang."],
    "venue": "Master’s thesis, Massachusetts Institute of Technology.",
    "year": 2005
  }, {
    "title": "Unsupervised dependency parsing with transferring distribution via parallel guidance and entropy regularization",
    "authors": ["Xuezhe Ma", "Fei Xia."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
    "year": 2014
  }, {
    "title": "Parsing universal dependencies without training",
    "authors": ["Héctor Martı́nez Alonso", "Željko Agić", "Barbara Plank", "Anders Søgaard"],
    "venue": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume",
    "year": 2017
  }, {
    "title": "Effective self-training for parsing",
    "authors": ["David McClosky", "Eugene Charniak", "Mark Johnson."],
    "venue": "Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,",
    "year": 2006
  }, {
    "title": "Multi-source transfer of delexicalized dependency parsers",
    "authors": ["Ryan McDonald", "Slav Petrov", "Keith Hall."],
    "venue": "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK., July. Associ-",
    "year": 2011
  }, {
    "title": "Universal dependency annotation for multilingual parsing",
    "authors": ["Ryan McDonald", "Joakim Nivre", "Yvonne QuirmbachBrundage", "Yoav Goldberg", "Dipanjan Das"],
    "venue": "In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics",
    "year": 2013
  }, {
    "title": "Selective sharing for multilingual dependency parsing",
    "authors": ["Tahira Naseem", "Regina Barzilay", "Amir Globerson."],
    "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 629–637. Association",
    "year": 2012
  }, {
    "title": "Universal Dependencies 1.3. LINDAT/CLARIN digital library at Institute of Formal and Applied Linguistics, Charles University in Prague",
    "authors": ["Joakim Nivre", "Željko Agić", "Lars Ahrenberg", "Maria Jesus Aranzabe", "Masayuki Asahara"],
    "year": 2016
  }, {
    "title": "A systematic comparison of various statistical alignment models",
    "authors": ["Franz Josef Och", "Hermann Ney."],
    "venue": "Computational Linguistics, 29(1):19–51.",
    "year": 2003
  }, {
    "title": "Density-driven cross-lingual transfer of dependency parsers",
    "authors": ["Mohammad Sadegh Rasooli", "Michael Collins."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 328–338, Lisbon, Portugal, September. Associ-",
    "year": 2015
  }, {
    "title": "Yara parser: A fast and accurate dependency parser",
    "authors": ["Mohammad Sadegh Rasooli", "Joel Tetreault."],
    "venue": "arXiv preprint arXiv:1503.06733.",
    "year": 2015
  }, {
    "title": "Klcpos3 a language similarity measure for delexicalized parser",
    "authors": ["Rudolf Rosa", "Zdenek Zabokrtsky"],
    "year": 2015
  }, {
    "title": "Crosslingual dependency parsing with late decoding for truly low-resource languages",
    "authors": ["Michael Schlichtkrull", "Anders Søgaard."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1,",
    "year": 2017
  }, {
    "title": "Model-based word embeddings from decompositions of count matrices",
    "authors": ["Karl Stratos", "Michael Collins", "Daniel Hsu."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Nat-",
    "year": 2015
  }, {
    "title": "Cross-lingual word clusters for direct transfer of linguistic structure",
    "authors": ["Oscar Täckström", "Ryan McDonald", "Jakob Uszkoreit."],
    "venue": "Proceedings of the 2012 conference of the North American chapter of the association for computational linguistics: Human language",
    "year": 2012
  }, {
    "title": "Target language adaptation of discriminative transfer parsers",
    "authors": ["Oscar Täckström", "Ryan McDonald", "Joakim Nivre."],
    "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
    "year": 2013
  }, {
    "title": "Synthetic treebanking for cross-lingual dependency parsing",
    "authors": ["Jörg Tiedemann", "Željko Agić."],
    "venue": "Journal of Artificial Intelligence Research, 55:209–248.",
    "year": 2016
  }, {
    "title": "Treebank translation for cross-lingual parser induction",
    "authors": ["Jörg Tiedemann", "Željko Agić", "Joakim Nivre."],
    "venue": "Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pages 130–140, Ann Arbor, Michigan, June. Association for",
    "year": 2014
  }, {
    "title": "Improving the cross-lingual projection of syntactic dependencies",
    "authors": ["Jörg Tiedemann."],
    "venue": "Nordic Conference of Computational Linguistics NODALIDA 2015, pages 191–199.",
    "year": 2015
  }, {
    "title": "The galactic dependencies treebanks: Getting more data by synthesizing new languages",
    "authors": ["Dingquan Wang", "Jason Eisner."],
    "venue": "Transactions of the Association for Computational Linguistics, 4:491–505.",
    "year": 2016
  }, {
    "title": "Minimally-constrained multilingual embeddings via",
    "authors": ["Michael Wick", "Pallika Kanani", "Adam Pocock"],
    "year": 2015
  }, {
    "title": "Annotation projection-based representation learning for crosslingual dependency parsing",
    "authors": ["Min Xiao", "Yuhong Guo."],
    "venue": "Proceedings of the Nineteenth Conference on Computational Natural Language Learning, pages 73–82, Beijing, China,",
    "year": 2015
  }, {
    "title": "Cross-language parser adaptation between related languages",
    "authors": ["Daniel Zeman", "Philip Resnik."],
    "venue": "Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, pages 35–42.",
    "year": 2008
  }, {
    "title": "Hierarchical low-rank tensors for multilingual transfer parsing",
    "authors": ["Yuan Zhang", "Regina Barzilay."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1857–1867, Lisbon, Portugal, September. Association",
    "year": 2015
  }, {
    "title": "Transition-based dependency parsing with rich non-local features",
    "authors": ["Yue Zhang", "Joakim Nivre."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 188–193, Portland, Ore-",
    "year": 2011
  }],
  "id": "SP:bcab879f6b2d8b647f50b9878912d83d0fc84a7c",
  "authors": [{
    "name": "Mohammad Sadegh Rasooli",
    "affiliations": []
  }, {
    "name": "Michael Collins",
    "affiliations": []
  }],
  "abstractText": "We describe a simple but effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where a large amount of translation data is not available. This method makes use of three steps: 1) a method for deriving cross-lingual word clusters, which can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of translation data is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of translation data show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets from the Universal Dependencies corpora.",
  "title": "Cross-Lingual Syntactic Transfer with Limited Resources"
}