{
  "sections": [{
    "text": "We propose a new variant of the top arm identification problem, top feasible arm identification, where there are K arms associated with D-dimensional distributions and the goal is to find m arms that maximize some known linear function of their means subject to the constraint that their means belong to a given set P Ă RD. This problem has many applications since in many settings, feedback is multi-dimensional and it is of interest to perform constrained maximization. We present problem-dependent lower bounds for top feasible arm identification and upper bounds for several algorithms. Our most broadly applicable algorithm, TF-LUCB-B, has an upper bound that is loose by a factor ofOpD logpKqq. Many problems of practical interest are twodimensional and, for these, it is loose by a factor of OplogpKqq. Finally, we conduct experiments on synthetic and real-world datasets that demonstrate the effectiveness of our algorithms. Our algorithms are superior both in theory and in practice to a naive two-stage algorithm that first identifies the feasible arms and then applies a best arm identification algorithm to the feasible arms."
  }, {
    "heading": "1 Introduction",
    "text": "In the top arm identification problem in multi-armed bandits, there areK scalar-valued distributions (also referred to as arms) and an agent plays a sequential game where, at each round, the agent chooses (or “pulls\") one of the arms and observes an i.i.d. realization from it. At the end of the game, the agent outputs the set of m arms believed to have the largest means. This problem\nProceedings of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR: Volume 89. Copyright 2019 by the author(s).\nhas applications in areas such as crowdsourcing, A/B testing, and clinical trials.\nWhile top arm identification considers settings where the feedback is scalar-valued and the goal is maximization, in many applications, the feedback is multidimensional and it is of interest to perform constrained maximization. For example, in crowdsourcing, an important challenge is to identify high-quality workers that complete work at a suitable pace (e.g., below 15 seconds on average) and, in clinical trials, it is of interest to efficiently find drugs that are most likely to be effective and have an acceptably low probability of causing an adverse effect.\nIn this paper, we introduce top feasible arm identification for situations where the feedback is multidimensional and the goal is constrained maximization. In this problem, there are K arms and each arm i is associated with a D-dimensional distribution νi that has mean µi. At each round t “ 1, 2, . . ., the agent chooses an arm It and observes an independent random vector drawn from νIt . For given P Ă RD, r P RD, m ď K, and δ P p0, 1q, the goal of the agent is to identify m arms that maximize rJµi subject to the constraint µi P P , with probability at least 1 ´ δ, in the fewest number of samples possible.\nWe make several contributions to this problem. We prove problem-dependent lower bounds for top feasible arm identification. We also propose a family of algorithms TF-LUCB, where each instance is specified by a test for feasibility TestF, and we prove a master theorem that characterizes an upper bound for TF-LUCB in terms of the subroutine TestF. Finally, we use this master theorem to prove upper bounds for several algorithms. Our most broadly applicable algorithm, TF-LUCB-B, has an upper bound that is loose by a factor of OpD logpKqq. Many problems of practical interest are two-dimensional and for these, it is loose by a factor of OplogpKqq. Notably, our algorithms are superior both in theory and in practice to a naive two-stage algorithm that first identifies the feasible arms and then applies a best arm identification algorithm to the feasible arms. The sample complexity of such a two-stage algorithm can be arbitrarily larger\nthan the sample complexity of our algorithms and, indeed, in our experiments we improve on such a baseline by as much as a factor of 4.5."
  }, {
    "heading": "2 Related Work",
    "text": "Top arm identification has received a lot of attention in recent years (Mannor and Tistisklis, 2004; Audibert and Bubeck, 2010; Gabillon et al., 2012; Kalyanakrishnan et al., 2012; Bubeck et al., 2013; Chen et al., 2014; Jamieson et al., 2014). Most work considers the case where arms are scalar-valued and, thus, their results cannot be applied to our problem setting. Recently, Chen et al. (2017) proposed the general sampling problem, which does encompass a variant of top feasible arm identification. Their work differs from ours in several significant ways. First, in the work of Chen et al. (2017), the agent samples from one dimension of one arm at a time, whereas in our setting pulling an arm yields a random D-dimensional vector. Second, Chen et al. (2017) assume that the arms are isotropic Gaussian, whereas we assume each arm is a multi-dimensional sub-Gaussian distribution. Finally, their algorithm (see their Algorithm 7) is impractical for moderate values of δ in the fixed confidence setting since its first stage consists of a uniform allocation strategy that terminates when the confidence bounds of all of the means are small enough to determine which of the arms are in the top feasible m with probability at least 0.99.\nAuer et al. (2016) also consider a setting where arms are multi-dimensional. Their goal is to determine the Pareto front of the arms, which is quite different from the task of constrained maximization in top feasible arm identification. We also remark that they use an elimination algorithm, whereas we adapt the LUCB algorithm from Kalyanakrishnan et al. (2012) to our setting.\nRecently, Katz-Samuels and Scott (2018) proposed the feasible arm identification problem, in which there are K multi-dimensional distributions and a given polyhedron, and the goal is to determine which of the distributions have means belonging to the polyhedron. By contrast, in top feasible arm identification, the goal is to find a collection of arms whose means are feasible and maximize some linear function. In short, Katz-Samuels and Scott (2018) deal with feasibility while the current paper deals with constrained maximization. Furthermore, whereas Katz-Samuels and Scott (2018) consider the fixed budget setting (in which there is a fixed number of rounds), we consider the fixed confidence setting. These differences require the development of new ideas and algorithms.\nWe also note that top feasible arm identification differs from best-arm identification in linear bandits (Soare\net al., 2014). In best-arm identification in linear bandits, each arm i is associated with a known feature vector xi and the reward of arm i has mean xJi θ where θ is unknown. In our setting, each arm is associated with a D-dimensional distribution and the goal is to maximize some known linear function f : RD ÝÑ R subject to the constraint that µi P P ."
  }, {
    "heading": "3 Problem Statement",
    "text": "Notation. For n P N, let rns “ t1, . . . , nu. Let U be a finite set and f be a scalar-valued function with domain containing U , and define maxplqxPUfpxq –\n#\nmax txPU :|tyPU :fpyqěfpxqu|ěl´1u\nfpxq : |U | ě l\n´8 : otherwise .\nIn words, maxplqxPUfpxq is the value of the lth largest x P U under fp¨q and if |U | ă l, then it is ´8. For a set A Ă RD, let BA denote the boundary of A, i.e., BA “ sAzA˝ (where sA denotes the closure of A and A˝ denotes the interior of A). Let x P RD, and define distpx, Aq “ infyPA }x´ y}2. Let γ ą 0, and define Bγpxq “ ty : }x´ y}2 ă γu. Let xi denote the ith entry of x and for yi P RD, let yi,j denote the jth entry of yi. Let ei denote the ith standard basis vector. We use “whp\" for “with high probability\" and “wrt\" for “with respect to.\"\nProblem Parameters. Suppose that there are K arms associated with distributions ν1, . . . , νK over RD that have means µ1, . . . ,µK P RD, and let ν “ pν1, . . . , νKq. At each round t “ 1, 2, . . ., an agent chooses an arm It and observes an independent draw Xt „ νIt .\nLet P Ă RD denote a nonempty set such that P ‰ RD. Let r denote a reward vector, which is fixed, known, and the same across all arms. We assume }r}2 “ 1. We say that rJµi is the expected reward of arm i. Let m denote the number of top feasible arms desired. We denote an instance of the top feasible arm identification problem by pν, P, r,mq. Let Prν (Eν) denote the probability measure (expected value) associated with the problem instance pν, P, r,mq.\nDefine FEAS “ ti P rKs : µi P P u, INFEAS “ FEASc, and\nOPT “ ti P FEAS : rJµi ě maxpmqjPFEAS r Jµju, SUBOPT “ ti P rKs : rJµi ă maxpmqjPFEAS r Jµju.\nWe say that an arm j is suboptimal if rJµj ă max\npmq iPFEASr Jµi; we say that an arm j is feasible (infeasible) if µj P P (µj R P ). We note that, in general, SUBOPT and INFEAS are not disjoint, and that when\nthere are fewer than m arms that are feasible (µi P P ), SUBOPT “ H.\nWe consider the following class of problems: M–\ntpν, P, r,mq : p@i : µi R BP q and\npmaxpmqiPFEASr Jµi ą maxpm`1qjPFEASr Jµj _ |FEAS | ď mqu.\nIn words,M consists of problems where the means of the arms do not belong to the boundary of P and either there are m or fewer feasible arms or the mth largest reward of a feasible arm and the pm ` 1qth largest reward of a feasible arm are distinct. It is possible to drop the assumption pν, P, r,mq PM by allowing for a tolerance for suboptimality or infeasibility, and we describe this extension in the supplemental material.\nGoal. We consider the fixed confidence setting with a novel criterion for correctness. An algorithm A is associated with a policy that determines which arm It P rKs is chosen at time t, a finite stopping time τ wrt I1,X1, I2,X2, . . . (i.e., Prνpτ ă 8q “ 1) that determines when the algorithm stops, and an outputted partition of the arms ppO, pS,pIq with pOY pSYpI “ rKs.\nA standard criterion of correctness for an algorithm is δ- PAC, which we now define. Definition 1. Let δ P p0, 1q. We say an algorithm A is δ- PAC wrtM if for any problem pν, P, r,mq belonging toM, A outputs pO Ă rKs such that PrνppO “ OPTq ě 1´ δ.\nA standard goal is to design algorithms that are δ- PAC wrt M and that minimize τ . We propose a novel criterion δ- PAC-EXPLANATORY and aim to design algorithms that are δ- PAC-EXPLANATORY wrtM and that minimize τ . Definition 2. Let δ P p0, 1q. We say an algorithm A is δ- PAC-EXPLANATORY wrtM if for any problem pν, P, r,mq belonging toM, A outputs a triple ppO, pS,pIq of disjoint sets such that pOY pSYpI “ rKs and\nPrνppO “ OPT and ppS,pIq P Valid-Partitionsq ě 1´ δ\nwhere Valid-Partitions –\ntpS, Iq :S Ă SUBOPT, I Ă INFEAS, S X I “ H, S Y I “ OPTcu.\nTo identify arms in OPT, an agent must rule out every i P OPTc as suboptimal or infeasible. When SUBOPTX INFEAS ‰ H, there are arms that can be ruled out in multiple ways. Valid-Partitions captures the various correct ways to partition the arms in OPTc to distinguish them from OPT. Thus, our notion, δ- PAC-EXPLANATORY, is slightly stronger than δ- PAC since it essentially requires that whp (i) an\nalgorithm output the correct top m feasible arms and (ii) that it provide a correct reason for rejecting each arm (either that it is suboptimal or infeasible). We remark that it is natural to require only one reason for rejecting an arm because once an algorithm identifies an arm as infeasible (suboptimal), there is no reason to keep pulling it to determine whether it is suboptimal (infeasible). Furthermore, in most problems and for most algorithms, if an arm is infeasible and suboptimal, showing one of these is easier than showing the other.\nThis notion is practically relevant since in many applications it is of interest to provide a reason to reject an arm. For example, in crowdsourcing, it might be necessary to provide a worker with a reason for why she was not hired. In clinical trials, it might be useful for the clinician to know why a drug is rejected. Furthermore, as we discuss in the supplemental material, we conjecture that there is a small gap between δ- PAC and δ- PAC-EXPLANATORY algorithms.\nSub-Gaussian Assumption. We assume that each νi is a multi-dimensional sub-Gaussian distribution, which we now define. LetX be a scalar random variable and X P RD a random vector. We say that X is sub-Gaussian if E exppX 2\nσ2 q ď 2 for some σ ą 0 and X P RD is sub-Gaussian if for all a P RD, XJa is sub-Gaussian. The sub-Gaussian norms of X and X are defined respectively as:\n}X}ψ2 “ inftσ ą 0 : E expp X2\nσ2 q ď 2u,\n}X}ψ2 “ sup aPRD:}a}2“1\n› ›XJa › ›\nψ2 ."
  }, {
    "heading": "X is said to be σ-sub-Gaussian if }X}ψ2 ď σ and X is said to be σ-sub-Gaussian if }X}ψ2 ď σ. For the",
    "text": "remainder of this paper, we assume that ν1, . . . , νK are σ-sub-Gaussian. See Vershynin (2012); Vershynin et al. (2017) for more details."
  }, {
    "heading": "4 Lower Bounds",
    "text": "Theorem 1 gives our lower bound for δ- PAC-EXPLANATORY algorithms. Theorem 1. Let µ1, . . . ,µK P RD such that @i ‰ j P rKs : µi,1 ‰ µj,1. Define νi “ Npµi, IDq for all i P rKs. Suppose P “ RˆP 1 for some P 1 Ă RD´1 and @x P BP,@ ą 0 : B pxqXP ˝ ‰ H and B pxqXpP cq˝ ‰ H. Let r “ e1. Assume pν, P, e1,mq P M and let δ P p0, 0.1q. For any pS, Iq P Valid-Partitions, define LpS, Iq –\nÿ\niPOPT maxprmin jPS rJpµi ´ µjqs´2, distpµi, BP q´2q\n` ÿ\niPS r min jPOPT\nrJpµj ´ µiqs´2 ` ÿ iPI distpµi, P q´2.\nThen, any algorithm A that is δ- PAC-EXPLANATORY wrt M has a stopping time τ on the problem pν, P, e1,mq that satisfies\nEνrτ s ě min pS,IqPValid-Partitions\n2 15 lnp 1 2δ qLpS, Iq.\nThe conditions P “ R ˆ P 1 and r “ e1 decouple the reward and feasibility of the arms and hold in many applications. The other conditions on P remove pathological cases such as isolated points and nowhere dense sets with positive measure.\nThe lower bound is the solution of a constrained minimization problem over all the ways to distinguish the arms in OPTc from OPT, i.e., pS, Iq P Valid-Partitions. If we fix some pS, Iq P Valid-Partitions, there are three main terms in the lower bound reflecting the difficulty of identifying arms as belonging to either OPT, S, or I, respectively. Essentially, optimal arms must be shown to be feasible and to have reward greater than all arms in S, arms in S must be shown to have reward less than arms in OPT, and arms in I must be shown to be infeasible.\nThe key observation in the proof is that for a given problem pν, P, r,mq, we can associate with an algorithm A a particular pS, Iq P Valid-Partitions such that for every i P S (i P I), it is likely that A puts i P pS (i P pI). Then, using the notion of δ- PAC-EXPLANATORY, it suffices to analyze the difficulty of identifying each arm as belonging either to OPT, S, or I. The result follows by minimizing over pS, Iq P Valid-Partitions.\nWe also state a similar lower bound for algorithms that are δ- PAC wrtM. Theorem 2. Assume the conditions of Theorem 1. Define ro “ minjPOPT rJµj, rs – maxjPOPTc XFEAS r\nJµj, and L1 – ÿ\niPINFEASXSUBOPT minprro ´ rJµis´2, distpµi, P q´2q ` ÿ\niPOPT maxprrJµi ´ rss´2, distpµi, BP q´2q\n` ÿ\niPOPTc XFEAS r min jPOPT rJpµj ´ µiqs´2\n` ÿ iPINFEASXSUBOPTc distpµi, P q´2.\nThen, any algorithm A that is δ- PAC wrt M has a stopping time τ on the problem pν, P, e1,mq that satisfies\nEνrτ s ě lnp 1\n2.4δ qL1.\nThe bound in Theorem 2 suggests that δ- PAC algorithms must show that arms in OPT are feasible and\nhave reward greater than every arm in OPTcXFEAS, arms in OPTcXFEAS have reward less than arms in OPT, arms in INFEASX SUBOPTc are infeasible, and, finally, arms in INFEASX SUBOPT are either infeasible or suboptimal.\nSince any δ- PAC-EXPLANATORY algorithm wrtM is δ- PAC wrtM, we expect the lower bound in Theorem 1 to be at least as large as the lower bound in Theorem 2, and this is indeed the case. The main difference between the bounds occurs in the terms corresponding to i P OPT. Essentially, in Theorem 1, it is required to show that every arm in OPT has reward greater than all arms that are ruled out as suboptimal (i.e., belong to S), whereas in Theorem 2, these arms must only be shown to have reward greater than arms in FEASXOPTc. See the supplemental material for a more detailed discussion."
  }, {
    "heading": "5 TF-LUCB: A Family of Algorithms for Top Feasible Arm Identification",
    "text": "In this section, we introduce an algorithm for the top feasible arm identification problem. To begin, we define some notation. Let pµi,s denote the empirical mean of arm i after s samples. Let Niptq “ řt´1 s“1 1tIs “ iu denote the number of times that arm i has been selected up to round t. Let\nUpt, δq “ σ c 2 logp1{δq ` 6 log logp1{δq ` 3 log logpetq t\ndenote a confidence bound, which holds uniformly over time (see Lemma F.10 in the supplemental material) (Kaufmann et al., 2016). For the sake of simplicity, we assume henceforth that µ1, . . . ,µK P B 1\n2 p0q and\nP Ă B 1 2 p0q.\nChallenge. As suggested by Theorem 2, a major challenge in designing a nearly optimal algorithm is how to rule out with nearly optimal sample complexity an arm i that is infeasible and whose reward rJµi is too small to be among the topm feasible arms (i.e., belongs to INFEASX SUBOPT). In short, a nearly optimal algorithm must determine which is easier to show: that arm i is infeasible or that it has too small reward. Either of these can be arbitrarily more difficult to show than the other; for example, consider an infeasible arm with mean very close to the set P and a very small reward relative to the other arms. In this case, it is quite easy to show suboptimality, but very difficult to show infeasibility.\nAlgorithm. TF-LUCB is a family of algorithms, where each instance is specified by a subroutine TestF. TestFpi, sq considers the first s pulls of arm i and returns True if arm i is feasible whp, returns False if i is in-\nfeasible whp, and otherwise returns ?, indicating “don’t know.\" When the context makes it clear which distribution is involved, we simply write TestFpsq. TestF essentially solves what we will call the set membership problem, which we now define. In this problem, there is a distribution ξ over RD with mean µ P RD and a set P Ă RD. At round t “ 1, 2, . . . an algorithm B observes Xt „ ξ. An algorithm B is associated with a stopping time τ wrt pXtqtPN, and after τ rounds outputs True if it concludes that µ P P and False if it concludes that µ R P . We define the following class of set membership problems:\nN “ tpξ, P q :ξ is a distribution over RD with mean µ P B 1\n2 p0q, P Ă B 1 2 p0q, P ‰ H,µ R BP u.\nWe defer our discussion of specific algorithms for the set membership problem until the next section.\nGiven a subroutine TestF, TF-LUCB is an adaptation of LUCB (Lower Upper Confidence Bound) from Kalyanakrishnan et al. (2012) to the top feasible arm identification problem. TF-LUCB maintains three sets: arms Ft that are feasible whp, arms Gt that have not been determined whp to be feasible or infeasible, and arms Et – Ft Y Gt that have not been ruled out as infeasible whp. At round t, TF-LUCB considers TOPt, the set of m arms that have not been ruled out as infeasible whp (i.e., belong to Et) and have the top m estimated rewards. TF-LUCB uses Urpt, δq – Upt, δ2K q for a confidence bound on the reward associated with an arm. If all of the arms in TOPt are feasible whp, then it pulls an arm ht in TOPt with the smallest lower confidence bound. If only some of the arms in TOPt are determined to be feasible whp, then to avoid oversampling optimal arms, it chooses the arm ht instead by picking the arm in TOPtXGt with the smallest lower confidence bound, i.e., an arm in the top empirical m for which it is still not determined whp whether it is feasible. We note that because TOPtXEct “ H by definition of TOPt, when TOPt Ć Ft, TOPtXGt is nonempty so that the argmax operator in line 14 is welldefined. If there are arms outside of TOPt that have not been ruled out as infeasible, then the algorithm pulls an additional arm lt among these (in TOPct XEt) that maximizes an upper confidence bound on its reward. The algorithm terminates when it determines whp that each arm in TOPt is feasible and has mean larger than arms in TOPct XEt, or that the arms in TOPt are feasible and all other arms are infeasible.\nFor the sake of brevity, define the function F px, yq “ x´2 logplogpx´2qyq. Theorem 3 shows that TF-LUCB is δ- PAC-EXPLANATORY with a bound on τ that nearly matches the lower bound. Theorem 3. Let δ P p0, 1q and pν, P, r,mq PM. Suppose that for any set membership problem pξ,Rq P N\nwhere ξ is σ-sub-Gaussian and has mean µ, with probability at least 1 ´ δ2K , TestF returns True only if µ P R and False only if µ P Rc, and TestF uses at most ηpξ,Rq samples, where ηpξ,Rq is a deterministic function of ξ and R. For any pS, Iq P Valid-Partitions, define UpS, Iq –\nÿ iPS F pminjPOPT rJpµj ´ µiq,\nK\nδ q `\nÿ iPI ηpνi, P q\n` ÿ iPOPT maxpF pminjPS rJpµi ´ µjq,\nK\nδ q, ηpνi, P qq.\nThen, with probability at least 1´ δ, TF-LUCB returns ppO, pS,pIq such that pO “ OPT, ppS,pIq P Valid-Partitions, and\nτ ď min pS,IqPValid-Partitions cσ2UpS, Iq. (1)\nwhere c is a universal positive constant.\nThis upper bound has a very similar structure to the lower bound in Theorem 1. It is the solution of a constrained minimization problem over pS, Iq P Valid-Partitions. One can interpret this form as saying that TF-LUCB finds the easiest way to solve a given instance of the top feasible arm identification problem. Ignoring doubly logarithmic factors, the upper bound on the reward-associated terms is loose by a factor of logpKq.1 Theorem 3 can be interpreted as a reduction of the top feasible arm identification problem to the set membership problem and in the next section we will discuss how various algorithms for the set membership problem affect the sample complexity of TF-LUCB.\nIn light of Theorem 3, it is instructive to consider a two-stage algorithm that first identifies the collection of feasible arms and then applies a best arm identification algorithm to the feasible arms. The drawback of this two-stage approach is that there may be suboptimal infeasible arms that are much easier to rule out as suboptimal rather than infeasible. Essentially, such a twostage algorithm solves a problem instance by picking the pS1, I 1q P Valid-Partitions such that I 1 “ INFEAS, whereas TF-LUCB adapts to the problem instance to choose the best pS, Iq P Valid-Partitions. Thus, the sample complexity of such a two-stage algorithm is at least the sample complexity of TF-LUCB and can be arbitrarily larger than the sample complexity of TFLUCB. To see this, consider a problem with an arm whose mean is very close to the boundary of P , but has very small reward relative to the other arms.\nThe proof of Theorem 3 considers the pS, Iq P Valid-Partitions that minimizes (1) and analyzes the\n1We note that this logarithmic factor could be improved by adapting LUCB++ (Simchowitz et al., 2017) instead of LUCB.\nAlgorithm 1 TF-LUCB: Top-m Feasible Lower Upper Confidence Bound algorithm 1: Input: TestF, sub-Gaussian norm bound σ, confidence δ 2: for t “ 1, 2, . . . do 3: Ft ÐÝ ti P rKs : TestFpi,Niptqq “ Trueu // arms that are feasible whp 4: Gt ÐÝ ti P rKs : TestFpi,Niptqq “ ?u // arms whose feasibility is unclear whp 5: Et ÐÝ Ft YGt // arms that are not ruled out as infeasible whp 6: TOPt ÐÝ arg maxZĂEt,|Z|“minpm,|Et|q ř iPZ r J pµi,Niptq\n7: if TOPt “ Ft and Ft “ Et 8: return pTOPt,TOPct XEt, Ect q 9: if TOPt Ă Ft and miniPTOPt rJpµi,Niptq ´ UrpNiptq, δq ě maxjPTOPct XEt r J pµj,Njptq ` UrpNjptq, δq\n10: return pTOPt,TOPct XEt, Ect q 11: if TOPt Ă Ft 12: ht “ arg miniPTOPt r J pµi,Niptq ´ UrpNiptq, δq 13: if TOPt Ć Ft 14: ht “ arg miniPTOPt XGt r J pµi,Niptq ´ UrpNiptq, δq 15: if TOPct XEt ‰ H 16: lt “ arg maxjPTOPct XEt r J pµj,Njptq ` UrpNjptq, δq 17: Pull arm lt 18: Pull arm ht\nsample complexity of TF-LUCB to identify each arm as belonging to either OPT, S, or I. It is shown that at each round t, either ht or lt is a needy arm wrt to the sets OPT, S, and I (defined precisely in the supplemental material) in the sense that either it is necessary to determine whether it is feasible or it is necessary to improve our estimate of its reward.\nAllowing for a tolerance: It is possible to extend TF-LUCB to allow for a tolerance on suboptimality or infeasibility (see supplemental material). For example, if a suboptimality gap of ą 0 is permitted, then pO is correct if it satisfies @i P pO, i P FEAS and rJpµi ` ě minjPOPT r Jµj ."
  }, {
    "heading": "6 Three Instances of TF-LUCB",
    "text": "In this section, we consider three distinct general classes of sets and apply Theorem 3 to derive upper bounds for algorithms for each of these. To begin, we consider a general set P . Since there are in general no known computationally efficient algorithms for such a general setting, we then consider the computationally tractable and very rich class of polyhedra. For this setting, let P “ tx P RD : Ax ď bu denote a polyhedron, where A P RMˆD and b P RM . Let aJj denote the jth row of A. By dividing each constraint j by }aj}2, we can assume without loss of generality that }aj}2 “ 1 for all j P rM s. Finally, we consider the common case where the polyhedron has orthogonal constraints, i.e., aJi aj “ 0 for all i ‰ j P rM s, which arises for example when there is one constraint per coordinate. Note that in this case, it follows that M ď D.\nFor a general set, we propose the TestF subroutine:\nTestF-B (see Algorithm 2). It controls }pµi,t ´ µi}2 with a confidence bound Uballpt, δq – 2Upt, δ5D2K q that is constructed based on an -net argument. TestF-B returns True if the ball centered at pµi,t with radius Uballpt, δq does not intersect P c, False if this ball does not intersect P , and otherwise returns ?. The variant of TF-LUCB that uses TestF-B is called TF-LUCB-B.\nFor a polyhedron, we propose the subroutine TestF-CB, which also uses the confidence bound Uconpt, δ2 q – Upt, δ4KM q (see Algorithm 3). If it determines that µi satisfies all of the constraints whp, it returns True, if it determines that the ball centered at pµi,t with radius Uballpt, δ2 q does not intersect P whp, it returns False, and otherwise it returns ?. The variant of TF-LUCB that uses TestF-CB is called TF-LUCB-CB.\nFinally, a polyhedron with orthogonal constraints, we propose the subroutine TestF-C, which uses the confidence bound Uconpt, δq (see Algorithm 4). If it determines that µi satisfies all of the constraints whp, it returns True, if it determines that µi violates one of the constraints whp, it returns False, and otherwise it returns ?.\nThe following theorem establishes upper bounds for TF-LUCB-B, TF-LUCB-CB, and TF-LUCB-C. Theorem 4. Let δ P p0, 1q and pν, P, r,mq P M. Then, with probability at least 1´ δ,\n• TF-LUCB-B returns ppO, pS,pIq such that pO “ OPT, ppS,pIq P Valid-Partitions, τ is bounded as in (1), and ηpνi, P q is bounded as in Table 1.\n• If P is a polyhedron, TF-LUCB-CB returns ppO, pS,pIq such that pO “ OPT, ppS,pIq P\nAlgorithm 2 TestF-B: Input: arm index i, number of pulls t if distppµi,t, P cq ą Uballpt, δq return True\nAlgorithm 3 TestF-CB: Input: arm index i, number of pulls t if Apµi,t ` Uconpt, δ2 q1 ď b return True\nAlgorithm 4 TestF-C: Input: arm index i, number of pulls t if Apµi,t ` Uconpt, δq1 ď b return True\nValid-Partitions, τ is bounded as in (1), and ηpνi, P q is bounded as in Table 1.\n• If P is a polyhedron with orthogonal constraints, TF-LUCB-C returns ppO, pS,pIq such that pO “ OPT, ppS,pIq P Valid-Partitions, τ is bounded as in (1), and ηpνi, P q is bounded as in Table 1.\nIgnoring doubly logarithmic factors, the terms related to determining feasibility for TF-LUCB-B are loose by a factor of D logpKq relative to our lower bound. When D is OplogKq, then the bound is loose by a polylogarithmic factor. Since in many applications the dimension of the feedback is not very large, this bound is practically relevant. TF-LUCB-CB only requires F p distpµi, BP q, KMδ q samples to show that an arm i P OPT is feasible, which is a significant improvement over the corresponding term for TF-LUCB-B if M is polynomial in D. TF-LUCB-C differs from TF-LUCBCB in the term for showing infeasibility. The term for determining that arms in I are infeasible is loose by a factor vi logpKMq, which can be much smaller than D logpKq. In the common setting where the arms are two-dimensional with one coordinate encoding reward and the other a constraint, the upper bound is only loose by a logarithmic factor. See the supplemental material for an upper bound for TF-LUCB-C for the case of a general polyhedron."
  }, {
    "heading": "7 Experiments",
    "text": "In this section, we demonstrate experimentally the effectiveness of our algorithms. We consider the task of identifying OPT Ă rKs.\nSynthetic Datasets: In each of the experiments, we use δ “ 0.1, the last coordinate determines the reward (r “ p0, . . . , 0, 1qJ), and the rest of the coordinates\ndetermine whether x P P . We consider two kinds of reward structures: linearly varying rewards rJµi “ .95p1´ i100 q and polynomially varying rewards r\nJµi “ .95p1 ´ p i100 q\n.3q. In each trial, we randomly permute the rewards among the arms in the sense that we take a random permutation σ : rKs ÝÑ rKs and set µi,D to µσpiq,D.\nIn one set of experiments, we use 6-dimensional multivariate Gaussian distributions as arms with covariance matrix 14I. We use a simplex P “ tx P R6 :\nř5 i“1 xi ď 2, xi ě 0@i P r5su. We consider\none setting where there are four groups of arms µ1:15,1:5 “ p.1qb5,µ16:30,1:5 “ p.35qb5,µ31:45,1:5 “ p.45qb5,µ46:60,1:5 “ p´.1qb5. Only the arms in r30s are feasible. In another setting, we consider arms with arithmetically changing values. In this setting, for i P r30s, µi,1:5 “ rp.1 ` p 2´0.055 ´ .1q i 30 s\nb5, for i P r45szr30s, µi,1:5 “ r2.05{5`p3{5´ 2.05{5q i´3015 s\nb5, and for i P r60szr45s, µi,1:5 “ r´0.05`p´.3` 0.05q i´4515 s\nb5. Only the arms in r30s are feasible. We use a\n1{4 as the sub-Gaussian norm for the arms.\nIn another set of experiments, we use 5-dimensional Bernoulli distributions. We use an ordered polyhedron P “ tx P R5 : xi ď xi`1@i P r3su. We consider a setting with three groups: µ1:30,1:4 “ p0.05, 0.35, 0.65, 0.95qJ, µ31:40,1:4 “ p0.95, 0.65, 0.35, 0.05qJ, and µ41:50,1:4 “ p.7, .6, .5, .4qJ. Only the arms in r30s are feasible. We use 1 as the sub-Gaussian norm of the arms.\nCrowdsourcing Application: We consider the task of finding the most accurate crowdsourcing workers subject to the constraint that they complete tasks at a suitable average speed. We use a crowdsourcing dataset collected by Venanzi et al. (2016) in which Amazon Mechanical Turk workers determine what kind of a\nstatement a tweet makes regarding the weather: (i) positive, (ii) neutral, (iii) negative, (iv) unrelated, or (v) can’t tell. We only consider workers that have answered at least 100 questions, leaving a total of 21 workers. Here, µi,1 is the probability of being correct and µi,2 is the average amount of time required. We seek the top 3 most accurate workers who on average answer questions within 15 seconds. Whenever an algorithm pulls an arm corresponding to a worker, it samples a datapoint associated with that worker uniformly at random with replacement. We use the standard deviation of the speed measurements (135.86 sec) as the sub-Gaussian norm for the coordinate corresponding to the speed and 1 as the sub-Gaussian norm for the other coordinate. We use δ “ 0.1 and allow for a suboptimality gap of 0.05.\nClinical Trials Application: We examine the problem in clinical trials of finding the most effective drugs that also meet some safety threshold. We use data from Genovese et al. (2013) (see ARCR20 in week 16 in Table 2 and Table 3), which studies the drug secukinumab for treating rheumatoid arthritis. Each arm corresponds to a dosage level (25mg, 75mg, 150mg, 300mg, placebo) and has two attributes: the probability of being effective, µi,1, and the probability of causing an infection or infestation, µi,2. The dosage levels 25mg, 75mg, 150mg, and 300mg have averages µ1 “ p.34, .259qJ, µ2 “ p.469, .184qJ, µ3 “ p.465, .209qJ, µ4 “ p.537, .293qJ, respectively, and the placebo has average µ5 “ p.36, .36qJ. In our experiment, whenever arm i is chosen two Bernoulli random variables with means given by µi are drawn. We assume that a drug is acceptable if the probability of an infection is below .25, we set m “ 1, and we allow for a suboptimality gap of 0.05. Thus, the correct answer is either arm 2 or arm 3. We use δ “ 0.05. We use 1 as the sub-Gaussian norm.\nAlgorithms: We consider our algorithms TF-LUCBC and TF-LUCB-CB. We also consider Find-FeasibleArms-First (FFAF), which is a two-stage algorithm that first determines which of the arms are feasible and then applies LUCB to the feasible arms to find the top arms. FFAF-CB uses TestF-CB to test feasibility,\nwhereas FFAF-C uses TestF-C. We also implement an action elimination algorithm (TF-AE-C) that samples remaining arms in a round-robin fashion, eliminating an arm if it is determined using confidence bounds to be either suboptimal or infeasible. We only consider a variant that uses TestF-C since TF-AE-C has poor performance. For the experiments where D “ 2, we only run the constraint based algorithms since the - net approach uses strictly worse (by a constant factor) confidence bounds.\nDiscussion of Results: Table 2 displays our results as the number of samples required, relative to TFLUCB-C. All algorithms find a correct set of arms on every trial. TF-LUCB-C has the best sample complexity in all of the experiments, beating the FFAF algorithms by a substantial margin in many of them. In particular, FFAF-C requires nearly five times as many samples as TF-LUCB-C on the medical dataset and nearly three times as many samples on the crowdsourcing dataset. The performance gap between TF-LUCB and FFAF depends on the relative difficulty of showing arms to be suboptimal vs. infeasible. In particular, FFAF-C has poor performance on the real-world datasets because on the crowdsourcing dataset the subGaussian norm for showing feasibility is large and on the medical dataset one of the suboptimal infeasible arms is very close to the boundary. TF-AE-C performs so poorly because each suboptimal feasible arm must be pulled until at least m arms are shown to be feasible and have larger reward than it."
  }, {
    "heading": "8 Conclusion",
    "text": "We introduced a novel problem, top feasible arm identification: the first general pure exploration multi-armed bandit problem on constrained optimization. We argued that it has many real-world applications since in many settings there is multi-dimensional feedback and a natural goal is constrained optimization based on this feedback (e.g., safety and effectiveness in clinical trials); thus, we argue that our algorithms are of significant practical interest."
  }, {
    "heading": "Acknowledgements",
    "text": "We thank the anonymous reviewers for their very helpful comments. This work was supported in part by NSF grants 1422157 and 1838179."
  }],
  "year": 2019,
  "references": [{
    "title": "Best arm identification in multi-armed bandits",
    "authors": ["J.-Y. Audibert", "S. Bubeck"],
    "venue": "Conference on Learning Theory,",
    "year": 2010
  }, {
    "title": "Pareto front identification from stochastic bandit feedback",
    "authors": ["P. Auer", "C.-K. Chiang", "R. Ortner", "M. Drugan"],
    "venue": "Artificial Intelligence and Statistics,",
    "year": 2016
  }, {
    "title": "Multiple identifications in multi-armed bandits",
    "authors": ["S. Bubeck", "T. Wang", "N. Viswanathan"],
    "venue": "International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "Nearly optimal sampling algorithms for combinatorial pure exploration",
    "authors": ["L. Chen", "A. Gupta", "J. Li", "M. Qiao", "R. Wang"],
    "venue": "Proceedings of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Combinatorial pure exploration of multi-armed bandits",
    "authors": ["S. Chen", "T. Lin", "I. King", "M. Lyu", "W. Chen"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Best arm identification: A unified approach to fixed budget and fixed confidence",
    "authors": ["V. Gabillon", "M. Ghavamzadeh", "A. Lazaric"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "lil’ucb: An optimal exploration algorithm for multiarmed bandits",
    "authors": ["K. Jamieson", "M. Malloy", "R. Nowak", "S. Bubeck"],
    "venue": "Conference on Learning Theory,",
    "year": 2014
  }, {
    "title": "PAC subset selection in stochastic multi-armed bandits",
    "authors": ["S. Kalyanakrishnan", "A. Tewari", "P. Auer", "P. Stone"],
    "year": 2012
  }, {
    "title": "On the complexity of best-arm identification in multi-armed bandit models",
    "authors": ["E. Kaufmann", "O. Cappé", "A. Garivier"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "The sample complexity of exploration in the multi-armed bandit problem",
    "authors": ["S. Mannor", "J. Tistisklis"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2004
  }, {
    "title": "The simulator: Understanding adaptive sampling in the moderate-confidence regime",
    "authors": ["M. Simchowitz", "K. Jamieson", "B. Recht"],
    "venue": "Conference on Learning Theory,",
    "year": 2017
  }, {
    "title": "Best-arm identification in linear bandits",
    "authors": ["M. Soare", "A. Lazaric", "R. Munos"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Timesensitive bayesian information aggregation for crowdsourcing systems",
    "authors": ["M. Venanzi", "J. Guiver", "P. Kohli", "N. Jennings"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 2016
  }, {
    "title": "Introduction to the non-asymptotic analysis of random matrices",
    "authors": ["R. Vershynin"],
    "venue": "Compressed Sensing: Theory and Applications,",
    "year": 2012
  }, {
    "title": "High-dimensional probability: An introduction with applications in data science",
    "authors": ["R. Vershynin", "P. Hsu", "C. Ma", "J. Nelson", "E. Schnoor", "D. Stoger", "T. Sullivan", "T. Tao"],
    "year": 2017
  }],
  "id": "SP:5c6bc62b888a2662b760142a2b1d624d1832884d",
  "authors": [{
    "name": "Julian Katz-Samuels",
    "affiliations": []
  }, {
    "name": "Clayton Scott",
    "affiliations": []
  }],
  "abstractText": "We propose a new variant of the top arm identification problem, top feasible arm identification, where there are K arms associated with D-dimensional distributions and the goal is to find m arms that maximize some known linear function of their means subject to the constraint that their means belong to a given set P Ă R. This problem has many applications since in many settings, feedback is multi-dimensional and it is of interest to perform constrained maximization. We present problem-dependent lower bounds for top feasible arm identification and upper bounds for several algorithms. Our most broadly applicable algorithm, TF-LUCB-B, has an upper bound that is loose by a factor ofOpD logpKqq. Many problems of practical interest are twodimensional and, for these, it is loose by a factor of OplogpKqq. Finally, we conduct experiments on synthetic and real-world datasets that demonstrate the effectiveness of our algorithms. Our algorithms are superior both in theory and in practice to a naive two-stage algorithm that first identifies the feasible arms and then applies a best arm identification algorithm to the feasible arms.",
  "title": "Top Feasible Arm Identification"
}