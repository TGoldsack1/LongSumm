{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Models of the statistical structure of natural images play a key role in computer vision and image processing (Srivastava et al., 2003). Due to the high dimensionality of the images captured by modern cameras, a rich research literature instead models the statistics of small image patches. For example, the K-SVD method (Elad & Aharon, 2006) generalizes K-means clustering to learn a dictionary for sparse coding of image patches. The state-of-the-art learned simultaneous sparse coding (LSSC, Mairal et al. (2009)) and block matching and 3D filtering (BM3D, Dabov et al. (2008)) methods integrate clustering, dictionary learning,\n1Brown University, Providence, RI, USA. 2Harvard University, Cambridge, MA, USA. 3University of California, Irvine, CA, USA. Correspondence to: Geng Ji <gji@cs.brown.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nand denoising to extract information directly from a single corrupted image. Alternatively, the accurate expected patch log-likelihood (EPLL, Zoran & Weiss (2011)) method maximizes the log-likelihood of overlapping image patches under a finite Gaussian mixture model learned from uncorrupted natural images.\nWe show that with minor modifications, the objective function underlying EPLL is equivalent to a variational loglikelihood bound for a novel generative model of whole images. Our model coherently captures overlapping image patches via a randomly positioned spatial grid. By deriving a rigorous variational bound, we then develop improved nonparametric models of natural image statistics using the hierarchical Dirichlet process (HDP, Teh et al. (2006)). In particular, DP mixtures allow an appropriate model complexity to be inferred from data, while the hierarchical DP captures the patch self-similarities and repetitions that are ubiquitous in natural images (Jégou et al., 2009). Unlike previous whole-image generative models such as fields of experts (FoE, Roth & Black (2005)), which uses a single set of Markov random field parameters to model all images, our HDP model learns image-specific clusters to accurately model distinctive textures. Coupled with a scalable structured variational inference algorithm, we improve on the excellent denoising accuracy of the LSSC and BM3D algorithms, while providing a Bayesian nonparametric model with a broader range of potential applications."
  }, {
    "heading": "2. Expected Patch Log-likelihood",
    "text": "Our approach is derived from models of small (8× 8 pixel) patches of a large natural image x. Let Pi be a binary indicator matrix that extracts the G = 82 pixels Pix ∈ RG in patch i. To reduce sensitivity to lighting variations, a contrast normalizing transform is applied to remove the mean (or “DC component”) of the pixel intensities in each patch:\nvi = Pix− 1G1TPix = BPix, (1)\nfor a “zero-centering” matrix B. Zoran & Weiss (2012) show that a finite mixture of K zero-mean Gaussians,\np(vi) = ∑K k=1 πkNorm(vi | 0,Λ−1k ), (2)\nis superior to many classic image models in terms of predictive likelihood and patch denoising performance.\nThe widely-used EPLL image restoration framework measures the quality of a reconstruction by the expected patch log-likelihood, “assuming a patch location in the image is chosen uniformly at random” (Zoran & Weiss, 2011). Given a corrupted image y, EPLL estimates a clean image x by minimizing the objective:\nmin x\nλ 2 ‖x− y‖2 −∑i log p(BPix). (3)\nHere, the sum ranges over all overlapping, completely visible (uncropped) image patches. The constant λ is determined by the noise level of the corrupted image y.\nDirect optimization of Eq. (3) is challenging, so inspired by half quadratic splitting (Geman & Yang, 1995), the EPLL objective can be reformulated as follows:\nmin x,v̄\nλ 2 ‖x− y‖2 + ∑ i κ 2 ‖Pix− v̄i‖2 − log p(Bv̄i). (4)\nEach patch i is allocated an auxiliary variable v̄i, which (unlike the vi variable in Eq. (1)) includes an estimate of the mean patch intensity. This augmented objective leads to closed-form coordinate descent updates. Gating. Assign each patch i to some cluster zi:\nzi = arg max k\nπk Norm ( BPix | 0,Λ−1k + κI ) . (5)\nFiltering. Given an approximate clean image x and cluster assignments z, denoise patches via least squares:\nv̄i = ( I + κ−1BTΛziB )−1 Pix. (6)\nMixing. Given a fixed set of auxiliary patches v̄ and the noisy image y, a denoised image x is estimated as\nx = ( λI + κ ∑ i PTi Pi )−1( λy + κ ∑ i PTi v̄i ) . (7)\nAnnealing. Optimal solutions of Eq. (4) approach those of the EPLL objective in Eq. (3) as κ→∞. EPLL denoising algorithms slowly increase κ via an annealing schedule that must be tuned for best performance. Justification? Empirically, the intuitive EPLL objective is much more effective than baselines which use only a subset of non-overlapping patches, or average independently denoised patches (Zoran & Weiss, 2011). But why should we optimize the expected log-likelihood, instead of the expected likelihood or another function of patch-specific likelihoods? And how can the EPLL heuristic be generalized to capture more complex statistics of natural images? This paper answers these questions by linking EPLL to a rigorous, nonparametric generative model of whole images."
  }, {
    "heading": "3. Mixture Models for Grids of Image Patches",
    "text": "We now develop the HDP-Grid generative model summarized in Fig. 1, which uses randomly placed patch grids to formalize the EPLL objective, and hierarchical DP mixtures to capture image patch self-similarity."
  }, {
    "heading": "3.1. Hierarchical Dirichlet Process Mixtures",
    "text": "The hierarchical Dirichlet process (HDP, Teh et al. (2006)) is a Bayesian nonparametric prior used to cluster groups of related data; we model natural images as groups of patches. The HDP shares visual structure, such as patches of grass or bricks, by sharing a common set of clusters (called topics in applications to text data) across images. In addition, the HDP models image-specific variability by allowing each image to use this shared set of clusters with unique frequencies; grass might be abundant in one image but absent in another. Via the HDP, we can learn the proper number of hidden clusters from data, and discover new clusters as we collect new images with novel visual textures.\nThe HDP uses a stick-breaking construction to generate a corpus-wide vector π0 = [π01, π02, . . . , π0k, . . .] of frequencies for a countably infinite set of visual clusters:\nβk ∼ Beta(1, γ), π0k(β) , βk ∏k−1 `=1 (1− β`). (8) The HDP allocates each image m its own cluster frequencies πm, where the vector π0 determines the mean of a DP prior on the frequencies of shared clusters:\nπm ∼ DP(απ0), E[πmk] = π0k. (9) When the concentration parameter α < 1, we capture the “burstiness” and self-similarity of natural image regions (Jégou et al., 2009) by placing most probability mass in πm on a sparse subset of global clusters."
  }, {
    "heading": "3.2. Image Generation via Random Grids",
    "text": "We sample pixels in imagem via a randomly placed grid of patches. When each patch has G pixels, Fig. 2 shows there are exactlyG grid alignments for an image of arbitrary size. The alignment wm ∈ {1, . . . , G} has a uniform prior: wm ∼ Cat(1/G, . . . , 1/G). (10) Modeling multiple overlapping grids is crucial to capture real image statistics. As the true grid alignment for each image is uncertain, posterior inference will favor images\nthat are likely under all possible wm. Models based on a single, fixed grid produce severe artifacts at patch boundaries, as shown in Fig. 2 of Zoran & Weiss (2011)."
  }, {
    "heading": "3.3. Patch Generation via Gaussian Mixtures",
    "text": "Gaussian mixtures provide excellent density models for natural image patches (Zoran & Weiss, 2012). We associate clusters with zero-mean, full-covariance Gaussian distributions on patches with G pixels. We parameterize cluster k by a precision (inverse covariance) matrix Λk ∼ Wish(ν,W ), whose conjugate Wishart prior has ν degrees of freedom and scale matrix W . Given that wm = g, each of the Nmg patches vmgn in grid g is sampled from an infinite mixture with image-specific cluster frequencies:\np(vmgn|wm = g) = ∞∑ k=1 πmkNorm(vmgn|0,Λ−1k ). (11) Let zmgn | wm = g ∼ Cat(πm) denote the cluster that generates patch n. To account for the contrast normalization of Eq. (1), the intensities in patch n are shifted by an independent, scalar “DC offset” umgn: p(umgn | wm = g) = Norm(umgn | r, s2). (12) Finally, if wm 6= g so that grid g is unobserved, we sample (zmgn, vmgn, umgn) from some reference distribution\nindependent of the HDP mixture model parameters."
  }, {
    "heading": "3.4. From Patches to Corrupted Images",
    "text": "Given patches vmg with offsets umg generated via grid wm = g, we sample a whole “clean image” xm as\nNorm ( xm | ∑Nmg n=1 PTmgnv̄mgn, δ 2I ) , (13)\nwhere v̄mgn , Cmgnvmgn+umgn. Binary indicator matrices Pmgn, as in Sec. 2, stitch together patches in the chosen grid g. Image xm is then generated by adding independent Gaussian noise with small variance δ2. Most patches in the chosen grid will be fully observed in xm, but as illustrated in Fig. 2, some may be clipped by the image boundary. Indicator matrices Cmgn are defined so Cmgnvmgn + umgn is a vector containing the observed pixels from patch n.\nFor image restoration tasks, the observed image ym is a corrupted version of some clean image xm that we would like to estimate. Models of natural image statistics are commonly validated on the problem of image denoising, where xm is polluted by additive white Gaussian noise:\np(ym | xm) = Norm(ym | xm, σ2I). (14) The variance σ2 δ2 indicates the noise level. We also validate our model on image inpainting problems (Bertalmio et al., 2000), where some pixels are observed without noise but others are completely missing. By replacing Eq. (14) with other linear likelihood models, our novel generative model for natural images may be easily applied to other tasks including image deblurring (Zoran & Weiss, 2011), image super resolution (Yang & Huang, 2010), and color image demosaicing (Mairal et al., 2009)."
  }, {
    "heading": "4. Variational Inference",
    "text": "We now develop scalable learning algorithms for our nonparametric, grid-based image model. We first examine a baseline DP Grid model in which the same cluster frequencies π0 are shared by all images. Our full HDP Grid model then learns image-specific cluster frequencies πm, and instantiates new clusters to model unique visual textures."
  }, {
    "heading": "4.1. DP Grid: Variational Inference",
    "text": "Our goal is to infer the DP Grid model parameters that best explain observed images which may be clean (xm) or corrupted by noise (ym). The DP Grid model uses the same cluster probabilities π0, generated from stickbreaking weights β as in Eq. (8), for all images.\nLearning from clean images. Given a training set D of uncorrupted images x1, . . . xM , we estimate the posterior distribution p(β,Λ, w,Ψpatch | x) for our global mixture model parameters β and Λ, grid assignment indicators wm, and patch-level latent variables Ψpatchm = {um, vm, zm}.\nExact posterior inference is intractable, so we instead find an approximate posterior q(·) = q(β,Λ, w,Ψpatch) minimizing the KL divergence (Wainwright & Jordan, 2008) from the true posterior p(·|x). Equivalently, our variational method maximizes the following objective L:\nmax q∈Q L(q, x) = max q∈Q Eq [ log p(x, ·) q(·) ] ≤ log p(x). (15)\nWe constrain the solution of our optimization to come from a tractable family of structured mean-field distributions Q, parameterized by free parameters. Unlike naı̈ve mean-field methods which assume complete posterior independence, our structured mean-field approximation is more accurate and includes dependencies between some latent variables:\nq(·) = ∞∏ k=1 q(Λk)q(βk) · M∏ m=1 q(wm)q(Ψ patch m |wm).\nAs in Hughes & Sudderth (2013), this approximate posterior family contains infinitely many clusters, just like the true posterior. Rather than applying a fixed truncation to the stick-breaking prior (Blei & Jordan, 2006), we dynamically truncate the patch assignment distributions q(z) to only use the first K clusters to explain the M observed images. Clusters with indices k > K then have factors q(Λk) set to the prior, and need not be explicitly represented.\nGlobal mixture model. The global cluster weights β and precision matrices Λ have standard exponential family forms (free parameters are marked by hats):\nq(Λk) = Wish ( ν̂k, Ŵk ) , q(βk) = Beta ( ρ̂kω̂k, (1− ρ̂k)ω̂k ) .\nHere ρ̂k = Eq[βk], and ω̂k controls the variance of q(βk).\nImage-specific alignment. For natural images, all grid alignments are typically of similar quality, so we fix a uniform alignment posterior q(wm) = Cat ( 1 G , . . . , 1 G ) . This simplifies many updates while still avoiding artifacts that would arise from a single, non-overlapping patch grid.\nPatch-specific factors. The patch-specific variables Ψpatch have structured posteriors, conditioned on the value of the grid indicator wm for the current image:\nq(zmgn | wm = g) = Categorical ( r̂mgn1, ..., r̂mgnK ) ,\nq(umgn | wm = g) = Norm ( ûmgn, φ̂ u mgn ) ,\nq(vmgn | wm = g,zmgn = k) = Norm ( v̂mgnk, φ̂ v mgnk ) .\nBelow, we let Eq[·] denote the conditional expectation with respect to the variational distribution q, given wm.\nLearning. Given clean images x, we perform coodinate ascent on the objective L, alternatively updating one factor among q(β)q(Λ)q(w)q(Ψpatch). Most updates have closed forms due to the exponential families defining Q (see supplement). As one intuitive example, consider the update for\nthe cluster precision matrix posterior q(Λk|ν̂k, Ŵk):\nν̂k = ν + 1\nG Nk, Nk = M∑ m=1 G∑ g=1 Nmg∑ n=1 r̂mgnk, (16)\nŴk = W + 1\nG M∑ m=1 G∑ g=1 Nmg∑ n=1 Eq [ 1k(zmgn)vmgnv T mgn ] .︸ ︷︷ ︸\nSk\nStatistic Nk(r̂) counts patches assigned to cluster k, while Sk(r̂, v̂, φ̂\nv) aggregates second moments. These updates follow the standard form of prior parameter plus expected sufficient statistic, except the statistics are averaged (not simply added) across the G grid alignments."
  }, {
    "heading": "4.2. Image Denoising and Connections to EPLL",
    "text": "Given a corrupted image ym, we seek to compute the posterior p(xm | ym,D), where we condition on the training set D. Our variational posterior family Q now includes an additional factor for the unobserved, “clean” image xm:\nq(xm) = Norm ( xm | x̂m, φ̂xm ) . (17)\nThe variational inference objective becomes\nmax q∈Q\nEq [ log\np(D, ym, xm, ·) q(xm, ·)\n] ≤ log p(ym,D), (18)\nand the coordinate ascent update for q(xm) equals\nx̂m = φ̂ x m (ym σ2 + hm δ2 ) , φ̂xm = δ2σ2 δ2 + σ2 I. (19)\nThe updated covariance is diagonal, improving computational efficiency. The mean depends on the average image vector across all patches in all grids, denoted by hm:\nhm , 1\nG G∑ g=1 Nmg∑ n=1 PTmgn(CmgnEq[vmgn] + ûmgn). (20)\nNote that the update for x̂m in Eq. (19) is similar to the EPLL update in Eq. (7), except that some terms involving projection matrices become constants because we account for partially observed patches. Modeling partial patches is necessary to produce a valid likelihood bound in Eq. (18).\nIn fact, as we show below all three terms in the EPLL objective in Eq. (4) are very similar to our proposed minimization objective function −L, up to a scale factor of G. Of course, a key difference is that our objective seeks full posteriors rather than point estimates, and enables the HDP model of multiple images detailed in Sec. 4.3.\nEPLL Term 1. When we set λ , Gσ2 , the first term of the EPLL objective in Eq. (4) becomes\nG · 12σ2 (x− y)T (x− y). (21) Similarly, suppressing the subscript m denoting the image for simplicity, Eq[− log p(y|x)] in our −L simplifies as\n1 2σ2Eq[(x− y)T (x− y)]. (22)\nEPLL Term 2. Taking the second term in Eq. (4) and substituting κ = 1/δ2, we have:\n1 2δ2 ∑ i(Pix− v̄i)T (Pix− v̄i). (23)\nThe corresponding term Eq[− log p(x|w, u, v)] in our objective −L can be written similarly up to a scaling by G:\n1\nG\n1\n2δ2 G∑ g=1 Ng∑ n=1 Eq [ (Pgnx− v̄gn)T (Pgnx− v̄gn) ] . (24)\nEPLL Term 3. The third EPLL term assumes zerocentered patches Bv̄i are drawn from Gaussian mixtures:\n−∑i log p(Bv̄i | π0,Λ). (25) Similarly, in our minimization objective −L we draw vgn from a DP mixture model. Explicitly including the cluster assignment zgn, Eq[− log p(v, z|w)] equals\n− 1 G G∑ g=1 Ng∑ n=1 Eq[log p(vgn, zgn | π0,Λ)]. (26)\nEPLL is similar, but maximizes assignments (Eq. (5)) rather than computing posterior assignment probabilities."
  }, {
    "heading": "4.3. HDP Grid: Variational Inference",
    "text": "Image-specific frequencies. The DP model above, and the parametric EPLL objective it generalizes, assume the same cluster frequency vector π0 for each image m. Our HDP Grid model allows image-specific frequencies πm to be learned from data, via the hierarchical regularization of the HDP prior (Teh et al., 2006). Our approximate posterior family Q now has the following HDP-specific factors:\nq(β) = ∏∞ k=1 Beta (βk | ρ̂kω̂k, (1− ρ̂k)ω̂k) , (27)\nq([πm1 . . .πmK πm>K ]) = Dir(θ̂m1 . . . θ̂mK , θ̂m>K). This approximate posterior represents infinitely many clusters via a finite partition of πm into K + 1 terms: one for each of theK active clusters, and a remainder term at index >K that aggregates the mass of all inactive clusters. The free parameter θ̂m is also a vector of size K + 1 whose last entry represents all inactive clusters. We follow Hughes et al. (2015) to obtain a closed-form update for θ̂m, and gradient-based updates for ρ̂, ω̂; see the supplement for details. We highlight that the θ̂m update naturally includes a 1G rescaling of count sufficient statistics as in Eq. (16). Other factors remain unchanged from the DP Grid model.\nImage-specific clusters. Due to the heavy-tailed distribution of natural images (Ruderman, 1997), even with large training sets, test images may still contain unique textural patterns like the striped scarf in the Barbara image in Fig. 3. Fortunately, our Bayesian nonparametric HDP Grid model provides a coherent way to capture such patterns by appending K ′ novel, image-specific clusters to the original K clusters learned from training images. These novel clusters lead to more accurate posterior approximations q ∈ Q that better optimize our objective L.\nWe initialize inference by creating K ′ = 100 imagespecific clusters with the k-means++ algorithm (Arthur & Vassilvitskii, 2007), which minimizes the cost function\nJ (z′,Λ′) = ∑i∑K′k=1 1k(z′i)D(ṽiṽTi ,Λ′k), (28) where the first sum is over the set of fully-observed patches within the image. The function D is the Bregman divergence associated with our zero-mean Gaussian likelihood (Banerjee et al., 2005), and ṽi = BPiy is a zerocentered patch. We initialize the algorithm by sampling K ′ diverse patches in a distance-biased fashion, and refine with 50 iterations of coordinate descent updates of z′ and Λ′.\nThen we expand the variational posterior q(Λ) intoK+K ′ clusters. The first K indices are kept the same as training, and the last K ′ indices are set via Eq. (16) using sufficient statistics N ′, S′ derived from hard assignments z′:\nN ′k′ ← ∑ i 1k′(z ′ i), S ′ k′ ← [∑ i 1k′(z ′ i)ṽiṽ T i −Nk′σ2I ] + . Here, following Portilla et al. (2003) and Kivinen et al. (2007), S′k′ estimates the clean data statistic Sk′ by subtracting the expected noise covariance. The [·]+ operator thresholds any negative eigenvalues to zero.\nSimilarly, the other global variational factor q(β) is also expanded to K + K ′ clusters via sufficient statistics N ′ and counts of cluster usage from training data. Given {β,Λ}K+K′k=1 , each factor in q may then be updated in turn to maximize the variational objective L (see supplement). Finally, while we initialize K ′ to a large number to avoid local optima, this may lead to extraneous clusters. We thus delete new clusters that our sparsity-biased variational updates do not assign to any patch. In the Barbara image in Fig. 3, this leaves 9 image-specific clusters. Deletion improves model interpretability and algorithm speed, because costs scale linearly with the number of instantiated clusters."
  }, {
    "heading": "5. Experiments",
    "text": "Following EPLL, we train our HDP-Grid model using 400 clean training and validation images from the Berkeley segmentation dataset (BSDS, Martin et al. (2001)). We fix δ = 0.5/255 to account for the quantization of image intensities to 8-bit integers. Observed DC offsets u provide maximum likelihood estimates of the mean r and variance s2 in Eq. (12). Similarly, we compute empirical covariance matrices for patches in the same image segments to estimate hyperparameters W and ν in Eq. (16). Using variational learning algorithms that adapt the number of clusters to the observed data (Hughes & Sudderth, 2013), we discover K = 449 clusters for the DP-Grid model, which we use to initialize our HDP model. We set our annealing schedule for κ to match that used by the public EPLL code.\nImage denoising methods are often divided into two types (Zontak & Irani, 2011): external methods (like\nEPLL) that learn all parameters from a training database of clean images, and internal methods that denoise patches using other patches of the single noisy image. For example, the K-SVD (Elad & Aharon, 2006) has an external variant that uses a dictionary learned from clean images, and an internal variant that learns its dictionary from the noisy image. A major contribution of our paper is to show that the hierarchical DP leads to a principled hybrid of internal and external methods, in which cues from clean and noisy images are automatically combined in an adaptive way."
  }, {
    "heading": "5.1. Image Denoising",
    "text": "We test our algorithm on 12 “classic” images used in many previous denoising papers (Mairal et al., 2009; Zoran & Weiss, 2011), as well as the 68 BSDS test images used by (Roth & Black, 2005; Zoran & Weiss, 2011). We evaluate\nthe denoising performance by the peak signal-to-noise ratio (PSNR), a logarithmic transform of the mean squared error (MSE) between images with normalized intensities,\nPSNR , −20 log10 MSE. (29) We also evaluate the structural similarity index (SSIM, Wang et al. (2004)), which quantifies image quality degradation via changes in structure, luminance, and contrast.\nInternal vs. external clusters. In result figures, we use eDP to refer to our DP-Grid model trained solely on external clean images and HDP to refer to the HDP-Grid model that also learns novel image-specific clusters. We also train an internal DP-Grid model, referred to as iDP, using only information from the noisy test image. The first four columns of Table 1 compare their average denoising performance, where EPLL can be viewed as a simplification of eDP. For all noise levels and datasets, the HDP model has superior performance. As shown in Fig. 6, HDP is more accurate than EPLL and eDP for every single classic-12 image. Also, the consistent gain in performance from EPLL to eDP demonstrates the benefits of Bayesian nonparametric learning of an appropriate model complexity (for EPLL, the number of clusters was arbitrarily fixed at K = 200).\nFig. 3 further illustrates the complementary role of internal\nTable 1. Average PSNR and SSIM values on benchmark datasets (larger values indicate better denoising). Methods are highlighted if they are indistinguishable with 95% confidence, according to a Wilcoxon signed-rank test on the fraction of images where one method outperforms another. For all noise levels the patch size of BM3D is fixed to 8× 8 and LSSC is fixed to 9× 9.\nmetric dataset σ iDP EPLL eDP HDP FoE eKSVD iKSVD BM3D LSSC\nPSNR\nclassic-12 10 33.66 33.68 33.77 33.99 33.11 33.45 33.62 33.98 34.05 25 29.02 29.39 29.47 29.68 28.32 28.89 29.11 29.73 29.74 50 25.44 26.22 26.28 26.42 24.69 25.44 25.64 26.55 26.43 BSDS-68 10 33.10 33.37 33.42 33.47 32.69 33.06 33.08 33.26 33.45 25 28.33 28.72 28.76 28.82 27.76 28.28 28.28 28.55 28.70 50 25.10 25.72 25.75 25.83 24.48 25.17 25.17 25.59 25.50\nSSIM\nclassic-12 10 0.9118 0.9136 0.9143 0.9169 0.8962 0.9084 0.9111 0.9168 0.9185 25 0.8189 0.8286 0.8299 0.8337 0.8018 0.8082 0.8131 0.8357 0.8359 50 0.6962 0.7301 0.7316 0.7366 0.6885 0.6926 0.6975 0.7425 0.7390 BSDS-68 10 0.9119 0.9219 0.9224 0.9230 0.8971 0.9128 0.9135 0.9157 0.9206 25 0.7964 0.8090 0.8103 0.8131 0.7804 0.7859 0.7879 0.8010 0.8109 50 0.6636 0.6870 0.6880 0.6962 0.6585 0.6544 0.6539 0.6840 0.6885\n1 1.5 2\nELBO/pixel\n26\n28\n30\n32\nP S\nN R\neDP HDP\nFigure 6. Clean-image evidence lower bound (ELBO) versus output PSNR (σ = 25) for 12 “classic” images. The horizontal axis plots log p(xtest|xtrain) ≈ L(xtest, xtrain)−L(xtrain), divided by the number of pixels. Our HDP is uniformly superior to the eDP.\nand external clusters for a single test image (“Barbara”). The internal iDP perfectly captures some unique textures like the striped clothing, but produces artifacts in smooth background regions. The external EPLL and eDP better represent smooth surfaces and contours, which are common in training data, but poorly recover striped textures.\nAs shown in Fig. 5, while the relative accuracy of the eDP and iDP models varies depending on image statistics, the HDP model adaptively combines external and internal clusters for superior performance at all noise levels. By capturing the expected self-similarity of image patches, the HDP model also reduces artifacts in large regions with regular textures, such as the smoothly shaded areas of Fig. 4.\nComputational speed. To denoise a 512× 512 pixel image on a modern laptop, our Python code for eDP inference with K = 449 clusters takes about 12 min. The public EPLL Matlab code (Zoran & Weiss, 2011) with K = 200 clusters takes about 5 min. With equal numbers of clusters, the two methods have comparable runtimes. Our open-source Python code is available online at\nOriginal FoE\nEPLL HDP\nFigure 7. A qualitative comparison of image inpainting algorithms. As illustrated in the three close-up views, the HDP exploits patch self-similarity to better recover fine details.\ngithub.com/bnpy/hdp-grid-image-restoration.\nLearning image-specific clusters for the HDP model is more expensive: our non-optimized Python denoising code currently requires about 30 min. per image. Nearly all of the extra time is spent on the k-means++ initialization of Eq. (28). We expect this can be sped up significantly by coding core routines in C, parallelizing some sub-steps (possibly via GPUs), using fewer internal clusters (100 is often too many), or using faster initialization heuristics.\nPerformance. We compare our HDP model to other patch-based denoising methods in Table 1. On classic-12, where many top methods have been hand-tuned to perform well, our model is statistically indistinguishable from the best baselines. On the larger BSDS-68, our performance is superior to the state-of-the-art, showing the value of nonparametric learning from large image collections. See Fig. 8 for examples. At higher noise levels (σ = 50), LSSC has modestly improved performance (0.2 dB in PSNR) when modeling 12× 12 patches (Mairal et al., 2009). HDP models of larger patches are a promising research area."
  }, {
    "heading": "5.2. Image Inpainting",
    "text": "While many image processing systems are designed for just one problem, our generative model is useful for many tasks. For example, we can “inpaint” occluded image regions (like the red pixels in Fig. 7) by modifying Eq. (14) to\nlet σ2 →∞ for only those regions and setting σ2 = 0 elsewhere. To process color images, we follow the approach of FoE and EPLL and convert to the YCbCr color space before independently inpainting each channel. While ground truth is unavailable for the classic image in Fig. 7, our gridbased HDP produces fewer visual artifacts than baselines."
  }, {
    "heading": "6. Conclusion",
    "text": "We have developed a coherent Bayesian nonparametric model that, via randomly positioned grids of image patches, provides a novel statistical foundation for the popular EPLL method. We show that HDP mixture models of visual textures can grow in complexity as additional images are observed and capture the self-similarity of natural images. Our HDP-grid image denoising and inpainting algorithms are competitive with the state-of-the-art, and our model is applicable to many other computer vision tasks."
  }, {
    "heading": "Acknowledgements",
    "text": "This research supported in part by NSF CAREER Award No. IIS-1349774. MCH supported in part by Oracle Labs."
  }],
  "year": 2017,
  "references": [{
    "title": "k-means++: The advantages of careful seeding",
    "authors": ["D. Arthur", "S. Vassilvitskii"],
    "venue": "In ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2007
  }, {
    "title": "Clustering with Bregman divergences",
    "authors": ["A. Banerjee", "S. Merugu", "I.S. Dhillon", "J. Ghosh"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2005
  }, {
    "title": "Image inpainting",
    "authors": ["M. Bertalmio", "G. Sapiro", "V. Caselles", "C. Ballester"],
    "venue": "In Computer Graphics and Interactive Techniques,",
    "year": 2000
  }, {
    "title": "Variational inference for Dirichlet process mixtures",
    "authors": ["D.M. Blei", "M.I. Jordan"],
    "venue": "Bayesian Analysis,",
    "year": 2006
  }, {
    "title": "Image restoration by sparse 3d transform-domain collaborative filtering",
    "authors": ["K. Dabov", "A. Foi", "V. Katkovnik", "K. Egiazarian"],
    "venue": "In Electronic Imaging,",
    "year": 2008
  }, {
    "title": "Image denoising via sparse and redundant representations over learned dictionaries",
    "authors": ["M. Elad", "M. Aharon"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 2006
  }, {
    "title": "Nonlinear image recovery with half-quadratic regularization",
    "authors": ["D. Geman", "C. Yang"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 1995
  }, {
    "title": "Memoized online variational inference for Dirichlet process mixture models",
    "authors": ["M.C. Hughes", "E.B. Sudderth"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2013
  }, {
    "title": "Reliable and scalable variational inference for the hierarchical Dirichlet process",
    "authors": ["M.C. Hughes", "D.I. Kim", "E.B. Sudderth"],
    "venue": "In Artificial Intelligence and Statistics,",
    "year": 2015
  }, {
    "title": "On the burstiness of visual elements",
    "authors": ["H. Jégou", "M. Douze", "C. Schmid"],
    "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,",
    "year": 2009
  }, {
    "title": "Image denoising with nonparametric hidden Markov trees",
    "authors": ["J.J. Kivinen", "E.B. Sudderth", "M.I. Jordan"],
    "venue": "In International Conference on Image Processing,",
    "year": 2007
  }, {
    "title": "Non-local sparse models for image restoration",
    "authors": ["J. Mairal", "F. Bach", "J. Ponce", "G. Sapiro", "A. Zisserman"],
    "venue": "In International Conference on Computer Vision,",
    "year": 2009
  }, {
    "title": "A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics",
    "authors": ["D. Martin", "C. Fowlkes", "D. Tal", "J. Malik"],
    "venue": "In International Conference on Computer Vision,",
    "year": 2001
  }, {
    "title": "Image denoising using scale mixtures of Gaussians in the wavelet domain",
    "authors": ["J. Portilla", "V. Strela", "M.J. Wainwright", "E.P. Simoncelli"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 2003
  }, {
    "title": "Fields of experts: A framework for learning image priors",
    "authors": ["S. Roth", "M.J. Black"],
    "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,",
    "year": 2005
  }, {
    "title": "Origins of scaling in natural images",
    "authors": ["D.L. Ruderman"],
    "venue": "Vision Research,",
    "year": 1997
  }, {
    "title": "On advances in statistical modeling of natural images",
    "authors": ["A. Srivastava", "A.B. Lee", "E.P. Simoncelli", "S. Zhu"],
    "venue": "Journal of Mathematical Imaging and Vision,",
    "year": 2003
  }, {
    "title": "Hierarchical Dirichlet processes",
    "authors": ["Y.W. Teh", "M.I. Jordan", "M.J. Beal", "D.M. Blei"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2006
  }, {
    "title": "Graphical models, exponential families, and variational inference",
    "authors": ["M.J. Wainwright", "M.I. Jordan"],
    "venue": "Foundations and Trends in Machine Learning,",
    "year": 2008
  }, {
    "title": "Image quality assessment: From error visibility to structural similarity",
    "authors": ["Z. Wang", "A.C. Bovik", "H.R. Sheikh", "E.P. Simoncelli"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 2004
  }, {
    "title": "Image super-resolution: Historical overview and future challenges",
    "authors": ["J. Yang", "T. Huang"],
    "venue": "Super-resolution imaging,",
    "year": 2010
  }, {
    "title": "Internal statistics of a single natural image",
    "authors": ["M. Zontak", "M. Irani"],
    "venue": "In IEEE Conf. on Computer Vision and Pattern Recognition,",
    "year": 2011
  }, {
    "title": "From learning models of natural image patches to whole image restoration",
    "authors": ["D. Zoran", "Y. Weiss"],
    "venue": "In International Conference on Computer Vision,",
    "year": 2011
  }, {
    "title": "Natural images, Gaussian mixtures and dead leaves",
    "authors": ["D. Zoran", "Y. Weiss"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2012
  }],
  "id": "SP:b01114b48fd2b027649dce64d5fe50b93328f5e1",
  "authors": [{
    "name": "Geng Ji",
    "affiliations": []
  }, {
    "name": "Michael C. Hughes",
    "affiliations": []
  }, {
    "name": "Erik B. Sudderth",
    "affiliations": []
  }],
  "abstractText": "We propose a hierarchical generative model that captures the self-similar structure of image regions as well as how this structure is shared across image collections. Our model is based on a novel, variational interpretation of the popular expected patch log-likelihood (EPLL) method as a model for randomly positioned grids of image patches. While previous EPLL methods modeled image patches with finite Gaussian mixtures, we use nonparametric Dirichlet process (DP) mixtures to create models whose complexity grows as additional images are observed. An extension based on the hierarchical DP then captures repetitive and self-similar structure via imagespecific variations in cluster frequencies. We derive a structured variational inference algorithm that adaptively creates new patch clusters to more accurately model novel image textures. Our denoising performance on standard benchmarks is superior to EPLL and comparable to the state-ofthe-art, and we provide novel statistical justifications for common image processing heuristics. We also show accurate image inpainting results.",
  "title": "From Patches to Images: A Nonparametric Generative Model"
}