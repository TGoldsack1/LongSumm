{
  "sections": [{
    "text": "Keywords: Frank–Wolfe algorithm, conditional gradient, caching, linear optimization oracle, convex optimization"
  }, {
    "heading": "1. Introduction",
    "text": "Convex optimization is an important technique both from a theoretical and an applications perspective. Gradient descent based methods are widely used due to their simplicity and easy applicability to many real-world problems. We are interested in solving constraint convex optimization problems of the form\nmin x∈P f(x), (1)\nwhere f is a smooth convex function and P is a polytope, with access to f being limited to first-order information, i.e., we can obtain ∇f(x) and f(x) for a given x ∈ P and access to P via a linear minimization oracle, which returns LPP (c) = argminx∈P cx for a given linear objective c.\nWhen solving Problem (1) using gradient descent approaches in order to maintain feasibility, typically a projection step is required. This projection back into the feasible region P is potentially computationally expensive, especially for complex feasible regions in very large dimensions. As such, projection-free methods gained a lot of attention recently, in particular the Frank–Wolfe algorithm Frank and Wolfe (1956) (also known as conditional gradient descent Levitin and Polyak (1966); see also Jaggi (2013) for an overview) and its online version Hazan and Kale (2012) due to their simplicity. We recall the basic Frank–Wolfe algorithm in Algorithm 1. These methods eschew the projection step and rather use a\nc©2019 Gábor Braun, Sebastian Pokutta, and Daniel Zink.\nLicense: CC-BY 4.0, see https://creativecommons.org/licenses/by/4.0/. Attribution requirements are provided at http://jmlr.org/papers/v20/18-114.html.\nAlgorithm 1 Frank–Wolfe Algorithm Frank and Wolfe (1956) Input: smooth convex function f with curvature C, start vertex x1 ∈ P , linear minimization oracle LPP Output: points xt in P 1: for t = 1 to T − 1 do 2: vt ← LPP (∇f(xt)) 3: xt+1 ← (1− γt)xt + γtvt with γt := 2t+2 4: end for\nlinear optimization oracle to stay within the feasible region. While convergence rates and regret bounds are often suboptimal, in many cases the gain due to only having to solve a single linear optimization problem over the feasible region in every iteration still leads to significant computational advantages (see e.g., (Hazan and Kale, 2012, Section 5)). This led to conditional gradient algorithms being used for e.g., online optimization and more generally machine learning. Also the property that these algorithms naturally generate sparse distributions over the extreme points of the feasible region is often helpful. Further increasing the relevance of these methods, it was shown recently that conditional gradient methods can also achieve linear convergence (see e.g., Garber and Hazan (2013); Lacoste-Julien and Jaggi (2015); Garber and Meshi (2016)) as well as that the number of total gradient evaluations can be reduced while maintaining the optimal number of oracle calls as shown in Lan and Zhou (2014).\nUnfortunately, for complex feasible regions even solving the linear optimization problem might be time-consuming and as such the cost of solving the LP might be non-negligible. This could be the case, e.g., when linear optimization over the feasible region is a hard problem or when solving large-scale optimization or learning problems. As such it is natural to ask the following questions:\n(i) Does the linear optimization oracle have to be called in every iteration?\n(ii) Does one need approximately optimal solutions for convergence?\n(iii) Can one reuse information across iterations?\nWe will answer these questions in this work, showing that (i) the LP oracle is not required to be called in every iteration, (ii) much weaker guarantees are sufficient, and (iii) we can reuse information. To significantly reduce the cost of oracle calls while maintaining identical convergence rates up to small constant factors, we replace the linear optimization oracle by a (weak) separation oracle (Oracle 1) which approximately solves a separation problem\nOracle 1 Weak Separation Oracle LPsepP (c, x,Φ,K) Input: linear objective c ∈ Rn, point x ∈ P , accuracy K ≥ 1, objective value Φ > 0; Output: Either (1) vertex y ∈ P with c(x− y) > Φ/K, or (2) false: c(x− z) ≤ Φ for all z ∈ P .\nwithin a multiplicative factor and returns improving vertices. We stress that the weak separation oracle is significantly weaker than approximate minimization, which has been\nalready considered in Jaggi (2013). In fact, there is no guarantee that the improving vertices returned by the oracle are near to the optimal solution to the linear minimization problem. It is this relaxation of dual bounds and approximate optimality that will provide a significant speedup as we will see later. However, if the oracle does not return an improving vertex (returns false), then this fact can be used to derive a reasonably small dual bound of the form: f(xt) − f(x∗) ≤ ∇f(xt)(xt − x∗) ≤ Φt for some Φt > 0. While the accuracy K is presented here as a formal argument of the oracle, an oracle implementation might restrict to a fixed value K > 1, which often makes implementation easier. We point out that the cases (1) and (2) potentially overlap if K > 1. This is intentional and in this case it is unspecified which of the cases the oracle should choose (and it does not matter for the algorithms).\nThis new oracle encapsulates the smart use of the original linear optimization oracle, even though for some problems it could potentially be implemented directly without relying on a linear programming oracle. Concretely, a weak separation oracle can be realized by a single call to a linear optimization oracle and as such is no more complex than the original oracle. However it has two important advantages: it allows for caching and early termination. Caching refers to storing previous solutions, and first searching among them to satisfy the oracle’s separation condition. The underlying linear optimization oracle is called only, when none of the cached solutions satisfy the condition. Algorithm 2 formalizes this process. Early termination is the technique to stop the linear optimization algorithm before it finishes at an appropriate stage, when from its internal data a suitable oracle answer can be easily recovered; this is clearly an implementation dependent technique. The two techniques can be combined, e.g., Algorithm 2 could use an early terminating linear oracle or other implementation of the weak separation oracle in line 4.\nAlgorithm 2 LPsepP (c, x,Φ,K) via LP oracle Input: linear objective c ∈ Rn, point x ∈ P , accuracy K ≥ 1, objective value Φ > 0; Output: Either (1) vertex y ∈ P with c(x− y) > Φ/K, or (2) false: c(x− z) ≤ Φ for all\nz ∈ P . 1: if y ∈ P cached with c(x− y) > Φ/K exists then 2: return y {Cache call} 3: else 4: y ← argmaxx∈P cx {LP call} 5: if c(x− y) > Φ/K then 6: add y to cache 7: return y 8: else 9: return false\n10: end if 11: end if\nWe call lazification the technique of replacing a linear programming oracle with a much weaker one, and we will demonstrate significant speedups in wall-clock performance (see e.g., Figure 12), while maintaining identical theoretical convergence rates.\nTo exemplify our approach we provide conditional gradient algorithms employing the weak separation oracle for the standard Frank–Wolfe algorithm as well as the variants in\nHazan and Kale (2012); Garber and Meshi (2016); Garber and Hazan (2013), which have been chosen due to requiring modified convergence arguments that go beyond those required for the vanilla Frank–Wolfe algorithm. Complementing the theoretical analysis we report computational results demonstrating effectiveness of our approach via a significant reduction in wall-clock time compared to their linear optimization counterparts.\nRelated Work\nThere has been extensive work on Frank–Wolfe algorithms and conditional gradient algorithms, so we will restrict to review work most closely related to ours. The Frank–Wolfe algorithm was originally introduced in Frank and Wolfe (1956) (also known as conditional gradient descent Levitin and Polyak (1966) and has been intensely studied in particular in terms of achieving stronger convergence guarantees as well as affine-invariant versions. We demonstrate our approach for the vanilla Frank–Wolfe algorithm Frank and Wolfe (1956) (see also Jaggi (2013)) as an introductory example. We then consider more complicated variants that require non-trivial changes to the respective convergence proofs to demonstrate the versatility of our approach. This includes the linearly convergent variant via local linear optimization Garber and Hazan (2013) as well as the pairwise conditional gradient variant of Garber and Meshi (2016), which is especially efficient in terms of implementation. However, our technique also applies to the Away-Step Frank–Wolfe algorithm, the Fully-Corrective Frank–Wolfe algorithm, the Pairwise Conditional Gradient algorithm, as well as the Block-Coordinate Frank–Wolfe algorithm. Recently, in Freund and Grigas (2016) guarantees for arbitrary step-size rules were provided and an analogous analysis can be also performed for our approach. On the other hand, the analysis of the inexact variants, e.g., with approximate linear minimization does not apply to our case as our oracle is significantly weaker than approximate minimization as pointed out earlier. For more information, we refer the interested reader to the excellent overview in Jaggi (2013) for Frank–Wolfe methods in general as well as Lacoste-Julien and Jaggi (2015) for an overview with respect to global linear convergence.\nIt was also recently shown in Hazan and Kale (2012) that the Frank–Wolfe algorithm can be adjusted to the online learning setting and in this work we provide a lazy version of this algorithm. Combinatorial convex online optimization has been investigated in a long line of work (see e.g., Kalai and Vempala (2005); Audibert et al. (2013); Neu and Bartók (2013)). It is important to note that our regret bounds hold in the structured online learning setting, i.e., our bounds depend on the `1-diameter or sparsity of the polytope, rather than its ambient dimension for arbitrary convex functions (see e.g., Cohen and Hazan (2015); Gupta et al. (2016)). We refer the interested reader to Hazan (2016) for an extensive overview.\nA key component of the new oracle is the ability to cache and reuse old solutions, which accounts for the majority of the observed speed up. The idea of caching of oracle calls was already explored in various other contexts such as cutting plane methods (see e.g., Joachims et al. (2009)) as well as the Block-Coordinate Frank–Wolfe algorithm in Shah et al. (2015); Osokin et al. (2016). Our lazification approach (which uses caching) is however much more lazy, requiring no multiplicative approximation guarantee; see (Osokin et al., 2016, Proof of Theorem 3. Appendix F) and Lacoste-Julien et al. (2013) for comparison to our setup.\nContribution\nThe main technical contribution of this paper is a new approach, whereby instead of finding the optimal solution, the oracle is used only to find a good enough solution or a certificate that such a solution does not exist, both ensuring the desired convergence rate of the conditional gradient algorithms.\nOur contribution can be summarized as follows:\n(i) Lazifying approach. We provide a general method to lazify conditional gradient algorithms. For this we replace the linear optimization oracle with a weak separation oracle, which allows us to reuse feasible solutions from previous oracle calls, so that in many cases the oracle call can be skipped. In fact, once a simple representation of the underlying feasible region is learned no further oracle calls are needed. We also demonstrate how parameter-free variants can be obtained.\n(ii) Lazified conditional gradient algorithms. We exemplify our approach by providing lazy versions of the vanilla Frank–Wolfe algorithm as well as of the conditional gradient methods in Hazan and Kale (2012); Garber and Hazan (2013); Garber and Meshi (2016).\n(iii) Weak separation through augmentation. We show in the case of 0/1 polytopes how to implement a weak separation oracle with at most k calls to an augmentation oracle that on input c ∈ Rn and x ∈ P provides either an improving solution x ∈ P with cx < cx or ensures optimality, where k denotes the `1-diameter of P . This is useful when the solution space is sparse.\n(iv) Computational experiments. We demonstrate computational superiority by extensive comparisons of the weak separation based versions with their original versions. In all cases we report significant speedups in wall-clock time often of several orders of magnitude.\nIt is important to note that in all cases, we inherit the same requirements, assumptions, and properties of the baseline algorithm that we lazify. This includes applicable function classes, norm requirements, as well as smoothness and (strong) convexity requirements. We also maintain identical convergence rates up to (small) constant factors.\nA previous version of this work appeared as extended abstract in Braun et al. (2017); this version has been significantly revised over the conference version including a representative subset of more extensive computational results, full proofs for all described variants, as well as a variant that uses an augmentation oracle instead of linear optimization oracle (see Section 7).\nOutline\nWe briefly recall notation and notions in Section 2 and consider conditional gradient algorithms in Section 3. In Section 4 we consider parameter-free variants of the proposed algorithms, and in Section 5 we examine online versions. Finally, in Section 7 we show a realization of a weak separation oracle with an even weaker oracle in the case of combinatorial problem and we provide extensive computational results in Section 8."
  }, {
    "heading": "2. Preliminaries",
    "text": "Let ‖·‖ be an arbitrary norm on Rn, and let ‖·‖∗ denote the dual norm of ‖·‖. A function f is L-Lipschitz if |f(y) − f(x)| ≤ L‖y − x‖ for all x, y ∈ dom f . A convex function f is smooth with curvature at most C if\nf(γy + (1− γ)x) ≤ f(x) + γ∇f(x)(y − x) + Cγ2/2\nfor all x, y ∈ dom f and 0 ≤ γ ≤ 1. A function f is S-strongly convex if\nf(y)− f(x) ≥ ∇f(x)(y − x) + S 2 ‖y − x‖2\nfor all x, y ∈ dom f . Unless stated otherwise Lipschitz continuity and strong convexity will be measured in the norm ‖·‖. Moreover, let Br (x) := {y | ‖x− y‖ ≤ r} be the ball around x with radius r with respect to ‖.‖. In the following, P will denote the feasible region, a polytope and the vertices of P will be denoted by v1, . . . , vN ."
  }, {
    "heading": "3. Lazy Conditional Gradient",
    "text": "We start with the most basic Frank–Wolfe algorithm as a simple example for lazifying by means of a weak separation oracle. We then lazify more complex Frank–Wolfe algorithms in Garber and Hazan (2013) and Garber and Meshi (2016). Throughout this section ‖·‖ denotes the `2-norm."
  }, {
    "heading": "3.1. Lazy Conditional Gradient: a basic example",
    "text": "We start with lazifying the original Frank–Wolfe algorithm (arguably the simplest Conditional Gradient algorithm), adapting the baseline argument from (Jaggi, 2013, Theorem 1). While the vanilla version has suboptimal convergence rate O(1/T ), its simplicity makes it an illustrative example of the main idea of lazification. The lazy algorithm (Algorithm 3) maintains an upper bound Φt on the convergence rate, guiding its eagerness for progress when searching for an improving vertex vt. If the weak separation oracle provides an improving vertex vt we refer to this as a positive call and if the oracle claims there are no improving vertices we call it a negative call.\nThe step size γt is chosen to (approximately) minimize Φt in Line 2; roughly Φt−1/KC.\nTheorem 1 Assume f is convex and smooth with curvature C. Then Algorithm 3 with γt = 2(K2+1) K(t+K2+2) and f(x1)− f(x∗) ≤ Φ0 has convergence rate\nf(xt)− f(x∗) ≤ 2 max{C,Φ0}(K2 + 1)\nt+K2 + 2 ,\nwhere x∗ is a minimum point of f over P . Proof We prove by induction that\nf(xt)− f(x∗) ≤ Φt−1.\nAlgorithm 3 Lazy Conditional Gradient Input: smooth convex function f with curvature C, start vertex x1 ∈ P , weak linear separation oracle LPsepP , accuracy K ≥ 1, step sizes γt, initial upper bound Φ0 Output: points xt in P 1: for t = 1 to T − 1 do 2: Φt ← Φt−1+ Cγ2t 2\n1+ γt K\n3: vt ← LPsepP (∇f(xt), xt,Φt,K) 4: if vt = false then 5: xt+1 ← xt 6: else 7: xt+1 ← (1− γt)xt + γtvt 8: end if 9: end for\nThe claim is clear for t = 1 by the choice of Φ0. Assuming the claim is true for t, we prove it for t+ 1. We distinguish two cases depending on the return value of the weak separation oracle in Line 3.\nIn case of a positive call, i.e., when the oracle returns an improving solution vt, then ∇f(xt)(xt − vt) ≥ Φt/K, which is used in the second inequality below. The first inequality follows by smoothness of f , and the second inequality by the induction hypothesis and the fact that vt is an improving solution:\nf(xt+1)− f(x∗) ≤ f(xt)− f(x∗)︸ ︷︷ ︸ ≤Φt−1 +γt∇f(xt)(vt − xt)︸ ︷︷ ︸ ≤−Φt/K + Cγ2t 2\n≤ Φt−1 − γt Φt K + Cγ2t\n2 = Φt,\nIn case of a negative call, i.e., when the oracle returns no improving solution, then in particular ∇f(xt)(xt − x∗) ≤ Φt, hence by Line 5\nf(xt+1)− f(x∗) = f(xt)− f(x∗) ≤ ∇f(xt)(xt − x∗) ≤ Φt.\nFinally, using the specific values of γt we prove the upper bound\nΦt−1 ≤ 2 max{C,Φ0}(K2 + 1)\nt+K2 + 2\nby induction on t. The claim is obvious for t = 1. The induction step is an easy computation relying on the definition of Φt on Line 2:\nΦt = Φt−1 +\nCγ2t 2\n1 + γtK ≤\n2 max{C,Φ0}(K2+1) t+K2+2 + max{C,Φ0}γ2t 2\n1 + γtK ≤ 2 max{C,Φ0}(K 2 + 1) t+K2 + 3 .\nHere the last inequality follows from the concrete value of γt.\nNote that by design, the algorithm converges at the worst-case rate that we postulate due to the negative calls when it does not move. Clearly, this is highly undesirable, therefore the algorithm should be understood as the textbook variant of lazy conditional gradient. We will present an improved, parameter-free variant of Algorithm 3 in Section 4 that converges at the best possible rate that the non-lazy variant would achieve (up to a small constant factor)."
  }, {
    "heading": "3.2. Lazy Pairwise Conditional Gradient",
    "text": "In this section we provide a lazy variant (Algorithm 4) of the Pairwise Conditional Gradient algorithm from Garber and Meshi (2016), using separation instead of linear optimization. We make identical assumptions: the feasible region is a 0/1 polytope, i.e., all vertices of P have only 0/1 entries, and moreover it is given in the form P = {x ∈ Rn | 0 ≤ x ≤ 1, Ax = b}, where 1 denotes the all-one vector.\nAlgorithm 4 Lazy Pairwise Conditional Gradient (LPCG)\nInput: polytope P , smooth and S-strongly convex function f with curvature C, accuracy K ≥ 1, non-increasing step-sizes ηt, eagerness ∆t Output: points xt 1: x1 ∈ P arbitrary and Φ0 ≥ f(x1)− f(x∗) 2: for t = 1, . . . , T do\n3: ∇̃f(xt)i := { ∇f(xt)i if xt,i > 0 −∞ if xt,i = 0 4: Φt ← 2Φt−1+η 2 tC\n2+ ηt K∆t 5: ct ← ( ∇f(xt),−∇̃f(xt) ) 6: (v+t , v − t )← LPsepP×P ( ct, (xt, xt), Φt ∆t , K ) 7: if (v+t , v − t ) = false then 8: xt+1 ← xt 9: else\n10: η̃t ← max{2−δ | δ ∈ Z≥0, 2−δ ≤ ηt} 11: xt+1 ← xt + η̃t(v+t − v−t ) 12: end if 13: end for\nObserve that Algorithm 4 calls the linear separation oracle LPsep on the cartesian product of P with itself. Choosing the objective function as in Line 5 allows us to simultaneously find an improving direction and an away-step direction.\nLet cardx denote the number of non-zero entries of the vector x.\nTheorem 2 Let x∗ be a minimum point of f in P , and Φ0 an upper bound of f(x1)−f(x∗). Furthermore, let card(x∗) ≤ α, M1 := √ S 8α , κ := min { M1 KC , 1/ √ Φ0 } , ηt := κ √ Φt−1 and\n∆t := √ 2αΦt−1 S , then Algorithm 4 has convergence rate\nf(xt+1)− f(x∗) ≤ Φt ≤ Φ0 ( 1 +B\n1 + 2B\n)t ,\nwhere B := κ · M12K .\nWe recall a technical lemma for the proof.\nLemma 3 ((Garber and Meshi, 2016, Lemma 2)) Let x, y ∈ P . Then x is a liner combination x = ∑k i=1 λivi of some vertices vi of P (in particular, ∑k i=1 λi = 1) with\nx−y = ∑ki=1 γi(vi−z) for some 0 ≤ γi ≤ λi and z ∈ P such that ∑ki=1 γi ≤√card(y)‖x−y‖. Proof [Proof of Theorem 2] The feasibility of the iterates xt is ensured by Line 10 and the monotonicity of the sequence {ηt}t≥1 with the same argument as in (Garber and Meshi, 2016, Lemma 1 and Observation 2).\nWe first show by induction that\nf(xt+1)− f(x∗) ≤ Φt.\nFor t = 0 we have Φ0 ≥ f(x1)− f(x∗). Now assume the statement for some t ≥ 0. In case of a negative call (Line 8), we use the guarantee of Oracle 1 to get\nct[(xt, xt)− (z1, z2)] ≤ Φt ∆t\nfor all z1, z2 ∈ P , which is equivalent to (as ct(xt, xt) = 0)\n∇̃f(xt)z2 −∇f(xt)z1 ≤ Φt ∆t\nand therefore\n∇f(xt)(z̃2 − z1) ≤ Φt ∆t , (2)\nfor all z̃2, z1 ∈ P with supp(z̃2) ⊆ supp(xt), where supp(x) denotes the set of non-zero coordinates of x. We use Lemma 3 for the decompositions xt = ∑k i=1 λivi and xt − x∗ =∑k\ni=1 γi(vi − z) with 0 ≤ γi ≤ λi, z ∈ P and\nk∑ i=1 γi ≤ √ card(x∗)‖xt − x∗‖ ≤ √ 2 card(x∗)Φt−1 S ≤ ∆t,\nusing the induction hypothesis and strong convexity in the second inequality. Then\nf(xt+1)− f(x∗) = f(xt)− f(x∗) ≤ ∇f(xt)(xt − x∗) = k∑ i=1 γi · ∇f(xt)(vi − z)︸ ︷︷ ︸ ≤Φt/∆t ≤ Φt,\nwhere we used Equation (2) for the last inequality.\nIn case of a positive call (Lines 10 and 11) we get, using first smoothness of f , then ηt/2 < η̃t ≤ ηt and ∇f(xt)(v+t − v−t ) ≤ −Φt/(K∆t), and finally the definition of Φt:\nf(xt+1)− f(x∗) = f(xt)− f(x∗) + f(xt + η̃t(v+t − v−t ))− f(xt)\n≤ Φt−1 + η̃t∇f(xt)(v+t − v−t ) + η̃2tC\n2\n≤ Φt−1 − ηt 2 · Φt K∆t + η2tC 2 = Φt.\nPlugging in the values of ηt and ∆t to the definition of Φt gives the desired bound.\nΦt = 2Φt−1 + η\n2 tC\n2 + ηtK∆t = Φt−1\n1 + κ2C/2\n1 + κM1/K ≤ Φt−1\n1 +B\n1 + 2B ≤ Φ0\n( 1 +B\n1 + 2B\n)t ."
  }, {
    "heading": "3.3. Lazy Local Conditional Gradient",
    "text": "In this section we provide a lazy version (Algorithm 5) of the conditional gradient algorithm from Garber and Hazan (2013). Let P ⊆ Rn be any polytope, D denote an upper bound on the `2-diameter of P , and µ ≥ 1 be an affine invariant parameter of P satisfying Lemma 4 below, see (Garber and Hazan, 2013, Section 2) for a possible definition. As the algorithm is not affine invariant by nature, we need a non-invariant version of smoothness: Recall that a convex function f is β-smooth if\nf(y)− f(x) ≤ ∇f(x)(y − x) + β‖y − x‖2/2.\nAlgorithm 5 Lazy Local Conditional Gradient (LLCG)\nInput: feasible polytope P , β-smooth and S-strongly convex function f , parameters K, S, β, µ; diameter D Output: points xt 1: x1 ∈ P arbitrary and Φ0 ≥ f(x1)− f(x∗) 2: α← S\n2Kβnµ2\n3: for t = 1, . . . , T do 4: rt ← √ 2Φt−1 S 5: Φt ← Φt−1+ β 2 α2 min{nµ2r2t ,D2} 1+α/K 6: pt ← LLPsepP (∇f(xt), xt, rt,Φt,K) 7: if pt = false then 8: xt+1 ← xt 9: else\n10: xt+1 ← xt + α(pt − xt) 11: end if 12: end for\nAlgorithm 6 Weak Local Separation LLPsepP (c, x, r,Φ,K) Input: polytope P together with invariant µ, linear objective c ∈ Rn, point x ∈ P , radius r > 0, objective value Φ > 0, accuracy K ≥ 1 Output: Either (1) y ∈ P with ‖x − y‖ ≤ √nµr and c(x − y) > Φ/K, or (2) false: c(x− z) ≤ Φ for all z ∈ P ∩ Br (x).\n1: ∆← min {√\nnµ D r, 1 } 2: Decompose x: x = ∑M j=1 λjvj , λj > 0, ∑ j λj = 1.\n3: Sort vertices: i1, . . . , iM cvi1 ≥ · · · ≥ cviM . 4: k ← min{k : ∑kj=1 λij ≥ ∆} 5: p− ← ∑k−1 j=1 λijvij + ( ∆−∑k−1j=1 λij) vik\n6: v∗ ← LPsepP ( c, p−∆ , Φ ∆ ) 7: if v∗ = false then 8: return false 9: else\n10: return y ← x− p− + ∆v∗ 11: end if\nAs an intermediary step, we first implement a local weak separation oracle in Algorithm 6, a local version of Oracle 1, which finds improving points only in a small neighborhood of the original point, analogously to the local linear optimization oracle in Garber and Hazan (2013). To this end, we recall a technical lemma from Garber and Hazan (2013). Lemma 4 (Garber and Hazan, 2013, Lemma 7) Let P ⊆ Rn be a polytope and v1, . . . , vN be its vertices. Let x, y ∈ P and x = ∑Ni=1 λivi a convex combination of the vertices of P . Then there are numbers 0 ≤ γi ≤ λi and z ∈ P satisfying\nx− y = ∑ i∈[N ] γi(z − vi)\n∑ i∈[N ] γi ≤ √ nµ D ‖x− y‖.\nNow we prove the correctness of the weak local separation algorithm.\nLemma 5 Algorithm 6 is correct. In particular LLPsepP (c, x, r,Φ,K)\n(i) returns either an y ∈ P with ‖x− y‖ ≤ √nµr and c(x− y) ≥ Φ/K, (ii) or returns false, and then c(x− z) ≤ Φ for all z ∈ P ∩ Br (x).\nProof We first consider the case when the algorithm exits in Line 10. Observe that y ∈ P since y is a convex combination of vertices of by construction: y = ∑M j=1(λij − γj)vij + ∆v∗\nwith ∆ = ∑M j=1 γj ≤ √ nµ D r, where γj = λij for j < k, and γk = ∆− ∑k−1 j=1 λij , and γj = 0 for j > k. Therefore\n‖x− y‖ = ∥∥∥∥∥∥ M∑ j=1 γj(vij − v∗) ∥∥∥∥∥∥ ≤ M∑ j=1 γj‖vij − v∗‖ ≤ √ nµr.\nFinally using the guarantee of LPsepP we get c(x− y) = ∆c (p−\n∆ − v∗ ) ≥ Φ K .\nIf the algorithm exits in Line 8, we use Lemma 4 to decompose any y ∈ P ∩ Br (x):\nx− y = M∑ i=1 γi(vi − z),\nwith z ∈ P and ∑Mi=1 γi ≤ √nµD ‖x − y‖ ≤ ∆. Since ∑Mi=1 λi = 1 ≥ ∆, there are numbers γi ≤ η−i ≤ λi with ∑M i=1 η − i = ∆. Let\np̃− := M∑ i=1 η−i vi,\np̃+ := y − x+ p̃− = M∑ i=1 (η−i − γi)vi + M∑ i=1 γiz,\nso that p̃+/∆ ∈ P . To bound the function value we first observe that the choice of p− in the algorithm assures that cu ≤ cp− for all u = ∑M i=1 ηivi with ∑M i=1 ηi = ∆ and all 0 ≤ ηi ≤ λi. In particular, cp̃− ≤ cp−. The function value of the positive part p̃+ can be bounded with the guarantee of LPsepP :\nc ( p− ∆ − p̃+ ∆ ) ≤ Φ ∆ ,\ni.e., c(p− − p̃+) ≤ Φ. Finally combining these bounds gives\nc(x− y) = c (p̃− − p̃+) ≤ c(p− − p̃+) ≤ Φ\nas desired.\nWe are ready to examine the Conditional Gradient Algorithm based on LLPsepP :\nTheorem 6 Algorithm 5 converges with the following rate: f(xt+1)− f(x∗) ≤ Φt ≤ Φ0 ( 1 + α/(2K)\n1 + α/K\n)t .\nProof The proof is similar to the proof of Theorem 2. We prove this rate by induction. For t = 0 the choice of Φ0 guarantees that f(x1)− f(x∗) ≤ Φ0. Now assume the theorem holds for t ≥ 0. With strong convexity and the induction hypothesis we get\n‖xt − x∗‖2 ≤ 2 S (f(xt)− f(x∗)) ≤ 2 S Φt−1 = r 2 t ,\ni.e., x∗ ∈ P ∩ Brt (xt). In case of a negative call, i.e., when pt = false, then case (ii) of Lemma 5 applies:\nf(xt+1)− f(x∗) = f(xt)− f(x∗) ≤ ∇f(xt)(xt − x∗) ≤ Φt.\nIn case of a positive call, i.e., when Line 10 is executed, we get the same inequality via:\nf(xt+1)− f(x∗) ≤ Φt−1 + α∇f(xt)(pt − xt) + β\n2 α2‖xt − pt‖2\n≤ Φt−1 − α Φt K + β 2 α2 min{nµ2r2t , D2} = Φt.\nTherefore using the definition of α and rt we get the desired bound:\nΦt ≤ Φt−1 +\nβ 2α 2r2t nµ 2\n1 + α/K = Φt−1\n( 1 + α/(2K)\n1 + α/K\n) ≤ Φ0 ( 1 + α/(2K)\n1 + α/K\n)t ."
  }, {
    "heading": "4. Parameter-free Conditional Gradient via Weak Separation",
    "text": "In this section we provide a parameter-free variant of the Lazy Frank–Wolfe Algorithm, which is inspired by Pokutta (2017) and which exhibits a very favorable behavior in computations; the same technique applies to all other variants from Section 3 as well. The idea is that instead of using predetermined values for progress parameters, like Φt and γt in Algorithm 3, to optimize worst-case progress, the parameters are adjusted adaptively, using data encountered by the algorithm, and avoiding hard-to-estimate parameters, like the curvature C. In practice, this leads to faster convergence, as usual for adaptive methods, while the theoretical convergence rate is worse only by a small constant factor. See Figure 14 for a comparison and Section 8.1.1 for more experimental results.\nThe occasional halving of the Φt is reminiscent of an adaptive restart strategy, considering successive iterates with the same Φt as an epoch. It ensures that Φt is always at least half of the primal gap, while quickly reducing it if it is too large for the algorithm to make progress, and as such it represents a reasonable amount of expected progress throughout the whole run of the algorithm, not just at the initial iterates.\nRemark 7 (Additional LP call for initial bound) Note that Algorithm 7 finds a tight initial bound Φ0 with a single extra LP call. If this is undesired, this can be also done approximately as long as Φ0 is a valid upper bound, for example by means of binary search via the weak separation oracle.\nTheorem 8 Let f be a smooth convex function with curvature C. Algorithm 7 converges at a rate proportional to 1/t. In particular to achieve a bound f(xt)− f(x∗) ≤ ε, given an initial upper bound f(x1)− f(x∗) ≤ 2Φ0, the number of required steps is upper bounded by\nt ≤ ⌈\nlog Φ0 ε\n⌉ + 1 + 4K ⌈ log\nΦ0 KC\n⌉ + 16K2C\nε .\nProof The main idea of the proof is to maintain an approximate upper bound on the optimality gap. We then show that negative calls halve the upper bound 2Φt and positive oracle calls make significant objective function improvement.\nAlgorithm 7 Parameter-free Lazy Conditional Gradient (LCG) Input: smooth convex function f , start vertex x1 ∈ P , weak linear separation oracle LPsepP , accuracy K ≥ 1 Output: points xt in P 1: Φ0 ← maxx∈P ∇f(x1)(x1 − x)/2 {Initial bound} 2: for t = 1 to T − 1 do 3: vt ← LPsepP (∇f(xt), xt,Φt−1,K) 4: if vt = false then 5: xt+1 ← xt 6: Φt ← Φt−12 {Update Φ} 7: else 8: γt ← argmin0≤γ≤1 f((1− γ)xt + γvt) {Line search} 9: xt+1 ← (1− γt)xt + γtvt {Update iterate} 10: Φt ← Φt−1 11: end if 12: end for\nWe analyze iteration t of the algorithm. If Oracle 1 in Line 3 returns a negative answer (i.e., false, case (2)), then this guarantees ∇f(xt)(xt−x) ≤ Φt−1 for all x ∈ P , in particular, using convexity, f(xt+1)− f(x∗) = f(xt)− f(x∗) ≤ ∇f(xt)(xt − x∗) ≤ Φt−1 = 2Φt.\nIf Oracle 1 returns a positive answer (case (1)), then we have f(xt) − f(xt+1) ≥ γtΦt−1/K − (C/2)γ2t by smoothness of f . By minimality of γt, therefore f(xt)− f(xt+1) ≥ min0≤γ≤1(γΦt−1/K−(C/2)γ2), which is Φ2t−1/(2CK2) if Φt−1 < KC, and Φt−1/K−C/2 ≥ C 2 if Φt−1 ≥ KC.\nNow we bound the number t′ of consecutive positive oracle calls immediately following an iteration t with a negative oracle call. Note that the same argument bounds the number of initial consecutive positive oracle calls with the choice t = 0, as we only use f(xt+1)−f(x∗) ≤ 2Φt below.\nNote that Φt = Φt+1 = · · · = Φt+t′. Therefore\n2Φt ≥ f(xt+1)− f(x∗) ≥ t+t′∑ τ=t+1\n(f(xτ )− f(xτ+1)) ≥ { t′ Φ2t 2CK2\nif Φt < KC t′ (\nΦt K − C2 ) if Φt ≥ KC ,\nwhich gives in the case Φt < KC that t ′ ≤ 4CK2/Φt, and in the case Φt ≥ KC that\nt′ ≤ 2Φt Φt K − C2 = 4KΦt 2Φt −KC ≤ 4KΦt 2Φt − Φt = 4K.\nThus iteration t is followed by at most 4K consecutive positive oracle calls as long as Φt ≥ KC, and 4CK2/Φt < 2`+1 · 4K ones for 2−`−1KC < Φt ≤ 2−`KC with ` ≥ 0.\nAdding up the number of oracle calls gives the desired rate: in addition to the positive oracle calls we also have at most dlog(Φ0/ε)e+ 1 negative oracle calls, where log(·) is the binary logarithm and ε is the (additive) accuracy. Thus after a total of⌈\nlog Φ0 ε\n⌉ +1+4K ⌈ log\nΦ0 KC\n⌉ + dlog(KC/ε)e∑ `=0 2`+1 ·4K ≤ ⌈ log Φ0 ε ⌉ +1+4K ⌈ log Φ0 KC ⌉ + 16K2C ε\niterations (or equivalently oracle calls) we have f(xt)− f(x∗) ≤ ε.\nAs seen from the proof, the algorithm receives few negative oracle calls by design; these are usually more expensive than positive ones as the oracle has to compute a certificate by, e.g., executing a full linear optimization oracle call.\nCorollary 9 Algorithm 7 receives at most dlog Φ0/εe+ 1 negative oracle answers.\nRemark 10 (Improved use of Linear Optimization oracle) A possible improvement to Line 6 is Φt ← maxx∈P ∇f(xt)(xt − x)/2, assuming that at a negative call the oracle also provides the dual gap maxx∈P ∇f(xt)(xt − x) as well as the minimizer x̄ ∈ P of the oracle call. This is the case e.g., when the weak separation oracle is implemented as in Algorithm 2. Clearly, the minimizer x̄ can be also used to perform a progress step; albeit without guarantee w.r.t. to Φt.\nRemark 11 (Line Search) If line search is too expensive we can choose γt = min{1,Φt/KC} in Algorithm 7. In this case an estimate of the curvature C is required."
  }, {
    "heading": "5. Lazy Online Conditional Gradient",
    "text": "In this section we lazify the online conditional gradient algorithm of Hazan and Kale (2012) over arbitrary polytopes P = {x ∈ Rn | Ax ≤ b}, resulting in Algorithm 8. We slightly improve constant factors by replacing (Hazan and Kale, 2012, Lemma 3.1) with a better estimation via solving a quadratic inequality arising from strong convexity. In this section the norm ‖·‖ can be arbitrary.\nTheorem 12 Let 0 ≤ b, s < 1. Let K ≥ 1 be an accuracy parameter. Assume ft is L-Lipschitz, and smooth with curvature at most Ct−b. Let D := maxy1,y2∈P ‖y1 − y2‖ denote the diameter of P in norm ‖·‖. Then the following hold for the points xt computed by Algorithm 8 where x∗T is the minimizer of ∑T t=1 ft:\n(i) With the choice γt = t −(1−b)/2,\nthe xt satisfy\n1\nT T∑ t=1 (ft(xT )− ft(x∗T )) ≤ AT−(1−b)/2,\nwhere\nA := CK\n2(1− b) + L(K + 1)D.\n(ii) Moreover, if all the ft are St −s-strongly convex, then with the choice\nγt = t (b+s−2)/3,\nAlgorithm 8 Lazy Online Conditional Gradient (LOCG) Input: functions ft, start vertex x1 ∈ P , weak linear separation oracle LPsepP , parameters K, C, b, S, s; diameter D Output: points xt 1: for t = 1 to T − 1 do 2: ∇t ← ∇ft(xt) 3: if t = 1 then 4: h1 ← min{‖∇1‖∗D, 2 ‖∇1‖∗2 /S} 5: else\n6: ht ← Φt−1 + min { ‖∇t‖∗D, ‖∇t‖ ∗2\nSt1−s + 2 √ ‖∇t‖∗2 2St1−s ( ‖∇t‖∗2 2St1−s + Φt−1 )} 7: end if 8: Φt ← ht+ Ct1−bγ2t 2(1−b)\n1+ γt K 9: vt ← LPsepP ( ∑t\ni=1∇fi(xt), xt,Φt,K) 10: if vt = false then 11: xt+1 ← xt 12: else 13: xt+1 ← (1− γt)xt + γtvt 14: Φt ← ht − ∑t i=1 fi(xt) + ∑t i=1 fi(xt+1) 15: end if 16: end for\nthe xt satisfy\n1\nT T∑ t=1 (ft(xT )− ft(x∗T )) ≤ AT−(2(1+b)−s)/3, (3)\nwhere\nA := 2 ( (K + 1)(K + 2) L2\nS +\nCK\n2(1− b)\n) .\nProof We prove only Claim (ii), as the proof of Claim (i) is similar and simpler. Let FT := ∑T t=1 ft. Furthermore, let hT := AT\n1−(2(1+b)−s)/3 be T times the right-hand side of Equation (3). In particular, FT is ST -strongly convex, and smooth with curvature at most CFT where\nCFT := CT 1−b 1− b ≥ C T∑ t=1 t−b, ST := ST 1−s ≤ S T∑ t=1 t−s.\nWe prove Ft(xt)−Ft(x∗t ) ≤ ht ≤ ht by induction on t. The case t = 1 is clear. Let Φt denote the value of Φt in Line 8, while we reserve Φt to denote its value as used in Line 6. We start by showing Ft(xt+1)− Ft(x∗t ) ≤ Φt ≤ Φt. We distinguish two cases depending on the oracle answer vt from Line 9. For a negative oracle answer (vt = false), we have Φt = Φt and the weak separation oracle asserts maxy∈P ∇Ft(xt)(xt − y) ≤ Φt, which combined with the convexity of Ft provides\nFt(xt+1)− Ft(x∗t ) = Ft(xt)− Ft(x∗t ) ≤ ∇Ft(xt)(xt − xt∗) ≤ Φt = Φt.\nOtherwise, for a positive oracle answer, Line 14 and the induction hypothesis provides Ft(xt+1)−Ft(x∗t ) ≤ ht+Ft(xt+1)−Ft(xt) = Φt. To prove Φt ≤ Φt, we apply the smoothness of Ft followed by the inequality provided by the choice of vt:\nFt(xt+1)− Ft(xt)− CFtγ\n2 t\n2 ≤ ∇Ft(xt)(xt+1 − xt) = γt∇Ft(xt)(vt − xt) ≤ − γtΦt K .\nRearranging provides the inequality:\nΦt = ht + Ft(xt+1)− Ft(xt) ≤ ht − γtΦt K + CFtγ\n2 t\n2 = Φt.\nFor later use, we bound the difference between ht and Φt using the value of parameters, ht ≤ ht, and γt ≤ 1:\nht − Φt ≥ ht − ht +\nCFtγ 2 t\n2\n1 + γtK =\nhtγt K −\nCFtγ 2 t\n2 1 + γtK ≥\nhtγt K −\nCFtγ 2 t\n2 1 + 1K = A− CK2(1−b) K + 1 t[2s−(1+b)]/3.\nWe now apply Ft(xt+1)−Ft(x∗t ) ≤ Φt, together with convexity of ft+1, and the minimality Ft(x ∗ t ) ≤ Ft(x∗t+1) of x∗t , followed by strong convexity of Ft+1:\nFt+1(xt+1)− Ft+1(x∗t+1) ≤ (Ft(xt+1)− Ft(x∗t )) + (ft+1(xt+1)− ft+1(x∗t+1)) ≤ Φt + ‖∇t+1‖∗ · ‖xt+1 − x∗t+1‖\n≤ Φt + ‖∇t+1‖∗ √ 2\nSt+1 (Ft+1(xt+1)− Ft+1(x∗t+1)).\n(4)\nSolving the quadratic inequality provides\nFt+1(xt+1)− Ft+1(x∗t+1) ≤ Φt + ‖∇t+1‖∗2 St+1 + 2 √√√√‖∇t+1‖∗2 2St+1 ( ‖∇t+1‖∗2 2St+1 + Φt ) . (5)\nFrom Equation (4), ignoring the last line, we also obtain Ft+1(xt+1) − Ft+1(x∗t+1) ≤ Φt + ‖∇t+1‖∗D via the estimate ‖xt+1 − x∗t+1‖ ≤ D. Thus Ft+1(xt+1) − Ft+1(x∗t+1) ≤ ht+1, by Line 6, as claimed.\nNow we estimate the right-hand side of Equation (5) by using the actual value of the parameters, the estimate ‖∇t+1‖∗ ≤ L, and the inequality s+ b ≤ 2. In fact, we estimate a proxy for the right-hand side. Note that A was chosen to satisfy the second inequality:\nL2\nSt+1 + 2\n√ L2\n2St+1 ht ≤\nL2\nSt1−s + 2\n√ L2\n2St1−s ht ≤\nL2\nS t[2s−(1+b)]/3 + 2\n√ L2\n2St1−s ht\n=\n( L2\nS +\n√ 2 L2\nS A\n) t[2s−(1+b)]/3 ≤\nA− CK2(1−b) K + 1 t[2s−(1+b)]/3\n≤ ht − Φt ≤ ht − Φt.\nIn particular, L 2 2St+1 + Φt ≤ ht hence combining with Equation (5) we obtain\nht+1 ≤ Φt + L2\nSt+1 + 2\n√ L2\n2St+1\n( L2\n2St+1 + Φt\n)\n≤ Φt + L2\nSt+1 + 2\n√ L2\n2St+1 ht\n≤ ht ≤ ht+1."
  }, {
    "heading": "5.1. Stochastic and Adversarial Versions",
    "text": "Complementing the offline algorithms from Section 3, we will now derive various online versions. The presented cases here are similar to those in Hazan and Kale (2012) and thus we state them without proof.\nFor stochastic cost functions ft, we obtain bounds from Theorem 12 (i) similar to (Hazan and Kale, 2012, Theorems 4.1 and 4.3) (with δ replaced by δ/T in the bound to correct an inaccuracy in the original argument). The proof is analogous and hence omitted, but note that ‖y1 − y2‖2 ≤ √ ‖y1 − y2‖1‖y1 − y2‖∞ ≤ √ k for all y1, y2 ∈ P .\nCorollary 13 Let ft be convex functions sampled i.i.d. with expectation E [ft] = f∗, and δ > 0. Assume that the ft are L-Lipschitz in the 2-norm.\n(i) If all the ft are smooth with curvature at most C, then Algorithm 8 applied to the ft (with b = 0) yields with probability 1− δ\nT∑ t=1 f∗(xt)−min x∈P T∑ t=1 f∗(x) ≤ O ( C √ T + Lk √ nT log(nT 2/δ) log T ) .\n(ii) Without any smoothness assumption, Algorithm 8 (applied to smoothenings of the ft) provides with probability 1− δ\nT∑ t=1 f∗(xt)−min x∈P T∑ t=1 f∗(x) ≤ O (√ nLkT 2/3 + Lk √ nT log(nT 2/δ) log T ) .\nSimilar to (Hazan and Kale, 2012, Theorem 4.4), from Theorem 12 (ii) we obtain the following regret bound for adversarial cost functions with an analogous proof.\nCorollary 14 For any L-Lipschitz convex cost functions ft, Algorithm 8 applied to the functions f̃t(x) := ∇ft(xt)x+ 2L√k t −1/4‖x− x1‖22 (with b = s = 1/4, C = L √ k, S = L/ √ k, and Lipschitz constant 3L) achieving regret\nT∑ t=1 ft(xt)−min x∈P T∑ t=1 ft(x) ≤ O(L √ kT 3/4)\nwith at most T calls to the weak separation oracle.\nNote that the gradient of the f̃t are easily computed via the formula ∇f̃t(x) = ∇ft(xt) + 4Lt−1/4(x− x1)/ √ k, particularly because the gradient of the ft need not be recomputed, so that we obtain a weak separation-based stochastic gradient descent algorithm, where we only have access to the ft through a stochastic gradient oracle, while retaining all the favorable properties of the Frank–Wolfe algorithm with a convergence rate O(T−1/4) (c.f., Garber and Hazan (2013))."
  }, {
    "heading": "6. Non-polytopal domains",
    "text": "So far we have formulated our results for the polytopal case as most of the base methods that we lazify are usually formulated for polytopal domains. However, whenever a base method extends to general compact convex sets as domains then so does our lazification of the base method. In fact it is not even required to use vertices or extremal points as answers to either the LP oracle or weak-separation oracle calls; this is usually only required to obtain iterates as convex combinations of extremal points but it is not necessary for convergence.\nBase methods that extend to general compact convex sets in particular include the vanilla Frank–Wolfe algorithm, the Away-Step Frank–Wolfe algorithm, and the Pairwise Frank–Wolfe algorithm. Note, however that for the Away-Step Frank–Wolfe algorithm and the Pairwise Frank–Wolfe algorithm (irrespective of lazification) it is not known whether a linear rate of convergence can be achieved for strongly convex functions over general compact convex sets. Base variants that do not readily apply to the non-polyhedral case are the variants in Garber and Meshi (2016) (see Section 3.2) and Garber and Hazan (2013) (see Section 3.3).\nWe further would like to mention, that often (but not always) for non-polyhedral domains the linear optimization oracle might be more expensive, so that lazification might offer attractive benefits in this case as the effect of caching and early termination might be even more pronounced. We present computational tests for non-polyedral domains for matrix completion, where the feasible domain is given via ‖X‖∗ ≤ R, where ‖·‖∗ is the (non-polyhedral) nuclear norm (see Section 8.1)."
  }, {
    "heading": "7. Weak Separation through Augmentation",
    "text": "So far we realized the weak separation oracle via lazy optimization. We will now create a (weak) separation oracle for integral polytopes, employing an even weaker, so-called augmentation oracle, which only provides an improving solution but provides no guarantee with respect to optimality. We call this approach lazy augmentation. This is especially useful when a fast augmentation oracle is available or the vertices of the underlying polytope P are particularly sparse, i.e., ‖y1 − y2‖1 ≤ k n for all y1, y2 ∈ P , where n is the ambient dimension of P . As before theoretical convergence rates are maintained.\nFor simplicity of exposition we restrict to 0/1 polytopes P here. For general integral polytopes, one considers a so-called directed augmentation oracle, which can be similarly linearized after splitting variables in positive and negative parts; we refer the interested reader to see Schulz and Weismantel (2002); Bodic et al. (2015) for an in-depth discussion.\nLet k denote the `1-diameter of P . Upon presentation with a 0/1 solution x and a linear objective c ∈ Rn, an augmentation oracle either provides an improving 0/1 solution x̄ with cx̄ < cx or asserts optimality for c:\nOracle 2 Linear Augmentation Oracle AUGP (c, x) Input: linear objective c ∈ Rn, vertex x ∈ P Output: vertex x̄ ∈ P with cx̄ < cx when exists, otherwise x̄ = x\nSuch an oracle is significantly weaker than a linear optimization oracle but also significantly easier to implement and much faster; we refer the interested reader to Grötschel and Lovász (1993); Schulz et al. (1995); Schulz and Weismantel (2002) for an extensive list of examples. While augmentation and optimization are polynomially equivalent (even for convex integer programming Oertel et al. (2014)) the current best linear optimization algorithms based on an augmentation oracle are slow for general objectives. While optimizing an integral objective c ∈ Rn needs O(k log‖c‖∞) calls to an augmentation oracle (see Schulz et al. (1995); Schulz and Weismantel (2002); Bodic et al. (2015)), a general objective function, such as the gradient in Frank–Wolfe algorithms has only an O(kn3) guarantee in terms of required oracle calls (e.g., via simultaneous diophantine approximations Frank and Tardos (1987)), which is not desirable for large n. In contrast, here we use an augmentation oracle to perform separation, without finding the optimal solution. Allowing a multiplicative error K > 1, we realize an augmentation-based weak separation oracle (see Algorithm 9), which decides given a linear objective function c ∈ Rn, an objective value Φ > 0, and a starting point x ∈ P , whether there is a y ∈ P with c(x− y) > Φ/K or c(x− y) ≤ Φ for all y ∈ P . In the former case, it actually provides a certifying y ∈ P , i.e., with c(x− y) > Φ/K. Note that a constant accuracy K requires a linear number of oracle calls in the diameter k, e.g., K = (1− 1/e)−1 ≈ 1.582 needs at most N ≤ k oracle calls, which can be much smaller than the ambient dimension of the polytope.\nAt the beginning, in Line 2, the algorithm has to replace the input point x with an integral point x0. If the point x is given as a convex combination of integral points, then a possible solution is to evaluate the objective c on these integral points, and choose x0 the first one with cx0 ≤ cx. This can be easily arranged for Frank–Wolfe algorithms as they maintain convex combinations.\nProposition 15 Assume ‖y1−y2‖1 ≤ k for all y1, y2 ∈ P . Then Algorithm 9 is correct, i.e., it outputs either (1) y ∈ P with c(x−y) > Φ/K, or (2) false. In the latter case c(x−y) ≤ Φ for all y ∈ P holds. The algorithm calls AUGP at most N ≤ dlog(1− 1/K)/ log(1− 1/k)e many times. Proof First note that (1 − 2x)v + ‖x‖1 = ‖v − x‖1 for x, v ∈ {0, 1}n, hence Line 7 is equivalent to xi ← AUGP (c+ Φ−c(x−xi−1)k ‖· − xi−1‖1, xi−1).\nThe algorithm obviously calls the oracle at most N times by design, and always returns a value, so we need to verify only the correctness of the returned value. We distinguish cases according to the output.\nAlgorithm 9 Augmenting Weak Separation LPsepP (c, x,Φ,K) Input: linear objective c ∈ Rn, point x ∈ P , objective value Φ > 0; accuracy K > 1 Output: Either (1) y ∈ P vertex with c(x− y) > Φ/K, or (2) false: c(x− z) ≤ Φ for all\nz ∈ P . 1: N ← dlog(1− 1/K)/ log(1− 1/k)e 2: Choose x0 ∈ P vertex with cx0 ≤ cx. 3: for i = 1 to N do 4: if c(x− xi−1) ≥ Φ then 5: return xi−1 6: end if 7: xi ← AUGP (c+ Φ−c(x−xi−1)k (1− 2xi−1), xi−1) 8: if xi = xi−1 then 9: return false\n10: end if 11: end for 12: return xN\nClearly, Line 5 always returns an xi−1 with c(x− xi−1) ≥ Φ > [1− (1− 1/k)N ]Φ. When Line 9 is executed, the augmentation oracle just returned xi = xi−1, i.e., for all y ∈ P\ncxi−1 ≤ cy+ Φ− c(x− xi−1)\nk ‖y−xi−1‖1 ≤ cy+ Φ− c(x− xi−1) k k = c(y−x)+ cxi−1 +Φ,\nso that c(x− y) ≤ Φ, as claimed. Finally, when Line 12 is executed, the augmentation oracle has found an improving vertex xi at every iteration, i.e.,\ncxi−1 > cxi + Φ− c(x− xi−1)\nk ‖xi − xi−1‖1 ≥ cxi + Φ− c(x− xi−1) k ,\nusing ‖xi − xi−1‖1 ≥ 1 by integrality. Rearranging provides the convenient form\nΦ− c(x− xi) < (\n1− 1 k\n) [Φ− c(x− xi−1)],\nwhich by an easy induction provides\nΦ− c(x− xN ) < (\n1− 1 k\n)N [Φ− c(x− x0)] ≤ ( 1− 1\nK\n) Φ,\ni.e., c(x− xN ) ≥ ΦK , finishing the proof."
  }, {
    "heading": "8. Experiments",
    "text": "We implemented and compared the parameter-free variant of LCG (Algorithm 7) to the standard Frank–Wolfe algorithm (CG), then Algorithm 4 (LPCG) to the Pairwise Conditional\nGradient algorithm (PCG) of Garber and Meshi (2016), as well as Algorithm 8 (LOCG) to the Online Frank–Wolfe algorithm (OCG) of Hazan and Kale (2012). While we did implement the Local Conditional Gradient algorithm of Garber and Hazan (2013) as well, the very large constants in the original algorithms made it impractical to run. Unless stated otherwise the weak separation oracle is implemented as sketched in Algorithm 2 through caching and early termination of the original LP oracle.\nWe have used K = 1.1 and K = 1 as multiplicative factors for the weak separation oracle; for the impact of the choice of K see Section 8.2.2. For the baseline algorithms we use inexact variants, i.e., we solve linear optimization problems only approximately. This is a significant speedup in favor of non-lazy algorithms at the (potential) cost of accuracy, while neutral to lazy optimization as it solves an even more relaxed problem anyways. To put things in perspective, the non-lazy baselines could not complete even a single iteration for a significant fraction of the considered problems in the given time frame if we were to exactly solve the linear optimization problems. In terms of using line search, for all tests we treated all algorithms equally: either all or none used line search. If not stated otherwise, we used (simple backtracking) line search.\nThe linear optimization oracle over P × P for LPCG was implemented by calling the respective oracle over P twice: once for either component. Contrary to the non-lazy version, the lazy algorithms depend on the initial upper bound Φ0. For the instances that need a very long time to solve the (approximate) linear optimization even once, we used a binary search for Φ0 for the lazy algorithms: starting from a conservative initial value, using the update rule Φ0 ← Φ0/2 until the separation oracle returns an improvement for the first time and then we start the algorithm with 2Φ0, which is an upper bound on the Wolfe gap and hence also on the primal gap. This initial phase is also included in the reported wall-clock time. Alternatively, if the linear optimization was less time consuming we used a single (approximate) linear optimization at the start to obtain an initial bound on Φ0 (see e.g., Section 4).\nIn some cases, especially when the underlying feasible region has a high dimension and the (approximate) linear optimization can be solved relatively fast compared to the cost of computing an inner product, we observed that the costs of maintaining the cache was very high. In these cases we reduced the cache size every 100 steps by keeping only the 100 points that were used the most so far. Both the number of steps and the approximate size of the cache were chosen arbitrarily, however 100 for both worked very well for all our examples. Of course there are many different strategies for maintaining the cache, which could be used here and which could lead to further improvements in performance.\nThe stopping criteria for each of the experiments was a given wall clock time limit in seconds. The time limit was enforced separately for the main code and the oracle code, so in some cases the actual time used can be larger, when the last oracle call started before the time limit was reached and took longer than the time left.\nWe implemented all algorithms in Python 2.7 with critical functions cythonized for performance employing Numpy. We used these packages from the Anaconda 4.2.0 distribution as well as Gurobi 7.0 Gurobi Optimization (2016) as a black box solver for the linear optimization oracle. The weak separation oracle was implemented via a callback function to stop linear optimization as soon as a good enough feasible solution has been found in a schema as outlined in Algorithm 2. The parameters for Gurobi were kept at their\ndefault settings except for enforcing the time limit of the tests and setting the acceptable duality gap to 10%, allowing Gurobi to terminate the linear optimization early avoiding the expensive proof of optimality. This is used to realize the inexact versions of the baseline algorithms. All experiments were performed on a 16-core machine with Intel Xeon E5-2630 v3 @ 2.40GHz CPUs and 128GB of main memory. While our code does not explicitly use multiple threads, both Gurobi and the numerical libraries use multiple threads internally."
  }, {
    "heading": "8.1. Computational results",
    "text": "We performed computational tests on a large variety of different problems that are instances of the three machine learning tasks video colocalization, matrix completion, and structured regression.\nVideo colocalization. Video colocalization is the problem of identifying objects in a sequence of multiple frames in a video. In Joulin et al. (2014) it is shown that video colocalization can be reduced to optimizing a quadratic objective function over a flow or a path polytope, which is the problem we are going to solve. The resulting linear program is an instance of the minimum-cost network flow problem, see (Joulin et al., 2014, Eq. (3)) for the concrete linear program and more details. The quadratic functions are of the form ‖Ax− b‖2 where we choose the non-zero entries in A according to a density parameter at random and then each of these entries to be [0, 1]-uniformly distributed, while b is chosen as a linear combination of the columns of A with random multipliers from [0, 1]. For some of the instances we also use ‖x− b‖2 as the objective function with bi ∈ [0, 1] uniformly at random.\nMatrix completion. The formulation of the matrix completion problem we are going to use is the following:\nmin X ∑ (i,j)∈Ω |Xi,j −Ai,j |2 s.t. ‖X‖∗ ≤ R, (6)\nwhere ‖·‖∗ denotes the nuclear norm, i.e., ‖A‖∗ = Tr( √ AtA). The set Ω, the matrix A and R are given parameters. Similarly to Lan and Zhou (2014) we generate the m× n matrix A as the product of AL of size m × r and AR of size r × n. The entries in AL and AR are chosen from a standard Gaussian distribution. The set Ω is chosen uniformly of size s = min{5r(m+n−r), d0.99mne}. The linear optimization oracle is implemented in this case by a singular value decomposition of the linear objective function and we essentially solve the LP to (approximate) optimality. The matrix completion tests will only demonstrate the impact of caching solutions. Note that this test is also informative as due to the ‘roundness’ of the feasible region the solution of the actual LP oracle will induce a direction that is equal to the true gradient and as such it provides insight into how much per-iteration progress is lost due to working with gradient approximations from the weak separation oracle.\nStructured regression. The structured regression problem consists of solving a quadratic function of the form ‖Ax− b‖2 over some structured feasible set or a polytope P , i.e., we solve minx∈P ‖Ax− b‖2. We construct the objective functions in the same way as for the video colocalization problem.\nTests. In the following two sections we will present our results for various problems grouped by the versions of the considered algorithms. Every figure contains two columns, each containing one experiment. We use different measures to report performance: we report progress of loss or function value in wall-clock time in the first row (including time spent by the oracle), in the number of iterations in the second row, and in the number of linear optimization calls in the last row. Obviously, the latter only makes sense for the lazy algorithms. In some other cases we report in another row the dual bound or Wolfe gap in wall-clock time. The red line denotes the non-lazy algorithm and the green line denotes the lazy variants. For each experiment we also report the cache hit rate, which is the number of oracle calls answered with a point from the cache over all oracle calls given in percent.\nWhile we found convergence rates in the number of iterations quite similar (as expected!), we consistently observe a significant speedup in wall-clock time. In particular for many large-scale or hard combinatorial problems, lazy algorithms performed several thousand iterations whereas the non-lazy versions completed only a handful of iterations due to the large time spent approximately solving the linear optimization problem. The observed cache hit rate was at least 90% in most cases, and often even above 99%.\nCompared to the non-lazy variants, the lazy variants might use weaker descent directions (due to employing the weak-separation oracle instead of the LP oracle), and hence one expects that the lazy algorithms in general require more iterations despite being faster in wall-clock time. However, the lazy and non-lazy algorithms usually generate different sequences of iterates, and hence the lazy algorithms may converge faster even in the number of iterations by chance; this is even expected in a small number of cases by the law of large numbers. This happens for example in Figures 3 and 14."
  }, {
    "heading": "8.1.1. Offline Results",
    "text": "We describe the considered instances in the offline case separately for the vanilla Frank–Wolfe method and the Pairwise Conditional Gradient method.\nVanilla Frank–Wolfe Method We tested the vanilla Frank–Wolfe algorithm on the six video colocalization instances with underlying path polytopes from http://lime.cs.elte. hu/~kpeter/data/mcf/netgen/ (Figure 1). In these instances we additionally report the dual bound or Wolfe gap in wall clock time. We further tested the vanilla Frank–Wolfe algorithm on eight instances of the matrix completion problem generated as described above, for which we did not use line search; the parameter-free lazy variant is run with approximate minimization as described in Remark 11, the others use their respective standard step sizes. We provide the used parameters for each example in the figures below (Figures 2 and 3). The last tests for this version were performed on three instances of the structured regression problem, two with the feasible region containing flow-based formulations of Hamiltonian cycles in graphs (Figure 4), and further tests on two spanning tree instances of different size (Figure 5).\nWe observed a significant speedup of LCG compared to CG, due to the faster iteration of the lazy algorithm.\nPairwise Conditional Gradient Algorithm As we inherit structural restrictions of PCG on the feasible region, the problem repertoire is limited in this case. We tested the\nPairwise Conditional Gradient algorithm on the structured regression problem with feasible regions from the MIPLIB instances eil33-2, air04 (Figure 6).\nAgain similarly to the vanilla Frank–Wolfe algorithm, we observed a significant improvement in wall-clock time of LPCG compared to CG, due to the faster iteration of the lazy algorithm."
  }, {
    "heading": "8.1.2. Online Results",
    "text": "Additionally to the quadratic objective functions above we tested the online version on random linear functions cx + b with c ∈ [−1,+1]n and b ∈ [0, 1]. For online algorithms, each experiment used a random sequence of 100 different random loss functions. In every figure the left column uses linear loss functions, while the right one uses quadratic loss functions over the same polytope. As customary, we did not use line search here but used the respective prescribed step sizes.\nAs an instance of the structured regression problem we used the standard formulation of the cut polytope for graphs with 28 nodes as the feasible region (Figure 7). We also tested our algorithm on the quadratic unconstrained boolean optimization (QUBO) instances defined on Chimera graphs Dash (2013), which are available at http://researcher.watson.ibm.com/ researcher/files/us-sanjeebd/chimera-data.zip. The instances are relatively hard albeit their rather small size and in general the problem is NP-hard. (Figure 8).\nOne instance of the video colocalization problem uses a path polytope from http:// lime.cs.elte.hu/~kpeter/data/mcf/netgen/ that was generated with the netgen graph generator (Figure 9). Most of these instances are very large-scale minimum cost flow instances with several tens of thousands nodes in the underlying graphs, therefore solving still takes considerable time despite the problem being in P. Finally, for the spanning tree problem, we used the well-known extended formulation with O(n3) inequalities for an n-node graph. We considered graphs with 25 nodes (Figures 10).\nWe observed that similarly to the offline case while OCG and LOCG converge comparably in the number of iterations, the lazy LOCG performed significantly more iterations; for hard problems, where linear optimization is costly and convergence requires a large number of iterations, this led LOCG converging much faster in wall-clock time. In extreme cases OCG could not complete even a single iteration. This is due to LOCG only requiring some good enough solution, whereas OCG requires a stronger guarantee. This is reflected in faster oracle calls for LOCG.\nWeak-Separation via Augmentation As discussed in Section 7 in some cases it can be very beneficial to realize the weak-separation oracle by means of augmentation instead of linear optimization. To verify this we implemented a weak-separation oracle via an augmentation oracle for quadratic unconstrained boolean optimization (QUBO) instances (see above for details). For those instances, the primal heuristics of Gurobi (or CPLEX) can find improving solutions very fast due to the structure of the instances. We obtain the augmentation oracle then by exiting the Gurobi call as soon as the first improving solution is found. For comparability, apart from using the augmentation oracle we used the same configuration as above. The results can be found in Figure 11, where we can observe a significant speedup of the lazified variant of OCG using augmentation over the base OCG algorithm. Also observe that this is in contrast to Figure 8, where the advantage of LOCG\n(without augmentation) over OCG was not that pronounced. To provide further insight in this case we also report oracle time, which denotes actual time spent in the augmentation oracle, which is minimal in both cases as can be seen."
  }, {
    "heading": "8.2. Performance improvements, parameter sensitivity, and tuning",
    "text": ""
  }, {
    "heading": "8.2.1. Effect of caching",
    "text": "As mentioned before, lazy algorithms have two improvements: caching and early termination. Here we depict the effect of caching in Figure 12, comparing OCG (no caching, no early termination), LOCG (caching and early termination) and LOCG (only early termination) (see Algorithm 8). We did not include a caching-only OCG variant, because caching without early termination does not make much sense: in each iteration a new linear optimization problem has to be solved; previous solutions can hardly be reused as they are unlikely to be optimal for the new linear optimization problem."
  }, {
    "heading": "8.2.2. Effect of K",
    "text": "If the parameter K of the oracle can be chosen, which depends on the actual oracle implementation, then we can increase K to bias the algorithm towards performing more positive calls. At the same time the steps get shorter. As such there is a natural trade-off between the cost of many positive calls vs. a negative call. We depict the impact of the parameter choice for K in Figure 13."
  }, {
    "heading": "8.2.3. Parameter-free vs. textbook variant",
    "text": "For illustrative purposes, we compare the textbook variant of the lazy conditional gradient (Algorithm 3) with its parameter-free counterpart (Algorithm 7) in Figure 14. The parameterfree variant outperforms the textbook variant due to the active management of Φ combined with line search.\nSimilar parameter-free variants can be derived for the other algorithms; see discussion in Section 4."
  }, {
    "heading": "9. Final Remarks",
    "text": "As discussed above in Section 6, if a given baseline algorithm works over general compact convex sets P , then so does the lazified version. In fact, as the lazified algorithm runs, it produces a polyhedral approximation of the set P with very few vertices (subject to optimality vs. sparsity tradeoffs; see (Jaggi, 2013, Appendix C)).\nMoreover, the weak separation oracle does not need to return extreme points. All algorithms also work with maximal solutions that are not necessarily extremal (e.g., lying in a higher-dimensional face). However, in that case we lose the desirable property that the final solution is a sparse convex combination of extreme points (typically vertices in the polyhedral setup).\nWe would also like to briefly address potential downsides of our approach. In fact, we believe the right perspective is the following: when using the lazy oracle over the LP oracle, we obtain potentially weaker approximations vt − xt of the true gradient ∇f(xt) compared\nto solving the actual LP, but the computation might be much faster. This is the tradeoff that one has to consider: working with weaker approximations (which implies potentially less progress per iteration) vs. potentially significantly faster computation of the approximations. If solving the LP is expensive, then lazification will be usually very beneficial, if the LP is very cheap as in the case of P = [0, 1]n or P = ∆n being the probability simplex, then lazification might be slower.\nA related remark in this context is that once the lazified algorithm has obtained vertices x1, . . . , xm of P , so that the minimizer x\n∗ of f satisfies x∗ ∈ conv{x1, . . . , xm}, then from that point onwards no actual calls to the true LP oracle have to be performed anymore for primal progress and the algorithm will only use cache calls; the only remaining true LP calls are at most a logarithmic number for dual progress updates of the Φt."
  }, {
    "heading": "Acknowledgements",
    "text": "We are indebted to Alexandre D’Aspremont, Simon Lacoste-Julien, and George Lan for the helpful discussions and for providing us with relevant references. Research reported in this paper was partially supported by NSF CAREER award CMMI-1452463."
  }],
  "year": 2019,
  "references": [{
    "title": "Following the perturbed leader for online structured learning",
    "authors": ["2017. Alon Cohen", "Tamir Hazan"],
    "year": 2017
  }, {
    "title": "Linear-memory and decomposition-invariant linearly convergent conditional gradient algorithm for structured polytopes",
    "authors": ["Dan Garber", "Ofer Meshi"],
    "venue": "arXiv preprint,",
    "year": 2016
  }, {
    "title": "Solving combinatorial games using products, projections and lexicographically optimal bases",
    "authors": ["Swati Gupta", "Michel Goemans", "Patrick Jaillet"],
    "venue": "arXiv preprint arXiv:1603.00522,",
    "year": 2016
  }, {
    "title": "Introduction to online convex optimization",
    "authors": ["Elad Hazan"],
    "venue": "Foundations and Trends in Optimization,",
    "year": 2016
  }, {
    "title": "Projection-free online learning",
    "authors": ["Elad Hazan", "Satyen Kale"],
    "venue": "arXiv preprint arXiv:1206.4657,",
    "year": 2012
  }, {
    "title": "Revisiting Frank–Wolfe: Projection-free sparse convex optimization",
    "authors": ["Martin Jaggi"],
    "venue": "In Proceedings of the 30th International Conference on Machine Learning",
    "year": 2013
  }, {
    "title": "Cutting-plane training of structural SVMs",
    "authors": ["Thorsten Joachims", "Thomas Finley", "Chun-Nam John Yu"],
    "venue": "Machine Learning,",
    "year": 2009
  }, {
    "title": "Efficient image and video co-localization with Frank-Wolfe algorithm",
    "authors": ["Armand Joulin", "Kevin Tang", "Li Fei-Fei"],
    "venue": "In European Conference on Computer Vision,",
    "year": 2014
  }, {
    "title": "Efficient algorithms for online decision problems",
    "authors": ["Adam Kalai", "Santosh Vempala"],
    "venue": "Journal of Computer and System Sciences,",
    "year": 2005
  }, {
    "title": "On the global linear convergence of Frank–Wolfe optimization variants",
    "authors": ["Simon Lacoste-Julien", "Martin Jaggi"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Block-coordinate Frank–Wolfe optimization for structural SVMs",
    "authors": ["Simon Lacoste-Julien", "Martin Jaggi", "Mark Schmidt", "Patrick Pletscher"],
    "venue": "In ICML 2013 International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "Conditional gradient sliding for convex optimization",
    "authors": ["Guanghui Lan", "Yi Zhou"],
    "venue": "Optimization-Online preprint (4605),",
    "year": 2014
  }, {
    "title": "Constrained minimization methods",
    "authors": ["Evgeny S Levitin", "Boris T Polyak"],
    "venue": "USSR Computational mathematics and mathematical physics,",
    "year": 1966
  }, {
    "title": "An efficient algorithm for learning with semi-bandit feedback",
    "authors": ["Gergely Neu", "Gábor Bartók"],
    "venue": "In Algorithmic Learning Theory,",
    "year": 2013
  }, {
    "title": "Integer convex minimization by mixed integer linear optimization",
    "authors": ["Timm Oertel", "Christian Wagner", "Robert Weismantel"],
    "venue": "Oper. Res. Lett.,",
    "year": 2014
  }, {
    "title": "Minding the gaps for block Frank–Wolfe optimization of structured SVMs",
    "authors": ["Anton Osokin", "Jean-Baptiste Alayrac", "Isabella Lukasewitz", "Puneet K Dokania", "Simon Lacoste-Julien"],
    "venue": "ICML 2016 International Conference on Machine Learning / arXiv preprint arXiv:1605.09346,",
    "year": 2016
  }, {
    "title": "Smooth convex optimization via geometric scaling",
    "authors": ["Sebastian Pokutta"],
    "year": 2017
  }, {
    "title": "The complexity of generic primal algorithms for solving general integer programs",
    "authors": ["Andreas S Schulz", "Robert Weismantel"],
    "venue": "Mathematics of Operations Research,",
    "year": 2002
  }, {
    "title": "0/1-integer programming: Optimization and augmentation are equivalent",
    "authors": ["Andreas S. Schulz", "Robert Weismantel", "Günter M. Ziegler"],
    "venue": "In Algorithms – ESA ’95,",
    "year": 1995
  }, {
    "title": "A multi-plane block-coordinate Frank–Wolfe algorithm for training structural SVMs with a costly max-oracle",
    "authors": ["Neel Shah", "Vladimir Kolmogorov", "Christoph H Lampert"],
    "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
    "year": 2015
  }],
  "id": "SP:805188f5c03e5432eba9b868bf0e901cc51ca5cb",
  "authors": [{
    "name": "Gábor Braun",
    "affiliations": []
  }, {
    "name": "Sebastian Pokutta",
    "affiliations": []
  }, {
    "name": "Daniel Zink",
    "affiliations": []
  }, {
    "name": "Mark Schmidt",
    "affiliations": []
  }],
  "abstractText": "Conditional gradient algorithms (also often called Frank–Wolfe algorithms) are popular due to their simplicity of only requiring a linear optimization oracle and more recently they also gained significant traction for online learning. While simple in principle, in many cases the actual implementation of the linear optimization oracle is costly. We show a general method to lazify various conditional gradient algorithms, which in actual computations leads to several orders of magnitude of speedup in wall-clock time. This is achieved by using a faster separation oracle instead of a linear optimization oracle, relying only on few linear optimization oracle calls.",
  "title": "Lazifying Conditional Gradient Algorithms"
}