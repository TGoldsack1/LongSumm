{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Causal graphs (Pearl, 2009b) are useful for representing causal relationships among interacting variables in large systems (Bottou et al., 2013). Over the last few decades, causal models have found use in computational advertising (Bottou et al., 2013), biological systems (Meinshausen et al., 2016), sociology (Blalock, 1985), agriculture (Splawa-Neyman et al., 1990) and epidemiology (Joffe et al., 2012). There are two important questions commonly studied with causal graphs: (i) How to learn a directed causal graph that encodes the pattern of interaction among components in a system (casual structure learning)? (Pearl, 2009b) , and (ii) Using previously acquired (partial) knowledge about the causal graph structure, how to estimate\n*Equal contribution 1The University of Texas at Austin 2IBM Thomas J. Watson Research Center. Correspondence to: Rajat Sen <rajat.sen@utexas.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nand/or to optimize the effect of a new intervention on other variables (optimization) (Bottou et al., 2013; Joffe et al., 2012; Kemmeren et al., 2014; Bonneau et al., 2007; Krouk et al., 2013)? Here, an intervention is a forcible change to the value of a variable in a system. The change either alters the relationship between the parental causes and the variable, or decouples it from the parental causes entirely. Our focus is on optimizing over a given set of interventions.\nAn illustrative example includes online advertising (Bottou et al., 2013), where there is a collection of click-through rate scoring algorithms that provide an estimate of the probability that an user clicks on an ad displayed at a specific position. The interventions occur through the choice of click-through rate scoring algorithm; the algorithm choice directly impacts ad placement and pricing, and through a complex network of interactions, affects the revenue generated through advertisements. The revenue is used to determine the best scoring algorithm (optimize for the best intervention); see Figure 1. Another example is in biological gene-regulatory networks (Bonneau et al., 2007), where a large number of genomes interact amongst each other and\nalso interact with environmental factors. The objective here is to understand the best perturbation of some genomes in terms of its effect on the expression of another subset of genomes (target) in cellular systems.\nThis paper focuses on the following setting: We are given apriori knowledge about the structure and strength of interactions over a small part of the causal graph. In addition, there is freedom to intervene (from a set of allowable interventions) at a certain node in the known part of the graph, and collect data under the chosen intervention; further we can alter the interventions over time and observe the corresponding effects. Given a set of potential interventions to optimize over, the key question of interest is: How to choose the best sequence of T allowable interventions in order to discover which intervention maximizes the expectation of a downstream target node?\nDetermining the best intervention in the above setting can be cast as a best arm identification bandit problem, as noted in (Lattimore et al., 2016). The possible interventions to optimize over are the arms of the bandit, while the sample value of the target node under an intervention is the reward.\nMore formally, suppose that V is a node in a causal graph G(V, E) (as shown in Fig. 2), with the parents of V denoted by pa(V ). In Fig. 1, V corresponds to the click-through rate and its parents are user-query and ads-chosen. This essentially means that V is causally determined by a function of pa(V ) and some exogenous random noise. This dependence is characterized by the conditional P(V |pa(V ))1. Then a (soft) intervention mathematically corresponds to changing this conditional probability distribution i.e. probabilistically forcing V to certain states given its parents. In the computational advertising example, the interventions correspond to changing the click through rate scoring algorithm (i.e P(click through rate|ads chosen, user query), whose input-output characteristics are well-studied. Further, suppose that the effect of an intervention is observed at a node Y which is downstream of V in the topological order (w.r.t G) -refer to Fig. 2. Then, our key question is stated as follows: Given a collection of interventions {P\n0 (V |pa(V )), . . . PK 1(V |pa(V ))}, find the best intervention among these K possibilites that maximizes E[Y ] under a fixed budget of T (intervention, observation) pairs."
  }, {
    "heading": "1.1. Main Contributions",
    "text": "(Successive Rejects Algorithm) We provide an efficient successive rejects multi-phase algorithm. The algorithm uses clipped importance sampling. The clipper level is set adaptively in each phase in order to trade-off bias and vari-\n1Formally if node V has parents V1, V2, then this distribution is the conditional P(V = v|V1 = v1, V2 = v2) for all v, v1, v2.\nance. Our procedure yields a major improvement over the algorithm in (Lattimore et al., 2016) (both in theoretical guarantees and in practice), which sets the clippers and allocates samples in a static manner.\n(Gap Dependent Error Guarantees under Budget Constraints) In the classic best arm identification problem (Audibert & Bubeck, 2010), Audibert et al. derive gap dependent bounds on the probability of error given a fixed sample budget. Specifically, let\n(i) be the i-th largest gap (difference) in the expected reward from that of the best arm (e.g.\n(1) is the difference between the best arm expected reward and the second best reward). Then, it has been shown in (Audibert & Bubeck, 2010) that the number of samples needed scales as (upto poly log factors) maxi(i/ 2\n(i)).\nIn our setting, a fundamental difference from the classical best arm setting (Audibert & Bubeck, 2010) is the information leakage across the arms, i.e, samples from one arm can inform us about the expected value of other arms because of the shared causal graph. We show that this information leakage yields significant improvement both in theory and practice. We derive the first gap dependent (gaps between the expected reward at the target under different interventions) bounds on the probability of error in terms of the number of samples T , cost budget B on the relative fraction of times various arms are sampled and the divergences between soft intervention distributions of the arms.\nIn our result (upto poly log factors) the factor i is replaced by the ’effective variance’ of the estimator for arm (i), i.e. we obtain (with informal notation) maxi 2i / 2\n(i). i can be much smaller than p i (the corresponding term in the results of (Audibert & Bubeck, 2010)). Our theoretical guarantees quantify the improvement obtained by leveraging information leakage, which has been empirically observed in (Bottou et al., 2013). We discuss in more detail in Sections 3.3, about how these guarantees can be exponentially better than the classical ones. We also derive gap dependent simple regret bounds (Section 3.1).\n(Novel f -divergence measure for analyzing Importance Sampling ) We provide a novel analysis of clipped importance sampling estimators, where pairwise f -divergences between the distributions {Pk(V |pa(V ))}, for a carefully chosen function f(.) (see Section E.1) act as the ‘effective variance’ term in the analysis for the estimators (similar to Bernstein’s bound (Bennett, 1962)).\n(Extensive Empirical Validation) We demonstrate that our algorithm outperforms the prior works (Lattimore et al., 2016; Audibert & Bubeck, 2010) on the Flow Cytometry data-set (Sachs et al., 2005) (in Section 4.1). We exhibit an innovative application of our algorithm for model interpretation of the Inception Deep Network (Szegedy et al., 2015) for image classification (refer to Section 4.2). Remark 1. The techniques in this paper can be directly applied to more general settings like (i) the intervention source (V ) can be a collection of nodes (V) and the changes affect the distribution P (V|pa(V)), where pa(V) is the union of all the parents; (ii) the importance sampling can be applied at a directed cut separating the sources and the targets, provided the effect of the interventions, on the nodes forming the cut can be estimated. Moreover, our techniques can be applied without the complete knowledge of the source distributions. We explain the variations in more detail in Section B in the appendix."
  }, {
    "heading": "1.2. Related Work",
    "text": "The problem lies at the intersection of causal inference and best arm identification in bandits. There have been many studies on the classical best arm identification in the bandit literature, both in the fixed confidence regime (Kaufmann et al., 2015; Gabillon et al., 2012) and in the fixed budget setting (Audibert & Bubeck, 2010; Chen & Li, 2015; Jamieson et al., 2014; Carpentier & Locatelli, 2016). It was shown recently in (Carpentier & Locatelli, 2016) that the results of (Audibert & Bubeck, 2010) are optimal. The key difference from our work is that, in these models, there is no information leakage among the arms.\nThere has been a lot of work (Mooij et al., 2016; Hyttinen et al., 2013; Eberhardt, 2008; Hauser & Bühlmann, 2012; Spirtes et al., 2001; Pearl, 2009a; Loh & Bühlmann, 2014; Shanmugam et al., 2015) on learning casual models from data and/or experiments and using it to estimate causal strength questions of the counterfactual nature. One notable work that partially inspired our work is (Bottou et al., 2013) where the causal graph underlying a computational advertising system (like in Bing, Google etc.) is known and the primary interest is to find out how a change in the system would affect some other variable.\nAt the intersection of causality and bandits, (Lattimore et al., 2016) is perhaps most relevant to our setting. It studies the problem of identifying the best hard interventions\non multiple variables (among many), provided the distribution of the parents of the target is known under those interventions. Simple regret bound of order O(1/ p T ) was derived. We assume soft interventions that affect the mechanism between a ’source’ node and its parents, far away from the target (similar to the case of computational advertising considered in (Bottou et al., 2013)). Further, we derive the first gap dependent bounds (that can be exponentially small in T ), generalizing the results of (Audibert & Bubeck, 2010). Our formulation can handle general budget constraints on the bandit arms and also recover the problem independent bounds of (Lattimore et al., 2016) (orderwise). Budget constraints in bandit settings have been explored before in (Abernethy et al., 2015; Slivkins, 2013).\nIn the context of machine learning, importance sampling has been mostly used to recondition input data to adhere to conditions imposed by learning algorithms (Sugiyama et al., 2007; Li et al., 2011; Zhang & Zhao, 2014)."
  }, {
    "heading": "2. Problem Setting",
    "text": "In this work, we consider the problem of identifying the best soft intervention, i.e. the one that maximizes the expected value of a certain target variable. The problem setting is best illustrated in Figure 2. Consider a causal graph G(V, E) that specifies directed causal relationships between the variables V . We provide a short introduction to causal graphs in Section A (in the appendix) for the sake of completeness. Let Y be a target random variable which is downstream in the graph G; the expected value of this target variable is the quantity of interest. Consider another random variable V along with its parents pa(V ). We assume that there are K possible soft interventions. Each soft intervention is a distinct conditional distribution that dictates the relationship pa(V ) ! V . During a soft intervention k 2 [K] ([K] = {0, 1, ..., K 1}), the conditional distribution of V given its parents is set to Pk(V |pa(V )) and all other relationships in the causal graph are unchanged.\nIt is assumed that the conditional distributions Pk(V |pa(V )) and marginals for pa(V ) for k 2 [K] are known from past experiments or existing domain knowledge. We only observe samples of Y, V and pa(V ), while the rest of the variables in the causal graph may be unobserved under different interventions. For simplicity we assume that the variables V, pa(V ) are discrete while the target variable Y may be continuous/discrete and has bounded support in [0, 1]. Further, we assume that the various conditionals, i.e. Pk (V |pa(V )) are absolutely continuous with respect to each other. In the case of discrete distributions, the non-zero supports of these distributions are identical. However, our algorithm can be easily generalized for continuous distributions on V and pa(V ) (as in our experiments in Section 4.1). In this setting, we\nare interested in the following natural question: Which of the K soft interventions yield the highest expected value of the target (E[Y ]) and what is the misidentification error that can be achieved with a finite total budget T for samples ?\nRemark 2. Although we may know apriori the joint distribution of pa(V ) and V under different interventions, how the change affects another variable Y in the causal graph is unknown and must be learnt from samples. The task is to transfer prior knowledge to identify the best intervention.\nBandit Setting: The K different soft interventions can be thought of as the K arms of a bandit problem. Let the reward of arm k be denoted by: µk = Ek [Y ], where Ek [Y ] is the expected value of Y under the soft intervention when the conditional distribution of V given its parents pa(V ) is set to Pk(V |pa(V )) (soft intervention k) while keeping all other things in G unchanged. We assume that there is only one best arm. Let k⇤ be the arm that yields the highest expected reward and µ⇤ be the value of the corresponding expected reward i.e. k⇤ = arg maxk µk and µ⇤ = µk⇤ . Let the optimality gap of the kth arm be defined as k = µ⇤ µk. We shall see that the these gaps { k}K 1k=0 and the relationship between distributions {Pk(V |pa(V ))}K 1k=0 are important parameters in the problem. Let = mink 6=k⇤ k.\nFixed Budget for Samples: In this paper, we work under the fixed budget setting of best arm identification (Audibert & Bubeck, 2010). Let Tk be the number of times the kth intervention is used to obtain samples. We require that PK\nk=0 Tk = T . Let ⌫k = Tk T be the fraction of times the\nkth intervention is played.\nAdditional Cost Budget on Interventions: In the context of causal discovery, some interventions require a lot more resources or experimental effort than the others. We find such examples in the context of online advertisement design (Bottou et al., 2013). Therefore, we introduce two variants of an additional cost constraint that influences the choice of interventions. (i) Difficult arm budget (S1): Some arms are deemed to be difficult. Let B ⇢ [K] be the set of difficult arms. We require that the total fraction of times the difficult arms are played does not exceed B i.e. P\nk2B ⌫k  B. (ii) Cost Budget (S2): This is the most general budget setting that captures the variable costs of sampling each arm (Slivkins, 2013). We assume that there is a cost ck associated with sampling arm k. It is required that the average cost of sampling does not exceed a cost budget B .ie.\nPK 1 k=0 ck⌫k  B. c = [c1, .., ck] along with\nthe total budget T completely defines this budget setting. It should be noted that S1 is a special case of S2.\nWe note that unless otherwise stated, we work with the most general setting in S2. We state some of our results\nin the setting S1 for clearer exposition.\nObjectives: There are two main quantities of interest:\n(Probability of Error): This is the probability of failing to identify the best soft intervention (arm). Let k̂(T, B) be the arm that is predicted to be the best arm at the end of the experiment. Then the probability of error e(T, B) (Audibert & Bubeck, 2010; Carpentier & Locatelli, 2016) is given by,\ne(T, B) = P ⇣ k̂(T, B) 6= k⇤ ⌘\n(Simple Regret): Another important quantity that has been analyzed in the best arm identification setting is the simple regret (Lattimore et al., 2016). The simple regret is given by r(T, B) = P\nk 6=k⇤ kP ⇣ k̂(T, B) = k ⌘ ."
  }, {
    "heading": "3. Our Main Results",
    "text": "In this section we provide our main theoretical contributions. In Section 3.2, we provide a successive rejects style algorithm that leverages the information leakage via importance sampling. Then, we provide theoretical guarantees on the probability of mis-identification (e(T, B)) and simple regret (r(T, B)) for our algorithm in Section 3.3. In order to explain our algorithm and our results formally, we first describe several key ideas in our algorithm and introduce important definitions in Section 3.1."
  }, {
    "heading": "3.1. Definitions",
    "text": "Quantifying Information Leakage: Observe that, µk = Ek[Y ] = Ek0 h\nY Pk(V |pa(V )) Pk0 (V |pa(V ))\ni\n. By weighting samples with the correct ratio of conditional probabilities Pk(·) and Pk0(·), it is possible to use samples under intervention k0 to estimate the mean under intervention k. This is the basic idea behind importance sampling which has been used in similar settings (Lattimore et al., 2016; Bottou et al., 2013). However, the variance of this estimator depends on the ratio of Pk(·) to P0k(·). We use a specific f -divergence measure between Pk(·) and P0k(·) to quantify the variance. This f -divergence measure can be calculated analytically or estimated from empirical data (without access to full distributions) using techniques like that of (Pérez-Cruz, 2008).\nDefinition 1. Let f(·) be a non-negative convex function such that f(1) = 0. For two joint distributions pX,Y (x, y) and qX,Y (x, y) (and the associated conditionals), the conditional f -divergence Df (pX|Y kqX|Y ) is given by:\nDf (pX|Y kqX|Y ) = EqX,Y h f ⇣ pX|Y (X|Y ) qX|Y (X|Y ) ⌘i .\nRecall that Pi is the conditional distribution of node V given the state of its parents pa(V ). Thus, Df (PikPj) is the conditional f -divergence between the conditional distributions Pi and Pj . Now we define some log-divergences\nthat are are crucial in the our analysis. Definition 2. (Mij measure) Let f1(x) = x exp(x 1) 1. We define the following log-divergence measure: Mij = 1 + log(1 + Df1(PikPj)), 8i, j 2 [K].\nAggregating Interventional Data: We describe an efficient estimator of Ek[Y ] (8k 2 [K]) that combines available samples from different arms. This estimator adaptively weights samples depending on the relative Mij measures, and also uses clipping to control variance by introducing bias. The estimator is given by (1).\nSuppose we obtain ⌧i samples from arm i 2 [K]. Let the total number of samples from all arms be denoted by ⌧ . Further, let us index all the samples by s 2 {1, 2, .., ⌧}, and Tk ⇢ {1, 2, .., ⌧} be the indices of all the samples collected from arm k. Let Xj(s) denotes the sample collected for random variable X under intervention j, at time instant s. Finally, let Zk = P\nj2[K] ⌧j/Mkj . We denote the estimate of µk by Ŷ ✏k (✏ is an indicator of the level of confidence desired). Our estimator is:\nŶ ✏k = 1\nZk\nK X\nj=0\nX\ns2Tj\n1\nMkj Yj(s) Pk(Vj(s)|pa(V )j(s)) Pj(Vj(s)|pa(V )j(s)) ⇥\n1\n⇢\nPk(Vj(s)|pa(V )j(s)) Pj(Vj(s)|pa(V )j(s))  2 log(2/✏)Mkj . (1)\nIn other words, Ŷ ✏k is the weighted average of the clipped samples, where the samples from arm j are weighted by 1/Mkj and clipped at 2 log(2/✏)Mkj . The choice of ✏ controls the bias-variance tradeoff which we will adaptively change in our algorithm. This adaptive clipping is crucial in deriving gap dependent bounds2."
  }, {
    "heading": "3.2. Algorithm",
    "text": "Now, we describe our main algorithmic contribution - Algorithm 1 and 2. Algorithm 1 starts by having all the K arms under consideration and then proceeds in phases, possibly rejecting one or more arms at the end of each phase.\nAt every phase, Estimator (1) with a phase specific choice of the ✏ parameter (i.e. controlling bias variance trade-off), is applied to all arms under consideration. Using a phase specific threshold on these estimates, some arms are rejected at the end of each phase. A random arm among the ones surviving at the end of all phases is declared to be the optimal. We now describe the duration of various phases.\nRecall the parameters T - Total sample budget available and B - average cost budget constraint. Let n(T ) =\n2We note that the authors in (Lattimore et al., 2016) discuss the possibility of a multi-phase approach, where clipper levels could change across phases. However, they do not pursue this direction (no specific algorithm or results) as their objective is to derive gap independent bounds (minimax regret).\ndlog 2 ⇥ log 10 p T e. Let log(n) = Pn\ni=1(1/i). We will have an algorithm with n(T ) phases numbered by ` = 1, 2., , n(T ). Let ⌧(`) be the total number of samples in phase `. We set ⌧(l) = T/(llog(n(T ))) for l 2 {1, .., n(T )}. Note that P\nl ⌧(l) = T . Let R be the set of arms remaining to compete with the optimal arm at the beginning of phase ` which is continuously updated.\nLet ⌧k(`) be the samples allocated to arm k in phase `. Let ⌧(`) be the vector consisting of entries {⌧k (`)}. The vector of allocated samples, i.e. ⌧(`) is decided by Algorithm 3. Intuitively, an arm that provides sufficient information about all the remaining arms needs to be given more budget than other less informative arms. This allocation depends on the average budget constraints and the relative log divergences between the arms (Definition 2). Algorithm 3 formalizes this intuition, and ensures that variance of the worst estimator (of the form (1)) for the arms in R is as good as possible (quantified in Theorem 4 and Lemma 4).\nAlgorithm 1 Successive Rejects with Importance Sampling -v1 (SRISv1) - Given total budget T and the cost budget B (along with ci’s) picks the best arm.\n1: SRIS(B, {Mkj}, T ) 2: R = [K]. 3: Form the matrix A 2 RK⇥K such that Akj = 1Mkj . 4: for ` = 1 to n(T ) do 5: ⌧(`) = ALLOCATE (c, B,A, R, ⌧(`)) (Algorithm 3) 6: Use arm k, ⌧k(`) times and collect samples (Y, V, pa(V )). 7: for k 2 R do 8: Let Ŷk be the estimator for arm k as in (1) calcu-\nlated with {Mkj}, ✏ = 2 (` 1) and the samples obtained in Line 6.\n9: end for 10: Let ŶH = arg maxk2R Ŷk. 11: R = R {k 2 R : ŶH > Ŷk + 5/2l}. 12: if |R| = 1 then 13: return: the arm in R. 14: end if 15: end for 16: return: A randomly chosen arm from R.\nRemark 3. Note that Line 6 uses only the samples acquired in that phase. Clearly, a natural extension is to modify the algorithm to re-use all the samples acquired prior to that step. We give that variation in Algorithm 2. We prove all our guarantees for Algorithm 1. We conjecture that the second variation has tighter guarantees (dropping a multiplicative log factor) in the sample complexity requirements.\nThe inverse of the maximal objective of the LP in Algorithm 3 acts as effective standard deviation uniformly for\nAlgorithm 2 Successive Rejects with Importance Sampling -v2 (SRISv2) - Given total budget T and the cost budget B (along with c) picks the best arm.\n1: Identical to Algorithm 1 except for Line 6 where all samples acquired in all the phases till that Line is used.\nall the estimators for the remaining arms in R. It is analogous to the variance terms appearing in Bernstien-type concentration bounds (refer to Lemma 4 in the appendix).\nDefinition 3. The effective standard deviation for budget B and arm set R ✓ [K] is defined as ⇤(B, R) = 1/v⇤(B, R) from Algorithm 3 with input B and arm set R.\nAlgorithm 3 Allocate - Allocates a given budget ⌧ among the arms to reduce variance.\n1: ALLOCATE(c, B,A, R, ⌧) 2: Solve the following LP:\n1\n⇤(B, R) = v ⇤(B, R) = max ⌫ min k2R [A⌫ ]k (2)\ns.t. K X\ni=0\nci⌫i  B and K X\nj=0\n⌫j = 1, ⌫i 0.\n3: Assign ⌧j = ⌫⇤j (B, R)⌧"
  }, {
    "heading": "3.3. Theoretical Guarantees",
    "text": "We state our main results as Theorem 1 and Theorem 2, which provide guarantees on probability of error and simple regret respectively. Our results can be interpreted as a natural generalization of the results in (Audibert & Bubeck, 2010), when there is information leakage among the arms. This is the first gap dependent characterization.\nTheorem 1. (Proved formally as Theorem 5) Let = min k 6=k⇤ k. Let ⇤(.) be the effective standard deviation as in Definition 3. The probability of error for Algorithm 1 satisfies:\ne(T, B)  2K2 log 2 (20/ ) exp\n✓\nT 2H̄log(n(T ))\n◆\n(3)\nwhen the budget for the total number of samples is T and 10/ p T . Here,\nH̄ = max k 6=k⇤ log 2 (10/ k) 3\n✓ ⇤(B, R⇤( k)) k ◆ 2\n(4)\nand R⇤( k) = {s : log 2\n⇣\n10\ns\n⌘\nblog 2\n⇣\n10\nk\n⌘\nc} is the set of arms whose distance from the optimal arm is roughly at most twice that of arm k.\nComparison with the result in (Audibert & Bubeck, 2010): Let R̃( k) = {s : s  k}, i.e. the set of arms which are closer to the optimal than arm k. Let H̃ = max\nk 6=k⇤ | ˜R( k)| 2 k . The result in (Audibert & Bubeck,\n2010) can be stated as: The error in finding the optimal arm is bounded as: e(T )  O ⇣ K2 exp ⇣\nT K log(K) ˜H\n⌘⌘\n.\nOur work is analogous to the above result (upto poly log factors) except that H̄ appears instead of H̃ . In Section D.1 (in the appendix), we demonstrate through simple examples that ⇤(B, R⇤( k)) can be significantly smaller than q\nR̃( k) (the corresponding term in e(T ) above) even when there are no average budget constraints. Moreover, our results can be exponentially better in the presence of average budget constraints (examples in Section D.1). Now we present our bounds on simple regret in Theorem 2. Theorem 2. (Proved formally as Theorem 5) Let ⇤(.) be the effective standard deviation as in Definition 3. The simple regret of Algorithm 1 when the number of samples is T satisfies:\nr(T, B)  10p T 1 n\n9k 6= k⇤ s.t k < 10/ p T o +\n2K2 X\nk 6=k⇤: k 10/ p T\nk log 2\n✓\n20\nk\n◆\nexp\n✓\nT 2H̄klog(n(T ))\n◆\n(5)\nHere, H̄k = max{l: l k} log2(10/ l)\n3\n( l/10)2v⇤(B,R⇤( l))2 and\nR⇤( k) = {s : log 2\n⇣\n10\ns\n⌘\nblog 2\n⇣\n10\nk\n⌘\nc}.\nComparison with the result in (Lattimore et al., 2016): In (Lattimore et al., 2016), the simple regret scales as O(1/ p T ) and does not adapt to the gaps. We provide gap dependent bounds that can be exponentially better than that of (Lattimore et al., 2016) (when k’s are not too small and the first term in (5) is zero). More over our bounds generalize to gap independent bounds that match O(1/ p T ). Further details are provided in Section D.2 (in the appendix).\nWe defer the theoretical analysis to Section E. Theorem 1 and Theorem 2 are subparts of our main technical theorem (Theorem 5), which is proved in Section E.5."
  }, {
    "heading": "4. Empirical Validation",
    "text": "We empirically validate the performance of our algorithms in two real data settings. In Section 4.1, we study the empirical performance of our algorithm on the flow cytometry data-set (Sachs et al., 2005). In Section 4.2, we apply our algorithms for the purpose of model interpretability of the Inception Deep Network (Szegedy et al., 2015) in the context of image classification. In Section F (in the appendix)\nwe include more experiments. In the appendix we empirically show that our divergence metric is fundamental and replacing it with other divergences is sub-optimal."
  }, {
    "heading": "4.1. Flow Cytometry Data-Set",
    "text": "The flow cytometry data-set (Sachs et al., 2005) (extensively used for validating causal inference algorithms) consists of multi-variate measurements of protein interactions in a single cell, under different experimental conditions (soft interventions). Our experiments are aimed at identifying the best intervention among many, given some ground truth about the causal graph. For, this purpose we borrow the causal graph from Fig. 5(c) in (Mooij & Heskes, 2013) (shown in Fig. 3a) and consider it to be the ground truth.\nParametric linear models have been popularly used for causal inference on this data-set (Meinshausen et al., 2016; Cho et al., 2016). We fit a GLM gamma model (Hardin et al., 2007) between the activation of each node and its parents in Fig. 3a using the observational data. In Section F.2 (in the appendix) we provide further details showing that the sampled distributions in the fitted model are extremely close to the empirical distributions from the data. The soft interventions signifying the arms are generated by changing the distribution of a source node pkc in the GLM. The objective is to identify the intervention that yields the highest output at the target node erk3 We provide empirical results for two sets of interventions at the source node. Both these experiments have been performed with 15 arms each representing different distributions at pkc.\nBudget Restriction: The experiments are performed in the budget setting S1, where all arms except arm 0 are deemed to be difficult. We plot our results as a function of the total samples T , while the fractional budget of the difficult arms (B) is set to 1/ p T . Therefore, we have P k 6=0 Tk  p\nT . This essentially belongs to the case when there is a lot of data that can be acquired for a default arm while any new change requires significant cost in acquiring samples.\nCompeting Algorithms: We test our algorithms on different problem parameters and compare with related prior work (Audibert & Bubeck, 2010; Lattimore et al., 2016). The algorithms compared are (i) SRISv1: Algorithm 1 introduced in Section 3.2. The divergences, Df1(Pi||Pj) are estimated from sampled data using techniques from (PérezCruz, 2008); (ii)SRISv2: Algorithm 2 as detailed in Section 3.2; (iii) SR: Successive Rejects Algorithm from (Audibert & Bubeck, 2010) adapted to the budget setting. The division of the total budget T into K 1 phases is identical,\n3The activations of the node erk have been scaled so that the mean is less than one. Note that the marginal distribution still has an exponential tail, and thus does not strictly adhere to our boundedness assumption on the target variable. However, the experiments suggest that our algorithms still perform extremely well.\nwhile the individual arm budgets are decided in each phase according to the budget restrictions; (iv) CR: Algorithm 2 from (Lattimore et al., 2016). The optimization problem for calculating the mixture parameter ⌘ is not efficiently solvable for general distributions and budget settings. Therefore, the mixture proportions are set by Algorithm 3.\nIn these experiments, the budget restrictions imply that arm 0 can be pulled much more than the other arms. Intuitively the divergences of the arms from arm 0 as well as the gap defines the hardness of identification. Fig. 3b represents a difficult scenario where the divergences Mk0 > 400 for many arms (large divergences imply low information leakage) and = 0.01 (small increases hardness). In Fig. 3c (easier scenario) the divergences Mk0 < 20 for most arms while the gap is same as before. We see that SRISv2 outperforms all the other algorithms by a large margin, especially in the low sample regime."
  }, {
    "heading": "4.2. Interpretability of Inception Deep Network",
    "text": "In this section we use our algorithm for model interpretation of the pre-trained Inception-v3 network (Szegedy et al., 2015) for classifying images. Model Interpretation essentially addresses: ’why does a learning model classify in a certain way?’, which is an important question for complicated models like deep nets (Ribeiro et al., 2016).\nWhen an RGB image is fed to Inception, it produces an ordered sequence of 1000 labels (e.g ’drums’, ’sunglasses’) and generally the top-10 labels are an accurate description of the objects in the image. To address interpretability, we segment the image into a number of superpixels/segments (using segmentation algorithms like SLIC (Achanta et al., 2010)) and infer which superpixels encourage the neural net to output a certain label (henceforth referred to as labelI; e.g ’drum’) in top-k (e.g. k = 10), and to what extent.\nGiven a mixture distribution over the superpixels of an image (Figure 4a), a few superpixels are randomly sampled from the distribution with replacement. Then a new image is generated where all other superpixels of the original image are blurred out except the ones selected. This image is then fed to Inception, and it is observed whether labelI appears within the top-k labels. A mixture distribution is said to be a good interpretation for label-I if there is a high probability that label-I appears for an image generated by this mixture distribution. To empirically test the goodness of a mixture distribution, we would generate (using this mixture distribution) a number of random images, and determine the fraction of images for which label-I appears; a large fraction indicates that the mixture distribution is a good interpretation of label-I.\nMotivated by the above discussion, we generate a large number (3200) of mixture distributions, with the goal of\nfinding the one that best interprets label-I. To highlight the applicability of our algorithm, we allow images to be generated for only 200 of these mixture distributions; in other words, most of the mixture distributions cannot be directly tested. Nevertheless, we determine the best from among the entire collection of mixture distributions (counterfactuals).\nSpecifically in our experiments, we consider the image in Figure 4a, partition it into 43 superpixels, and generate images from mixture distributions by sampling 5 superpixels (with replacement). We generate 3000 arm distributions which lie in the 43-dimensional simplex but have sparse support (sparsity of 10 in our examples). The support of these distributions are randomly generated by techniques like markov random walk (encourages contiguity), random choice, etc. as detailed in Section F.3 in the appendix. We are only allowed to sample using a different set of 200 arms that are dense distributions chosen uniformly at random from the 43-dimensional simplex. The distributions are generated in a manner which is completely agnostic to the image content. The total sample budget (T ) is 2500.\nFigure 4 shows images in which the segments are weighted in proportion to the optimal distribution (obtained by SRISv2) for the interpretation of three different labels. This showcases the true counterfactual power of the algorithm, as the set of arms that can be optimized over are disjoint from the arms that can be sampled from. Moreover the sample budget is less than the number of arms. This is an extreme special case of budget setting S2. We see that our algorithm can generate meaningful interpretations for all the labels with relatively less number of runs of Inception. Even sampling 10 times from each of the arms to be optimized over would require 30, 000 runs of Inception for a single image and label, while we use only 2500 runs by leveraging information leakage.\nConclusion: In this paper we provide the first gap depen-\ndent error and simple regret bounds for identifying the best soft intervention at a source node i.e the one that maximizes the expected value of a downstream target node. These bounds are a generalization of the classical best arm identification bounds (Audibert & Bubeck, 2010), when there is information leakage among the arms. We test our algorithm empirically on the flow cytometry data-set and also use it for interpretability of Inception-v3 deep net."
  }, {
    "heading": "Acknowledgements",
    "text": "This work is partially supported by NSF grants CNS1320175, CCF-1344364, 1407278, 1422549, 1618689, ARO grants W911NF-15-1-0227, W911NF-14-1-0258, W911NF-16-1-0377 and the US DoT supported D-STOP Tier 1 University Transportation Center."
  }],
  "year": 2017,
  "references": [{
    "title": "Low-cost learning via active data procurement",
    "authors": ["Abernethy", "Jacob", "Chen", "Yiling", "Ho", "Chien-Ju", "Waggoner", "Bo"],
    "venue": "In Proceedings of the Sixteenth ACM Conference on Economics and Computation,",
    "year": 2015
  }, {
    "title": "Best arm identification in multi-armed bandits",
    "authors": ["Audibert", "Jean-Yves", "Bubeck", "Sébastien"],
    "venue": "In COLT-23th Conference on Learning Theory-2010, pp. 13–p,",
    "year": 2010
  }, {
    "title": "Probability inequalities for the sum of independent random variables",
    "authors": ["Bennett", "George"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1962
  }, {
    "title": "Causal models in the social sciences",
    "authors": ["Blalock", "Hubert M"],
    "venue": "Transaction Publishers,",
    "year": 1985
  }, {
    "title": "Tight (lower) bounds for the fixed budget best arm identification bandit problem",
    "authors": ["Carpentier", "Alexandra", "Locatelli", "Andrea"],
    "venue": "arXiv preprint arXiv:1605.09004,",
    "year": 2016
  }, {
    "title": "On the optimal sample complexity for best arm identification",
    "authors": ["Chen", "Lijie", "Li", "Jian"],
    "venue": "arXiv preprint arXiv:1511.03774,",
    "year": 2015
  }, {
    "title": "Reconstructing causal biological networks through active learning",
    "authors": ["Cho", "Hyunghoon", "Berger", "Bonnie", "Peng", "Jian"],
    "venue": "PloS one,",
    "year": 2016
  }, {
    "title": "Almost optimal intervention sets for causal discovery",
    "authors": ["Eberhardt", "Frederick"],
    "venue": "In Proceedings of 24th Conference in Uncertainty in Artificial Intelligence (UAI),",
    "year": 2008
  }, {
    "title": "Best arm identification: A unified approach to fixed budget and fixed confidence",
    "authors": ["Gabillon", "Victor", "Ghavamzadeh", "Mohammad", "Lazaric", "Alessandro"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "Generalized linear models and extensions",
    "authors": ["Hardin", "James William", "Hilbe", "Joseph M", "Joseph"],
    "venue": "Stata press,",
    "year": 2007
  }, {
    "title": "Two optimal strategies for active learning of causal networks from interventional data",
    "authors": ["Hauser", "Alain", "Bühlmann", "Peter"],
    "venue": "In Proceedings of Sixth European Workshop on Probabilistic Graphical Models,",
    "year": 2012
  }, {
    "title": "Experiment selection for causal discovery",
    "authors": ["Hyttinen", "Antti", "Eberhardt", "Frederick", "Hoyer", "Patrik"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2013
  }, {
    "title": "lil’ucb: An optimal exploration algorithm for multi-armed bandits",
    "authors": ["Jamieson", "Kevin G", "Malloy", "Matthew", "Nowak", "Robert D", "Bubeck", "Sébastien"],
    "venue": "In COLT,",
    "year": 2014
  }, {
    "title": "Causal diagrams in systems epidemiology",
    "authors": ["Joffe", "Michael", "Gambhir", "Manoj", "Chadeau-Hyam", "Marc", "Vineis", "Paolo"],
    "venue": "Emerging themes in epidemiology,",
    "year": 2012
  }, {
    "title": "On the complexity of best arm identification in multiarmed bandit models",
    "authors": ["Kaufmann", "Emilie", "Cappé", "Olivier", "Garivier", "Aurélien"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2015
  }, {
    "title": "Gene regulatory networks in plants: learning causality from time and perturbation",
    "authors": ["Krouk", "Gabriel", "Lingeman", "Jesse", "Colon", "Amy Marshall", "Coruzzi", "Gloria", "Shasha", "Dennis"],
    "venue": "Genome biology,",
    "year": 2013
  }, {
    "title": "Causal bandits: Learning good interventions via causal inference",
    "authors": ["Lattimore", "Finnian", "Tor", "Reid", "Mark D"],
    "venue": "In Advances In Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Unbiased offline evaluation of contextual-bandit-based news article recommendation algorithms",
    "authors": ["Li", "Lihong", "Chu", "Wei", "Langford", "John", "Wang", "Xuanhui"],
    "venue": "In Proceedings of the fourth ACM international conference on Web search and data mining,",
    "year": 2011
  }, {
    "title": "High-dimensional learning of linear causal networks via inverse covariance estimation",
    "authors": ["Loh", "Po-Ling", "Bühlmann", "Peter"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Methods for causal inference from gene perturbation experiments and validation",
    "authors": ["Meinshausen", "Nicolai", "Hauser", "Alain", "Mooij", "Joris M", "Peters", "Jonas", "Versteeg", "Philip", "Bühlmann", "Peter"],
    "venue": "Proceedings of the National Academy of Sciences,",
    "year": 2016
  }, {
    "title": "Cyclic causal discovery from continuous equilibrium data",
    "authors": ["Mooij", "Joris", "Heskes", "Tom"],
    "venue": "arXiv preprint arXiv:1309.6849,",
    "year": 2013
  }, {
    "title": "Distinguishing cause from effect using observational data: methods and benchmarks",
    "authors": ["Mooij", "Joris M", "Peters", "Jonas", "Janzing", "Dominik", "Zscheischler", "Jakob", "Schölkopf", "Bernhard"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Causality: Models, Reasoning and Inference",
    "authors": ["Pearl", "Judea"],
    "year": 2009
  }, {
    "title": "Kullback-leibler divergence estimation of continuous distributions",
    "authors": ["Pérez-Cruz", "Fernando"],
    "venue": "In Information Theory,",
    "year": 2008
  }, {
    "title": "Why should i trust you?: Explaining the predictions of any classifier",
    "authors": ["Ribeiro", "Marco Tulio", "Singh", "Sameer", "Guestrin", "Carlos"],
    "venue": "In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2016
  }, {
    "title": "Causal protein-signaling networks derived from multiparameter single-cell data",
    "authors": ["Sachs", "Karen", "Perez", "Omar", "Pe’er", "Dana", "Lauffenburger", "Douglas A", "Nolan", "Garry P"],
    "year": 2005
  }, {
    "title": "Learning causal graphs with small interventions",
    "authors": ["Shanmugam", "Karthikeyan", "Kocaoglu", "Murat", "Dimakis", "Alexandros G", "Vishwanath", "Sriram"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Dynamic ad allocation: Bandits with budgets",
    "authors": ["Slivkins", "Aleksandrs"],
    "venue": "arXiv preprint arXiv:1306.0155,",
    "year": 2013
  }, {
    "title": "Causation, Prediction, and Search",
    "authors": ["Spirtes", "Peter", "Glymour", "Clark", "Scheines", "Richard"],
    "venue": "A Bradford Book,",
    "year": 2001
  }, {
    "title": "On the application of probability theory to agricultural experiments",
    "authors": ["Splawa-Neyman", "Jerzy", "DM Dabrowska", "TP Speed"],
    "venue": "essay on principles",
    "year": 1990
  }, {
    "title": "Covariate shift adaptation by importance weighted cross validation",
    "authors": ["Sugiyama", "Masashi", "Krauledat", "Matthias", "MÃžller", "Klaus-Robert"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2007
  }, {
    "title": "Stochastic optimization with importance sampling for regularized loss minimization",
    "authors": ["Zhang", "Tong", "Zhao", "Peiling"],
    "venue": "arXiv preprint arXiv:1401.2753,",
    "year": 2014
  }],
  "id": "SP:b0c5a226bf4e11a8e6094858ce791ac17f546d97",
  "authors": [{
    "name": "Rajat Sen",
    "affiliations": []
  }, {
    "name": "Karthikeyan Shanmugam",
    "affiliations": []
  }, {
    "name": "Alexandros G. Dimakis",
    "affiliations": []
  }, {
    "name": "Sanjay Shakkottai",
    "affiliations": []
  }],
  "abstractText": "Motivated by applications in computational advertising and systems biology, we consider the problem of identifying the best out of several possible soft interventions at a source node V in an acyclic causal directed graph, to maximize the expected value of a target node Y (located downstream of V ). Our setting imposes a fixed total budget for sampling under various interventions, along with cost constraints on different types of interventions. We pose this as a best arm identification bandit problem with K arms where each arm is a soft intervention at V, and leverage the information leakage among the arms to provide the first gap dependent error and simple regret bounds for this problem. Our results are a significant improvement over the traditional best arm identification results. We empirically show that our algorithms outperform the state of the art in the Flow Cytometry data-set, and also apply our algorithm for model interpretation of the Inception-v3 deep net that classifies images.",
  "title": "Identifying Best Interventions through Online Importance Sampling"
}