{
  "sections": [{
    "text": "Seong-Bae Park sbpark@sejong.knu.ac.kr\nHyun-Je Song hjsong@sejong.knu.ac.kr\nJunho Go jhgo@sejong.knu.ac.kr\nSe-Young Park seyoung@knu.ac.kr\nKweon Yang Kim kykim@kiu.ac.kr\n1 School of Computer Science and Engineering, Kyungpook National University, 80, Daehakro, Bukgu, Daegu, 702-701, Republic of Korea\n2 Department of Computer Engineering, Kyungil University, 50, Gamasilgil, Hayangeup, Gyeonsan, Gyeongbuk, 712-701, Republic of Korea\nKeywords Just-In-Time keyword extraction · Graph-Based keyword extraction · Forgetting curve · Keyword extraction from meeting transcripts"
  }, {
    "heading": "1 Introduction",
    "text": "A meeting is generally accomplished by a number of participants and a wide range of subjects are discussed. Therefore, it would be helpful to meeting participants to provide them with some additional information related to the current subject. For example, assume that a participant is discussing a specific topic with other participants at a meeting. A summary of previous meetings on the topic or detailed information of the ongoing meeting is one of the most important resources for the discussion.\nIn order to provide information on a topic to the participants, keywords should first be generated because keywords are often representatives of a topic. A number of techniques have been proposed for automatic keyword extraction (Frank et al. 1999; Turney 2000; Mihalcea and Tarau 2004; Wan et al. 2007), and they are designed to extract keywords from a written document. On the other hand, they are unsuitable for meeting transcripts. In a meeting, it is often desirable to extract the keywords at the time when a new utterance is made for the just-in-time service of additional information. Otherwise, the extracted keywords simply become the important words at the end of a meeting.\nFigure 1 presents a simple scenario of a meeting that consists of three participants discussing a specific topic, “improving sales in rural market areas.” If the participants know the results of the previous meeting or have detailed information, such as “sales in rural market areas last month,” they can improve their decision-making. To provide such information, keywords, such as “sale” and “rural market area” should be extracted from the speaker’s utterance as soon as they are spoken.\nThree key factors should be considered for just-in-time keyword extraction from meeting transcripts: time of the preceding utterances, topic of current utterance, and participants in a meeting. First, the current utterance is affected by the temporal history of the preceding utterances. That is, when a new utterance is made, it is likely to be related more closely to the latest utterances than older ones. Second, the preceding utterances that carry similar topics to the current utterance are more important than the irrelevant utterances. Because a meeting consists of several topics, utterances unrelated to the current utterance are inappropriate as a history of the current utterance. Third, the participants have their own interests, even if\nthey are in the same meeting. When a new utterance is made by a participant, the preceding utterances are likely to be more important than the utterances of the other participants.\nThis paper proposes a graph-based keyword extraction to reflect these factors. The proposed method represents each utterance as a graph where the nodes are candidate keywords. The preceding utterances are also expressed as history graphs, where the weight of an edge is the temporal importance of the keywords connected by the edge. There exist two kinds of history graphs. One is a content-based history graph that carries the contents of the meeting prior to the current utterance. The other is a participant-based history graph that manages the contents of a meeting connected to the participants. To reflect the temporal history of the utterances, a forgetting curve (Wozniak 1999) is adopted when updating the weights of the edges in the history graphs. This curve expresses effectively not only the reciprocal relationship between memory retention and time, but also the active recall that makes frequent words more consequential in keyword extraction. Then, two subgraphs relevant to the current utterance are derived from the content-based and participant-based history graphs. The subgraph from the content-based history graph is used as a history of the current utterance, whereas the one from the participant-based history graph is considered history of the current speaker. The content-based keywords for the current utterance are extracted by Mihalcea and Tarau (2004) from the merged graph of the current utterance graph and the subgraph derived from the content-based history graph. Similarly, the participant-based keywords are also extracted by TextRank from the merged graph of the current utterance graph and the subgraph from the participant-based history graph. Finally, the final keywords are selected by weighted sum of the extracted keywords from each merged graph.\nThe proposed method is evaluated using two kinds of data sets: the National Assembly transcripts in Korean and the ICSI meeting corpus (Janin et al. 2003) in English. The experimental results show that the proposed method outperforms both the TFIDF framework (Frank et al. 1999; Liu et al. 2009) and the PageRank-based graph model (Wan et al. 2007). One thing to note is that the proposed method improves even the supervised methods that do not reflect the utterance time and topic relevance for the ICSI corpus. In addition, it also achieves better performance than previous work (Song et al. 2013), which does not consider the meeting participants. This proves that it is essential to consider the time and content of the utterances and participants simultaneously in keyword extraction from meeting transcripts.\nThe main contributions of this paper are as follows.\n– We have introduced the just-in-time keyword extraction for meeting transcripts. To the best of our knowledge, this is the first study to define just-in-time keyword extraction. – We have extracted keywords by considering time of the preceding utterances, topic of current utterance, and participants in a meeting those are suitable to just-in-time circumstances. – We have used the forgetting curve in order to reflect the temporal history of the utterances. This is an interesting contribution, because it is naturally considered that recent history is more related to the current utterance than old history.\nThe rest of the paper is organized as follows. Section 2 reviews the related studies on keyword extraction. Section 3 explains the overall process of the proposed method. Section 4 addresses the detailed description on how to reflect the time and content of the utterances. Section 5 shows the keyword extraction incorporated with the participants. Section 6 explains how to select the final keywords with regard to both contents and participants. The experimental results are presented in Section 7. Finally, Section 8 draws some conclusions."
  }, {
    "heading": "2 Related work",
    "text": "Keyword extraction has been of interest for a long time in a range of fields, such as information retrieval, document clustering, summarization, etc. Therefore, there have been many studies on automatic keyword extraction. The frequency-based keyword extraction with TFIDF weighting (Frank et al. 1999) and the graph-based keyword extraction (Mihalcea and Tarau 2004) are two base models for this task. Many studies have attempted to extend them by incorporating specific information such as linguistic knowledge (Hulth 2003; Medelyan et al. 2009), language model (Tomokiyo and Hurst 2003), web-based resource (Turney 2003), and semantic knowledge (Chen et al. 2010). Recently, a topical graph-based keyword extraction (Liu et al. 2010) and knowledge-based (Wikipedia) keyword extraction (Xu et al. 2010; Wu and Giles 2013) have been proposed to reflect the semantic information. As a result, they show good performance in written texts. On the other hand, it is difficult to use them directly for spoken genres because such genres have significantly different characteristics from written text.\nA few studies have focused on keyword extraction for spoken genres. Among them, the extraction from meetings has attracted more concern because of the increased need for the grasping of important points in a meeting, or the opinion of each participant. The studies on meetings have focused on the exterior features of meeting dialogues, such as unstructured and ill-formed sentences. Liu et al. used some knowledge sources, such as Part-of-Speech (POS) filtering, word clustering, and sentence salience to reflect dialogue features, and found that a simple TFIDF-based keyword extraction that uses these knowledge sources works reasonably well (Liu et al. 2009). They also extended their work by adopting several features, such as decision-making sentence features, speech-related features, and summary features, which reflect meeting transcripts better (Liu et al. 2011). Chen et al. extracted keywords from spoken course lectures (Chen et al. 2010). In this study, they reflected prosodic information from the HKT forced alignment and topics in a lecture generated by Probabilistic Latent Semantic Analysis (pLSA). These studies focused on the exterior characteristics of spoken genres, because they assumed that entire scripts are given in advance and they extracted the keywords that best describe the scripts. However, to the best of our knowledge, there is no previous study that considers the time of the utterances, which is an intrinsic element of the spoken genres.\nThe relevance between current utterance and preceding utterances is a critical feature in keyword extraction from meeting transcripts. The study that considers this relevance explicitly is CollabRank, proposed by Wan and Xiao (2008). This is a collaborative approach to extract the keywords in a document. In this study, it was assumed that a few neighbor documents close to the current document can help extract keywords. Therefore, they applied a clustering algorithm to a document set, and then extracted the words that were reinforced by the documents within a cluster. However, this method did not consider the utterance time because it was designed to extract the keywords from normal documents. As a result, if it is applied to meeting transcripts, all preceding utterances would affect the current utterance uniformly, which leads to poor performance.\nAs micro-blogging services, such as Facebook and Twitter, are been widely used recently, there exist some studies on keyword extraction from such services. Zhao et al. proposed a method to extract keywords from tweets (Zhao et al. 2011). Their method is based on the insight that the previous keyword extractions do not work well with a single tweet because of the length limitation of tweets. To solve this problem, they first collected a large number of tweets and adopted the topical PageRank method proposed by Liu et al. (2010)\nto find topics from the tweets. Then, they incorporated the topics and information derived from retweets into extracting keywords in a probabilistic manner. On the other hand, Abilhoa and de Castro represented tweets as graphs and simply applied centrality measures to finding keywords (Abilhoa and de Castro L.N. 2014).\nTweets and meeting transcripts share a few characteristics. They are both quite short compared to normal text and they have a time-stamp, i.e., they are written with a timestamp. However, their major difference is focused topic flow. Tweets are usually represented with diverse topics non-continuously even if the tweets are written by a single person. This implies that it is not adequate to consider a topic flow of tweets when we extract keywords of tweets. However, meeting transcripts have a more focused flow of topics. Because utterances are influenced by previous context, keyword extraction on meetings should consider the flow.\nAs far as we know, there are only a few studies that consider temporal characteristics in keyword extraction. Saga and Tsuji proposed a method for extracting keywords from news articles (Saga and Tsuji 2013). They divided the articles into multiple sets according to time and extracted keywords in each article set using TFIDF. Because they managed each article set independently, their method can not achieve good performance if applied to meeting transcripts. Song et al. proposed the just-in-time keyword extraction on meeting transcripts (Song et al. 2013). This is our previous work, and it describes a preliminary version of the just-in-time keyword extraction presented in this paper. The method proposed in this paper has been improved from our previous work in that the meeting participants are considered in extracting keywords since they are one of the important components of a meeting. As a result, the keywords that fit a current utterance can be extracted better."
  }, {
    "heading": "3 Just-in-time keyword extraction for a meeting",
    "text": "Figure 2 shows the overall process of extracting the keywords from an utterance as soon as it is spoken. We represent all the components in a meeting as graphs. This is because graphs are effective in expressing the relationship between words, and the graph operations required for keyword extraction are also performed efficiently. That is, whenever an utterance is spoken, it is represented as a graph (G1), where the nodes are the potential keywords in the utterance. This is called the current utterance graph.\nNormally, all words within the current utterance are not keywords. We first extract the potential keywords from the current utterance. When the current utterance consists of m words, some are filtered using a stop-word list and their POS tags. Assume that n words remain after filtering, where n ≤ m. These n words become the vertices of the current utterance graph.\nGiven the current utterance graph, two kinds of keyword extraction methods are applied independently according to the data type that they handle. The first method extracts the keyword candidates based on the content words of the utterances, whereas the other performs this task based on the speaker of the utterances. The final keywords are then chosen from both keyword candidates.\nFigure 3 provides a detailed description of the content-based keyword extraction. The summary of all preceding utterances is represented as the Content-based history graph (G2). Based on this history graph, we extract the keywords from the current utterance. We assume that only the preceding utterances that are directly related to the current utterance are important for extracting keywords from the current utterance. Therefore, a content-based subgraph\nof G2 that maximally covers the current utterance graph (G1), is extracted. This is labeled as G3 in Fig. 3. The current utterance graph, G1, is then expanded by merging it with the subgraph. This expanded graph, G4, is referred to as the combined representation of the current and preceding utterances, and the keywords of the current utterance are then extracted from this expanded graph.\nFigure 4 presents the process of extracting the keywords based on the speakers of the utterances. Similar to the content-based keyword extraction, the participant-based keyword extraction also extracts the keywords from the current utterance by considering the speakers of the preceding utterances. First, a summary of all preceding utterances is represented as the Participant-based history graph (G5). Unlike the content-based history graph, the participant-based history graph incorporates meeting participants by considering only the previous utterances spoken by the speaker of current utterance. According to the assumption\nthat only the preceding utterances that are related directly to current utterance are important for extracting keywords, a participant-based subgraph of G5, which covers the current utterance graph (G1) maximally, is extracted. This is labeled as G6 in Fig. 4. Then, the current utterance graph, G1, is expanded by merging it with G6. Given the expanded graph, G7, the keywords are extracted from this expanded graph.\nFrom the candidate keywords extracted from of G4 and G7, the final keywords are selected by combining the two views. As a result, the final keywords reflect the information from both the meeting contents and the speaker’s interests. After the keywords are extracted from the current utterance, the current utterance becomes part of the history graph for the next utterance. Figure 5 gives an overview of extracting the final keywords and updating the history graphs. For this, the extracted keywords are also represented as a graph (G8), and are merged into the current history, G2 and G5. This merged graph becomes a new history graph for the next utterance. When merging the two graphs between the graph, G8 and the history graphs, the weight of each edge in G2 and G5 is updated to reflect the temporal history. If an edge connects two keywords from an old utterance, its weight becomes small. Similarly, the weights for the edges from the recent utterances become large. The weights of the edges from G8 are 1, which is the largest possible value."
  }, {
    "heading": "4 Content-based keyword extraction",
    "text": ""
  }, {
    "heading": "4.1 Current utterance graph and content-based history graph",
    "text": "Formally, the current utterance graph G1 = (V1, E1) is an undirected graph, where |V1| = n. E1 is a set of edges, and each edge implies that the nodes connected by the edge co-occur within a window of size W . The window slides from the beginning of the current utterance\nto its end, and creates edges whenever two keyword candidates belong to a window. For each e1ij ∈ E1 that connects nodes v1i and v1j , its weight is given by\nw1ij = { 1 if v1i and v 1 j co-occur within the window,\n0 otherwise. (1)\nThe preceding utterances in a meeting affect the current utterance. In content-based keyword extraction, it is assumed that only the keywords of the preceding utterances are effective, and thus represent the keywords of the preceding utterances as history graphs. The content-based history graph G2 = (V2, E2) is an undirected graph of keywords in the preceding utterances. That is, all vertices in V2 are the keywords extracted from one or more previous utterances, and the edge between the two keywords implies that they co-occurred at least once. Every edge in E2 has a weight that represents its temporal importance."
  }, {
    "heading": "4.2 Updating weights of history graphs",
    "text": "History graphs are updated whenever the keywords are extracted from a new utterance. This is because the current utterance becomes a part of the history graph for the next utterance. As a history, old utterances are less important than recent ones. Therefore, temporal importance should decrease gradually according to the passage of time. In addition, the keywords that occur frequently at a meeting are more important than those mentioned only once or twice.\nBecause the frequently mentioned keywords are normally the major topics of the meeting, their influence should last for a long time.\nTo model these characteristics, the forgetting curve (Wozniak 1999) is adopted when updating the history graphs. This curve models the decline of memory retention with time. Figure 6 shows a typical representation of the forgetting curve. The X-axis of this figure is time and the Y-axis is memory retention. As shown in this figure, the memory retention of new information decreases gradually by the exponential nature of forgetting. On the other hand, whenever the information is repeated, it is recalled longer. This is formulated as\nR = e− tS , where R is the memory retention, t is time, and S is the relative strength of the memory.\nBased on the forgetting curve, the weight of each edge w2ij in the history graphs is set to\nw2ij = e − t f (vi ,vj ) , (2)\nwhere t is the elapse of the utterance time and f (vi, vj ) is the frequency that vi and vj co-occur from the beginning of the meeting to now. The weight range of each edge is 0 < w2ij ≤ 1 since t and f (·, ·) are both positive. The strength of connection between keywords, w2ij , is initialized to one at t = 0, and it decreases gradually as time goes on. Therefore, the keywords extracted from old utterances are less important than those extracted from a new utterance. If some keywords appear again during a meeting, we increase their relative strength by incrementing their frequency f (·, ·), and t is set to zero again. As f (·, ·) becomes larger, the rate of w2ij reduction gets slower. Therefore, they are remembered longer in the history graph."
  }, {
    "heading": "4.3 Keyword extraction by merging the current utterance and history graphs",
    "text": "All words within the history graph are not equally important when extracting keywords from the current utterance. In general, many participants discuss a wide range of topics in a meeting. Therefore, some preceding utterances that share topics with the current utterance are more significant. We assume that the preceding utterances that contain the words in the current utterance share topics with the current utterance. Thus, only a subgraph of G2 that contains words in G1 is relevant for keyword extraction from G1.\nGiven the current utterance graph, G1 = (V1, E1), and the content-based history graph, G2 = (V2, E2), the relevant graph G3 = (V3, E3) is a subgraph of G2. Here, V3 = (V1 ∩ V2)∪adjacency(V1), where adjacency(V1) is a set of vertices from G2 that are connected directly to the words in V1. That is, V3 contains the words of G1 and their direct neighbor words in G2. E3 is a subset of E2. Only those edges that appear in E2 are included in E3. The weight, w3ij , of each e 3 ij ∈ E3 is also borrowed from G2. That is, w3ij = w2ij . Therefore, G3 is a 1-walk subgraph of G2 where the words in G1 and their neighboring words appear. The keywords of the current utterance should reflect the relevant history and the current utterance itself. For this purpose, G1 is expanded with respect to G3. The expanded graph G4 = (V4, E4) of G1 is defined as\nV4 = V1 ∪ V3, E4 = E1 ∪ E3.\nFor each edge e4ij ∈ E4, its weight, w4ij , is determined to be the larger value between w1ij and w3ij if it appears in both G1 and G3. When it appears in only one of the graphs, w 4 ij is set to be the weight of its corresponding graph, i.e.,\nw4ij = ⎧⎪⎨ ⎪⎩ max(w1ij , w 3 ij ) if e 4 ij ∈ E1 and e4ij ∈ E3, w1ij if e 4 ij ∈ E1 and e4ij /∈ E3,\nw3ij otherwise.\nFrom this expanded graph G4, the keywords are extracted by Mihalcea and Tarau (2004). TextRank is an unsupervised graph-based method for keyword extraction. This selects the key vertices of a graph by providing a ranking mechanism. In order to rank the vertices, TextRank calculates the score of each vertex, vi ∈ V4, by\nS(vi) = (1 − d) + d · ∑\nvj ∈adj (vi )\nwji∑ vk∈adj (vj ) wjk S(vj ), (3)\nwhere 0 ≤ d ≤ 1 is a damping factor and adj (vi) denotes the neighbors of vi’. Finally, the words, whose score is larger than a specific threshold, θ , are chosen as keywords. In particular, when the current utterance is the first utterance of a meeting, the history graph does not exist. In this case, the current utterance graph becomes the expanded graph (G4 = G1), and the keywords are extracted from the current utterance graph."
  }, {
    "heading": "5 Participant-based keyword extraction",
    "text": "Participant-based keyword extraction extracts the keywords from the current utterance by reflecting the interests of the participants. In order to consider the meeting participants, the participant-based keyword extraction first incorporates the meeting participants to the history graph. Second, it extracts a subgraph from the history graph to cover the current utterance maximally, considering the speaker of the current utterance.\nThe participant-based history graph G5 = (V5, E5) is an undirected graph of keywords in the preceding utterances and participants in a meeting. Here, the keywords and participants are represented as vertices. Therefore, there are two kinds of vertices in G5. One is a keyword vertex that represents the keyword extracted from one or more previous utterances. The other is a participant vertex that expresses the participant in a meeting. By adopting the participant as a vertex, an edge e5ij ∈ E5 between v5i and v5j implies that\n– v5i and v 5 j co-occur at least once if v 5 i and v 5 j are both keyword vertices, – a keyword is extracted from the utterances of the participant, if one of v5i and v 5 j is a\nkeyword and the other is a participant.\nThere is no edge between the participants because we have no interest in the relationship among participants. Thus, the weight w5ij of an edge e 5 ij is set as follows.\nw5ij = ⎧⎨ ⎩ λ if v5i and v 5 j are both keywords, 1 if v5i is a participant and v 5 j is a keyword, or vice versa,\n0 otherwise.\nwhere 0 ≤ λ ≤ 1 represents the temporal importance between two keywords. As with the content-based history graph, all words in the participant-based history graph are not equally important in extracting the keywords from the current utterance. We assume that only the preceding utterances that share the words with G1 and spoken by the speaker of G1 are relevant to the current utterance. Therefore, the keywords should be extracted from a subgraph of G5 that contains words in G1 and are uttered by the speaker of G1. Such a relevant subgraph of G5 is found through three steps. First, the participant vertex that corresponds to the speaker of G1 is identified. Next, a participant subgraph of G5 that consists of the words connected with the participant vertex is found. The relevant subgraph is then part of the participant subgraph, and its vertices are the words that appear in G1.\nFormally, when the current utterance G1 = (V1, E1), the participant-based history graph G5 = (V5, E5), and the participant, p, who is the speaker of G1 are given, the participant history graph Gp5 = (V p5 , Ep5 ) is a subgraph of G5. Here, V p5 is a set of vertices connected directly to the vertex of the speaker of G1. E p\n5 is a subset of E5 connected to the words of V p\n5 . The weight of each edge in E p 5 is also borrowed from E5. The relevant graph G6 = (V6, E6) is then a subgraph of G p\n5 , where\nV6 = (V1 ∩ V p5 ) ∪ adjacency(V1). Here, adjacency(V1) is a set of vertices from V p\n5 connected directly to the words in V1. The weight of edge w6ij of each e 6 ij ∈ E6 is borrowed from Gp5 . Then, the expanded graph G7 = (V7, E7) is constructed to reflect the relevant history G6 and the current utterance G1. That is, the current utterance G1 is expanded with respect to G6. From this expanded graph G7, the keywords are extracted using (3). That is, the words whose score is larger than a specific threshold, θ , are chosen as keywords."
  }, {
    "heading": "6 Keyword extraction by combining content and participant information",
    "text": "Because the content-based and participant-based extractions suggest candidate keywords independently, they need to be combined to generate the final keywords. For this purpose, a linear combination is used. Assume that the content-based keyword extraction generates a candidate keyword set C, and the participant-based keyword extraction generates a candidate keyword set P . All candidate keywords C ∪ P are then scored. That is, the score of v ∈ C ∪ P is calculated by\nS(v) = α · Sc(v) + (1 − α) · Sp(v), (4) where Sc(·) is the score by the content-based keyword extraction and Sp(·) is one by the participant-based keyword extraction. α is the importance ratio between the two extractions.\nIf a candidate v is extracted only from the content-based keyword extraction, Sp(v) is zero. Similarly, if v is suggested only by the participant-based keyword extraction, Sc(v) is zero. The final keywords are determined by choosing the top-K candidate keywords according to this score.\nBecause the keywords for the current utterance should be the history for the next utterance, they need to be reflected into the history graphs. Therefore, a keyword graph G8 = (V8, E8) is constructed from the final keywords. Here, V8 is a set of keywords selected using (4), where E8 is a set of edges, and each edge represents its temporal importance. The weights of the edges in E8 have a weight that are 1 because the keywords are extracted at the latest time. The keyword graph G8 is then merged into the history graphs, G2 and G5 respectively in the same manner that the current utterance and the subgraph are merged. As stated above, the weights of the edges in the history graph are updated using (2). Therefore, before merging the keyword graph, G8, and the history graphs, G2 and G5, all the weights of G2 and G5 are updated by increasing t as t + 1 to reflect the temporal importance of the preceding utterances.\nConstruction of the current utterance graph is related only to n, the number of candidate keywords. If we index the vertices of the history graph, the calculations of adjacency(·) and merge of the current utterance graph and the extracted subgraph are both computed in a linear time n. Because the number of vertices in the expanded graph (G4 and G7) is greater than or equal to n, the time complexity of our keyword extraction depends mainly on the operation of the expanded graph, that is, the TextRank.\nFor the content-based keyword extraction, let nc and ec be the number of nodes and edges in the expanded graph G4, respectively. Computing (3) takes O(i(nc + ec)) time, where i is the number of iterations needed to converge, and it is normally set to under 20. Similarly, extracting keywords from the participant expanded graph G7 requires O(i(np + ep)) time, where np and ep are the numbers of nodes and edges of G7, respectively. Hence, the time complexity of our keyword extraction is O(i(nc+np+ec+ep)). Although the history graph is quite large when a meeting is long, the proposed method considers, as candidate keywords, only a few words within the history graph that are also uttered currently. Therefore, the proposed method works efficiently even if it is a graph-based method."
  }, {
    "heading": "7 Experiments",
    "text": "The proposed method is evaluated using two kinds of data sets: the National Assembly transcripts in Korean and the ICSI meeting corpus in English. Both data sets are the records of meetings dictated manually by human transcribers."
  }, {
    "heading": "7.1 National assembly transcripts in korean",
    "text": ""
  }, {
    "heading": "7.1.1 Experimental setting",
    "text": "The first corpus used to evaluate our method is the National Assembly transcripts.1 This corpus is obtained from the Knowledge Management System of the National Assembly of Korea. This is transcribed from the 305th assembly record of the Knowledge Economy Committee in 2012. Table 1 summarizes the simple statistics of the National Assembly\n1This data set is available at http://ml.knu.ac.kr/dataset/keywordextraction.html.\nTable 1 Simple statistics of the National Assembly transcripts\nFirst meeting Second meeting\nNo. of utterances 1,280 573\nAverage No. of words per utterance 7.22 10.17\nNo. of participants 19 16\ntranscripts. The 305th assembly record actually consists of two meetings. The first meeting contains 1,280 utterances and the second has 573 utterances. The average number of words per utterance in the first meeting is 7.22, whereas the second meeting contains 10.17 words per utterance on average. The number of participants in the first meeting is 19, and that in the second meeting is 16. The second meeting transcript is used as a development data set to determine the window size, W , in (1), the damping factor, d , in (3), and the threshold, θ . For all experiments below, d is set to 0.85, W is 5, and θ is 0.28. The remaining first meeting transcript is used as a data set to extract the keywords because this transcript contains more utterances. Only nouns are considered as potential keywords. That is, only the words whose POS tag is NNG (common noun) or NNP (proper noun) can be a keyword.\nThree annotators are engaged to extract the keywords manually from each utterance in the first meeting transcript, because the Knowledge Management System does not provide any keyword.2 The average number of keywords per utterance is 2.58. To see the inter-judge agreement among the annotators, the Kappa coefficient (Carletta 1996) was investigated. The Kappa agreement of the National Assembly transcript is 0.31, which falls under the category of “Fair”. Although all congressmen in the transcript belong to the same committee, they discussed a range of topics at the meeting. As a result, the keywords are difficult to be agreed upon unanimously by all three annotators. Therefore, those words recommended by more than two annotators are chosen as keywords.\nThe evaluation is performed with two metrics: F-measure and the weighted relative score (WRS). Because the previous work by Liu et al. (2009) reported only F-measure and WRS, F-measure is used instead of precision/recall for the comparison with their method. The weighted relative score is derived from Pyramid metric (Nenkova and Passonneau 2004). When a keyword extraction system generates keywords with which many annotators agree, a higher score is given to it. On the other hand, a lower score is given if fewer annotators agree.\nThe proposed method is compared with two baseline models to see its relative performance. One is the frequency-based keyword extraction with TFIDF weighting (Frank et al. 1999), and the other is TextRank where the weight of the edges is the mutual information between vertices (Wan et al. 2007). In TFIDF, each utterance is considered as a document, and thus all utterances including the current one are regarded as whole documents. The frequency-based TFIDF chooses the top-K words according to their TFIDF value from the set of words that appear in the meeting transcript. Because human annotators are restricted to extracting up to five keywords, the keyword extraction systems including our method are also requested to select the top-5 keywords when more than five keywords are produced.\n2A guideline was given to the annotators that keywords must be a single word and the maximum number of keywords per utterance is five."
  }, {
    "heading": "7.1.2 Experimental results",
    "text": "In order to see the effect of the preceding utterances in the baseline models, the performances are measured according to the number of preceding utterances used. Figure 7 shows the results. The X-axis of this figure is the number of preceding utterances and the Y-axis\nrepresents the F-measures. As shown in this figure, the performance of the baseline models improves monotonically at first as the number of preceding utterances increases. However, the performance improvement stops when many preceding utterances are involved, and the performance begins to drop when too many utterances are considered. The performance of the TextRank model drops from 20 preceding utterances, whereas that of the TFIDF model begins to decrease at 50 utterances. When too many preceding utterances are taken into account, it is highly possible that some of their topics are irrelevant to the current utterance, which leads to poor performance.\nFigure 8 depicts the performance of the proposed method with various values of α in (4). In this figure, α = 1 means that only the keywords extracted from the keyword-based expanded graph are used, which is the same as our previous work (Song et al. 2013). On the other hand, α = 0 implies that only the keyword candidates extracted from the participant-based expanded graph are adopted as the final keywords. When α = 0.7, the best performance of 0.543 in F-measure is observed. From the fact that the best F-measure is observed at α = 0.7, we can find out that the keywords from the keyword-based expanded graph are more significant than those from the participant-based expanded graph. Thus, we use α = 0.7 for all experiments below.\nIn order to see the influence of the width W in (1) solely, the performances are measured according to various values of W in the development data set of the National Assembly transcripts. Before we measure the performance, we fix the damping factor d as 0.85 and the threshold θ as 0.28, respectively. Furthermore, we also fix α in (4) as 0.7. Figure 9 shows the results. As shown in the figure, the F-measure of the proposed method increases when 1 ≤ W ≤ 4. When W is 5, the proposed method achieves the best performance of 0.543 and then it shows similar performance with 5 < W ≤ 9. F-measure decreases with W > 10. Since the best performance is achieved with W = 5, we set the width W as 5 for the following experiments.\nTable 2 Experimental results on the National Assembly transcripts\nMethods F-measure WRS\nTextRank 0.478 0.387\nTFIDF 0.481 0.394\nParticipant-based extraction (α = 0) 0.495 0.361\nContent-based extraction (α = 1) (Song et al. 2013) 0.533 0.421\nProposed method (α = 0.7) 0.545 0.426\nTable 2 compares our method with the baseline models and our previous work on the National Assembly transcripts. The performance of the baseline models is obtained when they show the best performance for various numbers of preceding utterances. The TextRank model achieves F-measure of 0.478 and weighted relative score of 0.387 respectively, while TFIDF reports its best F-measure of 0.481 and weighted relative score of 0.394. The transcripts used in this experiment are the records of hearing at Korean National Assembly that deal with four main topics. Each topic is composed with a few sub-topics that changes frequently during the hearing. Since TFIDF can reflect the topic based on the value of DF, TFIDF shows slightly better performance than TextRank. However, the difference between TFIDF and TextRank is not significant.\nThe F-measure and weighted relative score of our previous method are 0.533 and 0.421 respectively, and they are much higher than those of the baseline models. Because previous work uses, as its history, only the preceding utterances relevant to the current utterance, its performance is kept high even if whole utterances are used. Therefore, it can be inferred that it is important to adopt only the relevant history in keyword extraction from the meeting transcripts.\nThe proposed method that takes the speaker of the current utterance into account shows better performance than the previous work. It achieves F-measure of 0.545 and weighted relative score of 0.426 respectively. One thing to note is that the method that considers only the speaker of the current utterance (α = 0) achieves reasonable performance. Its F-measure is 0.495 and this is slightly lower than α = 1. However, its WRS is worst among all methods in Table 2. This is because the participant-based keyword extraction focuses only on the contents of the current speaker. Nevertheless, the proposed method, which combines both types of information with α = 0.7, shows the best performance. Therefore, it can be inferred that both the content and participant information are important for keyword extraction and that the linear combination manages both kinds of information effectively."
  }, {
    "heading": "7.1.3 Considering role of participant",
    "text": "The participants of a meeting, in general, have different roles and have different importance according to their role. This different importance affects extraction of keywords. In order to verify that the participants roles would be helpful in extracting keywords, the participant roles are incorporated into the proposed model. In the Korean National Assembly transcripts, there are two explicit roles: chairperson and participant. Normally, the utterances of a chairperson are more important than those of participants because he/she controls a meeting and mentions main issues directly. Thus, the keywords extracted from the utterances of a chairperson should be regarded more importantly than those extracted from the utterances of other participants. Based on this intuition, the proposed method is modified so that the\nTable 3 The experimental results on the National Assembly transcripts when considering participant roles\nMethods F-measure WRS\nWithout participant role (α = 0.7) 0.545 0.426\nWith participant role (α = 0.7) 0.544 0.425\nkeywords extracted from a chairperson have an influence for a longer time than those from other participants. For this purpose, (2) is changed as follows.\nw2ij = ⎧⎨ ⎩ e − t2∗f (vi ,vj ) , if vi and vj are extracted from utterances of a chairperson,\ne − t f (vi ,vj ) , otherwise.\nThe larger the denominator of the above equation becomes, the slower the rate of w2ij reduction gets.\nTable 3 shows how the proposed method is affected by considering participant roles. The newly-changed model achieves 0.544 of F-measure and 0.425 of WRS, which is not different from the original proposed model. This is because the transcripts used in our experiment are recorded at a kind of hearing. Although the chairperson manages a meeting, some other participants are also as important as the chairperson. As a result, most extracted keywords of the participants and the chairperson are overlapped, and the long memorization of keywords extracted from a chairperson is not helpful to improve empirical performance in the National Assembly transcripts."
  }, {
    "heading": "7.1.4 Restricting influence of history graph",
    "text": "The proposed method extracts keywords from the current utterance by considering all preceding utterances. In order to see the effect of the preceding utterances in our method, we control the preceding utterances using temporal information. That is, we ignore some preceding utterances over a certain time when extracting keywords. This means that we consider only the keywords of the history graph that are extracted after the time. To do this, we modify (2) so that the keywords extracted over a certain time (limit) are vanished. That is,\nw2ij = { e − t\nf (vi ,vj ) if t ≤ limit, 0 otherwise.\nFigure 10 shows the performance of the proposed method according to limit . From the results, we notice that the larger limit is, the higher the performance becomes gradually. This implies that the consideration of many preceding utterances helps improving the performance. When limit is 20, the performance reaches 0.540. Then, the performance remains same with limit > 20. This is because in our meeting dataset the subtopics change approximately every 20 utterances on average."
  }, {
    "heading": "7.1.5 Working example",
    "text": "Figure 11 shows the process of the proposed method. The sample utterance originates from the Korean National Assembly transcripts. Due to the limitation of space and several intricate graphs, we draw only the content-based keyword extraction. As shown in Fig. 11-a,\nwhen an utterance is made, we first commit morphological analysis of the utterance, and filter out non-keyword candidates with the help of POS tags. Then, a current utterance graph is constructed, similar to Fig. 11-b. When a history graph like Fig. 11-c is given, the subgraph of the current utterance graph is derived. Because only the keyword “resource” appears both at the current utterance and the histroy graph, the derived subgraph becomes 11-d. As a result, the expanded graph is constructed as Fig. 11-e by merging the current utterance graph and the subgraph. Figure 11-f lists the keywords extracted from this graph. Because the current utterance graph is expanded by being merged with the subgraph, “resource” could be a keyword. Without this expansion, the “resource” keyword would not be extracted. Finally, by incorporating the keyword graph in Fig. 11-g into the history graph, the history graph is updated as shown in Fig. 11-h."
  }, {
    "heading": "7.2 ICSI meeting corpus in english",
    "text": ""
  }, {
    "heading": "7.2.1 Experimental setting",
    "text": "The proposed method is also evaluated on the ICSI meeting corpus (Janin et al. 2003) that consists of naturally occurring meeting recordings. This corpus is widely used to summarize and extract meeting keywords. We followed all the experimental settings proposed by Liu et al. (2009) for this corpus. Among the 26 meeting transcripts chosen by Liu et al. from 161 transcripts of the ICSI meeting corpus, 6 transcripts are used as development data, and the remaining transcripts are used as data from which to extract the keywords. The parameters for the ICSI meeting corpus are set to d = 0.85,W = 10, and θ = 0.20. Only nouns, verbs, and adjectives are considered as candidate keywords, and the Stanford Log-linear POS tagger (Toutanova et al. 2003) is adopted for POS tagging. Each meeting of the corpus\nTable 4 Simple statistics of the ICSI meeting data\nInformation Value\nNo. of meetings 26\nNo. of topic segments 201\nNo. of topic segments used actually 140\nAverage No. of utterances per topic segment 260\nAverage No. of participants per topic segment 4.76\nAverage No. of words per utterance 7.22\nconsists of several topic segments, and every topic segment contains three keyword sets annotated by three annotators, where a set has up to five keywords.\nTable 4 shows simple statistics of the ICSI meeting data. The total number of topic segments in the 26 meetings is originally 201, but some of them do not have keywords. Such segments are discarded, and the remaining 140 topic segments are actually used. The average number of utterances in a topic segment is 260 and the average number of words per utterance is 7.22. The average number of participants in a topic segment is 4.76.\nUnlike the National Assembly transcripts, the keywords of the ICSI meeting corpus are annotated at the topic segment level, not the utterance level. Topic segmentation of the ICSI corpus was made by Murray et al. (2005).3 Therefore, the proposed method that extracts keywords at the utterance level can not be applied directly to this corpus. In order to obtain keywords from a topic segment with the proposed method, the keywords are first extracted from each utterance in the segment by the proposed method, and then all are accumulated. The proposed method extracts the keywords of a topic segment from these accumulated utterance-level keywords as follows. Assume that a topic segment consists of l utterances. Because the proposed method extracts up to 5 keywords for each utterance, the number of keywords for a segment can reach up to 5 · l. From these keywords, we select the top-5 keywords ranked by (4)."
  }, {
    "heading": "7.2.2 Experimental results",
    "text": "Figure 12 depicts the performances of the proposed method with various values of α in (4). As with the National Assembly transcripts, α = 0 means the keywords are extracted only from the participant-based extraction module, whereas α = 1 implies that the keywords are extracted only from the content-based extraction module. Unlike the best value of α in the National Assembly transcripts, the best F-measure is observed at α = 0.9 for this corpus. The difference of α is determined to be the characteristics of corpora. The ICSI data are a record of natural meetings. That is, they are not subject-concentrated. Therefore, the influence of speaker-related information is as important as that of content-related information. On the other hand, the National Assembly data is a record of discussions conducted by Korean congressmen. Because the congressmen in this corpus discussed Korean economic affairs mainly, this corpus is more subject-oriented than the ICSI data set. As a result, content-based keyword extraction is much more important than participant-based extraction.\n3The instructions how to segment a meeting into several topic segments are given at http://groups.inf.ed.ac. uk/ami/corpus/Guidelines/TopicSegmentationGuidelinesNonScenario.pdf\nThe proposed method is compared with three previous studies. The first two are the methods proposed by Liu et al. (2009). One is a frequency-based method with TFIDF weighting of features, such as POS filtering, word clustering, and sentence salience score. The other is a graph-based method with POS filtering. The last method compared is a maximum entropy model applied to this task (Liu et al. 2008). Note that the maximum entropy is a supervised learning model.\nTable 5 summarizes the comparison results. As shown in this table, the content-based keyword extraction (α = 1) achieves F-score of 0.334 and weight relative score of 0.533, respectively. This is an improvement of up to 0.057 in the F-measure and 0.153 in the weighted relative score, respectively, over other unsupervised methods (TFIDF-Liu and TextRank-Liu). It should also be noted that it outperforms even the supervised method (ME model). The difference in weighted relative score between our content-based extraction and maximum entropy model is 0.132. The combined method (α = 0.9) shows slightly better performance than α = 1. It achieves 0.336 of F-score and 0.538 of weighted relative score, respectively. Although the performance difference is small, its higher performance\nTable 6 Simple statistics of crawled tweets\n@oisoo @Juna0465\nNo. of crawled tweets 200 200 Period Aug 03, 2015 ∼ Oct 13, 2015 Jan 21, 2015 ∼ Oct 13, 2015 Average No. of candidate 11.80 9.10\nkeywords per utterance\nproves the importance of the participants in a meeting for keyword extraction from meeting transcripts. From all experimental results above, we can conclude that the consideration of temporal history, topic relevance, and participants is essential in keyword extraction from meeting transcripts."
  }, {
    "heading": "7.3 Keyword extraction on tweets",
    "text": "Tweets have similar properties to meeting transcripts in terms of time-stamping and short length. In addition, they both have different sub-topics related to main topics. Therefore, we apply the proposed method to tweets in order to see the generality of the method. The experiment with tweets is accomplished as follows. First, we selected two twitter accounts: @oisoo and @Juna0465. @oisoo is an account of a Korean novelist and @Juna0465 is of a comedian. Both accounts have followers over 500K. Then, we crawled the latest 200 tweets for each account. Table 6 summarizes a simple statistics of the crawled tweets. The average number of candidate keywords per tweet in @oisoo is 11.80, whereas @Juna0465 contains 9.10 words per tweet on average.\nOur keyword extraction method is directly applied to extracting keywords of tweets by regarding each tweet as an utterance. The flow of tweets is obtained by the time-stamping. The parameters are chosen heuristically (d = 0.85, W = 5, and θ = 0.15). Only nouns are considered as keyword candidates, where hashtags and shorturl text are excluded in advance.\nTable 7 shows the experimental results. The proposed method achieves 0.465 of Fmeasure in @oisoo and 0.528 in @Juna0465, respectively. These performances are slightly higher than those of TextRank, but the differences are not significant. The reason why the proposed method does not outperform TextRank is that even if tweets have different subtopics related to main topics, subtopic repetitions occur infrequently and there exist just a small number of duplicated keywords between two tweets which belong to the same topic. As a result, we can not measure topic sharedness properly. In addition, some broken tweets (without spacing) affect the performance of keyword extraction. From the results, we believe that our method is applicable to tweets, but some tweet-dependent properties must be devised to obtain better performance."
  }, {
    "heading": "8 Conclusion",
    "text": "In this paper, we have proposed a just-in-time keyword extraction from meeting transcripts. Whenever an utterance is spoken, the proposed method extracts the keywords from the utterance that best describe the utterance. Based on the graph representation of all components in a meeting, the proposed method extracts the keywords by TextRank and some graph operations.\nTemporal history, topic, and speaker of the current utterance are three major factors in keyword extraction from meeting transcripts. This is because recent utterances are more important than older ones, and only the preceding utterances for which the topic is relevant to the current utterance are important. To model the temporal importance of the preceding utterances, the concept of forgetting curve is used to update the history graph of the preceding utterances. In addition, the subgraph of the history graph that shares those words that appear in the current utterance graph is used to extract the keywords rather than the entire history graph. Finally, based on the history graph that is based, in turn, on the current utterance speaker, the keywords that reflects the speaker’s own interests are extracted.\nThe proposed method was evaluated from the National Assembly transcripts and the ICSI meeting corpus. The National Assembly transcripts are records of the discussions performed by Korean congressmen, whereas the ICSI meeting corpus is about natural meetings. According to the experimental results on these data sets, the performance of keyword extraction is improved when we consider all temporal history, topic relevance, and participants.\nWe have extracted content-based keywords and participant-based keywords from the content-based expanded graph and the participant-based expanded graph, respectively because we assume that they are independent each other. In general, however, content and participant information are related each other. One future work of this paper is to model both of them in a single graph in order to consider them simultaneously. The other work is to enhance the expansion of the current utterance. That is, the current utterance is not be expanded if there is no duplicated keywords from preceding utterances even if they belong to the same topic. One possible way to solve this problem is to use topic models. We will seek methods to expand the current utterance by considering both word and topic representations.\nAcknowledgments This study was supported by the BK21 Plus project (SW Human Resource Development Program for Supporting Smart Life) funded by the Ministry of Education, School of Computer Science and Engineering, Kyungpook National University, Korea (21A20131600005)."
  }],
  "year": 2017,
  "references": [{
    "title": "A keyword extraction method from twitter messages represented as graphs",
    "authors": ["W.D. Abilhoa", "de Castro L.N"],
    "venue": "Applied Mathematics and Computation,",
    "year": 2014
  }, {
    "title": "Assessing agreement on classification tasks: The kappa statistic",
    "authors": ["J. Carletta"],
    "venue": "Computational Linguistics,",
    "year": 1996
  }, {
    "title": "Automatic key term extraction from spoken course lectures using branching entropy and prosodic/semantic features",
    "authors": ["Y.N. Chen", "Y. Huang", "S.Y. Kong", "L.S. Lee"],
    "venue": "In Proceedings of IEEE workshop on spoken language technology (pp. 265–270)",
    "year": 2010
  }, {
    "title": "Domain-specific keyphrase extraction",
    "authors": ["E. Frank", "G.W. Paynter", "I.H. Witten", "C. Gutwin", "C.G. Nevill-Manning"],
    "venue": "In Proceedings of the 18th international joint conference on artificial intelligence (pp. 668–671)",
    "year": 1999
  }, {
    "title": "Improved automatic keyword extraction given more linguistic knowledge. In Proceedings of international conference on empirical methods in natural language processing",
    "authors": ["A. Hulth"],
    "year": 2003
  }, {
    "title": "The icsi meeting corpus",
    "authors": ["A. Janin", "D. Baron", "J. Edwards", "D. Ellis", "D. Gelbart", "N. Morgan", "B. Peskin", "T. Pfau", "E. Shriberg", "A. Stolcke", "C. Wooters"],
    "venue": "In Proceedings of international conference on acoustics,",
    "year": 2003
  }, {
    "title": "Automatic keyword extraction for the meeting corpus using supervised approach and bigram expansion",
    "authors": ["F. Liu", "Y. Liu"],
    "venue": "In Proceedings of IEEE spoken language technology (pp. 181–184)",
    "year": 2008
  }, {
    "title": "Unsupervised approaches for automatic keyword extraction using meeting transcripts",
    "authors": ["F. Liu", "D. Pennell", "Y. Liu"],
    "venue": "In Proceedings of annual conference of the north American chapter of the ACL (pp. 620628)",
    "year": 2009
  }, {
    "title": "A supervised framework for keyword extraction from meeting transcripts",
    "authors": ["F. Liu", "Y. Liu"],
    "venue": "IEEE Transactions on Audio, Speech, and Language Processing,",
    "year": 2011
  }, {
    "title": "Automatic keyphrase extraction via topic decomposition",
    "authors": ["Z. Liu", "W. Huang", "Y. Zheng", "M. Sun"],
    "venue": "In Proceedings of the 2010 conference on empirical methods in natural language processing (pp. 366–376)",
    "year": 2010
  }, {
    "title": "Human-competitive tagging using automatic keyphrase extraction",
    "authors": ["O. Medelyan", "E. Frank", "I.H. Witten"],
    "venue": "In Proceedings of the 2009 conference on empirical methods in natural language processing (pp. 1318–1327)",
    "year": 2009
  }, {
    "title": "Textrank: Bringing order into texts. In Proceedings of international conference on empirical methods in natural language processing",
    "authors": ["R. Mihalcea", "P. Tarau"],
    "year": 2004
  }, {
    "title": "Evaluating automatic summaries of meeting recordings. In Proceedings of the workshop on machine translation and summarization evaluation",
    "authors": ["G. Murray", "S. Renals", "J. Carletta", "J. Moore"],
    "year": 2005
  }, {
    "title": "Evaluating content selection in summarization: The pyramid method",
    "authors": ["A. Nenkova", "R. Passonneau"],
    "venue": "In Proceedings of annual conference of the north American chapter of the ACL (pp. 145–152)",
    "year": 2004
  }, {
    "title": "Improved keyword extraction by separation into multiple document sets according to time series",
    "authors": ["R. Saga", "H. Tsuji"],
    "venue": "In Proceedings of the 15th international conference on human-computer interaction (pp. 450–453)",
    "year": 2013
  }, {
    "title": "A just-in-time keyword extraction from meeting transcripts. In Proceedings of the 2013 conference of the north American chapter of the association for computational linguistics: human language technologies (pp. 888–896)",
    "authors": ["H.J. Song", "J. Go", "S.B. Park", "S.Y. Park"],
    "year": 2013
  }, {
    "title": "A language model approach to keyphrase extraction",
    "authors": ["T. Tomokiyo", "M. Hurst"],
    "venue": "In Proceedings of the ACL 2003 workshop on multiword expressions: analysis (pp. 33–40)",
    "year": 2003
  }, {
    "title": "Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 conference of the north American chapter of the association for computational linguistics on human language technology",
    "authors": ["K. Toutanova", "D. Klein", "C.D. Manning", "Y. Singer"],
    "year": 2003
  }, {
    "title": "Learning algorithms for keyphrase extraction",
    "authors": ["P.D. Turney"],
    "venue": "Information Retrieval,",
    "year": 2000
  }, {
    "title": "Coherent keyphrase extraction via web mining",
    "authors": ["P.D. Turney"],
    "venue": "In Proceedings of the 18th international joint conference on artificial intelligence (pp. 434–439)",
    "year": 2003
  }, {
    "title": "Collabrank: Towards a collaborative approach to single-document keyphrase extraction",
    "authors": ["X. Wan", "J. Xiao"],
    "venue": "In Proceedings of international conference on computational linguistics (pp. 969–976)",
    "year": 2008
  }, {
    "title": "Towards an iterative reinforcement approach for simultaneous document summarization and keyword extraction",
    "authors": ["X. Wan", "J. Yang", "J. Xiao"],
    "venue": "In Proceedings of the 45th annual meeting of the association of computational linguistics (pp. 552–559)",
    "year": 2007
  }, {
    "title": "Classics in psychology, 1855–1914: Historical Essays",
    "authors": ["R.H. Wozniak"],
    "year": 1999
  }, {
    "title": "Measuring term informativeness in context. In Proceedings of the 2013 conference of the north american chapter of the association for computational linguistics: human language technologies",
    "authors": ["Z. Wu", "C.L. Giles"],
    "year": 2013
  }, {
    "title": "Keyword extraction and headline generation using novel word features",
    "authors": ["S. Xu", "S. Yang", "F.C.M. Lau"],
    "venue": "In Proceedings of the twenty-fourth AAAI conference on artificial intelligence (pp. 1461–1466)",
    "year": 2010
  }, {
    "title": "Topical keyphrase extraction from twitter. In Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies (pp. 379–388)",
    "authors": ["W.X. Zhao", "J. Jiang", "J. He", "Y. Song", "P. Achananuparp", "E.P. Lim", "X. Li"],
    "year": 2011
  }],
  "id": "SP:b3c8b1ecf31c0dcffabd82dcb933e67bee17ceea",
  "authors": [{
    "name": "Hyun-Je Song",
    "affiliations": []
  }, {
    "name": "Junho Go",
    "affiliations": []
  }, {
    "name": "·Seong-Bae Park",
    "affiliations": []
  }, {
    "name": "Se-Young Park",
    "affiliations": []
  }, {
    "name": "·Kweon Yang Kim",
    "affiliations": []
  }],
  "abstractText": "In a meeting, it is often desirable to extract the keywords from each utterance as soon as it is spoken. Therefore, this paper proposes a just-in-time keyword extraction from meeting transcripts. The proposed method considers three major factors that make it different from keyword extraction from normal texts. The first factor is the temporal history of the preceding utterances that grants higher importance to recent utterances than older ones, and the second is topic relevance, which focuses only on the preceding utterances relevant to the current utterance. The final factor is the participants. The utterances spoken by the current speaker should be considered more important than those spoken by other participants. The proposed method considers these factors simultaneously under a graph-based keyword extraction with some graph operations. Experiments on two data sets in English and Korean show that consideration of these factors results in improved performance in keyword extraction from meeting transcripts. Seong-Bae Park sbpark@sejong.knu.ac.kr Hyun-Je Song hjsong@sejong.knu.ac.kr Junho Go jhgo@sejong.knu.ac.kr Se-Young Park seyoung@knu.ac.kr Kweon Yang Kim kykim@kiu.ac.kr 1 School of Computer Science and Engineering, Kyungpook National University, 80, Daehakro, Bukgu, Daegu, 702-701, Republic of Korea 2 Department of Computer Engineering, Kyungil University, 50, Gamasilgil, Hayangeup, Gyeonsan, Gyeongbuk, 712-701, Republic of Korea January 2016 118 J Intell Inf Syst (2017) 48:117–140",
  "title": "A just-in-time keyword extraction from meeting transcripts using temporal and participant information"
}