{
  "sections": [{
    "heading": "1 Introduction",
    "text": "The advent of “big data” in recent years has generated countless opportunities for the prediction of real world phenomena with unprecedented accuracy and at unprecedented scale. Statistical methods for prediction exploit associations in existing data to predict some response variable. However, the task at hand is often not to predict the response variable from pre-existing data, but rather to determine how a change in one or more of the explanatory variables will cause changes in the response variable.\n1Department of Mathematics, University of Virginia, Charlottesville, VA 22904, USA 2Department of Computer Science, University of Virginia, Charlottesville, VA 22904, USA. Correspondence to: Quanquan Gu <qg5w@virginia.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nIn statistics, causality is often established by means of a controlled, randomized experiment. Nevertheless, controlled, randomized experiments are often infeasible, leaving researchers with only access to observational data. This situation arises routinely when working with time series data. Areas that must cope with this obstacle frequently include genetics (Shojaie & Michailidis, 2010) and neuroscience (Seth et al., 2015). The natural question that arises is: how can one determine which factors cause changes in a certain response variable using only data in which all variables change simultaneously? Causal inference seeks to address this problem.\nThe classic method for causal inference among time series is a concept from econometrics known as Granger causality, named after Nobel Prize winning econometrician Clive Granger (Granger, 1969). Granger causality formalizes the intuitive notion that in a causal system, the cause must precede the effect, and the cause must hold some unique information that helps predict the effect. For example, let X\n1 , . . . , X T and Y 1 , . . . , Y T be two stationary one-dimensional time series. We can model time series Y using the following auto-regressive model (Stock & Watson, 2011):\nY t =\npX\ni=1\na i Y t i + ✏t, (1.1)\nwhere a 1 , . . . , a p are the coefficient parameters for the regression, p < T is the maximal lag of the model, and ✏\nt is the error term. To determine whether or not X is a Granger cause of Y , we also form a second auto-regressive model:\nY t =\npX\ni=1\nb i Y t i +\npX\ni=1\nc i X t i + !t, (1.2)\nwith coefficient parameters b 1 , . . . , b p , c 1 , . . . , c p , and error term !\nt . In this classical regime, where the number of observations exceeds the number of variables (T p > 2p), one can fit both of these models with ordinary least squares (OLS). We can conduct an F-test between models (1.1) and (1.2) as well as hypothesis tests on coefficients c\ni , 1  i  p, to determine if the extra information encompassed by previous values of X significantly aides in the prediction of\nfuture values of Y . If this pair of models passes the F-test and at least one of the coefficient hypothesis tests at some significance level ↵, then we may reject the null hypothesis that X is not a Granger cause of Y (Granger, 1969).\nAlthough the concept of Granger causality has existed for decades, Granger (1969) only rigorously treated the bivariate case. However, as noted by Arnold et al. (2007), Eichler (2006) provided one framework for multivariate analysis by applying graphical models to Granger causal inference.\nMultivariate Granger causal inference relies on hypothesis testing of model coefficients in a fitted vector-autoregressive (VAR) model (Lutkepohl, 2007). VAR models are fit with OLS. In the high-dimensional regime, where the number of parameters exceeds the number of observations (T p < pd, where d is the number of time series in the VAR model), OLS estimation is impossible. Hence, one must employ regularized regression methods. Perhaps the most wellknown such method is the Lasso (Tibshirani, 1996), which encourages sparsity in the coefficient parameter vector via an `\n1 penalty. To conduct Granger causal inference in the high-dimensional regime, Arnold et al. (2007) proposed the “Lasso Granger” estimator, which we fully specify in (3.3). Unfortunately, since the limiting distribution of the underlying Lasso estimator is not normal (Knight & Fu, 2000) and intractable in general (Javanmard & Montanari, 2014), one cannot construct confidence intervals or compute test statistics for hypothesis tests of Lasso Granger coefficient point estimates. Thus, existing methods for high-dimensional Granger causal inference do not allow for the assessment of uncertainty. Uncertainty characterization proves an important, and often necessary, element of research in the natural sciences. Therefore, uncertainty assessment techniques would augment the versatility of high-dimensional Granger causal inference methods, and drive their wider adoption by the scientific community.\nAnother issue in high-dimensional causal inference is how to limit the number of false positives generated when testing a large number of explanatory variables without sacrificing identification of the true causal effects. That is, the researcher wants to attain high power while still maintaining a low type I error rate. To this end, false discovery rate (FDR) control (Benjamini & Hochberg, 1995) proves an important part of any method for high-dimensional causal inference. Unfortunately, existing FDR control methods cannot cope with the two challenges posed by our setting: dependent test statistics and dependent observations. These methods thus prove unsuitable in many practical applications.\nIn this paper, we make two contributions. First, we propose a novel asymptotically unbiased estimator for highdimensional Granger causal inference inspired by Javanmard & Montanari (2014). We leverage this estimator’s unbiasedness to construct confidence intervals and p-values\nfor coefficient point estimates. In this way, we allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference. Second, we propose a novel FDR control technique that can cope with dependent test-statistics and dependent observations. In addition to surmounting these theoretical obstacles to existing methods, our FDR control technique also achieves higher power in multiple testing than existing methods. Additionally, the proof techniques we use to extend high-dimensional results from the independent and identically distributed (i.i.d.) setting to our time series setting are of independent interest. Specifically, to establish the asymptotic unbiasedness and normality of our estimator, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory. We further employ martingale theory, along with empirical process theory, to prove the asymptotic validity of our FDR control procedure.\nThe rest of this paper is organized as follows. Section 2 contextualizes our contributions in the existing literature. Section 3 sets up the problem of high-dimensional Granger causal inference. Section 4 presents our novel de-biased estimator and FDR control procedure. Section 5 establishes our main theoretical results, which we corroborate empirically in Section 6. Section 7 concludes the paper."
  }, {
    "heading": "2 Related Work",
    "text": "As mentioned above, Clive Granger examined bivariate Granger causality in 1969 (Granger, 1969). Advances in the area of graphical models provided a strong framework for multivariate causal inference in general (Pearl, 2009). Graphical models were first applied specifically to Granger causal inference by Eichler (2001) and Eichler (2006), and have provided a foundation for more complex models.\nHowever, these methods rely on OLS estimation, which is impossible in the high-dimensional regime. Meinshausen & Bühlmann (2006) applied Lasso to the estimation of highdimensional graphical models. Arnold et al. (2007) then applied the method proposed by Meinshausen & Bühlmann (2006) to multivariate Granger causal inference, and introduced the estimator of primary interest for this work: the Lasso Granger estimator. The Lasso Granger estimator yields a coefficient vector in which non-zero coefficients indicate conditional Granger causes of the response variable.\nClassical methods for uncertainty analysis prove impossible for the Lasso Granger estimator. Recent work (Lee et al., 2013; Lockhart et al., 2014; Taylor et al., 2014) in the area of high-dimensional inference has made great strides toward addressing this issue. Early work focussed on constructing pvalues and confidence intervals for Lasso coefficients via the bootstrap (Chatterjee et al., 2013; Liu et al., 2013a). However, later work found that these methods perform poorly compared to more recent methods (Dezeure et al., 2015), especially in non-i.i.d. settings (Karoui & Purdom, 2016).\nPerhaps the most promising work in high-dimensional inference has emerged from the perspective of bias correction (Bühlmann et al., 2013; Zhang & Zhang, 2014). Subsequent work by Van de Geer et al. (2014) and Javanmard & Montanari (2014) introduced a method to de-bias the Lasso solution to yield asymptotically valid confidence intervals and hypothesis tests for coefficient point estimates. Nevertheless, these existing methods assume that the observations forming the design matrix are independent, and so cannot tackle causal inference among time series. Our method applies the Lasso de-biasing technique to the original Lasso Granger estimator. We overcome the inability of existing methods to cope with non-i.i.d. data by using Talagrand’s generic chaining (Talagrand, 2006) and the martingale technique to derive the asymptotic distribution of our novel de-biased Lasso Granger estimator.\nHypothesis testing in the high-dimensional setting raises the need for procedures to address the multiple testing problem. FDR control is one such way to control type I error in multiple testing. Our setting poses two challenges to existing FDR control procedures. First, the most-widely used methods, such as the Benjamini-Hochberg procedure (Benjamini & Hochberg, 1995), assume the test statistics under consideration are independent. While Benjamini & Yekutieli (2001) proposed a slight variation on the Benjamini-Hochberg procedure that could control FDR under “positive regression dependency” (e.g., when the covariance matrix of the explanatory variables is strictly positive), in our setting where the explanatory variables interact in complex ways, the test statistics will not satisfy this property. This version of the Benjamini-Hochberg procedure achieves only low power in the presence of a general dependence structure (Romano et al., 2008), and is thus unsuitable for our setting. Recent methods from the area of graphical models, which explicitly model the dependency of explanatory variables, have made progress in addressing the case of dependent test statistics (Xie et al., 2011; Liu et al., 2013b). However, these methods still encounter the second challenge of our setting: dependent observations arising from time series data. To control FDR for dependent observations, one must resort to assumption-free methods, such as the Bonferroni technique, that achieve low power in practice. We propose a FDR control procedure that can cope with dependent test statistics and observations, and that achieves high power.\nNotation We denote matrix A = [A i,j ] 2 Rm⇥n and column vector v = [v\ni ] 2 RT . We write the ` p\nnorm of vector v as kvk\np\n= ⌃\ni=T\ni=1\n|v i |p. Furthermore, kvk1 denotes the max-norm of vector v: kvk1 = max1iT |vi|. Additionally, kvk\n0 = supp(v) designates the cardinality of the support (the set of all non-zero entries) of v. We represent the the max-norm of matrix A as kAk1 = maxi,j |Ai,j |. The minimum and maximum singular values of A are denoted by\nmin (A) and max (A), respectively. (x) ⌘\n(1/ p 2⇡) R x\n1 e t2/2dt refers to the cumulative distribu-\ntion function of the standard normal distribution. For a random variable X and a sequence of random variables X\nn , we write X n P ! X if X n\nconverges in probability to X , and X\nn D ! X if X n\nconverges in distribution to X . For sequences of random variables X\nn and Y n , we say X\nn ⇣ Y n if X n has the “same asymptotic order” as Y n\n, that is, if both sequences bound each other up to some universal multiplicative constant."
  }, {
    "heading": "3 Granger Causality and its Estimator",
    "text": "In this section, we set up the problem of high dimensional Granger causal inference. Denote the design matrix X, the number of parameters d, the number of observations T , and the maximal lag p. For a given design matrix X = [X\nt,j ] 2 RT⇥d define the sample covariance matrix b⌃ = X>X/T 2 Rd⇥d. The j-th column of X represents time series X\nj , 1  j  d. We can further denote lagged versions of each column in the design matrix with fX\nt,j\n=\n(X t p,j , Xt p+1,j , . . . , Xt 1,j)> 2 Rp. Note that Xt 1,j represents the observation immediately before X t,j\nin time series X\nj . In Granger causal analysis, the response variable is one of the explanatory variables. Hence, we can model an arbitrary variable X\nt,j , with 1  j  d and p+ 1  t  T , by using the lagged values of all explanatory variables as predictors:\nX t,j =\ndX\ni=1\n✓ j⇤> i f X t,i + ✏ t,j . (3.1)\nHere ✓j⇤ i 2 Rp and ✏ t,j ⇠ N(0, 2 j ). Time series X i is a conditional Granger cause of time series X j\n(conditioned on the other d - 2 time series) if ✓j⇤\ni contains any non-zero elements (i.e., k✓j⇤\ni\nk 0\n> 0). We can vectorize the sets of all ✓j⇤\ni\nand all fX t,i , for 1  i  d, as ✓j⇤ = (✓j⇤>\n1 ,✓j⇤> 2 , . . . ,✓j⇤> d ) > 2 Rpd and fX t =\n( f X > t,1 , fX> t,2 , . . . , fX> t,d ) > 2 Rpd, respectively. Based on (3.1), the Lasso Granger estimator (Arnold et al., 2007) is given by\nb ✓ j = argmin\n✓j\n1 2(T p) TX\nt=p+1\n(X t,j ✓j>fX t ) 2 + k✓jk 1 ,\nwhere > 0 is the regularization parameter.\nEquivalently, letting eX = (fX p+1 , fX p+2 , . . . , fX T ) > 2 R(T p)⇥pd and Y\nj = X p+1:T,j represent the lower T p elements of the j-th column of X , we can re-express our model in more standard notation as:\nY\nj\n= eX✓j⇤ + ✏, (3.2)\nwhere ✏ ⇠ N(0, 2I (T p)⇥(T p)). We can now re-express\nthe Lasso Granger estimator as:\nb ✓ j = argmin\n✓j\n1 2(T p)kYj eX✓jk2 2 + k✓jk 1 . (3.3)\nFor ease of presentation, we will henceforth omit the identifying variable j from ✓j⇤, b✓j , and Y\nj , and assume we are referring to some arbitrary response variable. Using the above notation, we can now denote the sample covariance matrix of eX as e⌃\nn\n= eX> eX/(T p) 2 Rpd⇥pd and the true covariance matrix as e⌃ = E[e⌃\nn\n]."
  }, {
    "heading": "4 Asymptotic Inference for Lasso Granger",
    "text": "In this section, we introduce our de-biased Lasso Granger estimator, and construct confidence intervals and p-values for its elements. We will then present our method for false discovery rate control in multiple testing."
  }, {
    "heading": "4.1 Confidence Intervals and Hypothesis Tests",
    "text": "In deriving a de-biased version of the Lasso Granger estimator, we employ a variation of the Lasso de-biasing procedure proposed by Javanmard & Montanari (2014). In particular, we define the de-biased Lasso Granger estimator b✓u as follows:\nb ✓ u = b ✓ + 1 T pM eX>(Y eXb✓), (4.1)\nwhere b✓ 2 Rpd is the parameter vector yielded when computing the Lasso Granger estimator (3.3) for an arbitrary response variable Y = Y\nj . M = (m 1 ,m 2 , . . . ,m pd ) > 2 Rpd⇥pd is an estimate of e⌃ 1\nn , the inverse sample covariance matrix of eX, where each m\ni is the solution to the following optimization algorithm:\nminimize m> e⌃ n m subject to ke⌃ n m e i k1  µ, (4.2)\nwhere e i 2 Rpd is the i-th column of I pd⇥pd, and the choice of µ will be clear after we deliver theory. Our unbiased estimator b✓u, though inspired by Javanmard & Montanari (2014), diverges sharply from their work in several respects. While Javanmard and Montanari use the observed design matrix X in their estimator, we use the transformed design matrix eX. Although in our time series setting the rows of design matrix X are already dependent, transforming X to eX exacerbates this dependency and renders the i.i.d. results underpinning Javanmard and Montanari’s work unusable. Hence, we appeal to Talagrand’s generic chaining (Talagrand, 2006) and martingale theory to establish our theoretical results about b✓u.\nTheorem 5.5 in Section 5 below proves that for any i 2 {1, 2, . . . , pd}, the standardized estimate of the i-th element\nof b✓u converges in distribution to the standard normal distribution:\np T p\nb✓u i ✓⇤ i\n[Me⌃ n M>]1/2 i,i\nD ! N(0, 1). (4.3)\nUnfortunately, the true noise level, denoted here by , is unknown in most real-world applications. Hence, we replace with a consistent estimator, denoted b , yielded by the Scaled Lasso (Sun & Zhang, 2012):\n{b✓( ), b ( )} =\nargmin\n✓2Rpd, >0\n⇢ 1\n2 (T P )kY eX✓k2 2 + 2 + k✓k 1 ,\n(4.4)\nwhere is the regularization parameter. Sun & Zhang (2012) prove b is a consistent estimator of when the penalized loss function is convex. Sun & Zhang (2012) use the i.i.d assumption to establish convexity. In our non-i.i.d. setting, we establish convexity via a restricted eigenvalue condition for martingale difference sequences. Thus, b is consistent in our setting as well. Then by the Slutsky Theorem (Van der Vaart, 2000), we can replace in (4.3) with b .\nOne can easily apply (4.3) to construct confidence intervals for ✓⇤\ni , for 1  i  pd. If the significance level is ↵ > 0, the 1 ↵ confidence interval for ✓⇤\ni\nis:\nI i = [ b✓u i\n(↵, T p), b✓u i\n+ (↵, T p)], (4.5) where\n(↵, T p) = 1(1 ↵/2)(b /pT p)[Me⌃ n M>]1/2 i,i .\nWe prove the asymptotic validity of this confidence interval in Corollary 5.6.\nSimilarly, we can also conduct hypothesis tests on the individual regression coefficients ✓⇤\ni , for 1  i  pd. In the context of Granger causality, the relevant null and alternative hypotheses are Hi\n0 : ✓⇤ i = 0 and Hi a : ✓⇤ i 6= 0, respectively. Having zero-coefficients for all variables p(x 1) < i  px implies that time series 1  x  d is not a conditional Granger cause of the response time series. Conversely, rejecting Hi\n0 for any variable p(x 1) < i  px amounts to rejecting the null hypothesis that time series x is not a Granger cause of the response time series. We thus consider the following test statistic for Hi\n0 : ✓⇤ i = 0:\ncZ i =\nb✓u i\np T p\nb [Me⌃ n M>]1/2 i,i\n. (4.6)\nNote that under the null hypothesis cZ i D ! N(0, 1) by (4.3). The hypothesis test at significance level ↵ is thus given by\nZ (↵) = 1( |cZ i | < z ↵/2 ), (4.7)\nwhere z ↵/2 is the quantile of the standard normal distribution such that (z\n↵/2 ) = ↵/2. We reject the null hypothesis if and only if\nZ (↵) = 1. The p-value for this hypothesis test is\nP i = 2(1 (|cZ i |)). (4.8) As usual, one would reject Hi\n0 at a pre-specified significance level ↵ if P\ni < ↵. We establish that the type I error of the hypothesis test\nZ (↵) converges to the specified significance level, and that the p-value P\ni is asymptotically uniformly distributed in Corollary 5.7."
  }, {
    "heading": "4.2 False Discovery Rate Control",
    "text": "Having established test statistics for individual coefficients of the de-biased Lasso Granger estimator, we now address the issue of FDR control. First, denote the set of coefficient indices i such that ✓⇤\ni\n= 0 as H 0 = {i|✓⇤ i = 0, 1  i  pd}. Define the complement of this set as H\n1 = {i|✓⇤ i 6= 0, 1  i  pd}. We define FDR and false discovery proportion (FDP) as follows:\nFDP(⌫) = P i2H 0 1(|cZ i\n| ⌫) max{P 1jpd 1(|cZi| ⌫), 1} ,\nFDR(⌫) = E[FDP(⌫)].\nWhen conducting hypothesis tests at significance 0 < ↵ < 1, we seek the smallest ⌫ such that FDR(⌫)  ↵. In this way, we will be able to reject the null hypothesis as often as possible (i.e., we maximize power) while still guaranteeing that our type I error rate does not exceed ↵. Thus, the ideal choice of ⌫ is\nb⌫ = inf ⇢ ⌫ > 0 :\nP i2H\n0\n1{|cZ i | ⌫} max{P 1jpd 1{|cZj | ⌫}, 1}  ↵ .\n(4.9)\nNote that the left hand side of the inequality in (4.9) is FDP, whose expectation is FDR. Unfortunately, b⌫ cannot be computed under the unknown H\n0 (Liu et al., 2013b). However, following Liu & Luo (2014), we use the asymptotic normality of cZ\ni under the null hypothesis to approximateP i2H\n0\n1{|cZ i | ⌫} by 2(1 (⌫))pd. In multiple hypothesis testing, we use b⌫ as the threshold for rejecting the null hypothesis, instead of z\n↵/2\n, in hypothesis test Z (↵) (4.7). Theorem 5.9 below demonstrates the asymptotic validity of this FDR control method."
  }, {
    "heading": "5 Main Theory",
    "text": "In this section we present our main theoretical results: the test statistic cZ\ni from (4.6) converges in distribution to the standard normal under the null hypothesis, and the FDR control procedure presented in (4.9) asymptotically controls both FDR and FDP. To begin, we present several definitions.\nDefinition 5.1. (Vershynin, 2012) A random variable X is sub-Gaussian if there exists a constant C > 0 such that\nP(|X| > t)  2 exp[ t2/C2], for all t > 0.\nA random vector X 2 Rn is sub-Gaussian if the onedimensional marginals < X,v > are sub-Gaussian random variables for all v 2 Rn. Definition 5.2. (Javanmard & Montanari, 2014) The subGaussian norm of a random scalar variable X is:\nkXk\n2\n= sup q 1 q 1/2(E[|X|q])1/q.\nThe sub-Gaussian norm of a random vector X 2 Rn is: kXk\n2\n= sup u2Sn 1 khX,uik 2 ,\nwhere Sn 1 is the unit sphere in Rn space.\nHaving established these definitions, we impose two assumptions on the design matrix and the true covariance matrix of the design matrix. Assumption 5.3. There exist universal constants C\nmin , C max such that 0 < C min  min ( e⌃)  max ( e⌃)  C max . Assumption 5.4. The rows of eX are sub-Gaussian and the sub-Gaussian norm of each row is bounded by some constant  so that kfX\ni\nk\n2  , for i 2 {1, 2, . . . , T p}. We use Assumption 5.3 to demonstrate that the restricted eigenvalue condition holds for e⌃\nn in order to prove the asymptotic unbiasedness of b✓u. Assumption 5.4 plays a role at multiple stages of the proof of Theorem 5.5, including proving the restricted eigenvalue condition for e⌃\nn and establishing a high-probability bound for the regularization parameter . Both of these assumptions prove common in the high-dimensional inference literature.\nWe leverage Assumptions 5.3 and 5.4 to present the following theorem. Theorem 5.5. Suppose Assumptions 5.3 and 5.4 are satisfied. Let s\n0 = supp(✓⇤) ⇣ pT p/ log(pd) and µ ⇣ plog(pd)/(T p). Then for any element b✓u\ni of the de-biased Lasso Granger estimator b✓u defined in (4.1), we have\np T p\nb✓u i ✓⇤ i\n[Me⌃ n M>]1/2 i,i\nD ! N(0, 1).\nTheorem 5.5 immediately yields several useful results. We first demonstrate the asymptotic validity of confidence interval (4.5) for any element of b✓u in the following corollary.\nCorollary 5.6. Denote significance level ↵ > 0, and for 1  i  pd, define interval I\ni\n= [ b✓u i\n(↵, T p), b✓u\ni + (↵, T p)]. Here, (↵, T p) = (1 ↵/2)( / p T p)[Me⌃\nn M>]1/2 i,i . Then\nlim T p!1 P(✓⇤ i 2 I i ) = 1 ↵.\nBy Corollary 5.6, the asymptotic coverage probability corresponds the the given confidence level. Note that we can replace with b by the Slutsky Theorem. Similarly, we confirm in the following corollary that the type I error for hypothesis test\nZ (↵), introduced in (4.7), matches the given significance level ↵. Furthermore, we prove that the CDF of the p-value P\ni for Z (↵), which we introduced in (4.8), converges in distribution to a uniform distribution. Corollary 5.7. With\nZ (↵) and P i defined as above, and significance level ↵ > 0, we have:\nP( Z (↵) = 1|Hi 0 ) (T p)!1 ! ↵ and P i D ! U [0, 1].\nWe now turn our attention to demonstrating the asymptotic validity of the FDR control method we present in Section 4.2. To control FDR we desire the following property:\nP i2H\n0\n1(|cZ i | b⌫) 2|H\n0\n|(1 (b⌫)) P ! 1. (5.1)\nUnfortunately, in this application, the test statistics cZ i\nare correlated, rendering the convergence in (5.1) non-trivial. In order to prove (5.1), we will leverage martingale theory, empirical process theory, and the following assumption. Assumption 5.8. For constant c > 2,\nX\ni2H 1\n1\n✓ |✓⇤ i\n| e⌃ 1/2\ni,i\ns\nc log(pd) (T p) ◆ ! 1,\nas (T p, pd) ! 1. Assumption 5.8 implies that the number of true alternative hypotheses approaches infinity. This property proves important because, as demonstrated by Liu et al. (2014), FDR control is impossible when the number of true alternative hypotheses is fixed. This assumption allows us to present the following theorem: Theorem 5.9. Assume pd  (T p)r and log(pd) = o( p T p) for some r > 0. Furthermore, suppose that Assumption 5.8 and the assumptions of Theorem 5.5 hold. Then at significance level ↵,\nlim (T p,pd) FDR(b⌫) ↵|H 0 |/(pd) = 1 and FDP(b⌫) ↵|H 0 |/(pd) P ! 1,\nas (T p, pd) ! 1.\nTheorem 5.9 establishes that the FDR control procedure we present in Section 4.2 asymptotically controls both FDR and FDP. Note that the upper bound rate imposed on pd is very mild and will pose no issues in the vast majority of applications. The assumptions of Theorem 5.5 guarantee the asymptotic normality of test statistic cZ\ni\n."
  }, {
    "heading": "6 Numerical Experiments",
    "text": "In this section, we establish the effectiveness of our debiased Lasso Granger estimator and our FDR control procedure via experimental results. We also demonstrate that our methods outperform existing techniques."
  }, {
    "heading": "6.1 Synthetic Data",
    "text": "In this section, we corroborate our theoretical results and compare our contributions to existing methods with numerical experiments on synthetic data. The data for these experiments are generated by model (3.1). In order to satisfy the assumptions of Theorem 5.5, each ✓j⇤ is a sparse vector such that the probability of each element being non-zero is p T p/(2pd log(pd)) for 1  j  d. We use the R package“flare” (Li et al., 2012) to generate sparse transition matrices, and the “glmnet” package (Friedman et al., 2010) to compute the biased Lasso Granger estimate. We examine multiple different transition matrix patterns (“random” and “cluster”, as generated by the “flare” package) and multiple different configurations of (T, d, p).\nIn Table 1, we see that the empirical type 1 error of hypothesis test\nZ (↵) (4.7) corresponds to the given significance level across multiple configurations of (T, d, p). Figure 1(a) corroborates Theorem 5.5 by demonstrating that the empirical distribution of test statistic cZ\ni under the null hypothesis is the standard normal distribution. Figure 1(a) also illustrates that coefficient point estimates for the biased Lasso Granger estimator do not follow the standard normal distribution. Figure 1(b) validates Corollary 5.7 by demonstrating that the empirical CDF of p-value (4.8) for a true zero parameter is the uniform distribution. Furthermore, Figures 1(c) and 1(d) exhibit that hypothesis test\nZ (↵) (4.7) attains higher power than the biased Lasso Granger estimator when testing a single true non-zero parameter. Table 2 demonstrates the accuracy of the de-biased Lasso Granger estimator via computations of the `\n1 and ` 2 norms of the\nerror vector between b✓u and ✓⇤.\nTable 3 exhibits that, as suggested by theory, our FDR control procedure outperforms the Bonferroni and BenjaminiHochberg (B-H) (Benjamini & Hochberg, 1995; Benjamini & Yekutieli, 2001) methods in terms of power, while still maintaining low FDP. While the Bonferroni method generally achieves only low power, the Benjamini-Hochberg method performs poorly in this application because the test statistics exhibit complex dependency, and thus violate a theoretical assumption of the Benjamini-Hochberg method.\nLastly, Figure 2 demonstrates that our de-biased Lasso Granger estimator paired with our FDR control procedure outperform the original biased Lasso Granger estimator in terms of precision and recall. Define sets TP = {i 2 H\n1 |1(✓⇤ i identified as non-zero)} and FP = {i 2 H\n0 |1(✓⇤ i identified as non-zero)}, so precision is |TP|/max{|TP| + |FP|, 1}, and recall is |TP|/|H\n1 |. Note that precision is equivalent to 1 FDP and recall is equivalent to power. We calculate precision and recall at each point along the Lasso-path of the regularization parameter to generate the curves in Figure 2. These curves demonstrate that our de-biased Lasso Granger estimator and FDR control procedure achieve higher recall than the original Lasso Granger estimator without sacrificing precision. Thus, not only does our method provide the interpretability and flexibility of uncertainty characterization, it also achieves higher power\nthan the original Lasso Granger estimator while maintaining low FDP. Therefore, our method proves more suitable for high-dimensional Granger causal inference."
  }, {
    "heading": "6.2 Real Data",
    "text": "To demonstrate the applicability of our method to real-world data, we consider the climatological data set made available by Lozano et al. (2009). This data set contains monthly observations for seventeen climatological variables (e.g., temperature, precipitation, CO2, CH4, etc.) for 128 grid points spanning the continental United States (latitudes 32.975 to 45.475 and longitudes 84.75 to 117.25) from 1990 to\n2002. Following the setup from Lozano et al. (2009), we enforce stationarity by deseasonlaizing the data using the R package “deseasonalize” (McLeod & Gweon, 2013). We model the monthly temperature change of each grid point as a linear model of the first three lagged values of all explanatory variables in the surrounding 3⇥ 3 grid. Thus, for each of the 81 interior grid points, we obtain design matricies with dimensions T = 13⇥ 12 = 156 (13 years of monthly data), d = 17 ⇥ 9 = 153 (17 climatological variables observed at 9 grid points), and p = 3. For each of these design matricies, we use the R package “glmnet”(Friedman et al., 2010) to produce the biased Lasso Granger estimate from (3.3), and then apply (4.1) to construct the de-biased Lasso Granger estimate.\nFor each grid point, we test the significance of the three lagged values of monthly changes in Carbon Dioxide (CO2) emissions for that grid point to determine if local CO2 emissions are a Granger cause of temperature changes when conditioned on many other climatological variables. Recall that an explanatory variable is a Granger cause of the response variable if and only if any of the coefficients for any of the lags prove significant. We use the Bonferroni method, the Benjamini-Hochberg (B-H) procedure, and our FDR control method from Section 4.2 to control for multiple testing. At significance level ↵ = .05, the Bonferroni and Benjamini-Hochberg methods found that CO2 emissions are a Granger cause of monthly temperature changes for 10 of the 81 grid points, whereas our FDR control method discovered 13 such grid points. We thus corroborate the findings of Lozano et al. (2009), who employed graphical Granger modeling methods to establish Granger causality between CO2 emissions and temperature changes, and those of many climate researchers who have found increased CO2 emissions to “cause” higher temperatures. We also find empirical evidence that our FDR control method achieves higher power than the Bonferroni and Benjamini-Hochberg methods. Figure 3 displays the results of this simulation."
  }, {
    "heading": "7 Conclusion",
    "text": "In this paper, we propose a novel unbiased estimator for conducting Granger causal inference in the high-dimensional\n(a) Bonferroni, B-H (b) FDR Control\nregime. We introduce test statistics and confidence intervals for our estimator, thereby accomplishing the previously impossible task of uncertainty characterization in high-dimensional Granger causal inference. Additionally, we introduce a novel method for false discovery rate control that achieves higher-power in multiple testing than existing alternatives in our setting. Lastly, we validate our theoretical results with experiments on both synthetic data and real-world climatological data. Future extensions of our work may include generalizations of our method to cope with non-Gaussian noise and non-linear causality."
  }, {
    "heading": "Acknowledgements",
    "text": "We would like to thank the anonymous reviewers for their helpful comments. This research was sponsored in part by the National Science Foundation IIS-1618948 and IIS1652539. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies."
  }],
  "year": 2017,
  "references": [{
    "title": "Controlling the false discovery rate: a practical and powerful approach to multiple testing",
    "authors": ["Benjamini", "Yoav", "Hochberg", "Yosef"],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp",
    "year": 1995
  }, {
    "title": "The control of the false discovery rate in multiple testing under dependency",
    "authors": ["Benjamini", "Yoav", "Yekutieli", "Daniel"],
    "venue": "Annals of statistics,",
    "year": 2001
  }, {
    "title": "Statistical significance in highdimensional linear models",
    "authors": ["Bühlmann", "Peter"],
    "year": 2013
  }, {
    "title": "The convex geometry of linear inverse problems",
    "authors": ["Chandrasekaran", "Venkat", "Recht", "Benjamin", "Parrilo", "Pablo A", "Willsky", "Alan S"],
    "venue": "Foundations of Computational mathematics,",
    "year": 2012
  }, {
    "title": "Rates of convergence of the adaptive lasso estimators to the oracle distribution and higher order refinements by the bootstrap",
    "authors": ["A Chatterjee", "SN Lahiri"],
    "venue": "The Annals of Statistics,",
    "year": 2013
  }, {
    "title": "High-dimensional inference: Confidence intervals, p-values and r-software hdi",
    "authors": ["Dezeure", "Ruben", "Bühlmann", "Peter", "Meier", "Lukas", "Meinshausen", "Nicolai"],
    "venue": "Statistical Science,",
    "year": 2015
  }, {
    "title": "Graphical modelling of multivariate time series",
    "authors": ["Eichler", "Michael"],
    "year": 2001
  }, {
    "title": "Graphical modeling of multivariate time series with latent variables",
    "authors": ["Eichler", "Michael"],
    "year": 2006
  }, {
    "title": "Maintainer Trevor, and Matrix, Depends",
    "authors": ["Friedman", "Jerome", "Hastie", "Trevor", "Simon", "Noah", "Tibshirani", "Rob"],
    "venue": "Package ‘glmnet’. Journal of Statistical Software,",
    "year": 2010
  }, {
    "title": "On milman’s inequality and random subspaces which escape through a mesh inn",
    "authors": ["Gordon", "Yehoram"],
    "venue": "In Geometric Aspects of Functional Analysis,",
    "year": 1988
  }, {
    "title": "Investigating causal relations by econometric models and cross-spectral methods",
    "authors": ["Granger", "Clive WJ"],
    "venue": "Econometrica: Journal of the Econometric Society,",
    "year": 1969
  }, {
    "title": "Confidence intervals and hypothesis testing for high-dimensional regression",
    "authors": ["Javanmard", "Adel", "Montanari", "Andrea"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Structured stochastic linear bandits",
    "authors": ["Johnson", "Nicholas", "Sivakumar", "Vidyashankar", "Banerjee", "Arindam"],
    "venue": "arXiv preprint arXiv:1606.05693,",
    "year": 2016
  }, {
    "title": "Can we trust the bootstrap in high-dimension",
    "authors": ["Karoui", "Noureddine El", "Purdom", "Elizabeth"],
    "venue": "arXiv preprint arXiv:1608.00696,",
    "year": 2016
  }, {
    "title": "Asymptotics for lasso-type estimators",
    "authors": ["Knight", "Keith", "Fu", "Wenjiang"],
    "venue": "Annals of statistics,",
    "year": 2000
  }, {
    "title": "Exact post-selection inference with the lasso",
    "authors": ["Lee", "Jason D", "Sun", "Dennis L", "Yuekai", "Taylor", "Jonathan E"],
    "venue": "arXiv preprint arXiv:1311.6238,",
    "year": 2013
  }, {
    "title": "An r package flare for high dimensional linear regression and precision matrix estimation",
    "authors": ["Li", "Xingguo", "Zhao", "Tuo", "Yuan", "Xiaoming", "Liu", "Han"],
    "venue": "R Package Vigette,",
    "year": 2012
  }, {
    "title": "Asymptotic properties of lasso+ mls and lasso+ ridge in sparse high-dimensional linear regression",
    "authors": ["Liu", "Hanzhong", "Yu", "Bin"],
    "venue": "Electronic Journal of Statistics,",
    "year": 2013
  }, {
    "title": "Hypothesis testing for highdimensional regression models",
    "authors": ["Liu", "Weidong", "Luo", "Shan"],
    "year": 2014
  }, {
    "title": "Phase transition and regularized bootstrap in large-scale t-tests with false discovery rate control",
    "authors": ["Liu", "Weidong", "Shao", "Qi-Man"],
    "venue": "The Annals of Statistics,",
    "year": 2025
  }, {
    "title": "Gaussian graphical model estimation with false discovery rate control",
    "authors": ["Liu", "Weidong"],
    "venue": "The Annals of Statistics,",
    "year": 2013
  }, {
    "title": "A significance test for the lasso",
    "authors": ["Lockhart", "Richard", "Taylor", "Jonathan", "Tibshirani", "Ryan J", "Robert"],
    "venue": "Annals of statistics,",
    "year": 2014
  }, {
    "title": "New Introduction to Multiple Time Series Analysis",
    "authors": ["Lutkepohl", "Helmut"],
    "year": 2007
  }, {
    "title": "Optimal deseasonalization for monthly and daily geophysical time series",
    "authors": ["A.I. McLeod", "Gweon", "Hyukjun"],
    "venue": "Journal of Environmental Statistics,",
    "year": 2013
  }, {
    "title": "Highdimensional graphs and variable selection with the lasso",
    "authors": ["Meinshausen", "Nicolai", "Bühlmann", "Peter"],
    "venue": "The Annals of Statistics,",
    "year": 2006
  }, {
    "title": "Reconstruction and subgaussian operators in asymptotic geometric analysis",
    "authors": ["Mendelson", "Shahar", "Pajor", "Alain", "Tomczak-Jaegermann", "Nicole"],
    "venue": "Geometric and Functional Analysis,",
    "year": 2007
  }, {
    "title": "A unified framework for highdimensional analysis of m-estimators with decomposable regularizers",
    "authors": ["Negahban", "Sahand N", "Ravikumar", "Pradeep", "Wainwright", "Martin J", "Yu", "Bin"],
    "venue": "Statistical Science, 27(4):538–557,",
    "year": 2012
  }, {
    "title": "Control of the false discovery rate under dependence using the bootstrap and subsampling",
    "authors": ["Romano", "Joseph P", "Shaikh", "Azeem M", "Wolf", "Michael"],
    "year": 2008
  }, {
    "title": "Granger causality analysis in neuroscience and neuroimaging",
    "authors": ["Seth", "Anil K", "Barrett", "Adam B", "Barnett", "Lionel"],
    "venue": "The Journal of Neuroscience,",
    "year": 2015
  }, {
    "title": "Discovering graphical granger causality using the truncating lasso",
    "authors": ["Shojaie", "Ali", "Michailidis", "George"],
    "venue": "penalty. Bioinformatics,",
    "year": 2010
  }, {
    "title": "Introduction to Econometrics (3rd edition)",
    "authors": ["Stock", "James", "Watson", "Mark"],
    "venue": "Addison Wesley Longman,",
    "year": 2011
  }, {
    "title": "Scaled sparse linear regression",
    "authors": ["Sun", "Tingni", "Zhang", "Cun-Hui"],
    "venue": "Biometrika, pp. ass043,",
    "year": 2012
  }, {
    "title": "The generic chaining: upper and lower bounds of stochastic processes",
    "authors": ["Talagrand", "Michel"],
    "venue": "Springer Science & Business Media,",
    "year": 2006
  }, {
    "title": "Upper and lower bounds for stochastic processes: modern methods and classical problems, volume 60",
    "authors": ["Talagrand", "Michel"],
    "venue": "Springer Science & Business Media,",
    "year": 2014
  }, {
    "title": "Post-selection adaptive inference for least angle regression and the lasso",
    "authors": ["Taylor", "Jonathan", "Lockhart", "Richard", "Tibshirani", "Ryan J", "Robert"],
    "venue": "arXiv preprint,",
    "year": 2014
  }, {
    "title": "Regression shrinkage and selection via the lasso",
    "authors": ["Tibshirani", "Robert"],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pp",
    "year": 1996
  }, {
    "title": "On asymptotically optimal confidence regions and tests for high-dimensional models",
    "authors": ["Van de Geer", "Sara", "Bühlmann", "Peter", "Ritov", "Ya’acov", "Dezeure", "Ruben"],
    "venue": "The Annals of Statistics,",
    "year": 2014
  }, {
    "title": "Introduction to the non-asymptotic analysis of random matrices",
    "authors": ["R. Vershynin"],
    "venue": "Compressed Sensing: Theory and Applications,",
    "year": 2012
  }, {
    "title": "Optimal false discovery rate control for dependent data",
    "authors": ["Xie", "Jichun", "Cai", "T Tony", "Maris", "John", "Li", "Hongzhe"],
    "venue": "Statistics and its interface,",
    "year": 2011
  }, {
    "title": "On the gaussian approximation of convolutions under multidimensional analogues of sn bernstein’s inequality conditions",
    "authors": ["Zaitsev", "A Yu"],
    "venue": "Probability theory and related fields,",
    "year": 1987
  }, {
    "title": "Confidence intervals for low dimensional parameters in high dimensional linear models",
    "authors": ["Zhang", "Cun-Hui", "Stephanie S"],
    "venue": "Journal of the Royal Statistical Society: Series B,",
    "year": 2014
  }],
  "id": "SP:59cdb43ce4707048c3403a493092a8a2c407b28d",
  "authors": [{
    "name": "Aditya Chaudhry",
    "affiliations": []
  }, {
    "name": "Pan Xu",
    "affiliations": []
  }, {
    "name": "Quanquan Gu",
    "affiliations": []
  }],
  "abstractText": "Causal inference among high-dimensional time series data proves an important research problem in many fields. While in the classical regime one often establishes causality among time series via a concept known as “Granger causality,” existing approaches for Granger causal inference in high-dimensional data lack the means to characterize the uncertainty associated with Granger causality estimates (e.g., p-values and confidence intervals). We make two contributions in this work. First, we introduce a novel asymptotically unbiased Granger causality estimator with corresponding test statistics and confidence intervals to allow, for the first time, uncertainty characterization in high-dimensional Granger causal inference. Second, we introduce a novel method for false discovery rate control that achieves higher power in multiple testing than existing techniques and that can cope with dependent test statistics and dependent observations. We corroborate our theoretical results with experiments on both synthetic data and real-world climatological data.",
  "title": "Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference"
}