{
  "sections": [{
    "heading": "1. Introduction",
    "text": "For well over a decade there has been extensive work on learning social network influence models (Liben-Nowell & Kleinberg, 2003; Netrapalli & Sanghavi, 2012; Abrahao et al., 2013; Friggeri et al., 2014; Anderson et al., 2015; Subbian et al., 2017), and the independent cascade model in particular (Saito et al., 2008; Gomez Rodriguez et al., 2010; Goyal et al., 2010; Gomez Rodriguez et al., 2011; Du et al., 2014; Lemonnier et al., 2014; Bourigault et al.,\n*Equal contribution 1Department of Computer Science, Harvard University 2Facebook, Menlo Park. Correspondence to: Dimitris Kalimeris <kalimeris@g.harvard.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\n2014; Narasimhan et al., 2015). Independent cascade (IC) was popularized by the seminal work of Kempe, Kleinberg, and Tardos (Kempe et al., 2003) and is a stochastic model that predicts the likelihood of information diffusing from one individual to another in a social network. In this model for every pair of individuals connected in the network u, v there is a probability pu,v that v adopts the behavior of u (i.e. information is diffused from u to v).\nThe main challenge with learning the IC model is that the sample complexity is often overwhelmingly large or simply infeasible. To illustrate this point, Figure 1 shows the cumulative distribution of edge interactions for millions of public events on Facebook over varying periods of time, ranging from one week to two months (see detailed description of the dataset in Section 5). The vertical line marks the minimal number of observations per edge required to infer the likelihood of influence with error 0.1 and confidence 95%. In this data set, more than 90% of the edges do not have enough observations to learn the respective diffusion probabilities accurately, even over a period of two months. Furthermore, in a single week (the timeframe in which inference about an event is often most relevant), none of the edges in the data set have sufficiently many observations.\nGiven that even with the data available on Facebook there are not enough observations to learn the model, one needs to impose additional assumptions. A natural approach is to assume that the diffusion probabilities are a function of network and individuals’ characteristics and some underlying\nglobal hyperparameter θ. In the case of events for example, it seems reasonable that influence could be estimated as a function of some global unknown multidimensional parameter θ and individuals’ characteristics such as location, gender, and age, and topological features like the ratio between the intersection and the union of the individuals’ neighborhoods. Using xu,v to denote the characteristics of u and v, the hyperparametric approach assumes that the probability of u to influence v denoted pu,v is not arbitrary and can be faithfully estimated via some function p that maps θ and xu,v to [0, 1], i.e. pu,v = p(θ,xu,v). Given a set of characteristics, learning the IC model then reduces to recovering the underlying hyperparameter θ.\nIntuitively, learning a hyperparametric model necessitates far fewer samples than a general diffusion model for two main reasons. First, since the diffusion probabilities are correlated, each observation provides information about all edges in the network. Second, it seems reasonable that the sample complexity of learning the hyperparameter should largely depend on the dimension of the hyperparameter rather than the number of edges the network.\nA simple example. To solidify our intuition, consider a simple bipartite network G = (U, V,E) where nodes in U attempt to activate nodes from V as depicted in Figure 1.1 and each activation attempt together with its outcome (label) constitutes one sample. Our goal is to find a p̂u,v for every edge (u, v) ∈ E, s.t. with prob. at least 1− δ for all edges:\n|pu,v − p̂u,v| ≤\nHoeffding’s inequality and a union bound imply that Θ ( |E| 2 log |E| δ ) samples are necessary and sufficient to learn the diffusion probabilities on all the edges in the graph. In comparison, suppose that the diffusion probability of each edge is a function of a hyperparameter θ ∈ [0, 1]d and some known features of the edge xu,v ∈ [0, 1]d as follows:\npu,v = 1\n1 + e−〈θ,xu,v〉\nThen, learning the diffusion probabilities becomes a logistic regression problem and thus only O ( d 2 log d δ ) samples are required, independent of the number of edges. This reduces the sample complexity by a factor of |E|d which is quite dramatic when the number of edges in the network |E| is large and the dimension of the hyperparameter d is small.\nBeyond potential improvements in sample complexity, a hyperparametric model is convenient due to the structure it imposes. A recent line of work on influence maximization in bandit models (Wen et al., 2015; Vaswani et al., 2017), assumes that the diffusion probabilities are a linear function of edge features, i.e. pu,v = 〈θ, xu,v〉 and this structure is leveraged in order to develop faster algorithms."
  }, {
    "heading": "1.1. A Hyperparametric Approach",
    "text": "Our goal in this paper is to explore a hyperparametric approach for learning the independent cascade diffusion model. Doing so requires addressing three open questions:\n• Does restriction to a low-dimensional hyperparameter substantially decrease the sample complexity? As discussed above, the motivation for a hyperparametric approach is that intuitively its sample complexity should depend on the dimension of the hyperparameter rather than the number of edges. While intuitive, when the indegree of nodes is greater than 1, minimizing empirical risk becomes a non-convex optimization problem and analyzing sample complexity is not trivial; • Can a hyperparametric model be learned efficiently? As learning a hyperparametric model requires solving a non-convex optimization problem, it is not clear it can be learned efficiently, in theory or in practice; 1 • Are low-dimensional hyperparametric models predictive? Assuming that sample complexity heavily depends on its dimension, our approach is relevant only if reasonable estimates of the IC model are achievable with a low-dimensional hypothesis class.\nIn this paper we address the above questions. We first show that the sample complexity can indeed be dramatically reduced when restricting the hypothesis class to a lowdimensional hyperparameter. Specifically, when comparing with the state-of-the-art bound for learning the independent cascade model (without the hyperparametric assumption) we show that the sample complexity can be reduced by a factor of |E|/d, as foreshadowed by the example above.\nDespite being a non-concave optimization problem we show that the problem has a great deal of structure. Under mild assumptions about the distribution generating the samples, we show how this structure can be leveraged to efficiently train a model with arbitrarily small generalization error.\nLastly, we show that the hyperparametric approach does work in practice. To do so, we ran experiments on large scale cascades recorded on the Facebook social network. We show that with a hyperparameter of dimension 40 one\n1We note that even without the hyperparametric assumption PAC learning the IC model is a non-convex optimization problem (Narasimhan et al., 2015).\ncan estimate the diffusion probabilities with remarkably high accuracy. Naturally, there are data sets that do not contain individuals’ characteristics. Nonetheless, most social networking services include useful information about its members that help predict diffusion, and the topology of the network alone often may serve as a good proxy."
  }, {
    "heading": "2. The Hyperparametric Model",
    "text": "A social network is a finite directed graph G = (V,E), where the set of nodes V represents the individuals in the network and the set of edges E represents their social links.\nIndependent Cascade (IC) model. The IC model assumes that every node v ∈ V can either be active or inactive. All nodes begin as inactive. At time step t = 0 a subset of the nodes X called the seed becomes active, and activations in the network continue according to the following stochastic process: Each node u that became active at time step t = τ attempts to influence every one of its neighbors v only once at time step t = τ + 1 independently, and succeeds with some probability pu,v. A node v that became active during the process will never go back to being inactive. Our work generalizes the standard IC model by assuming that the probabilities pu,v are not arbitrary but correlated and specifically consequences of nodes’ features. This is the hyperparametric assumption, as described below.\nHyperparametrization. Every node u ∈ V is associated with a vector of features containing information about it. Every edge (u, v) ∈ E, is also associated with a feature vector, the concatenation of the feature vectors of its endpoints, denoted by xu,v. The diffusion probability of each edge is a function of a global hyperparameter θ and its feature vector. Formally, we assume that there exists a function p : Rd × Rd → [0, 1] s.t. pu,v = p(θ, xu,v) for any edge (u, v) ∈ E. In this work we define p as the sigmoid function:\npu,v = σ(θ, xu,v) = 1\n1 + e−〈θ,xu,v〉 .\nWe restrict the hyperparameter θ to lie in a hypothesis class H = [−B,B]d for some constant B > 0, and w.l.o.g. we assume that the feature vector of every edge lies in [0, 1]d. Additionally, we assume that pu,v is bounded away from 0 and 1 for all edges, i.e. pu,v ∈ [λ, 1− λ], for some λ > 0.\nFurther discussion about the hyperparametric model and the choice of the sigmoid function can be found in Appendix A.\nSamples. The input to a learning algorithm is a collection of labeled samples. We assume that there is some unknown distribution D0 over subset of nodes, that activates the initial seed of the cascade, V0. Subsequently, as we discussed before, we can partition V \\ V0 into subsets of nodes V1, V2, . . . , Vn−1 that become activated at steps\nτ = 1, 2, . . . , n− 1, respectively 2. Notice that the cascade can be further decomposed into a sequence of simpler samples as follows: for every τ ∈ {0, 1, . . . , n− 1} consider all the nodes v /∈ ∪τ−1t=0 Vt that are within distance of 1 from Vτ . For every v that became activated by Vτ (i.e. v ∈ Vτ+1) create the sample ((Vτ , v), 1), and for every v that remained inactive create the sample ((Vτ , v), 0). Throughout this paper we assume that the input to our learning algorithm is of the form {(Xi, vi), yi}mi=1 where Xi ⊆ V is a subset of active nodes, vi is a node in distance 1 from Xi and yi ∈ {0, 1} is its label. In Appendix C we map every seed-generating distribution D0 to a sample-generating distribution D.\nLog-likelihood of a sample. For every node v, the event “v becomes influenced by X , when the hyperparameter has value θ” is a Bernoulli random variable with probability of success fθv (X) = 1− ∏ u∈X∩N(v)(1−pu,v(θ)) whereN(v) is the set of in-neighbors of node v. Hence, the likelihood of a sample s = ((X, v), y), where v /∈ X is fθv (X)y · ( 1−\nfθv (X) )1−y , and the respective log-likelihood of s is:\nL(s, θ) = y ln(fθv (X)) + (1− y) ln(1− fθv (X)) (1)\nWe want to recover a hyperparameter θ that yields accurate estimates. To do so, given a training set S = {si}mi=1, we seek the most probable hyperparameter generating S by maximizing the cumulative log-likelihood function:\nθ̂ = arg max θ∈H\n1\nm m∑ i=1 L(si, θ) (2)\nLearning a diffusion model. Our goal is to bound the sample complexity, i.e. the number of i.i.d. samples generated by a distribution D that we need to observe to PAC learn H. That is, guarantee that supθ∈H Es∼D[L(s, θ)] − Es∼D[L(s, θ̂)] ≤ , with probability at least 1 − δ (see definition of PAC learnability in Appendix B).\nNotice that while there are |E| edges in the network, which translates to |E| diffusion probabilities, in the optimization problem (2) there are only d parameters to be learned.\nWe would like to note that PAC learning guarantees are required to hold for any distribution D that generates the data. Hence, it is easy to see that the diffusion probabilities or the hyperparameter θ are not learnable without extra assumptions on D. For details refer to Appendix D."
  }, {
    "heading": "3. Learning a Hyperparametric Model",
    "text": "In this section we prove Theorem 2 which is the main technical result of the paper. The main takeaway is that a hyperparameteric approach makes learning an influence model feasible. Informally, the theorem states that the number of samples required to ( , δ)-PAC learn the model is\n2The influence process terminates after at most |V | − 1 steps.\nÕ ( ∆2 ( ∆·d+log 1δ 2 )) , where ∆ is the maximum degree in\nthe network and d is the dimension of the hyperparameter. As we later show in the experiments section, very small constant values of d suffice to learn an influence model with almost no error on real data. This is in sharp contrast to the best sample complexity guarantees due to (Narasimhan et al., 2015) for learning the model without the hyperparametric assumption which is Õ ( ∆2 ( ∆·|E|+log 1δ 2 )) .\nFurthermore, imposing assumptions on the distribution D, can reduce the dependence on ∆ making the sample complexity (almost) independent of the size of the network."
  }, {
    "heading": "3.1. Sample Complexity via Radamacher Complexity",
    "text": "The main technical challenge is due to the fact that the MLE objective in (2) is non-concave and we cannot immediately derive sample complexity bounds from convergence guarantees of Stochastic Gradient Descent for example. Instead, to analyze the sample complexity we will argue about the Rademacher complexity of our hypothesis class by using covering numbers. Informally, the Rademacher complexity measures the expressive power of a hypothesis classH with respect to a probability distribution and the covering number of a set is the number of balls of a certain radius whose union contains the set (see Definitions 2 and 3 in Appendix B). Recall that the sample complexity of a hypothesis class can be derived from its Rademacher complexity.\nTheorem 1 ((Shalev-Shwartz & Ben-David, 2014)). Assume that for every sample s ∼ D and every θ ∈ H we have that: |L(s, θ)| ≤ C. Let S ∼ Dm and θ̂ = arg maxθ∈H { 1 m ∑m i=1 L (si, θ) } . Then with probability at least 1− δ over the choice of S we have that:\nEs∼D[L(s, θ̂)] ≥ sup θ∈H Es∼D[L(s, θ)]\n−R(S,H)−O C √\nlog 1δ m  whereR(S,H) is the Rademacher complexity of the class H with respect to S.\nHence, our goal reduces to boundingR(S,H) for a training set S of size m. We do so by discretizingH by , and prove that if the discretization is dense enough, then we do not sacrifice a lot by searching for the most likely hyperparameter in the discrete spaceH instead of the continuousH.\nTo this end, we construct an -cover of the hypothesis class H = [−B,B]d. Proving that the log-likelihood of any fixed sample s, is bounded and Lipschitz3 in θ with respect to\n3intuitively for a Lipschitz function a small change in the argument cannot lead to a large change in the value of the function, see Definition 4, Appendix B.\nthe `1-norm, where the Lipschitz parameter depends on λ (Lemma 3 in Appendix E), allows us to translate the cover of the space of the hyperparameter, into a cover of the space of the log-likelihood functions, by slightly increasing the number of points we include in it, as stated in Lemma 1. The proof is deferred to Appendix E.\nLemma 1. Let S = {((Xi, vi), yi)}mi=1 be a non-empty set of samples and let ∆S = maxs∈S |X∩N(v)| (maximum indegree of a node that was activated, across all samples). The covering number of the class of all log-likelihood functions for S is O (( Bρd λ∆S )d) , i.e. we can choose a discrete cover\nH ⊆ H of size O ((\nBρd λ∆S\n)d) , such that for all θ ∈ H,\nthere exists a θ ∈ H with sup s∈S |L(s, θ)− L(s, θ )| ≤ .\nGiven the above lemma, we can invoke Massart’s lemma (Lemma 5 in Appendix E) onH which upper bounds the Rademacher complexity of finite hypothesis classes. Subsequently, we use Lemma 4 (Appendix E) to upper bound the Rademacher complexity ofH from that ofH . We are now ready to prove the main theorem of the section.\nTheorem 2 (Sample Complexity of MLE). Let G = (V,E) be a directed graph and D be a distribution that generates samples of the form s = ((X, v), y). Let ∆ = maxs∼D |X ∩N(v)|. Then, for any , δ ∈ (0, 1) , if we use Maximum Likelihood Estimation on a training set of size m ≥ m( , δ) = O ( ∆2 log2(1/λ)d log(Bρd/λ ∆ )+log(1/δ) 2\n) samples drawn i.i.d. from D, with probability at least 1− δ (over the draw of the training set) it holds:\nsup θ∈H\nEs∼D[L ( s, θ ) ]− Es∼D[L ( s, θ̂ ) ] ≤ .\nProof. Define ∆ := maxs∼D |X ∩N(v)|, i.e. the maximum active in-degree that any sample generated by D can have. Then, applying Lemma 1 we can create a discrete -cover of the space of the log-likelihoods, H ⊆ H, of size |H | = O (( Bρd λ∆ )d) for any training set S of any size. Invoking Lemma 4 (Appendix E), we can associate the Rademacher complexity ofH with that of its coverH , for any S and any > 0, as follows:\nR(S,H) ≤ R(S,H ) + 2 .\nHence, we can focus on bounding the Rademacher complexity of H instead of that of H. Since H is finite, the well-known Massart’s lemma apply yielding:\nR(S,H) ≤ R(S,H ) + 2\n≤ 2 max θ∈H ∣∣∣∣∣∣(L(si, θ))mi=1∣∣∣∣∣∣2 √ 2 log(|H |) m + 2\n≤ 2 √ m∆ ln 1 λ · √ 2 log(|H |) m + 2\n= 2∆ ln 1\nλ\n√ 2 log(|H |)\nm + 2\n= O ( ∆ log 1\nλ\n√ d log(Bρd/λ∆ )\nm\n) + 2\nwhere the first inequality holds because of Lemma 4 (discretization), the second because of Massart’s lemma (finite hypothesis class), the third because of Lemma 3 (bounded L), and the last one because of Lemma 1 (covering number). Setting = 1/m yields: R(S,H) = O ( ∆ log(1/λ) √\nd log(Bρdm/λ∆) m\n) . Now using the\ngeneralization bound of Theorem 1, one can see that in order to achieve Es∼D[L(s, θ̂)] ≥ supθ∈H Es∼D[L(s, θ)]− , with probability at least 1 − δ, we need S to be of size m = O ( ∆2 log2(1/λ)d log(Bρd/λ ∆ )+log(1/δ) 2 ) , which\nconcludes the proof.\nGiven that B and λ are constants the above bound simplifies to Õ ( ∆2 ( ∆·d+log 1δ 2 )) , which allows immediate compar-\nison with the bounds derived in (Narasimhan et al., 2015). Additionally, when the degree of every node is constant (which is the case for real social networks like Facebook) or when the distribution D activates only seeds of constant size, ∆ is a constant and the sample complexity becomes Õ ( d+log 1δ 2 ) , independent of the size of the network."
  }, {
    "heading": "4. Algorithms",
    "text": "As we mentioned in the previous section, the maximization problem (2) is non-concave and it cannot be solved efficiently. However, the cumulative log-likelihood function we aim to optimize has a great deal of structure we can utilize.\nTo understand this structure, note that there are only three distinct cases for a sample s = ((X, v), y) in the training set S: (i) node v was not influenced, (ii) node v was influenced and there is only one neighbor of v in X and (iii) node v was influenced and there is more than one neighbor of v in X . The only case that makes the respective log-likelihood non-concave is (iii) since we are unable to identify which of the parents of v actually influenced it and how to update the hyperparameter (equation (1) yields that formally). We refer to such samples as obfuscated.\nOne can partition S into So and S \\ So where So contains the obfuscated samples. We can then write f̃(θ) := 1m ∑ s∈S L(s, θ) = 1 m ∑ s∈S\\So L(s, θ) + 1 m ∑ s∈So L(s, θ) =: f(θ) + ξ(θ). Optimizing f̃ can be perceived as optimizing a concave function f under noise ξ. The magnitude of the noise depends on the probability of seeing an obfuscated sample, which characterizes the difficulty of the optimization problem and can be computed in simple cases (see e.g. Lemma 8 in Appendix F).\nThere are three distinct approaches that we can follow:\n1. Ignore the obfuscated samples and optimize f instead of f̃ , using standard methods like Gradient Descent. The fact that the likelihood of each sample is bounded (Lemma 3 in Appendix E) will assure that the recovered solution will approximately optimize f̃ as well. 2. Optimize f̃ directly by applying techniques from (Belloni et al., 2015) for concave optimization under noise. 3. Attempt to optimize f̃ using standard concave optimization techniques (for example Stochastic Gradient Descent (SGD) which is widely used in the training of deep networks, a non-convex optimization problem).\nThe first two methods provide theoretical guarantees for noise of small magnitude, if the noise is large however, they can lead to large error. See Appendix F for a detailed description of these two approaches. The third heuristic approach works remarkably well in practice, even when the noise is large, as the experiments of Section 5.1 demonstrate. Additionally, in Section 5.2 we include experiments indicating that, even if the noise is small, it is still in our best interest to utilize all the available samples since the shortage of the training set hurts us more than non-concavity."
  }, {
    "heading": "5. Experiments",
    "text": "We conduct two sets of experiments. First, using synthetic datasets we show that if the hyperparametric assumption holds in a network, we can accurately learn the edge probabilities despite the non-concavity of (2), and significantly outperform methods that do not include information about the node features, for small training sets4. We also investigate which properties of the network and the model affect the convergence rate. Secondly, we validate our approach using real Facebook data, by showing that low-dimensional hyperparametric models are predictive in practice."
  }, {
    "heading": "5.1. Learning the Diffusion Probabilities",
    "text": "Real Graphs: We also use the “ego-facebook”, “wiki-Vote”, “bitcoin-otc” and “bitcoin-alpha” datasets from (Leskovec & Krevl, 2014), which are publicly available real-world social networks, enabling the reproducibility of our experiments.\nGraphs. We synthetically generate the social graph and the hyperparameter that determines the diffusion probabilities.\nSynthetic Graphs: We simulate a social network using standard graph models. Since different models yield graphs with different topology, we selected four of the widely used ones: Barabási-Albert, Kronecker, Erdös-Rényi and the con-\n4Notice that learning the diffusion probabilities allows us to compute other quantities of interest as well, like the probability of a node becoming influenced, the final size of a cascade initiated from a given set, or the influence function.\nfiguration model. For a more detailed description of these models and the construction process refer to Appendix G.\nExperimental setup. We generate 15 random features in [0, 1] for every node (we found consistent results across a large range of features). We define the first 10 of them to be the ones in which the hyperparametric assumption is based, and the rest is redundant information (30 features for each edge, where only 20 of them are important). Additionally, we generate a random hyperparameter in [−1, 1]d (d = 20). We use the sigmoid function over the important features of each edge e and the hyperparameter to compute pe, as described in Section 2, imposing correlation between the probabilities of different edges by construction.\nSubsequently, we generate 100,000 samples, and attempt to solve the optimization problem (2) using SGD, initializing the hyperparameter to 0 and using a learning rate of 1/ √ T , where T is the size of the training set. Details on how we create the training set can be found in Appendix G.\nBenchmarks. We tested the hyperparametric model against the following benchmarks: • Omniscient MLE: The true diffusion probability of an\nedge is approximated by p̂e = n+e /ne, where n + e is the number of activations of edge e, while ne is the total number of exposures of e (activation attempts). Here, we assume that for every sample ((X, v), y) we observe the activation or not of all the edges e = (u, v), where u is an active neighbor of v. This is a strong benchmark since in practice, we can observe whether v became active but not which node activated it. • Non-hyperparametric MLE: We implemented the algorithm of (Narasimhan et al., 2015), that allows one\nto learn the diffusion probabilities only by observing whether a node v was influenced by the seed X or not. • Hyperparametric MLE, reduced information: We com-\npare ourselves against a hyperparametric model that is unaware of the exact features that are important, and selects only a subset of them. Here we select only 5 out of 10 important features of every node. • Hyperparametric MLE, augmented information: Similarly, we compare ourselves against a hyperparametric model that is unaware of the important features, thus it selects all the available ones (15 features per node).\nResults. We repeat each experiment 10 times, and provide the mean and the standard deviation in Figure 3. The y-axis corresponds to 1|E| ∑ e∈E |pe − p̂e|, the average absolute error between the real probability (known by construction) and the empirical one across the network. In all networks, the hyperparametric approach greatly outperforms the nonhyperparametric benchmarks, even assuming omniscience.\nNote that in the non-hyperparametric benchmarks, since samples do not carry global information, there exist edges that have no exposures given the samples that we have seen so far. In that case, we define p̂e = 0. This explains the initial increase in the error in the omniscient MLE since, if pe is small and the first exposure of edge e is an activation, the error on e increases from pe to 1 − pe. Once we see enough samples, p̂e converges to pe. One can also notice, the effect of omniscience since it leads to faster convergence than actual implementable non-hyperparametric methods.\nRegarding the two benchmarks that involve the hyperparametric assumption it is worth noting that reduced information does not allow convergence to 0 error, while augmented\ninformation does (see also Figure 4d for a more detailed investigation). Finally, the initial difference in the errors of different networks is related to how good predictor the initialization of SGD is (i.e. θ = 0), as well as how large the average diffusion probability in the network is. The learning effect is evident and universal though, since the error converges to 0 independently of the underlying network."
  }, {
    "heading": "5.2. Convergence Rate Investigation",
    "text": "In these experiments we use Erdös-Rényi graphs with 1000 nodes and 20000 edges (unless otherwise stated).\nSamples vs Concavity. In Section 4 we classified the samples into categories based on whether they yield concave log-likelihood or not. Recall that if we ignore the obfuscated samples, the optimization problem becomes concave. A natural question is whether sacrificing samples for concavity leads to faster convergence. To this end, we generate samples and if a sample is obfuscated, we discard it with probability p ∈ {0.0, 0.25, 0.5, 0.75, 1.0}. The results can be found in Figure 4a. It is evident that even though our optimization problem becomes concave and hence theoretically easier to solve, the price due to data shortage is huge.\nApproximate models. Here we investigate how properties of the graph or the model affect the convergence rate. • Graph Density: We create an Erdös-Rényi graph with\n1000 nodes and varying number of edges, exploring how does graph density affect the convergence of the error. As the density increases, so does the average degree in the network and, as a result, the number of obfuscated samples. Hence, the information obtained becomes “noisier” and convergence is slower. • Noisy model: Until now we assumed that the hyperparametric model is the ground truth. Here we relax this assumption. We generate each edge probability as before, and subsequently add noise uniform in [−N,N ], for increasing values ofN . Now, the average error does not converge to 0 and increases with N . • Features Effect: In many cases we might not know the exact features that support the hyperparametric model.\nWe explore the effect of this lack of information by including varying number of significant features in our model. Our results show that in terms of convergence more information does not hurt, despite being more costly computationally. However, if we fail to include all the significant features, we do not converge to 0 error, and the error grows with the removal of features.\nThe results can be found in Figure 4b-d. In all the cases the way that we enforced the hyperparametric assumption, created the samples and ran SGD is the same as in Section 5.1."
  }, {
    "heading": "5.3. Are Low-dimensional Models Predictive?",
    "text": "Importantly, we evaluate the validity of the hyperparametric assumption on real cascade data. To this end, we use the following aggregated and public Facebook data sets containing only de-identified data (i.e. they don’t include personally identifying information about individuals in the dataset).\nEvents. In Facebook a user can invite a set of other users for an event, who can then forward the invite to their friends to join. Moreover, when friends join an event a user may be notified in their Facebook feed and join in turn. The cascade in this scenario is an event and an exposure is either a direct invite or a feed notification. A user is influenced if she marked herself as “going” to the event. This dataset is a random sample of events that happened over a twomonth period in late 2017. We have included only public events that are visible to everyone and also excluded users who created the event or joined without being invited. The number of cascades in our dataset is roughly 3 million with 90 million users participating and 130 million exposures.\nVideo and Photo Reshares. A cascade in this dataset is a video or photo content. Whenever a user watches a video (photo) posted from a friend we consider it as an exposure and when the user shares that video (photo) after watching we consider it as an adoption (we consider only videos that were explicitly seen and not auto-played). We collected a random sample of photo/video data on a random day in January 2018, and included only public photo and video\nposts. Our data sets contain roughly 10 million cascades with more than 100 million users and 500 million exposures.\nExperimental setup. The features that we include in our model in both cases are user attributes such as Facebook age in days, friend count, number of initiated friendship requests, subscriber count and subscription count, city, country, and language, number of days active in last 7 days, and 28 days. The categorical features were binarized in the model. An important difference with the experiments of Sections 5.1 and 5.2 is that here we don’t know the true diffusion probability of every edge by construction. Instead, we estimate it from samples as p̂e = n+e ne\n. In order to estimate p̂e accurately, we need enough samples for edge e. Hence, we restrict our evaluation set (the set of edges where we measure the error) only to edges that have at least 67 interactions, meaning that |pe − p̂e| ≤ 0.15 with probability at least 90%. Each experiment is repeated 50 times and the averages together with the standard deviations are reported in Figures 5 and 6.\nResults. Our first set of experiments is to validate the hyperparametric assumption in real data. We observe that using the optimization problem (2), with very few samples, the hyperparametric model achieves significant reduction in average error (up to 60%) over methods that don’t utilize node features. The results, reported in Fig. 5, are consistent with our synthetic experiments, where the hyperparametric assumption holds by construction. Note that the non-hyperparametric methods will eventually converge to zero error as they correspond to the ground truth while the hyperparametric model is only a good approximation of it.\nWe also included reduced and augmented hyperparametric models for comparison as in the synthetic experiments. In the case of the reduced model we used only 20% of the most important features of each edge (measured using Mutual Information). For the augmented version on the other hand, we augment the feature vector of each node with redundant information (increase its dimension by 50% and fill the extra coordinates with random noise) and investigate whether convergence still occurs. As in the experiments of Section 5.1, the reduced model converges to higher average error than the models that use more information, while the augmented model successfully ignores all the redundant features.\nWe also evaluated the sensitivity of the hyperparametric model when we include all versus few selected features. The picture that we see matches the synthetic experiments (Figure 4d), i.e. the hyperparametric model is supported on several features and if we fail to include all of them our error won’t converge to 0. However, an important difference with the synthetic experiments is that here not all the features are equally important, hence by applying feature-selection algorithms we can collect a small subset that performs almost as well as using the entire feature vector (see e.g. the difference in the error between 20% and 90% of the features)."
  }, {
    "heading": "6. Acknowledgements",
    "text": "This research was supported by NSF grant CAREER CCF1452961, BSF grant 2014389, NSF USICCS proposal 1540428, and a Facebook research award."
  }],
  "year": 2018,
  "references": [{
    "title": "Trace complexity of network inference",
    "authors": ["Abrahao", "Bruno D", "Chierichetti", "Flavio", "Kleinberg", "Robert", "Panconesi", "Alessandro"],
    "venue": "In The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2013
  }, {
    "title": "Global diffusion via cascading invitations: Structure, growth, and homophily",
    "authors": ["Anderson", "Ashton", "Huttenlocher", "Daniel P", "Kleinberg", "Jon M", "Leskovec", "Jure", "Tiwari", "Mitul"],
    "venue": "In Proceedings of the 24th International Conference on World Wide Web,",
    "year": 2015
  }, {
    "title": "Escaping the local minima via simulated annealing: Optimization of approximately convex functions",
    "authors": ["Belloni", "Alexandre", "Liang", "Tengyuan", "Narayanan", "Hariharan", "Rakhlin", "Alexander"],
    "venue": "In Proceedings of The 28th Conference on Learning Theory, pp",
    "year": 2015
  }, {
    "title": "Learning social network embeddings for predicting information diffusion",
    "authors": ["Bourigault", "Simon", "Lagnier", "Cedric", "Lamprier", "Sylvain", "Denoyer", "Ludovic", "Gallinari", "Patrick"],
    "venue": "In Proceedings of the 7th ACM international conference on Web search and data mining,",
    "year": 2014
  }, {
    "title": "Influence function learning in information diffusion networks",
    "authors": ["Du", "Nan", "Liang", "Yingyu", "Balcan", "Maria", "Song", "Le"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "Rumor cascades",
    "authors": ["Friggeri", "Adrien", "Adamic", "Lada", "Eckles", "Dean", "Cheng", "Justin"],
    "venue": "In International AAAI Conference on Web and Social Media,",
    "year": 2014
  }, {
    "title": "Uncovering the temporal dynamics of diffusion networks",
    "authors": ["M Gomez Rodriguez", "D Balduzzi", "B Schölkopf", "Scheffer", "Getoor T"],
    "venue": "In 28th International Conference on Machine Learning (ICML",
    "year": 2011
  }, {
    "title": "Inferring networks of diffusion and influence",
    "authors": ["Gomez Rodriguez", "Manuel", "Leskovec", "Jure", "Krause", "Andreas"],
    "venue": "In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2010
  }, {
    "title": "Learning influence probabilities in social networks",
    "authors": ["Goyal", "Amit", "Bonchi", "Francesco", "Lakshmanan", "Laks VS"],
    "venue": "In Proceedings of the third ACM international conference on Web search and data mining,",
    "year": 2010
  }, {
    "title": "Maximizing the spread of influence through a social network",
    "authors": ["Kempe", "David", "Kleinberg", "Jon", "Tardos", "Éva"],
    "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2003
  }, {
    "title": "Tight bounds for influence in diffusion networks and application to bond percolation and epidemiology",
    "authors": ["Lemonnier", "Rémi", "Scaman", "Kevin", "Vayatis", "Nicolas"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Snap datasets: Stanford large network dataset collection",
    "authors": ["Leskovec", "Jure", "A. Krevl"],
    "venue": "URL http://snap. stanford.edu/data",
    "year": 2014
  }, {
    "title": "Realistic, mathematically tractable graph generation and evolution, using kronecker multiplication",
    "authors": ["Leskovec", "Jure", "D Chakrabarti", "Kleinberg", "Jon", "Faloutsos", "Christos"],
    "venue": "In PKDD 2005,",
    "year": 2005
  }, {
    "title": "The link prediction problem for social networks",
    "authors": ["Liben-Nowell", "David", "Kleinberg", "Jon M"],
    "venue": "In Proceedings of the 2003 ACM CIKM International Conference on Information and Knowledge Management,",
    "year": 2003
  }, {
    "title": "Birds of a feather: Homophily in social networks",
    "authors": ["McPherson", "Miller", "Smith-Lovin", "Lynn", "Cook", "James M"],
    "venue": "Annual Review of Sociology,",
    "year": 2001
  }, {
    "title": "Learnability of influence in networks",
    "authors": ["Narasimhan", "Harikrishna", "Parkes", "David C", "Singer", "Yaron"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Learning the graph of epidemic cascades",
    "authors": ["Netrapalli", "Praneeth", "Sanghavi", "Sujay"],
    "venue": "In SIGMETRICS,",
    "year": 2012
  }, {
    "title": "Prediction of information diffusion probabilities for independent cascade model",
    "authors": ["Saito", "Kazumi", "Nakano", "Ryohei", "Kimura", "Masahiro"],
    "venue": "In International Conference on Knowledge-Based and Intelligent Information and Engineering Systems,",
    "year": 2008
  }, {
    "title": "Understanding machine learning: From theory to algorithms",
    "authors": ["Shalev-Shwartz", "Shai", "Ben-David"],
    "year": 2014
  }, {
    "title": "Detecting large reshare cascades in social networks",
    "authors": ["Subbian", "Karthik", "Prakash", "B Aditya", "Adamic", "Lada"],
    "venue": "In Proceedings of the 26th International Conference on World Wide Web,",
    "year": 2017
  }, {
    "title": "Diffusion independent semibandit influence maximization",
    "authors": ["Vaswani", "Sharan", "Kveton", "Branislav", "Wen", "Zheng", "Ghavamzadeh", "Mohammad", "Lakshmanan", "Laks V. S", "Schmidt", "Mark"],
    "venue": "In arXiv preprint, pp",
    "year": 2017
  }, {
    "title": "Efficient learning in large-scale combinatorial semi-bandits",
    "authors": ["Wen", "Zheng", "Kveton", "Branislav", "Ashkan", "Azin"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2015
  }],
  "id": "SP:1363cc4630aab752c1d7dfea51579d310e2c0935",
  "authors": [{
    "name": "Dimitris Kalimeris",
    "affiliations": []
  }, {
    "name": "Yaron Singer",
    "affiliations": []
  }, {
    "name": "Karthik Subbian",
    "affiliations": []
  }, {
    "name": "Udi Weinsberg",
    "affiliations": []
  }],
  "abstractText": "In this paper we advocate for a hyperparametric approach to learn diffusion in the independent cascade (IC) model. The sample complexity of this model is a function of the number of edges in the network and consequently learning becomes infeasible when the network is large. We study a natural restriction of the hypothesis class using additional information available in order to dramatically reduce the sample complexity of the learning process. In particular we assume that diffusion probabilities can be described as a function of a global hyperparameter and features of the individuals in the network. One of the main challenges with this approach is that training a model reduces to optimizing a non-convex objective. Despite this obstacle, we can shrink the best-known sample complexity bound for learning IC by a factor of |E|/d where |E| is the number of edges in the graph and d is the dimension of the hyperparameter. We show that under mild assumptions about the distribution generating the samples one can provably train a model with low generalization error. Finally, we use large-scale diffusion data from Facebook to show that a hyperparametric model using approximately 20 features per node achieves remarkably high accuracy.",
  "title": "Learning Diffusion using Hyperparameters"
}