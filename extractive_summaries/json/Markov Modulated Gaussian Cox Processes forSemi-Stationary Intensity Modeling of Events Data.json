{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Accurately modeling the underlying generative process of complex events is an important problem in statistical machine leaning and many related areas. Although events could be spatial and/or high-dimensional, in this paper we exclusively focus on event modeling in the temporal setup due to its dominance in real-world applications. The Poisson process is a de facto standard for its simplicity in mathematical analysis and flexibility in representing the intensity function (i.e., the event occurring rate) λ(t). Unlike traditional treatments via adopting a fixed parametric form of λ(t) (e.g., piecewise constant or the Weibull), several extensions have been introduced. The nonparametric modeling of λ(t) (e.g., the recent RKHS formulation (Flaxman et al., 2017)) can\n1Seoul National University of Science & Technology, Korea 2Rutgers University, Piscataway, NJ, USA. Correspondence to: Minyoung Kim <mikim21@gmail.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nreduce the burden of deciding an appropriate form of λ(t). Another is to regard λ(t) as a random process, known as the Cox process (Cox, 1955), which is useful for accounting for uncertainty in the intensity function.\nIn this paper, we are particularly interested in the Cox process where two most popular ones are: the Markov modulated Poisson process (MMPP) and the Gaussian process modulated Cox process (GPCox). Popular in statistics, the MMPP considers λ(t) as a random sample (trajectory) from a continuous-time Markov chain. The model has a finite set of intensity levels where the latent state at each time determines which intensity level is used at that moment. The GPCox is a nonparametric Bayesian model formed by placing a Gaussian process (GP) prior on λ(t). The GPCox has received significant attention in the machine learning community for the last decade for its flexible nonparametric modeling with principled uncertainty treatment.\nThe MMPP is good at modeling highly different intensity phases: bursty events for some intervals and rare events for others. However, there can be abrupt intensity changes between these regimes which may be unnatural in certain situations. Furthermore, for the interval under a given latent state, the model follows a constant intensity (i.e., a homogeneous process), which may limit its representational capacity. On the other hand, the GPCox encourages smooth intensity changes over time. However, the disadvantage is that the drastic intensity changes are not properly dealt with unless a highly non-smooth kernel is adopted, which can usually happen when a large amount of data is available.\nSo the main idea in this paper is to devise a novel model that takes benefits from both models. Similar to the MMPP, we consider an underlying continuous-time Markov chain (CTMC) that generates a latent state trajectory (taking say, r different states). We incorporate r latent functions with their own GP priors, each of which serves as the intensity responsible for each of the r states. This model is thus able to model major intensity regime (possibly abrupt) changes via the CTMC dynamics, and at the same time, it also enjoys the GP’s smooth intensity modeling, non-constant within the interval under a given latent state. Our model, referred to as the Markov modulated Gaussian Cox Process (MMGCP), has richer representational power than previous two models.\nIndeed, it subsumes both models as special cases: i) if the GP priors put all their masses to constant functions, then we end up with the MMPP, and ii) if r = 1 (single-state), then the model reduces to the GPCox.\nIn terms of time-stationarity1, the previous two models exhibit extreme characteristics. The MMPP makes λ(t) fully stationary (i.e., time independent) since the CTMC is stationary and the intensity under a given state is a constant, invariant of t. On the other hand, the GPCox builds a fully non-stationary (time-variant) λ(t) on top of the kernel function defined over t. Our MMGCP somehow aims to model a so-called semi-stationary intensity function in that the macro-scale intensity regime change is governed by the stationary CTMC dynamics, while within each regime, the intensity is modeled as a smooth time-variant function. In this sense, an ideal scenario for our model is as follows: there are r underlying candidate intensity functions {λi(t)}ri=1 where at a given time t, which of these candidates is active is determined by the stationary r-state Markov process X(t), that is, λX(t)(t). Our model further imposes the GP prior on these candidate functions to account for uncertainty and grant more modeling flexibility. In the evaluations, we not only implement this scenario as a synthetic setup, but we also demonstrate on some real datasets that our MMGCP significantly outperforms the previous models.\nWe provide an efficient variational inference for the model which is also analytic by adopting the squared link function for the intensity, similar to that of (Lloyd et al., 2015). However, the posterior expectation over the latent state trajectory required in the variational inference, is carefully analyzed within our model to derive closed-form formulas. The paper is organized as follows. After briefly discussing some background and reviewing previous two models in Sec. 2, our model is introduced in Sec. 3 with the variational inference fully described in Sec. 4. The empirical evaluation on some synthetic and real-world event datasets follows in Sec. 5."
  }, {
    "heading": "2. Background",
    "text": "We are interested in modeling events that can occur over the fixed time horizon [0, T ]. We basically assume that the events are generated by the (inhomogeneous) Poisson process, which is fully specified by the non-negative intensity function λ : [0, T ]→ R+. It defines the event occurring rate (i.e., the probability of event occurring during the infinitesimal interval [t, t+dt) is λ(t)dt). Then the log-likelihood of observing the event data D = {t1, . . . , tN} (⊂ [0, T ]) can\n1For clarity, the term stationarity is used in the following sense: if there is no time dependency in the data generating model (eg, MMPP), we say that it is stationary; if the data generation process is solely dependent on the time index (eg, a non-constant deterministic intensity function), then it is non-stationary. As our model contains both components, we call it semi-stationary.\nbe written as:\nlogP (D|λ(·)) = N∑\nn=1\nlog λ(tn)− ∫ T\n0\nλ(t) dt. (1)\nIt is common in statistics to assume a specific parametric form for λ(t), then estimate it by the maximum likelihood criterion with (1). Instead, the Cox process further regards λ(t) as a random process. Two most popular ones are briefly described below."
  }, {
    "heading": "2.1. Markov Modulated Poisson Process (MMPP)",
    "text": "This model basically forms piecewise constant λ(t). Specifically there are r constant intensity levels {λ1, . . . , λr}, but which level is used at a given moment is determined by the latent Markov process X : [0, T ] → {1, . . . , r} governed by a continuous-time Markov chain (CTMC). An r-state CTMC is specified by the initial state probability πi = P (X(0) = i) for i = 1, . . . , r, and the transition rate matrix Q whose off-diagonal Qij (i 6= j) defines the probability rate of state change from i to j, namely\nQij = lim ∆t→0 P (X(t+ ∆t) = j|X(t) = i) ∆t . (2)\nDefining diagonal entries as Qii := − ∑\nj 6=iQij lets the probability of staying at state i for duration h be ehQii . Note that the model has no time-variant component, thus adequate for modeling stationary event data. There are well-known EM learning algorithms (Asmussen et al., 1996; Ryden, 1996) for estimating the parameters of the model."
  }, {
    "heading": "2.2. Gaussian Cox Process (GPCox)",
    "text": "The GPCox model has a latent function f(t) distributed by a Gaussian process a priori, which determines the intensity function as λ(t) = ρ(f(t)) where ρ(·) is a non-negative link function, for instance, sigmoid, exponential or square function. The posterior inference P (f(·)|D) is challenging mainly due to the integration in the likelihood function (1). Let alone the computational overhead of evaluating the integral, one has to deal with latent function values at all inputs t ∈ [0, T ], not just those tn’s in the data D as in most conventional GP models (Rasmussen & Williams, 2006). Accordingly some previous approaches had to resort to discretizing the time domain (Rathbun & Cressie, 1994; Møller et al., 1998; Cunningham et al., 2008).\nRecently, several sophisticated inference methods have been proposed to address this difficulty. (Adams et al., 2009) formed a tractable MCMC dynamics by exploiting the idea of thinning-based sampling in the Poisson process. However, its time complexity is cubic in the data size, which is often prohibitive for large-scale problems. To deal with the scalability, (Gunter et al., 2014) proposed an alternative\nthinning strategy by sampling from a non-uniform intensity process, while (Samo & Roberts, 2015) introduced inducing points within the MCMC sampler. (Lasko, 2014) used a positively transformed intensity function for direct numerical integration and interpolation. In parallel, (Lloyd et al., 2015) derived analytic formulation for the scalable variational inference using the square link function and the pseudo input treatment (Titsias, 2009; Dezfouli & Bonilla, 2015)."
  }, {
    "heading": "3. Markov Modulated Gaussian Cox Process",
    "text": "In this section we describe our model that can take benefits from previous models in Sec. 2. We consider that there are r underlying latent functions devoted for representing different characteristics of the intensity function. Denoted by f(·) := {f i(·)}ri=1, they are assumed to be independently GP distributed a priori. That is,\nP (f(·)) = P (f1(·), . . . , fr(·)) = r∏\ni=1\nP (f i(·)) (3)\nwhere f i(·) ∼ GP ( mi(·), ki(·, ·) ) , i = 1, . . . , r.\nTo determine which of these r functions is responsible for the intensity at each time, we introduce a latent Markov process X(t), similarly as the MMPP, generated from a r-state CTMC (Q, π). The intensity at time t is then determined by fX(t), and we use the square link function similarly as (Lloyd et al., 2015), which leads to:\nλ(t) | f(·), X(·) = (fX(t))2. (4)\nThe full joint distribution of the model can be written as:\nP (D, X(·), f(·)|Θ,Ω) = (5) P (f(·)|Θ)× P (X(·)|Ω)× P (D|X(·), f(·)),\nwhere Θ = {θm,θk} is the parameters of the mean and covariance functions of the prior GP (e.g., θk = {θik}ri=1 with θik denoting the parameters of the covariance function ki(·, ·) for f i(·)). The CTMC parameters are denoted by Ω = {Q, π}. Thus Θ and Ω constitute the model parameters of the MMGCP. The last two terms in the RHS of (5) correspond to the likelihood of the state trajectory under the CTMC and the data likelihood given the state trajectory and the latent functions. To formally derive these likelihoods, it is convenient to partition the horizon [0, T ] according to a realized state trajectory X(·). Suppose that a realization X(·) undergoes (L − 1) state changes during [0, T ]. We denote by ul the time epoch when the l-th state change occurs (l = 1, . . . , L − 1) with u0 = 0 and uL = T for convenience. We let sl ∈ {1, . . . , r} be the state during the interval [ul−1, ul), and ∆ul be the length of the interval (i.e., ∆ul = ul − ul−1). Note that these variables {ul, sl,∆ul}l are determined by the realization X(·), and vice versa, in a one-to-one manner.\nLooking into the likelihood of X restricted to each interval (ul−1, ul], it is composed of two steps: i) no state change during (ul−1, ul) and ii) state change from sl to sl+1 right at the moment ul. For the last interval (l = L), it only involves the step i). From the well-known theorems of the CTMC2, the probability of the first step is exp(∆ulQslsl), while the likelihood of the second step is Qslsl+1 . Combining these over l = 1, . . . , L and including the initial state probability P (X(0) = s1) = πs1 , we have the likelihood of the state trajectory as follows.\nP (X(·)|Ω) = πs1 × L∏\nl=1 e∆ulQslsl × L−1∏ l=1 Qslsl+1 . (6)\nTo derive the likelihood of observingD given X(·) and f(·), we let {tl1, . . . , tlkl} be the event times in D that fall into the interval Il := [ul−1, ul). Within Il, the intensity is fixed as λsl(t) := (fsl(t))2, and applying the Poisson process likelihood gives: λsl(tl1) · · ·λsl(tlkl) exp(− ∫ Il λ\nsl(t)dt). Multiplying them over l = 1, . . . , L yields:\nP (D|X, f) = ∏\n1≤l≤L, n:tn∈Il\n(fsl(tn)) 2 × e−\n∫ Il (fsl (t))2dt . (7)"
  }, {
    "heading": "4. Variational Inference and Learning",
    "text": "In this section we provide inference for the posterior distribution in our MMGCP model, specifically\nP (X(·), f(·)|D,Θ,Ω). (8)\nThis inference is analytically intractable, however, we do it approximately using the recent scalable variational inference technique3 (Titsias, 2009; Dezfouli & Bonilla, 2015; Lloyd et al., 2015; Matthews et al., 2016). It is based on the pseudo inputs which especially plays a crucial role of making inference tractable even if one has to deal with function values for all inputs t ∈ [0, T ]. So we begin with the introduction of our GP notations regarding pseudo inputs.\nWe often use the superscript for indicating a specific function among the r latent functions, while the subscript for a specific time epoch or a set of time epochs at which the functions are evaluated. For instance, for a set of p inputs T = {t̃1, . . . , t̃p} ⊂ [0, T ], we denote by f iT = [f i(t̃1), . . . , f i(t̃p)] >, the p-dim vector of the i-th function\n2The full derivation can be found in standard textbooks on Markov chains or stochastic ODEs such as (Anderson, 2011). We also provide some brief derivations in Appendix A in the supplemental materials.\n3We specifically follow the variational free energy approach. But we would like to note that there exist other approximation techniques where the readers are encouraged to refer to the recent work on comparison of different approaches (Bauer et al., 2016) and some unified view (Bui et al., 2017).\nvalues. The boldfaced fT indicates the collection of the function values for all r functions, that is, fT = {f1T , . . . , frT }. For the GP prior mean and covariance functions (3), we follow the similar convention: miT = [m i(t̃1), . . . ,m i(t̃p)] > is the p-dim vector of the i-th mean function values on T . For two input sets T and S, KiT ,S denotes the (|T | × |S|) kernel matrix by applying ki(·, ·) on (T × S).\nFor each i-th GP (i = 1, . . . , r), we assume that there areMi ( N ) pseudo inputs denoted by Zi = {zi1, . . . , ziMi} ⊂ [0, T ]. We also let Z = ⋃r i=1Zi. These pseudo inputs can be thought of as representative points in that knowing the function values at Z has significant impacts on inferring function values at the other input points. But further insights can be found in the nice survey (Quiñonero-Candela & Rasmussen, 2005). The pseudo inputs can also be learned from data along with the model parameters, but for the time being we assume that they are fixed4.\nWe denote the whole state trajectory and the function values of all r latent functions for the entire set [0, T ] as (infinite dimensional) X and f , respectively. We define a tractable form of the variational density q(X, f), and optimize it to approximate the true posterior (8) as much as possible. In defining q(·), we impose independence betweenX and f for computational tractability. First, we let the posterior distribution of X follows a CTMC, which allows analytic derivations feasible as will be shown below. Also the posterior of the latent functions f are assumed to be Gaussians factorized over i = 1, . . . , r. Furthermore, we force the conditional density q(f |fZ) to coincide with the prior P (f |fZ) exactly, which is crucial to have some difficult terms canceled out in the KL divergence objective, making the inference scalable (Titsias, 2009; Lloyd et al., 2015). In summary, our variational density is defined as:\nq(X, f) = q(X;C,α)× ∫ q(fZ)P (f |fZ) dfZ (9)\nwhere C is the (r × r) transition rate matrix and α is the (1× r) initial state probabilities for the CTMC q(X). Also,\nq(fZ) = r∏ i=1 N (f iZi ;µ i,Σi). (10)\nHere µi is theMi-dim mean vector and Σi is the (Mi×Mi) covariance matrix. The variational parameters are denoted as Λ := (C,α,µ := {µi}ri=1,Σ := {Σi}ri=1).\nWe aim to minimize the KL divergence between q(·) and the posterior (8), which can be written as:\nKL ( q(X, f)||P (X, f |D) ) = logP (D)− ELBO(Θ,Ω,Λ), (11) where the ELBO (evidence lower-bound) is defined as:\nELBO(Θ,Ω,Λ) = Eq(X,f) [ logP (D|X, f) ] −\nKL ( q(X)||P (X) ) − KL ( q(fZ)||P (fZ) ) . (12)\n4We often use the uniformly sampled points from [0, T ].\nFrom (11) and the fact that KL divergence is non-negative, the ELBO is the lower bound of the log-evidence, namely\nlogP (D|Θ,Ω) ≥ ELBO(Θ,Ω,Λ). (13)\nNote that the bounding gap in (13) is exactly the KL divergence between q(·) and the posterior. Thus increasing ELBO(Θ,Ω,Λ) wrt Λ leads to a better variational density (closer to the posterior), whereas increasing it wrt the model parameters (Θ,Ω) can potentially5 improve the data evidence score of the model. Hence, maximizing the ELBO wrt all the parameters can achieve both variational inference (i.e., q(·) optimization) and model selection (i.e, learning prior model parameters) simultaneously.\nIn what follows, we provide full derivations for evaluating each term comprising (12). The gradients are also required for the optimization of the ELBO, and can be found in Appendix C in the supplemental material. 4.1. KL ( q(fZ)||P (fZ)\n) It is not difficult to see that due to the fully factorized q(fZ) and P (fZ) over individual latent functions i = 1, . . . , r, the KL divergence is the sum of the individual Gaussian KL divergences. More specifically,\nKL ( q(fZ)||P (fZ) ) =\nr∑ i=1 1 2\n[ log ∣∣KiZi,Zi∣∣∣∣Σi∣∣ −Mi + Tr((KiZi,Zi)−1Σi) + (µi −miZi) >(KiZi,Zi)−1(µi −miZi) ] (14)\nThe gradients with respect to the related parameters are derived in Appendix C.1. 4.2. KL ( q(X)||P (X)\n) This term involves computing the expectations of the loglikelihoods of the CTMC models (both the prior logP (X) and the variational posterior log q(X)) with respect to q(X). We describe how to compute Eq(X)[P (X)] analytically (Eq(X)[q(X)] done similarly). For this purpose, we rephrase the CTMC likelihood in (6) using some total statistics from the realization X(·). With X(·) fixed, let nij be the number of transitions from state i to j where j 6= i, and ∆i be the sojourn time at state i, that is, ∆i = ∑ l:sl=i\n∆ul. Note that (nij ,∆i) are the functions ofX(·). Then we have:\nlogP (X) = (15) r∑\ni=1\n( I{X(0)=i} log πi + ∆iQii + ∑ j 6=i nij logQij ) ,\n5However, this does not guarantee to improve the evidence logP (D) since the inequality (13) is not tight.\nwhere I{p} is 1 (0) if the predicate p is true (false).\nThus the expectation of (15) requires: Eq[nij ] and Eq[∆i]. For the latter, we first note that ∆i = ∫ T 0 I{X(t)=i}dt. Using q(X(t) = i) = [αetC ]i from the CTMC theorems (see (4) in Appendix A), we have:\nEq(X)[∆i] = [αJC ]i, (16) where JC = ∫ T 0 etCdt, is the (r × r) matrix by integrating the matrix exponential over [0, T ], and [v]i indicates the i-th element of the vector v. As the number of transitions nij = ∫ T 0 I{X(t)=i AND X(t+dt)=j}, and using q(X(t) = i,X(t+ dt) = j) = [αetC ]iCijdt ((5) in Appendix A),\nEq(X)[nij ] = [αJC ]iCij . (17)\nBy applying these to (15), we finally have: KL ( q(X)||P (X) ) = r∑ i=1\n{ αi log\nαi πi + (18)\n[αJC ]i ( Cii −Qii + ∑ j 6=i Cij log Cij Qij )} .\nThe remaining thing is how to compute JC . It can be done analytically once the matrix C is diagonalized. The details are found in Appendix B of the supplemental material. Since r is usually small (e.g., 2 or 3), diagonalization must not incur any computational or numerical issues. When we compute the gradients of (18) with respect to C, special techniques of taking derivatives of matrix exponentials such as (Kalbfleisch & Lawless, 1985) can be used. The technical details are described in Appendix B and Appendix C.2. 4.3. Eq(X,f) [ logP (D|X, f) ]\nThis is the conditional log-likelihood given the state trajectory and the latent functions, expected with respect to the variational posterior q(X, f). From (7), after slight rephrasing, the conditional log-likelihood can be written as:\nlogP (D|X, f) = r∑\ni=1 N∑ n=1 I{X(tn)=i} log (f i(tn)) 2\n− r∑\ni=1\n∫ T 0 I{X(t)=i}(f i(t))2dt. (19)\nExploiting the factorization q(X, f) = q(X)q(f), we take the expectation of (19) wrt q(X) first, followed by q(f). Using q(X(t) = i) = [αetC ]i from the previous section, Eq(X,f) [ logP (D|X, f) ] =\nr∑ i=1 ( ELLi − ENOi ) where (20)\nELLi = N∑\nn=1\n[αetnC ]iEq(fi(tn)) [ log (f i(tn)) 2 ] , (21)\nENOi = ∫ T\n0\n[αetC ]iEq(fi(t)) [ (f i(t))2 ] dt. (22)\nNote that (21) and (22) are very similar to those in the variational inference of the GPCox model proposed in (Lloyd et al., 2015). However, we have the weighted expected log-likelihood by the weights [αetC ]i over i = 1, . . . , r, determined by the latent state posterior probabilities q(X(t)). Computing these weights for each t can be done analytically when we have a diagonalization ofC (See Appendix B in the supplemental material). The expectations in (21) and (22) are with respect to Gaussians, more specifically, q(f i(t))) =∫ q(f iZi)P (f i(t)|f iZi)df i Zi = N (µ̃i(t), σ̃ 2 i (t)) where\nµ̃i(t) = m i(t) +Kit,Zi(K i Zi,Zi) −1(µi −miZi), (23) σ̃2i (t) = K i t,t −Kit,Zi(K i Zi,Zi) −1KiZi,t +\nKit,Zi(K i Zi,Zi) −1Σi(KiZi,Zi) −1KiZi,t. (24)\nThen the expectation in (22) equals (µ̃i(t))2 + σ̃2i (t), which allows us to compute the integral analytically for a certain kernel form (e.g., squared exponential or polynomial kernel) as shown in (Lloyd et al., 2015). With the additional weight term [αetC ]i multiplied to the integrand in our model, by rewriting the weight as a sum of scalar exponentials after diagonalization of C, we can still derive a closed-form expression for ENOi. However, it is highly complicated, which becomes even worse when evaluating its gradients (e.g., wrt C). For the expectation of the log-squared term of ELLi in (21), some confluent hyper-geometric function was adopted in (Lloyd et al., 2015), however, it is either numerically unstable or based on certain interpolation.\nInstead, we employ fairly straightforward strategies for computing ELLi and ENOi. First, the expectation of the logsquared term in (21) is done by the Monte-Carlo estimation. This must not incur much computational overhead since it is univariate sampling. Considering that we have to take derivatives of ELLi wrt the parameters related to q(f i(tn)), we also adopt the re-parametrized Gaussian sampling technique as suggested in (Kingma & Welling, 2014). The idea is to express the random samples from q(f i(tn)), denoted by f in (s) for s = 1, . . . , S, as:\nf in (s) = µ̃i(tn)+(σ̃ 2 i (tn)) 1/2 (s) in ,\n(s) in ∼ N (0, 1). (25)\nAfter sampling (s)in , we fix them, and ELLi is estimated as:\nN∑ n=1 [αetnC ]i S S∑ s=1 log ( µ̃i(tn) + (σ̃ 2 i (tn)) 1/2 (s) in )2 . (26)\nAs it separates randomness ( (s)in ) from the parameters, the gradient of (26) can be computed straightforwardly while yielding an unbiased estimate of the gradient of the original (21). See Appendix C.3 for the full derivations. Furthermore, to reduce the variance of the estimate, one can use the Rao-Blackwellization technique (Casella & Robert, 1996).\nFor the integration in (22), we do this numerically by uniform grid sampling. Specifically, by having G uniform grid points {t̃g}Gg=1 over [0, T ] with ∆t = t̃g+1 − t̃g , we define the following statistics:\nΨi0 = G∑ g=1 wigK i Zi,t̃gK i t̃g,Zi , Ψ i 1 = G∑ g=1 wigm i(t̃g)K i t̃g,Zi ,\nΨi2 = G∑ g=1 wig(m i(t̃g)) 2, Ψi3 = G∑ g=1 wigK i t̃g,t̃g , (27)\nwhere wig = [αe t̃gC ]i∆t. We then numerically compute ENOi as:\n(µi −miZi) >(KiZi,Zi) −1Ψi0(K i Zi,Zi) −1(µi −miZi) + + 2Ψi1(K i Zi,Zi) −1(µi −miZi)− Tr ( (KiZi,Zi) −1Ψi0 )\n+ Tr ( (KiZi,Zi) −1Σi(KiZi,Zi) −1Ψi0 ) + Ψi2 + Ψ i 3. (28)\nIn this way the gradient of ENOi can be derived fairly easily, which is summarized in Appendix C.3.\nWhen the optimization is done by first-order gradient methods, the computational complexity of the variational inference for our model is no more than r (the number of latent GP functions) times that of the variational inference of the GPCox as in (Lloyd et al., 2015), which can be seen as a special MMGCP model with r = 1."
  }, {
    "heading": "4.4. Model Selection and Test Prediction",
    "text": "We discuss how to determine the optimal value of r. The ELBO objective, the lower bound of the data log-likelihood, tends to increase as we increase r since models with higher r naturally subsume those with lower. However, it would incur higher chance of overfitting and worse generalization on unseen test data. We need to trade off between the model complexity and the goodness of data fitting, and along this line one can employ certain information criteria such as the Bayesian criterion (Schwarz, 1978). When specifying the model complexity, we take into consideration all related parameters as well as the inducing points. Alternatively, we can choose r by cross validation, measuring performance on a validation set, randomly held-out portion of the training data. Once the model and the variational parameters are learned, we can estimate the predictive likelihood for an unseen test dataD∗. We see that the predictive log-likelihood, logP (D∗|D,Θ,Ω) is lower-bounded by Eq(X,f) [ logP (D∗|X, f ,Θ,Ω) ] , which can be computed by the exactly same procedures as in Sec. 4.3 with D∗."
  }, {
    "heading": "5. Evaluations",
    "text": "In this section we demonstrate the performance of the proposed MMGCP model. We mainly compare our model with two existing extreme stationarity models, MMPP and\nGPCox, since our model is motivated from both. For the GPCox, among several inference strategies, we opt for the latest variational inference method proposed in (Lloyd et al., 2015), which exhibits comparable generalization performance to other approaches while being significantly faster than sampling-based methods such as (Adams et al., 2009). As a baseline, we also consider: i) the classical kernel smoothing (KS) approach (Diggle, 1985), specifically the Gaussian kernel density estimator, and ii) the log Gaussian Cox process (LGCP) (Rathbun & Cressie, 1994; Møller et al., 1998), which approximates the problem as a standard GP inference with Poisson-likelihood iid data via event counting through discretization of the time horizon."
  }, {
    "heading": "5.1. Synthetic data",
    "text": "To demonstrate the effectiveness of the proposed MMGCP model, we devise three different synthetic data setups that exhibit highly different aspects in terms of time stationarity.\nThe first setup simulates a fully stationary scenario (denoted by Full-Stn), where we generate data from a r = 3- state MMPP model with highly different intensity levels {1.0, 4.0, 8.0}. Within the time horizon T = 50, we generate 10 event sequences from the model (Fig. 1 for two exemplar sequences), from which we randomly take 5 sequences as training data while the rest as a test set. For the MMPP and our MMGCP models, we choose the model order by cross validation, which both correctly recovered r = 3 hidden states. For the GPCox and our model, we use the squared exponential kernels, and the variational inference in both models uses the same M = 10 pseudo inputs (also the same across i = 1, . . . , r for the MMGCP).\nThe average test log-likelihoods are shown in Table 1(A). As expected, the MMPP model attains the best performance since the model structure exactly matches that of the data generating one. Our MMGCP, although a generalization of MMPP, performs worse than the MMPP due to the use of smooth kernels. However, the MMGCP significantly outperforms the GPCox and other non-stationary models. The figures in the parentheses indicate the p-values from the paired sample t-test for the competing models against our MMGCP. Thus the differences between existing models and ours are all statistically significant (p-values less than 0.05).\nThe second synthetic dataset represents fully non-stationary intensity setup (denoted by Non-Stn). From (Adams et al., 2009) we take λ(t) = 2 exp(−t/15) + exp(−((t − 25)/10)2) as the true (deterministic) intensity function over [0, 50], and generate data from the inhomogeneous Poisson process. See Fig. 2 for the true intensity function and a sample event sequence. With the similar experimental setups as the first dataset, we run the five models and report the test scores in Table 1(B). The MMPP, with r = 3 hidden states chosen, now underperforms the non-stationary time-dependent intensity modeling methods with statistical significance. The GPCox and our MMGCP perform comparably well. The MMGCP selects r = 2 hidden states by the cross validation although r = 1 (i.e., GPCox) yields a slightly smaller but very close validation score than that of r = 2. This implies that the smooth intensity change is properly represented by the covariance functions of the Gaussian processes.\nIn this Non-Stn dataset, since we have the true intensity function available, we can measure the distance between\nthe estimated (expected) intensity functions and the true one. We use the L2 error defined as ∫ T 0\n(λtrue(t)−λ(t))2 dt, where λ(t) = E[λ(t)|D] is the posterior-expected intensity function. In our MMGCP model, as we have the posterior approximation q(X, f), using λ(t) ≈ Eq[(fX(t))2] we have:\nλ(t) ≈ r∑\ni=1\n[αetC ]i ( (µ̃i(t)) 2 + σ̃2i (t) ) . (29)\nThe L2 errors of the competing methods are reported in Table 2. See also Fig. 2 for the estimated intensity functions. Our MMGCP and the GPCox exhibit the best performance.\nFor the last synthetic setup, we aim to simulate the semistationary scenario (denoted by Semi-Stn). We consider two underlying candidate intensity functions as follows:\nλ1(t) = 2e−t/30 +G25(t) + 2G50(t) + 3.5G85(t) + 4\n3 ,\nλ2(t) = 1\n3 (1.8 sin(0.005t2) + 2), (30)\nwhere Ga(t) = e−((t−a)/10) 2\n. As shown in Fig. 3, they exhibit highly different patterns and levels from each other. We also incorporate a 2-state CTMC so that which of the two candidate functions is active at each moment is determined stochastically by the latent Markov process. We generate event sequences over the horizon T = 100 from the model.\nWe follow the experimental setup similar to the previous two datasets. The test log-likelihood scores of the compet-\ning approaches are summarized in Table 1(C). In this case, our MMGCP is outstanding for this semi-stationary data. The superiority of the MMGCP to competing methods is statistically significant whereas the fully stationary MMPP and the time-dependent inhomogeneous models like GPCox and kernel smoother suffer from the heterogeneity of data: globally undergoing stationary regime switching but being time-dependent within each regime.\nOverall, our MMGCP is viable consistently across all different time stationarity setups, ranging from fully stationary to non-stationary as well as semi-stationary in between. In the following sections, we also demonstrate the effectiveness of our model on some real-world event datasets."
  }, {
    "heading": "5.2. Football Data",
    "text": "We test on the football events dataset6 from the Kaggle open data platform. There are 9074 football games as a whole collected from major European leagues for 5 years (from 2011/12 season to 2016/17). For each game, the major events (e.g., shot attempts, goals, corners, fouls, etc.) are marked in the minute scale. The types and times of the events are obtained from various sources, mainly text commentary and web scraping.\nFrom the dataset, we consider the events of shot attempts only, and focus on those games which contain 30 or more events, which comprise about 2000 games. Each game is represented as a sequence of events, and we regard each sequence as an iid sample from an unknown process within the horizon [0, T ] with T = 90+αminutes where α amounts to the random extra time which is usually less than 5 (minutes). The average number of events per sequence is 33.4 with standard deviation 3.4.\nAmong these sequences, we randomly select 500 sequences for training and 100 as a test set. The test likelihood scores are summarized in Table 3(A). It shows that the proposed MMGCP outperforms the competing models with statistical significance (the p-values with regard to our MMGCP are all\n6https://www.kaggle.com/secareanualin/football-events\nless than 10−4). The improvement achieved by the proposed approach can be attributed to the semi-stationary nature of the data in some sense: the event rates can be time dependent in certain regimes (e.g., there are often more active attack attempts during the beginning/end of the game or the half time than in the middle of the game), but overall intensities tend to be stationary, exhibiting highly different aspects from game to game."
  }, {
    "heading": "5.3. Italy’s Earthquakes Data",
    "text": "We next demonstrate the performance of the proposed approach on the daily earthquake data publicly available from the Kaggle open data platform. The dataset7 is obtained by real-time collections of the earthquake events from the Italian Earthquakes National Center, which contains earthquake records of various magnitudes that hit the center of Italy for three months, from August to November in 2016. As we are interested in the daily patterns, we group them on a daily basis, and regard the events for each day as an iid sequence sample. There are 99 (daily) event sequences for which we split them randomly into 60/39 training/test sets.\nWe consider all the events with the Richter magnitude no less than 2.0, where the magnitude 2.0 corresponds to earthquakes that are minor, but felt by some people. The number of events per sequence is highly varying across sequences: the mean is 81.7 and the standard deviation 107.5. We also scale the event times from the original data down to [0, 100]. The test results are shown in Table 3(B). The MMGCP again exhibits significantly better generalization capability than models based on the extreme time stationarity assumptions. Considering the complexity of the underlying event generating process for this data (e.g., time-sensitive factors as well as stationary changes of states), it signifies that the MMGCP’s added flexibility attained by combining inhomogeneous Poisson process with the latent regime switching to account for major trend changes, can be highly effective for representing a complex event process."
  }, {
    "heading": "6. Conclusion",
    "text": "In this paper we have proposed a novel Markov modulated Gaussian Cox process model that incorporates both the GP-based smooth intensity changes along with major regime switches through a hidden Markov process. While subsuming existing stationary and non-stationary Cox process models as special cases, the proposed model is especially suitable for representing semi-stationary event data. Through empirical evaluations on both synthetic and realworld datasets, we have demonstrated that the model is promising, yielding better generalization for complex event data modeling than existing approaches.\n7https://www.kaggle.com/blackecho/italy-earthquakes/data"
  }, {
    "heading": "Acknowledgements",
    "text": "This research is supported by National Research Foundation of Korea (NRF-2016R1A1A1A05921948). The author thanks Mark Schmidt for helpful discussions where part of this work was conducted when the author was at UBC."
  }],
  "year": 2018,
  "references": [{
    "title": "Tractable nonparametric Bayesian inference in Poisson processes with Gaussian process intensities",
    "authors": ["R.P. Adams", "I. Murray", "D.J. MacKay"],
    "venue": "International Conference on Machine Learning",
    "year": 2009
  }, {
    "title": "Continuous-Time Markov Chains: An Applications-Oriented",
    "authors": ["W.J. Anderson"],
    "year": 2011
  }, {
    "title": "Fitting phasetype distributions via the EM algorithm",
    "authors": ["S. Asmussen", "O. Nerman", "M. Olsson"],
    "venue": "Scandinavian Journal of Statistics,",
    "year": 1996
  }, {
    "title": "Understanding probabilistic sparse Gaussian process approximations, 2016",
    "authors": ["M. Bauer", "M. van der Wilk", "C.E. Rasmussen"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2016
  }, {
    "title": "A unifying framework for Gaussian process pseudo-point approximations using power expectation propagation",
    "authors": ["T.D. Bui", "J. Yan", "R.E. Turner"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Some statistical methods connected with series of events",
    "authors": ["D.R. Cox"],
    "venue": "Journal of the Royal Statistical Society, Series B,",
    "year": 1955
  }, {
    "title": "Fast Gaussian process methods for point process intensity",
    "authors": ["J.P. Cunningham", "K.V. Shenoy", "M. Sahani"],
    "venue": "International Conference on Machine Learning",
    "year": 2008
  }, {
    "title": "Scalable inference for Gaussian process models with black-box likelihoods",
    "authors": ["A. Dezfouli", "E.V. Bonilla"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "A kernel method for smoothing point process data",
    "authors": ["P. Diggle"],
    "venue": "Applied Statistics,",
    "year": 1985
  }, {
    "title": "Poisson intensity estimation with reproducing kernels, 2017",
    "authors": ["S. Flaxman", "Y.W. Teh", "D. Sejdinovic"],
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2017
  }, {
    "title": "Efficient Bayesian nonparametric modelling of structured point processes",
    "authors": ["T. Gunter", "C. Lloyd", "M.A. Osborne", "S.J. Roberts"],
    "year": 2014
  }, {
    "title": "The analysis of panel data under a Markov assumption",
    "authors": ["J.D. Kalbfleisch", "J.F. Lawless"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1985
  }, {
    "title": "Auto-encoding variational Bayes",
    "authors": ["D.P. Kingma", "M. Welling"],
    "venue": "In Proceedings of the Second International Conference on Learning Representations",
    "year": 2014
  }, {
    "title": "Efficient inference of Gaussian process modulated renewal processes with application to medical event",
    "authors": ["T.A. Lasko"],
    "year": 2014
  }, {
    "title": "Variational inference for Gaussian process modulated",
    "authors": ["C. Lloyd", "T. Gunter", "M.A. Osborne", "S.J. Roberts"],
    "venue": "Poisson processes,",
    "year": 2015
  }, {
    "title": "On sparse variational methods and the KullbackLeibler divergence between stochastic processes, 2016",
    "authors": ["A. Matthews", "J. Hensman", "R.E. Turner", "Z. Ghahramani"],
    "venue": "International Conference on Artificial Intelligence and Statistics",
    "year": 2016
  }, {
    "title": "A unifying view of sparse approximate Gaussian process regression",
    "authors": ["J. Quiñonero-Candela", "C.E. Rasmussen"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2005
  }, {
    "title": "Gaussian Processes for Machine Learning",
    "authors": ["C.E. Rasmussen", "C.K.I. Williams"],
    "year": 2006
  }, {
    "title": "Asymptotic properties of estimators for the parameters of spatial inhomogeneous Poisson point processes",
    "authors": ["S.L. Rathbun", "N. Cressie"],
    "venue": "Advances in Applied Probability,",
    "year": 1994
  }, {
    "title": "An EM algorithm for estimation in Markovmodulated Poisson processes",
    "authors": ["T. Ryden"],
    "venue": "Computational Statistics & Data Analysis,",
    "year": 1996
  }, {
    "title": "Scalable nonparametric Bayesian inference on point processes with",
    "authors": ["Samo", "Y.-L. K", "S. Roberts"],
    "venue": "Gaussian processes,",
    "year": 2015
  }, {
    "title": "Estimating the dimension of a model",
    "authors": ["G.E. Schwarz"],
    "venue": "Annals of Statistics,",
    "year": 1978
  }, {
    "title": "Variational learning of inducing variables in sparse Gaussian processes",
    "authors": ["M.K. Titsias"],
    "venue": "In Proceedings of the Twelfth International Conference on Artificial Intelligence and Statistics",
    "year": 2009
  }],
  "id": "SP:b32e664017a99d3b2aaaff5bfcb63bc5e156ee47",
  "authors": [{
    "name": "Minyoung Kim",
    "affiliations": []
  }],
  "abstractText": "The Cox process is a flexible event model that can account for uncertainty of the intensity function in the Poisson process. However, previous approaches make strong assumptions in terms of time stationarity, potentially failing to generalize when the data do not conform to the assumed stationarity conditions. In this paper we bring up two most popular Cox models representing two extremes, and propose a novel semi-stationary Cox process model that can take benefits from both models. Our model has a set of Gaussian process latent functions governed by a latent stationary Markov process where we provide analytic derivations for the variational inference. Empirical evaluations on several synthetic and real-world events data including the football shot attempts and daily earthquakes, demonstrate that the proposed model is promising, can yield improved generalization performance over existing approaches.",
  "title": "Markov Modulated Gaussian Cox Processes forSemi-Stationary Intensity Modeling of Events Data"
}