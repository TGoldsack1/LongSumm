{
  "sections": [{
    "text": "Proceedings of NAACL-HLT 2018, pages 37–46 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Human languages are far from arbitrary; crosslinguistically, they exhibit surprising similarity in many respects and many properties appear to be universally true. The field of linguistic typology seeks to investigate, describe and quantify the axes along which languages vary. One facet of language that has been the subject of heavy investigation is the nature of vowel inventories, i.e., which vowels a language contains. It is a cross-linguistic universal that all spoken languages have vowels (Gordon, 2016), and the underlying principles guiding vowel selection are understood: vowels must be both easily recognizable and well-dispersed (Schwartz et al., 2005). In this work, we offer a more formal treatment of the subject, deriving a generative probability model of vowel inventory typology. Our work builds on (Cotterell and Eisner, 2017) by investigating not just discrete IPA inventories but the cross-linguistic variation in acoustic formants.\nThe philosophy behind our approach is that linguistic typology should be treated probabilistically\nand its goal should be the construction of a universal prior over potential languages. A probabilistic approach does not rule out linguistic systems completely (as long as one’s theoretical formalism can describe them at all), but it can position phenomena on a scale from very common to very improbable. Probabilistic modeling also provides a discipline for drawing conclusions from sparse data. While we know of over 7000 human languages, we have some sort of linguistic analysis for only 2300 of them (Comrie et al., 2013), and the dataset used in this paper (Becker-Kristal, 2010) provides simple vowel data for fewer than 250 languages.\nFormants are the resonant frequencies of the human vocal tract during the production of speech sounds. We propose a Bayesian generative model of vowel inventories, where each language’s inventory is a finite subset of acoustic vowels represented as points (F1, F2) ∈ R2. We deploy tools from the neural-network and point-process literatures and experiment on a dataset with 233 distinct languages. We show that our most complicated model outperforms simpler models."
  }, {
    "heading": "2 Acoustic Phonetics and Formants",
    "text": "Much of human communication takes place through speech: one conversant emits a sound wave to be comprehended by a second. In this work, we consider the nature of the portions of such sound waves that correspond to vowels. We briefly review the relevant bits of acoustic phonetics so as to give an overview of the data we are actually modeling and develop our notation.\nThe anatomy of a sound wave. The sound wave that carries spoken language is a function from time to amplitude, describing sound pressure variation in the air. To distinguish vowels, it is helpful to transform this function into a spectrogram (Fig. 1) by using a short-time Fourier transform\n37\n0 Hz\n1000 Hz\n2000 Hz\n3000 Hz\n4000 Hz\n5000 Hz /i/ /u/ /ɑ/\nFigure 1: Example spectrogram of the three English vowels: /i/, /u/ and /A/. The x-axis is time and y-axis is frequency. The first two formants F1 and F2 are marked in with arrows for each vowel. The figure was made with Praat (Boersma et al., 2002).\n(Deng and O’Shaughnessy, 2003, Chapter 1) to decompose each short interval of the wave function into a weighted sum of sinusoidal waves of different frequencies (measured in Hz). At each interval, the variable darkness of the spectrogram indicates the weights of the different frequencies. In phonetic analysis, a common quantity to consider is a formant—a local maximum of the (smoothed) frequency spectrum. The fundamental frequency F0 determines the pitch of the sound. The formants F1 and F2 determine the quality of the vowel.\nTwo is all you need (and what we left out). In terms of vowel recognition, it is widely speculated that humans rely almost exclusively on the first two formants of the sound wave (Ladefoged, 2001, Chapter 5). The two-formant assumption breaks down in edge cases: e.g., the third formant F3 helps to distinguish the roundness of the vowel (Ladefoged, 2001, Chapter 5). Other non-formant features may also play a role. For example, in tonal languages, the same vowel may be realized with different tones (which are signaled using F0): Mandarin Chinese makes a distinction between mǎ (horse) and má (hemp) without modifying the quality of the vowel /a/. Other features, such as creaky voice, can play a role in distinguishing phonemes. We do not explicitly model any of these aspects of vowel space, limiting ourselves to (F1, F2) as in previous work (Liljencrants and Lindblom, 1972). However, it would be easy to extend all the models we will propose here to incorporate such information, given appropriate datasets."
  }, {
    "heading": "3 The Phonology of Vowel Systems",
    "text": "The vowel inventories of the world’s languages display clear structure and appear to obey several underlying principles. The most prevalent of these\nprinciples are focalization and dispersion.\nFocalization. The notion of focalization grew out of quantal vowel theory (Stevens, 1989). Quantal vowels are those that are phonetically “better” than others. They tend to display certain properties, e.g., the formants tend to be closer together (Stevens, 1987). Cross-linguistically, quantal vowels are the most frequently attested vowels, e.g., the cross-linguistically common vowel /i/ is considered quantal, but less common /y/ is not.\nDispersion. The second core principle of vowel system organization is known as dispersion. As the name would imply, the principle states that the vowels in “good” vowel systems tend to be spread out. The motivation for such a principle is clear—a well-dispersed set of vowels reduces a listener’s potential confusion over which vowel is being pronounced. See Schwartz et al. (1997) for a review of dispersion in vowel system typology and its interaction with focalization, which has led to the joint dispersion-focalization theory.\nNotation. We will denote the universal set of international phonetic alphabet (IPA) symbols as V . The observed vowel inventory for language ` has size n` and is denoted V ` = {(v`1,v`1), . . . , (v`n` ,v`n`)} ⊆ V × Rd, where for each k ∈ [1, n`], v`k ∈ V is an IPA symbol assigned by a linguist and v`k ∈ Rd is a vector of d measurable phonetic quantities. In short, the IPA symbol v`k was assigned as a label for a phoneme with pronunciation v`k. The ordering of the elements within V ` is arbitrary.\nGoals. This framework recognizes that the same IPA symbol v (such as /u/) may represent a slightly different sound v in one language than in another, although they are transcribed identically. We are specifically interested in how the vowels in a language influence one another’s fine-grained pronunciation in Rd. In general, there is no reason to suspect that speakers of two languages, whose phonological systems contain the same IPA symbol, should produce that vowel with identical formants.\nData. For the remainder of the paper, we will take d = 2 so that each v = (F1, F2) ∈ R2, the vector consisting of the first two formant values, as compiled from the field literature by BeckerKristal (2006). This dataset provides inventories V ` in the form above. Thus, we do not consider further variation of the vowel pronunciation that\nmay occur within the language (between speakers, between tokens of the vowel, or between earlier and later intervals within a token)."
  }, {
    "heading": "4 Phonemes versus Phones",
    "text": "Previous work (Cotterell and Eisner, 2017) has placed a distribution over discrete phonemes, ignoring the variation across languages in the pronunciation of each phoneme. In this paper, we crack open the phoneme abstraction, moving to a learned set of finer-grained phones.\nCotterell and Eisner (2017) proposed (among other options) using a determinantal point process (DPP) over a universal inventory V of 53 symbolic (IPA) vowels. A draw from such a DPP is a language-specific inventory of vowel phonemes, V ⊆ V . In this paper, we say that a language instead draws its inventory from a larger set V̄ , again using a DPP. In both cases, the reason to use a DPP is that it prefers relatively diverse inventories whose individual elements are relatively quantal.\nWhile we could in principle identify V̄ with Rd, for convenience we still take it to be a (large) discrete finite set V̄ = {v̄1, . . . , v̄N}, whose elements we call phones. V̄ is a learned cross-linguistic parameter of our model; thus, its elements—the “universal phones”—may or may not correspond to phonetic categories traditionally used by linguists.\nWe presume that language ` draws from the DPP a subset V̄ ` ⊆ V̄ , whose size we call n`. For each universal phone v̄i that appears in this inventory V̄ `, the language then draws an observable languagespecific pronunciation v`i ∼ N ( µi, σ 2I )\nfrom a distribution associated cross-linguistically with the universal phone v̄i. We now have an inventory of pronunciations.\nAs a final step in generating the vowel inventory, we could model IPA labels. For each v̄i ∈ V̄ `, a field linguist presumably draws the IPA label v`i conditioned on all the pronunciations {v`i ∈ Rd : v̄i ∈ V̄ `} in the inventory (and perhaps also on their underlying phones v̄i ∈ V̄ `). This labeling process may be complex. While each pronunciation in Rd (or each underlying phone in V̄) may have a preference for certain IPA labels in V , the n` labels must be drawn jointly because the linguist will take care not to use the same label for two phones, and also because the linguist may like to describe the inventory using a small number of distinct IPA features, which will tend to favor factorial grids of symbols. The linguist’s use of IPA\nfeatures may also be informed by phonological and phonetic processes in the language. We leave modeling of this step to future work; so our current likelihood term ignores the evidence contributed by the IPA labels in the dataset, considering only the pronunciations in Rd.\nThe overall idea is that human languages ` draw their inventories from some universal prior, which we are attempting to reconstruct. A caveat is that we will train our method by maximum-likelihood, which does not quantify our uncertainty about the reconstructed parameters. An additional caveat is that some languages in our dataset are related to one another, which belies the idea that they were drawn independently. Ideally, one ought to capture these relationships using hierarchical or evolutionary modeling techniques."
  }, {
    "heading": "5 Determinantal Point Processes",
    "text": "Before delving into our generative model, we briefly review technical background used by Cotterell and Eisner (2017). A DPP is a probability distribution over the subsets of a fixed ground set of size N—in our case, the set of phones V̄ . The DPP is usually given as an L-ensemble (Borodin and Rains, 2005), meaning that it is parameterized by a positive semi-definite matrix L ∈ RN×N . Given a discrete base set V̄ of phones, the probability of a subset V̄ ⊆ V̄ is given by\np(V̄ ) ∝ det (LV̄ ) , (1)\nwhere LV̄ is the submatrix of L corresponding to the rows and columns associated with the subset V̄ ⊆ V̄ . The entry Lij , where i 6= j, has the effect of describing the similarity between the elements v̄i and v̄j (both in V̄)—an ingredient needed to model dispersion. And, the entry Lii describes the quality—focalization—of the vowel v̄i, i.e., how much the model wants to have v̄i in a sampled set independent of the other members."
  }, {
    "heading": "5.1 Probability Kernel",
    "text": "In this work, each phone v̄i ∈ V̄ is associated with a probability density over the space of possible pronunciations R2. Our measure of phone similarity will consider the “overlap” between the densities associated with two phones. This works as follows: Given two densities f(x, y) and f ′(x, y) over R2, we define the kernel (Jebara et al., 2004) as\nK(f, f ′; ρ) = ∫\nx\n∫\ny f(x, y)ρf ′(x, y)ρdx dy, (3)\nwith inverse temperature parameter ρ. In our setting, f, f ′ will both be Gaussian distributions with means µ and µ′ that share a fixed spherical covariance matrix σ2I . Then eq. (3) and indeed its generalization to any Rd has a closedform solution (Jebara et al., 2004, §3.1):\nK(f,f ′; ρ) = (4)\n(2ρ) d 2 ( 2πσ2 ) (1−2ρ)d 2 exp ( −ρ||µ− µ\n′||2 4σ2\n) .\nNotice that making ρ small (i.e., high temperature) has an effect on (4) similar to scaling the variance σ2 by the temperature, but it also results in changing the scale of K, which affects the balance between dispersion and focalization in (6) below."
  }, {
    "heading": "5.2 Focalization Score",
    "text": "The probability kernel given in eq. (3) naturally handles the linguistic notion of dispersion. What about focalization? We say that a phone is focal to the extent that it has a high score\nF (µ) = exp (U2 tanh(U1µ + b1) + b2) > 0 (5)\nwhere µ is the mean of its density. To learn the parameters of this neural network from data is to learn which phones are focal. We use a neural network since the focal regions of R2 are distributed in a complex way."
  }, {
    "heading": "5.3 The L Matrix",
    "text": "If fi = N (µi, σ2I) is the density associated with the phone v̄i, we may populate an N × N real\nAlgorithm 1 Generative Process 1: N ∼ Poisson (λ) (∈ N) 1 2: for i = 1 to N : 3: µi ∼ N (0, I) (∈ R2) 2 4: define L ∈ RN×N via (6) 5: for ` = 1 to M : 6: V̄ ` ∼ DPP (L) (⊆ [1, N ]); let n` = |V̄ `| 3 7: for i ∈ V̄ ` : 8: ṽ`i ∼ N ( µi, σ 2I ) 4\n9: v`i = νθ ( ṽ`i )\n4\nmatrix L where\nLij = { K(fi, fj ; ρ) if i 6= j K(fi, fj ; ρ) + F (µi) if i = j\n(6)\nSince L is the sum of two positive definite matrices (the first specializes a known kernel and the second is diagonal and positive), it is also positive definite. As a result, it can be used to parameterize a DPP over V̄ . Indeed, since L is positive definite and not merely positive semidefinite, it will assign positive probability to any subset of V̄ .\nAs previously noted, this DPP does not define a distribution over an infinite set, e.g., the powerset of R2, as does recent work on continuous DPPs (Affandi et al., 2013). Rather, it defines a distribution over the powerset of a set of densities with finite cardinality. Once we have sampled a subset of densities, a real-valued quantity may be additionally sampled from each sampled density."
  }, {
    "heading": "6 A Deep Generative Model",
    "text": "We are now in a position to expound our generative model of continuous-space vowel typology. We\ngenerate a set of formant pairs for M languages in a four step process. Note that throughout this exposition, language-specific quantities with be superscripted with an integral language marker `, whereas universal quantities are left unsuperscripted. The generative process is written in algorithmic form in Alg. 1. Note that each step is numbered and color-coded for ease of comparison with the full joint likelihood in Fig. 2.\nStep 1 : p(N). We sample the size N of the universal phone inventory V̄ from a Poisson distribution with a rate parameter λ, i.e.,\nN ∼ Poisson (λ) . (7)\nThat is, we do not presuppose a certain number of phones in the model.\nStep 2 : p(µ1, . . . ,µN ). Next, we sample the means µi of the Gaussian phones. In the model presented here, we assume that each phone is generated independently, so p(µ1, . . . ,µN ) =∏N i=1 p(µi). Also, we assume a standard Gaussian prior over the means, µi ∼ N (0, I). The sampled means define our N Gaussian phones N ( µi, σ 2I ) : we are assuming for simplicity that all phones share a single spherical covariance matrix, defined by the hyperparameter σ2. The dispersion and focalization of these phones define the matrix L according to equations (4)–(6), where ρ in (4) and the weights of the focalization neural net (5) are also hyperparameters.\nStep 3 : p(V̄ ` | µ1, . . . ,µN ). Next, for each language ` ∈ [1, . . . ,M ], we sample a diverse subset of the N phones, via a single draw from a DPP parameterized by matrix L:\nV̄ ` ∼ DPP(L), (8)\nwhere V̄ ` ⊆ [1, N ]. Thus, i ∈ V̄ ` means that language ` contains phone v̄i. Note that even the size of the inventory, n` = |V̄ `|, was chosen by the DPP. In general, we have n` N . Step 4 : ∏ i∈V̄ ` p(v ` i | µi) The final step in our generative process is that the phones v̄i in language ` must generate the pronunciations v`i ∈ R2 (formant vectors) that are actually observed in language `. Each vector takes two steps. For each i ∈ V̄ `, we generate an underlying ṽi ∈ R2 from the corresponding Gaussian phone. Then, we run\nthis vector through a feed-forward neural network νθ with parameters θ. In short:\nṽ`i ∼ N (µi, σ2I) (9) v`i = νθ(ṽ ` i), (10)\nwhere the second step is deterministic. We can fuse these two steps into a single step p(vi | µi), whose closed-form density is given in eq. (12) below. In effect, step 4 takes a Gaussian phone as input and produces the observed formant vector with an underlying formant vector in the middle.\nThis completes our generative process. We do not observe all the steps, but only the final collection of pronunciations v`i for each language, where the subscripts i that indicate phone identity have been lost. The probability of this incomplete dataset involves summing over possible phones for each pronunciation, and is presented in Fig. 2."
  }, {
    "heading": "6.1 A Neural Transformation of a Gaussian",
    "text": "A crucial bit of our model is running a sample from a Gaussian through a neural network. Under certain restrictions, we can find a closed form for the resulting density; we discuss these below. Let νθ be a depth-2 multi-layer perceptron\nνθ(ṽi) = W2 tanh (W1ṽi + b1) + b2. (11)\nIn order to find a closed-form solution, we require that (5) be a diffeomorphism, i.e., an invertible mapping from R2 → R2 where both νθ and its inverse ν−1θ are differentiable. This will be true as long asW1,W2 ∈ R2×2 are square matrices of fullrank and we choose a smooth, invertible activation function, such as tanh. Under those conditions, we may apply the standard theorem for transforming a random variable (see Stark and Woods, 2011):\np(vi | µi) = p(ν−1θ (vi) | µi) det Jν−1θ (vi) = p(ṽi | µi) det Jν−1θ (vi) (12)\nwhere Jν−1θ (x) is the Jacobian of the inverse of the neural network at the point x. Recall that p(ṽi | µi) is Gaussian-distributed."
  }, {
    "heading": "7 Modeling Assumptions",
    "text": "Imbued in our generative story are a number of assumptions about the linguistic processes behind vowel inventories. We briefly draw connections between our theory and the linguistics literature.\nWhy underlying phones? A technical assumption of our model is the existence of a universal set of underlying phones. Each phone is equipped with a probability distribution over reported acoustic measurements (pronunciations), to allow for a single phone to account for multiple slightly different pronunciations in different languages (though never in the same language). This distribution can capture both actual interlingual variation and also random noise in the measurement process.\nWhile our universal phones may seem to resemble the universal IPA symbols used in phonological transcription, they lack the rich featural specifications of such phonemes. A phone in our model has no features other than its mean position, which wholly determines its behavior. Our universal phones are not a substantive linguistic hypothesis, but are essentially just a way of partitioning R2 into finitely many small regions whose similarity and focalization can be precomputed. This technical trick allows us to use a discrete rather than a continuous DPP over the R2 space.1\nWhy a neural network? Our phones are Gaussians of spherical variance σ2, presumed to be scattered with variance 1 about a two-dimensional latent vowel space. Distances in this latent space are used to compute the dissimilarity of phones for modeling dispersion, and also to describe the phone’s ability to vary across languages. That is, two phones that are distant in the latent space can appear in the same inventory—presumably they are easy to discriminate in both perception and articulation—and it is easy to choose which one better explains an acoustic measurement, thereby affecting the other measurements that may appear in the inventory.\nWe relate this latent space to measurable acoustic space by a learned diffeomorphism νθ (Cotterell and Eisner, 2017). ν−1θ can be regarded as warping the acoustic distances into perceptual/articulatory distances. In some “high-resolution” regions of acoustic space, phones with fairly similar (F1, F2) values might yet be far apart in the latent space. Conversely, in other regions, relatively large acous-\n1Indeed, we could have simply taken our universal phone set to be a huge set of tiny, regularly spaced overlapping Gaussians that “covered” (say) the unit circle. As a computational matter, we instead opted to use a smaller set of Gaussians, giving the learner the freedom to infer their positions and tune their variance σ2. Because of this freedom, this set should not be too large, or a MAP learner may overfit the training data with zero-variance Gaussians and be unable to explain the test languages—similar to overfitting a Gaussian mixture model.\ntic changes in some direction might not prevent two phones from acting as similar or two pronunciations from being attributed to the same phone. In general, a unit circle of radius σ in latent space may be mapped by νθ to an oddly shaped connected region in acoustic space, and a Gaussian in latent space may be mapped to a multimodal distribution."
  }, {
    "heading": "8 Inference and Learning",
    "text": "We fit our model via MAP-EM (Dempster et al., 1977). The E-step involves deciding which phones each language has. To achieve this, we fashion a Gibbs sampler (Geman and Geman, 1984), yielding a Markov-Chain Monte Carlo E-step (Levine and Casella, 2001)."
  }, {
    "heading": "8.1 Inference: MCMC E-Step",
    "text": "Inference in our model is intractable even when the phones µ1, . . . ,µN are fixed. Given a language with n vowels, we have to determine which subset of the N phones best explains those vowels. As discussed above, the alignment a between the n vowels and n of the N phones represents a latent variable. Marginalizing it out is #P-hard, as we can see that it is equivalent to summing over all bipartite matchings in a weighted graph, which, in turn, is as costly as computing the permanent of a matrix (Valiant, 1979). Our sampler2 is an approximation algorithm for the task. We are interested in sampling a, the labeling of observed vowels with universal phones. Note that this implicitly samples the language’s phone inventory V̄ (a), which is fully determined by a.\nSpecifically, we employ an MCMC method closely related to Gibbs sampling. At each step of the sampler, we update our vowel-phone alignment a` as follows. Choose a language ` and a vowel index k ∈ [1, n`], and let i = a`k (that is, pronunciation v`,k is currently labeled with universal phone v̄i). We will consider changing a`k to j, where j is drawn from the (N − n`) phones that do not appear in V̄ (a`), heuristically choosing j in proportion to the likelihood p(v`,k | µj). We then stochastically decide whether to keep a`k = i or set a`k = j in proportion to the resulting values of the product 4 · 3 in eq. (2).\nFor a single E-step, the Gibbs sampler “warmstarts” with the labeling from the end of the previous iteration’s E-step. It sweeps S = 5 times\n2Taken from Volkovs and Zemel (2012, 3.1).\nthrough all vowels for all languages, and returns S sampled labelings, one from the end of each sweep.\nWe are also interested in automatically choosing the number of phones N , for which we take the Poisson’s rate parameter λ = 100. To this end, we employ reversible-jump MCMC (Green, 1995), resampling N at the start of every E-step."
  }, {
    "heading": "8.2 Learning: M-Step",
    "text": "Given the set of sampled alignments provided by the E-step, our M-step consists of optimizing the log-likelihood of the now-complete training data using the inferred latent variables. We achieved this through SGD training of the diffeomorphism parameters θ, the means µi of the Gaussian phones, and the parameters of the focalization kernel F ."
  }, {
    "heading": "9 Experiments",
    "text": ""
  }, {
    "heading": "9.1 Data",
    "text": "Our data is taken from the Becker-Kristal corpus (Becker-Kristal, 2006), which is a compilation of various phonetic studies and forms the largest multilingual phonetic database. Each entry in the corpus corresponds to a linguist’s phonetic description of a language’s vowel system: an inventory consisting of IPA symbols where each symbol is associated with two or more formant values. The corpus contains data from 233 distinct languages. When multiple inventories were available for the same language (due to various studies in the literature), we selected one at random and discarded the others."
  }, {
    "heading": "9.2 Baselines",
    "text": "Baseline #1: Removing dispersion. The key technical innovation in our work lies in the incorporation of a DPP into a generative model of vowel formants—a continuous-valued quantity. The role of the DPP was to model the linguistic principle of dispersion—we may cripple this portion of our model, e.g., by forcing K to be a diagonal kernel, i.e., Kij = 0 for i 6= j. In this case the DPP becomes a Bernoulli Point Process (BPP)—a special case of the DPP. Since dispersion is widely accepted to be an important principle governing naturally occurring vowel systems, we expect a system trained without such knowledge to perform worse.\nBaseline #2: Removing the neural network νθ. Another question we may ask of our formulation is whether we actually need a fancy neural mapping νθ to model our typological data well. The human\nperceptual system is known to perform a non-linear transformation on acoustic signals, starting with the non-linear cochlear transform that is physically performed in the ear. While ν−1θ is intended as loosely analogous, we determine its benefit by removing eq. (10) from our generative story, i.e., we take the observed formants vk to arise directly from the Gaussian phones.\nBaseline #3: Supervised phones and alignments. A final baseline we consider is supervised phones. Linguists standardly employ a finite set of phones— symbols from the international phonetic alphabet (IPA). In phonetic annotation, it is common to map each sound in a language back to this universal discrete alphabet. Under such an annotation scheme, it is easy to discern, cross-linguistically, which vowels originate from the same phoneme: an /I/ in German may be roughly equated with an /I/ in English. However, it is not clear how consistent this annotation truly is. There are several reasons to expect high-variance in the cross-linguistic acoustic signal. First, IPA symbols are primarily useful for interlinked phonological distinctions, i.e., one applies the symbol /I/ to distinguish it from /i/ in the given language, rather than to associate it with the sound bearing the same symbol in a second language. Second, field linguists often resort to the closest common IPA symbol, rather than an exact match: if a language makes no distinction between /i/ and /I/, it is more common to denote the sound with a /i/. Thus, IPA may not be as universal as hoped. Our dataset contains 50 IPA symbols so this baseline is only reported for N = 50."
  }, {
    "heading": "9.3 Evaluation",
    "text": "Evaluation in our setting is tricky. The scientific goal of our work is to place a bit of linguistic theory on a firm probabilistic footing, rather than a downstream engineering-task, whose performance we could measure. We consider three metrics.\nCross-Entropy. Our first evaluation metric is cross-entropy: the average negative log-probability of the vowel systems in held-out test data, given the universal inventory ofN phones that we trained through EM. We find this to be the cleanest method for scientific evaluation—it is the metric of optimization and has a clear interpretation: how surprised was the model to see the vowel systems of held-out, but attested, languages? The cross-entropy is the negative log of the∏[ · · · ] expression in eq. (2), with ` now rang-\ning over held-out languages.3 Wallach et al. (2009) give several methods for estimating the intractable sum in language `. We use the simple harmonic mean estimator, based on 50 samples of a` drawn with our Gibbs sampler (warm-started from the final E-step of training).\nCloze Evaluation. In addition, following Cotterell and Eisner (2017), we evaluate our trained model’s ability to perform a cloze task (Taylor, 1953). Given n`−1 or n`−2 of the vowels in heldout language `, can we predict the pronunciations vk of the remaining 1 or 2? We predict vk to be νθ(µi) where i = a ` k is the phone inferred by the sampler. Note that the sampler’s inference here is based only on the observed vowels (the likelihood) and the focalization-dispersion preferences of the DPP (the prior). We report the expected error of such a prediction—where error is quantified by Euclidean distance in (F1, F2) formant space—over the same 50 samples of a`.\nFor instance, consider a previously unseen vowel system with formant values {(499, 2199), (861, 1420), (571, 1079)}. A “cloze1” evaluation would aim to predict {(499, 2199)} as the missing\n3Since that expression is the product of both probability distributions and probability densities, our “cross-entropy” metric is actually the sum of both entropy terms and (potentially negative) differential entropy terms. Thus, a value of 0 has no special significance.\nvowel, given {(861, 1420), (571, 1079)}, and the fact that n` = 3. A “cloze12” evaluation would aim to predict two missing vowels."
  }, {
    "heading": "9.4 Experimental Details",
    "text": "Here, we report experimental details and the hyperparameters that we use to achieve the results reported. We consider a neural network νθ with k ∈ [1, 4] layers and find k = 1 the best performer on development data. Recall that our diffeomorphism constraint requires that each layer have exactly two hidden units, the same as the number of observed formants. We consider N ∈ {15, 25, 50, 100} phones as well as letting N fluctuate with reversible-jump MCMC (see footnote 1). We train for 100 iterations of EM, taking S = 5 samples at each E-step. At each M-step, we run 50 iterations of SGD for the focalization NN and also for the diffeomorphism NN. For each N , we selected (σ2, ρ) by minimizing cross-entropy on a held-out development set. We considered (σ2, ρ) ∈ {10k}5k=1 × {ρk}5k=1."
  }, {
    "heading": "9.5 Results and Error Analysis",
    "text": "We report results in Tab. 1. We find that our DPP model improves over the baselines. The results support two claims: (i) dispersion plays an important role in the structure of vowel systems and (ii) learning a non-linear transformation of a Gaussian improves our ability to model sets of formant-pairs. Also, we observe that as we increase the number of phones, the role of the DPP becomes more important. We visualize a sample of the trained alignment in Fig. 3.\nFrequency Encodes Dispersion. Why does dispersion not always help? The models with fewer phones do not reap the benefits that the models with more phones do. The reason lies in the fact that the most common vowel formants are already dispersed. This indicates that we still have not quite modeled the mechanisms that select for good vowel formants, despite our work at the phonetic level; further research is needed. We would prefer a model that explains the evolutionary motivation of sound systems as communication systems.\nNumber of Induced Phones. What is most salient in the number of induced phones is that it is close to the number of IPA phonemes in the data. However, the performance of the phonemesupervised system is much worse, indicating that, perhaps, while the linguists have the right idea about the number of universal symbols, they did not specify the correct IPA symbol in all cases. Our data analysis indicates that this is often due to pragmatic concerns in linguistic field analysis. For example, even if /I/ is the proper IPA symbol for the sound, if there is no other sound in the vicinity the annotator may prefer to use more common /i/."
  }, {
    "heading": "10 Related Work",
    "text": "Most closely related to our work is the classic study of Liljencrants and Lindblom (1972), who provide a simulation-based account of vowel systems. They argued that minima of a certain objective that encodes dispersion should correspond to canonical vowel systems of a given size n. Our tack is different in that we construct a generative probability model, whose parameters we learn from data. However, the essence of modeling is the same in that we explain formant values, rather than discrete IPA symbols. By extension, our work is also closely related to extensions of this theory (Schwartz et al., 1997; Roark, 2001) that focused on incorporating the notion of focalization into the experiments.\nOur present paper can also be regarded as a continuation of Cotterell and Eisner (2017), in which we used DPPs to model vowel inventories as sets of discrete IPA symbols. That paper pretended that each IPA symbol had a single cross-linguistic (F1, F2) pair, an idealization that we remove in this paper by discarding the IPA symbols and modeling formant values directly."
  }, {
    "heading": "11 Conclusion",
    "text": "Our model combines existing techniques of probabilistic modeling and inference to attempt to fit the actual distribution of the world’s vowel systems. We presented a generative probability model of sets of measured (F1, F2) pairs. We view this as a necessary step in the development of generative probability models that can explain the distribution of the world’s languages. Previous work on generating vowel inventories has focused on how those inventories were transcribed into IPA by field linguists, whereas we focus on the field linguists’ acoustic measurements of how the vowels are actually pronounced."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to acknowledge Tim Vieira, Katharina Kann, Sebastian Mielke and Chu-Cheng Lin for reading many early drafts. The first author would like to acknowledge an NDSEG grant and a Facebook PhD fellowship. This material is also based upon work supported by the National Science Foundation under Grant No. 1718846 to the last author."
  }],
  "year": 2018,
  "references": [{
    "title": "Approximate inference in continuous determinantal processes",
    "authors": ["Raja Hafiz Affandi", "Emily Fox", "Ben Taskar."],
    "venue": "Advances in Neural Information Processing Systems, pages 1430–1438.",
    "year": 2013
  }, {
    "title": "Predicting vowel inventories: The dispersion-focalization theory revisited",
    "authors": ["Roy Becker-Kristal."],
    "venue": "The Journal of the Acoustical Society of America, 120(5):3248–3248.",
    "year": 2006
  }, {
    "title": "Acoustic Typology of Vowel Inventories and Dispersion Theory: Insights from a Large Cross-Linguistic Corpus",
    "authors": ["Roy Becker-Kristal."],
    "venue": "Ph.D. thesis, UCLA.",
    "year": 2010
  }, {
    "title": "Praat, a system for doing phonetics by computer",
    "authors": ["Paulus Petrus Gerardus Boersma"],
    "venue": "Glot International, 5.",
    "year": 2002
  }, {
    "title": "EynardMehta theorem, Schur process, and their Pfaffian analogs",
    "authors": ["Alexei Borodin", "Eric M. Rains."],
    "venue": "Journal of Statistical Physics, 121(34):291–317.",
    "year": 2005
  }, {
    "title": "Introduction",
    "authors": ["Bernard Comrie", "Matthew S. Dryer", "David Gil", "Martin Haspelmath."],
    "venue": "Matthew S. Dryer and Martin Haspelmath, editors, The World Atlas of Language Structures Online. Max Planck Institute for Evolutionary Anthropol-",
    "year": 2013
  }, {
    "title": "Probabilistic typology: Deep generative models of vowel inventories",
    "authors": ["Ryan Cotterell", "Jason Eisner."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), Vancouver, Canada.",
    "year": 2017
  }, {
    "title": "Maximum likelihood from incomplete data via the EM algorithm",
    "authors": ["Arthur P. Dempster", "Nan M. Laird", "Donald B. Rubin."],
    "venue": "Journal of the Royal Rtatistical Society, Series B (Statistical Methodology), pages 1–38.",
    "year": 1977
  }, {
    "title": "Speech Processing: A Dynamic and Optimization-Oriented Approach",
    "authors": ["Li Deng", "Douglas O’Shaughnessy"],
    "year": 2003
  }, {
    "title": "Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images",
    "authors": ["Stuart Geman", "Donald Geman."],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence, (6):721–741.",
    "year": 1984
  }, {
    "title": "Phonological Typology",
    "authors": ["Matthew K. Gordon."],
    "venue": "Oxford.",
    "year": 2016
  }, {
    "title": "Reversible jump Markov chain Monte Carlo computation and Bayesian model determination",
    "authors": ["Peter J. Green."],
    "venue": "Biometrika, 82(4):711–732.",
    "year": 1995
  }, {
    "title": "Probability product kernels",
    "authors": ["Tony Jebara", "Risi Kondor", "Andrew Howard."],
    "venue": "Journal of Machine Learning Research, 5:819–844.",
    "year": 2004
  }, {
    "title": "Vowels and Consonants: An Introduction to the Sounds of Languages",
    "authors": ["Peter Ladefoged."],
    "venue": "WileyBlackwell.",
    "year": 2001
  }, {
    "title": "Implementations of the Monte Carlo EM algorithm",
    "authors": ["Richard A. Levine", "George Casella."],
    "venue": "Journal of Computational and Graphical Statistics, 10(3):422–439.",
    "year": 2001
  }, {
    "title": "Numerical simulation of vowel quality systems: The role of perceptual contrast",
    "authors": ["Johan Liljencrants", "Björn Lindblom."],
    "venue": "Language, pages 839–862.",
    "year": 1972
  }, {
    "title": "Explaining vowel inventory tendencies via simulation: Finding a role for quantal locations and formant normalization",
    "authors": ["Brian Roark."],
    "venue": "North East Linguistic Society, volume 31, pages 419–434.",
    "year": 2001
  }, {
    "title": "The dispersion-focalization theory of sound systems",
    "authors": ["Jean-Luc Schwartz", "Christian Abry", "Louis-Jean Boë", "Nathalie Vallée", "Lucie Ménard."],
    "venue": "The Journal of the Acoustical Society of America, 117(4):2422–2422.",
    "year": 2005
  }, {
    "title": "The dispersionfocalization theory of vowel systems",
    "authors": ["Jean-Luc Schwartz", "Louis-Jean Boë", "Nathalie Vallée", "Christian Abry."],
    "venue": "Journal of Phonetics, 25(3):255–286.",
    "year": 1997
  }, {
    "title": "Probability, Statistics, and Random Processes for Engineers",
    "authors": ["Henry Stark", "John Woods."],
    "venue": "Pearson.",
    "year": 2011
  }, {
    "title": "Relational properties as perceptual correlates of phonetic features",
    "authors": ["Kenneth N. Stevens."],
    "venue": "International Conference of Phonetic Sciences, pages 352– 355.",
    "year": 1987
  }, {
    "title": "On the quantal nature of speech",
    "authors": ["Kenneth N. Stevens."],
    "venue": "Journal of Phonetics, 17:3–45.",
    "year": 1989
  }, {
    "title": "Cloze procedure: a new tool for measuring readability",
    "authors": ["Wilson L. Taylor."],
    "venue": "Journalism and Mass Communication Quarterly, 30(4):415.",
    "year": 1953
  }, {
    "title": "The complexity of computing the permanent",
    "authors": ["Leslie G. Valiant."],
    "venue": "Theoretical Computer Science, 8(2):189–201.",
    "year": 1979
  }, {
    "title": "Efficient sampling for bipartite matching problems",
    "authors": ["Maksims Volkovs", "Richard S. Zemel."],
    "venue": "Advances in Neural Information Processing Systems, pages 1313–1321.",
    "year": 2012
  }, {
    "title": "Evaluation methods for topic models",
    "authors": ["Hanna Wallach", "Ian Murray", "Ruslan Salakhutdinov", "David Mimno."],
    "venue": "International Conference on Machine Learning (ICML), pages 1105–1112.",
    "year": 2009
  }],
  "id": "SP:2f2030366f84c8dff3544d0f4e07d21c42d109eb",
  "authors": [{
    "name": "Ryan Cotterell",
    "affiliations": []
  }, {
    "name": "Jason Eisner",
    "affiliations": []
  }],
  "abstractText": "What makes some types of languages more probable than others? For instance, we know that almost all spoken languages contain the vowel phoneme /i/; why should that be? The field of linguistic typology seeks to answer these questions and, thereby, divine the mechanisms that underlie human language. In our work, we tackle the problem of vowel system typology, i.e., we propose a generative probability model of which vowels a language contains. In contrast to previous work, we work directly with the acoustic information—the first two formant values—rather than modeling discrete sets of phonemic symbols (IPA). We develop a novel generative probability model and report results based on a corpus of 233 languages.",
  "title": "A Deep Generative Model of Vowel Formant Typology"
}