{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 937–943 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n937"
  }, {
    "heading": "1 Introduction",
    "text": "The ability to automatically generate paraphrases (alternative phrasings of the same content) has been shown to be useful in many areas of Natural Language Processing such as question answering (Riezler et al., 2007), semantic parsing (Berant and Liang, 2014)), machine translation (Kauchak and Barzilay, 2006; Zhou et al., 2006), sentence compression (Napoles et al., 2011) and sentence representation (Wieting et al., 2015). From a linguistic standpoint, the automatic generation of paraphrases is an important task in its own right as it demonstrates the capacity of NLP techniques to handle a key feature of natural language.\nIn this paper, we focus on the automatic generation of syntactic paraphrases that is, texts which share the same meaning but differ in their syntax. Our work makes the following contributions. We show that conditioning text generation on syntactic information permits generating distinct syntactic paraphrases for the same input. We provide a systematic exploration of how different types of generation tasks impact paraphrasing and show that exploiting different types of input permits increasing the number of paraphrases produced for a\ngiven input. We make available four training corpora for syntactically constrained, data- and textto-text generation, text expansion and text reduction."
  }, {
    "heading": "2 Related Work",
    "text": "Previous work on paraphrase generation falls into three main groups. Based mainly on monolingual data, earlier approaches use data-driven, (Lin and Pantel, 2001), grammar- or thesaurus-based methods (Madnani et al., 2007; McKeown, 1983; Hassan et al., 2007; Kozlowski et al., 2003; Quirk et al., 2004; Zhao et al., 2008). In contrast, the pivot-based approach exploits bilingual data and machine translation methods to extract and generate paraphrases (Callison-Burch, 2008; Ganitkevitch and Callison-Burch, 2014; Ganitkevitch et al., 2011). Finally, neural approaches build upon the encoder-decoder architecture to learn paraphrase generation models (Mallinson et al., 2017; Prakash et al., 2016).\n(Prakash et al., 2016) uses a stacked residual LSTM network with residual connections between LSTM layers and show that their model outperforms sequence to sequence, attention-based, and bi- directional LSTM model on three datasets (PPDB, WikiAnswers, and MSCOCO).\n(Mallinson et al., 2017) introduces a neural model for multi-lingual, multi-pivot backtranslation and show that it outperforms a paraphrase model trained with a commonly used Statistical Machine Translation system (SMT) on three tasks, namely, correlation with human judgments of paraphrase quality; paraphrase and similarity detection; and sentence-level paraphrase generation.\n(Iyyer et al., 2018) also use backtranslation as a mean to provide training data. In addition, it uses syntax to control paraphrase generation. Given\na syntactic template T and an input sentence S, the model first generates a full syntactic parse PT . Next this syntactic parse is used together with the input sentence to predict a syntactic paraphrase of S which realises the input syntactic template T .\nOur approach is closest to (Iyyer et al., 2018) but differs from it in that instead of restricting paraphrase generation to a text rewriting problem, we explore how various sources of input impacts the number and the type of generated paraphrases. It also differs from the former two approaches (Prakash et al., 2016; Mallinson et al., 2017) in that we focus on syntactic paraphrases and condition generation on syntax. In that sense, our approach also shares similarities with recent models for controllable text generation (Hu et al., 2017; Semeniuta et al., 2017), which use variational autoencoders to model holistic properties of sentences such as style, topic and various other syntactic features. Our work is arguably conceptually simpler, focuses on syntactic paraphrases and introduces a new text production mode based on hybrid “data and text” input."
  }, {
    "heading": "3 Generating Syntactic Paraphrases",
    "text": "In order to generate syntactically distinct paraphrases, we formulate the generation task as a structured prediction task conditioned on both some input I and some syntactic constraint k. In this way, the same input I can be mapped to several output Ti each satisfying a different syntactic constraint ki. Table 1 shows some examples.\nIn addition, we consider different, semantically equivalent, sources of information. That is, we compare the paraphrases obtained when generating text from data, from text or from text and data. For the later, we consider two subtasks namely text expansion and text reduction. For each of these two tasks, the input is a text and a data unit. For text expansion, the output is a text verbalising both the input text and the input data. Conversely, for text reduction, the output is a text verbalising the input text minus the text verbalising the input data. Table 2 shows some example input and output for text expansion and text reduction."
  }, {
    "heading": "4 Training and Test Data",
    "text": "Training data. The WEBNLG dataset (Gardent et al., 2017) associates sets of RDF triples with one or more texts verbalising these sets of triples.\nWe derive training corpora for syntactically constrained generation from this dataset as follows.\nWe enrich the WEBNLG texts with labels indicating syntactic structures that are realised by these texts by first, parsing1 these texts and then using syntactic templates to identify the target structures occurring in those texts. We use the following list of syntactic labels: subject relative, object relative, sentence coordination, VP coordination, passive voice, apposition, possessive relative, pied piping, transitive clause, prepositional object, ditransitive clause, predicative clause.\nBased on the resulting, syntactically enriched, WEBNLG corpus, we then build four training corpora (T2Tsyn, TXsyn, D2Tsyn, TRsyn) using the sets of RDF triples as pivots to relate paraphrases. For data-to-text generation (D2Tsyn), the input is a linearised and delexicalised version of the set of RDF triples representing the meaning of the output text, for text-to-text generation (T2Tsyn), the input is a text and for hybrid data-and-text-to-text generation (TXsyn and TRsyn), the input is a text and a linearised RDF triple.\nFor the text-to-text datasets, we additionally require that, for any corpus instance 〈k, Ti, To〉, To differs from Ti on exactly one syntactic label2.\nTest data. For any input 〈k, I〉 occuring in the test data, we ensure that 〈k, I〉 does not occur in the training data. (where I is either a set of RDF triples, a text or a text and an RDF triple)."
  }, {
    "heading": "5 Experimental Setup",
    "text": "Models and Baselines D2T5best and T2T5best For each generation task, we aim to learn a model that maximises the likelihood P (T |I; k; θ) of a text given some input I , some model parameters θ and some syntactic constraint k. We use a simple encoder-decoder model where both encoder and decoder are bidirectional LSTMs and the encoder receives as input a sequence including both the input I and the syntactic constraint k.\nWe compare our models with the output produced by beam search when no syntactic constraint applies. For D2T5best, we take the 5 best output generated from data. For T2T5best, there may be several input sentences associated with the same meaning: we take the 5 best output for each\n1We used the Stanford CoreNLP dependency parser version 3.8, 2018-06-09\n2K(Ti) = (K(Ti) ∩ K(To)) ∪ {k} and K(To) = (K(Ti) ∩K(To)) ∪ {k′} for some k 6= k′.\nof these sentences hence T2T5best may (and does) in fact yield more than 5 output per input meaning. Finally, ALLsyn groups together all output generated by the four syntactically constrained models for a given meaning.\nImplementation Details We use the OpenNMTpy sequence-to-sequence model (Klein et al., 2017) with attention and a bidirectional LSTM encoder. The encoder and decoder have two layers. Models were trained for 13 epochs, with a mini-batch size of 64, a dropout rate of 0.3, and a word embedding size of 500. They were optimised with SGD with a starting learning rate of 1.0.\nEvaluation. We assess both the linguistic/syntactic adequacy of the generated texts and the diversity of the paraphrases being generated.\nSyntactic and Linguistic Adequacy (BLEU, Synt, BLEUsyn). For the syntactically constrained models, given an input syntactic constraint k, the BLEU score3 is computed with respect to those references which satisfy k. In that way, the BLEU score indicates how close to the syntactic target the generated sentence is and therefore how well the model succeeds in generating the required syntactic constructs – as the number of references varies across inputs, we use BLEU at the sentence level (Papineni et al., 2002). In addition, we compute the proportion of output satisfying the input syntactic constraint (Synt) and the BLEU score for these output which satisfy the input syntactic constraint (BLEUsyn). The number of output satisfying the input syntactic constraint is computed by first parsing the generated output and then applying the templates used for the automatic annotation of the training data.\nDiversity (Sim, #Txt/Mg). To measure the level of paraphrasing obtained, we group together inputs which share the same meaning (i.e., inputs that are linked in the WEBNLG dataset to the same set of RDF triples) and we compute the number of distinct texts generated per meaning (# Txt/Mg). We further analyse these sets by computing the average pairwise similarity (Sim) of the texts present in these sets. We use the Ratcliff/Obershelp algorithm (Black, 2004) to compute similarity4. A low similarity indicates more\n3We use the sacrebleu script with BLEU-4. 4The Ratcliff/Obershelp similarity score varies between O and 1 where 1 is a complete match. It is expressed by the\ndiversity across the set of outputs sharing the same meaning.\nHuman Evaluation (% SPar). For each model, we manually examined for 50 meanings, a maximum of 10 randomly chosen output and recorded the average number (# SPar) of syntactically correct paraphrases per input."
  }, {
    "heading": "6 Results",
    "text": "Table 3 summarises the results.\nDiversity. The results for ALLsyn (aggregating all output texts generated for a given meaning) shows that combining different generation models increases diversity (# Txt/Mg:13.25, Sim:0.61)) while maintaining a good level of linguistic (BLEU:62.87) and syntactic adequacy (Synt:0.91).\nThe human evaluation further shows that the distinct outputs generated by the ALLsyn model are indeed syntactic, not purely lexical, variants. Table 1 shows some example output for ALLsyn.\nExpansion, Reduction and Generation. Interestingly, the text expansion and reduction models markedly improve on traditional T2T and D2T models both in terms of linguistic adequacy (higher BLEU score) and in terms of diversity (higher number of distinct output per meaning, lower similarity between texts generated from the same meaning). The comparison with T2T generation is particularly striking as the training data is 3 to 5 times larger for the T2Tsyn model than for the TXsyn and the TRsyn model respectively. Similarly, it is noticable that although the T2Tsyn training corpus is 3 times larger than the D2Tsyn corpus, the T2Tsyn and the D2Tsyn models show similar results. This is in line with results from (Aharoni and Goldberg, 2018) which shows that rephrasing is a difficult task.\nLinguistic Adequacy. Overall the linguistic adequacy of the syntactically constrained models is high with a BLEU score with respect to a single reference ranging from 46.20 (D2Tsyn) to 83.87 (TXsyn). Moreover, the generated sentences show close similarity with the reference sentence realising the input constraint (BLEUsyn: from 48.16 to 89.32).\nformula sim(S1, S2) = 2∗match(S1,S2) len(S1)+len(S2)\nwhere a match is defined as the sum of the length of the matching segments (match(S1, S2) = ∑ m∈overlap(S1,S2) len(m).\nWhile the baseline models underperform in terms of BLEU scores, the manual evaluation (# SPar/Mg) indicates that they, in fact, produce acceptable output. The low BLEU scores for these models are probably due to the fact that each output is evaluated against a single reference while the dataset is constructed to maximise the number of paraphrases available for a given input."
  }, {
    "heading": "7 Some examples",
    "text": "Table 1 shows some example outputs illustrating the main differences between the D2T5best, T2T5best and the ALLsyn model. As these examples show, syntactically constrained generation (ALLsyn) outputs a much larger number of paraphrases. The difference is due both to the fact that ALLsyn groups together the output of 4 (syntactically driven) generation models and to the input syntactic constraint, which ensures greater diversity. Thus in the example shown, ALLsyn yields 15 paraphrases each with strong syntactic differences as summarised below.\nSentence Segmentation. The number of verb phrases, clauses and sentences used to verbalise the same input varies. One output text is made of 2 sentences and one VP coordination, another of 3 coordinated clauses and a third of two coordinated clauses and a VP coordination.\nSyntax. The same input property is realised by different syntactic structures. For instance, the property operatingOrganisation is alternatively realised by an active verb (operates), a passive verb (is operated by), a participial apposition (,operated by ..,), a subject relative (which is operated\nby), a nominal predicative construction (is the operation organization) and a preposed participial (Operated by .., ).\nWord Order. The same content is verbalised using varying word order and clause ordering. Thus the ALLsyn output shows four different ways of ordering the realisation of the three properties operatinOrganization (oO), runwayLength (rL), runwayName (rN) contained in the input namely, rLoO-rN (once), oO-rN-rL (6 times), oO-rL-rN (6 times) and rN-rL-oO (once).\nBy constrast, the baseline models output a much smaller range of syntactic paraphrases. The D2T5best model is particularly weak as among the five best outputs it produces, only three are distinct and all have almost identical syntax. The T2T5best model produces more outputs (8 against 3 for the D2T5best model and 15 for the ALLsyn model). One reason for this is that, contrary to the D2T5best model which has a single input (namely a set of RDF triples), this model can have several inputs for the same set of RDF triples."
  }, {
    "heading": "8 Conclusion",
    "text": "We have proposed new syntactically constrained models for text generation and shown that their use effectively supports the generation of syntactic paraphrases. In future work, we plan to investigate to what extent these methods can be used to support the automatic generation of grammar exercises."
  }],
  "year": 2018,
  "references": [{
    "title": "Split and rephrase: Better evaluation and a stronger baseline",
    "authors": ["Roee Aharoni", "Yoav Goldberg."],
    "venue": "ACL.",
    "year": 2018
  }, {
    "title": "Semantic parsing via paraphrasing",
    "authors": ["Jonathan Berant", "Percy Liang."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 1415–1425.",
    "year": 2014
  }, {
    "title": "Ratcliff/obershelp pattern recognition",
    "authors": ["Paul E Black."],
    "venue": "Dictionary of Algorithms and Data Structures,",
    "year": 2004
  }, {
    "title": "Syntactic constraints on paraphrases extracted from parallel corpora",
    "authors": ["Chris Callison-Burch."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 196–205. Association for Computational Linguistics.",
    "year": 2008
  }, {
    "title": "The multilingual paraphrase database",
    "authors": ["Juri Ganitkevitch", "Chris Callison-Burch."],
    "venue": "LREC, pages 4276–4283.",
    "year": 2014
  }, {
    "title": "Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation",
    "authors": ["Juri Ganitkevitch", "Chris Callison-Burch", "Courtney Napoles", "Benjamin Van Durme."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural",
    "year": 2011
  }, {
    "title": "Creating training corpora for nlg micro-planning",
    "authors": ["Claire Gardent", "Anastasia Shimorina", "Shashi Narayan", "Laura Perez-Beltrachini."],
    "venue": "55th annual meeting of the Association for Computational Linguistics (ACL).",
    "year": 2017
  }, {
    "title": "Unt: Subfinder: Combining knowledge sources for automatic lexical substitution",
    "authors": ["Samer Hassan", "Andras Csomai", "Carmen Banea", "Ravi Sinha", "Rada Mihalcea."],
    "venue": "Proceedings of the 4th International Workshop on Semantic Evaluations, pages 410–413.",
    "year": 2007
  }, {
    "title": "Controllable text generation",
    "authors": ["Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P Xing."],
    "venue": "arXiv preprint arXiv:1703.00955.",
    "year": 2017
  }, {
    "title": "Adversarial example generation with syntactically controlled paraphrase networks",
    "authors": ["Mohit Iyyer", "John Wieting", "Kevin Gimpel", "Luke Zettlemoyer."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
    "year": 2018
  }, {
    "title": "Paraphrasing for automatic evaluation",
    "authors": ["David Kauchak", "Regina Barzilay."],
    "venue": "Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages",
    "year": 2006
  }, {
    "title": "Opennmt: Open-source toolkit for neural machine translation",
    "authors": ["Guillaume Klein", "Yoon Kim", "Yuntian Deng", "Jean Senellart", "Alexander M. Rush."],
    "venue": "Proc. ACL.",
    "year": 2017
  }, {
    "title": "Generation of single-sentence paraphrases from predicate/argument structure using lexico-grammatical resources",
    "authors": ["Raymond Kozlowski", "Kathleen F McCoy", "K VijayShanker."],
    "venue": "Proceedings of the second international workshop on Paraphrasing-",
    "year": 2003
  }, {
    "title": "Discovery of inference rules for question-answering",
    "authors": ["Dekang Lin", "Patrick Pantel."],
    "venue": "Natural Language Engineering, 7(4):343–360.",
    "year": 2001
  }, {
    "title": "Using paraphrases for parameter tuning in statistical machine translation",
    "authors": ["Nitin Madnani", "Necip Fazil Ayan", "Philip Resnik", "Bonnie J Dorr."],
    "venue": "Proceedings of the Second Workshop on Statistical Machine Translation, pages 120–127. Association for",
    "year": 2007
  }, {
    "title": "Paraphrasing revisited with neural machine translation",
    "authors": ["Jonathan Mallinson", "Rico Sennrich", "Mirella Lapata."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Pa-",
    "year": 2017
  }, {
    "title": "Paraphrasing questions using given and new information",
    "authors": ["Kathleen R McKeown."],
    "venue": "Computational Linguistics, 9(1):1–10.",
    "year": 1983
  }, {
    "title": "Paraphrastic sentence compression with a character-based metric: Tightening without deletion",
    "authors": ["Courtney Napoles", "Chris Callison-Burch", "Juri Ganitkevitch", "Benjamin Van Durme."],
    "venue": "Proceedings of the Workshop on Monolingual Text-To-Text Gener-",
    "year": 2011
  }, {
    "title": "Bleu: a method for automatic evaluation of machine translation",
    "authors": ["Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu."],
    "venue": "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for",
    "year": 2002
  }, {
    "title": "Generating grammar exercises",
    "authors": ["Laura Perez-Beltrachini", "Claire Gardent", "German Kruszewski."],
    "venue": "Proceedings of the Seventh Workshop on Building Educational Applications Using NLP, pages 147– 156. Association for Computational Linguistics.",
    "year": 2012
  }, {
    "title": "Neural paraphrase generation with stacked residual lstm networks",
    "authors": ["Aaditya Prakash", "Sadid A Hasan", "Kathy Lee", "Vivek Datla", "Ashequl Qadir", "Joey Liu", "Oladimeji Farri."],
    "venue": "arXiv preprint arXiv:1610.03098.",
    "year": 2016
  }, {
    "title": "Monolingual machine translation for paraphrase generation",
    "authors": ["Chris Quirk", "Chris Brockett", "Bill Dolan"],
    "year": 2004
  }, {
    "title": "Statistical machine translation for query expansion in answer retrieval",
    "authors": ["Stefan Riezler", "Alexander Vasserman", "Ioannis Tsochantaridis", "Vibhu Mittal", "Yi Liu."],
    "venue": "Proceedings of the 45th Annual Meeting of the Association of Computational",
    "year": 2007
  }, {
    "title": "A hybrid convolutional variational autoencoder for text generation",
    "authors": ["Stanislau Semeniuta", "Aliaksei Severyn", "Erhardt Barth."],
    "venue": "arXiv preprint arXiv:1702.02390.",
    "year": 2017
  }, {
    "title": "From paraphrase database to compositional paraphrase model and back",
    "authors": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu", "Dan Roth."],
    "venue": "arXiv preprint arXiv:1506.03487.",
    "year": 2015
  }, {
    "title": "Combining multiple resources to improve smt-based paraphrasing model",
    "authors": ["Shiqi Zhao", "Cheng Niu", "Ming Zhou", "Ting Liu", "Sheng Li."],
    "venue": "Proceedings of ACL-08: HLT, pages 1021–1029.",
    "year": 2008
  }, {
    "title": "Re-evaluating machine translation results with paraphrase support",
    "authors": ["Liang Zhou", "Chin-Yew Lin", "Eduard Hovy."],
    "venue": "Proceedings of the 2006 conference on empirical methods in natural language processing, pages 77–84. Association for Computa-",
    "year": 2006
  }],
  "id": "SP:5efb98eab60a9f2e5dd49024fe6731be1f5bf0a2",
  "authors": [{
    "name": "Emilie Colin",
    "affiliations": []
  }, {
    "name": "Claire Gardent",
    "affiliations": []
  }],
  "abstractText": "We study the automatic generation of syntactic paraphrases using four different models for generation: data-to-text generation, textto-text generation, text reduction and text expansion, We derive training data for each of these tasks from the WebNLG dataset and we show (i) that conditioning generation on syntactic constraints effectively permits the generation of syntactically distinct paraphrases for the same input and (ii) that exploiting different types of input (data, text or data+text) further increases the number of distinct paraphrases that can be generated for a given input.",
  "title": "Generating Syntactic Paraphrases"
}