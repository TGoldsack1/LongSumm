{
  "sections": [{
    "heading": "1. Introduction",
    "text": "The advancement of modern society is driven by the development of Integrated Circuits (IC). Unlike the digital circuits where the design flow is already highly automated, the automation of analog circuit design is still a challenging problem.\nTraditionally, the design parameters of analog circuits like widths and lengths of transistors are manually calculated by designers with their experience and the understanding of the design specifications. However, due to the progress\n1State Key Lab of ASIC and System, School of Microelectronics, Fudan University, Shanghai, China 2Department of Electrical Engineering, University of Texas at Dallas, Richardson, TX, U.S.A. Correspondence to: Fan Yang <yangfan@fudan.edu.cn>, Xuan Zeng <xzeng@fudan.edu.cn>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nof IC manufacture technology forecasted by Moore’s law, the circuit devices become more and more complicated, and the parasitic effect of the circuits can no longer be ignored. On the other hand, the demands for high-performance, lowpower analog circuits are increasing. It is much more difficult to meet the performance and time-to-market requirements with manual circuit design. Automated analog circuit design has thus attracted much research interest in the past decade (Rutenbar et al., 2007).\nThe analog circuit design automation problems can be formulated as optimization problems. The aim is to find the optimal design parameters that provide the best circuit performance, which can be represented by a figure of merit (FOM) real-valued function. Prior works about analog circuit optimization include offline model-based approaches (Colleran et al., 2003; Daems et al., 2003; Wang et al., 2014) and simulation-based approaches. The offline model-based methods try to build global models of the FOM via manual calculation or regression with simulated data and then optimize the cheap-to-evaluate models. The problem with this approach is that the accurate models are usually hard to get. For example, in Wang et al. (2014), 100,000 randomly simulated points are used to train a sparse polynomial model for an amplifier circuit with ten design parameters.\nSimulation-based methods, instead, treat the performances of the circuits as black-box functions. The performances are obtained from circuit simulations. Global optimization algorithms are directly applied to the black-box functions. For simulation-based circuit optimization methods, metaheuristic algorithms (Phelps et al., 2000; Liu et al., 2009) are widely used. Although these algorithms can explore the whole design space, they have relatively low convergence rate. When the circuit simulation takes a long time, both model-based and simulation-based approaches can be very time-consuming.\nIn recent years, the Gaussian process (GP) (Rasmussen, 2006) model has been introduced for the automated design of analog circuits to reduce the required number of circuit simulations. In Liu et al. (2014), GP is combined with differential evolution algorithm. Recently, Bayesian optimization (BO) (Shahriari et al., 2016) algorithm has also been applied for analog circuit optimization. In Lyu et al. (2017),\nBayesian optimization algorithm is firstly introduced for the single- and multi-objective optimization of general analog circuits and has shown to be much more efficient compared with other simulation-based approaches. In Wang et al. (2017), Bayesian optimization algorithm is combined with adaptive Monte-Carlo sampling to optimize the yield of analog circuits and static random-access memory (SRAM).\nBayesian optimization algorithm is a well-studied algorithm and has demonstrated to be promising for the automated design of analog circuits. However, the standard Bayesian optimization algorithm is sequential. It chooses only one point at each iteration by optimizing the acquisition function. It is often desirable to select a batch of points at each iteration. The sequential property of Bayesian optimization limits its further applications in multi-core computer systems.\nBayesian optimization algorithm has been extended to enable batch selection. Some prior works, like the qEI (Chevalier & Ginsbourger, 2013), qKG (Wu & Frazier, 2016) and parallel predictive entropy search (PPES) (Shah & Ghahramani, 2015) approaches, consider to search for the optimal batch selection for a specific acquisition function. These methods usually involve some approximations or MonteCarlo sampling, and thus scale poorly as the batch size increases. Other works, including the simulation matching (SM) (Azimi et al., 2010) method, the batch-UCB (BUCB, BLCB for minimization problems) (Desautels et al., 2014) method, the parallel UCB with pure exploration (GP-UCBPE) (Contal et al., 2013) method, and the local penalization (LP) (González et al., 2016) method, adopted the greedy strategies that select individual points until the batch is filled.\nAll the batch Bayesian optimization algorithms mentioned above choose to use single acquisition function. And except for the SM method (Azimi et al., 2010) and LP method (González et al., 2016) which can use arbitrary acquisition function, other parallelization methods rely on a specific acquisition function. The UCB acquisition function must be used for BUCB and GP-UCB-PE, and the knowledge gradient (KG) acquisition function must be used for the qKG algorithm. As is stated in Hoffman et al. (2011), no single acquisition function can always outperform other acquisition functions. Relying on one acquisition function may result in poor performance.\nIn this paper, we propose to parallelize Bayesian optimization algorithm via the Multi-objective ACquisition Ensemble (MACE). The proposed MACE method exploits the disagreement between different acquisition functions to enable batch selection. At each iteration, after the GP model is updated, multiple acquisition functions are selected. We then perform multi-objective optimization to find the Pareto front (PF) of the acquisition functions. The PF represents the best trade-off between these acquisition functions. When batch\nevaluations are possible, we can sample multiple points on the PF to accelerate the optimization.\nThe MACE algorithm is tested using several analytical benchmark functions and two real-world analog circuits, including an operational amplifier with ten design parameters and a class-E power amplifier with twelve design parameters. The BLCB method (Desautels et al., 2014), local penalization method with expected improvement acquisition function (EI-LP) (González et al., 2016), qEI (Chevalier & Ginsbourger, 2013) and qKG (Wu & Frazier, 2016) methods are compared with MACE. The proposed MACE method achieved competitive performance when compared with the state-of-the-art algorithms listed in the paper."
  }, {
    "heading": "2. Background",
    "text": "In this section, we will present the problem formulation of analog circuit optimization, and review the background of Gaussian process regression and Bayesian optimization."
  }, {
    "heading": "2.1. Problem Formulation",
    "text": "When designing integrated circuits, the designers have to decide what circuit topology to use and then set the corrsponding design parameters. In this work, we handle the scenarios where the topology of the analog circuit is fixed. This is practical as there are usually a lot of classical topologies for a given design task, so unlike digital circuits, choosing appropriate topology is relatively easy.\nOnce the circuit topology is fixed, the designer has to choose the appropriate design parameters according to the specifications and the circuit device model. What we want to do is automatically searching for the optimal design parameters. This problem can then be formulated as a bound-constrained black-box optimization problem:\nminimize FOM(x), (1)\nwhere x ∈ D is the vector of design variables, FOM(x) is the objective constructed from the design specifications, the FOM(x) can be deterministric or noisy depending on the design specifications. Given the design parameters x, the FOM value can be obtained by commercial circuit simulators like HSPICE or Spectre."
  }, {
    "heading": "2.2. Gaussian Process Regression",
    "text": "The objective function FOM(x) in (1) can be approximated by Gaussian process (GP) model (Rasmussen, 2006). The GP model is the most commonly used model for Bayesian optimization. The advantage of GP is that it provides a well-calibrated uncertainty of prediction. GP is characterized by a mean function m(x) and a covariance function k(x,x′). In this work, we use squared-exponential ARD kernel (Rasmussen, 2006), and a constant mean function\nm(x) = µ0 for all our experiments. By default, we assume the objective function evaluations are influenced by i.i.d. noise t ∼ N(0, σ2n) and set the noise level σ2n as a hyperparameter. The introduction of the i.i.d noise also helps to improve the numerical stability.\nDenote the training set as {X,y} where X = {x1, . . . ,xN} and y = {y1, . . . , yN}, given a new data point x, the prediction of f(x) is not a scalar value, but a predictive distribution\nf(x) ∼ N(µ(x), σ2(x)), (2)\nwhere µ(x) and σ2(x) can be expressed as\nµ(x) = µ0 + k(x, X)[K + σ 2 nI] −1(y − µ0) σ2(x) = k(x,x)− k(x, X)[K + σ2nI]−1k(X,x),\n(3) where k(x, X) = (k(x,x1), . . . , k(x,xN ))T and k(X,x) = k(x, X)T . The µ(x) can be viewed as the prediction of the function value, while the σ2(x) is a measure of uncertainty of the prediction."
  }, {
    "heading": "2.3. Bayesian Optimization",
    "text": "Bayesian optimization (Shahriari et al., 2016) was proposed for the optimization of expensive black-box functions. It consists of two essential ingredients, i.e., the probabilistic surrogate models and the acquisition functions. The probabilistic surrogate models provide predictions with uncertainties. The acquisition functions make use of the predictive distribution to explore the state space. The procedure of Bayesian optimization is summarized in Algorithm 1.\nAlgorithm 1 Bayesian Optimization Require: Number of initial sampling points Ninit, number\nof iterations Niter 1: Randomly sample Ninit points in the design space 2: Construct initial GP model 3: for t = 1, 2, . . . , Niter do 4: Construct the acquisition function 5: Find xt that optimizes the acquisition function 6: Sample yt = f(xt) 7: Update probabilistic surrogate model 8: end for 9: Return best f(x) recorded during iterations\nIn Bayesian optimization described in Algorithm 1, the acquisition function is used to balance the exploration and exploitation during the optimization. The acquisition function considers both the predictive value and the uncertainty. There are a lot of existing acquisition functions. Examples include the lower confidence bound (LCB), the probability of improvement (PI), and the expected improvement (EI).\nThe LCB function is defined as follows:\nLCB(x) = µ(x)− κσ(x), (4)\nwhere the µ(x) and the σ(x) are the predictive value and uncertainty of GP defined in (3), κ is a parameter that balances the exploitation and exploration.\nFollowing the suggestion of (Srinivas et al., 2010; Brochu et al., 2010), the κ in (4) is defined as:\nκ = √ ντt τt = 2 log(t d/2+2π2/3δ),\n(5)\nwhere t is the number of current iteration, ν and δ are two user-defined parameters. We fix ν = 0.5 and δ = 0.05 in this paper for the proposed MACE algorithm and our implementation of the BLCB algorithm.\nThe PI and EI functions are defined as\nPI(x) = Φ(λ) EI(x) = σ(x)(λΦ(λ) + φ(λ)) λ = τ − ξ − µ(x)\nσ(x) ,\n(6)\nwhere τ is the current best value objective value, and ξ is a small positive jitter to improvement the ability of exploration. The Φ(.) and φ(.) functions are the CDF and PDF functions of normal distribution. In our implementation of the MACE algorithm, we fix ξ = 1e-3.\nThere are also other acquisition functions, like the knowledge gradient (Scott et al., 2011) function, predictive entropy search (Hernández-Lobato et al., 2014), and the max-value entropy search(Wang & Jegelka, 2017). A portfolio of several acquisition functions is also possible (Hoffman et al., 2011)."
  }, {
    "heading": "3. Proposed Batch Bayesian Optimization Algorithm",
    "text": "We will present the proposed batch Bayesian optimization algorithm in this section."
  }, {
    "heading": "3.1. Multi-objective Optimization",
    "text": "Unlike single-objective optimization, there are multiple objectives to optimize in multi-objective optimization problems(Marler & Arora, 2004). The multi-objective optimization problem is formulated as\nminimize f1(x), . . . , fm(x). (7)\nThe multiple objectives to be optimized can be conflicting so that it is usually impossible to find a single solution that is the optimum of all objectives. The goal of multi-objective optimization algorithms is to approximate the Pareto front of\nthe objectives. A solution x1 is said to dominate x2 if ∀i ∈ {1 . . .m}, fi(x1) ≤ fi(x2) and ∃j ∈ {1 . . .m}, fj(x1) < fj(x2). A design is Pareto-optimal if it is not dominated by any other point in the design space and dominates at least one point. The whole set of the Pareto-optimal points in the design space is called the Pareto set, and the set of Pareto-optimal points in the objective space is called the Pareto front. It is often unlikely to get the whole Pareto front as there might be infinite points on the Paret front, multi-objective optimization algorithms try to find a set of evenly distributed solutions that approximate the true Pareto front.\nThere exist many mature multi-objective optimization algorithms, like the non-dominated sorting based genetic algorithm (NSGA-II) (Deb et al., 2002), and the multiobjective evolutionary algorithm based on decomposition (MOEA/D) (Zhang & Li, 2007). In this paper, the multi-objective optimization based on differential evolution (DEMO) (Robič & Filipič, 2005) is used to solve multiobjective optimization problems, but other multi-objective optimization algorithms can also be applied."
  }, {
    "heading": "3.2. Batch Bayesian Optimization via Multi-objective Acquisition Function Ensemble",
    "text": "Each acquisition function represents a unique selection strategy, different acquisition functions may not agree with each other about where to sample the next point. For example, the value of LCB function always decreases as the σ(x) increases. However, for the PI function, when σ(x) increases, the value of PI would decrease when µ(x) < τ , and increase when µ(x) > τ . For the EI function, if the function is noiseless, the values of EI function at already sampled points would always be worse than the EI values at any\nunsampled locations, while this property does not hold for the LCB function.\nAlgorithm 2 Multi-objective Acquisition Ensemble Algorithm Require: Number of initial sampling points Ninit, number\nof iterations Niter, batch size B. 1: Randomly sample Ninit points in the design space 2: Construct initial GP model 3: for t = 1, 2, . . . , Niter do 4: Construct the LCB, EI and PI functions according to (4) and (6) 5: Find the Pareto front of LCB, EI, PI functions using the DEMO algorithm 6: Randomly sample B points x1, . . . ,xB from the Pareto-optimal points 7: Evaluate x1, . . . ,xB to get y1 = f(x1), . . . , yB = f(xB) 8: Update the GP model 9: end for\n10: Return best f(x) recorded during iterations\nWith multi-objective optimization, the best trade-off between acquisition functions can be captured by the Pareto front of these acquisition functions. We can then sample on the Pareto front to obtain multiple candidate points for the objective function evaluations.\nThe proposed MACE algorithm is described in Algorithm 2. In the proposed MACE algorithm, the LCB, EI, and PI acquisition functions are selected. Other acquisition functions like KG and PES can also be incorporated into the MACE framework. In each iteration, the following multi-objective\noptimization problem is constructed:\nminimize LCB(x), − EI(x), − PI(x). (8)\nThen the DEMO multi-objective optimization algorithm (Robič & Filipič, 2005) is applied to solve the multiobjective problem in (8). Once the Pareto front of LCB, EI and PI is obtained, the candidate points are then randomly sampled from the Pareto front.\nIn Figure 1, we illustrate the proposed MACE algorithm using an example of a real-world amplifier circuit. The optimization objective is to maximize the phase margin (PM) of the amplifier, so the FOM is defined as FOM(x) = −PM(x). The width of one of its transistor is the design variable. We sweep the width of the transistor and perform HSPICE simulations to get the FOM values. The curve of FOM values is plotted in Figure 1(a) (the blue line). Several points are randomly sampled from the FOM curve to train the GP model. The LCB, EI, PI functions and the Pareto front of the acquisition functions are plotted in Figure 1(b). We can see from Figure 1(b) that the optimal locations of the three acquisition functions are different, while their best trade-off is captured by the Pareto front. The Pareto set that represents the best trade-off between the three acquisition functions is the interval [43, 50.4], as plotted in Figure 1(a). The candidate points for the next batch of evaluations are randomly sampled from the Pareto set."
  }, {
    "heading": "4. Experimental Results",
    "text": "The proposed MACE algorithm1 was tested using eight benchmark functions and two real-world analog circuits. Four state-of-the-art parallel Bayesian optimization methods were compared, including the BLCB algorithm (Desautels et al., 2014), the local penalization method with EI acquisition function (EI-LP) (González et al., 2016), the qEI and qKG methods (Chevalier & Ginsbourger, 2013; Wu & Frazier, 2016). 2\nFor the MACE, BLCB, and EI-LP method, the ARD squared-exponential kernel is used and the GP models are fitted by maximum likelihood estimations (MLE); for the qKG and qEI methods, the ARD Matern52 kernels are used, and the GP hyperparameters are integrated via MCMC sampling. The Matern52 kernel and MCMC integration are the default strategies of the qKG and qEI implementations and it is unclear in the documentation about how to change the GP settings.\n1Available at https://github.com/Alaya-in-Matrix/MACE 2We implemented the BLCB algorithm as the available open source implementations only allow discrete input. For the EI-LP method, the code is downloaded from https://github.com/SheffieldML/GPyOpt. The code for qEI and qKG is downloaded from https://github.com/wujian16/CornellMOE."
  }, {
    "heading": "4.1. Benchmark Problems",
    "text": "We tested the MACE algorithm and other parallel BO methods using eight commonly used benchmark functions, as summarized in Table 1.\nFor all functions except the two 10D functions, we set the number of initial random sampling to Ninit = 20 and the number of iterations toNiter = 45. Batch size is set toB = 4, the total number of function evaluations is Ninit +B × Niter. For the 10D Ackley and 10D Rosenbrock functions, we set Ninit = 100 and Niter = 175. The experiments were repeated ten times to average the random fluctuations.\nWe also ran the MACE algorithm in sequential mode and compared with the EI and LCB acquisition functions. The sequential EI and LCB based Bayesian optimization are implemented by setting the batch size B = 1 for EI-LP and BLCB respectively.\nThe mean convergence plots of the tested algorithms on the benchmark functions are given in Figure 2, the statistics of the final regrets are listed in Table 2. As can be seen in Figure 2 and Table 2, when running in sequential mode, the MACE algorithm is competitive with the LCB and EI acquisition functions. The sequential MACE (MACE-1) algorithm gave better performances than the sequential EI (EI-1) and sequential LCB (LCB-1) algorithms in the Eggholder, Branin, Hartmann6, Ackley10, and Rosenbrock10 functions. Also, the parallel MACE (MACE-4) gave the best performances among all the tested algorithms for six out of the eight benchmark functions, and has shown dramatic speedup compared to the sequential MACE. We also performed additional experiments with varied batch sizes, the detail of those experimental results can be seen in the supplementary materials. We report the time spent on the ten-dimensional Rosenbrock function optimization with B = 4 as a measure of the algorithm overhead, for the ten-dimensional Rosenbrock function, it took MACE about 11 hours to finish all the Niter = 175 iterations, the BLCB algorithm took about five hours, for the EI-LP algorithm, it took only one hour to finish the optimization. The overheads for qEI and qKG are much larger, it took more than two days for qKG and qEI to\nfinish the optimization of the ten-dimensional Rosenbrock function."
  }, {
    "heading": "4.2. Operational Amplifier",
    "text": "The operational amplifier (Wang et al., 2014) shown in Figure 3 is used to test Bayesian optimization algorithms. The circuit is designed using the 180nm process. It has 10 design parameters, including the lengths and widths of transistors, the resistance of the resistors and the capacitance of the capacitors. The circuit is simulated using the commercial HSPICE circuit simulator.\nWe want to maximize the gain, unit gain frequency (UGF) and the phase margin (PM) for this amplifier. The Figure of Merit FOM is constructed as\nFOM = −1.2× gain − 10×UGF − 1.6× PM .\nFor this circuit, we compared the MACE algorithm with the BLCB and EI-LP algorithms. The qKG and qEI are not compared as the computation of qEI and qKG acquisition functions become very slow for the ten-dimensional functions.\nWe run the algorithms in sequential mode and batch mode. For the batch mode, the batch size is set to B = 4. The number of initial random sampling is set to Ninit = 100, and the number of iterations is set to Niter = 100.\nThe mean convergence plot for the sequential and batch runs are given in Figure 4. The mean and standard deviation of the final optimized FOM values are listed in Table 3. As can be seen, on average, the batch MACE algorithm had the fastest convergence rate compared with the sequential MACE algorithm and other parallel algorithms. It should also be noted that the final optimized FOM values given by MACE-4 have very small deviation (0.105) compared with other algorithms.\nTable 2. Statistics of the regrets of the benchmark functions\nEggholder Branin Alpine1 Hartmann6\nMACE-1 87.65±75.83 1.05e-5±1.31e-5 2.66305±1.05844 0.0646869±0.0621189 LCB-1 153.9±112.8 6.86e-5±1.13e-4 5.66812±1.76973 0.125565±0.122684 EI-1 172.8±132.2 1.62e-2±1.63e-2 2.46061±1.56079 0.110561±0.146809 MACE-4 46.38±40.89 4.62e-6±6.64e-6 0.903805±0.835209 0.0275738±0.052254 BLCB-4 56.86±35.91 4.32e-5±6.33e-5 1.8843±0.938873 0.06447±0.0621176 EI-LP-4 44.68±56.45 2.11e-2±1.84e-2 1.0059±0.456865 0.0540446±0.0558557 qKG-4 106.4±67.64 2.65e-1±2.70e-1 3.01513±1.13414 0.47134±0.18939 qEI-4 72.13±52.08 3.29e-4±1.14e-3 2.7074±1.05145 0.186088±0.116323\nAckley2 Rosenbrock2 Ackley10 Rosenbrock10\nMACE-1 1.71474±1.12154 0.026173±0.051189 3.1348±0.447874 499.697±300.899 LCB-1 1.624±0.926437 0.0201124±0.0205367 3.14797±0.519164 517.944±288.955 EI-1 1.0136±0.985858 13.5508±9.52734 18.8006±0.652136 1367.08±637.507 MACE-4 1.07906±0.886466 0.00095416±0.00093729 2.56439±0.535488 158.116±50.0024 BLCB-4 1.40051±1.02849 0.00191986±0.00180895 3.27543±0.735501 406.819±127.351 EI-LP-4 0.284265±0.24634 2.73645±2.05923 18.2682±0.608564 721.351±327.365 qKG-4 5.59394±1.80595 5.03976±3.72014 18.197±0.764103 705.112±412.762 qEI-4 2.87373±1.02405 10.1881±15.0432 18.3686±0.501869 655.208±340.954\nVin\nC0\nC1\nVdd1=2.5V\nVg\nVdd2=1.8V\nM4\nM3\nM2\nM1\nL3 C2\nC3\nVout\nRLC1\nL1\nCc\nR0\nR1\nL2\nFigure 5. Schematic of the power amplifier"
  }, {
    "heading": "4.3. Class-E Power Amplifier",
    "text": "The class-E power amplifier shown in Figure 5 is used to test Bayesian optimization algorithms. The circuit is designed using the 180nm process with 12 design parameters, the circuit is simulated by the commercial HSPICE circuit simulator to get its performances.\nFor this power amplifier, we aim to maximize the power added efficiency (PAE) and the output power (Pout), the Figure of Merit FOM is constructed as\nFOM = −3× PAE − Pout .\nThe MACE, BLCB, and EI-LP algorithms were tested in both sequential and batch modes. The number of initial sampling is Ninit = 100. The number of iterations is\nNiter = 100. The batch size is set to B = 4. The total number of HSPICE simulations is 500 for each batch run and 200 for each sequential run.\nThe optimization results of the class-E power amplifier are given in Figure 6 and Table 4. We can see that the MACE outperformed the BLCB and EI-LP in both sequential and batch mode. For the batch runs, the MACE converges fastest among the three algorithms, while the sequential MACE (MACE-1) has comparable performance as the batch EI-LP (EI-LP-4) method."
  }, {
    "heading": "5. Conclusion",
    "text": "In this paper, a batch Bayesian optimization algorithm is proposed for the automation of analog circuit design. The parallelization is achieved via the multi-objective ensemble of acquisition functions. In each iteration, the candidate points are sampled from the Pareto front of multiple acquisition functions. We compared the proposed MACE algorithm using analytical benchmark functions and real-world circuits, it is shown that the MACE algorithm is competitive compared with the state-of-the-art methods listed in the paper."
  }, {
    "heading": "Acknowledgements",
    "text": "This research was supported partly by the National Major Science and Technology Special Project of China (2017ZX01028101-003), partly by National Key Research and Development Program of China 2016YFB0201304, partly by National Natural Science Foundation of China (NSFC) research projects 61774045, 61574044, 61474026, 61574046, 61674042, and 61628402 and partly by the Recruitment Program of Global Experts (the Thousand Talents Plan)."
  }],
  "year": 2018,
  "references": [{
    "title": "Batch bayesian optimization via simulation matching",
    "authors": ["J. Azimi", "A. Fern", "X.Z. Fern"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2010
  }, {
    "title": "A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning",
    "authors": ["E. Brochu", "V.M. Cora", "N. De Freitas"],
    "venue": "arXiv preprint arXiv:1012.2599,",
    "year": 2010
  }, {
    "title": "Fast computation of the multi-points expected improvement with applications in batch selection",
    "authors": ["C. Chevalier", "D. Ginsbourger"],
    "venue": "In International Conference on Learning and Intelligent Optimization,",
    "year": 2013
  }, {
    "title": "Optimization of phase-locked loop circuits via geometric programming",
    "authors": ["D.M. Colleran", "C. Portmann", "A. Hassibi", "C. Crusius", "S.S. Mohan", "S. Boyd", "T.H. Lee", "M. del Mar Hershenson"],
    "venue": "In Proceedings of the IEEE 2003 Custom Integrated Circuits Conference,",
    "year": 2003
  }, {
    "title": "Parallel gaussian process optimization with upper confidence bound and pure exploration",
    "authors": ["E. Contal", "D. Buffoni", "A. Robicquet", "N. Vayatis"],
    "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
    "year": 2013
  }, {
    "title": "Simulation-based generation of posynomial performance models for the sizing of analog integrated circuits",
    "authors": ["W. Daems", "G. Gielen", "W. Sansen"],
    "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,",
    "year": 2003
  }, {
    "title": "A fast and elitist multiobjective genetic algorithm: NSGAII",
    "authors": ["K. Deb", "A. Pratap", "S. Agarwal", "T. Meyarivan"],
    "venue": "IEEE transactions on evolutionary computation,",
    "year": 2002
  }, {
    "title": "Parallelizing exploration-exploitation tradeoffs in gaussian process bandit optimization",
    "authors": ["T. Desautels", "A. Krause", "J.W. Burdick"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Batch bayesian optimization via local penalization",
    "authors": ["J. González", "Z. Dai", "P. Hennig", "N. Lawrence"],
    "venue": "In Artificial Intelligence and Statistics,",
    "year": 2016
  }, {
    "title": "Predictive entropy search for efficient global optimization of black-box functions",
    "authors": ["J.M. Hernández-Lobato", "M.W. Hoffman", "Z. Ghahramani"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2014
  }, {
    "title": "Portfolio Allocation for Bayesian Optimization",
    "authors": ["M.D. Hoffman", "E. Brochu", "N. de Freitas"],
    "venue": "In UAI,",
    "year": 2011
  }, {
    "title": "Analog circuit optimization system based on hybrid evolutionary algorithms",
    "authors": ["B. Liu", "Y. Wang", "Z. Yu", "L. Liu", "M. Li", "Z. Wang", "J. Lu", "F.V. Fernández"],
    "venue": "Integration, the VLSI journal,",
    "year": 2009
  }, {
    "title": "An efficient bayesian optimization approach for automated optimization of analog circuits",
    "authors": ["W. Lyu", "P. Xue", "F. Yang", "C. Yan", "Z. Hong", "X. Zeng", "D. Zhou"],
    "venue": "IEEE Transactions on Circuits and Systems I: Regular Papers,",
    "year": 2017
  }, {
    "title": "Survey of multi-objective optimization methods for engineering",
    "authors": ["R.T. Marler", "J.S. Arora"],
    "venue": "Structural and multidisciplinary optimization,",
    "year": 2004
  }, {
    "title": "Anaconda: simulation-based synthesis of analog circuits via stochastic pattern search",
    "authors": ["R. Phelps", "M. Krasnicki", "R.A. Rutenbar", "L.R. Carley", "J.R. Hellums"],
    "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,",
    "year": 2000
  }, {
    "title": "Gaussian processes for machine learning",
    "authors": ["C.E. Rasmussen"],
    "year": 2006
  }, {
    "title": "Demo: Differential evolution for multiobjective optimization",
    "authors": ["T. Robič", "B. Filipič"],
    "venue": "Evolutionary Multi-Criterion Optimization,",
    "year": 2005
  }, {
    "title": "Hierarchical Modeling, Optimization, and Synthesis for System-Level Analog and RF Designs",
    "authors": ["R.A. Rutenbar", "G.G.E. Gielen", "J. Roychowdhury"],
    "venue": "Proceedings of the IEEE,",
    "year": 2007
  }, {
    "title": "The correlated knowledge gradient for simulation optimization of continuous parameters using gaussian process regression",
    "authors": ["W. Scott", "P. Frazier", "W. Powell"],
    "venue": "SIAM Journal on Optimization,",
    "year": 2011
  }, {
    "title": "Parallel predictive entropy search for batch global optimization of expensive objective functions",
    "authors": ["A. Shah", "Z. Ghahramani"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Taking the Human Out of the Loop: A Review of Bayesian Optimization",
    "authors": ["B. Shahriari", "K. Swersky", "Z. Wang", "R.P. Adams", "N. de Freitas"],
    "venue": "Proceedings of the IEEE,",
    "year": 2016
  }, {
    "title": "Gaussian process optimization in the bandit setting: no regret and experimental design",
    "authors": ["N. Srinivas", "A. Krause", "S. Kakade", "M. Seeger"],
    "venue": "In Proceedings of the 27th International Conference on International Conference on Machine Learning,",
    "year": 2010
  }, {
    "title": "Efficient yield optimization for analog and sram circuits via gaussian process regression and adaptive yield estimation",
    "authors": ["M. Wang", "W. Lv", "F. Yang", "C. Yan", "W. Cai", "D. Zhou", "X. Zeng"],
    "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,",
    "year": 2017
  }, {
    "title": "Enabling efficient analog synthesis by coupling sparse regression and polynomial optimization",
    "authors": ["Y. Wang", "M. Orshansky", "C. Caramanis"],
    "venue": "In 2014 51st ACM/EDAC/IEEE Design Automation Conference (DAC),",
    "year": 2014
  }, {
    "title": "Max-value entropy search for efficient bayesian optimization",
    "authors": ["Z. Wang", "S. Jegelka"],
    "venue": "arXiv preprint arXiv:1703.01968,",
    "year": 2017
  }, {
    "title": "The parallel knowledge gradient method for batch bayesian optimization",
    "authors": ["J. Wu", "P. Frazier"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "MOEA/D: A multiobjective evolutionary algorithm based on decomposition",
    "authors": ["Q. Zhang", "H. Li"],
    "venue": "IEEE Transactions on evolutionary computation,",
    "year": 2007
  }],
  "id": "SP:9e3f4807fda1d876836e2fa3fd49d460fbf5711a",
  "authors": [{
    "name": "Wenlong Lyu",
    "affiliations": []
  }, {
    "name": "Fan Yang",
    "affiliations": []
  }, {
    "name": "Changhao Yan",
    "affiliations": []
  }, {
    "name": "Dian Zhou",
    "affiliations": []
  }, {
    "name": "Xuan Zeng",
    "affiliations": []
  }],
  "abstractText": "Bayesian optimization methods are promising for the optimization of black-box functions that are expensive to evaluate. In this paper, a novel batch Bayesian optimization approach is proposed. The parallelization is realized via a multi-objective ensemble of multiple acquisition functions. In each iteration, the multi-objective optimization of the multiple acquisition functions is performed to search for the Pareto front of the acquisition functions. The batch of inputs are then selected from the Pareto front. The Pareto front represents the best trade-off between the multiple acquisition functions. Such a policy for batch Bayesian optimization can significantly improve the efficiency of optimization. The proposed method is compared with several state-of-the-art batch Bayesian optimization algorithms using analytical benchmark functions and real-world analog integrated circuits. The experimental results show that the proposed method is competitive compared with the state-of-the-art algorithms.",
  "title": "Batch Bayesian Optimization via Multi-objective Acquisition Ensemble for Automated Analog Circuit Design"
}