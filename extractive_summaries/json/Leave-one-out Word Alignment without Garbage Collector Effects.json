{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1817–1827, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "Unsupervised word alignment (WA) on bilingual sentence pairs serves as an essential foundation for building most statistical machine translation (SMT) systems. A lot of methods have been proposed to raise the accuracy of WA in an effort to improve end-to-end translation quality. This paper contributes to this effort through refining the widely used expectation-maximization (EM) algorithm for WA (Dempster et al., 1977; Brown et al., 1993b; Och and Ney, 2000).\n∗ The author now is affiliated with Google, Japan.\nThe EM algorithm for WA has a great influence in SMT. Many well-known toolkits including GIZA++ (Och and Ney, 2003), the Berkeley Aligner (Liang et al., 2006; DeNero and Klein, 2007), Fast Align (Dyer et al., 2013) and SyMGIZA++ (Junczys-Dowmunt and Sza, 2012), all employ this algorithm. GIZA++ in particular is frequently used in systems participating in many shared tasks (Goto et al., 2011; Cettolo et al., 2013; Bojar et al., 2013).\nHowever, the EM algorithm for WA is wellknown for introducing “garbage collector effects.” Rare words have a tendency to collect garbage, that is they have a tendency to be erroneously aligned to untranslated words (Brown et al., 1993a; Moore, 2004; Ganchev et al., 2008; V Graça et al., 2010). Figure 1(a) shows a real sentence pair, denoted s, from the GALE ChineseEnglish Word Alignment and Tagging Training corpus (GALE WA corpus)1 with it’s humanannotated word alignment. The Chinese word “HE ZHANG,” denoted wr, which means river custodian, only occurs once in the whole corpus. We performed EM training using GIZA++ on this corpus concatenated with 442,967 training sentence pairs from the NIST Open Machine Translation (OpenMT) 2006 evaluation2. The resulting alignment is shown in Figure 1(b). It can be seen that wr is erroneously aligned to multiple English words.\nTo find the cause of this, we checked the alignments in each iteration i of s, denoted ais. We found that in a1s , wr together with the other source-side words were aligned with uniform probability to all the target-side words since the alignment models provided no prior information. However, in a2s , wr became erroneously aligned,\n1Released by Linguistic Data Consortium, catalog number LDC2012T16, LDC2012T20, LDC2012T24 and LDC2013T05.\n2http://www.itl.nist.gov/iad/mig/ tests/mt/2006/\n1817\nbecause the alignment distribution3 of wr was only learned from a1s , thus consisted of non-zero values only for generating the target-side words in s. Therefore, the alignment probabilities from the rare word wr to the unaligned words in s were extraordinarily high, since almost all of the probability mass was distributed among them. In other words, the story behind these garbage collector effects is that erroneous alignments are able to provide support for themselves; the probability distribution learned only from s is re-applied to s. In this way, these “garbage collector effects” are a form of over-fitting.\nMotivated by this observation, we propose a leave-one-out EM algorithm for WA in this paper. Recently this technique has been applied to avoid over-fitting in kernel density estimation (Roux and Bach, 2011); instead of performing maximum likelihood estimation, maximum leaveone-out likelihood estimation is performed. Figure 1(c) shows the effect of using our technique on the example. The garbage collection has not occurred, and the alignment of the word “HE ZHANG” is identical to the human annotation."
  }, {
    "heading": "2 Related Work",
    "text": "The most related work to this paper is training phrase translation models with leave-one-out forced alignment (Wuebker et al., 2010; Wuebker et al., 2012). The differences are that their work operates at the phrase level, and their aim is to improve translation models; while our work operates at the word level, and our aim is to provide better word alignment. As word alignment is a foundation of most MT systems, our method have a wider application.\nRecently, better estimation methods during the maximization step of EM have been proposed to avoid the over-fitting in WA, such as using Kneser-Ney Smoothing to back-off the expected counts (Zhang and Chiang, 2014) or integrating the smoothed l0 prior to the estimation of probability (Vaswani et al., 2012). Our work differs from theirs by addressing the over-fitting directly in the EM algorithm by adopting a leave-one-out approach.\nBayesian methods (Gilks et al., 1996; Andrieu et al., 2003; DeNero et al., 2008; Neubig et al.,\n3The probability distribution of generating target language words from wr . The description here is only based on IBM model1 for simplicity, and the other alignment models are similar.\n(a)\n2011), also attempt to address the issue of overfitting, however EM algorithms related to the proposed method have been shown to be more efficient (Wang et al., 2014)."
  }, {
    "heading": "3 Methodology",
    "text": "This section first formulates the standard EM for WA, then presents the leave-one-out EM for WA, and finally briefly discusses handling singletons and effecient implementation. The main notation used in this section is shown in Table 1."
  }, {
    "heading": "3.1 Standard EM for IBM Models 1, 2 and HMM Model",
    "text": "To perform WA through EM, the parallel corpus is taken as observed data, the alignments are taken as latent data. In order to maximize the likelihood of the alignment model θ given the data S, the following two steps are conducted iteratively (Brown et al., 1993b; Och and Ney, 2000; Och and Ney, 2003),\nExpectation Step (E step): calculating the conditional probability of alignments for each sentence pair, P (a|s, θ) = ∏Jj=1 θali(aj |aj−1, I)θlex(fj |eaj ),(1) where θali(i|i′, I) is the alignment probability and θlex(f |e) is the translation probability. Note that\n(1) is a general form for IBM model 1, model 2 and the HMM model.\nMaximization step (M step): re-estimating the probability models,\nθali(i|i′, I) ← ∑\ns Ni|i′,I(s)∑ s Ni′,I(s)\n(2) θlex(f |e) ← ∑\ns Nf |e(s)∑ s ne(s)\n(3)\nwhere Ni′,I(s) is the marginal number of times ei′ is aligned to some foreign word if the length of e is I , or 0 otherwise; Ni|i′,I(s) is the marginal number of times the next alignment position after i′ is i in a if the length of e is I , or 0 otherwise; ne(s) is the count of e in e; Nf |e(s,a) is the marginal number of times e is aligned to f ."
  }, {
    "heading": "3.2 Leave-one-out EM for IBM Models 1, 2 and HMM Model",
    "text": "Leave-one-out EM for WA differs from standard EM in the way the alignment and translation probabilities are calculated. Each sentence pair will\nhave its own alignment and translation probability models calculated by excluding the sentence pair itself. More formally, leave-one-out EM for WA are formulated as follows,\nLeave-one-out E step: employing leave-oneout models for each s to calculate the conditional probability of alignments\nP (a|s, θs̄) = ∏J j=1 θ s̄ ali(aj |aj−1, I)θs̄lex(fj |eaj ),(4)\nwhere θs̄ali(i|i′, I) and θs̄lex(fj |eaj ) are the leaveone-out alignment probability and translation probability, respectively.\nLeave-one-out M step: re-estimating leaveone-out probability models,\nθs̄ali(i|i′, I) ← ∑ s′ 6=s Ni|i′,I(s ′)∑\ns′ 6=s Ni′,I(s′) (5) θs̄lex(f |e) ← ∑ s′ 6=s Nf |e(s ′)∑\ns′ 6=s ne(s′) . (6)"
  }, {
    "heading": "3.3 Standard EM for IBM Model 4",
    "text": "The framework of the standard EM for IBM Model 4 is similar with the one for IBM Models 1, 2 and HMM Model, but the calculation of alignment probability is more complicated.\nE step: calculating the conditional probability through the reverted alignment (Och and Ney, 2003),\nP (a|s, θ) = P (B0|B1, . . . , BI)· I∏\ni=1\nP (Bi|Bi−1, ei) · I∏\ni=1 ∏ j∈Bi θlex(fj |ei), (7)\nwhere B0 means the set of foreign words aligned with the empty word; P (B0|B1, . . . , BI) is assumed to be a binomial distribution for the size of B0 (Brown et al., 1993b) or an modified distribution to relieve deficiency (Och and Ney, 2003).\nThe distribution P (Bi|Bi−1, ei) is decomposed as\nP (Bi|Bi−1, ei) = θfer(φi|ei)· θhea(Bi,1 −Bρi |Eρi) · φi∏\nk=2\nθoth(Bi,k −Bi,k−1),\n(8)\nwhere θfer is a fertility model; θhea is a probability model for the head (first) aligned foreign word; θoth is a probability model for the other aligned foreign words. θhea is assumed to be conditioned\non the word class Eρi , following the paper of (Och and Ney, 2003) and the implementation of GIZA++ and CICADA.\nM step: re-estimating the probability models, θfer(φ|e) ← ∑\ns Nφ|e(s)∑ s ∑ φ′ Nφ′|e(s)\n(9)\nθhea(∆i|E) ← ∑ s N hea ∆i|E(s)∑\ns ∑ ∆i′ N hea ∆i′|E(s)\n(10)\nθoth(∆i) ← ∑ s N oth ∆i (s)∑\ns ∑ ∆i′ N oth ∆i′(s) , (11)\nwhere ∆i is a difference of the indexes of two foreign words."
  }, {
    "heading": "3.4 Leave-one-out EM for IBM Model 4",
    "text": "The leave-one-out treatment were applied to the three component probability models θfer, θhea and θoth of IBM model 4.\nLeave-one-out E step: calculating the conditional probability through leave-one-out probability models\nP (a|s, θs̄) = P (B0|B1, . . . , BI)· I∏\ni=1\nP s̄(Bi|Bi−1, ei) · I∏\ni=1 ∏ j∈Bi θs̄lex(fj |ei), (12)\nP s̄(Bi|Bi−1, ei) = θs̄fer(φi|ei)·\nθs̄hea(Bi,1 −Bρi |Eρi) · φi∏\nk=2\nθs̄oth(Bi,k −Bi,k−1).\n(13)\nLeave-one-out M step: re-estimating the leaveone-out probability models,\nθs̄fer(φ|e) ← ∑ s′ 6=s Nφ|e(s ′)∑\ns′ 6=s ∑ φ′ Nφ′|e(s′) (14)\nθs̄hea(∆i|E) ← ∑ s′ 6=s N hea ∆i|E(s\n′)∑ s′ 6=s ∑ ∆i′ N hea ∆i′|E(s ′) (15)\nθs̄oth(∆i) ← ∑ s′ 6=s N oth ∆i (s\n′)∑ s′ 6=s ∑ ∆i′ N oth ∆i′(s ′) . (16)"
  }, {
    "heading": "3.5 Handling Singletons",
    "text": "Singletons are the words that occur only once in corpora. Singletons cause problems when applying leave-one-out to lexicalized models such as the translation model θs̄lex and the fertility model θ s̄ fer. When calculating (6) and (14) for singletons, the\ndenominators become zero, thus the probabilities are undefined.\nFor singletons, there is no prior information to guide their alignment, so we back off to uniform distributions. In that case, the alignments are primarily determined by the rest of the sentence.\nIn addition, singletons can be in the target side of the translation model θs̄lex. In that case, the probabilities become zero. This is handled by setting a minimum probability value of 1.0× 10−12, which was decided by pilot experiments."
  }, {
    "heading": "3.6 Implementation Details",
    "text": "To alleviate memory requirements and increase speed, our implementation did not build or store the local alignment models explicitly for each sentence pair. The following formula was used to efficiently calculate (5), (6) and (14–16) to build temporary probability models,∑\ns′ 6=s Nx(s′) = ( ∑ s′ Nx(s′))−Nx(s), (17)\nwhere x is a alignment event. Our implementation maintained global counts of all alignment events ∑ s′ Nx(s\n′), and (considerably smaller) local counts Nx(s) from each sentence pair s.\nTake the translation model θs̄lex for example. For a sentence pair s = (f1 . . . fJ , e1 . . . eI), it is cauclulated as,\nθs̄lex(fj |ei) = ( ∑ s′ N(fj |ei)(s ′))−N(fj |ei)(s) ( ∑ s′ nei(s′))− nei(s) .\n(18)\nThe global counts to be maintained are∑ s′ N(fj |ei)(s\n′) and nei(s′), and the local counts are ∑ s N(fj |ei)(s) and nei(s). Therefore the memory cost is,\n|E| · (|F|+ 1) + ∑ s Is(Js + 1), (19)\nwhere |E| is the size of English vocabulary, |F| is the size of foreign language vocabulary, Is is the length of the English sentence of s, and Js is the length of the foreign sentence of s.\nThe calculation of the leave-one-out translation model is performed for each English word and foreign word in s. Therefore, the time cost is,∑\ns\nIs(Js + 1). (20)\nIn addition, because the local counts N(fj |ei)(s) and nei(s) are read in order, storing them in a external memory such as a hard disk will not slow down the running speed much. This will reduce the memory cost to\n|E| · (|F|+ 1). (21) This cost is independent to the number of sentence pairs4.\nThe speed of the proposed method can be boosted through parallelism. These calculations on each sentence pair can be performed independently. We found empirically that when our implementation of the proposed method is run on a 16-core computer, it finishes the task earlier than GIZA++5."
  }, {
    "heading": "4 Experiments",
    "text": "The proposed WA method was tested on two language pairs: Chinese-English and JapaneseEnglish (Table 2). Performance was measured both directly using the agreement with reference to manual WA annotations, and indirectly using the BLEU score in end-to-end machine translation tasks. GIZA++ and our own implementation of standard EM were used as baselines."
  }, {
    "heading": "4.1 Experimental Settings",
    "text": "The Chinese-English experimental data consisted of the GALE WA corpus and the OpenMT corpus. They are from the same domain, both contain newswire texts and web blogs. The OpenMT evaluation 2005 was used as a development set for MERT tuning (Och, 2003), and the OpenMT evaluation 2006 was used as a test set. The JapaneseEnglish experimental data was the Kyoto Free Translation Task (Neubig, 2011)6. The corpus contains a set of 1,235 sentence pairs that are manually word aligned.\nThe corpora were processed using a standard procedure for machine translation. The English texts were tokenized with the tokenization script released with Europarl corpus (Koehn, 2005) and converted to lowercase; the Chinese texts were segmented into words using the Stanford Word Segmenter (Xue et al., 2002)7; the Japanese texts\n4We found the memory of our server is large enough, so we did not implement it\n5We plan to make our code public available. 6http://www.phontron.com/kftt/ 7http://nlp.stanford.edu/software/\nsegmenter.shtml\nwere segmented into words using the Kyoto Text Analysis Toolkit (KyTea8). Sentences longer than 100 words or those with foreign/English word length ratios between larger than 9 were filtered out.\nGIZA++ was run with the default Moses settings (Koehn et al., 2007). The IBM model 1, HMM model, IBM model 3 and IBM model 4 were run with 5, 5, 3 and 3 iterations. We implemented the proposed leave-one-out EM and standard EM in IBM model 1, HMM model and IBM model 4. In the original work (Och and Ney, 2003) this combination of models achieved comparable performance to the default Moses settings. They were run with 5, 5 and 6 iterations.\nThe standard EM was re-implemented as a baseline to provide a solid basis for comparison, because GIZA++ contains many undocumented details. Our implementation is based on the toolkit of CICADA (Watanabe and Sumita, 2011; Watanabe, 2012; Tamura et al., 2013)9. We named the implemented aligner AGRIPPA, to support our inhouse decoders OCTAVIAN and AUGUSTUS.\nIn all experiments, WA was performed independently in two directions: from foreign languages to English, and from English to foreign languages. Then the grow-diag-final-and heuristic was used to combine the two alignments from both directions to yield the final alignments for evaluation (Och and Ney, 2000; Och and Ney, 2003)."
  }, {
    "heading": "4.2 Word Alignment Accuracy",
    "text": "Word alignment accuracy of the baseline and the proposed method is shown in Table 3 in terms of precision, recall and F1 (Och and Ney, 2003). The proposed method gave rise to higher quality alignments in all our experiments. The improvement in F1, precision and recall based on IBM Model 4 is in the range 8.3% to 9.1% compared with the GIZA++ baseline, and in the range 5.0% to 17.2% compared with our own baseline.\nThe most meaningful result comes from the comparison of the models trained using standard EM log-likelihood training, and the proposed EM leave-one-out log-likelihood training. These models are identical except for way in which the model likelihood is calculated. In all our experiments the proposed method gave rise to higher quality alignments. The standard EM implementation achieved\n8http://www.phontron.com/kytea/ 9http://www2.nict.go.jp/univ-com/multi trans/cicada/\nalignment performance approximately comparable to GIZA++, whereas the proposed method exceeded the performance of both implementations."
  }, {
    "heading": "4.3 End-to-end Translation Quality",
    "text": "BLEU scores achieved by the phrase-based and hierachical SMT systems10 which were trained from different alignment results, are shown in Table 4. Each experiment was conducted three times to mitigate the variance in the results due to MERT. The results show that the proposed alignment method achieved the highest BLEU score in all experiments. The improvement over the baseline is in range 0.03 to 1.03 for phrase-based systems, and ranged from 0.43 to 1.30 for hierarchical systems.\nHierarchical systems benifit more from the proposed method than phrase-based systems. We think this is because that hierarchical systems are more sensitive to word alignment quality than phrase-based systems. Phrase-based systems only\n10from the Moses toolkit\ntake contiguous parallel phrase pairs as translation rules, while hierarchical systems also use patterns made by subtracting (inner) short parallel phrases from (outer) longer parallel phrases. Both the outer and inner phrases typically need to be noisefree in order to produce high quality rules. This puts a high demand on the alignment quality."
  }, {
    "heading": "4.4 Effect of Training Corpus Size",
    "text": "Training corpora of different sizes were employed to perform unsupervised WA experiments and MT experiments (see Tables 5 and 6).\nThe training corpora were randomly sampled from the Chinese-English manual WA corpora and the parallel training corpus. The manual WA corpus has a priority for being sampled so that the gold WA annotation is available for MT experi-\nments. The settings of the unsupervised WA experiments and the MT experiments are the same with the previous experiments. In the WA experiments, GIZA++, our implemented standard EM and the proposed leave-one-out EM are applied to training corpora with the same parameter settings as the previous. In the MT experiments, the WA results of different methods and the gold WA (if available) are employed to extract translation rules; the rest settings including language models, development and test corpus, and parameters are the same as the previous.\nOn word alignment accuracy, the proposed method achieved improvements of F1 from 0.041 to 0.090 under the different training corpora (Table 5. The maximum improvement compared with GIZA++ is 0.069 when the training corpus has 4,000 sentence pairs. The maximum improvement compared with our own implement is 0.090 when the training corpus has 64,000 sentence pairs.\nFigure 2 shows that the extent of improvements slightly changes under different training corpora, but they are all quite stable and obvious.\nOn translation quality, the proposed method achieved improvements of BLEU under the different training corpora. The improvements ranged from 0.19 to 1.72 for phrase-based MT and ranged from 0.25 to 3.02 (see Table 5). The improvements are larger under smaller training corpora (see Figure 3).\nIn addition, the BLEUs achieved by the proposed method is close to the ones achieved by gold WA annotations. The proposed method slightly outperforms the gold WA annotations when using the full manual WA corpus of 18,057 sentence pairs.\n4.5 Comparison to l0-Normalization and Kneser-Ney Smoothing Methods\nThe proposed leave-one-word word alignment method was empirically compared to l0-normalized GIZA++ (Vaswani et al., 2012)11 and Kneser-Ney smoothed GIZA++ (Zhang and Chiang, 2014)12. l0-normalization and KneserNey smoothing methods are established methods to overcome the sparse problem. This enables the probability distributions on rare words to be estimated more effectively. In this way, these two GIZA++ variants are related to the proposed method.\nl0-normalized GIZA++ and Kneser-Ney smoothed GIZA++ were run with the same settings as GIZA++, which came from the default settings of MOSES. For the settings of l0-normalized GIZA++ that are not in common with GIZA++ were the default settings. As for Kneser-Ney smoothed GIZA++, the smooth switches of IBM models 1 – 4 and HMM model\n11http://www.isi.edu/˜avaswani/ giza-pp-l0.html\n12https://github.com/hznlp/giza-kn\nwere turned on.\nThe experimental results are presented in Table 7. The experiments were run on the ChineseEnglish language pair. The word alignment quality was evaluated separately for all words and for various levels of rare words. The leave-one-out method outperformed related methods in terms of precision, recall and F1 when evaluated on all words.\nRare words were categorized based on the number of occurences in the source-language text of the training data. The evaluations were carried out on the subset of alignment links that had a rare word on the source side. Table 7 presents the results for thresholds 1, 2, 5 and 10. The proposed method achieved much higher precision on rare words than the other methods, but performed poorly on recall. The Kneser-Ney Smoothed GIZA++ had higher recall. The explanation might be that the leave-one-out method punishes rare words more than the Kneser-Ney smoothing method, by totally removing the derived expected counts of current sentence pair from the alignment models. This leads to rare words being passively aligned. In other words, the leave-one-out method would align rare words unless the confidence is high. Therefore, we plan to seek a method to integrate Kneser-Ney smoothing into the proposed leave-one-out method in the future work.\nThe BLEU scores achieved by phrase-based SMT and hierarchical SMT for different alignment methods are presented in Table 7. The proposed method outperforms the other methods. The Kneser-Ney Smoothed GIZA++ performed the second best. We tried to further analyze the relation between word alignment and BLEU, but found the analysis was obscured by the many processing stages. These stages include paral-\nlel phrase extraction (or translation rule extraction from hierarchical SMT), log-linear model, MERT tuning and practical decoding where a lot of pruning happened."
  }, {
    "heading": "5 Conclusion",
    "text": "This paper proposes a leave-one-out EM algorithm for WA to overcome the over-fitting problem that occurs when using standard EM for WA. The experimental results on Chinese-English and Japanese-English corpora show that both the WA accuracy and the end-to-end translation are improved.\nIn addition, we have a interesting finding about the effect of manual WA annotations on training MT systems. In a Chinese-English parallel training corpus of 18,057 sentence pairs, the manual WA annotation outperformed the unsupervised WA results produced by standard EM algorithms. However, the unsupervised WA results produced by proposed leave-one-out EM algorithm outperformed the manual WA annotation.\nOur future work will focus on increasing the gains in end-to-end translation quality through the proposed leave-one-out aligner. It is a interesting question why GIZA++ achieved competitive BLEU scores though its alignment accuracy measured by F1 was substantially lower. The answer to this question which may reveal essence of good word alignment for MT and eventually help to improve MT. In addition, we plan to improve the proposed method by integrating Kneser-Ney smoothing."
  }, {
    "heading": "Acknowledgments",
    "text": "We appreciated the valuable comments from the reviewers."
  }],
  "year": 2015,
  "references": [{
    "title": "An introduction to MCMC for machine learning",
    "authors": ["Christophe Andrieu", "Nando De Freitas", "Arnaud Doucet", "Michael I. Jordan."],
    "venue": "Machine learning, 50(1-2):5–43.",
    "year": 2003
  }, {
    "title": "Findings of the 2013 workshop on statistical machine translation",
    "authors": ["Ondrej Bojar", "Christian Buck", "Chris Callison-Burch", "Christian Federmann", "Barry Haddow", "Philipp Koehn", "Christof Monz", "Matt Post", "Radu Soricut", "Lucia Specia."],
    "venue": "Proceedings of",
    "year": 2013
  }, {
    "title": "But dictionaries are data too",
    "authors": ["Peter F. Brown", "Stephen A. Della Pietra", "Vincent J. Della Pietra", "Meredith J. Goldsmith", "Jan Hajic", "Robert L. Mercer", "Surya Mohanty."],
    "venue": "Proceedings of the Workshop on Human Language Technology, HLT",
    "year": 1993
  }, {
    "title": "The mathematics of statistical machine translation: parameter estimation",
    "authors": ["Peter F. Brown", "Vincent J. Della Pietra", "Stephen A. Della Pietra", "Robert L. Mercer."],
    "venue": "Computational linguistics, 19(2):263–311.",
    "year": 1993
  }, {
    "title": "Report on the 10th IWSLT evaluation campaign",
    "authors": ["Mauro Cettolo", "Jan Niehues", "Sebastian Stüker", "Luisa Bentivogli", "Marcello Federico."],
    "venue": "Proceedings of the International Workshop on Spoken Language Translation, pages 29–38.",
    "year": 2013
  }, {
    "title": "Maximum likelihood from incomplete data via the EM algorithm",
    "authors": ["Arthur P. Dempster", "Nan M. Laird", "Donald B. Rubin."],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological), pages 1–38.",
    "year": 1977
  }, {
    "title": "Tailoring word alignments to syntactic machine translation",
    "authors": ["John DeNero", "Dan Klein."],
    "venue": "Proceedings of the 45th Annual Meeting on Association for Computational Linguistics, pages 17–24.",
    "year": 2007
  }, {
    "title": "Sampling alignment structure under a bayesian translation model",
    "authors": ["John DeNero", "Alexandre Bouchard-Côté", "Dan Klein."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 314–",
    "year": 2008
  }, {
    "title": "A simple, fast, and effective reparameterization of ibm model 2",
    "authors": ["Chris Dyer", "Victor Chahuneau", "Noah A Smith."],
    "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,",
    "year": 2013
  }, {
    "title": "Better alignments = better translations",
    "authors": ["Kuzman Ganchev", "Joao V. Graça", "Ben Taskar"],
    "venue": "Proceedings of the 46th Annual Meeting on Association for Computational Linguistics,",
    "year": 2008
  }, {
    "title": "Markov chain Monte Carlo in practice, volume 2",
    "authors": ["Walter R. Gilks", "Sylvia Richardson", "David J. Spiegelhalter."],
    "venue": "CRC press.",
    "year": 1996
  }, {
    "title": "Overview of the patent machine translation task at the NTCIR-9 workshop",
    "authors": ["Isao Goto", "Bin Lu", "Ka Po Chow", "Eiichiro Sumita", "Benjamin K Tsou."],
    "venue": "Proceedings of NTCIR, volume 9, pages 559–578.",
    "year": 2011
  }, {
    "title": "Symgiza++: Symmetrized word alignment models for machine translation",
    "authors": ["Marcin Junczys-Dowmunt", "Arkadiusz Sza."],
    "venue": "Pascal Bouvry, Mieczyslaw A. Klopotek, Franck Leprvost, Malgorzata Marciniak, Agnieszka Mykowiecka, and Hen-",
    "year": 2012
  }, {
    "title": "Moses: Open source toolkit for statistical machine translation",
    "authors": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"],
    "year": 2007
  }, {
    "title": "Europarl: A parallel corpus for statistical machine translation",
    "authors": ["Philipp Koehn."],
    "venue": "Proceedings of MT Summit, volume 5, pages 79–86.",
    "year": 2005
  }, {
    "title": "Alignment by agreement",
    "authors": ["Percy Liang", "Ben Taskar", "Dan Klein."],
    "venue": "Proceedings of the North American Chapter of the Association of Computational Linguistics: Human Language Technologies, pages 104–111. Association for Computational Lin-",
    "year": 2006
  }, {
    "title": "Improving IBM wordalignment model 1",
    "authors": ["Robert C. Moore."],
    "venue": "Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 518. Association for Computational Linguistics.",
    "year": 2004
  }, {
    "title": "An unsupervised model for joint phrase alignment and extraction",
    "authors": ["Graham Neubig", "Taro Watanabe", "Eiichiro Sumita", "Shinsuke Mori", "Tatsuya Kawahara."],
    "venue": "ACL, pages 632–641.",
    "year": 2011
  }, {
    "title": "The Kyoto free translation task",
    "authors": ["Graham Neubig."],
    "venue": "http://www.phontron.com/kftt.",
    "year": 2011
  }, {
    "title": "A comparison of alignment models for statistical machine translation",
    "authors": ["Franz Josef Och", "Hermann Ney."],
    "venue": "Proceedings of the 18th conference on Computational linguistics-Volume 2, pages 1086–1090. Association for Computational Linguis-",
    "year": 2000
  }, {
    "title": "A Systematic Comparison of Various Statistical Alignment Models",
    "authors": ["Franz Josef Och", "Hermann Ney."],
    "venue": "Computational Linguistics, 29(1):19–51.",
    "year": 2003
  }, {
    "title": "Minimum error rate training in statistical machine translation",
    "authors": ["Franz Josef Och."],
    "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 160–167. Association for Computational Linguistics.",
    "year": 2003
  }, {
    "title": "Local component analysis",
    "authors": ["Nicolas Le Roux", "Francis Bach."],
    "venue": "Technical report.",
    "year": 2011
  }, {
    "title": "Partof-speech induction in dependency trees for statistical machine translation",
    "authors": ["Akihiro Tamura", "Taro Watanabe", "Eiichiro Sumita", "Hiroya Takamura", "Manabu Okumura."],
    "venue": "Proceedings of the 51th Annual Meeting of the Association for Computa-",
    "year": 2013
  }, {
    "title": "Learning tractable word alignment models with complex constraints",
    "authors": ["João V Graça", "Kuzman Ganchev", "Ben Taskar."],
    "venue": "Computational Linguistics, 36(3):481–504.",
    "year": 2010
  }, {
    "title": "Smaller alignment models for better translations: unsupervised word alignment with the l0norm",
    "authors": ["Ashish Vaswani", "Liang Huang", "David Chiang."],
    "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics:",
    "year": 2012
  }, {
    "title": "Empirical study of unsupervised chinese word segmentation methods for smt on large-scale corpora",
    "authors": ["Xiaolin Wang", "Masao Utiyama", "Andrew Finch", "Eiichiro Sumita."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computa-",
    "year": 2014
  }, {
    "title": "Machine translation system combination by confusion forest",
    "authors": ["Taro Watanabe", "Eiichiro Sumita."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1249–1257. Associ-",
    "year": 2011
  }, {
    "title": "Optimized online rank learning for machine translation",
    "authors": ["Taro Watanabe."],
    "venue": "Proceedings of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 253–262. Association for Computational Lin-",
    "year": 2012
  }, {
    "title": "Training phrase translation models with leaving-one-out",
    "authors": ["Joern Wuebker", "Arne Mauser", "Hermann Ney."],
    "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 475–484. Association for Computa-",
    "year": 2010
  }, {
    "title": "Leave-one-out phrase model training for large-scale deployment",
    "authors": ["Joern Wuebker", "Mei-Yuh Hwang", "Chris Quirk."],
    "venue": "Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 460–467. Association for Computational Lin-",
    "year": 2012
  }, {
    "title": "Building a large-scale annotated chinese corpus",
    "authors": ["Nianwen Xue", "Fu-Dong Chiou", "Martha Palmer."],
    "venue": "Proceedings of the 19th International Conference on Computational Linguistics, pages 1–8. Association for Computational Linguistics.",
    "year": 2002
  }, {
    "title": "Kneser-ney smoothing on expected counts",
    "authors": ["Hui Zhang", "David Chiang."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 765–774, Baltimore, Maryland, June.",
    "year": 2014
  }],
  "id": "SP:3ad5aea3a98dbf00eb8800816040dbee88572f72",
  "authors": [{
    "name": "Xiaolin Wang",
    "affiliations": []
  }, {
    "name": "Masao Utiyama",
    "affiliations": []
  }, {
    "name": "Andrew Finch",
    "affiliations": []
  }, {
    "name": "Taro Watanabe",
    "affiliations": []
  }, {
    "name": "Eiichiro Sumita",
    "affiliations": []
  }],
  "abstractText": "Expectation-maximization algorithms, such as those implemented in GIZA++ pervade the field of unsupervised word alignment. However, these algorithms have a problem of over-fitting, leading to “garbage collector effects,” where rare words tend to be erroneously aligned to untranslated words. This paper proposes a leave-one-out expectationmaximization algorithm for unsupervised word alignment to address this problem. The proposed method excludes information derived from the alignment of a sentence pair from the alignment models used to align it. This prevents erroneous alignments within a sentence pair from supporting themselves. Experimental results on Chinese-English and Japanese-English corpora show that the F1, precision and recall of alignment were consistently increased by 5.0% – 17.2%, and BLEU scores of end-to-end translation were raised by 0.03 – 1.30. The proposed method also outperformed l0-normalized GIZA++ and Kneser-Ney smoothed GIZA++.",
  "title": "Leave-one-out Word Alignment without Garbage Collector Effects"
}