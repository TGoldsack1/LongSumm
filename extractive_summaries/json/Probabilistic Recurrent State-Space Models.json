{
  "sections": [{
    "heading": "1. Introduction",
    "text": "System identification, i.e. learning dynamics models from data (Ljung, 2010), is key in model-based control design (Aström & Murray, 2010; Camacho & Alba, 2013) and model-based reinforcement learning (RL) (Deisenroth & Rasmussen, 2011; Doerr et al., 2017b). State-space models (SSMs) are one popular class of representations for model learning (Billings, 2013), which describe a system with input ut, output yt, and a latent Markovian state xt. The transition model f , observation model g, process, and measurement noise t and γt form a discrete-time SSM\nxt+1 = f(xt,ut) + t ,\nyt = g(xt) + γt . (1)\n1Bosch Center for Artificial Intelligence, Renningen, Germany. 2Max Planck Institute for Intelligent Systems, Stuttgart/Tübingen, Germany. 3University of Southern California, Los Angeles, USA. 4Machine Learning and Robotics Lab, University of Stuttgart, Germany. Correspondence to: Andreas Doerr <andreasdoerr@gmx.net>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nIn real systems, the latent state xt can typically not be measured directly, but has to be inferred from a series of noisy output observations. Efficient methods exist for linear models (Van Overschee & De Moor, 2012) and non-linear, deterministic models (Hochreiter & Schmidhuber, 1997).\nProbabilistic models enable safe RL and alleviate model bias (Deisenroth & Rasmussen, 2011). Placing a Gaussian process (GP) prior on the unknown transition function f and potentially on the observation model g allows for Bayesian model learning, resulting in GP-SSMs. Robust training of these probabilistic, non-linear SSMs is a challenging and only partially solved problem, especially for higher dimensional systems (Frigola et al., 2013; Bayer & Osendorfer, 2014; Krishnan et al., 2015; Fraccaro et al., 2016; Eleftheriadis et al., 2017; Svensson & Schön, 2017). This paper proposes the probabilistic recurrent state-space model1 (PRSSM2). PR-SSM takes inspiration from RNN model learning. In particular, the transition model is unrolled over time, therefore accounting for temporal correlations whilst simultaneously allowing for learning by backpropagation through time. The proposed method enables probabilistic model predictions, inferring complex latent state distributions, and principled model complexity regularization. We propose an adapted form of a recognition model for the initial state, which facilitates scalability through batch learning and learning of slow or unstable system dynamics (cf. Sec. 5).\nIn summary, the key contributions of this paper are: • Combining gradient-based and sample-based inference\nfor efficient learning of nonlinear Gaussian process state-space models; • Tractable variational approximation, maintaining the true latent state posterior and temporal correlations; • Doubly stochastic inference scheme for scalability; • Recognition model, which allows for initializing the\nlatent state distribution and thus for robust training and prediction.\nTogether, these contributions allow for efficient and robust learning of the PR-SSM. The proposed framework is evaluated on a set of real-world system identification datasets and benchmarked against a range of state-of-the art methods.\n1Code available at: https://github.com/ boschresearch/PR-SSM .\n2Pronounced prism."
  }, {
    "heading": "2. Related Work",
    "text": "Modeling the behavior of systems with only partially observable states has been an active field of research for many years and several schools of thought have emerged. Representations range from SSMs (Van Overschee & De Moor, 2012) over Predictive State Representations (PSRs) (Littman & Sutton, 2002; Singh et al., 2003; Rudary & Singh, 2004) to autoregressive models (Murray-Smith & Girard, 2001; Girard et al., 2003; Likar & Kocijan, 2007; Billings, 2013), as well as hybrid versions combining these approaches (Mattos et al., 2015; 2016; Doerr et al., 2017a).\nAutoregressive (history-based) methods avoid the complex inference of a latent state and instead directly learn a mapping from a history of h past inputs and observations to the next observation, i.e. yt+1 = f(yt:t−h,ut:t−h). These models face the issue of learning from noise corrupted input data. Recent work addresses this problem by either actively accounting for input noise (McHutchon & Rasmussen, 2011) or reverting to a hybrid, autoregressive formulation in a latent, but noise free state (Mattos et al., 2016; Doerr et al., 2017a). Such models can be made deep and trained in a recurrent manner (Mattos et al., 2015).\nIn contrast, SSMs are based on a compact, Markovian state representation. Furthermore, they allow for the direct application of many existing control algorithms, which rely on the explicit representation of the latent state. Exact solutions for state inference and model learning for linear Gaussian SSMs are given by the well known Kalman filter/smoother (Kalman, 1960) and subspace identification (Van Overschee & De Moor, 2012). In the case of non-linear latent state transition dynamics, both deterministic and probabilistic variants are active fields of research.\nDeterministic variants such as Long Short-Term Memory (LSTM) models have been shown to be powerful representations for tasks such as natural language processing (Venugopalan et al., 2014) or text understanding (Sutskever et al., 2011). However, for the purpose of system identification and control, probabilistic predictions are often preferred to make model errors explicit (Deisenroth & Rasmussen, 2011). A variety of stochastic deep recurrent models has been presented based on Stochastic Gradient Variational Bayes (SGVB) (Bayer & Osendorfer, 2014; Krishnan et al., 2015; Watter et al., 2015; Chung et al., 2015; Archer et al., 2015; Karl et al., 2016; Fraccaro et al., 2016; Gemici et al., 2017). The PR-SSM inference is inspired by the learning procedure in these deep recurrent models while employing GPs as a principled way of model regularization. Both procedures share the explicit unrolling of transition and observation model. Errors between the predicted and the observed system output are propagated back over time. Therefore, the transition dynamics has to be inferred, but the latent state (distribution) is given implicitly. This way, the challenging\ninitialization and optimization of latent state variables is prevented. In contrast to deep recurrent models, the PR-SSM loss and model regularization is automatically obtained from the GP assumption. Furthermore, PR-SSMs obtain predictive distributions and the proposed initial state recognition model facilitates learning on shorter sub-trajectories and unstable systems, which is not possible in deep recurrent models.\nGP-SSMs are a popular class of probabilistic SSMs (Wang et al., 2008; Ko & Fox, 2009; Turner et al., 2010; Frigola et al., 2013; 2014; Eleftheriadis et al., 2017). The use of GPs allows for a fully Bayesian treatment of the modeling problem resulting in an automatic complexity trade-off, which regularizes the learning problem. Filtering and smoothing in GP-SSMs has already been covered extensively: deterministic (e.g. linearization) as well as stochastic (e.g. particles) methods are presented in (Ko & Fox, 2009; Deisenroth et al., 2012). These methods, however, assume an established system model, which is generally not available without prior knowledge. In this work, the latent state smoothing distribution is given implicitly and optimized jointly during model learning.\nApproaches to probabilistic GP-SSMs mainly differ in their approximations to the model’s joint distribution (e.g. when solving for the smoothing distribution or for the observation likelihood). One class of approaches aims to solve for the true distribution, which requires sample-based methods, e.g. Particle Markov Chain Monte Carlo (PMCMC), as in (Frigola et al., 2013; 2014). These methods are close to exact and thus are able to represent temporal correlations. However, they are computationally inefficient and intractable for higher latent state dimensions or larger datasets. A second class of approaches is based on variational inference and mean field approximations in the latent state (Mattos et al., 2015; Föll et al., 2017). These methods, however, operate on latent autoregressive models, which can be initialized by the observed output time series, such that the learned latent representation acts as a smoothed version of the observations. In Markovian latent spaces, no such prior information is available and therefore initialization is non-trivial. Model optimization based on mean field approximations empirically leads to highly suboptimal local solutions. Bridging the gap between both classes, recent methods strive to recover (temporal) latent state structure. In (Eleftheriadis et al., 2017), a linear, time-varying latent state structure is enforced as a tractable compromise between the true non-linear dependencies and no dependencies as in mean field variational inference. However, to facilitate learning, a more complex recognition model over the linear time-varying dynamics is required. In contrast, the proposed PR-SSM can efficiently incorporate the true dynamics by combining sampling- and gradient-based learning."
  }, {
    "heading": "3. Gaussian Process State-Space Model",
    "text": "This section presents the general model background for GPSSMs. Following a short recap of GPs in Sec. 3.1 and a specific sparse GP prior in Sec. 3.2, PR-SSM as one particular GP-SSM is introduced in Sec. 3.3. Inference on this model is detailed in Sec. 4."
  }, {
    "heading": "3.1. Gaussian Process",
    "text": "A GP (Williams & Rasmussen, 2005) is a distribution over functions f : RD → R that is fully defined by a mean function m(·) and covariance function k(·, ·). For each finite set of points X = [x1, . . . ,xN ] from the function’s domain, the corresponding function evaluations f = [f(x1), . . . , f(xN )] are jointly Gaussian as given by\np(f |X) = N (f |mX ,KX,X) , (2)\nwith mean vector mX having elements mi = m(xi) and covariance matrix KX,X with entries Kij = k(xi,xj). Given observed function values f at input locationsX , the GP predictive distribution at a new input location x∗ is obtained as the conditional distribution\np(f∗ | x∗,f ,X) = N (f∗ | µ, σ2), (3)\nwith posterior mean and variance\nµ = mx∗ + kx∗,XK −1 X,X(f −mX) , (4) σ2 = kx∗,x∗ − kx∗,XK−1X,XkX,x∗ , (5)\nwhere kA,B denotes the scalar or vector of covariances for each pair of elements inA andB. In this work, the squared exponential kernel with Automatic Relevance Determination (ARD) (Williams & Rasmussen, 2005) with hyperparameters θGP is employed. Due to the proposed samplingbased inference scheme (cf. Sec. 4), any other differentiable kernel might be incorporated instead."
  }, {
    "heading": "3.2. GP Sparsification",
    "text": "Commonly, the GP prediction in (3) is obtained by conditioning on all training data X , y. To alleviate the computational cost, several sparse approximations have been presented (Snelson & Ghahramani, 2006). By introducing P inducing GP targets z = [z1, . . . , zP ] at pseudo input points ζ = [ζ1, . . . , ζP ], which are jointly Gaussian with the latent function f , the true GP predictive distribution is approximated by conditioning only on this set of inducing points,\np(f∗ | x∗,f ,X) ≈ p(f∗ | x∗, z, ζ) , (6) p(z) = N (z |mζ ,Kζ,ζ) . (7)\nThe predicted function values consequently become mutually independent given the inducing points."
  }, {
    "heading": "3.3. PR-SSM Model Definition",
    "text": "The PR-SSM is built upon a GP prior on the transition function f(·) and a parametric observation model g(·). This is a common model structure, which can be assumed without loss of generality over (1), since any observation model can be absorbed into a sufficiently large latent state (FrigolaAlcade, 2015). Eliminating the non-parametric observation model, however, mitigates the problem of ‘severe nonidentifiability’ between transition model f(·) and observation model g(·) (Frigola et al., 2014). Independent GP priors are employed for each latent state dimension d given individual inducing points ζd and zd.\nIn the following derivations, the system’s latent state, input and output at time t are denoted by xt ∈ RDx , ut ∈ RDu , and yt ∈ RDy , respectively. The shorthand x̂t = (xt,ut) denotes the transition model’s input at time t. The output of the transition model is denoted by ft+1 = f(x̂t). A time series of observations from time a to time b (including) is abbreviated by ya:b (analogously for the other model variables).\nThe joint distribution of all PR-SSM random variables is given by\np(y1:T ,x1:T ,f2:T , z) = [ T∏ t=1 p(yt | xt) ] p(x1)p(z) (8)[\nT∏ t=2 p(xt | ft)p(ft | x̂t−1, z)\n] ,\nwhere p(ft | x̂t−1, z) = ∏Dx d=1 p(ft,d | x̂t−1, zd) and z ≡ [z1, . . . zDx ]. A graphical model of the resulting PRSSM is shown in Fig. 1.\nThe individual contributions to (8) are given by the observation model and the transition model, which are now described in detail. The observation model is governed by\np(yt | xt) = N (yt | g(xt), diag(σ2y,1, . . . , σ2y,Dy )), (9)\nIn particular, in our experiments, we employed a parametric observation model\ng(xt) = Cxt . (10)\nThe matrixC is chosen to select theDy first entries of xt by defining C := [I,0] ∈ RDy×Dx with I being the identity matrix. This model is suitable for observation spaces that are low-dimensional compared to the latent state dimensionality, i.e. Dy < Dx, which is often the case for physical systems with a restricted number of sensors. The first Dy latent state dimensions can therefore be interpreted as noise free sensor measurements. For high-dimensional observation spaces (e.g. images), a more involved, given observation model (e.g. a pretrained neural network) may be seamlessly\nincorporated into the presented framework as long as g(·) is differentiable.\nProcess noise is modeled as\np(xt | ft) = N (xt | ft, diag(σ2x,1, . . . , σ2x,Dx)) . (11)\nThe transition dynamics is described independently for each latent state dimension d by p(ft,d | x̂t−1, zd)p(zd). This probability is given by the sparse GP prior (7) and predictive distribution (6), where x∗ = x̂t and f∗ = ft,d. The initial system state distribution p(x1) is unknown and has to be estimated."
  }, {
    "heading": "4. PR-SSM Inference",
    "text": "Computing the log likelihood or a posterior based on (8) is generally intractable due to the nonlinear GP dynamics model in the latent state. However, the log marginal likelihood log p(y1:T ) (evidence) can be bounded from below by the Evidence Lower BOound (ELBO) (Blei et al., 2017). This ELBO is derived via Jensen’s inequality by introducing a computationally simpler, variational distribution q(x1:T ,f2:T , z) to approximate the model’s true posterior distribution p(x1:T ,f2:T , z | y1:T ) (cf. eq. (8)). In contrast to previous work (Frigola et al., 2014; Mattos et al., 2015; Eleftheriadis et al., 2017), the proposed approximation explicitly incorporates the true temporal correlations in the latent state, whilst being scalable to large datasets. Previous work based on sequential Monte Carlo methods (Frigola et al., 2013; Svensson & Schön, 2017) already allowed for temporal correlations but required computationally challenging resampling in each timestep. The inference scheme is inspired by doubly stochastic variational inference for deep GPs as presented in (Salimbeni & Deisenroth, 2017)."
  }, {
    "heading": "4.1. Variational Sparse GP",
    "text": "PR-SSM employs a variational sparse GP (Titsias, 2009) based on a variational distribution q(z) on the GP’s inducing outputs as previously used in (Frigola et al., 2014; Eleftheriadis et al., 2017). Eliminating the inducing outputs, however, results in dependencies between inducing outputs and data which, in turn, leads to a complexity of O(NP 2), where\nN is the number of data points and P the number of inducing points (Titsias, 2009). Unfortunately, this complexity is still prohibitive for large datasets. Therefore, we resort to an explicit representation of the variational distribution over inducing outputs as previously proposed in (Hensman et al., 2013). This explicit representation enables scalability by utilizing stochastic gradient-based optimization since individual GP predictions become independent given the explicit inducing points. Following a mean-field variational approximation the inducing output distribution is given as q(z) = ∏Dx d=1N (zd | µd,Σd) for each latent state dimension d with diagonal variance Σd. Marginalizing out the inducing outputs, the GP predictive distribution is obtained as Gaussian with mean and variance given by\nµ = mx̂t +α(x̂t)(µd −mζd) , σ2 = kx̂t,x̂t −α(x̂t)(Kζd,ζd − Σd)α(x̂t)T ,\nα(x̂t) := kx̂t,ζdK −1 ζd,ζd .\n(12)"
  }, {
    "heading": "4.2. Variational Approximation",
    "text": "In previous work (Mattos et al., 2015), a factorized variational distribution is considered based on a mean-field approximation for the latent states x1:T . Their variational distribution is given by\nq(x1:T ,f2:T , z) =[ Dx∏ d=1 q(zd) [ T∏ t=2 p(ft,d | x̂t−1, zd) ]][ T∏ t=1 q(xt) ] .\nThis choice, however, leads to several caveats: (i) The number of model parameters grows linearly with the length of the time series since each latent state is parametrized by its individual distribution q(xt) for every time step. (ii) Initializing the latent state is non-trivial since the true, underlying observation mapping is generally unknown and non-bijective. (iii) The model design does not represent correlations between time steps. Instead, these correlations are only introduced by enforcing pairwise couplings during the optimization process. The first two problems have been addressed in (Mattos et al., 2015; Eleftheriadis et al., 2017) by introducing a recognition model, e.g. a Bi-RNN3, which acts as a smoother which can be learned through backpropagation and which allows to obtain the latent states given the input/output sequence.\nThe issue of representing correlations between time steps, however, is currently an open problem which we aim to address with our proposed model structure. Properly representing these correlations is a crucial step in making the\n3A bi-directional RNN operates on a sequence from left to right and vice versa to obtain predictions based on past and future inputs.\noptimization problem tractable in order to learn GP-SSMs for complex systems.\nFor PR-SSM, the variational distribution is given by\nq(x1:T ,f2:T , z) = (13) T∏ t=2 [ p(xt | ft) Dx∏ d=1 [p(ft,d | x̂t−1, zd)q(zd)] ] q(x1) ,\nwith\nq(x1)=N (x1 | µx1 ,Σx1) , q(zd)=N (zd | µd,Σd) .\nIn contrast to previous work, the proposed variational distribution does not factorize over the latent state but takes into account the true transition model, based on the sparse GP approximation from (8). In previous work, stronger approximations have been required to achieve an analytically tractable ELBO. This work, however, deals with the more complex distribution by combining sampling and gradientbased methods.\nIn (Frigola et al., 2014), the variational distribution over inducing outputs has been optimally eliminated. This leads to a smoothing problem in a second system requiring computationally expensive, e.g. sample-based, smoothing methods. Instead, we approximate the distribution by a Gaussian, which is the optimal solution in case of sparse GP regression (cf. (Titsias, 2009)).\nThe PR-SSM model parameters include the variational parameters for the initial state and inducing outputs and hyperparameters, such as inducing inputs, noise parameters and GP kernel parameters: θPR-SSM = (µx1 ,Σx1 ,µ1:Dx ,Σ1:Dx , ζ1:Dx , σ 2 x,1:Dx , σ 2 y,1:Dy , θGP,1:Dx). Note that in the PR-SSM, the number of parameters grows only with the number of latent dimensions, but not with the length of the time series."
  }, {
    "heading": "4.3. Variational Evidence Lower Bound",
    "text": "Following standard variational inference techniques (Blei et al., 2017), the ELBO is given by\nlog p(y1:T )≥Eq(x1:T ,f2:T ,z) [ log p(y1:T ,x1:T ,f2:T ,z)\nq(x1:T ,f2:T , z) ] =: LPR-SSM . (14)\nMaximizing the ELBO is equivalent to minimizing KL(q(x1:T ,f2:T , z) ‖ p(x1:T ,f2:T , z | y1:T )) (Blei et al., 2017), therefore this is a way to optimize the approximated model parameter distribution with respect to the intractable, true model parameter posterior.\nBased on (8) and (13) and using standard variational calcu-\nlus, the ELBO (14) can be transformed into\nLPR-SSM = T∑ t=1 Eq(xt)[log p(yt | xt)]\n− Dx∑ d=1 KL(q(zd) ‖ p(zd; ζd)) , (15)\nwith q(xt) defined in Sec. 4.4. The first part is the expected log-likelihood of the observed system outputs y based on the observation model and the variational latent state distribution q(xt). This term captures the capability of the learned latent state model to explain the observed system behavior. The second term is a regularizer on the inducing output distribution that penalizes deviations from the GP prior. Due to this term, PR-SSM automatically trades off data fit against model complexity. A detailed derivation of the ELBO can be found in the supplementary material."
  }, {
    "heading": "4.4. Stochastic Gradient ELBO Optimization",
    "text": "Training the proposed PR-SSM requires maximizing the ELBO in (15) with respect to the model parameters θPR-SSM. While the second term, as KL between two Gaussian distributions, can be easily computed, the first term requires evaluation of an expectation with respect to the latent state distribution q(xt), given by\nq(xt) = ∫ t∏ τ=2 [p(xτ | fτ )p(fτ | x̂τ−1, z)]\nq(x1)q(z)dx1:t−1df2:tdz . (16)\nSince the true non-linear, latent dynamics is maintained in the variational approximation (13), analytic evaluation of (16) is still intractable. Because of the latent state’s Markovian structure, the marginal latent state distribution q(xt) at time t is conditionally independent of past time steps, given the previous state distribution q(xt−1) and the explicit representation of GP inducing points. This enables a differentiable, sampling-based estimation of the expectation term. Samples x̃t from (16) can be obtained by recursively drawing from the sparse GP posterior in (12) for t = 1, . . . , T . Drawing samples from a Gaussian distribution can be made differentiable with respect to its parameters µd, σ2d using the re-parametrisation trick (Kingma & Welling, 2013). The gradient can be propagated back through time due to this re-paramatrization and unrolling of the latent state. An unbiased estimator of the first term in the ELBO in (15) is given by\nEq(xt)[log(yt | xt)] ≈ 1\nN N∑ i=1 log p(yt | x̃(i)t ) . (17)\nBased on the stochastic ELBO evaluation, analytic gradients of (15) can be derived to facilitate stochastic gradientdescent-based model optimization."
  }, {
    "heading": "4.5. Model Predictions",
    "text": "After model optimization based on the ELBO (15), model predictions for a new input sequence u1:T and initial latent state x1 can be obtained based on the approximate, variational posterior distribution in (13). In contrast to (Mattos et al., 2015), no approximations such as moment matching are required for model predictions. Instead, the complex latent state distribution is approximated based on samples from (16). The predicted observation distribution can then be computed from the latent distribution according to the observation model in (9). Instead of a fixed, uninformative initial latent state, a learned recognition model (cf. Sec. 5 for details) can be utilized to find a more informative model initialization."
  }, {
    "heading": "5. Extensions for Large Datasets",
    "text": "Optimizing the ELBO (15) based on the full gradient is prohibitive for large datasets and long trajectories. Instead, a stochastic optimization scheme based on mini-batches of sub-trajectories is introduced.\nDirectly optimizing the initial latent state distribution q(x1) for each sub-trajectory would lead to a full parametrization of the latent state which is undesirable as described in Sec. 4.2. Instead, we propose a parametric recognition model, which initializes the latent state q(x1). In recent work on SSMs (Mattos et al., 2015; Eleftheriadis et al., 2017), a recognition model is introduced to parametrize the smoothing distribution p(x1:T | y1:T ,u1:T ). We propose a\nsimilar approach, but only to model the initial latent state\nq(x1) = N (x1 | µ1,Σ1) ≈ q(x1 | y1:L,u1:L) , (18) µ1,Σ1 = h(y1:L,u1:L; θrecog) . (19)\nThe initial latent state distribution is approximated by a Gaussian, where mean and variance are modeled by a recognition model h. The recognition model acts as a smoother, operating on the first L elements of the system input/output data to infer the first latent state. Instead of directly optimizing q(x1) during training, errors are propagated back into the recognition model h, which is parametrized by θrecog.\nAdditionally, the proposed recognition model can also be used to predict behavior on test data, where the initial latent state is not known."
  }, {
    "heading": "6. Experimental Evaluation",
    "text": "In the following, we present insights into the PR-SSM optimization schemes, comparisons to state-of-the-art model learning methods and a large scale experiment."
  }, {
    "heading": "6.1. PR-SSM Learning",
    "text": "For small datasets (i.e. short training trajectory lengths), the model can be trained based on the full gradient of the ELBO in (15). A comparison of the model predictions before and after training with the full ELBO gradient is shown in Fig. 2.\nEmpirically, three major shortcomings of the full gradientbased optimization schemes are observed: (i) Computing the full gradient for long trajectories is expensive and prone\nto the well-known problems of exploding and vanishing gradients (Pascanu et al., 2013). (ii) An uninformative initial state is prohibitive for unstable systems or systems with slowly decaying initial state transients. (iii) Momentumbased optimizers (e.g. Adam) exhibit fragile optimization performance and are prone to overfitting.\nThe proposed method addresses these problems by employing the stochastic ELBO gradient based on minibatches of sub-trajectories and the initial state recognition model (cf. Sec. 5). Fig. 3 visualizes the initial state distribution q(x1) and the corresponding predictive output distribution p(y1) for the fully trained model based on the full gradient (top row), as well as for the model based on the stochastic gradient and recognition model (bottom row). The transient dynamics and the associated model uncertainty is clearly visible for the first 15 time steps until the initial transient decays and approaches the true system behavior. In contrast, the learned recognition model almost perfectly initializes the latent state, leading to much smaller deviations in the predicted observations and far less predictive uncertainty. Notice how the recognition model is most certain about the distribution of the first latent state dimension (orange), which is directly coupled to the observation through the parametric observation model (cf. (9)). The uncertainty for the remaining, latent states, in contrast, is slightly higher.\nComparing the full ELBO gradient-based model learning and the stochastic version with the recognition model, the stochastic model learning is far more robust and counteracts the overfitting tendencies in the full gradient-based model learning. A comparison of the model learning progress for both methods is depicted in the supplementary material. Due to the improved optimization robustness and the applicability to larger datasets, the stochastic, recognition-modelbased optimization scheme is employed for the model learning benchmark presented in the next section. Empirically, the cost of the proposed sampling scheme is much lower\ncompared to methods employing SMC for sampling the full model posterior. In the experiments, 50 latent state samples were employed (details in the supplementary material)."
  }, {
    "heading": "6.2. Model Learning Benchmark",
    "text": "The performance of PR-SSM is assessed in comparison to state-of-the-art model learning methods on several realworld datasets as previously utilized by (Mattos et al., 2015). The suite of reference methods is composed of: One-step ahead autoregressive GP models: GP-FITC (Snelson & Ghahramani, 2006) and NIGP (McHutchon & Rasmussen, 2011). Multi-step-ahead autoregressive and recurrent GP models in latent space: REVARB based on 1, respectively 2, hidden layers (Mattos et al., 2015) and MSGP (Doerr et al., 2017a). GP-SSMs, based on a full Markovian state: SS-GP-SSM (Svensson & Schön, 2017) and the proposed PR-SSM. Currently, no published and runnable code exists for the model learning frameworks presented in (Turner et al., 2010; Frigola et al., 2013; 2014; Eleftheriadis et al., 2017). To enable a fair comparison of the methods’ performance and robustness, whitened data, a default configuration across tasks and a predefined amount of input/output data for initialization is employed. The presented results are therefore not directly comparable to previous work, where different data pre/postprocessing or method configurations are employed. A more thorough evaluation, which matches the published results from previous work, as well as experimental details are given in the supplementary material.\nThe benchmark results are summarized in Tab. 1. A detailed visualization of the resulting model predictions on the Drives dataset is shown in Fig. 4. For the one-step-ahead models (GP-NARX, NIGP), two variants are used to obtain long-term predictive distributions: Propagating the mean (no uncertainty propagation) and approximating the true posterior by a Gaussian using exact moment matching (Girard et al., 2003). The results show that PR-SSM consistently\noutperforms the SS-GP-SSM learning method. Similarly, performance is improved in comparison to baseline methods (GP-NARX and NIGP). In the ensemble of models based on long-term optimized autoregressive structure (REVARB, MSGP), no method is clearly superior. However, the performance of PR-SSM is consistently strong. The probabilistic methods results are competitive or improve over the performance of deterministic RNN/LSTM models, as shown in (Mattos et al., 2015). Note that PR-SSM demonstrates robust model learning performance across all datasets."
  }, {
    "heading": "6.3. Large Scale Experiment",
    "text": "To evaluate the scalability, results are provided for the forward dynamics model of the SARCOS 7 degree of freedom robotic arm. The task is characterized by 60 experiments of length 337 (≈ 20.000 datapoints), 7 input, and 7 output\ndimensions. PR-SSM is set up with a latent state dimensionality Dx = 14. From the set of reference methods, only GP-NARX can be adapted to run efficiently on this dataset without major effort (details are given in the supplementary material). A visualization of the model predictions is shown in Fig 5 and prediction RMSEs are listed in Tab. 1. The results show that PR-SSM is able to learn robustly and accurately for all system outputs from all experimental data. In contrast, the GP-NARX baseline achieves worse predictions and fails to predict the remaining five joints (not shown)."
  }, {
    "heading": "7. Conclusion",
    "text": "In this work, we presented Probabilistic Recurrent StateSpace Models (PR-SSM) as a novel model structure and efficient inference scheme for learning probabilistic, Markovian state-space models. Based on GP priors and doubly stochastic variational inference, a novel model optimization criterion is derived, which is closely related to the one of powerful, but deterministic, RNNs or LSTMs. By maintaining the true latent state distribution and thereby enabling long-term gradients, efficient inference in latent space becomes feasible. Furthermore, a novel recognition model enables learning of unstable or slow dynamics as well as scalability to large datasets. Robustness, scalability and high performance in model learning is demonstrated on realworld datasets in comparison to state-of-the-art methods.\nA limitation of PR-SSM is its dependency on an a-priori fixed latent state dimensionality. This shortcoming could potentially be resolved by a sparsity enforcing latent state prior, which would suppress unnecessary latent state dimensions."
  }, {
    "heading": "Acknowledgements",
    "text": "This research was supported in part by National Science Foundation grants IIS-1205249, IIS-1017134, EECS0926052, the Office of Naval Research, the Okawa Foundation, the Max-Planck-Society, and the Cyber Valley initiative."
  }],
  "year": 2018,
  "references": [{
    "title": "Black box variational inference for state space models",
    "authors": ["E. Archer", "I.M. Park", "L. Buesing", "J. Cunningham", "L. Paninski"],
    "venue": "arXiv preprint arXiv:1511.07367,",
    "year": 2015
  }, {
    "title": "Feedback systems: an introduction for scientists and engineers",
    "authors": ["K.J. Aström", "R.M. Murray"],
    "venue": "Princeton university press,",
    "year": 2010
  }, {
    "title": "Learning stochastic recurrent networks",
    "authors": ["J. Bayer", "C. Osendorfer"],
    "venue": "arXiv preprint arXiv:1411.7610,",
    "year": 2014
  }, {
    "title": "Nonlinear system identification: NARMAX methods in the time, frequency, and spatio-temporal domains",
    "authors": ["S.A. Billings"],
    "year": 2013
  }, {
    "title": "Variational inference: A review for statisticians",
    "authors": ["D.M. Blei", "A. Kucukelbir", "J.D. McAuliffe"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2017
  }, {
    "title": "A recurrent latent variable model for sequential data",
    "authors": ["J. Chung", "K. Kastner", "L. Dinh", "K. Goel", "A.C. Courville", "Y. Bengio"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2015
  }, {
    "title": "PILCO: A modelbased and data-efficient approach to policy search",
    "authors": ["M.P. Deisenroth", "C.E. Rasmussen"],
    "venue": "In Proceedings of the 28th International Conference on Machine Learning (ICML),",
    "year": 2011
  }, {
    "title": "Robust filtering and smoothing with gaussian processes",
    "authors": ["M.P. Deisenroth", "R.D. Turner", "M.F. Huber", "U.D. Hanebeck", "C.E. Rasmussen"],
    "venue": "IEEE Transactions on Automatic Control,",
    "year": 2012
  }, {
    "title": "Optimizing long-term predictions for model-based policy search",
    "authors": ["A. Doerr", "C. Daniel", "D. Nguyen-Tuong", "A. Marco", "S. Schaal", "M. Toussaint", "S. Trimpe"],
    "venue": "In Conference on Robot Learning (CORL),",
    "year": 2017
  }, {
    "title": "Model-based policy search for automatic tuning of multivariate PID controllers",
    "authors": ["A. Doerr", "D. Nguyen-Tuong", "A. Marco", "S. Schaal", "S. Trimpe"],
    "venue": "In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA),",
    "year": 2017
  }, {
    "title": "Identification of Gaussian process state space models",
    "authors": ["S. Eleftheriadis", "T. Nicholson", "M. Deisenroth", "J. Hensman"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2017
  }, {
    "title": "Deep recurrent Gaussian process with variational sparse spectrum approximation",
    "authors": ["R. Föll", "B. Haasdonk", "M. Hanselmann", "H. Ulmer"],
    "venue": "arXiv preprint arXiv:1711.00799,",
    "year": 2017
  }, {
    "title": "Sequential neural models with stochastic layers",
    "authors": ["M. Fraccaro", "S.K. Sønderby", "U. Paquet", "O. Winther"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2016
  }, {
    "title": "Bayesian inference and learning in Gaussian process state-space models with particle MCMC",
    "authors": ["R. Frigola", "F. Lindsten", "T.B. Schön", "C.E. Rasmussen"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2013
  }, {
    "title": "Variational Gaussian process state-space models",
    "authors": ["R. Frigola", "Y. Chen", "C.E. Rasmussen"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2014
  }, {
    "title": "Bayesian time series learning with Gaussian processes",
    "authors": ["R. Frigola-Alcade"],
    "venue": "University of Cambridge,",
    "year": 2015
  }, {
    "title": "Generative temporal models with memory",
    "authors": ["M. Gemici", "Hung", "C.-C", "A. Santoro", "G. Wayne", "S. Mohamed", "D.J. Rezende", "D. Amos", "T. Lillicrap"],
    "venue": "arXiv preprint arXiv:1702.04649,",
    "year": 2017
  }, {
    "title": "Gaussian processes for big data",
    "authors": ["J. Hensman", "N. Fusi", "N.D. Lawrence"],
    "venue": "arXiv preprint arXiv:1309.6835,",
    "year": 2013
  }, {
    "title": "LSTM can solve hard long time lag problems",
    "authors": ["S. Hochreiter", "J. Schmidhuber"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 1997
  }, {
    "title": "A new approach to linear filtering and prediction problems",
    "authors": ["R. Kalman"],
    "venue": "Journal of Basic Engineering,",
    "year": 1960
  }, {
    "title": "Deep variational bayes filters: Unsupervised learning of state space models from raw data",
    "authors": ["M. Karl", "M. Soelch", "J. Bayer", "P. van der Smagt"],
    "venue": "In International Conference on Learning Representations,",
    "year": 2016
  }, {
    "title": "Auto-encoding variational bayes",
    "authors": ["D.P. Kingma", "M. Welling"],
    "venue": "arXiv preprint arXiv:1312.6114,",
    "year": 2013
  }, {
    "title": "GP-BayesFilters: Bayesian filtering using Gaussian process prediction and observation models",
    "authors": ["J. Ko", "D. Fox"],
    "venue": "Autonomous Robots,",
    "year": 2009
  }, {
    "title": "Predictive control of a gas–liquid separation plant based on a Gaussian process model",
    "authors": ["B. Likar", "J. Kocijan"],
    "venue": "Computers & chemical engineering,",
    "year": 2007
  }, {
    "title": "Predictive representations of state",
    "authors": ["M.L. Littman", "R.S. Sutton"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2002
  }, {
    "title": "Perspectives on system identification",
    "authors": ["L. Ljung"],
    "venue": "Annual Reviews in Control,",
    "year": 2010
  }, {
    "title": "Recurrent Gaussian processes",
    "authors": ["C.L.C. Mattos", "Z. Dai", "A. Damianou", "J. Forth", "G.A. Barreto", "N.D. Lawrence"],
    "venue": "arXiv preprint arXiv:1511.06644,",
    "year": 2015
  }, {
    "title": "Latent autoregressive Gaussian processes models for robust system",
    "authors": ["C.L.C. Mattos", "A. Damianou", "G.A. Barreto", "N.D. Lawrence"],
    "venue": "identification. IFACPapersOnLine,",
    "year": 2016
  }, {
    "title": "Gaussian process training with input noise",
    "authors": ["A. McHutchon", "C.E. Rasmussen"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2011
  }, {
    "title": "Gaussian process priors with ARMA noise models",
    "authors": ["R. Murray-Smith", "A. Girard"],
    "venue": "In Irish Signals and Systems Conference,",
    "year": 2001
  }, {
    "title": "On the difficulty of training recurrent neural networks",
    "authors": ["R. Pascanu", "T. Mikolov", "Y. Bengio"],
    "venue": "In Proceedings of the 30th International Conference on Machine Learning (ICML),",
    "year": 2013
  }, {
    "title": "A nonlinear predictive state representation",
    "authors": ["M.R. Rudary", "S.P. Singh"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2004
  }, {
    "title": "Doubly stochastic variational inference for deep Gaussian processes",
    "authors": ["H. Salimbeni", "M. Deisenroth"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2017
  }, {
    "title": "Learning predictive state representations",
    "authors": ["S.P. Singh", "M.L. Littman", "N.K. Jong", "D. Pardoe", "P. Stone"],
    "venue": "In Proceedings of the 20th International Conference on Machine Learning (ICML),",
    "year": 2003
  }, {
    "title": "Sparse Gaussian processes using pseudo-inputs",
    "authors": ["E. Snelson", "Z. Ghahramani"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2006
  }, {
    "title": "Generating text with recurrent neural networks",
    "authors": ["I. Sutskever", "J. Martens", "G.E. Hinton"],
    "venue": "In Proceedings of the 28th International Conference on Machine Learning (ICML),",
    "year": 2011
  }, {
    "title": "A flexible state–space model for learning nonlinear dynamical systems",
    "authors": ["A. Svensson", "T.B. Schön"],
    "year": 2017
  }, {
    "title": "Variational learning of inducing variables in sparse Gaussian processes",
    "authors": ["M.K. Titsias"],
    "venue": "In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2009
  }, {
    "title": "State-space inference and learning with Gaussian processes",
    "authors": ["R. Turner", "M. Deisenroth", "C. Rasmussen"],
    "venue": "In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2010
  }, {
    "title": "Subspace identification for linear systems: Theory - Implementation - Applications",
    "authors": ["P. Van Overschee", "B. De Moor"],
    "venue": "Springer Science & Business Media,",
    "year": 2012
  }, {
    "title": "Translating videos to natural language using deep recurrent neural networks",
    "authors": ["S. Venugopalan", "H. Xu", "J. Donahue", "M. Rohrbach", "R. Mooney", "K. Saenko"],
    "venue": "arXiv preprint arXiv:1412.4729,",
    "year": 2014
  }, {
    "title": "Gaussian process dynamical models for human motion",
    "authors": ["J.M. Wang", "D.J. Fleet", "A. Hertzmann"],
    "venue": "IEEE transactions on pattern analysis and machine intelligence,",
    "year": 2008
  }, {
    "title": "Embed to control: A locally linear latent dynamics model for control from raw images",
    "authors": ["M. Watter", "J. Springenberg", "J. Boedecker", "M. Riedmiller"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2015
  }, {
    "title": "Gaussian processes for machine learning",
    "authors": ["C.K. Williams", "C.E. Rasmussen"],
    "year": 2005
  }],
  "id": "SP:2a13822d53e9f43cf057ac231e6c2b7b1db0e95f",
  "authors": [{
    "name": "Andreas Doerr",
    "affiliations": []
  }, {
    "name": "Christian Daniel",
    "affiliations": []
  }, {
    "name": "Martin Schiegg",
    "affiliations": []
  }, {
    "name": "Duy Nguyen-Tuong",
    "affiliations": []
  }, {
    "name": "Stefan Schaal",
    "affiliations": []
  }, {
    "name": "Marc Toussaint",
    "affiliations": []
  }, {
    "name": "Sebastian Trimpe",
    "affiliations": []
  }],
  "abstractText": "State-space models (SSMs) are a highly expressive model class for learning patterns in time series data and for system identification. Deterministic versions of SSMs (e.g., LSTMs) proved extremely successful in modeling complex time series data. Fully probabilistic SSMs, however, are often found hard to train, even for smaller problems. We propose a novel model formulation and a scalable training algorithm based on doubly stochastic variational inference and Gaussian processes. This combination allows efficient incorporation of latent state temporal correlations, which we found to be key to robust training. The effectiveness of the proposed PR-SSM is evaluated on a set of real-world benchmark datasets in comparison to state-of-the-art probabilistic model learning methods. Scalability and robustness are demonstrated on a high dimensional problem.",
  "title": "Probabilistic Recurrent State-Space Models"
}