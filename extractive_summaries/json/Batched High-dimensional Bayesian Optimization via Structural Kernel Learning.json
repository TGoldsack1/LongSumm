{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Optimization is one of the fundamental pillars of modern machine learning. Considering that most modern machine learning methods involve the solution of some optimization problem, it is not surprising that many recent breakthroughs in this area have been on the back of more effective techniques for optimization. A case in point is deep learning, whose rise has been mirrored by the development of numerous techniques like batch normalization.\nWhile modern algorithms have been shown to be very\n*Equal contribution 1Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Massachusetts, USA 2DeepMind, London, UK. Correspondence to: Zi Wang <ziw@csail.mit.edu>, Chengtao Li <ctli@mit.edu>, Stefanie Jegelka <stefje@csail.mit.edu>, Pushmeet Kohli <pushmeet@google.com>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\neffective for convex optimization problems defined over continuous domains, the same cannot be stated for nonconvex optimization, which has generally been dominated by stochastic techniques. During the last decade, Bayesian optimization has emerged as a popular approach for optimizing black-box functions. However, its applicability is limited to low-dimensional problems because of computational and statistical challenges that arise from optimization in high-dimensional settings.\nIn the past, these two problems have been addressed by assuming a simpler underlying structure of the black-box function. For instance, Djolonga et al. (2013) assume that the function being optimized has a low-dimensional effective subspace, and learn this subspace via low-rank matrix recovery. Similarly, Kandasamy et al. (2015) assume additive structure of the function where different constituent functions operate on disjoint low-dimensional subspaces. The subspace decomposition can be partially optimized by searching possible decompositions and choosing the one with the highest GP marginal likelihood (treating the decomposition as a hyper-parameter of the GP). Fully optimizing the decomposition is, however, intractable. Li et al. (2016) extended (Kandasamy et al., 2015) to functions with a projected-additive structure, and approximate the projective matrix via projection pursuit with the assumption that the projected subspaces have the same and known dimensions. The aforementioned approaches share the computational challenge of learning the groups of decomposed subspaces without assuming the dimensions of the subspaces are known. Both (Kandasamy et al., 2015) and subsequently (Li et al., 2016) adapt the decomposition by maximizing the GP marginal likelihood every certain number of iterations. However, such maximization is computationally intractable due to the combinatorial nature of the partitions of the feature space, which forces prior work to adopt randomized search heuristics.\nIn this paper, we develop a new formulation of Bayesian optimization specialized for high dimensions. One of the key contributions of this work is a new formulation that interprets prior work on high-dimensional Bayesian optimization (HDBO) through the lens of structured kernels, and places a prior on the kernel structure. Thereby, our\nformulation enables simultaneous learning of the decomposition of the function domain.\nPrior work on latent decomposition of the feature space considers the setting where exploration/evaluation is performed once at a time. This approach makes Bayesian optimization time-consuming for problems where a large number of function evaluations need to be made, which is the case for high dimensional problems. To overcome this restriction, we extend our approach to a batched version that allows multiple function evaluations to be performed in parallel (Desautels et al., 2014; González et al., 2016; Kathuria et al., 2016). Our second contribution is an approach to select the batch of evaluations for structured kernel learning-based HDBO.\nOther Related Work. In the past half century, a series of different acquisition functions was developed for sequential BO in relatively low dimensions (Kushner, 1964; Moc̆kus, 1974; Srinivas et al., 2012; Hennig & Schuler, 2012; Hernández-Lobato et al., 2014; Kawaguchi et al., 2015; Wang et al., 2016a; Kawaguchi et al., 2016; Wang & Jegelka, 2017). More recent developments address high dimensional BO by making assumptions on the latent structure of the function to be optimized, such as lowdimensional structure (Wang et al., 2016b; Djolonga et al., 2013) or additive structure of the function (Li et al., 2016; Kandasamy et al., 2015). Duvenaud et al. (2013) explicitly search over kernel structures.\nWhile the aforementioned methods are sequential in nature, the growth of computing power has motivated settings where at once a batch of points is selected for observation (Contal et al., 2013; Desautels et al., 2014; González et al., 2016; Snoek et al., 2012; Wang et al., 2017). For example, the UCB-PE algorithm (Contal et al., 2013) exploits that the posterior variance of a Gaussian Process is independent of the function mean. It greedily selects points with the highest posterior variance, and is able to update the variances without observations in between selections. Similarly, B-UCB (Desautels et al., 2014) greedily chooses points with the highest UCB score computed via the out-dated function mean but up-to-date function variances. However, these methods may be too greedy in their selection, resulting in points that lie far from an optimum. More recently, Kathuria et al. (2016) tries to resolve this issue by sampling the batch via a diversity-promoting distribution for better randomized exploration, while Wang et al. (2017) quantifies the goodness of the batch with a submodular surrogate function that trades off quality and diversity."
  }, {
    "heading": "2. Background",
    "text": "Let f : X → R be an unknown function and we aim to optimize it over a compact set X ⊆ RD. Within as few\nfunction evaluations as possible, we want to find\nf(x∗) = max x∈X f(x).\nFollowing (Kandasamy et al., 2015), we assume a latent decomposition of the feature dimensions [D] = {1, . . . , D} into disjoint subspaces, namely, ⋃M m=1Am = [D] and Ai ∩ Aj = ∅ for all i 6= j, i, j ∈ [D]. Further, f can be decomposed into the following additive form:\nf(x) = ∑\nm∈[M ]\nfm(x Am).\nTo make the problem tractable, we assume that each fm is drawn independently from GP(0, k(m)) for all m ∈ [M ]. The resulting f will also be a sample from a GP: f ∼ GP(µ, k), where the priors are µ(x) = ∑ m∈[M ] µm(x Am)\nand k(x, x′) = ∑ m∈[M ] k (m)(xAm , x′ Am). Let Dn = {(xt, yt)}nt=1 be the data we observed from f , where yt ∼ N (f(xt), σ). The log data likelihood for Dn is\nlog p(Dn|{k(m), Am}m∈[M ]) (2.1)\n= −1 2 (yT(Kn + σ 2I)−1y + log |Kn + σ2I|+ n log 2π)\nwhere Kn = [∑M m=1 k (m)(xAmi , x Am j ) ] i≤n,j≤n is the gram matrix associated with Dn, and y = [yt]t≤n are the concatenated observed function values. Conditioned on the observations Dn, we can infer the posterior mean and covariance function of the function component f (m) to be\nµ(m)n (x Am) = k(m)n (x Am)T(Kn + σ 2I)−1y,\nk(m)n (x Am , x′ Am) = k(m)(xAm , x′ Am)\n− k(m)n (xAm)T(Kn + σ2I)−1k(m)n (x′ Am),\nwhere k(m)n (xAm) = [k(m)(xAmt , x Am)]t≤n.\nWe use regret to evaluate the BO algorithms, both in the sequential and the batch selection case. For the sequential selection, let r̃t = maxx∈X f(x) − f(xt) denote the immediate regret at iteration t. We are interested in both the averaged cumulative regret RT = 1T ∑ t r̃t and the simple regret rT = mint≤T r̃t for a total number of T iterations. For batch evaluations, r̃t = maxx∈X ,b∈[B] f(x) − f(xt,b) denotes the immediate regret obtained by the batch at iteration t. The averaged cumulative regret of the batch setting is RT = 1T ∑ t r̃t, and the simple regret rT = mint≤T r̃t. We use the averaged cumulative regret in the bandit setting, where each evaluation of the function incurs a cost. If we simply want to optimize the function, we use the simple regret to capture the minimum gap between the best point found and the global optimum of the black-box function f . Note that the averaged cumulative regret upper bounds the simple regret."
  }, {
    "heading": "3. Learning Additive Kernel Structure",
    "text": "We take a Bayesian view on the task of learning the latent structure of the GP kernel. The decomposition of the input space X will be learned simultaneously with optimization as more and more data is observed. Our generative model draws mixing proportions θ ∼ DIR(α). Each dimension j is assigned to one out of M groups via the decomposition assignment variable zj ∼ MULTI(θ). The objective function is then f(x) = ∑M m=1 fm(x\nAm), where Am = {j : zj = m} is the set of support dimensions for function fm, and each fm is drawn from a Gaussian Process. Finally, given an input x, we observe y ∼ N (f(x), σ). Figure 1 illustrates the corresponding graphical model.\nGiven the observed data Dn = {(xt, yt)}nt=1, we obtain a posterior distribution over possible decompositions z (and mixing proportions θ) that we will include later in the BO process:\np(z, θ | Dn;α) ∝ p(Dn | z)p(z | θ)p(θ;α).\nMarginalizing over θ yields the posterior distribution of the decomposition assignment\np(z | Dn;α) ∝ p(Dn | z) ∫ p(z | θ)p(θ;α) dθ\n∝ p(Dn | z) Γ( ∑ m αm)\nΓ(D + ∑ m αm) ∏ m Γ(|Am|+ αm) Γ(αm)\nwhere p(Dn|z) is the data likelihood (2.1) for the additive GP given a fixed structure defined by z. We learn the posterior distribution for z via Gibbs sampling, choose the decomposition among the samples that achieves the highest data likelihood, and then proceed with BO. The Gibbs sampler repeatedly draws coordinate assignments zj according to\np(zj = m | z¬j ,Dn; α) ∝ p(Dn | z)p(zj | z¬j) ∝ p(Dn | z)(|Am|+ αm) ∝ eφm ,\nwhere\nφm = − 1\n2 yT(K(zj=m)n + σ 2I)−1y\n− 1 2 log |K(zj=m)n + σ2I|+ log(|Am|+ αm)\nand K(zj=m)n is the gram matrix associated with the observations Dn by setting zj = m. We can use the Gumbel trick to efficiently sample from this categorical distribution. Namely, we sample a vector of i.i.d standard Gumbel variables ωi of length M , and then choose the sampled decomposition assignment zj = arg maxi≤M φi + ωi.\nWith a Dirichlet process, we could make the model nonparametric and the number M of possible groups in the decomposition infinite. Given that we have a fixed number of input dimension D, we set M = D in practice."
  }, {
    "heading": "4. Diverse Batch Sampling",
    "text": "In real-world applications where function evaluations translate into time-intensive experiments, the typical sequential exploration strategy – observe one function value, update the model, then select the next observation – is undesirable. Batched Bayesian Optimization (BBO) (Azimi et al., 2010; Contal et al., 2013; Kathuria et al., 2016) instead selects a batch of B observations to be made in parallel, then the model is updated with all simultaneously.\nExtending this scenario to high dimensions, two questions arise: (1) the acquisition function is expensive to optimize and (2), by itself, does not sufficiently account for exploration. The additive kernel structure improves efficiency for (1). For batch selection (2), we need an efficient strategy that enourages observations that are both informative and non-redundant. Recent work (Contal et al., 2013; Kathuria et al., 2016) selects a point that maximizes the acquisition function, and adds additional batch points via a diversity criterion. In high dimensions, this diverse selection becomes expensive. For example, if each dimension has a finite number of possible values1, the cost of sampling batch points via a Determinantal Point Process (DPP), as proposed in (Kathuria et al., 2016), grows exponentially with the number of dimensions. The same obstacle arises with the approach by Contal et al. (2013), where points are selected greedily. Thus, naı̈ve adoptions of these approaches in our setting would result in intractable algorithms. Instead, we propose a general approach that explicitly takes advantage of the structured kernel to enable relevant, non-redundant high-dimensional batch selection.\nWe describe our approach for a single decomposition sampled from the posterior; it extends to a distribution of decompositions by sampling a set of decompositions from the posterior and then sampling points for each decomposition individually. Given a decomposition z, we define a separate Determinantal Point Process (DPP) on each group of Am dimensions. A set S of points in the subspace R|Am| is sampled with probability proportional to det(K(m)n (S)),\n1While we use this discrete categorical domain to illustrate the batch setting, our proposed method is general and is applicable to continuous box-constrained domains.\nwhere K(m)n is the posterior covariance matrix of the mth group given n observations, and K(S) is the submatrix of K with rows and columns indexed by S. Assuming the group sizes are upper-bounded by some constant, sampling from each such DPP individually implies an exponential speedup compared to using the full kernel.\nSampling vs. Greedy Maximization The determinant det(K (m) n (S)) measures diversity, and hence the DPP assigns higher probability to diverse subsets S. An alternative to sampling is to directly maximize the determinant. While this is NP-hard, a greedy strategy gives an approximate solution, and is used in (Kathuria et al., 2016), and in (Contal et al., 2013) as Pure Exploration (PE). We too test this strategy in the experiments. In the beginning, if the GP is not approximating the function well, then greedy may perform no better than a stochastic combination of coordinates, as we observe in Fig. 6.\nSample Combination Now we have chosen a diverse subset Xm = {x(m)i }i∈[B−1] ⊂ R|Am| of size (B − 1) for each group Am. We need to combine these subspace points to obtain B − 1 final batch query points in RD. A simple way to combine samples from each group is to do it randomly without replacement, i.e., we sample one x (m) i from each Xm uniformly randomly without replacement, and combine the parts, one for each m ∈ [M ], to get one sample in RD. We repeat this procedure until we have (B − 1) points. This retains diversity across the batch of samples, since the samples are diverse within each group of features.\nBesides this random combination, we can also combine samples greedily. We define a quality function ψ(m)t for each group m ∈ [M ] at time t, and combine samples to maximize this quality function. Concretely, for the first point, we combine the maximizers x(m)∗ = arg maxx(m)∈Xm ψ (m) t (x\n(m)) from each group. We remove those used parts, Xm ← Xm\\{x(m)∗ }, and repeat the procedure until we have (B − 1) samples. In each iteration, the sample achieving the highest quality score gets selected, while diversity is retained.\nBoth selection strategies can be combined with a wide range of existing quality and acquisition functions.\nAdd-UCB-DPP-BBO We illustrate the above framework with GP-UCB (Srinivas et al., 2012) as both the acquisition and quality functions. The Upper Confidence Bound (f (m)t ) + and Lower Confidence Bound (f (m)t ) − with parameter βt for group m at time t are\n(f (m) t ) +(x) = µ (m) t−1(x) + β 1/2 t σ (m) t (x); (4.1)\n(f (m) t ) −(x) = µ (m) t−1(x)− β 1/2 t σ (m) t (x),\nand combine the expected value µ(m)t−1(x) of f (m) t with the uncertainty β1/2t σ (m) t (x). We set both the acquisition function and quality function ψ(m)t to be (f (m) t )\n+ for group m at time t.\nTo ensure that we select points with high acquisition function values, we follow (Contal et al., 2013; Kathuria et al., 2016) and define a relevance region R(m)t for each group m as\nR(m)t = {x ∈ Xm |\nµ (m) t−1(x) + 2 √ β (m) t+1σ (m) t−1(x) ≥ (y (m) t ) • } ,\nwhere (y(m)t ) • = maxx(m)∈Xm(f (m) t ) −(x(m)). We then use R(m)t as the ground set to sample with PE/DPP. The full algorithm is shown in the appendix."
  }, {
    "heading": "5. Empirical Results",
    "text": "We empirically evaluate our approach in two parts: First, we verify the effectiveness of using our Gibbs sampling algorithm to learn the additive structure of the unknown function, and then we test our batch BO for high dimensional problems with the Gibbs sampler. Our code is available at https://github.com/zi-w/ Structural-Kernel-Learning-for-HDBBO."
  }, {
    "heading": "5.1. Effectiveness of Decomposition Learning",
    "text": "We first probe the effectiveness of using the Gibbs sampling method described in Section 3 to learn the decomposition of the input space. More details of the experiments including sensitivity analysis for α can be found in the appendix.\nRecovering Decompositions First, we sample test functions from a known additive Gaussian Process prior with zero-mean and isotropic Gaussian kernel with bandwidth = 0.1 and scale = 5 for each function component. For D = 2, 5, 10, 20, 50, 100 input dimensions, we randomly sample decomposition settings that have at least two groups in the decomposition and at most 3 dimensions in each group.\nWe set the burn-in period to be 50 iterations, and the total number of iterations for Gibbs sampling to be 100. In Tables 1 and 2, we show two quantities that are closely related\nto the learned empirical posterior of the decompositions with different numbers of randomly sampled observed data points (N ). Table 1 shows the probability of two dimensions being correctly grouped together by Gibbs sampling in each iteration of Gibbs sampling after the burn-in period, namely, ( ∑ i<j≤D 1zgi≡z g j∧zi≡zj )/( ∑ i<j≤D 1zi≡zj ). Table 2 reports the probability of two dimensions being correctly separated in each iteration of Gibbs sampling after the burn-in period, namely, ( ∑ i<j≤D 1zgi 6=z g j∧zi 6=zj )/( ∑ i<j≤D 1zi 6=zj ). The results show that the more data we observe, the more accurate the learned decompositions are. They also suggest that the Gibbs sampling procedure can converge to the ground truth decomposition with enough data for relatively small numbers of dimensions. The higher the dimension, the more data we need to recover the true decomposition.\nEffectiveness of Learning Decompositions for Bayesian Optimization To verify the effectiveness of the learned decomposition for Bayesian optimization, we tested on 2, 10, 20 and 50 dimensional functions sampled from a zero-mean Add-GP with randomly sampled decomposi-\ntion settings (at least two groups, at most 3 dimensions in each group) and isotropic Gaussian kernel with bandwidth = 0.1 and scale = 5. Each experiment was repeated 50 times. An example of a 2-dimensional function component is shown in the appendix. For Add-GPUCB, we used β(m)t = |Am| log 2t for lower dimensions (D = 2, 5, 10), and β(m)t = |Am| log 2t/5 for higher dimensions (D = 20, 30, 50). We show parts of the results on averaged cumulative regret and simple regret in Fig. 2, and the rest in the appendix. We compare Add-GP-UCB with known additive structure (Known), no partitions (NP), fully partitioned with one dimension for each group (FP)\nand the following methods of learning the decomposition: Gibbs sampling (Gibbs), randomly sampling the same number of decompositions sampled by Gibbs and select the one with the highest data likelihood (PL-1), randomly sampling 5 decompositions and selecting the one with the highest data likelihood (PL-2). For the latter two learning methods are referred to as “partial learning” in (Kandasamy et al., 2015). The learning of the decomposition is done every 50 iterations. Fig. 3 shows the improvement of learning decompositions with Gibbs over optimizing without partitions (NP).\nOverall, the results show that Gibbs outperforms both of the partial learning methods, and for higher dimensions, Gibbs is sometimes even better than Known. Interestingly, similar results can be found in Fig. 3 (c) of (Kandasamy et al., 2015), where different decompositions than the ground truth may give better simple regret. We conjecture that this is because Gibbs is able to explore more than Known, for two reasons:\n1. Empirically, Gibbs changes the decompositions across iterations, especially in the beginning. With fluctuating partitions, even exploitation leads to moving around, because the supposedly “good” points are influenced by the partition. The result is an implicit “exploration” effect that is absent with a fixed partition.\n2. Gibbs sometimes merges “true” parts into larger parts. The parameter βt in UCB depends on the size of the part, |Am|(log 2t)/5 (as in (Kandasamy et al., 2015)). Larger parts hence lead to larger βt and hence more exploration.\nOf course, more exploration is not always better, but Gibbs was able to find a good balance between exploration and exploitation, which leads to better performance. Our preliminary experiments indicate that one solution to ensure that the ground truth decomposition produces the best result is to tune βt. Hyperparameter selection (such as choosing βt) for BO is, however, very challenging and an active topic of research (e.g. (Wang et al., 2016a)).\nNext, we test the decomposition learning algorithm on a real-world function, which returns the distance between a designated goal location and two objects being pushed by two robot hands, whose trajectory is determined by 14 parameters specifying the location, rotation, velocity, moving direction etc. This function is implemented with a physics engine, the Box2D simulator (Catto, 2011). We use add-GP-UCB with different ways of setting the additive structure to tune the parameters for the robot hand so as to push the object closer to the goal. The regrets are shown in Fig. 4. We observe that the performance of learning the decomposition with Gibbs dominates all existing\nalternatives including partial learning. Since the function we tested here is composed of the distance to two objects, there could be some underlying additive structure for this function in certain regions of the input space, e.g. when the two robots hands are relatively distant from each other so that one of the hands only impacts one of the objects. Hence, it is possible for Gibbs to learn a good underlying additive structure and perform effective BO with the structures it learned."
  }, {
    "heading": "5.2. Diverse Batch Sampling",
    "text": "Next, we probe the effectiveness of batch BO in high dimensions. In particular, we compare variants of the AddUCB-DPP-BBO approach outlined in Section 4, and a baseline:\n• Rand: All batch points are chosen uniformly at random from X .\n• Batch-UCB-*: *∈ {PE,DPP}. All acquisition functions are UCB (Eq. 4.1). Exploration is done via PE or DPP with posterior covariance kernels for each group. Combination is via sampling without replacement.\n• *-Fnc: *∈ {Batch-UCB-PE,Batch-UCB-DPP}. All quality functions are also UCB’s, and combination is done by maximizing the quality functions.\nA direct application of existing batch selection methods is very inefficient in the high-dimensional settings where they differ more, algorithmically, from our approach that ex-\nploits decompositions. Hence, we only compare to uniform sampling as a baseline.\nEffectiveness We tested on 2, 10, 20 and 50-dimensional functions sampled the same way as in Section 5.1; we assume the ground-truth decomposition of the feature space is known. Since Rand performs the worst, we show relative averaged cumulative regret and simple regret of all methods compared to Rand in Fig. 5. Results for absolute values of regrets are shown in the appendix. Each experiment was repeated for 20 times. For all experiments, we set βmt = |Am| log 2t and B = 10. All diverse batch sampling methods perform comparably well and far better than Rand, although there exist slight differences. While in lower dimensions (D ∈ {2, 10}), Batch-UCB-PE-Fnc performs among the best, in higher dimensions (D ∈ {20, 50}), Batch-UCB-DPP-Fnc performs better than (or comparable to) all other variants. We will see a larger performance gap in later real-world experiments, showing that biasing the combination towards higher quality functions while retaining diversity across the batch of samples provides a better exploration-exploitation trade-off.\nFor a real-data experiment, we tested the diverse batch sampling algorithms for BBO on the Walker function which returns the walking speed of a three-link planar bipedal walker implemented in Matlab (Westervelt et al., 2007). We tune 25 parameters that may influence the walking speed, including 3 sets of 8 parameters for the ODE solver and 1 parameter specifying the initial velocity of the stance leg. We discretize each dimension into 40 points, resulting in a function domain of |X | = 4025. This size is very inefficient for existing batch sampling techniques. We learn the additive structure via Gibbs sampling and sample batches of size B = 5. To further improve efficiency, we limit the maximum size of each group to 2. The regrets for all methods are shown in Fig. 6. Again, all diverse batch sampling methods outperform Rand by a large gap. Moreover, Batch-UCB-DPP-Fnc is a bit better than other variants, suggesting that a selection by quality functions is useful.\nBatch Sizes Finally, we show how the batch size B affects the performance of the proposed methods. We test the algorithms on the 14-dimensional Robot dataset with B ∈ {5, 10}. The regrets are shown in Fig. 4. With larger batches, the differences between the batch selection approaches become more pronounced. In both settings, Batch-UCB-DPP-Fnc performs a bit better than other variants, in particular with larger batch sizes."
  }, {
    "heading": "6. Conclusion",
    "text": "In this paper, we propose two novel solutions for high dimensional BO: inferring latent structure, and combining it with batch Bayesian Optimization. The experimental results demonstrate that the proposed techniques are effective at optimizing high-dimensional black-box functions.\nMoreover, their gain over existing methods increases as the dimensionality of the input grows. We believe that these results have the potential to enable the increased use of Bayesian optimization for challenging black-box optimization problems in machine learning that typically involve a large number of parameters."
  }, {
    "heading": "Acknowledgements",
    "text": "We gratefully acknowledge support from NSF CAREER award 1553284, NSF grants 1420927 and 1523767, from ONR grant N00014-14-1-0486, and from ARO grant W911NF1410433. We thank MIT Supercloud and the Lincoln Laboratory Supercomputing Center for providing computational resources. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of our sponsors."
  }],
  "year": 2017,
  "references": [{
    "title": "Batch Bayesian optimization via simulation matching",
    "authors": ["Azimi", "Javad", "Fern", "Alan", "Xiaoli Z"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2010
  }, {
    "title": "Box2D, a 2D physics engine for games",
    "authors": ["Catto", "Erin"],
    "year": 2011
  }, {
    "title": "High-dimensional Gaussian process bandits",
    "authors": ["Djolonga", "Josip", "Krause", "Andreas", "Cevher", "Volkan"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2013
  }, {
    "title": "Structure discovery in nonparametric regression through compositional kernel search",
    "authors": ["Duvenaud", "David", "Lloyd", "James Robert", "Grosse", "Roger", "Tenenbaum", "Joshua B", "Ghahramani", "Zoubin"],
    "venue": "In International Conference on Machine Learning (ICML),",
    "year": 2013
  }, {
    "title": "Batch Bayesian optimization via local penalization",
    "authors": ["González", "Javier", "Dai", "Zhenwen", "Hennig", "Philipp", "Lawrence", "Neil D"],
    "venue": "International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2016
  }, {
    "title": "Entropy search for information-efficient global optimization",
    "authors": ["Hennig", "Philipp", "Schuler", "Christian J"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "Predictive entropy search for efficient global optimization of black-box functions",
    "authors": ["Hernández-Lobato", "José Miguel", "Hoffman", "Matthew W", "Ghahramani", "Zoubin"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2014
  }, {
    "title": "High dimensional Bayesian optimisation and bandits via additive models",
    "authors": ["Kandasamy", "Kirthevasan", "Schneider", "Jeff", "Poczos", "Barnabas"],
    "venue": "In International Conference on Machine Learning (ICML),",
    "year": 2015
  }, {
    "title": "Batched Gaussian process bandit optimization via determinantal point processes",
    "authors": ["Kathuria", "Tarun", "Deshpande", "Amit", "Kohli", "Pushmeet"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2016
  }, {
    "title": "Bayesian optimization with exponential convergence",
    "authors": ["Kawaguchi", "Kenji", "Kaelbling", "Leslie Pack", "LozanoPérez", "Tomás"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2015
  }, {
    "title": "Global continuous optimization with error bound and fast convergence",
    "authors": ["Kawaguchi", "Kenji", "Maruyama", "Yu", "Zheng", "Xiaoyu"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 2016
  }, {
    "title": "A new method of locating the maximum point of an arbitrary multipeak curve in the presence of noise",
    "authors": ["Kushner", "Harold J"],
    "venue": "Journal of Fluids Engineering,",
    "year": 1964
  }, {
    "title": "High dimensional Bayesian optimization via restricted projection pursuit models",
    "authors": ["Li", "Chun-Liang", "Kandasamy", "Kirthevasan", "Póczos", "Barnabás", "Schneider", "Jeff"],
    "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2016
  }, {
    "title": "On Bayesian methods for seeking the extremum",
    "authors": ["J. Moc̆kus"],
    "venue": "In Optimization Techniques IFIP Technical Conference,",
    "year": 1974
  }, {
    "title": "Practical Bayesian optimization of machine learning algorithms",
    "authors": ["Snoek", "Jasper", "Larochelle", "Hugo", "Adams", "Ryan P"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 2012
  }, {
    "title": "Information-theoretic regret bounds for Gaussian process optimization in the bandit setting",
    "authors": ["Srinivas", "Niranjan", "Krause", "Andreas", "Kakade", "Sham M", "Seeger", "Matthias W"],
    "venue": "IEEE Transactions on Information Theory,",
    "year": 2012
  }, {
    "title": "Max-value entropy search for efficient Bayesian optimization",
    "authors": ["Wang", "Zi", "Jegelka", "Stefanie"],
    "venue": "In International Conference on Machine Learning (ICML),",
    "year": 2017
  }, {
    "title": "Optimization as estimation with Gaussian processes in bandit settings",
    "authors": ["Wang", "Zi", "Zhou", "Bolei", "Jegelka", "Stefanie"],
    "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2016
  }, {
    "title": "Focused model-learning and planning for non-Gaussian continuous state-action systems",
    "authors": ["Wang", "Zi", "Jegelka", "Stefanie", "Kaelbling", "Leslie Pack", "Pérez", "Tomás Lozano"],
    "venue": "In International Conference on Robotics and Automation (ICRA),",
    "year": 2017
  }, {
    "title": "Bayesian optimization in a billion dimensions via random embeddings",
    "authors": ["Wang", "Ziyu", "Hutter", "Frank", "Zoghi", "Masrour", "Matheson", "David", "de Feitas", "Nando"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 2016
  }, {
    "title": "Feedback control of dynamic bipedal robot locomotion, volume 28",
    "authors": ["Westervelt", "Eric R", "Grizzle", "Jessy W", "Chevallereau", "Christine", "Choi", "Jun Ho", "Morris", "Benjamin"],
    "venue": "CRC press,",
    "year": 2007
  }],
  "id": "SP:deabd068c486782bf58a0e2447ebaaa3bae8857a",
  "authors": [{
    "name": "Zi Wang",
    "affiliations": []
  }, {
    "name": "Chengtao Li",
    "affiliations": []
  }, {
    "name": "Stefanie Jegelka",
    "affiliations": []
  }, {
    "name": "Pushmeet Kohli",
    "affiliations": []
  }],
  "abstractText": "Optimization of high-dimensional black-box functions is an extremely challenging problem. While Bayesian optimization has emerged as a popular approach for optimizing black-box functions, its applicability has been limited to low-dimensional problems due to its computational and statistical challenges arising from high-dimensional settings. In this paper, we propose to tackle these challenges by (1) assuming a latent additive structure in the function and inferring it properly for more efficient and effective BO, and (2) performing multiple evaluations in parallel to reduce the number of iterations required by the method. Our novel approach learns the latent structure with Gibbs sampling and constructs batched queries using determinantal point processes. Experimental validations on both synthetic and real-world functions demonstrate that the proposed method outperforms the existing state-of-the-art approaches.",
  "title": "Batched High-dimensional Bayesian Optimization via Structural Kernel Learning"
}