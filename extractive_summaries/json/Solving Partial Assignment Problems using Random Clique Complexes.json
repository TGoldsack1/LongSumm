{
  "sections": [{
    "heading": "1. Introduction",
    "text": "The assignment problem finds an assignment, or matching, between two finite sets U and V , each of cardinality n, such that the total cost of all matched pairs is minimized. The assignment problem can also be generalized to finding matchings between more than two sets. This is a fundamental problem in computer science and has been motivated by a wide gamut of research areas spanning diverse areas such as structural biology (Singer & Shkolnisky, 2011), protein structure comparisons in bioinformatics (Zaslavskiy et al., 2009), and computer vision (Conte et al., 2004). Computer vision especially boasts a broad range of applications that include object matching, image registration (Shen & Davatzikos, 2002), stereo matching (Goesele et al., 2007), shape matching (Petterson et al., 2009; Berg et al., 2005),\n1Department of Computer Science & Engineering, Indian Institute of Technology Hyderabad, Hyderabad, India. Correspondence to: Charu Sharma <charusharma1991@gmail.com>, Deepak Nathani <deepakn1019@gmail.com>, Manohar Kaul <mkaul@iith.ac.in>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nFigure 1. Matching cliques of two houses with 1-cliques (red), 2- cliques (green), 3-cliques (blue). Violet and yellow lines show the matchings of d-cliques where d = 2, 3 respectively.\nstructure from motion (SfM) (Szeliski, 2010), and object detection (Jiang et al., 2011), to name a few.\nVarious assignment approaches can broadly be classified as those that find a bijective assignment in the form of a permutation matrix by posing the problem as a linear assignment problem (LP) versus ones that solve a quadratic assignment problem (QAP) via graph matching, where each graph’s nodes represent the objects and the edges encode their corresponding distances; the goal of QAP then is to find node-wise correspondences between the graphs so that the overall discrepancy between their corresponding edgewise counterparts is minimized and the overall relational structure is best preserved.\nPartial assignment implies that only subsets of U and V can actually be assigned to each other successfully. This phenomenon is of particular interest to applications where either objects are absent due to incomplete observations, undergo deformations, and/or the objects in question cannot clearly be disambiguated because the objects in question along with their related objects are embedded in clutter. This variant of the assignment problem is widely accepted as a formidable challenge.\nAlthough graph matching methods were found to be instrumental, they too perform poorly when faced with nonsimilar geometric transformations or transformations that produce degenerate triangulations. This is attributed to assigning weights to only node and edge assignments, while ignoring the interplay of higher-order connections/relations. For example, using triplet weights can alleviate the above\nar X\niv :1\n90 7.\n01 73\n9v 3\n[ cs\n.L G\n] 2\n9 Ju\nl 2 02\n0\nmentioned problem to a very large extent by defining a measure invariant to scale and other transformations (Chertok & Keller, 2010).\nMotivated by the aforementioned observations and inspired by Kahle (Kahle, 2006)’s work on combinatorial topological models like the random clique complex, we focus our attention to matching higher-order components between two sets of points in the setting of some points missing completely at random. We pose our assignment problem as finding a matching between two sets of points, each represented as a random clique complex, which is a higher-order analogue of random graphs. Figure 1 illustrates such a matching of cliques of corresponding dimensionality, between two different scenes (taken from different camera angles) of the same house. Given an Erdős-Rényi (ER) graph, its clique complex is the simplicial complex with all complete subgraphs (i.e., cliques) as its faces. The Erdős-Rényi graph forms the 1-skeleton of the random clique complex, where the cliques have at most a dimension of 2, i.e., edges in the graph. The clique topology of a random adjacency matrix is analogous to its eigenvalue spectrum, as it provides a set of invariants that help detect structure (Giusti et al., 2015). This probabilistic and combinatorial framework of random clique complexes allows us to further study the assignment problem under various assumptions of the underlying distribution of the matrix entry distributions, its robustness to missing values, and its asymptotic behavior for large-scale cases.\nContributions: We present the following contributions.\n1. To the best of our knowledge, our proposed approach is a first attempt to formulate higher-order matching between two sets of points, given partial or incomplete information, as a matching between two random clique complexes. We also propose an efficient matching algorithm and study both its time and storage complexity.\n2. (i) We provide new bounds on the concentration inequality of eigenvalues of the QAP trace formulation for random symmetric matrices, (ii) we give tighter concentration inequality bounds on the largest eigenvalue for the Lawler QAP formulation on random matrices, in the context of affinity matrices that are used by some earlier works. Furthermore, we theoretically analyze and discuss the robustness of affinity-matrix based schemes to missing points, and (iii) we perform asymptotic analysis on the worst to best case ratio of a QAP solution for our higher-dimensional clique adjacency matrices in the clique percolation regime (Bollobás & Riordan, 2009), where the entries follow a Poisson distribution.\n3. Finally, we present a comprehensive empirical study that compares our method’s matching accuracy to that\nof a diverse set of matching approaches (Zhou & De la Torre, 2016; Zhou & De la Torre, 2013; Cho et al., 2010; Feizi et al., 2016; Leordeanu & Hebert, 2005; Cour et al., 2007; Pachauri et al., 2013; Gold & Rangarajan, 1996; Kuhn, 1955; Leordeanu et al., 2009; Zass & Shashua, 2008; Li et al., 2013; Duchenne et al., 2011). We conducted our experiments on both synthetic and well-known hard real-world datasets that span across affine/non-affine transformations, severe occlusions, and clutter. Our study reveals much better accuracy for the popular datasets against several of the state-of-the-art matching methods."
  }, {
    "heading": "2. Matching Random Clique Complexes",
    "text": "We consider the problem of capturing higher-order feature groups among landmark points in an image by representing them as a random clique complex (RCC) and then using these RCCs to match two sets of groupings from two different images. We begin this section by describing the construction of a random clique complex, followed by our proposed method of matching two RCCs, and we finally analyze the runtime and storage complexity of our algorithm."
  }, {
    "heading": "2.1. Structure of a Random Clique Complex",
    "text": "We begin with general definitions pertaining to the structure of simplicial complexes and then accordingly adapt these definitions to our domain of random graphs to build random clique complexes.\nLet G(n, p) be an Erdős-Rényi graph with a set of n vertices denoted by V , whose edges {v, v′} ∈ ( V 2 ) , are i.i.d Bernoulli(p) distributed. Recall, that a k-clique in G(n, p) is a complete subgraph that comprises of k vertices and( k 2 ) edges. Here onwards, for ease of notation, we will denote G(n, p) as G. Given any affinely independent set V = {vi}ki=0 of (k + 1) points in Rn, the k-simplex σ(k) is the convex hull of V , i.e., it is the set of all points of the form w0v0 + · · ·+ wkvk, where ∑k i=0 wi = 1 and wi ≥ 0 for all i. If we imagine the vertices of G embedded generically in Rn, then each (k + 1)-clique consisting of k + 1 vertices is represented by a k-dimensional simplex σ(k) in our random clique complex. For example, a 2-clique (edge) and a 3-clique (triangle) inG is represented as σ(1) and σ(2), respectively.\nGiven 0 ≤ i ≤ k, the i-th face fi of σ(k) is the subspace of points that satisfy wi = 0; it is the (k − 1)-simplex σ(k−1) whose vertices are all those of σ(k), except the i-th vertex. In other words, when σ(k) is a clique of G, then all its subsets are also cliques and hence considered faces of σ(k). For example, a 3-clique (triangle) has three 2-cliques (edges) in it.\nWith the aforementioned definitions in mind, we define our\nAlgorithm 1 Matching Random Clique Complexes Input: X (G) = {G(k,l)}hk=0 and X (G′) = {G′(k,l)}hk=0\n1: for k = h . . . 0 do 2: Let M,M ′ be the total number of (k + 1)-cliques in G(k,l) and G′(k,l), respectively 3: L := {c(k)i } M−1 i=0 # list of barycenters 4: for i = 0 . . .M − 1 do 5: Ni := Ni ∪ { g (k,l) (x,:) | x = i, g (k,l) (x,y) 6= 0\n} 6: N := N ∪ {Ni} # clique neighborhoods 7: end for 8: for i = 0 . . .M − 1 do 9: αi := [α1, . . . , αM−1]T\n10: α := α ∪ {αi} # affine weight vectors 11: end for 12: Repeat steps 3–11 on G′(k,l) for L′,N ′ and α′. 13: Build cost matrix C(k) from weights vectors α, α′ 14: X∗k := Kuhn-Munkres (G(k,l), G′(k,l), C(k)) 15: end for\nReturn: {X∗0 , . . . , X∗h} # set of permutation matrices\nrandom clique complex X (G) as the set of all cliques in G such that X (G) = {σ ∈ [n] | σ is a clique of G}. We denote a set of (k + 1)-cliques as Xk(G). Additionally, X (G) also satisfies the following conditions of a simplicial complex: (i) Any face in X (G) is also a simplex in X (G) and (ii) the intersection of any two simplexes σi, σj is a face (lower dimensional clique) of both σi and σj .\nThe faces of σ(k) are copies of σ(j) for j < k, which are glued together inductively. The k-skeleton of X (G), for k ∈ N, is defined as the following quotient space\nX (k)(G) := ( X (k−1)(G) ∪\n∐ σ:dim σ=k σ(k)\n)/ ∼\nwhere ∼ is the equivalence relation that identifies faces of σ(k) to the corresponding faces of σ ∈ X (j)(G) where j < k. Finally, X (G) = ∪∞k=0X (k)(G).\nk-skeleton as adjacency matrix: Given a random graph G and its k-skeleton X (k)(G) that contains all its (k + 1)- cliques, we follow the idea from Bollobás et. al. (Bollobás & Riordan, 2009), to represent X (k)(G) as an adjacency matrix G(k,l) whose vertex set is the set of of all (k + 1)- cliques in G and in which two vertices (i.e., (k+ 1)-cliques) are adjacent when they share a common face that has a minimum of l vertices, where k ≥ 1 and 1 ≤ l ≤ k. Such an adjacency matrix is built for each k-skeleton and therefore X (G) is expressed as a set of matrices {G(k,l)}hk=0, where (k + 1) is the dimension of the cliques."
  }, {
    "heading": "2.2. Problem Setup",
    "text": "The problem of matching random clique complexes each of dimension h, is the estimation of a set of optimal bijective maps of the formMi : X (i)(G) → X (i)(G′), for all i ≤ h, subject to assignment constraints. This can be formulated as a constrained quadratic assignment problem, which can later be relaxed to a linear programming optimization problem.\nGiven two h-dimensional random clique complexes X (G) = {G(k,l)}hk=0 and X (G′) = {G′(k,l)}hk=0, let X = {X0, . . . , Xh} ∈ Π be a set of permutation matrices such that Xk encodes assignments/matchings from G(k,l) to G′(k,l). The combinatorial matching requires the optimal set of permutation matrices that best align X (G) and X (G′). More formally, this can be expressed as the following constrained optimization problem\nargmin X0,...,Xh\nh∑ k=0 ‖G(k,l)Xk −XkG′(k,l)‖2F\nsubject to ∀k ≤ h,1TXk = 1, XTk 1 = 1\n(1)"
  }, {
    "heading": "2.3. Our Algorithm",
    "text": "At a high level, our goal is to minimize ‖X (G)−X (G′)‖C , where C is a combinatorial distance between two random clique complexes. Traditional metrics like Hausdorff distance are not suitable here because random clique complexes are combinatorial topological spaces. Recall that X (G) is comprised of a family of k-skeletons {X (k)(G)}hk=0, where each k-skeleton contains cliques whose dimension is at most k + 1 and X (k)(G) has a maximum dimension h. The solution of the optimization problem outlined in Equation (1) aims to find a set of permutation matrices {X1, . . . , Xh} that minimizes the overall number of misalignments between equi-dimensional faces of X (G) and X (G′), i.e., cliques belonging to the corresponding k-skeletons, and thus producing the optimal least cost assignment between X (G) and X (G′).\nAlgorithm 1 presents our method to solve the combinatorial optimization problem (Equation (1)). In decreasing order of clique dimensionality, for a fixed dimension k and given the adjacency matrices G(k,l) and G′(k,l) for k-skeletons X (k)(G) and X (k)(G′), respectively. In every iteration, our objective is to solve argminXk‖G\n(k,l)Xk−XkG′(k,l)‖2F to find the optimal permutation X∗k . We assume the barycenters of every clique is pre-computed (Step 3). Next, the neighborhood Ni of the i-th clique is computed as the set of entries with 1s in the i-th row of G(k,l) (Step 5). We denote the collection of every clique’s neighborhood as N (Step 6). An important objective of our method is to capture the geometric properties of the neighborhood of every clique. We achieve this by characterizing the i-th clique’s barycenter\nc (k) i as an affine combination of the barycenters (in all dimensions) associated with the cliques in its corresponding neighborhood Ni. Given an arbitrary clique’s barycenter c (k) i , let {x (k) 1 , . . . , x (k) n } denote the barycenters of its n ad-\njacent cliques. Then, c(k)i expressed as ∑n i=1 αix (k) i is an\naffine combination of the x(k)i s, if ∑n i=0 αi = 1, i.e., the weights αi sum to 1. Among all possible affine representations of c(k)i we chose to use least squares to guarantee minimal error under L2-norm, and furthermore it assigns non-zero weights to each of its adjacent clique barycenters, thereby capturing the local geometric properties in its neighborhood. The weight vector αi is then calculated for each clique (Step 9) and α denotes a collection of such weight vectors (Step 10). Next, a cost matrix is built by computing the L2-norm distance between weight vectors α and α′ (Step 13). Finally, the Kuhn-Munkres (Kuhn, 1955) algorithm is invoked with both the adjacency matrices and the cost matrix, which arrives at the optimal assignment (Step 14 ). At the end of all iterations, our method returns a set of optimal assignments for matches between each k-skeleton for every dimension below h and the algorithm terminates. We refer the reader to our supplementary section for a working example."
  }, {
    "heading": "2.4. Complexity Analysis",
    "text": "To begin our analysis, we must first ascertain the dimensionality of G(k,l), which is governed by the total number of (k + 1)-cliques that exist in the underlying random graph G. It is important to note that there doesn’t exist any closed form solution to counting the number of cliques of a given dimension in G.\nWe consider the distribution of a random variable Xn(k) counting the number of (k + 1)-cliques in a realization of G. We show in Appendix A of our supplementary material that this count is upper bounded by (en/k)k, where e is Euler’s number. This can be expressed in asymptotic notation as O(nk). As dimensionality increases, there occurs an explosion in the number of cliques. Fortunately, G(k,l) is a sparse matrix and its effective dimensionality measured by the number of non-zero rows, i.e., the number of cliques with non-empty neighborhoods, is of order O(nnz(G(k,l))). Therefore, we set out to count the number of non-zero entries in G(k,l).\nWe use a seminal result by Bollobás (Bollobás & Riordan, 2009), where they identify a threshold probability for percolation of cliques in G for all fixed k and l, which is given by p = Θ ( n −2 k+l−1 ) . Moreover, they proved that for p\naround this threshold, the number of cliques asymptotically converge to a Poisson distribution. Exceeding this threshold results in formation of giant connected clique clusters, which causes an explosion in the number of possible cliques.\nRecall from our definition of G(k,l), that two cliques are adjacent if they share at least l vertices. In order to analyze this further, we imagine an entry in G(k,l) occurs when we can migrate a (k + 1)-clique from its original position to an adjacent clique by relocating exactly (k + 1 − l) vertices and leaving the remaining l vertices intact. The expected number of such relocations is given by (( k+1 l ) − 1 ) ( n k+1−l ) p(( k+1 2 )−( l 2)), where the first term denotes the number of possible vertices in a (k + 1)-clique that can be chosen for relocation, the second term counts the number of new adjacent positions a clique can relocate to, and the final term decides the probability of relocations that are correct and acceptable. In our case, we define cliques to be adjacent to one another when they share at least l = k vertices. This is done in order to keep the number of adjacent cliques to a manageable size during experiments. Setting l = k, gives knpk expected relocations, which in turn estimates nnz(G(k,l)).\nNote that for every iteration in Algorithm 1, the dominating cost is that of running the Kuhn-Munkres matching algorithm in Step 14, which has a cubic cost in nnz(G(k,l)). Let Cmax denote an upper bound on all the number of nonzero entries in {G(k,l)}hi=0. Then, every iteration has a runtime O(C3max) and therefore after h iterations the final cost is O(hC3max). Observe that as the dimensionality of the cliques increases in every iteration, pk decays very sharply and hence drastically reduces nnz(G(k,l)), which in turn reduces the overall matching cost. Finally, the storage complexity can simply be given as O(hCmax)."
  }, {
    "heading": "3. Theoretical Analysis of QAP",
    "text": "In this section, we present three related results in the context of matching random matrices, namely: (i) concentration inequality of eigenvalue bounds on the QAP trace formulation for random symmetric matrices, (ii) tighter concentration inequality of eigenvalue bounds on the Lawler QAP formulation on random symmetric matrices in the context of works that use affinity matrices, and (iii) provide an asymptotic analysis on the worst to best case ratio of a QAP for higher-dimensional clique adjacency matrices. For ease of notation, we will refer to the random clique adjacency matrices simply as A and B."
  }, {
    "heading": "3.1. Eigenvalue Bounds of Trace QAP Formulation on Random Matrices",
    "text": "Let A = (avv′), B = (bvv′) ∈ Rn×n be random realsymmetric matrices. Let X = (xij) ∈ Rn×n be a permutation matrix. Then, the trace formulation of a QAP is given by\nminimize Tr(AXBXT ) s.t. X ∈ ΠX\nwhere ΠX is the set of permutation matrices.\nLet λ1(A) ≤ λ2(A) ≤ · · · ≤ λn(A) and λ1(B) ≥ λ2(B) ≥ · · · ≥ λn(B)1 be the eigenvalues of A and B, respectively. Let the corresponding eigen-decompositions of matrices A and B, be given by A = QAΛAQTA and B = QBΛBQ T B , where ΛA = diag(λ1(A), . . . , λn(A)) and ΛB = diag(λ1(B), . . . , λn(B)) with their corresponding orthogonal eigenvector matrices QA and QB . Finke et. al. (Martello et al., 1987) gave the following eigenvalue bounds.\nTheorem 1. Let A and B be symmetric matrices. Then for all X ∈ XΠ,\n1. Tr(AXBXT ) = λ(A)TQ(X)λ(B), where Q(X) = 〈Q(i)A , XQ (j) B 〉2 with vectors of eigen-\nvalues given by λ(A) = (λi(A)) and λ(B) = (λi(B)). Q (i) A and Q (i) B denote the i-th eigenvectors of A and B, respectively;\n2. L ≤ Tr(AXBXT ) ≤ U , where L = ∑n i=1 λi(A)λi(B), and\nU = ∑n i=1 λn−i+1(A)λi(B)\nIt was also noticed by Finke (Martello et al., 1987) that these bounds can further be tightened by reducing the spreads of matrices A and B, where the spread of a matrix A, denoted by S(A), is given by S(A) = maxi λi(A) −mini λi(A). There is no formula to compute the spread of a matrix directly, so Finke et. al. (Martello et al., 1987) suggested a reduction method to further sharpen the bound by replacing matrices A and B by smaller spread symmetric matrices Ã and B̃. The reductions are achieved as Ã = A−MA−MTA −DA and B̃ = B−MB−MTB −DB , where MA, MB are matrices with constant columns and DA, DB are diagonal matrices, whose values are chosen appropriately in order to tighten the bounds on spreads S(Ã) and S(B̃).\nOur bounds on Random Matrices: We propose new measure concentration inequalities on the spread of a random matrix, by redefining the spread in an alternate fashion that is more amenable to our analysis. Consider our reduced random symmetric matrix Ã ∈ Rn×n, with eigenvalues λ1(Ã) ≤ · · · ≤ λn(Ã), we define the gap (spacing) between its consecutive eigenvalues as δi(Ã) := |λi+1(Ã)− λi(Ã)| for 1 ≤ i ≤ n − 1. Then, the spread S(Ã) for the reduced matrix Ã can be redefined as: S(Ã) = ∑n i=1 δi(Ã)\nWe begin by upper bounding δi(Ã) using the following lemma 1 (proof in supplementary notes).\nLemma 1. Let |||.||| denote an algebraic matrix norm on a space of real n× n matricesMn, then for any A ∈Mn,\nδi(A) ≤ 2|||A||| 1 The two sets of eigenvalues differ in ordering.\nTo the best of the author’s knowledge there does not exist a known distribution of eigenvalue gaps for a symmetric random matrix. We now attempt to give concentration inequalities for the tail probabilities of the sum of eigenvalue gaps, i.e., the spread. For our i.i.d. random matrix A ∈ Rn×n, consider the sequence of independent eigenvalue gaps δ1(A), . . . , δn(A), where each δi(A) is upper bounded by 2|||A|||, as shown in Lemma 1. Let us denote their sum as Sn(A) := δ1(A) + · · · + δn(A). As δ1(A), . . . , δn(A) are independent scalar random variables with δi(A) ≤ |||A||| a.s, with mean µi(A) and variance σ2i (A). Then, using Chernoff bounds, for any > 0, we have\nP(|Sn(A)− µ| ≥ σ) ≤ K max ( e(−p 2), e(−p σ/2|||A|||) )\nfor some absolute constants K, p > 0. The Chernoff inequality above, shows that Sn(A) is sharply concentrated in the range nµ+O(σ √ n), when is not too large."
  }, {
    "heading": "3.2. Eigenvalue bounds on Lawler’s QAP on Random Affinity Matrices",
    "text": "In literature, many graph matching algorithms use Lawler’s QAP formulation. Recall, A = (aij), B = (buv) ∈ Rn×n. Let Ω(ai,j , bu,v) denote the pairwise affinity score of assigning the (i, j)-th entry in A to the (u, v)-th entry in B, implying that node ai is matched to node bu and node aj to node bv, simultaneously. Then, the affinity matrix A ∈ Rn 2×n2 is given by A [(i− 1)n+ u, (j − 1)n+ v] = Ω(ai,j , bu,v) and the optimal assignment to Lawler’s QAP is the one that maximizes the sum total pairwise affinity scores. Leordeanu et. al. (Leordeanu & Hebert, 2005) show via a spectral relaxation that Lawler’s WAP reduces to solving w∗ = argmaxw wTAw wTw\n, w ∈ Rn2 . This is solved by finding the leading eigenvalue λ1(A ).\nAs illustrated in (Alon et al., 2002), we also use Talagrand’s concentration inequality (Talagrand, 1995). We provide a tighter bound in the case of our affinity matrix using Rayleigh’s quotient.\nTheorem 2. For a random affinity matrix A ∈ Rm×m and for a positive constant t, P[|λ1(A )−M| ≥ t] ≤ 4e−t\n2/8, whereM is the median of λ1(A ).\nDiscussion: We further investigate the robustness of affinity-matrix based graph matching solutions when dealing with missing or incomplete data. We show the sharpness of our result in Theorem 5 on the affinity matrix, similar to (Alon et al., 2002), who analyze their results using fat matrices as an example. Consider an affinity matrix A = (aij) ∈ Rm×m, whose entries are i.i.d. Bernoulli distributed. Simulating missing affinity scores due to missing edge assignments, we set aij = 1 with probability 1/4 and aij = 0 with probability 3/4. Notice that our random\naffinity matrix represents the Erdős-Rényi graphG(m, 1/4). As shown in (Alon et al., 2002), the median and expectation of λ1(A) differ by a constant factor. Let G = (V,E) denote a general undirected graph, where the degree of each vertex v ∈ V is given by dG : V → Z. Then, the average degree of G is given by d̄ = ∑ v∈V dG(v)/|V | and its maximum degree is ∆ = maxv∈V dG(v). It is then well known that d̄ ≤ λ1(A) ≤ ∆, i.e., the largest eigenvalue of a graph is squeezed between its average and maximum degree.\nLet |E| denote the total number of edges in G(m, 1/4), then the average degree of G(m, 1/4) is given by 2|E|/n, where |E| = (Bin( ( m 2 ) , 1/4) and the standard deviation\nof |E| is √(\nm 2\n) (1/4)(3/4) = Θ(m). For large m, our\nbinomial distribution converges to a normal distribution. Therefore, we calculate the probability for the total number of edges |E| to deviate from its expectation by t standard deviations as e−Θ(t\n2). Furthermore, we know that if |E| exceeds its expectation by Θ(tn), then the average degree d̄ must also correspondingly exceed its expectation by Θ(t). Therefore, the probability of the average degree d̄ exceeding its expectation by t standard deviations is at least e−Θ(t\n2). Given that d̄ ≤ λ1(A), it follows that λ1 exceeding its expectation is also lower bounded by the same e−Θ(t\n2). The bounds achieved are tight up to a constant factor in the exponent. Our experimental results on Factorized Graph Matching (FGM) by Zhou et. al. (Zhou & De la Torre, 2016) and Re-weighted Random Walk Matching (RRWM) (Cho et al., 2010) also support the finding that affinity matrix based matching solutions are more robust to missing edges due to occlusions in data."
  }, {
    "heading": "3.3. Asymptotic Analysis of Higher-Order Clique Assignment",
    "text": "Following along the same lines as Finke et. al. (Martello et al., 1987), we study the asymptotic behavior of the worst to most optimal ratio and present it as the following theorem. Theorem 3. Given random clique adjacency matrices Ak,ln , B k,l n ∼ Pois(λ) and their associated cost matrix Cvv′ ∼ Pois(λ). We denote by λe := E(Cvv′) and λv := V(Cvv′) the expectation and variance of our Poisson distributed cost function. For > 0 and p = Θ ( n −2 (k+l−1) ) ,\nwe have the following bound on the ratio of the worse to the best solution as\nP  max π∈Π ∑ vv′ Cvv′\nmin π∈Π ∑ vv′ Cvv′ ≤ 1 +  ≥ 1− 2|Π| exp ( −2|Sπ| ( ′ √ λv\n′ + 2λv\n)2) =: ψ(n, )\nwhere, |Π| = n!, |Sπ| = ( n+1\n2\n) , limn→∞ ψ(n, ) = 1"
  }, {
    "heading": "4. Experiments",
    "text": "Here, we study the robustness of various matching algorithms when affected by missing or incomplete information and transformations (both affine and non-affine) on synthetic and real-world datasets. For the sake of brevity, we report detailed dataset descriptions in our supplementary notes. The graph matching algorithms can broadly be classified based on their use of (i) affinity-matrix: FGM (Zhou & De la Torre, 2016; Zhou & De la Torre, 2013)2, RRWM (Cho et al., 2010), (ii) Eigenvalues: EigenAlign (Feizi et al., 2016)3, SM (Leordeanu & Hebert, 2005), SMAC (Cour et al., 2007), PermSync (Pachauri et al., 2013)4, (iii) LP relaxation: GA (Gold & Rangarajan, 1996), Kuhn-Munkres (Kuhn, 1955), (iv) Integer QAP: IPFP (Leordeanu et al., 2009), (v) Probabilistic matching: PM (Zass & Shashua, 2008), (vi) Higher-order matching given complete data: Tensor (Duchenne et al., 2011)5, and (vii) Geometric and Feature matching: LAI-LP (Li et al., 2013)6. Our code7 is publicly available."
  }, {
    "heading": "4.1. Effect of Affine Transformations",
    "text": "Simulated Dataset: We perform affine transformations on CMU House, which is a sequence of N frames extracted from a video. More specifically, we uniformly sample frames (at 20% and 40%) and perform affine transformations on the selected frames to distort them. Figure 2 shows examples of affine transformations on house frame sequences. Table 1 shows the comparative error in matching for all the algorithms. We now describe each affine transformation as performance metrics in our experiments.\nRotation: Figure 8(b) shows a 180◦ rotated version of the original house frame (Figure 8(a)). Table 1 shows errors in matching when 20% of the frames are rotated by both 20◦ and 60◦, respectively and when the same transformations are applied to 40% of the frames. As the percentage of transformed frames with greater degree increases, we note a substantial increase in error for other methods in comparison to our method’s error increase.\nReflection: The reflected version of a house frame is shown in Figure 8(c). Table 1 shows that affinity-based approaches also performed equally well for reflection of house frame sequences.\nScaling: Resizing an image both horizontally and vertically scales the image as is shown in Figure 8(d) . We fixed the scales to 0.5, 0.75, 1.25, and 1.5 randomly in both the directions in order to transform the images. Our method in Table 1 produces much better matchings than the other methods. 2 FGM 3 EigenAlign 4 PermSync 5 Tensor 6 This algorithm serves as our naive baseline as it directly uses neighborhood properties of the underlying graph (LAI-LP). 7 Our Method\nShearing: We randomly apply shearing on house in one of the directions with shear factor 0.5 (shown in Figure 8(e)) and measured the performance shown in Table 1. In addition to our method, we find that affinity-based algorithms also produce robust matchings."
  }, {
    "heading": "4.2. Effect of Incomplete and Occluded Landmarks",
    "text": "To understand the effect of occlusions, we took two realworld datasets, i.e., Books and Building (Pachauri et al., 2013) with severe occlusions which are scenes of the same 3D object taken from arbitrary camera angles. These datasets have widely been used in Structure from Motion (SfM) problems and are known to be difficult for matching. Focusing our attention to the last two columns of Table 2, it is evident that our method gives the best results. Figure 3 shows the Books dataset where books are placed on a table in various orientations with varying levels of occlusion, along with two sample matchings between different pairs of images. Note that in Figure 3, when a corresponding matching clique is not found in the other image, a match isn’t forced but rather there is no match reported, which doesn’t degrade the matching accuracy. Matching as many random cliques, in order of decreasing dimensionality, as possible, manifests itself as an advantage over existing methods, especially when dealing with clutter and/or occlusions. Simulating missing points: In order to gain a deeper insight into the behavior of all the matching algorithms, we\nBooks Frame 2 and 17\nBooks Frame 5 and 20\nFigure 3. Two instances of matchings in Books dataset which is severely occluded. Yellow/green lines show correct/incorrect matches and isolated points show no matches.\nomit 2, 4, 6, 8, and 10 (6.66%, 13.33%, 20%, 26.66%, and 33.33%) points out of total House landmark points (i.e., 30 points) from 40% (Figure 4) of frame sequences randomly. In general, all algorithms show an increase in error as more points are removed, but our method has a less gradual increase, while eigenvalue related methods show a rather steep increase in error. Our method is comparable to FGM and RRWM, but the gap in error increases with more missing points. We also observed that FGM incurs the longest run-\n10 15 20 25 30\nMissing Points (%) from 40 % of Images\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nE rr\no r\n(% )\nOurMethod EigenAlign FGM LAI-LP PermSync RRWM Tensor IPFP PM SMAC SM GA Munkres\nFigure 4. Error (%) in matching when varying the number of missing landmarks in 40% of the images in the frame sequence.\n10 20 30 40 50 60 70 80 90 100\nFrame Separation\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nE rr\no r\n(% )\nOurMethod EigenAlign FGM LAI-LP PermSync RRWM Tensor IPFP PM SMAC SM GA Munkres\n20 40 60 80 100 120 140 160 180 200\nFrame Separation\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\nE rr\no r\n(% )\nOurMethod EigenAlign FGM LAI-LP PermSync RRWM Tensor IPFP PM SMAC SM GA Munkres\nFigure 5. Error (%) in matching by various methods with different frame separation level for CMU Hotel (on left) and Horse Shear (on right).\ntime for matching in this scenario."
  }, {
    "heading": "4.3. Effect of Frame Separation",
    "text": "Here, we pick two frames from a video for matching and vary the separation in their frame sequence number. The farther apart two frames are the more pronounced is the effect we seek between the frame images. For example, as the frame separation increases, CMU Hotel undergoes a more severe 3D rotation, while Horse-Shear (Caetano et al., 2009) undergoes a larger degree of shear. We set p = 0.7 and k = 7 as nearest neighbors to get the correct matchings. In Figure 5, in both the left and right plots we notice that most methods show a very sharp rise in error, while our method is quite stable and reports a 0% error. We observe that the naive baseline, LAI-LP also does well and doesn’t exhibit steep changes in error with larger frame separation.\nExperimental Summary: In general, we find that the affinity matrix based methods like FGM and RRWM are more robust to affine transformations than other competing algorithms. Our method performs the best as the weight vectors in our algorithm effectively capture even the higher-order geometric properties of the neighborhood and nearly preserves them under affine transformations. The naive baseline, i.e., LAI-LP, does not perform as well because it also has a feature-based component like SIFT which is known to fail on some affine transformations."
  }, {
    "heading": "5. Conclusion",
    "text": "To the best of our knowledge, we have presented the first approach towards partial higher-order matching by initially capturing higher-order structure as random clique complexes and then proposing a corresponding matching algorithm. From a theoretical point of view, we studied matching as a QAP on random clique adjacency matrices that represented the k-skeleton of our random clique complexes and gave bounds on the concentration inequality of the spread of its eigenvalues. We also improved bounds on the largest eigenvalue of the Lawler QAP formulation, used by affinitymatrix based approaches. We discussed the robustness of such approaches to missing points and also showed the sharpness of our result. Furthermore, inspired by Finke et. al. (Martello et al., 1987) we studied the asymptotic behavior of our higher dimensional clique adjacency matrices. A more detailed investigation of the distribution of eigenvalue gaps for such random matrices with Poisson distributed entries is left for future work.\nFrom an empirical perspective, we compared the matching accuracies of diverse algorithms on both synthetic and realworld datasets that were known to have severe occlusions and distortions, thus posing a daunting challenge to matching algorithms. We argue that our experiments show strong evidence that our approach outperforms all the state-of-theart matching methods on a diverse range of datasets."
  }, {
    "heading": "Acknowledgements",
    "text": "We thank our colleagues from the Mathematics Dept. at IIT-H (Sukumar Daniel, Narasimha Kumar, and Bhakti B. Manna) for their insight and expertise. We would also like to thank all the reviewers for their feedback and suggestions. We are grateful to the authors of (Zhou & De la Torre, 2016; Zhou & De la Torre, 2013; Cho et al., 2010; Feizi et al., 2016; Pachauri et al., 2013; Li et al., 2013; Duchenne et al., 2011) for providing their source codes and datasets."
  }, {
    "heading": "A. Proofs",
    "text": ""
  }, {
    "heading": "A.1. Upper Bound to Clique Size in a Random Graph",
    "text": "Let G(n, p) denote the Erdős-Rényi random graph on n vertices, i.e., G(n, p) = {Gij |1 ≤ i < j ≤ n}, where Gij ∼ Ber(p) are i.i.d Bernoulli random variables. We denote the number of k-cliques in the realization of G(n, p) as Xn(k). By definition, a k-clique in a graph G is a subset A of k vertices, which induce a complete subgraph of G. Additionally, no other vertex in G can be joined by edges to all vertices of A. Therefore, we can represent Xn(k) as a sum of indicator random variables 1A, where\n1A = { 1 if A is a k-clique in G(n, p) 0 otherwise\n(2)\nIt is clear that Xn(k) = ∑ |A|=k 1A. Hence, we get\nE(Xn(k)) = E( ∑ |A|=k 1A) = ∑ |A|=k E(1A) = ( n k ) p( k 2)\nUsing Stirling’s formula, we upper bound Xn(k) as ( en k )k , where e is the Euler’s number."
  }, {
    "heading": "A.2. Quadratic Assignment Problem",
    "text": "We begin by defining the general quadratic assignment problem (QAP) using the Koopman-Beckmann version. Let A = (avv′), B = (bvv′) ∈ Rn×n. Let Π denote the set of all possible bijections (permutations) π : N → N , where N = {1, 2, . . . n}. We define the QAP as:\nminimize ∑ v,v′ bvv′aπ(v)π(v′)\nsubject to π ∈ Π\nFor now on, for ease of notation, we denote the cost function bvv′aπ(v)π(v′) as Cvv′ ."
  }, {
    "heading": "A.3. Asymptotic Analysis of Higher-order Clique Assignment (Proof of Theorem 3)",
    "text": "Given that the QAP is a combinatorial optimization problem, in the case of random symmetric matrices, the subset of feasible solutions Sπ is of the form:\nSπ = {(π(v), π(v′) | v < v′, u, v = 1, . . . , n}\nwhere, |Sπ| = ( n+1\n2\n) and |Π| = n!.\nRecall that our cost function Cvv′ has expectation λe and variance λv . For notational convenience, we set ′ = λv− . Then, there exists a bijection π ∈ Π, for which the following\nholds by the definition of variance\nP  1|Sπ| ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ′ \nTo proceed further with our proof, we make use of the following lemma by Renyi et. al. (Rényi, 1970).\nLemma 2. Let X1, . . . , Xn be independent random variables with |Xk − E(Xk)| ≤ 1, k = 1, . . . , n. Denote\nD := √√√√ n∑ k=1 V(Xk)\nand let µ be a positive real number with µ ≤ D. Then\nP {∣∣∣∣∣ n∑ k=1 (Xk − E(Xk)) ∣∣∣∣∣ ≥ µD } ≤ 2 exp ( − µ 2 2(1 + µ/2D)2 )\nIn order to apply Lemma 2, we change the form of the inequality as follows:\nP  1|Sπ| ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ′  (3)\n≤ ∑ π∈Π P  1|Sπ| ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ′  (4)\n≤|Π|P  1|Sπ| ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ′  (5)\nBefore applying Lemma 2, we compute D as,\nD = √ ∑ v,v′∈π λv = √ |Sπ|λv\nWe can rewrite (5) as\n|Π|P  ( √ λv√ |Sπ| )( 1√ |Sπ|λv )∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ′ \n=|Π|P  ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ( ′ √ |Sπ|√ λv ) ︸ ︷︷ ︸\nµ\n(√ |Sπ|λv ) ︸ ︷︷ ︸\nD\n\nNow, we make use of Lemma 2 and get\n|Π|P  ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≥ ( ′ √ |Sπ|√ λv )(√ |Sπ|λv ) ≤2|Π| exp − ( ′ √ |Sπ|√ λv )2 2 ( 1 +\n′ √ |Sπ|√ λv\n1 2 √ |Sπ|λv\n)2 \n=2|Π| exp ( −2|Sπ| ( ′ √ λv\n′ + 2λv )2) Equation 3 can now be written as\nP  1|Sπ| ∣∣∣∣∣∣ ∑ v,v′∈π (Cvv′ − λe) ∣∣∣∣∣∣ ≤ ′  ≥ 1−\n2|Π| exp ( −2|Sπ| ( ′ √ λv\n′ + 2λv )2) It can easily be verified that the expression in the R.H.S. of the above inequality tends to 1 as n→∞.\nWe know that for the expression ∣∣∣∑v,v′∈π(Cvv′ − λe)∣∣∣ ≤\n′|Sπ|, the following bounds hold.\n|Sπ|(λe − ′) ≤ ∑ v,v′∈π Cvv′ ≤ |Sπ|(λe + ′)\nIt follows that\nmax π∈Π ∑ vv′ Cvv′\nmin π∈Π ∑ vv′ Cvv′ ≤ |Sπ|(λe + ′) |Sπ|(λe − ′) ≤ 1 +\nThis completes the proof."
  }, {
    "heading": "A.4. Eigenvalue Bounds on Lawler’s QAP Formulation on Random Matrices (Proof of Theorem 2)",
    "text": "As illustrated in (Alon et al., 2002), we will make use of Talagrand’s concentration inequality. We provide a tighter bound in the case of our affinity matrix using the Rayleigh’s quotient.\nTheorem 4. (Talagrand, 1995) Let Ω = ∏m i=1 Ωi be a product space of probability spaces. Let A and At be subsets of Ω and if for each y = (y1, . . . , ym) ∈ At, there exists a real vector α = (α1, . . . , αm), such that for every x = (x1, . . . , xk) ∈ A, the following inequality holds\n∑ i:xi 6=yi |αi| ≤ t ( m∑ i=1 α2i )1/2\nThen,\nP[A]P[Āt] ≤ e−t 2/4.\nHere, At denotes the set with Talagrand distance at most t from A and Āt denotes the complement of set At. Theorem 5. For a real symmetric matrix A = (aij) ∈ Rm×m and for positive constant t,\nP[|λ1(A)−M| ≥ t] ≤ 4e−t 2/8,\nwhereM is the median of λ1(A).\nProof. 8 Given a real symmetric matrix A = (aij) ∈ Rm×m and a non-zero vetor x, the Rayleigh Quotient R(A, x) is defined as\nR(A, x) = x TAx\nxTx\nGiven the eigenvalues of A in decreasing order as λ1(A) ≥ · · · ≥ λm(A), we know thatR(A, x) ∈ [λm(A), λ1(a)]. It is well known that R(A, x) attains its maximum value at λ1(A) when x = v, where v is the eigenvector corresponding to λ1(A). Therefore, we have\nλ1(A) = R(A, v) = vTAv\nvT v (6)\nIn our proof, we omit the constant factor vT v and normalize the eigenvector v, hence ‖v‖ = 1.\nConsider the product space Ω of entries aij , 1 ≤ i ≤ j ≤ m. Let t,M be real numbers, where t > 0 and M is the median of λ1(A). Let A be the set of matrices A = (aij) ∈ Ω, for which λ1(A) ≤ M. By definition, P[A] ≥ 1/2. Additionally, let B be the set of matrices B = (bij) ∈ Ω, for which λ1(B) ≥M+ t. Using Rayleigh’s equation (6) for λ1(A), we rewrite it as a summation of diagonal and off-diagonal terms\nλ1(A) = R(A, v) = vTAv = ∑\n1≤i<j≤m (vTi vj + v T j vi)aij︸ ︷︷ ︸\noff-diagonal\n+\nm∑ i=1\nvTi viaii︸ ︷︷ ︸ diagonal ≤M\nand λ1(B) = R(B, v) = vTBv = ∑\n1≤i<j≤m (vTi vj + v T j vi)bij︸ ︷︷ ︸\noff-diagonal\n+\nm∑ i=1\nvTi vibii︸ ︷︷ ︸ diagonal ≥M+ t\n8 Our proof technique follows the technique outlined in (Alon et al., 2002)\nIn order to apply Talagrand’s inequality (Theorem 4), we set a real vector α = (αij)1≤i≤j≤m as follows: For offdiagonal (1 ≤ i < j ≤ m) terms, we set\nαij = (v T i vj + v T j vi)\nFor diagonal (1 ≤ i ≤ m) terms, we set\nαii = v T i vi\nWe proceed by first proving two claims that will be used in this proof.\nClaim 1. ∑ 1≤i≤j≤m α2ij ≤ 2\nProof. By definition,\n∑ 1≤i≤j≤m α2ij = m∑ i=1 (vTi vi) 2 + ∑ 1≤i<j≤m (vTi vj + v T j vi) 2\n< 2 ( m∑ i=1 vTi 2 )( m∑ i=1 vi 2 ) = 2 (since ‖v‖ = 1)\nThis completes the proof.\nClaim 2. For every A ∈ A,∑ 1≤i≤j≤m;aij 6=bij |αij | ≥ t\nProof. Recall that for matrix A ∈ A, v is the eigenvector with unit-norm corresponding to λ1(A). We know that,\nvTAv ≤ λ1(A) ≤M (from set A)\nwhile,\nvTBv ≥ λ1(B) ≥M+ t (from set Āt)\nWe observe that the entries in affinity matrices A and B, are affinity scores in interval [0, 1]. Therefore, we have |bij − aij | ≤ 1, for all 1 ≤ i, j ≤ m. For ease of notation, let us denote by P , the set of ordered pairs ij with 1ß, j ≤ m where aij 6= bij . Then,\nt ≤ vT (B −A)v = ∑ i,j∈P (bij − aij)vTi vj\n≤ ∑ i,j∈P |vTi ||vj | ≤ ∑ i,j∈P |αij |\nThis completes the proof.\nBy the above two claims, we get the following form:\n∑ xi 6=yi |αi| ≥ t > ( t√ 2 ) ∑ 1≤i≤j≤m α2ij 1/2\nApplying Talagrand’s inequality, we get\nP[λ1(A) ≤M]P[λ1(B) ≥M+ t] ≤ e −1 4\n( t√ 2 )2 ≤ e−t 2/8\nSinceM is the median of λ1(A), by definition P[λ1(A) ≤ M] ≥ 1/2, then\nP[λ1(A) ≥M+ t] ≤ 2e−t 2/8 (7)\nAccordingly, we also have that,\nP[λ1(A) ≤M− t] ≤ 2e−t 2/8 (8)\nCombining results (7) and (8), we have\nP[|λ1(A)−M| ≥ t] ≤ 4e−t 2/8 (9)\nThis completes the proof."
  }, {
    "heading": "A.5. Proof of Lemma 1",
    "text": "For ease of understanding, we drop the (A) as it is obvious from context. Let λi be the i-th eigenvalue of A, and let xi 6= 0 be its corresponding eigenvector. From Axi = λixi, we have\nAXi = λiXi, where Xi := [ xi . . . xi ] ∈Mn \\ {0}\nIt follows,\n|λi||||Xi||||||Xi||| = |||λiXi||| = |||AXi||| ≤ |||A||||||Xi|||.\nAs |||X||| is non-negative, we get |λi| ≤ |||A|||. Thus, every eigenvalue of A is upper bounded by the matrix norm |||A|||. Applying the triangle inequality, we get that δi(A) = |λi+1(A)−λi(A)| ≤ 2|||A|||, which completes the proof."
  }, {
    "heading": "B. Example",
    "text": "We explained our method with the help of an example shown in Figure 6, Table 3 and Table 4 for a better understanding. We consider two random graphs G1 and G2 with 6 vertices each in Figure 6(a) for which we perform higher-order matching from 3-cliques 6(b) to 1-cliques 6(d). For a higherorder matching, we take the neighbourhood of a barycenter of a clique as the barycenters of the other cliques it is connected to. Thus, we place additional nodes of different order in the neighbourhood of each clique in addition to the same order cliques. This information would help the cliques to\nhave more accurate matches. The neighbours and matchings of 3-cliques, 2-cliques and 1-cliques are mentioned in the Table 3 and Table 4 for both the graphs G1 and G2 respectively. And, the matchings shown in Figure 6(b), 6(c) and 6(d) are based on having the same labels for each barycenter in graph G1 and G2."
  }, {
    "heading": "C. Experiments",
    "text": ""
  }, {
    "heading": "C.1. Setup",
    "text": "We compare the performance of our proposed method with various other matching algorithms on synthetic and real world datasets. The real world datasets are categorized in Table 5. Here, N is the total number of samples with n landmark points in each image to be matched. We represent random graphs on images in Figure 7 for better understanding and visualization of random graphs for our experiments. Matchings of two images for real world datasets (Table 5) are shown in Figure 14."
  }, {
    "heading": "C.2. Effect of Affine Transformation",
    "text": "We created a synthetic dataset from CMU House and Hotel dataset by uniformly sampling 20% and 40% frames from a video sequence and performing affine transformations like rotation, reflection, scaling, and shearing. We have explained the transformations we considered for this experiment which is similar to Figure (2) and Table (1) in\nmain paper. Table(1) in main paper shows the results on the CMU House dataset. Affine transformations on Hotel frame are shown in Figure 8. Figure 9 shows the results of matching for the remaining House (fig. 9(a) and 9(b)) and Hotel synthetic dataset for all the algorithms. We observe that our method produces best results in all the cases, whereas the error for other algorithms either remains stable or increases steeply with the increase in the percentage of transformed frames in the sequence."
  }, {
    "heading": "C.3. Effect of Occlusion",
    "text": "We considered two datasets with grave occlusions, mentioned in Table 5. Figures 14(i) and 14(j) show the matching of two images for both the datasets, although the matching results are shown in Table (2) in the main paper. We also created a synthetic dataset by removing 2, 4, 6, 8, and 10 (6.66%, 13.33%, 20%, 26.66%, and 33.33%) points out of total house landmark points (i.e., 30 points) from 20% and 60% of frame sequences randomly. Figures 10(a) and 10(b) show the increase in error as we remove more points from images. We also note the difference in both the results. Since we remove points from more percentage of frames in 10(b), there is more gradual increase in the error. This experimental setup is similar to Figure (4) in our main paper. It shows that affinity based methods like FGM and RRWM perform well but our method still consistently outperforms all the algorithms."
  }, {
    "heading": "C.4. Effect of Frame Separation",
    "text": "Figures 11(a) and 11(b) show the frame separation level result of CMU House and Horse Rotate frame sequences. We select a pair of frames at a time with increase in their frame separation (x-axis). Here, the House dataset consists of 3D rotations of House whereas Horse Rotate dataset applies rotation with more degree of rotation as the frame separation level increases. We see that most of the algorithms performs well for both the datasets even with 0% error."
  }, {
    "heading": "C.5. Effect of k-Nearest Neighbour",
    "text": "In Figures 12(a) and 12(b), error and computation time of matching two frames of house are shown with different probability p and nearest neighbor k values. We observe that as the value of p and k increases, the possibility of mismatching decreases which leads to correct matching. On the other hand, the computation time increases since it increases the number of edges in the underlying graph, which in turn leads to a larger number of d-cliques. This also causes a marked increase in the matching algorithm’s runtime. The computation time of our algorithm considers the time of the Kuhn-Munkres algorithm, which is used as a matching algorithm to match two random clique complexes, which takes O(n3) running time.\nThe overall time increases as we increase the value of p and k, since it increases the probability of an edge occurrence between two landmark points. As the number of edges increase in a random graph, the number of d-cliques also increase. Due to this phenomenon, the runtime of the KuhnMunkres algorithm also increases.\nFigure 12(c) shows the computation time of matching two\nCorrelation: 0.7267\nCorrelation: 0.3823\nimages with varying k-NN for different n landmark points in the image. We can clearly see that the time increases with increasing k and a larger number of landmark points. Here, 60 landmark points take maximum time for the highest value of k. On the other hand, if we consider lower values of k, even 60 landmark points take a reasonable amount of time to match, which is comparable to lower values of n. Thus, we set k value as low as possible for matching, depending on the complexity of the dataset."
  }, {
    "heading": "C.6. Noise Model",
    "text": "We analyze the performance of our method over other pairwise algorithms for two different noise models. We follow the noise model setup mentioned in (Feizi et al., 2016). We introduce noise in one random graph G1 and generate a noisy version G̃ to be matched with G2. G1 is a random graph here which is created as G1(n, p) with n nodes and p probability. We describe two noise models as follows:"
  }, {
    "heading": "Noise Model I:",
    "text": "G̃ = G1 (1−A) + (1−G1) A (10)\nG̃ is generated using the aforementioned equation where A is a binary random symmetric matrix, whose entries are drawn from a Bernoulli distribution asA(n, q) with n nodes and q probability and represents the element-wise multiplication of matrices. This model flips the node-node adjacency of G1 with probability q."
  }, {
    "heading": "Noise Model II:",
    "text": "G̃ = G1 (1−A) + (1−G1) B (11)\nAgain, A and B are binary random symmetric matrices, whose entries are drawn from the Bernoulli distribution as A(n, q) and B(n, r) with n nodes and q and r probabilities, respectively. This model flips node-node adjacency of G1 with probability q, and in addition it also creates edges between non-connected nodes with probability r.\nResults of noise model I and II on CMU Hotel and Horse Shear for frame separation level is shown in Figures 13(a), 13(c) and 13(b), 13(d) respectively. We observe that our method is robust to noise for both the models as compared to other algorithms since there is a very small increase or no increase in error (%) for all the cases."
  }],
  "year": 2020,
  "references": [{
    "title": "On the concentration of eigenvalues of random symmetric matrices. Israel",
    "authors": ["N. Alon", "M. Krivelevich", "V.H. Vu"],
    "venue": "Journal of Mathematics,",
    "year": 2002
  }, {
    "title": "Shape matching and object recognition using low distortion correspondences",
    "authors": ["A.C. Berg", "T.L. Berg", "J. Malik"],
    "venue": "In Computer Vision and Pattern Recognition,",
    "year": 2005
  }, {
    "title": "Clique percolation",
    "authors": ["B. Bollobás", "O. Riordan"],
    "venue": "Random Struct. Algorithms,",
    "year": 2009
  }, {
    "title": "Learning graph matching",
    "authors": ["T.S. Caetano", "J.J. McAuley", "L. Cheng", "Q.V. Le", "A.J. Smola"],
    "venue": "IEEE transactions on pattern analysis and machine intelligence,",
    "year": 2009
  }, {
    "title": "Efficient high order matching",
    "authors": ["M. Chertok", "Y. Keller"],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
    "year": 2010
  }, {
    "title": "Reweighted random walks for graph matching",
    "authors": ["M. Cho", "J. Lee", "K.M. Lee"],
    "venue": "In European conference on Computer vision,",
    "year": 2010
  }, {
    "title": "Learning graphs to match",
    "authors": ["M. Cho", "K. Alahari", "J. Ponce"],
    "venue": "In Proceedings of the IEEE International Conference on Computer Vision, pp",
    "year": 2013
  }, {
    "title": "Thirty years of graph matching in pattern recognition",
    "authors": ["D. Conte", "P. Foggia", "C. Sansone", "M. Vento"],
    "venue": "International journal of pattern recognition and artificial intelligence,",
    "year": 2004
  }, {
    "title": "Balanced graph matching",
    "authors": ["T. Cour", "P. Srinivasan", "J. Shi"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2007
  }, {
    "title": "A tensor-based algorithm for high-order graph matching",
    "authors": ["O. Duchenne", "F. Bach", "Kweon", "I.-S", "J. Ponce"],
    "venue": "IEEE transactions on pattern analysis and machine intelligence,",
    "year": 2011
  }, {
    "title": "Clique topology reveals intrinsic geometric structure in neural correlations",
    "authors": ["C. Giusti", "E. Pastalkova", "C. Curto", "V. Itskov"],
    "venue": "Proc. Nat. Acad. Sci. USA,",
    "year": 2015
  }, {
    "title": "Multi-view stereo for community photo collections",
    "authors": ["M. Goesele", "N. Snavely", "B. Curless", "H. Hoppe", "S.M. Seitz"],
    "venue": "In Computer Vision,",
    "year": 2007
  }, {
    "title": "A graduated assignment algorithm for graph matching",
    "authors": ["S. Gold", "A. Rangarajan"],
    "venue": "IEEE Transactions on pattern analysis and machine intelligence,",
    "year": 1996
  }, {
    "title": "Linear scale and rotation invariant matching",
    "authors": ["H. Jiang", "X.Y. Stella", "D.R. Martin"],
    "venue": "IEEE transactions on pattern analysis and machine intelligence,",
    "year": 2011
  }, {
    "title": "Topology of random clique complexes",
    "authors": ["M. Kahle"],
    "venue": "URL http://arxiv.org/abs/math.CO/",
    "year": 2006
  }, {
    "title": "The hungarian method for the assignment problem",
    "authors": ["H.W. Kuhn"],
    "venue": "Naval Research Logistics Quarterly,",
    "year": 1955
  }, {
    "title": "An integer projected fixed point method for graph matching and map inference",
    "authors": ["M. Leordeanu", "M. Hebert", "R. Sukthankar"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2009
  }, {
    "title": "Object matching using a locally affine invariant and linear programming techniques",
    "authors": ["H. Li", "X. Huang", "L. He"],
    "venue": "IEEE transactions on pattern analysis and machine intelligence,",
    "year": 2013
  }, {
    "title": "Surveys in Combinatorial Optimization, Volume 31",
    "authors": ["S. Martello", "M. Minoux", "C. Ribeiro", "G. Laporte"],
    "year": 1987
  }, {
    "title": "Solving the multiway matching problem by permutation synchronization",
    "authors": ["D. Pachauri", "R. Kondor", "V. Singh"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2013
  }, {
    "title": "Exponential family graph matching and ranking",
    "authors": ["J. Petterson", "J. Yu", "J.J. McAuley", "T.S. Caetano"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2009
  }, {
    "title": "Hammer: hierarchical attribute matching mechanism for elastic registration",
    "authors": ["D. Shen", "C. Davatzikos"],
    "venue": "IEEE transactions on medical imaging,",
    "year": 2002
  }, {
    "title": "Three-dimensional structure determination from common lines in cryo-em by eigenvectors and semidefinite programming",
    "authors": ["A. Singer", "Y. Shkolnisky"],
    "venue": "SIAM journal on imaging sciences,",
    "year": 2011
  }, {
    "title": "Computer vision: algorithms and applications",
    "authors": ["R. Szeliski"],
    "venue": "Springer Science & Business Media,",
    "year": 2010
  }, {
    "title": "Concentration of measure and isoperimetric inequalities in product spaces",
    "authors": ["M. Talagrand"],
    "venue": "Publications Mathématiques de l’Institut des Hautes Études Scientifiques,",
    "year": 1995
  }, {
    "title": "Global alignment of protein–protein interaction networks by graph matching methods",
    "authors": ["M. Zaslavskiy", "F. Bach", "Vert", "J.-P"],
    "venue": "Bioinformatics, 25(12):i259–1267,",
    "year": 2009
  }, {
    "title": "Probabilistic graph and hypergraph matching",
    "authors": ["R. Zass", "A. Shashua"],
    "venue": "In Computer Vision and Pattern Recognition,",
    "year": 2008
  }, {
    "title": "Deformable graph matching",
    "authors": ["F. Zhou", "F. De la Torre"],
    "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,",
    "year": 2013
  }, {
    "title": "Factorized graph matching",
    "authors": ["F. Zhou", "F. De la Torre"],
    "venue": "Transactions on Pattern Analysis and Machine Intelligence (PAMI),",
    "year": 2016
  }],
  "id": "SP:38ec29890c5ab7e94aad697996a1abe6df103c2b",
  "authors": [{
    "name": "Charu Sharma",
    "affiliations": []
  }, {
    "name": "Deepak Nathani",
    "affiliations": []
  }, {
    "name": "Manohar Kaul",
    "affiliations": []
  }],
  "abstractText": "We present an alternate formulation of the partial assignment problem as matching random clique complexes, that are higher-order analogues of random graphs, designed to provide a set of invariants that better detect higher-order structure. The proposed method creates random clique adjacency matrices for each k-skeleton of the random clique complexes and matches them, taking into account each point as the affine combination of its geometric neighborhood. We justify our solution theoretically, by analyzing the runtime and storage complexity of our algorithm along with the asymptotic behavior of the quadratic assignment problem (QAP) that is associated with the underlying random clique adjacency matrices. Experiments on both synthetic and real-world datasets, containing severe occlusions and distortions, provide insight into the accuracy, efficiency, and robustness of our approach. We outperform diverse matching algorithms by a significant margin.",
  "title": "Solving Partial Assignment Problems using Random Clique Complexes"
}