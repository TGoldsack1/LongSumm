{
  "sections": [{
    "text": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 2061–2071 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics\n2061"
  }, {
    "heading": "1 Introduction",
    "text": "Semantic role labeling (SRL), namely semantic parsing, is a shallow semantic parsing task, which aims to recognize the predicate-argument structure of each predicate in a sentence, such as who did what to whom, where and when, etc. Specifically, we seek to identify arguments and label their semantic roles given a predicate. SRL is an impor-\n∗ These authors made equal contribution.† Corresponding author. This paper was partially supported by National Key Research and Development Program of China (No. 2017YFB0304100), National Natural Science Foundation of China (No. 61672343 and No. 61733011), Key Project of National Society Science Foundation of China (No. 15- ZDA041), The Art and Science Interdisciplinary Funds of Shanghai Jiao Tong University (No. 14JCRZ04).\ntant method to obtain semantic information beneficial to a wide range of natural language processing (NLP) tasks, including machine translation (Shi et al., 2016), question answering (Berant et al., 2013; Yih et al., 2016) and discourse relation sense classification (Mihaylov and Frank, 2016).\nThere are two formulizations for semantic predicate-argument structures, one is based on constituents (i.e., phrase or span), the other is based on dependencies. The latter proposed by the CoNLL-2008 shared task (Surdeanu et al., 2008) is also called semantic dependency parsing, which annotates the heads of arguments rather than phrasal arguments. Generally, SRL is decomposed into multi-step classification subtasks in pipeline systems, consisting of predicate identification and disambiguation, argument identification and classification.\nIn prior work of SRL, considerable attention has been paid to feature engineering that struggles to capture sufficient discriminative information, while neural network models are capable of extracting features automatically. In particular, syntactic information, including syntactic tree feature, has been show extremely beneficial to SRL since a larger scale of empirical verification of Punyakanok et al. (2008). However, all the work had to take the risk of erroneous syntactic input, leading to an unsatisfactory performance.\nTo alleviate the above issues, Marcheggiani et al. (2017) propose a simple but effective model for dependency SRL without syntactic input. It seems that neural SRL does not have to rely on syntactic features, contradicting with the belief that syntax is a necessary prerequisite for SRL as early as Gildea and Palmer (2002). This dramatic contradiction motivates us to make a thorough exploration on syntactic contribution to SRL.\nThis paper will focus on semantic dependency parsing and formulate SRL as one or two se-\nquence tagging tasks with predicate-specific encoding. With the help of the proposed k-order argument pruning algorithm over syntactic tree, our model obtains state-of-the-art scores on the CoNLL benchmarks for both English and Chinese.\nIn order to quantitatively evaluate the contribution of syntax to SRL, we adopt the ratio between labeled F1 score for semantic dependencies (Sem-F1) and the labeled attachment score (LAS) for syntactic dependencies introduced by CoNLL2008 Shared Task1 as evaluation metric. Considering that various syntactic parsers contribute different syntactic inputs with various range of quality levels, the ratio provides a fairer comparison between syntactically-driven SRL systems, which will be surveyed by our empirical study."
  }, {
    "heading": "2 Model",
    "text": "To fully disclose the predicate-argument structure, typical SRL systems have to step by step perform four subtasks. Since the predicates in CoNLL2009 (Hajič et al., 2009) corpus have been preidentified, we need to tackle three other subtasks, which are formulized into two-step pipeline in this work, predicate disambiguation and argument labeling. Namely, we do the work of argument identification and classification in one model.\nArgument structure for each known predicate will be disclosed by our argument labeler over a sequence including possible arguments (candidates). There are two ways to determine the sequence, one is to simply input the entire sentence as a syntax-agnostic SRL system does, the other is to select words according to syntactic parse tree around the predicate as most previous SRL systems did. The latter strategy usually works through a syntactic tree based argument pruning algorithm. We will use the proposed k-order argument pruning algorithm (Section 2.1) to get a sequence w = (w1, . . . , wn) for each predicate. Then, we represent each word wi ∈ w as xi (Section 2.2). Eventually, we obtain contextual features with sequence encoder (Section 2.3). The overall role labeling model is depicted in Figure 1."
  }, {
    "heading": "2.1 Argument Pruning",
    "text": "As pointed out by Punyakanok et al. (2008), syntactic information is most relevant in identifying\n1CoNLL-2008 is an English-only task, while CoNLL2009 extends to a multilingual one. Their main difference is that predicates have been beforehand indicated for the latter.\nthe arguments, and the most crucial contribution of full parsing is in the pruning stage. In this paper, we propose a k-order argument pruning algorithm inspired by Zhao et al. (2009b). First of all, for node n and its descendant nd in a syntactic dependency tree, we define the order to be the distance between the two nodes, denoted as D(n, nd). Then we define k-order descendants of given node satisfying D(n, nd) = k, and k-order traversal that visits each node from the given node to its descendant nodes within k-th order. Note that the definition of k-order traversal is somewhat different from tree traversal in terminology.\nA brief description of the proposed k-order pruning algorithm is given as follow. Initially, we set a given predicate as the current node in a syntactic dependency tree. Then, collect all its argument candidates by the strategy of k-order traversal. Afterwards, reset the current node to its syntactic head and repeat the previous step till the root of the tree. Finally, collect the root and stop. The k-order argument algorithm is presented in Algorithm 1 in detail. An example of a syntactic dependency tree for sentence She began to trade the art for money is shown in Figure 2.\nThe main reasons for applying the extended korder argument pruning algorithm are two-fold.\nAlgorithm 1 k-order argument pruning algorithm Input: A predicate p, the root node r given a syn-\ntactic dependency tree T , the order k Output: The set of argument candidates S\n1: initialization set p as current node c, c = p 2: for each descendant ni of c in T do 3: if D(c, ni) ≤ k and ni /∈ S then 4: S = S + ni 5: end if 6: end for 7: find the syntactic head ch of c, and let c = ch 8: if c = r then 9: S = S + r\n10: else 11: goto step 2 12: end if 13: return argument candidates set S\nFirst, previous standard pruning algorithm may hurt the argument coverage too much, even though indeed arguments usually tend to surround their predicate in a close distance. As a sequence tagging model has been applied, it can effectively handle the imbalanced distribution between arguments and non-arguments, which is hardly tackled by early argument classification models that commonly adopt the standard pruning algorithm. Second, the extended pruning algorithm provides a better trade-off between computational cost and performance by carefully tuning k."
  }, {
    "heading": "2.2 Word Representation",
    "text": "We produce a predicate-specific word representation xi for each word wi, where i stands for the word position in an input sequence, following Marcheggiani et al. (2017). However, we differ by (1) leveraging a predicate-specific indicator embedding, (2) using deeper refined representation, including character and dependency relation embeddings, and (3) applying recent advances in RNNs, such as highway connections (Srivastava et al., 2015).\nIn this work, word representation xi is the concatenation of four types of features: predicatespecific feature, character-level, word-level and linguistic features. Unlike previous work, we leverage a predicate-specific indicator embedding xiei rather than directly using a binary flag either 0 or 1. At character level, we exploit convolutional neural network (CNN) with bidirectional LSTM (BiLSTM) to learn character embedding\nxcei . As shown in Figure 1, the representation calculated by the CNN is fed as input to BiLSTM. At word level, we use a randomly initialized word embedding xrei and a pre-trained word embedding xpei . For linguistic features, we employ a randomly initialized lemma embedding xlei and a randomly initialized POS tag embedding xposi . In order to incorporate more syntactic information, we adopt an additional feature, the dependency relation to syntactic head. Likewise, it is a randomly initialized embedding xdei . The resulting word representation is concatenated as xi = [x ie i , x ce i , x re i , x pe i , x le i , x pos i , x de i ]."
  }, {
    "heading": "2.3 Sequence Encoder",
    "text": "As Long short-term memory (LSTM) networks (Hochreiter and Schmidhuber, 1997) have shown significant representational effectiveness to NLP tasks, we thus use BiLSTM as the sentence encorder. Given an input sequence x = (x1, . . . , xn), BiLSTM processes the sequence in both forward and backward direction to obtain two separated hidden states, −→ h i which handles data from x1 to xi and ←− h i which tackles data from xn to xi for each word representation. Finally, we get a contextual representation hi = [ −→ h i, ←− h i] by concatenating the states of BiLSTM networks. To get the final predicted semantic roles, we exploit a multi-layer perceptron (MLP) with highway connections on the top of BiLSTM networks, which takes as input the hidden representation hi\nof all time steps. The MLP network consists of 10 layers with highway connections and we employ ReLU activations for the hidden layers. Finally, we use a softmax layer over the outputs to maximize the likelihood of labels."
  }, {
    "heading": "2.4 Predicate Disambiguation",
    "text": "Although predicates have been identified given a sentence, predicate disambiguation is an indispensable task, which aims to determine the predicate-argument structure for an identified predicate in a particular context. Here, we also use the identical model (BiLSTM composed with MLP) for predicate disambiguation, in which the only difference is that we remove the syntactic dependency relation feature in corresponding word representation (Section 2.2). Exactly, given a predicate p, the resulting word representation is pi = [p ie i , p ce i , p re i , p pe i , p le i , p pos i ]."
  }, {
    "heading": "3 Experiments",
    "text": "Our model2 is evaluated on the CoNLL-2009 shared task both for English and Chinese datasets, following the standard training, development and test splits. The hyperparameters in our model were selected based on the development set, and are summarized in Table 1. Note that the parameters of predicate model are the same as these in argument model. All real vectors are randomly initialized, and the pre-trained word embeddings for English are GloVe vectors (Pennington et al., 2014). For Chinese, we exploit Wikipedia documents to train Word2Vec embeddings (Mikolov\n2The code is available at https://github.com/ bcmi220/srl_syn_pruning.\net al., 2013). During training procedures, we use the categorical cross-entropy as objective, with Adam optimizer (Kingma and Ba, 2015). We train models for a maximum of 20 epochs and obtain the nearly best model based on development results. For argument labeling, we preprocess corpus with k-order argument pruning algorithm. In addition, we use four CNN layers with singlelayer BiLSTM to induce character representations derived from sentences. For English3, to further enhance the representation, we adopt CNNBiLSTM character embedding structure from AllenNLP toolkit (Peters et al., 2018)."
  }, {
    "heading": "3.1 Preprocessing",
    "text": "During the pruning of argument candidates, we use the officially predicted syntactic parses provided by CoNLL-2009 shared-task organizers on both English and Chinese. Figure 3 shows changing curves of coverage and reduction following k on the English train set. According to our statistics, the number of non-arguments is ten times more than that of arguments, where the data distribution is fairly unbalanced. However, a proper pruning strategy could alleviate this problem. Accordingly, the first-order pruning reduces more than 50% candidates at the cost of missing 5.5% true ones on average, and the second-order prunes about 40% candidates with nearly 2.0% loss. The coverage of third-order has achieved 99% and it reduces approximately 1/3 corpus size.\nIt is worth noting that as k is larger than 19,\n3For Chinese, we do not use character embedding.\nthere will come full coverage on all argument candidates for English training set, which let our high order pruning algorithm degrade into a syntaxagnostic setting. In this work, we use the tenthorder pruning for pursuing the best performance."
  }, {
    "heading": "3.2 Results",
    "text": "Our system performance is measured with the official script from CoNLL-2009 benchmarks, combining the output of our predicate disambiguation with our semantic role labeling. Our predicate disambiguation model achieves the accuracy of 95.01% and 95.58%4 on development and test sets, respectively. We compare our model performance with the state-of-the-art models for dependency SRL.5 Noteworthily, our model is local and single without reranking, which neither includes global inference nor combines multiple models. The experimental results on the English in-domain (WSJ) and out-of-domain (Brown) test sets are shown in Tables 2 and 3, respectively.\nFor English, our syntax-aware model outperforms previously published best single model, scoring 89.5% F1 with 1.5% absolute improvement on the in-domain (WSJ) test data. Compared\n4Note that we give a slightly better predicate model than Roth and Lapata (2016), with 94.77% and 95.47% accuracy on development and test sets, respectively.\n5Here, we do not compare against span-based SRL models, which annotate roles for entire argument spans instead of semantic dependencies.\nwith ensemble models, our single model even provides better performance (+0.4% F1) than the system (Marcheggiani and Titov, 2017), and significantly surpasses all the rest models. In the syntaxagnostic setting (without pruning and dependency relation embedding), we also reach the new stateof-the-art, achieving a performance gain of 1% F1.\nOn the out-of-domain (Brown) test set, we achieve the new best results of 79.3% (syntaxaware) and 78.8% (syntax-agnostic) in F1 scores. Moreover, our syntax-aware model performs better than the syntax-agnostic one.\nTable 4 presents the results on Chinese test set. Even though we use the same parameters as for English, our model also outperforms the best reported results by 0.3% (syntax-aware) and 0.6% (syntax-agnostic) in F1 scores."
  }, {
    "heading": "3.3 Analysis",
    "text": "To evaluate the contributions of key factors in our method, a series of ablation studies are performed on the English development set.\nIn order to demonstrate the effectiveness of our k-order pruning algorithm, we report the SRL performance excluding predicate senses in evaluation, eliminating the performance gain from predicate disambiguation. Table 5 shows the results from our syntax-aware model with lower order argument pruning. Compared to the best previous model, our system still yields an increment in recall by more than 1%, leading to improvements in F1 score. It demonstrates that refining syntactic parser tree based candidate pruning does help in argument recognition.\nTable 6 presents the performance of our syntaxagnostic SRL system with a basic configuration, which removes components, including indicator and character embeddings. Note that the first row is the results of BiLSTM (removing MLP from basic model), whose encoding is the same as Marcheggiani et al. (2017). Experiments show that both enhanced representations improve over our basic model, and our adopted labeling model is superior to the simple BiLSTM.\nFigure 4 shows F1 scores in different k-order pruning together with our syntax-agnostic model. It also indicates that the least first-order pruning fails to give satisfactory performance, the best performing setting coming from a moderate setting of k = 10, and the largest k shows that our argu-\nment pruning falls back to syntax-agnostic type. Meanwhile, from the best k setting to the lower order pruning, we receive a much faster performance drop, compared to the higher order pruning until the complete syntax-agnostic case. The proposed k-order pruning algorithm always works even it reaches the syntax-agnostic setting, which empirically explains why the current syntax-aware and syntax-agnostic SRL models hold little performance difference, as maximum k-order pruning actually removes few words just like syntaxagnostic model."
  }, {
    "heading": "3.4 End-to-end SRL",
    "text": "In this work, we consider additional model that integrates predicate disambiguation and argument labeling into one sequence labeling model. In order to implement an end-to-end model, we introduce a virtual root (VR) for predicate disambiguation similar to Zhao et al. (2013) who handled the entire SRL task as word pair classification. Concretely, we add a predicate sense feature to the input sequence by concatenating a VR. The word representation of VR is randomly initialized during training. In Figure 5, we give an example sequence with the labels for the given sentence.\nWe also report results of our end-to-end model on CoNLL-2009 test set with syntax-aware and syntax-agnostic settings. As shown in Table 7, our end-to-end model yields slightly weaker performance compared with our pipeline. A reasonable account for performance degradation is that the training data has completely different genre distributions over predicate senses and argument roles, which may be somewhat confusing for integrative model to make classification decisions."
  }, {
    "heading": "3.5 CoNLL-2008 SRL Setting",
    "text": "For a full SRL task, the predicate identification subtask is also indispensable, which has been included in CoNLL-2008 shared task. We thus evaluate our model in terms of data and setting of the CoNLL-2008 benchmark (WSJ).\nTo identify predicates, we train the BiLSTMMLP sequence labeling model with same parameters in Section 2.4 to tackle the predicate identification and disambiguation subtasks in one shot, and the only difference is that we remove the predicate-specific indicator feature. The F1 score of our predicate labeling model is 90.53% on indomain (WSJ) data. Compared with the best reported results, we observe absolute improvements in semantic F1 of 0.8% (in Table 8). Note that as predicate identification is introduced, our same model shows about 6% performance loss for either syntax-agnostic or syntax-aware case, which indicates that predicate identification should be carefully handled, as it is very needed in a complete practical SRL system."
  }, {
    "heading": "4 Syntactic Contribution",
    "text": "Syntactic information plays an informative role in semantic role labeling. However, few studies were done to quantitatively evaluate the syntactic contribution to SRL. Furthermore, we observe that most of the above compared neural SRL systems took the syntactic parser of (Björkelund et al., 2010) as syntactic inputs instead of the one from CoNLL-2009 shared task, which adopted a much weaker syntactic parser. Especially (Marcheggiani and Titov, 2017), adopted an external syntactic\nparser with even higher parsing accuracy. Contrarily, our SRL model is based on the automatically predicted parse with moderate performance provided by CoNLL-2009 shared task, but outperforms their models.\nThis section thus attempts to explore how much syntax contributes to dependency-based SRL in deep learning framework and how to effectively evaluate relative performance of syntax-based SRL. To this end, we conduct experiments for empirical analysis with different syntactic inputs.\nSyntactic Input In order to obtain different syntactic inputs, we design a faulty syntactic tree generator (refer to STG hereafter), which is able to produce random errors in the output parse tree like a true parser does. To simplify implementation, we construct a new syntactic tree based on the gold standard parse tree. Given an input error probability distribution estimated from a true parser output, our algorithm presented in Algorithm 2 stochastically modifies the syntactic heads of nodes on the premise of a valid tree.\nEvaluation Measure For SRL task, the primary evaluation measure is the semantic labeled F1 score. However, the score is influenced by the quality of syntactic input to some extent, leading to unfaithfully reflecting the competence of syntax-based SRL system. Namely, this is not the outcome of a true and fair quantitative comparison for these types of SRL models. To normalize the semantic score relative to syntactic parse, we take into account additional evaluation measure to estimate the actual overall performance of SRL. Here, we use the ratio between labeled F1 score for semantic dependencies (Sem-F1) and the labeled attachment score (LAS) for syntactic dependencies\nAlgorithm 2 Faulty Syntactic Tree Generator Input: A gold standard syntactic tree GT , the\nspecific error probability p Output: The new generative syntactic tree NT\n1: N denotes the number of nodes in GT 2: for each node n ∈ GT do 3: r = random(0, 1), a random number 4: if r < p then 5: h = random(0, N ), a random integer 6: find the syntactic head nh of n in GT 7: modify nh = h, and get a new tree NT 8: if NT is a valid tree then 9: break\n10: else 11: goto step 5 12: end if 13: end if 14: end for 15: return the new generative tree NT\nproposed by Surdeanu et al. (2008) as evaluation metric.6 The benefits of this measure are twofold: quantitatively evaluating syntactic contribution to SRL and impartially estimating the true performance of SRL, independent of the performance of the input syntactic parser.\nTable 9 reports the performance of existing models7 in term of Sem-F1/LAS ratio on CoNLL2009 English test set. Interestingly, even though our system has significantly lower scores than others by 3.8% LAS in syntactic components, we\n6The idea of ratio score in Surdeanu et al. (2008) actually was from author of this paper, Hai Zhao, which has been indicated in the acknowledgement part of Surdeanu et al. (2008).\n7Note that several SRL systems without providing syntactic information are not listed in the table.\nobtain the highest results both on Sem-F1 and the Sem-F1/LAS ratio, respectively. These results show that our SRL component is relatively much stronger. Moreover, the ratio comparison in Table 9 also shows that since the CoNLL-2009 shared task, most SRL works actually benefit from the enhanced syntactic component rather than the improved SRL component itself. All post-CoNLL SRL systems, either traditional or neural types, did not exceed the top systems of CoNLL-2009 shared task, (Zhao et al., 2009c) (SRL-only track using the provided predicated syntax) and (Zhao et al., 2009a) (Joint track using self-developed parser). We believe that this work for the first time reports both higher Sem-F1 and higher Sem-F1/LAS ratio since CoNLL-2009 shared task.\nWe also perform our first and tenth order pruning models with different erroneous syntactic inputs generated from STG and evaluate their per-\nformance using the Sem-F1/LAS ratio. Figure 6 shows Sem-F1 scores at different quality of syntactic parse inputs on the English test set whose LAS varies from 85% to 100%. Compared to previous state-of-the-arts (Marcheggiani and Titov, 2017). Our tenth-order pruning model gives quite stable SRL performance no matter the syntactic input quality varies in a broad range, while our firstorder pruning model yields overall lower results (1-5% F1 drop), owing to missing too many true arguments. These results show that high-quality syntactic parses may indeed enhance dependency SRL. Furthermore, it indicates that our model with an accurate enough syntactic input as Marcheggiani and Titov (2017), namely, 90% LAS, will give a Sem-F1 exceeding 90% for the first time in the research timeline of semantic role labeling."
  }, {
    "heading": "5 Related Work",
    "text": "Semantic role labeling was pioneered by Gildea and Jurafsky (2002). Most traditional SRL models rely heavily on feature templates (Pradhan et al., 2005; Zhao et al., 2009b; Björkelund et al., 2009). Among them, Pradhan et al. (2005) combined features derived from different syntactic parses based on SVM classifier, while Zhao et al. (2009b) presented an integrative approach for dependency SRL by greedy feature selection algorithm. Later, Collobert et al. (2011) proposed a convolutional neural network model of inducing word embeddings substituting for hand-crafted features, which was a breakthrough for SRL task.\nWith the impressive success of deep neural networks in various NLP tasks (Zhang et al., 2016; Qin et al., 2017; Cai et al., 2017), a series of neural SRL systems have been proposed. Foland and Martin (2015) presented a dependency semantic role labeler using convolutional and time-domain neural networks, while FitzGerald et al. (2015) exploited neural network to jointly embed arguments and semantic roles, akin to the work (Lei et al., 2015), which induced a compact feature representation applying tensor-based approach. Recently, researchers consider multiple ways to effectively integrate syntax into SRL learning. Roth and Lapata (2016) introduced dependency path embedding to model syntactic information and exhibited a notable success. Marcheggiani and Titov (2017) leveraged the graph convolutional network to incorporate syntax into neural models. Differently, Marcheggiani et al. (2017) proposed a\nsyntax-agnostic model using effective word representation for dependency SRL, which for the first time achieves comparable performance as stateof-the-art syntax-aware SRL models.\nHowever, most neural SRL works seldom pay much attention to the impact of input syntactic parse over the resulting SRL performance. This work is thus more than proposing a high performance SRL model through reviewing the highlights of previous models, and presenting an effective syntactic tree based argument pruning. Our work is also closely related to (Punyakanok et al., 2008; He et al., 2017). Under the traditional methods, Punyakanok et al. (2008) investigated the significance of syntax to SRL system and shown syntactic information most crucial in the pruning stage. He et al. (2017) presented extensive error analysis with deep learning model for span SRL, including discussion of how constituent syntactic parser could be used to improve SRL performance."
  }, {
    "heading": "6 Conclusion and Future Work",
    "text": "This paper presents a simple and effective neural model for dependency-based SRL, incorporating syntactic information with the proposed extended k-order pruning algorithm. With a large enough setting of k, our pruning algorithm will result in a syntax-agnostic setting for the argument labeling model, which smoothly unifies syntax-aware and syntax-agnostic SRL in a consistent way. Experimental results show that with the help of deep enhanced representation, our model outperforms the previous state-of-the-art models in both syntaxaware and syntax-agnostic situations.\nIn addition, we consider the Sem-F1/LAS ratio as a mean of evaluating syntactic contribution to SRL, and true performance of SRL independent of the quality of syntactic parser. Though we again confirm the importance of syntax to SRL with empirical experiments, we are aware that since (Pradhan et al., 2005), the gap between syntax-aware and syntax-agnostic SRL has been greatly reduced, from as high as 10% to only 1-2% performance loss in this work. However, maybe we will never reach a satisfying conclusion, as whenever one proposes a syntax-agnostic SRL system which can outperform all syntax-aware ones at then, always there comes argument that you have never fully explored creative new method to effectively exploit the syntax input."
  }],
  "year": 2018,
  "references": [{
    "title": "Semantic parsing on Freebase from question-answer pairs",
    "authors": ["Jonathan Berant", "Andrew Chou", "Roy Frostig", "Percy Liang."],
    "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP). Seattle, Washington,",
    "year": 2013
  }, {
    "title": "A high-performance syntactic and semantic dependency parser",
    "authors": ["Anders Björkelund", "Bohnet Bernd", "Love Hafdell", "Pierre Nugues."],
    "venue": "Proceedings of the 23rd International Conference on Computational Linguistics (CoLING 2010). Beijing, China,",
    "year": 2010
  }, {
    "title": "Multilingual semantic role labeling",
    "authors": ["Anders Björkelund", "Love Hafdell", "Pierre Nugues."],
    "venue": "Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task. Boulder, Colorado, pages 43–48.",
    "year": 2009
  }, {
    "title": "Fast and accurate neural word segmentation for Chinese",
    "authors": ["Deng Cai", "Hai Zhao", "Zhisong Zhang", "Yuan Xin", "Yongjian Wu", "Feiyue Huang."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL). Van-",
    "year": 2017
  }, {
    "title": "Natural language processing (almost) from scratch",
    "authors": ["Ronan Collobert", "Jason Weston", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."],
    "venue": "Journal of Machine Learning Research 12(1):2493–2537.",
    "year": 2011
  }, {
    "title": "Semantic role labeling with neural network factors",
    "authors": ["Nicholas FitzGerald", "Oscar Tckstrm", "Kuzman Ganchev", "Dipanjan Das."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). pages",
    "year": 2015
  }, {
    "title": "Dependencybased semantic role labeling using convolutional neural networks",
    "authors": ["William Foland", "James Martin."],
    "venue": "Joint Conference on Lexical and Computational Semantics. pages 279–288.",
    "year": 2015
  }, {
    "title": "Automatic labeling of semantic roles",
    "authors": ["Daniel Gildea", "Daniel Jurafsky."],
    "venue": "Computational linguistics 28(3):245–288.",
    "year": 2002
  }, {
    "title": "The necessity of parsing for predicate argument recognition",
    "authors": ["Daniel Gildea", "Martha Palmer."],
    "venue": "Proceedings of 40th Annual Meeting of the Association for Computational Linguistics (ACL). Philadelphia, Pennsylvania, USA, pages 239–246.",
    "year": 2002
  }, {
    "title": "Deep semantic role labeling: What works and what’s next",
    "authors": ["Luheng He", "Kenton Lee", "Mike Lewis", "Luke Zettlemoyer."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL). Vancouver, Canada, pages",
    "year": 2017
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jrgen Schmidhuber."],
    "venue": "Neural Computation 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Dependency-based syntactic-semantic analysis with propbank and nombank",
    "authors": ["Richard Johansson", "Pierre Nugues."],
    "venue": "Proceedings of the Twelfth Conference on Computational Natural Language Learning (CoNLL). pages 183–187.",
    "year": 2008
  }, {
    "title": "Adam: A method for stochastic optimization",
    "authors": ["Diederik Kingma", "Jimmy Ba."],
    "venue": "Proceedings of the 3rd International Conference on Learning Representations (ICLR).",
    "year": 2015
  }, {
    "title": "High-order lowrank tensors for semantic role labeling",
    "authors": ["Tao Lei", "Yuan Zhang", "Lluı́s Màrquez", "Alessandro Moschitti", "Regina Barzilay"],
    "venue": "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Lin-",
    "year": 2015
  }, {
    "title": "A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling",
    "authors": ["Diego Marcheggiani", "Anton Frolov", "Ivan Titov."],
    "venue": "Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017).",
    "year": 2017
  }, {
    "title": "Encoding sentences with graph convolutional networks for semantic role labeling",
    "authors": ["Diego Marcheggiani", "Ivan Titov."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP). Copenhagen, Den-",
    "year": 2017
  }, {
    "title": "Discourse relation sense classification using cross-argument semantic similarity based on word embeddings",
    "authors": ["Todor Mihaylov", "Anette Frank."],
    "venue": "Proceedings of the Twentieth Conference on Computational Natural Language Learning - Shared Task",
    "year": 2016
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "Advances in Neural Information Processing Systems (NIPS). pages 3111–3119.",
    "year": 2013
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Doha, Qatar, pages 1532–",
    "year": 2014
  }, {
    "title": "Deep contextualized word representations",
    "authors": ["Matthew E. Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
    "year": 2018
  }, {
    "title": "Semantic role labeling using different syntactic views",
    "authors": ["Sameer Pradhan", "Wayne Ward", "Kadri Hacioglu", "James Martin", "Daniel Jurafsky."],
    "venue": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL). Ann Arbor,",
    "year": 2005
  }, {
    "title": "The importance of syntactic parsing and inference in semantic role labeling",
    "authors": ["Vasin Punyakanok", "Dan Roth", "Wen-tau Yih."],
    "venue": "Computational Linguistics 34(2):257–287.",
    "year": 2008
  }, {
    "title": "Adversarial connectiveexploiting networks for implicit discourse relation classification",
    "authors": ["Lianhui Qin", "Zhisong Zhang", "Hai Zhao", "Zhiting Hu", "Eric Xing."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Lin-",
    "year": 2017
  }, {
    "title": "Neural semantic role labeling with dependency path embeddings",
    "authors": ["Michael Roth", "Mirella Lapata."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL). Berlin, Germany, pages 1192–1202.",
    "year": 2016
  }, {
    "title": "Knowledge-based semantic embedding for machine translation",
    "authors": ["Chen Shi", "Shujie Liu", "Shuo Ren", "Shi Feng", "Mu Li", "Ming Zhou", "Xu Sun", "Houfeng Wang."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
    "year": 2016
  }, {
    "title": "Training very deep networks",
    "authors": ["Rupesh K Srivastava", "Klaus Greff", "Jürgen Schmidhuber."],
    "venue": "Advances in neural information processing systems. pages 2377–2385.",
    "year": 2015
  }, {
    "title": "The conll 2008 shared task on joint parsing of syntactic and semantic dependencies",
    "authors": ["Mihai Surdeanu", "Richard Johansson", "Adam Meyers", "Lluı́s Màrquez", "Joakim Nivre"],
    "venue": "In Proceedings of the Twelfth Conference on Computational Natural Language",
    "year": 2008
  }, {
    "title": "The value of semantic parse labeling for knowledge base question answering",
    "authors": ["Wen-tau Yih", "Matthew Richardson", "Chris Meek", "MingWei Chang", "Jina Suh."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
    "year": 2016
  }, {
    "title": "Probabilistic graph-based dependency parsing with convolutional neural network",
    "authors": ["Zhisong Zhang", "Hai Zhao", "Lianhui Qin."],
    "venue": "Proceedings of the",
    "year": 2016
  }],
  "id": "SP:c7b2df69702d06a8cb99ddb48fdf29f05ac5a7ef",
  "authors": [{
    "name": "Shexia He",
    "affiliations": []
  }, {
    "name": "Zuchao Li",
    "affiliations": []
  }, {
    "name": "Hai Zhao",
    "affiliations": []
  }, {
    "name": "Hongxiao Bai",
    "affiliations": []
  }, {
    "name": "Gongshen Liu",
    "affiliations": []
  }],
  "abstractText": "Semantic role labeling (SRL) is dedicated to recognizing the predicate-argument structure of a sentence. Previous studies have shown syntactic information has a remarkable contribution to SRL performance. However, such perception was challenged by a few recent neural SRL models which give impressive performance without a syntactic backbone. This paper intends to quantify the importance of syntactic information to dependency SRL in deep learning framework. We propose an enhanced argument labeling model companying with an extended korder argument pruning algorithm for effectively exploiting syntactic information. Our model achieves state-of-the-art results on the CoNLL-2008, 2009 benchmarks for both English and Chinese, showing the quantitative significance of syntax to neural SRL together with a thorough empirical survey over existing models.",
  "title": "Syntax for Semantic Role Labeling, To Be, Or Not To Be"
}