{
  "sections": [{
    "text": "Proceedings of NAACL-HLT 2018, pages 386–396 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Human reasoning is lazy and biased but it perfectly serves its purpose in the argumentative context (Mercier and Sperber, 2017). When challenged by genuine back-and-forth argumentation, humans do better in both generating and evaluating arguments (Mercier and Sperber, 2011). The dialogical perspective on argumentation has been reflected in argumentation theory prominently by the pragma-dialectic model of argumentation (van Eemeren and Grootendorst, 1992). Not only sketches this theory an ideal normative model of argumentation but also distinguishes the wrong argumentative moves, fallacies (van Eemeren and Grootendorst, 1987). Among the plethora of prototypical fallacies, notwithstanding the controversy of most taxonomies (Boudry et al., 2015), ad hominem argument is perhaps the most famous one. Arguing against the person is considered faulty, yet is prevalent in online and offline discourse.1\n1According to ‘Godwin’s law’ known from the internet pop-culture (https://en.wikipedia.org/wiki/\nAlthough the ad hominem fallacy has been known since Aristotle, surprisingly there are very few empirical works investigating its properties. While Sahlane (2012) analyzed ad hominem and other fallacies in several hundred newspaper editorials, others usually only rely on few examples, as observed by de Wijze (2002). As Macagno (2013) concludes, ad hominem arguments should be considered as multifaceted and complex strategies, involving not a simple argument, but several combined tactics. However, such research, to the best of our knowledge, does not exist. Very little is known not only about the feasibility of ad hominem theories in practical applications (the NLP perspective) but also about the dynamics and triggers of ad hominem (the theoretical counterpart).\nThis paper investigates the research gap at three levels of increasing discourse complexity: ad hominem in isolation, direct ad hominem without dialogical exchange, and ad hominem in large inter-personal discourse context. We asked the following research questions. First, what qualitative and quantative properties do ad hominem arguments have in Web debates and how does that reflect the common theoretical view (RQ1)? Second, how much of the debate context do we need for recognizing ad hominem by humans and machine learning systems (RQ2)? And finally, what are the actual triggers of ad hominem arguments and can we predict whether the discussion is going to end up with one (RQ3)?\nWe tackle these questions by leveraging Webbased argumentation data (Change my View on Reddit), performing several large-scale annotation studies, and creating a new dataset. We experiment with various neural architectures and ex-\nGodwin’s_law), if a discussion goes on long enough, sooner or later someone will compare someone or something to Adolf Hitler.\n386\ntrapolate the trained models to validate our working hypotheses. Furthermore, we propose a list of potential linguistic and rhetorical triggers of ad hominem based on interpreting parameters of trained neural models.2 This article thus presents the first NLP work on multi-faceted ad hominem fallacies in genuine dialogical argumentation. We also release the data and the source code to the research community.3"
  }, {
    "heading": "2 Theoretical background and related work",
    "text": "The prevalent view on argumentation emphasizes its pragmatic goals, such as persuasion and groupbased deliberation (van Eemeren et al., 2014), although numerous works have dealt with argument as product, that is, treating a single argument and its properties in isolation (Toulmin, 1958; Habernal and Gurevych, 2017). Yet the social role of argumentation and its alleged responsibility for the very skill of human reasoning explained from the evolutionary perspective (Mercier and Sperber, 2017) provide convincing reasons to treat argumentation as an inherently dialogical tool.\nThe observation that some arguments are in fact ‘deceptions in disguise’ was made already by Aristotle (Aristotle and Kennedy (translator), 1991), for which the term fallacy has been adopted. Leaving the controversial typology of fallacies aside (Hamblin, 1970; van Eemeren and Grootendorst, 1987; Boudry et al., 2015), the ad hominem argument is addressed in most theories. Ad hominem argumentation relies on the strategy of attacking the opponent and some feature of the opponent’s character instead of the counterarguments (Tindale, 2007). With few exceptions, the following five sub-types of ad hominem are prevalent in the literature: abusive ad hominem (a pure attack on the character of the opponent), tu quoque ad hominem (essentially analogous to the “He did it first” defense of a three-year-old in a sandbox), circumstantial ad hominem (the “practice what you preach” attack and accusation of hypocrisy), bias ad hominem (the attacked opponent has a hidden agenda), and guilt by association (associating the opponent with somebody with a low credibility) (Schiappa and Nordin,\n2An attempt to address the plea for thinking about problems, cognitive science, and the details of human language (Manning, 2015).\n3https://github.com/UKPLab/ naacl2018-before-name-calling-habernal-et-al\n2013; Macagno, 2013; Walton, 2007; Hansen, 2017; Woods, 2008). We omit examples here as these provided in theoretical works or textbooks are usually artificial, as already criticized by (de Wijze, 2002) or (Boudry et al., 2015).\nThe topic of fallacies, which might be considered as sub-topic of argumentation quality, has recently been investigated also in the NLP field. Existing works are, however, limited to the monological view (Wachsmuth et al., 2017; Habernal and Gurevych, 2016b,a; Stab and Gurevych, 2017) or they focus primarily on learning fallacy recognition by humans (Habernal et al., 2017, 2018a). Another related NLP sub-field includes abusive language and personal attacks in general. Wulczyn et al. (2017) investigated whether or not Wikipedia talk page comments are personal attacks and annotated 38k instances resulting in a highly skewed distribution (only 0.9% were actual attacks). Regarding the participants’ perspective, Jain et al. (2014) examined principal roles in 80 discussions from the Wikipedia: Article for Deletion pages (focusing on stubbornness or ignoredness, among others) and found several typical roles, including ‘rebels’, ‘voices’, or ‘idiots’. In contrast to our data under investigation (Change My View debates), Wikipedia talk pages do not adhere to strict argumentation rules with manual moderation and have a different pragmatic purpose.\nReddit as a source platform has also been used in other relevant works. Saleem et al. (2016) detected hateful speech on Reddit by exploiting particular sub-communities to automatically obtain training data. Wang et al. (2016) experimented with an unsupervised neural model to cluster social roles on sub-reddits dedicated to computer games. Zhang et al. (2017) proposed a set of nine comment-level dialogue act categories and annotated 9k threads with 100k comments and built a CRF classifier for dialogue act labeling. Unlike these works which were not related to argumentation, Tan et al. (2016) examined persuasion strategies on Change My View using word overlap features. In contrast to our work, they focused solely on the successful strategies with delta-awarded posts. Using the same dataset, Musi (2017) recently studied concession in argumentation."
  }, {
    "heading": "3 Data",
    "text": "Change My View (CMV) is an online ‘place to post an opinion you accept [...] in an effort to un-\nderstand other perspectives on the issue’, in other words an online platform for ‘good-faith’ argumentation hosted on Reddit.4 A user posts a submission (also called original post(er); OP) and other participants provide arguments to change the OP’s view, forming a typical tree-form Web discussion. A special feature of CMV is that the OP acknowledges convincing arguments by giving a delta point (∆). Unlike the vast majority of internet discussion forums, CMV enforces obeying strict rules (such as no ‘low effort’ posts, or accusing of being unwilling to change view) whose violation results into deleting the comment by moderators. These formal requirements of an ideal debate with the notion of violating rules correspond to incorrect moves in critical discussion in the normative pragma-dialectic theory (van Eemeren and Grootendorst, 1987). Thus, violating the rule of ‘not being rude or hostile’ is equivalent to committing ad hominem fallacy. For our experiments, we scraped, in cooperation with Reddit, the complete CMV including the content of the deleted comments so we could fully reconstruct the fallacious discussions, relying on the rule violation labels provided by the moderators. The dataset contains ≈ 2M posts in 32k submissions, forming 780k unique threads.\nWe will set up the stage for further experiments by providing several quantitative statistics we performed on the dataset. Only 0.2% posts in CMV are ad hominem arguments. This contrasts with a typical online discussion: Coe et al. (2014) found 19.5% of comments under online news articles to be incivil. Most threads contain only a single ad hominem argument (3,396 threads; there are 3,866 ad hominem arguments in total in CMV); only 35 threads contain more than three ad hominem arguments. In 48.6% of threads containing a single ad hominem, the ad hominem argument is the very last comment. This corresponds to the popular belief that if one is out of arguments, they start attacking and the discussion is over. This trend is also shown in Figure 1 which displays the relative position of the first ad hominem argument in a thread. Replying to ad hominem with another ad hominem happens only in 15% of the cases; this speaks for the attempts of CMV participants to keep up with the standards of a rather rational discussion.\nRegarding ad hominem authors, about 66% of\n4https://www.reddit.com/r/changemyview/\nthem start attacking ‘out of blue’, without any previous interaction in the thread. On the other hand, 11% ad hominem authors write at least one ‘normal’ argument in the thread (we found one outlier who committed ad hominem after writing 57 normal arguments in the thread). Only in 20% cases, the ad hominem thread is an interplay between the original poster and another participant. It means that there are usually more people involved in an ad hominem thread. Unfortunately, sometimes the OP herself also commits ad hominem (12%).\nWe also investigated the relation between the presence of ad hominem arguments and the submission topic. While most submissions are accompanied by only one or two ad hominem arguments (75% of submissions), there are also extremes with over 50 ad hominem arguments. Manual analysis revealed that these extremes deal with religion, sexuality/gender, U.S. politics (mostly Trump), racism in the U.S., and veganism. We will elaborate on that later in Section 4.2."
  }, {
    "heading": "4 Experiments",
    "text": "The experimental part is divided into three parts according to the increasing level of discourse complexity. We first experiment with ad hominem in isolation in section 4.1, then with direct ad hominem replies to original posts without dialogical exchange in section 4.2, and finally with ad hominem in a larger inter-personal discourse context in section 4.3."
  }, {
    "heading": "4.1 Ad hominem without context in CMV",
    "text": "The first experimental set-up examines ad hominem arguments in Change my view regardless of its dialogical context."
  }, {
    "heading": "4.1.1 Data verification",
    "text": "Ad hominem arguments labeled by the CMV moderators come with no warranty. To verify their reliability, we conducted the following annotation studies. First, we needed to estimate parameters of crowdsourcing and its reliability. We sampled 100 random arguments from CMV without context: positive candidates were the reported ad hominem arguments, whereas negative candidates were sampled from comments that either violate other argumentation rules or have a delta label. To ensure the maximal content similarity of these two groups, for each positive instance the semantically closest negative instance was selected.5 We then experimented with different numbers of Amazon Mechanical Turk workers and various thresholds of the MACE gold label estimator (Hovy et al., 2013); comparing two groups of six workers each and 0.9 threshold yielded almost perfect interannotator agreement (0.79 Cohen’s κ). We then used this setting (six workers, 0.9 MACE threshold) to annotate another 452 random arguments sampled in the same way as above.\nCrowdsourced ‘gold’ labels were then compared to the original CMV labels (balanced binary task: positive instances (ad hominem) and negative instances) reaching accuracy of 0.878. This means that the ad hominem labels from CMV moderators are quite reliable. Manual error analysis of disagreements revealed 11 missing ad hominem labels. These were not spotted by the moderators but were annotated as such by crowd workers."
  }, {
    "heading": "4.1.2 Recognizing ad hominem arguments",
    "text": "We sampled a larger balanced set of positive instances (ad hominem) and negative instances using the same methodology as in section 4.1.1, resulting in 7,242 instances, and casted the task of recognition of ad hominem arguments as a binary supervised task. We trained two neural classifiers, namely a 2-stacked bi-directional LSTM network (Graves and Schmidhuber, 2005), and a convolutional network (Kim, 2014), and evaluated them using 10-fold cross validation. Throughout the paper we use pre-trained word2vec word embeddings (Mikolov et al., 2013). Detailed hyperpa-\n5Similarity was computed using a cosine similarity of average embedding vectors multiplied by the argument length difference to minimize length-related artifacts. The sample was balanced with roughly 50% positive and 50% negative instances.\nrameters are described in the source codes (link provided in section 1). As results in Table 1 show, the task of recognizing ad hominem arguments is feasible and almost achieves the human upper bound performance."
  }, {
    "heading": "4.1.3 Typology of ad hominem",
    "text": "While binary classification of ad hominem as presented above might be sufficient for the purpose of red-flagging arguments, theories provide us with a much finer granularity (recall the typology in section 2). To validate whether this typology is empirically relevant, we executed an annotation experiment to classify ad hominem arguments into the provided five types (plus ‘other’ if none applies). We sampled 200 ad hominem arguments from threads in which interlocution happens only between two persons and which end up with ad hominem. The Mechanical Turk workers were shown this last ad hominem argument as well as the preceding one. Each instance was annotated by 16 workers to achieve a stable distribution of labels as suggested by Aroyo and Welty (2015). While 41% arguments were categorized as abusive, other categories (tu quoque, circumstantial, and guilt by association) were found to be rather ambiguous with very subtle differences. In particular, we observed a very low percentage agreement on these categories and a label distribution spiked around two or more categories. After a manual inspection we concluded that (1) the theoretical typology does not account for longer ad hominem arguments that mix up different attacks and that (2) there are actual phenomena in ad hominem arguments not covered by theoretical categories. These observations reflect those of Macagno (2013, p. 399) about ad hominem moves as multifaceted strategies.\nWe thus propose a list of phenomena typical to ad hominem arguments in CMV based on our empirical study. For this purpose, we follow up with another annotation experiment on 400 arguments, with seven workers per instance.6 The goal was\n6Here we decided on seven workers per item by relying on other span annotation experiments done in a similar setup (Habernal et al., 2018b).\nto annotate a text span which made the argument an ad hominem; a single argument could contain several spans. We estimated the gold spans using MACE and performed a manual post-analysis by designing a typology of causes of ad hominem together with their frequency of occurrence. The results and examples are summarized in Table 2."
  }, {
    "heading": "4.1.4 Results and interpretation",
    "text": "The data verification annotation study (section 4.1.1) has two direct consequences. First, the high κ score (0.79) answers RQ2: for recognizing ad hominem argument, no previous context is necessary. Second, we still found 5% overlooked ad hominem arguments in CMV thus a moderationfacilitating tool might come handy; this can be served by the well-performing CNN model (0.810 accuracy; section 4.1.2).\nThe existing theoretical typology of ad hominem arguments, as presented for example in most textbooks, provides only a very simplified view. On the one hand, some of the categories which we found in the empirical labeling study (section 4.1.3) do map to their corresponding counterparts (such as the vulgar insults). On the other hand, some ad hominem insults typical to online argumentation (illiteracy insults, condescension) are not present in studies on ad hominem. Hence, we claim that any potential typology of ad hominem arguments should be multinomial rather than categorical, as we found multiple different spans in a single argument."
  }, {
    "heading": "4.2 Triggers of first level ad hominem",
    "text": "In the following section, we increase the complexity of the studied discourse by taking the original post into account."
  }, {
    "heading": "4.2.1 Annotation study",
    "text": "We already showed that ad hominem arguments are usually preceded by a discussion between the interlocutors. However, 897 submissions (original posts; OPs) have at least one intermediate ad hominem (in other words, the original post is directly attacked). We were thus interested in what triggers these first-level ad hominem arguments. We hypothesize two causes: (1) the controversy of the OP, similarly to some related works on news comments (Coe et al., 2014) and (2) the reasonableness of the OP (whether the topic is reasonable to argue about). We model both features on a three-point scale, namely controversy: 1 = ‘not re-\nally controversial’, 2 = ‘somehow controversial’, 3 = ‘very controversial’ and reasonableness: 1 = ‘quite stupid’, 2 = ‘neutral’, 3 = ‘quite reasonable’.7\nWe sampled two groups of OPs: those which had some ad hominem arguments in any of its threads but no delta (ad hominem group) and those without ad hominem but some deltas (Delta group). In total, 1,800 balanced instances were annotated by five workers and the resulting value was averaged for each item.8\nStatistical analysis of the annotated 1,800 OPs revealed that ad hominem arguments are associated with more controversial OPs (mean controversy 1.23) while delta-awarded arguments with less controversial OPs (mean controversy 1.06; K-S test;9 statistics 0.13, P-value: 7.97× 10−7). On the other hand, reasonableness does not seem to play such a role. The difference between ad hominem in reasonable OPs (mean 1.20) and delta in reasonable OPs (mean 1.11) is not that statistically strong; (K-S test statistics: 0.07, P-value: 0.02)."
  }, {
    "heading": "4.2.2 Regression model for predicting controversy and reasonableness",
    "text": "We further built a regression model for predicting controversy and reasonableness of the OPs. Along with Bi-LSTM and CNN networks (same models as in 4.1.2) we also developed a neural model that integrates CNN with topic distribution (CNN+LDA). The motivation for a topicincorporating model was based on our earlier observations presented in section 3. In particular, we trained an LDA topic model (k = 50) (Blei et al., 2003) on the heldout OPs and during training/testing, we merged the estimated topic distribution vector with the output layer after convolution and pooling. We performed 10-fold cross validation on the 1,800 annotated OPs and got reasonable performance for controversy prediction (ρ\n7Examples of not really controversial: ”I Don’t Think Monty Python is Funny”, very controversial: ”Blacks are generally intellectual inferior to the other major races”, quite stupid: ”Burritos are better than sandwiches”, and quite reasonable: ”Nations whose leadership is based upon religion are fundamentally backwards”.\n8A pilot crowd sourcing annotation with 5 + 5 workers showed a fair reliability for controversy (Spearman’s ρ 0.804) and medium reliability for reasonableness (Spearman’s ρ 0.646).\n9Kolmogorov-Smirnov (K-S) test is a non-parametric test without any assumptions about the underlying probability distribution.\n0.569) and medium performance for reasonableness prediction (ρ 0.385), respectively; both using the CNN+LDA model (see Table 3).\nWe then used the trained model and extrapolated on all held-out OPs (1,267 ad hominem and 10,861 delta OPs, respectively). The analysis again showed that ad hominem arguments tend to be found under more controversial OPs whereas delta arguments in the less controversial ones (KS test statistics: 0.14, P-value: 1 × 10−18). For reasonableness, the rather low performance of the predictor does not allow us draw any conclusions on the extrapolated data."
  }, {
    "heading": "4.2.3 Results and interpretation",
    "text": "Controversy of the original post is immediately heating up the debate participants and correlates with a higher number of direct ad hominem responses. This corresponds to observations made in comments in newswire where ‘weightier’ topics tended to stir incivility (Coe et al., 2014). On the other hand, ‘stupidity’ (or ‘reasonableness’) does not seem to play any significant role. The CNN+LDA model for predicting controversy (ρ 0.569) might come handy for signaling potentially ‘heated’ discussions."
  }, {
    "heading": "4.3 Before calling names",
    "text": "In this section, we focus on the dialogical aspect of CMV debates and dynamics of ad hominem fallacies. Although ad hominem arguments appear in many forms (Section 4.1.3), we treat all ad hominem arguments equal in the following experiments."
  }, {
    "heading": "4.3.1 Data sampling",
    "text": "So far we explored what makes an ad hominem argument and whether debated topic influences the\nnumber of intermediate attacks. However, possible causes of the argumentative dynamics that ends up with an ad hominem argument remain an open question, which has been addressed in neither argumentation theory nor in cognitive psychology, to the best of our knowledge. We thus cast an explanation of triggers and dynamics of ad hominem discussions as a supervised machine learning problem and draw theoretical insights by a retrospective interpretation of the learned models.\nWe sample positive instances by taking three contextual arguments preceding the ad hominem argument from threads which are an interplay between two persons. Negative samples are drawn similarly from threads in which the argument is awarded with ∆ as shown in Figure 2.10 Each instance consists of the three concatenated arguments delimited by a special OOV token. This resulted in 2,582 balanced training instances."
  }, {
    "heading": "4.3.2 Neural models",
    "text": "The alleged lack of interpretability of neural networks has motivated several lines of approaches, such as layer-wise relevance propagation (Arras et al., 2017) or representation erasure (Li et al., 2016), both on sentiment analysis. As our task at hand deals with multi-party discourse that presumably involves temporal relations important for the learned representation, we opted for a state-of-theart self-attentive LSTM model. In particular, we re-implemented the Structured Self-Attentive Embedding Neural Network (SSAE-NN) (Lin et al., 2017) which learns an embedding matrix representation of the input using attention weights. To make the attention even more interpretable, we replaced the final non-linear MLP layers with a single linear classifier (softmax). By summing over one dimension of the attention embedding matrix, each word from the input sequence gets associated\n10To ensure as much content similarity as possible, we used the same similarity sampling as in section 4.1.1.\nwith a single attention weight that gives us insights into the classifier’s ‘features’ (still indirectly, as the true representation is a matrix; see the original paper).11 The learning objective is to recognize whether the thread ends up in an ad hominem argument or a delta point. We trained the model in 10-fold cross-validation and although our goal is not to achieve the best performance but rather to gain insight, we also tested a CNN model (accuracy 0.7095) which performed slightly worse than the SSAE-NN model (accuracy 0.7208)."
  }, {
    "heading": "4.3.3 Results and interpretation",
    "text": "During testing the model, we projected attention weights to the original texts as heat maps and manually analyzed 191 true positives (ad hominem threads recognized correctly), as well as 77 false positives (ad hominem threads misclassified as delta) and 84 false negatives (delta as ad hominem), in total about 120k tokens. The full output is available in the supplementary materials, we use IDs as a reference in the following text.\nIn the following analysis, we solely relied on the weights of words or phrases learned by the attention model, see an example in Figure 3. Based on our observations, we summarize several linguistic and argumentative phenomena with examples most likely responsible for ad hominem threads in Table 4.\nThe identified phenomena have few interesting properties in common. First, they all are topic-independent rhetorical devices (except for the loaded keywords at the bottom). Second, many of them deal with meta-level argumentation, i.e., arguing about argumentation (such as missing support or fallacy accusations). Third, most of them do not contain profanity (in contrast to the actual ad hominem arguments of which a third are vulgar insults; cf. Table 2). And finally, all of them should be easy to avoid.\nMisleading ‘features’ False positives revealed properties that misled the network to classify delta threads as ad hominem threads.\n• These include topic words (such as racism, blacks, slave, abortion) which reflects the implicit bias in the data.\n• Actual interest mixed with indifference in 11We also experimented with regularizing the attention matrix as the authors proposed, but it resulted in worse performance.\nsarcasm is also problematic (185(-2) “That’s a very interesting ...”).\n• Another problematic phenomena is also expressed disagreement (678(-2) “overheated rhetoric”, 203(-2) “But I suppose this argument is ...”, 230(-2) “But I don’t think it’s quite ...”, 938(-1) “I disagree too, however ...”).\nFalse negatives were caused basically by presence of many ‘informative’ content words (980 unemployment, quarterly publication, inflation data, 474 actual publications, this experiment, biological ailments, medical doctorate, 1214 graduate degree, education, health insurance) and misinterpreted sarcasm (285(-1) “Also this is a cute analogy”)."
  }, {
    "heading": "5 Conclusion",
    "text": "In this article, we investigated ad hominem argumentation on three levels of discourse complexity. We looked into qualitative and quantative properties of ad hominem arguments, crowdsourced labeled data, experimented with models for prediction (0.810 accuracy; 4.1.2), and proposed an updated typology of ad hominem properties (4.1.3). We then looked into the dynamics of argumentation to examine the relation between the quality of the original post and immediate ad hominem arguments (4.2). Finally, we exploited the learned representation of Self-Attentive Embedding Neural Network to search for features triggering ad hominem in one-to-one discussions. We found several categories of rhetorical devices as well as misleading features (4.3.3).\nThere are several points that deserve further investigation. First, we have ignored metainformation of the debate participants, such as their overall activity (i.e., whether they are spammers or trolls). Second, the proposed typology of ad hominem causes has not yet been post-verified empirically. Third, we expect that personality traits of the participants (BIG5) may also play a significant role in the argumentative exchange. We leave these points for future work.\nWe believe that our findings will help gain better understanding of, and hopefully keep restraining from, ad hominem fallacies in good-faith discussions."
  }, {
    "heading": "Acknowledgments",
    "text": "This work has been supported by the ArguAna Project GU 798/20-1 (DFG), and by the DFGfunded research training group “Adaptive Preparation of Information form Heterogeneous Sources” (AIPHES, GRK 1994/1)."
  }],
  "year": 2018,
  "references": [{
    "title": "On Rhetoric: A Theory of Civil Discourse",
    "authors": ["Aristotle", "George Kennedy (translator"],
    "year": 1991
  }, {
    "title": "Truth is a lie: Crowd truth and the seven myths of human annotation",
    "authors": ["Lora Aroyo", "Chris Welty."],
    "venue": "AI Magazine 36(1):15–24. https://doi.org/10.1609/aimag.v36i1.2564.",
    "year": 2015
  }, {
    "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis",
    "authors": ["Leila Arras", "Grégoire Montavon", "Klaus-Robert Müller", "Wojciech Samek."],
    "venue": "Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and So-",
    "year": 2017
  }, {
    "title": "Latent dirichlet allocation",
    "authors": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan."],
    "venue": "Journal of Machine Learning Research 3:993–1022. http://dl.acm.org/citation.cfm?id=944919.944937.",
    "year": 2003
  }, {
    "title": "The Fake, the Flimsy, and the Fallacious: Demarcating Arguments in Real Life",
    "authors": ["Maarten Boudry", "Fabio Paglieri", "Massimo Pigliucci."],
    "venue": "Argumentation 29(4):431–456. https://doi.org/10.1007/s10503-015-9359-1.",
    "year": 2015
  }, {
    "title": "Online and Uncivil? Patterns and Determinants of Incivility in Newspaper Website Comments",
    "authors": ["Kevin Coe", "Kate Kenski", "Stephen A. Rains."],
    "venue": "Journal of Communication 64(4):658–679. https://doi.org/10.1111/jcom.12104.",
    "year": 2014
  }, {
    "title": "Complexity, Relevance and Character: Problems with Teaching the ”Ad Hominem” Fallacy",
    "authors": ["Stephen de Wijze."],
    "venue": "Educational Philosophy and Theory 35(1):31–56. https://doi.org/10.1111/14695812.00004.",
    "year": 2002
  }, {
    "title": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures",
    "authors": ["Alex Graves", "Jürgen Schmidhuber."],
    "venue": "Neural Networks 18(5):602–610. https://doi.org/10.1016/j.neunet.2005.06.042.",
    "year": 2005
  }, {
    "title": "What makes a convincing argument? Empirical analysis and detecting attributes of convincingness in Web argumentation",
    "authors": ["Ivan Habernal", "Iryna Gurevych."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natu-",
    "year": 2016
  }, {
    "title": "Which argument is more convincing? Analyzing and predicting convincingness of Web arguments using bidirectional LSTM",
    "authors": ["Ivan Habernal", "Iryna Gurevych."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Lin-",
    "year": 2016
  }, {
    "title": "Argumentation Mining in User-Generated Web Discourse",
    "authors": ["Ivan Habernal", "Iryna Gurevych."],
    "venue": "Computational Linguistics 43(1):125–179. https://doi.org/10.1162/COLI a 00276.",
    "year": 2017
  }, {
    "title": "Argotario: Computational Argumentation Meets Serious Games",
    "authors": ["Ivan Habernal", "Raffael Hannemann", "Christian Pollak", "Christopher Klamm", "Patrick Pauli", "Iryna Gurevych."],
    "venue": "Proceedings of the 2017 Conference on Empirical",
    "year": 2017
  }, {
    "title": "Adapting Serious Game for Fallacious Argumentation to German: Pitfalls, Insights, and Best Practices",
    "authors": ["Ivan Habernal", "Patrick Pauli", "Iryna Gurevych."],
    "venue": "Proceedings of the Eleventh International Conference on Language Resources and Eval-",
    "year": 2018
  }, {
    "title": "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants",
    "authors": ["Ivan Habernal", "Henning Wachsmuth", "Iryna Gurevych", "Benno Stein."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of",
    "year": 2018
  }, {
    "title": "Fallacies",
    "authors": ["Charles L. Hamblin."],
    "venue": "Methuen, London, UK.",
    "year": 1970
  }, {
    "title": "Fallacies",
    "authors": ["Hans Hansen."],
    "venue": "Edward N. Zalta, editor, The Stanford Encyclopedia of Philosophy, Metaphysics Research Lab, Stanford University. http://plato.stanford.edu/entries/fallacies/.",
    "year": 2017
  }, {
    "title": "Learning whom to trust with MACE",
    "authors": ["Dirk Hovy", "Taylor Berg-Kirkpatrick", "Ashish Vaswani", "Eduard Hovy."],
    "venue": "Proceedings of NAACLHLT 2013. Association for Computational Linguistics, Atlanta, Georgia, pages 1120–1130.",
    "year": 2013
  }, {
    "title": "A Corpus of Participant Roles in Contentious Discussions",
    "authors": ["Siddharth Jain", "Archna Bhatia", "Angelique Rein", "Eduard Hovy."],
    "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14). European Lan-",
    "year": 2014
  }, {
    "title": "Convolutional neural networks for sentence classification",
    "authors": ["Yoon Kim."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Doha, Qatar, pages 1746–",
    "year": 2014
  }, {
    "title": "Understanding Neural Networks through Representation Erasure",
    "authors": ["Jiwei Li", "Will Monroe", "Dan Jurafsky."],
    "venue": "arXiv preprint. http://arxiv.org/abs/1612.08220.",
    "year": 2016
  }, {
    "title": "A Structured Self-attentive Sentence Embedding",
    "authors": ["Zhouhan Lin", "Minwei Feng", "Cicero Nogueira dos Santos", "Mo Yu", "Bing Xiang", "Bowen Zhou", "Yoshua Bengio."],
    "venue": "Proceedings of the 5th International Conference on Learning Repre-",
    "year": 2017
  }, {
    "title": "Strategies of character attack",
    "authors": ["Fabrizio Macagno."],
    "venue": "Argumentation 27(4):369–401. https://doi.org/10.1007/s10503-013-9291-1.",
    "year": 2013
  }, {
    "title": "Computational Linguistics and Deep Learning",
    "authors": ["Christopher D. Manning."],
    "venue": "Computational Linguistics 41(4):701–707. https://doi.org/10.1162/COLI a 00239.",
    "year": 2015
  }, {
    "title": "Why do humans reason? Arguments for an argumentative theory",
    "authors": ["Hugo Mercier", "Dan Sperber."],
    "venue": "The Behavioral and Brain Sciences 34(2):57–74; discussion 74–111. https://doi.org/10.1017/S0140525X10000968.",
    "year": 2011
  }, {
    "title": "The Enigma of Reason",
    "authors": ["Hugo Mercier", "Dan Sperber."],
    "venue": "Harvard University Press, Cambridge, MA, USA.",
    "year": 2017
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Ad-",
    "year": 2013
  }, {
    "title": "How did you change my view? A corpus-based study of concessions’ argumentative role",
    "authors": ["Elena Musi."],
    "venue": "Discourse Studies page (in press). https://doi.org/10.1177/1461445617734955.",
    "year": 2017
  }, {
    "title": "Argumentation and fallacy in the justification of the 2003 War on Iraq",
    "authors": ["Ahmed Sahlane."],
    "venue": "Argumentation 26(4):459–488. https://doi.org/10.1007/s10503-012-9265-8.",
    "year": 2012
  }, {
    "title": "A Web of Hate: Tackling Hateful Speech in Online Social Spaces",
    "authors": ["Haji Mohammad Saleem", "Kelly P Dillon", "Susan Benesch", "Derek Ruths."],
    "venue": "Guy De Pauw, Ben Verhoeven, Bart Desmet, and Els Lefever, editors, Proceedings of the First Work-",
    "year": 2016
  }, {
    "title": "Argumentation: Keeping Faith with Reason",
    "authors": ["Edward Schiappa", "John P. Nordin."],
    "venue": "Pearson UK, 1st edition.",
    "year": 2013
  }, {
    "title": "Recognizing Insufficiently Supported Arguments in Argumentative Essays",
    "authors": ["Christian Stab", "Iryna Gurevych."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2017). Associa-",
    "year": 2017
  }, {
    "title": "Winning Arguments: Interaction Dynamics and Persuasion Strategies in Good-faith Online Discussions",
    "authors": ["Chenhao Tan", "Vlad Niculae", "Cristian DanescuNiculescu-Mizil", "Lillian Lee."],
    "venue": "Proceedings of the 25th International Conference on",
    "year": 2016
  }, {
    "title": "Fallacies and Argument Appraisal",
    "authors": ["Christopher W. Tindale."],
    "venue": "Cambridge University Press, New York, NY, USA, critical reasoning and argumentation edition.",
    "year": 2007
  }, {
    "title": "The Uses of Argument",
    "authors": ["Stephen E. Toulmin."],
    "venue": "Cambridge University Press.",
    "year": 1958
  }, {
    "title": "Handbook of Argumentation Theory",
    "authors": ["Frans H. van Eemeren", "Bart Garssen", "Erik C.W. Krabbe", "A. Francisca Snoeck Henkemans", "Bart Verheij", "Jean H.M. Wagemans."],
    "venue": "Springer, Berlin/Heidelberg.",
    "year": 2014
  }, {
    "title": "Fallacies in pragma-dialectical perspective",
    "authors": ["Frans H. van Eemeren", "Rob Grootendorst"],
    "year": 1987
  }, {
    "title": "Argumentation, communication, and fallacies: a pragma-dialectical perspective",
    "authors": ["Frans H. van Eemeren", "Rob Grootendorst."],
    "venue": "Lawrence Erlbaum Associates, Inc.",
    "year": 1992
  }, {
    "title": "Argumentation Quality Assessment: Theory vs",
    "authors": ["Henning Wachsmuth", "Nona Naderi", "Ivan Habernal", "Yufang Hou", "Graeme Hirst", "Iryna Gurevych", "Benno Stein."],
    "venue": "Practice. In Proceedings of the 55th Annual Meeting of the As-",
    "year": 2017
  }, {
    "title": "Media Argumentation: Dialect, Persuasion and Rhetoric",
    "authors": ["Douglas Walton."],
    "venue": "Cambridge University Press.",
    "year": 2007
  }, {
    "title": "Learning Linguistic Descriptors of User Roles in Online Communities",
    "authors": ["Alex Wang", "William L. Hamilton", "Jure Leskovec."],
    "venue": "Proceedings of 2016 EMNLP Workshop on Natural Language Processing and Computational Social Science. Associ-",
    "year": 2016
  }, {
    "title": "Lightening up on the Ad Hominem",
    "authors": ["John Woods."],
    "venue": "Informal Logic 27(1):109. https://doi.org/10.22329/il.v27i1.467.",
    "year": 2008
  }, {
    "title": "Ex Machina: Personal Attacks Seen at Scale",
    "authors": ["Ellery Wulczyn", "Nithum Thain", "Lucas Dixon."],
    "venue": "Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering",
    "year": 2017
  }, {
    "title": "Characterizing Online Discussion Using Coarse Discourse Sequences",
    "authors": ["Amy Zhang", "Bryan Culbertson", "Praveen Paritosh."],
    "venue": "Proceedings of the Eleventh International AAAI Conference on Web and Social Media (ICWSM 2017). AAAI Press,",
    "year": 2017
  }],
  "id": "SP:421e454bfbd306ede09decf2096a7c8f680e75ac",
  "authors": [{
    "name": "Ivan Habernal",
    "affiliations": []
  }, {
    "name": "Henning Wachsmuth",
    "affiliations": []
  }, {
    "name": "Iryna Gurevych",
    "affiliations": []
  }, {
    "name": "Benno Stein",
    "affiliations": []
  }],
  "abstractText": "Arguing without committing a fallacy is one of the main requirements of an ideal debate. But even when debating rules are strictly enforced and fallacious arguments punished, arguers often lapse into attacking the opponent by an ad hominem argument. As existing research lacks solid empirical investigation of the typology of ad hominem arguments as well as their potential causes, this paper fills this gap by (1) performing several large-scale annotation studies, (2) experimenting with various neural architectures and validating our working hypotheses, such as controversy or reasonableness, and (3) providing linguistic insights into triggers of ad hominem using explainable neural network architectures.",
  "title": "Before Name-calling: Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation"
}