{
  "sections": [{
    "heading": "1. Introduction",
    "text": "We consider the following optimization problem\nmin { f(x) = 1\nn n∑ i=1 fi(x) + λp(x)\n} , (1)\nwhose objective function f is a large sum of non-convex functions fi(x) and a regularization term p(x), where fi(x) corresponds to a criteria to optimize and λ ≥ 0 is a tradeoff parameter between the two terms. This model covers a very vast class of problems arising from several fields such as machine learning, signal processing, etc. For instance, least-squares regression, logistic regression problem, etc can be expressed in the form of (1).\n1Laboratory of Theoretical and Applied Computer Science, University of Lorraine, France. Correspondence to: Hoai Minh Le <minh.le@univ-lorraine.fr>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nNowadays, the growth of technologies leads to exponential augmentation of large-scale data where the number of both variables and samples are huge. Thus, optimization methods for solving the problem (1) are faced with a great challenge that is the number of samples n can be extremely large. Among existing methods for this problem, stochastic programming has been proved to be suitable thanks to its ability to exploit the advantage of the sum structure of the problem. In (Schmidt et al., 2015), the authors considered a special case of the large-sum problem (1) where fi are convex and smooth functions and p corresponds to the `2 regularization. Stochastic Average Gradient was developed to solve the resulting problem. Reddi et al. (Reddi et al., 2016) developed Proximal Stochastic Gradient method for the case where fi are smooth (can be non-convex) and p is convex, non-smooth function. Motivated by its success, we will study stochastic programming for solving (1) in order to deal with data having an extremely large number of samples.\nOn the other hand, in real-world applications such as image processing, microarray analysis, etc. datasets contain a very large number of variables. In such of cases, we are often to face with the problem of redundant and irrelevant variables. Redundant variables contain information already presented by other variables while irrelevant variables do not contain useful information. Variables selection methods that consist of selecting important variables for a considered task, are a popular and efficient way to deal with redundant and irrelevant variables. In this direction, a natural idea is to formulate the variables selection problem as a minimization of the `0-norm (or ‖.‖0). The sparse optimization has been extensively studied on both theoretical and practical aspects. The readers can refer to Le Thi et al. (Le Thi et al., 2015) for an extensive overview of existing approaches for the minimization of `0-norm.\nNevertheless, when the data possesses certain group structures, we are naturally interested in selecting important groups of variables rather than individual ones. For instance, in multi-factor analysis of variance, a factor with several levels may be expressed through a group of dummy variables. In genomic data analysis, the correlations between genes sharing the biological pathway can\nbe high. Hence these genes should be considered as a group. Recently, the mixed-norm regularization has been developed for the group variable selection. It consists in using the `2,0 regularization term. Assume that x = (x1, ..., xm) ∈ Rm is partitioned into J non-overlapping groups x(1), ..., x(J), then the `2,0-norm of x is defined by ‖x‖2,0 = | { j ∈ {1, ..., J} : ‖x(j)‖2 6= 0 } |. Clearly, `2,0- norm is non-convex that makes the optimization problem involving `2,0 challenging. Several works have been developed to solve the problem of mixed-norm regularization `2,0. The first approach, named the group Lasso (`2,1- norm) (Yuan & Lin, 2006), is closely connected to the Lasso (`1-norm) - an approximation of the `0-norm (Tibshirani, 1994). This approach was widely used for selecting groups of variables in multi-task learning (Obozinski et al., 2006), multiclass support vector machine (Blondel et al., 2013), principal component analysis (Khan et al., 2015), linear discriminant analysis (Gu et al., 2011), and compressed sensing (Sun et al., 2009), etc. The second approach consists in replacing the `2,0-norm by a DC (Difference of Convex functions) approximation. In (Wang et al., 2007), the authors used the smoothly clipped absolute deviation (SCAD) approximation and developed a group coordinate descent based algorithm for the sparse linear regression. Later, Huang et al. (Huang et al., 2012) used the minimax concave penalty (MCP) for the same problem. In (Lee et al., 2016), the authors considered both above approximations and developed DC programming and DCA (DC algorithm) based method for the resulting problems. Recently, Phan et al. (Phan et al., 2017) proposed DCA based algorithms for bi-level variable selection using the combination of the `0-norm and `q,0-norm.\nPaper’s contribution: In this paper, we aim at developing efficient methods to solve the problem (1) where n is extremely large and p(x) corresponds to `2,0 regularization (in order to deal with the group variables selection). The large-sum optimization (1) becomes\nmin { f(x) = 1\nn n∑ i=1 fi(x) + λ‖x‖2,0\n} . (2)\nWe assume that fi(x) is differentiable with L-Lipschitz gradient. This assumption is broad enough to cover several applications. Various important problems in machine learning such as Multi-task feature selection, Sparse logistic regression, Minimizing an expected loss in stochastic programming, etc. can be expressed in the form of (2). As we have mentioned above, the `2,0-norm can be approximated by a convex (e.g. `2,1-norm) or non-convex function. Using a non-convex approximation will lead to a ”harder” optimization problem but it has been proved that non-convex approximations perform better than convex approximations in terms of sparsity (Le Thi et al., 2015). The resulting problem is then reformulated as a DC program\nand DCA based algorithm will be developed to solve it. We exploit the special structure of the problem to propose an efficient DC decomposition for which the corresponding DCA scheme is very inexpensive: it only requires the projection of points onto balls that is explicitly computed. On the other hand, in order to deal with data having a large number of samples, we present stochastic version DCA. The convergence properties of the proposed algorithm is rigorously studied to show that the convergence is guaranteed with probability one.\nAs an application of our algorithm, we consider the group variables selection in multiclass logistic regression. We perform an empirical comparison of stochastic DCA with DCA and standard methods on very large synthetic and real-world datasets, and show that the stochastic DCA is efficient in group variable selection ability and classification accuracy as well as running time.\nThe remainder of the paper is organized as follows. Solution method based on Stochastic DCA for solving (2) is developed in Section 2. In Section 3, we apply the proposed algorithm to the group variables selection in multiclass logistic regression. Finally Section 4 concludes the paper."
  }, {
    "heading": "2. Solution method via stochastic DCA",
    "text": ""
  }, {
    "heading": "2.1. Outline of DC programming and DCA",
    "text": "DC programming and DCA constitute the backbone of smooth/non-smooth non-convex programming and global optimization (Pham Dinh & Le Thi, 1997; 1998; Le Thi & Pham Dinh, 2005). They address the problem of minimizing a DC function on the whole space Rn or on a closed convex set Ω ⊂ Rn. Generally speaking, a standard DC program takes the form:\nα = inf{F (x) := G(x)−H(x) |x ∈ Rn} (Pdc),\nwhere G,H are lower semi-continuous proper convex functions on Rn. Such a function F is called a DC function, andG−H is a DC decomposition of F whileG andH are the DC components of F . A DC program with convex constraint x ∈ Ω can be equivalently expressed as (Pdc) by adding the indicator function χΩ (χΩ(x) = 0 if x ∈ Ω and +∞ otherwise) to the first DC component G.\nThe modulus of strong convexity of θ on Ω, denoted by µ(θ,Ω) or µ(θ) if Ω = Rn, is given by\nµ(θ,Ω) = sup{µ ≥ 0 : θ − (µ/2)‖.‖2 is convex on Ω}\nOne says that θ is strongly convex on Ω if µ(θ,Ω) > 0.\nFor a convex function θ, the subdifferential of θ at x0 ∈ domθ := {x ∈ Rn : θ(x0) < +∞}, denoted by ∂θ(x0), is\ndefined by\n∂θ(x0) := {y ∈ Rn : θ(x) ≥ θ(x0) + 〈x− x0, y〉, ∀x ∈ Rn}.\nThe subdifferential ∂θ(x0) generalizes the derivative in the sense that θ is differentiable at x0 if and only if ∂θ(x0) ≡ {∇xθ(x0)}.\nA point x∗ is called a critical point of G − H , or a generalized Karush-Kuhn-Tucker point (KKT) of (Pdc)) if ∂H(x∗) ∩ ∂G(x∗) 6= ∅.\nThe main idea of DCA is simple: each iteration l of DCA approximates the concave part −H by its affine majorization (that corresponds to taking vl ∈ ∂H(xl)) and then computes xl+1 by solving the resulting convex problem.\nmin x∈Rn {G(x)− 〈vl, x〉}.\nThe sequence {xl} generated by DCA enjoys the following properties (Pham Dinh & Le Thi, 1997; 1998; Le Thi & Pham Dinh, 2005):\n(i) The sequence {F (xl)} is decreasing;\n(ii) If F (xl+1) = F (xl), then xl is a critical point of (Pdc) and DCA terminates at l-th iteration.\n(iii) If µ(G) + µ(H) > 0 then the series {‖xk+1 − xk‖2 converges.\n(iv) If the optimal value α of (Pdc) is finite and the infinite sequence {xl} is bounded then every limit point of the sequence {xl} is a critical point of G−H .\n2.2. Stochastic DCA for solving the problem (2)\nIn this section, we introduce a stochastic version of DCA for solving (2) that exploits the structure of objective function f . We consider a family of DC approximations p̃(x) of `2,0-norm, defined by\np̃(x) = J∑ j=1 η(‖x(j)‖2),\nwhere η is a non-convex penalty function which includes SCAD, MCP, Capped-`1, exponential function, `p+ with 0 < p < 1, `p− with p < 0 (see (Le Thi et al., 2015) for more details). p̃(x) can be expressed as p̃(x) = g̃(x) − h̃(x), where\ng̃(x) = α J∑ j=1 ‖x(j)‖2 and h̃(x) = α J∑ j=1 ‖x(j)‖2 − p̃(x).\nHence, the approximate problem of (2) can be written as\nmin x∈Rm\n{ f(x) = 1\nn n∑ i=1 [ fi(x) + λg̃(x)− λh̃(x) ]} . (3)\nEach function fi(x) can be rewritten as\nfi(x) = ρ\n2 ‖x‖2 − [ρ 2 ‖x‖2 − fi(x) ] .\nSince fi(x) is differentiable with L-Lipschitz gradient,[ ρ 2‖x‖ 2 − fi(x) ]\nis strongly convex with ρ > L. Hence, fi(x) is a DC function. Consequently, f(x) is a DC function with the following DC decomposition\nf(x) = g(x)− h(x), (4)\nwhere g(x) and h(x) are convex functions defined by\ng(x) = ρ2‖x‖ 2 + λg̃(x), h(x) = 1n n∑ i=1 hi(x);hi(x) = ρ 2‖x‖ 2 − fi(x) + λh̃(x).\nDCA for solving (3) amounts to computing two sequences {xl} and {vl} such that vl ∈ ∂h(xl) and xl+1 is an optimal solution of the following convex problem\nmin { g(x)− 〈vl, x〉 } . (5)\nThe computation of subgradients of h requires the one of all components hi. This can be expensive when n is very large. Hence we propose a stochastic version of DCA in which we only compute the subgradients of a small subset of components hi. Precisely, at each iteration l, we compute vli ∈ ∂hi(xl) for i ∈ sl and keep vli = v l−1 i for i 6∈ sl, where sl ⊂ {1, ..., n} is a randomly chosen set of index.\nThe computation of vli ∈ ∂hi(xl) can be given as vli = ρxl−∇fi(xl)+yl, where yl ∈ λ∂h̃(xl) for all i ∈ sl. The convex problem (5) take the form\nmin λα J∑ j=1 ‖x(j)‖2 + ρ 2 ‖x‖2 − 〈 1 n n∑ i=1 vli, x〉  . (6) We observe that the objective of (6) is separable in groups of x, then the solution to this problem can be computed by solving J independent sub-problems of the same form:\nmin { λα‖x(j)‖2 + ρ\n2 ‖x(j)‖2 − 〈vl(j), x(j)〉\n} , (7)\nwhere vl(j) = 1 ρn ∑n i=1(v l i)(j) for j = 1, ..., J . The solution of (7) can be explicitly computed by\nxl+1(j) = ( ‖vl(j)‖2 − λα/ρ ) + vl(j)\n‖vl(j)‖2 , (8)\nThus, the stochastic DCA (SDCA) for solving the problem (3) is described in Algorithm 1.\nNow we will prove that the convergence properties of SDCA are guaranteed with probability one.\nAlgorithm 1 SDCA for solving the problem (3) Initialization: Choose x0 ∈ Rm, ρ > L and s0 = {1, ..., n}, l← 0. Repeat\n1. Compute vli ∈ ∂hi(xl) for i ∈ sl and keep vli = vl−1i for i 6∈ sl.\n2. Compute xl+1 by using (8). 3. Set l← l+1 and randomly choose a small subset\nsl ⊂ {1, ..., n}. Until Stopping criterion.\nTheorem 1. If α∗ = inf f(x) > −∞ and |sl| = b for all l ≥ 1, then SDCA generates the sequence {xl} such that\na) {f(xl)} is the almost sure convergent sequence.\nb) ∑∞ l=1 ‖xl − xl−1‖2 is almost surely finite and\nliml→∞ ‖xl − xl−1‖ = 0 almost surely.\nc) Every limit point of {xl} is a critical point of f with probability one.\nProof. a) Let xli = x l and yli = y l for i ∈ sl, xli = x l−1 i and yli = y l−1 for i 6∈ sl. We denote T li the function given by\nT li (x) = λg̃(x) + ρ\n2 ‖x− xli‖2 − 〈x− xli, yli −∇fi(xli〉\n+ fi(x l i)− h̃(xli),\nand T l(x) = 1n ∑n i=1 T l i (x). From the step 2 in Algorithm 1, it follows that xl+1 = arg minT l(x). Hence, we have\nT l(xl+1) ≤ T l(xl) =T l−1(xl) + 1 n ∑ i∈sl [fi(x l)\n+ λp̃(xl)− T l−1i (x l)].\n(9)\nLet Fl denote the σ-algebra generated by the entire history of SDCA up to the iteration l, i.e., F0 = σ(x0) and Fl = σ(x0, ..., xl, s0, ..., sl−1) for all l ≥ 1. By taking the expectation of the inequality (9) conditioned on Fl, we have\nE [ T l(xl+1)|Fl ] ≤ T l−1(xl)− b\nn\n[ T l−1(xl)− f(xl) ] .\nBy the supermartingale convergence theorem, we can conclude that the sequence {T l−1(xl)−α∗} converges almost surely. Moreover,\n∞∑ l=1 [ T l−1(xl)− f(xl) ] <∞, (10)\nalmost surely and hence {f(xl)} converges almost surely.\nb) Since yl−1i ∈ λ∂h̃(x l−1 i ), we have\nλh̃(x) ≥ λh̃(xl−1i ) + 〈x− x l−1 i , y l−1 i 〉. (11)\nSince fi(x) is a differentiable function with L-Lipschitz gradient, we have\nfi(x) ≤ fi(xl−1i )+〈x−x l−1 i ,∇fi(x l−1 i )〉+\nL 2 ‖x−xl−1i ‖ 2.\nThus, we get that\nfi(x) + λp̃(x) ≤ T l−1i (x) + L− ρ\n2 ‖x− xl−1i ‖ 2. (12)\nFrom (9) and (12), we have\nT l(xl+1) ≤ T l−1(xl)− ρ− L 2n ∑ i∈sl ‖xl − xl−1i ‖ 2. (13)\nBy taking the expectation of the inequality (13) conditioned on Fl, we have\nE [ T l(xl+1)|Fl ] ≤ T l−1(xl)− b(ρ− L)\n2n2 n∑ i=1 ‖xl−xl−1i ‖ 2.\nBy the supermartingale convergence theorem, we conclude that\n∞∑ l=1 n∑ i=1 ‖xl − xl−1i ‖ 2 <∞, (14)\nis almost surely satisfied. In particular, we have ∞∑ l=1 ‖xl − xl−1‖2 <∞, (15)\nalmost surely and hence liml→∞ ‖xl − xl−1‖ = 0 almost surely.\nc) Assume that there exists a sub-sequence {xlk} of {xl} such that xlk → x∗ almost surely. From (14) and (15), we have ‖xlk+1 − xlki ‖ → 0 almost surely. Without loss of generality, we can suppose that the sub-sequences ylki → y∗ almost surely. We note that y lk i ∈ λ∂h̃(x lk i ) and by the closed property of the subdifferential mapping ∂h̃, we have y∗ ∈ λ∂h̃(x∗) with probability one. It follows from xlk+1 ∈ arg minT lk(x) that T lk(xlk+1) ≤ T lk(x). Taking k →∞, we get that\nλg̃(x∗) ≤ λg̃(x)+ρ 2 ‖x−x∗‖2−〈x−x∗, y∗− 1 n n∑ i=1 ∇fi(x∗)〉,\nis almost surely satisfied for all x ∈ Rm. Thus, we have\ny∗ − 1 n n∑ i=1 ∇fi(x∗) ∈ ∂λg̃(x∗), (16)\nwith probability one. Therefore,\ny∗ ∈ [ ∇ 1 n n∑ i=1 fi(x ∗) + ∂λg̃(x∗) ] ∩ ∂λh̃(x∗), (17) with probability one. This implies that x∗ is a critical point of f with probability one and the proof is complete."
  }, {
    "heading": "3. Application to Group Variables Selection in Multiclass Logistic Regression",
    "text": "Logistic regression, introduced by D. Cox in 1958 (Cox, 1958), is a popular method in supervised learning. Logistic regression has been successfully applied in various real-life problems such as cancer detection (Kim et al., 2008), medical (Bagley et al., 2001; Subasi & Erçelebi, 2005), social science (King & Zeng, 2001), etc. Especially, logistic regression combined with feature selection has been proved to be suitable for high dimensional problems, for instance, document classification (Genkin et al., 2007) and microarray classification (Liao & Chin, 2007; Kim et al., 2008).\nWe describe the multiclass logistic regression problem as follows. Let W be a d × Q matrix, where d and Q are the number of features and number of classes, respectively. We denote the i-th column ofW byW:,i and b = (b1, ..., bQ) ∈ RQ. In the multiclass logistic classification problem, a new instance x∗ is classified to class y∗ by using the rule y∗ = arg maxk p(Y = k|X = x∗), where p(Y = y|X = x) is the conditional probability defined by\np(Y = y|X = x) = exp(by +W\nT :,yx)\nQ∑ k=1 exp(bk +WT:,kx) . (18)\nGiven a training set containing n instances xi and their corresponding labels yi ∈ {1, ..., Q}, we aim to find (W, b) for which the total probability of the training instances xi belonging to its correct classes yi is maximized. To estimate (W, b), we maximize the log-likelihood function defined as\nL(W, b) := − 1 n n∑ i=1 `(xi, yi,W, b) (19)\nwhere `(xi, yi,W, b) = − log p(Y = yi|X = xi). As mentioned above, to deal with irrelevant and/or redundant variables in high-dimensional data, we use variables selection method. Note that a variable j is to be removed if and only if all components in the row j of W are zero. Therefore, we can consider each row of W as a group. Denote byWj,: the j-th row of the matrixW . The `2,0-norm ofW , i.e., the number of non-zero rows of W , is defined by\n‖W‖2,0 = |{j ∈ {1, ..., d} : ‖Wj,:‖2 6= 0}|.\nHence, the `2,0 regularized multiclass logistic regression problem is formulated as\nmin W,b\n{ 1\nn n∑ i=1 `(xi, yi,W, b) + λ‖W‖2,0\n} . (20)\nObserve that the problem (20) takes the form of (2) where the function fi(W, b) = `(xi, yi,W, b). In this application, we use a non-convex approximation of the `2,0-norm\nbased on the piecewise exponential penalty function. This approximation function has shown its efficiency in several problems, for instance, variables selection in SVM (Bradley & Mangasarian, 1998; Le Thi et al., 2008), semisupervised support vector machines (Le et al., 2015), sparse multiclass support vector machines (Le Thi & Nguyen, 2017), sparse signal recovery (Le Thi et al., 2013), sparse linear discriminant analysis (Le Thi & Phan, 2016a;b), variables selection in SVM with uncertain data (Le Thi et al., 2014), etc. Using the piecewise exponential penalty function, the corresponding approximate problem of (20) takes the form:\nmin W,b\n{ 1\nn n∑ i=1 fi(W, b) + λp̃(W )\n} , (21)\nwhere p̃(W ) = ∑d j=1 ηα(‖Wj,:‖2) with ηα(t) = 1 − exp(−α|t|). The function p̃(W ) can be expressed as a DC function:\np̃(W ) = α d∑ j=1 ‖Wj,:‖2 − h̃(W ),\nwhere h̃(W ) = ∑d j=1[−1+α|Wj,:‖2 +exp(−α‖Wj,:‖2)].\nAccording to the SDCA scheme in Algorithm 1, at each iteration l, we have to compute (vli, z l i) = ρ(W\nl, bl) − ∇fi(W l, bl) + (yl, 0) for i ∈ sl, where\n∇bkfi(W l, bl) = plk(xi)− δkyi ∇W:,kfi(W l, bl) = ( plk(xi)− δkyi ) xi\n(22)\nwith plk(xi) = exp(blk+(W l :,k) T xi)∑Q h=1 b l h+(W l :,h) T xi) and δkyi = 1 if k = yi and 0 otherwise. The computation of yl is given by\nylj,: = 0 if ‖W l j,:‖2 = 0\nλαηα(‖W lj,:‖2) ‖W lj,:‖2 W lj,: otherwise . (23)\nSDCA for solving (21) is described in Algorithm 2."
  }, {
    "heading": "3.1. Numerical Experiment",
    "text": ""
  }, {
    "heading": "3.1.1. DATASETS",
    "text": "To illustrate the performances of algorithms, we performed numerical tests on real datasets (aloi, covertype, madelon and sensorless) and simulated datasets (sim 1, sim 2 and sim 3). Dataset Aloi is a library of object images 1 while covertype, madelon, sensorless, are taken from the wellknown UCI data repository.\nWe used the same way as proposed in (Witten & Tibshirani, 2011) to generate simulated datasets. In sim 1, features are independent with different means in each class.\n1http://aloi.science.uva.nl/\nAlgorithm 2 SDCA for solving the problem (21) Initialization: Choose W 0 ∈ Rd×Q, b0 ∈ RQ, ρ > L, s0 = {1, ..., n}, l← 0. Repeat\n1. Compute (vli, z l i) = ρ(W l, bl) −∇fi(W l, bl) + (yl, 0) for i ∈ sl using (22)-(23) and keep (vli, zli) = (vl−1i , z l−1 i ) for i 6∈ sl.\n2. Compute (W l+1, bl+1) by\nbl+1 = 1ρn ∑n i=1 z l i\nW l+1j,: = ( ‖vlj,:‖2 − λα/ρ ) + vlj,: ‖vlj:,‖2 , (24)\nwhere vlj,: = 1 ρn ∑n i=1(v l i)j,: for j = 1, ..., d.\n3. Set l← l+1 and randomly choose a small subset sl ⊂ {1, ..., n}. Until Stopping criterion.\nIn sim 2, features also have different means in each class, however they are dependent. The dataset sim 3 has different one-dimensional means in each class with independent features. The procedure for generating simulated datasets is described as follows.\nFor sim 1: this dataset consists of four classes. The class k is sampled from the multivariate normal distribution N (µk, I), where the mean vector µk ∈ R50 is given by µkj = 0.5 if 10(k − 1) + 1 ≤ j ≤ 10k and 0 otherwise. We generate 25, 000 samples for each class.\nFor sim 2: we generate a dataset with three classes sampled from the multivariate normal distributions N (µk,Σ), k = 1, 2, 3, where µk ∈ R50 is defined by µkj = 0.4(k − 1) if j ≤ 40 and 0 otherwise. We use the block diagonal matrix Σ with five blocks of dimension 10 × 10 whose element (j, j′) is 0.6|j−j ′|. 150, 000 instances are generated.\nFor sim 3: we generate a dataset including four classes as follows: xi ∈ Ck then xij ∼ N ((k − 1)/3, 1) if j ≤ 100, k = 1, 2, 3, 4 and xij ∼ N (0, 1) otherwise. We generate 250, 000 instances with equal probabilities for each class.\nFor pre-processing data, we use standardization to scale the data."
  }, {
    "heading": "3.1.2. COMPARATIVE ALGORITHMS",
    "text": "We compare our algorithm with two algorithms: msgl and liblinear. msgl (Vincent & Hansen, 2014) is a coordinate gradient descent algorithm for solving the multiclass logistic regression using `2,1 regularization term, i.e., the\nconvex problem min W,b\n{ 1 n n∑ i=1 `(xi, yi,W, b) + λ‖W‖2,1 } .\nLibLinear (Fan et al., 2008) is a well-known package for solving large-scale problems by using the coordinate descent algorithm. We use the `1-\nregularized logistic regression solver of LibLinear to solve the binary logistic regression problem\nmin w { n∑ i=1 log(1 + e−yiw T xi) + λ d∑ j=1 |wj | } , and then the one-vs-the-rest strategy is used for the multiclass case."
  }, {
    "heading": "3.1.3. EXPERIMENT SETTING",
    "text": "The comparison of algorithms are performed in terms of three criteria: classification accuracy on test set, sparsity of solution and running time. Sparsity is computed as the percentage of selected features, where a feature j ∈ {1, . . . , d} is considered to be removed if all absolute values of components of row Wj,: are smaller than a threshold = 10−8.\nThe cross-validation procedure is used for experiments. We randomly take 80% of the whole dataset as a training set and the rest is used as test set (20%). This process is repeated 10 times and we report the mean and standard deviation of each criterion.\nWe use the early-stopping condition for SDCA. This is a well-know technique in machine learning, especially in stochastic learning which permits to avoid the over-fitting problem. After each epoch, we compute the accuracy based on the validation set, then we stop SDCA if the accuracy is not improved after npatience = 5 epochs. For comparative algorithms, we use their default stopping parameters. We also stop algorithms if they exceed 2 hours of running time in the training process. For SDCA, we set the trade-off parameter λ ∈{ 10−4, 10−3, ...1 } and the parameter for controlling the tightness of zero-norm approximation α ∈ {0.5, 1, 2, 5}. For both LibLinear and msgl, the trade-off parameter is chosen in interval {10−3, . . . , 104}.\nAll experiments are performed on a PC Intel (R) Xeon (R) E5-2630 v2 @2.60 GHz of 32GB RAM."
  }, {
    "heading": "3.1.4. EXPERIMENT 1 : COMPARISON OF SDCA AND",
    "text": "DCA\nFirstly, we will study the impact of batch size on the quality of solution and the running time of SDCA. The batch size refers to the size of set of index sl, i.e., the number of components hi that are used to compute the subgradients of h̄ at each iteration (c.f Algorithm 1). In DCA, or full-batch DCA, all components hi are used, i.e., sl ≡ {1, . . . , n}. The Table 1 reports the accuracy and the running time of SDCA as the batch size varies on an arbitrary chosen dataset (sensorless).\nWe observe that the running time is smallest (1.78s) with batch size equals to 10% while giving the second best classification accuracy 85.23%, only 0.07% smaller than the best one. Hence, we choose the batch size as 10% through-\nout our experiments.\nTo illustrate the potential gain of SDCA, we compare it with a DCA for solving the problem (21). From the Table 2, we see that the gain of running time of SDCA ranges from 11.6 times (aloi) to 55.1 times (covertype).\nConcerning the classification accuracy, SDCA and DCA are\ncomparable. SDCA gives slightly better accuracy than DCA on covertype, sim 1, sim 3, with a gain ranges from 0.06% to 0.28%. The gain of SDCA is higher on 2 datasets (madelon, sim 2), 1.35% and 3.07%. DCA furnishes a better result on aloi and sensorless, especially the gain is up to 4.9% on sensorless. The results prove that SDCA can greatly improve the running time of DCA while archiving a similar\naccuracy."
  }, {
    "heading": "3.1.5. EXPERIMENT 2 : SIMULATED DATASET",
    "text": "For synthetic datasets (sim 1, sim 2 and sim 3), we know in advance the informative features that were used to generate the datasets. Hence, the purpose of this experiment is to study the ability of algorithms to select these informative features in order to furnish a good classification accuracy. The comparison is performed with 3 algorithms, SDCA, msgl and LibLinear. We report the results in Table 2, and observe that.\nFor sim 1 dataset, LibLinear gives a slightly better classification accuracy (72.62%) comparing to SDCA (72.24%) and msgl (72.33%). However, SDCA is by far the fastest algorithm. SDCA is 1532 (resp. 136) times faster than LibLinear (resp. msgl). Furthermore, SDCA and LibLinear successfully suppress the 20% uninformative features, which it also matches with our procedure of generating this synthetic dataset. msgl fails on this purpose by selecting 82% of features.\nFor sim 2 dataset, SDCA is the best algorithm on both criteria: classification accuracy and running time. Similarly to sim 1 dataset, only SDCA and LibLinear can correctly select the informative features (80%).\nFor sim 3 dataset, SDCA exceeds LibLinear and GLASSO on all three comparison criteria: classification accuracy, sparsity and speed. LibLinear almost selects all the features (97.16% selected) but gives 0.89% accuracy lower than SDCA (99.93%), and it is also 2 times slower than SDCA. Among the three algorithm, only SDCA successfully selects the informative features.\nTo summarize, for all three synthetic datasets, SDCA successfully selects the exact informative features. LibLinear selects the exact features on 2 out of 3 datasets while GLASSO fails on all three datasets."
  }, {
    "heading": "3.1.6. EXPERIMENT 3 : REAL-WORLD DATASETS",
    "text": "In this experiment, we perform the comparative study between SDCA, msgl and LibLinear on real-world datasets . We observe from Table 2 that.\nFor aloi dataset, SDCA only selects 63.87% of features for a classification accuracy of 82.98% while LibLinear has a worse accuracy with 100% of features used. Moreover, SDCA is the 12.6 times faster than LibLinearwhile msgl fails to furnish a result after 2 hours of running time.\nFor covertype dataset, SDCA furnishes better classification accuracy than LibLinear and msgl. Moreover, SDCA is by far faster than the two others. SDCA is SDCA is 45 times faster than LibLinear and 89 times faster than msgl. Concerning the sparsity of solution, msgl is the best while\nLibLinear fails to suppress features.\nThe dataset madelon is known to be non-linear. Hence, all three algorithms furnish quite low classification accuracy (62.38% for SDCA, 61.54% for LibLinear and 60.48% for msgl). As for the sparsity, SDCA suppresses more features than LibLinear and msgl.\nFor sensorless dataset, SDCA is better than both LibLinear and msgl on all three aspects: classification accuracy, sparsity and running time. In terms of classification accuracy, the gain of SDCA versus msgl (resp. LibLinear) is 3.89% (resp. 2.26%). Regarding the running time, SDCA is 113 times faster than msgl and 137 times faster than LibLinear. As for the sparsity, SDCA selects 10% less features than msgl while LibLinear fails to suppress features.\nOverall, SDCA gives the best among the three in term of classification accuracy on all 4 datasets. As for running time, SDCA is by far the fastest algorithm. Concerning the sparsity of solution, SDCA suppresses more features than the two others on 3 out of 4 datasets."
  }, {
    "heading": "4. Conclusions",
    "text": "We have rigorously studied the large-sum optimization problem involving `2,0 regularization. The `2,0-norm is approximated by a DC function, namely the piecewise exponential function. The resulting problem is then reformulated as a DC program and we developed stochastic DCA to solve it. Exploiting the fact that each component fi(x) is differentiable with L-Lipschitz gradient, we propose, a stochastic version of DCA that is very inexpensive. At each iteration, the algorithm only requires the computing the subgradients of a small subset of functions and the projection of points onto balls that is explicitly computed. We have also proved that the convergence is guaranteed with probability one. As an application, we applied our algorithm to the group variables selection in multiclass logistic regression problem. Numerical experiments were carefully conducted on both synthetic and real-world datasets. The numerical results show that SDCA greatly improves the running time of DCA while giving similar accuracy. Moreover, our algorithm SDCA outperforms standard algorithms (Liblinear and msgl) on all 3 criteria: classification accuracy, sparsity of solution and running time. Especially, the gain in running time is huge. SDCA is up to 210 times faster than msgl and 1537 times faster than LibLinear. We are convinced that stochastic DCA is a promising approach for handling very large-scale datasets in machine learning."
  }],
  "year": 2017,
  "references": [{
    "title": "Logistic regression in the medical literature: Standards for use and reporting, with particular attention to one medical domain",
    "authors": ["S.C. Bagley", "H. White", "B.A. Golomb"],
    "venue": "Journal of Clinical Epidemiology,",
    "year": 2001
  }, {
    "title": "Block coordinate descent algorithms for large-scale sparse multiclass classification",
    "authors": ["Blondel", "Mathieu", "Seki", "Kazuhiro", "Uehara", "Kuniaki"],
    "venue": "Machine Learning,",
    "year": 2013
  }, {
    "title": "Feature Selection via Concave Minimization and Support Vector Machines",
    "authors": ["Bradley", "Paul S", "O.L. Mangasarian"],
    "venue": "In Proceedings of the Fifteenth International Conference on Machine Learning,",
    "year": 1998
  }, {
    "title": "The regression analysis of binary sequences (with discussion)",
    "authors": ["Cox", "David"],
    "venue": "J Roy Stat Soc B,",
    "year": 1958
  }, {
    "title": "Liblinear: A library for large linear classification",
    "authors": ["Fan", "R.-E", "Chang", "K.-W", "Hsieh", "C.-J", "Wang", "X.-R", "Lin"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2008
  }, {
    "title": "Large-scale Bayesian logistic regression for text",
    "authors": ["Genkin", "Alexander", "Lewis", "David D", "Madigan", "David"],
    "venue": "categorization. Technometrics,",
    "year": 2007
  }, {
    "title": "Linear discriminant dimensionality reduction",
    "authors": ["Gu", "Quanquan", "Li", "Zhenhuif", "Han", "Jiawei"],
    "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
    "year": 2011
  }, {
    "title": "Semiparametric Regression Pursuit",
    "authors": ["Huang", "Jian", "Wei", "Fengrong", "Ma", "Shuangge"],
    "venue": "Statistica Sinica,",
    "year": 2012
  }, {
    "title": "Joint Group Sparse PCA for Compressed Hyperspectral Imaging",
    "authors": ["Z. Khan", "F. Shafait", "A. Mian"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 2015
  }, {
    "title": "A Gradient-Based Optimization Algorithm for LASSO",
    "authors": ["Kim", "Jinseog", "Yuwon", "Yongdai"],
    "venue": "Journal of Computational and Graphical Statistics,",
    "year": 2008
  }, {
    "title": "Logistic Regression in Rare Events Data",
    "authors": ["King", "Gary", "Zeng", "Langche"],
    "venue": "Political Analysis,",
    "year": 2001
  }, {
    "title": "Sparse semisupervised support vector machines by DC programming and DCA",
    "authors": ["H.M. Le", "H.A. Le Thi", "M.C. Nguyen"],
    "year": 2015
  }, {
    "title": "DCA based algorithms for feature selection in multi-class support vector machine",
    "authors": ["H.A. Le Thi", "M.C. Nguyen"],
    "venue": "Annals of Operations Research,",
    "year": 2017
  }, {
    "title": "Sparse Signal Recovery by Difference of Convex Functions Algorithms",
    "authors": ["H.A. Le Thi", "Nguyen", "T.B. T", "H.M. Le"],
    "venue": "In Intelligent Information and Database Systems,",
    "year": 2013
  }, {
    "title": "Feature selection for linear SVMs under uncertain data: Robust optimization based on difference of convex functions algorithms",
    "authors": ["H.A. Le Thi", "X.T. Vo", "T. Pham Dinh"],
    "venue": "Neural Networks,",
    "year": 2014
  }, {
    "title": "DC approximation approaches for sparse optimization",
    "authors": ["H.A. Le Thi", "T. Pham Dinh", "H.M. Le", "X.T. Vo"],
    "venue": "European Journal of Operational Research,",
    "year": 2015
  }, {
    "title": "The DC (Difference of Convex Functions) Programming and DCA Revisited with DC Models of Real World Nonconvex Optimization Problems",
    "authors": ["Le Thi", "Hoai An", "Pham Dinh", "Tao"],
    "venue": "Annals of Operations Research,",
    "year": 2005
  }, {
    "title": "DC Programming and DCA for Sparse Optimal Scoring Problem",
    "authors": ["Le Thi", "Hoai An", "Phan", "Duy Nhat"],
    "venue": "Neurocomput., 186(C):170–181,",
    "year": 2016
  }, {
    "title": "DC programming and DCA for sparse Fisher linear discriminant analysis",
    "authors": ["Le Thi", "Hoai An", "Phan", "Duy Nhat"],
    "venue": "Neural Computing and Applications,",
    "year": 2016
  }, {
    "title": "A DC programming approach for feature selection in support vector machines learning",
    "authors": ["Le Thi", "Hoai An", "Le", "Hoai Minh", "Nguyen", "Van Vinh", "Pham", "Dinh Tao"],
    "venue": "Advances in Data Analysis and Classification,",
    "year": 2008
  }, {
    "title": "Sparse optimization for nonconvex group penalized estimation",
    "authors": ["Lee", "Sangin", "Oh", "Miae", "Kim", "Yongdai"],
    "venue": "Journal of Statistical Computation and Simulation,",
    "year": 2016
  }, {
    "title": "Logistic regression for disease classification using microarray data: Model selection in a large p and small n case",
    "authors": ["J.G. Liao", "Chin", "Khew-Voon"],
    "year": 1945
  }, {
    "title": "Multi-task feature selection",
    "authors": ["Obozinski", "Guillaume", "Taskar", "Ben", "Jordan", "Michael"],
    "venue": "Statistics Department, UC Berkeley, Tech. Rep,",
    "year": 2006
  }, {
    "title": "Convex analysis approach to dc programming: Theory, algorithms and applications",
    "authors": ["Pham Dinh", "Tao", "Le Thi", "Hoai An"],
    "venue": "Acta Mathematica Vietnamica,",
    "year": 1997
  }, {
    "title": "Optimization Algorithm for Solving the Trust-Region Subproblem",
    "authors": ["Pham Dinh", "Tao", "Le Thi", "Hoai An. A D. C"],
    "venue": "SIAM Journal of Optimization,",
    "year": 1998
  }, {
    "title": "Efficient bi-level variable selection and application to estimation of multiple covariance matrices. In Advances in Knowledge Discovery and Data Mining: 21st PacificAsia Conference, PAKDD 2017",
    "authors": ["Phan", "Duy Nhat", "Le Thi", "Hoai An", "Pham Dinh", "Tao"],
    "venue": "Proceedings, Part I,",
    "year": 2017
  }, {
    "title": "Proximal stochastic methods for Nonsmooth Nonconvex Finite-Sum Optimization",
    "authors": ["Reddi", "Sashank J", "Sra", "Suvrit", "Poczos", "Barnabas", "Smola", "Alexander J"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Minimizing finite sums with the stochastic average gradient",
    "authors": ["Schmidt", "Mark", "Le Roux", "Nicolas", "Bach", "Francis"],
    "venue": "Mathematical Programming,",
    "year": 2015
  }, {
    "title": "Classification of EEG signals using neural network and logistic regression",
    "authors": ["Subasi", "Abdulhamit", "Erçelebi", "Ergun"],
    "venue": "Computer Methods and Programs in Biomedicine,",
    "year": 2005
  }, {
    "title": "Regression Shrinkage and Selection Via the Lasso",
    "authors": ["Tibshirani", "Robert"],
    "venue": "Journal of the Royal Statistical Society, Series B,",
    "year": 1994
  }, {
    "title": "Sparse group lasso and high dimensional multinomial classification",
    "authors": ["Vincent", "Martin", "Hansen", "Niels Richard"],
    "venue": "Comput. Stat. Data Anal.,",
    "year": 2014
  }, {
    "title": "Group SCAD regression analysis for microarray time course gene expression data",
    "authors": ["Wang", "Lifeng", "Chen", "Guang", "Li", "Hongzhe"],
    "year": 2007
  }, {
    "title": "Penalized classification using Fisher’s linear discriminant",
    "authors": ["Witten", "Daniela M", "Tibshirani", "Robert"],
    "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
    "year": 2011
  }, {
    "title": "Model selection and estimation in regression with grouped variables",
    "authors": ["Yuan", "Ming", "Lin", "Yi"],
    "venue": "Journal of the Royal Statistical Society, Series B,",
    "year": 2006
  }],
  "id": "SP:9546ad2cc186c558824b67b29b3c884bcb66c4fa",
  "authors": [{
    "name": "Hoai An Le Thi",
    "affiliations": []
  }, {
    "name": "Hoai Minh Le",
    "affiliations": []
  }, {
    "name": "Duy Nhat Phan",
    "affiliations": []
  }],
  "abstractText": "In this paper, we present a stochastic version of DCA (Difference of Convex functions Algorithm) to solve a class of optimization problems whose objective function is a large sum of nonconvex functions and a regularization term. We consider the `2,0 regularization to deal with the group variables selection. By exploiting the special structure of the problem, we propose an efficient DC decomposition for which the corresponding stochastic DCA scheme is very inexpensive: it only requires the projection of points onto balls that is explicitly computed. As an application, we applied our algorithm for the group variables selection in multiclass logistic regression. Numerical experiments on several benchmark datasets and synthetic datasets illustrate the efficiency of our algorithm and its superiority over well-known methods, with respect to classification accuracy, sparsity of solution as well as running time.",
  "title": "Stochastic DCA for the Large-sum of Non-convex Functions Problem and its Application to Group Variable Selection in Classification"
}