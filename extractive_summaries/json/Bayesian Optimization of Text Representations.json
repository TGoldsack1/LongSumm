{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2100–2105, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "NLP researchers and practitioners spend a considerable amount of time comparing machine-learned models of text that differ in relatively uninteresting ways. For example, in categorizing texts, should the “bag of words” include bigrams, and is tf-idf weighting a good idea? In learning word embeddings, distributional similarity approaches have been shown to perform competitively with neural network models when the hyperparameters (e.g., context window, subsampling rate, smoothing constant) are carefully tuned (Levy et al., 2015). These choices matter experimentally, often leading to big differences in performance, with little consistency across tasks and datasets in which combination of choices works best. Unfortunately, these differences tell us little about language or the problems that machine learners are supposed to solve.\nWe propose that these decisions can be automated in a similar way to hyperparameter selection (e.g., choosing the strength of a ridge or lasso regularizer). Given a particular text dataset and classification task, we show a technique for optimizing over the space of representational choices, along\nwith other “nuisances” that interact with these decisions, like hyperparameter selection. For example, using higher-order n-grams means more features and a need for stronger regularization and more training iterations. Generally, these decisions about instance representation are made by humans, heuristically; our work seeks to automate them, not unlike Daelemans et al. (2003), who proposed to use genetic algorithms to optimize representational choices.\nOur technique instantiates sequential modelbased optimization (SMBO; Hutter et al., 2011). SMBO and other Bayesian optimization approaches have been shown to work well for hyperparameter tuning (Bergstra et al., 2011; Hoffman et al., 2011; Snoek et al., 2012). Though popular in computer vision (Bergstra et al., 2013), these techniques have received little attention in NLP.\nWe apply it to logistic regression on a range of topic and sentiment classification tasks. Consistently, our method finds representational choices that perform better than linear baselines previously reported in the literature, and that, in some cases, are competitive with more sophisticated non-linear models trained using neural networks."
  }, {
    "heading": "2 Problem Formulation and Notation",
    "text": "Let the training data consist of a collection of pairs dtrain = 〈〈d.i1, d.o1〉, . . . , 〈d.in, d.on〉〉, where each input d.i ∈ I is a text document and each output d.o ∈ O, the output space. The overall training goal is to maximize a performance function f (e.g., classification accuracy, log-likelihood, F1 score, etc.) of a machine-learned model, on a held-out dataset, ddev ∈ (I× O)n′ .\nClassification proceeds in three steps: first, x : I → RN maps each input to a vector representation. Second, a predictive model (typically, its parameters) is learned from the inputs (now transformed into vectors) and outputs: L : (RN × O)n → (RN → O). Finally, the resulting classifier c : I → O is fixed as L(dtrain) ◦ x (i.e., the composition of the representation function with\n2100\nthe learned mapping). Here we consider linear classifiers of the form c(d.i) = arg maxo∈O w>o x(d.i), where the parameters wo ∈ RN , for each output o, are learned using logistic regression on the training data. We let w denote the concatenation of all wo. Hence the parameters can be understood as a function of the training data and the representation function x. The performance function f , in turn, is a function of the held-out data ddev and x—also w and dtrain , through x. For simplicity, we will write “f(x)” when the rest are clear from context.\nTypically, x is fixed by the model designer, perhaps after some experimentation, and learning focuses on selecting the parameters w. For logistic regression and many other linear models, this training step reduces to convex optimization in N |O| dimensions—a solvable problem that is costly for large datasets and/or large output spaces. In seeking to maximize f with respect to x, we do not wish to carry out training any more times than necessary.\nChoosing x can be understood as a problem of selecting hyperparameter values. We therefore turn to Bayesian optimization, a family of techniques that can be used to select hyperparameter values intelligently when solving for parameters (w) is costly."
  }, {
    "heading": "3 Bayesian Optimization",
    "text": "Our approach is based on sequential model-based optimization (SMBO; Hutter et al., 2011). It iteratively chooses representation functions x. On each round, it makes this choice through a probabilistic model of f , then evaluates f—we call this a “trial.” As in any iterative search algorithm, the goal is to balance exploration of options for x with exploitation of previously-explored options, so that a good choice is found in a small number of trials.\nMore concretely, in the tth trial, xt is selected using an acquisition function A and a “surrogate” probabilistic model pt. Second, f is evaluated given xt—an expensive operation which involves training to learn parameters w and assessing performance on the held-out data. Third, the surrogate model is updated. See Algorithm 1; details on A and pt follow.\nAcquisition Function. A good acquisition function returns high values for x when either the value f(x) is predicted to be high, or the uncertainty about f(x)’s value is high; balancing between these is the classic tradeoff between exploitation\nAlgorithm 1 SMBO algorithm Input: number of trials T , target function f p1 = initial surrogate model Initialize y∗\nfor t = 1 to T do xt ← arg maxx A(x; pt, y∗) yt ← evaluate f(xt) Update y∗\nEstimate pt given x1:t and y1:t end for\nand exploration. We use a criterion called Expected Improvement (EI; Jones, 2001),1 which is the expectation (under the current surrogate model pt) that f(x) = y will exceed f(x∗) = y∗:\nA(x; pt, y∗) = ∫ ∞ −∞ max(y − y∗, 0)pt(y | x)dy\nwhere x∗ is chosen depending on the surrogate model, discussed below. (For now, think of it as a strongly-performing “benchmark” discovered in earlier iterations.) Other options for the acquisition function include maximum probability of improvement (Jones, 2001), minimum conditional entropy (Villemonteix et al., 2009), Gaussian process upper confidence bound (Srinivas et al., 2010), or a combination of them (Hoffman et al., 2011).\nSurrogate Model. As a surrogate model, we use a tree-structured Parzen estimator (TPE; Bergstra et al., 2011).2 This is a nonparametric approach to density estimation. We seek to estimate pt(y | x) where y = f(x), the performance function that is expensive to compute exactly. The TPE approach\nseeks pt(y | x) ∝ pt(y) · { p<t (x), if y<y ∗\np≥t (x), if y≥y∗ , where\np<t and p ≥ t are densities estimated using observations from previous trials that are less than and greater than y∗, respectively. In TPE, y∗ is defined as some quantile of the observed y from previous trials; we use 15-quantiles.\nAs shown by Bergstra et al. (2011), the Expected Improvement in TPE can be written as:\n1EI is the most widely used acquisition function that has been shown to work well on a range of tasks.\n2Another common approach to the surrogate is the Gaussian process (Rasmussen and Williams, 2006; Hoffman et al., 2011; Snoek et al., 2012). Like Bergstra et al. (2011), our preliminary experiments found the TPE to perform favorably. Further TPE’s tree-structured configuration space is advantageous, because it allows nested definitions of hyperparameters, which we exploit in our experiments (e.g., only allows bigrams to be chosen if unigrams are also chosen).\nA(x; pt, y∗) ∝ ( γ + p < t (x)\np≥t (x) (1− γ)\n)−1 , where\nγ = pt(y < y∗), fixed at 0.15 by definition of y∗ (above). Here, we prefer x with high probability under p≥t (x) and low probability under p < t (x). To maximize this quantity, we draw many candidates according to p≥t (x) and evaluate them according to p<t (x)/p ≥ t (x). Note that p(y) does not need to be given an explicit form. To compute p<t (x) and p≥t (x), we associate each hyperparameter with a node in the graphical model and multiply individual probabilities at every node—see Bergstra et al. (2011) for details."
  }, {
    "heading": "4 Experiments",
    "text": "We fix L to logistic regression. We optimize text representation based on the types of n-grams used, the type of weighting scheme, and the removal of stopwords; we also optimize the regularizer and training convergence criterion, which interact with the representation. See Table 1 for a complete list.\nNote that even with this limited number of options, the number of possible combinations is huge,3 so exhaustive search is computationally expensive. In all our experiments for all datasets, we limit ourselves to 30 trials per dataset. The only preprocessing we applied was downcasing.\nWe always use a development set to evaluate f(x) during learning and report the final result on an unseen test set. We summarize the hyperparameters selected by our method, and the accuracies achieved (on test data) in Table 5. We discuss comparisons to baselines for each dataset in turn. For each of our datasets, we select supervised, nonensemble classification methods from previous literature as baselines. In each case, we emphasize comparisons with the best-published linear method\n3It is actually infinite since the reg. strength and conv. tolerance are continuous values, but we could discretize them.\n(often an SVM with a linear kernel with representation selected by experts) and the best-published method overall. In the following, “SVM” always means “linear SVM.” All methods were trained and evaluated on the same training/testing splits as baselines; in cases where standard development sets were not available, we used a random 20% of the training data as a development set.\nStanford sentiment treebank (Socher et al., 2013)—Table 2. A sentence-level sentiment analysis dataset of rottentomatoes.com movie reviews: http://nlp.stanford.edu/sentiment. We use the binary classification task where the goal is to predict whether a review is positive or negative (no neutral). Our logistic regression model outperforms the baseline SVM reported by Socher et al. (2013), who used only unigrams but did not specify the weighting scheme for their SVM baseline. While our result is still below the state-of-the-art based on the the recursive neural tensor networks (Socher et al., 2013) and the paragraph vector (Le and Mikolov, 2014), we show that logistic regression is comparable with recursive and matrix-vector neural networks (Socher et al., 2011; Socher et al., 2012).\nAmazon electronics (McAuley and Leskovec, 2013)—Table 3. A binary sentiment analysis dataset of Amazon electronics product reviews: http://riejohnson.com/cnn data.html. The bestperforming methods on this dataset are based on convolutional neural networks (Johnson and Zhang, 2015).4 Our method is on par with the secondbest of these, outperforming all of the reported feed-forward neural networks and SVM variants Johnson and Zhang used as baselines. They varied\n4These are convolutional neural networks with a rectifier activation function, trained under `2 regularization with stochastic gradient descent. The authors also consider an extension based on parallel CNN that we do not include here.\nthe representations, and used log term frequency and normalization to unit vectors as the weighting scheme, after finding that this outperformed term frequency. Our method achieved the best performance with binary weighting, which they did not consider.\nIMDB movie reviews (Maas et al., 2011)— Table 3. A binary sentiment analysis dataset of highly polar IMDB movie reviews: http://ai.stanford.edu/~amaas/data/sentiment. The results parallel those for Amazon electronics; our method comes close to convolutional neural networks (Johnson and Zhang, 2015), which are state-of-the-art.5 It outperforms SVMs and feed-forward neural networks, the restricted Boltzmann machine approach presented by Dahl et al. (2012), and compressive feature learning (Paskov et al., 2013).6\nCongressional vote (Thomas et al., 2006)—Table 4. A dataset of transcripts from the U.S. Congressional debates: http://www.cs.cornell.edu/~ainur/sle-data.html. Similar to previous work (Thomas et al., 2006; Bansal et al., 2008; Yessenalina et al., 2010), we consider the task to predict the vote (“yea” or “nay”) for the speaker of each speech segment (speaker-based speech-segment classification). Our method outperforms the best results of Yessenalina et al. (2010), which use a multi-level structured\n5As noted, semi-supervised and ensemble methods are excluded for a fair comparison.\n6This approach is based on minimum description length, using unlabeled data to select a set of higher-order n-grams to use as features.\nmodel based on a latent-variable SVM. We show comparisons to two weaker baselines as well."
  }, {
    "heading": "20 Newsgroups (Lang, 1995) all topics—Table 6.",
    "text": "20 Newsgroups is a benchmark topic classification dataset: http://qwone.com/~jason/20Newsgroups. There are 20 topics in this dataset. Our method outperforms state-of-the-art methods including the distributed structured output model (Srikumar and Manning, 2014).7 The strong logistic regression baseline from Paskov et al. (2013) uses all 5-grams, heuristic normalization, and elastic net regularization; our method found that unigrams and bigrams, with binary weighting and `2 penalty, achieved far better results.\n20 Newsgroups: talk.religion.misc vs. alt.atheism and comp.graphics vs. comp.windows.x. We derived three additional topic classification tasks from the 20N dataset. The first and second tasks are talk.religion.misc vs. alt.atheism (test size = 686) and comp.graphics vs. comp.windows.x (test size = 942). Wang and Manning (2012) report a bigram naı̈ve Bayes model achieving 85.1% and 91.2% on these tasks, respectively (best single model results).8 Our\n7This method was designed for structured prediction, but Srikumar and Manning (2014) also applied it to classification. It attempts to learn a distributed representation for features and for labels. The authors used unigrams and did not discuss the weighting scheme.\n8They also report a naı̈ve Bayes/SVM ensemble achieving 87.9% and 91.2%.\nmethod achieves 86.3% and 92.1% using slightly different representations (see Table 5). The last task is to classify related science documents into four science topics (sci.crypt, sci.electronics, sci.space, sci.med; test size = 1, 899). We were not able to find previous results that are comparable to ours on this task; we include our result (95.82%) to enable further comparisons in the future."
  }, {
    "heading": "5 Discussion",
    "text": "Optimized representations. For each task, the chosen representation is different. Out of all possible choices in our experiments (Table 1), each of them is used by at least one of the datsets (Table 5). For example, on the Congress vote dataset, we only need to use bigrams, whereas on the Amazon electronics dataset we need to use {1, 2, 3}-grams. The binary weighting scheme works well for most of the datasets, except the sentence-level sentiment analysis task, where the tf-idf weighting scheme was selected. `2 regularization was best in all cases but one. We do not believe that an NLP expert would be likely to make these particular choices, except through the same kind of trial-and-error process our method automates efficiently.\nNumber of trials. We ran 30 trials for each dataset in our experiments. Figure 1 shows each trial accuracy and the best accuracy on development data as we increase the number of trials for two datasets. We can see that 30 trials are generally enough for the model to obtain good results, although the search space is large.\nTransfer learning and multitask setting. We treat each dataset independently and create a separate model for each of them. It is also possible to learn from previous datasets (i.e., transfer learning) or to learn from all datasets simultaneously (i.e., multitask learning) to improve performance. This has the potential to reduce the number of trials\nrequired even further. See Bardenet et al. (2013), Swersky et al. (2013), and Yogatama and Mann (2014) for more about how to perform Bayesian optimization in these settings.\nBeyond supervised learning. Our framework could also be extended to unsupervised and semisupervised models. For example, in document clustering (e.g., k-means), we also need to construct representations for documents. Log-likelihood might serve as a performance function. A range of random initializations might be considered. Investigation of this approach for nonconvex problems is an exciting area for future work."
  }, {
    "heading": "6 Conclusion",
    "text": "We used Bayesian optimization to optimize choices about text representations for various categorization problems. Our technique identifies settings for a standard linear model (logistic regression) that are competitive with far more sophisticated methods on topic classification and sentiment analysis."
  }, {
    "heading": "Acknowledgments",
    "text": "We thank several reviewers for their helpful feedback. This work was supported by the Defense Advanced Research Projects Agency through grant FA87501420244 and computing resources provided by Amazon. This research was completed while NAS was at CMU."
  }],
  "year": 2015,
  "references": [{
    "title": "The power of negative thinking: Exploiting label disagreement in the min-cut classification framework",
    "authors": ["Mohit Bansal", "Clair Cardie", "Lillian Lee."],
    "venue": "Proc. of COLING.",
    "year": 2008
  }, {
    "title": "Collaborative hyperparameter tuning",
    "authors": ["Remi Bardenet", "Matyas Brendel", "Balazs Kegl", "Michele Sebag."],
    "venue": "Proc. of ICML.",
    "year": 2013
  }, {
    "title": "Algorithms for hyper-parameter optimization",
    "authors": ["James Bergstra", "Remi Bardenet", "Yoshua Bengio", "Balazs Kegl."],
    "venue": "NIPS.",
    "year": 2011
  }, {
    "title": "Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures",
    "authors": ["James Bergstra", "Daniel Yamins", "David Cox."],
    "venue": "Proc. of ICML.",
    "year": 2013
  }, {
    "title": "Combined optimization of feature selection and algorithm parameters in machine learning of language",
    "authors": ["Walter Daelemans", "Veronique Hoste", "Fien De Meulder", "Bart Naudts."],
    "venue": "Proc. of ECML.",
    "year": 2003
  }, {
    "title": "Training restricted Boltzmann machines on word observations",
    "authors": ["George E. Dahl", "Ryan P. Adams", "Hugo Larochelle."],
    "venue": "Proc. of ICML.",
    "year": 2012
  }, {
    "title": "Portfolio allocation for Bayesian optimization",
    "authors": ["Matthew Hoffman", "Eric Brochu", "Nando de Freitas."],
    "venue": "Proc. of UAI.",
    "year": 2011
  }, {
    "title": "Sequential model-based optimization for general algorithm configuration",
    "authors": ["Frank Hutter", "Holger H. Hoos", "Kevin Leyton-Brown."],
    "venue": "Proc. of LION.",
    "year": 2011
  }, {
    "title": "Effective use of word order for text categorization with convolutional neural networks",
    "authors": ["Rie Johnson", "Tong Zhang."],
    "venue": "Proc. of NAACL.",
    "year": 2015
  }, {
    "title": "A taxonomy of global optimization methods based on response surfaces",
    "authors": ["Donald R. Jones."],
    "venue": "Journal of Global Optimization, 21:345–385.",
    "year": 2001
  }, {
    "title": "Newsweeder: Learning to filter netnews",
    "authors": ["Ken Lang."],
    "venue": "Proc. of ICML.",
    "year": 1995
  }, {
    "title": "Classification using discriminative restricted Boltzmann machines",
    "authors": ["Hugo Larochelle", "Yoshua Bengio."],
    "venue": "Proc. of ICML.",
    "year": 2008
  }, {
    "title": "Distributed representations of sentences and documents",
    "authors": ["Quoc V. Le", "Tomas Mikolov."],
    "venue": "Proc. of ICML.",
    "year": 2014
  }, {
    "title": "Improving distributional similarity with lessons learned from word embeddings",
    "authors": ["Omer Levy", "Yoav Goldberg", "Ido Dagan."],
    "venue": "Transactions of the Association for Computational Linguistics, 3:211–225.",
    "year": 2015
  }, {
    "title": "Learning word vectors for sentiment analysis",
    "authors": ["Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts."],
    "venue": "Proc. of ACL.",
    "year": 2011
  }, {
    "title": "Hidden factors and hidden topics: understanding rating dimensions with review text",
    "authors": ["Julian McAuley", "Jure Leskovec."],
    "venue": "Proc. of RecSys.",
    "year": 2013
  }, {
    "title": "Compressive feature learning",
    "authors": ["Hristo S. Paskov", "Robert West", "John C. Mitchell", "Trevor J. Hastie."],
    "venue": "Proc of NIPS.",
    "year": 2013
  }, {
    "title": "Gaussian Processes for Machine Learning",
    "authors": ["Carl Edward Rasmussen", "Christopher K.I. Williams."],
    "venue": "The MIT Press.",
    "year": 2006
  }, {
    "title": "Practical Bayesian optimization of machine learning algorithms",
    "authors": ["Jasper Snoek", "Hugo Larrochelle", "Ryan P. Adams."],
    "venue": "NIPS.",
    "year": 2012
  }, {
    "title": "Semi-supervised recursive autoencoders for predicting sentiment distributions",
    "authors": ["Richard Socher", "Jeffrey Pennington", "Eric H. Huang", "Andrew Y. Ng", "Christopher D. Manning."],
    "venue": "Proc. of EMNLP.",
    "year": 2011
  }, {
    "title": "Semantic compositionality through recursive matrix-vector spaces",
    "authors": ["Richard Socher", "Brody Huval", "Christopher D. Manning", "Andrew Y. Ng."],
    "venue": "Proc. of EMNLP.",
    "year": 2012
  }, {
    "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
    "authors": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Chris Manning", "Andrew Ng", "Chris Potts."],
    "venue": "Proc. of EMNLP.",
    "year": 2013
  }, {
    "title": "Learning distributed representations for structured output prediction",
    "authors": ["Vivek Srikumar", "Christopher D. Manning."],
    "venue": "NIPS.",
    "year": 2014
  }, {
    "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
    "authors": ["Niranjan Srinivas", "Andreas Krause", "Sham Kakade", "Matthias Seeger."],
    "venue": "Proc. of ICML.",
    "year": 2010
  }, {
    "title": "Multi-task Bayesian optimization",
    "authors": ["Kevin Swersky", "Jasper Snoek", "Ryan P. Adams."],
    "venue": "NIPS.",
    "year": 2013
  }, {
    "title": "Get out the vote: Determining support or opposition from congressional floor-debate transcripts",
    "authors": ["Matt Thomas", "Bo Pang", "Lilian Lee."],
    "venue": "Proc. of EMNLP.",
    "year": 2006
  }, {
    "title": "An informational approach to the global optimization of expensive-to-evaluate functions",
    "authors": ["Julien Villemonteix", "Emmanuel Vazquez", "Eric Walter."],
    "venue": "Journal of Global Optimization, 44(4):509– 534.",
    "year": 2009
  }, {
    "title": "Baselines and bigrams: Simple, good sentiment and topic classification",
    "authors": ["Sida Wang", "Christopher D. Manning."],
    "venue": "Proc. of ACL.",
    "year": 2012
  }, {
    "title": "Multi-level structured models for document sentiment classification",
    "authors": ["Ainur Yessenalina", "Yisong Yue", "Claire Cardie."],
    "venue": "Proc. of EMNLP.",
    "year": 2010
  }, {
    "title": "Efficient transfer learning method for automatic hyperparameter tuning",
    "authors": ["Dani Yogatama", "Gideon Mann."],
    "venue": "Proc. of AISTATS.",
    "year": 2014
  }],
  "id": "SP:fde0a7e5a0dec93b36b85fb016930689ca541c79",
  "authors": [{
    "name": "Dani Yogatama",
    "affiliations": []
  }, {
    "name": "Lingpeng Kong",
    "affiliations": []
  }, {
    "name": "Noah A. Smith",
    "affiliations": []
  }],
  "abstractText": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. They can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We apply sequential model-based optimization over this space of choices and show that it makes standard linear models competitive with more sophisticated, expensive state-ofthe-art methods based on latent variables or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning.",
  "title": "Bayesian Optimization of Text Representations"
}