{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2002–2006, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.\nThe conferences ACL (Association for Computational Linguistics) and EMNLP (Empirical Methods in Natural Language Processing) rank among the premier venues that track the research developments in Natural Language Processing and Computational Linguistics. In this paper, we present a study on the research papers of approximately two decades from these two NLP conferences. We apply keyphrase extraction and corpus analysis tools to the proceedings from these venues and propose probabilistic and vector-based representations to represent the topics published in a venue for a given year. Next, similarity metrics are studied over pairs of venue representations to capture the progress of the two venues with respect to each other and over time."
  }, {
    "heading": "1 Introduction",
    "text": "Scientific findings in a subject-area are typically published in conferences, journals, patents, and books in that domain. These research documents constitute valuable resources from the perspective of data mining applications. For instance, the citation links among research documents are used in computing bibliometric quantities for authors (Alonso et al., 2009) whereas topic models on research corpora are used to distinguish between influential and impactful researchers (Kataria et al., 2011) and to capture temporal topic trends (He et al., 2009).\nDespite several potential benefits mentioned above and the free availability of most research\nproceedings in NLP through the ACL Anthology1, the topical and temporal aspects of this corpus are yet to be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading publication venues. Our contributions are summarized below:\n1. We represent the NLP research corpus from approximately two decades as a keyphrasedocument matrix and apply Latent Dirichlet Allocation (Blei et al., 2003) to extract coherent topics from it (Newman et al., 2010).\n2. We propose two novel representations for summarizing the venue proceedings in a given year. (1) The probabilistic representation expresses each venue as a probability distribution over topics, whereas (2) the TPICP representation captures topics that are the major focus in the venue for a particular year via Topic Proportion (TP) as well as topic importance as measured with inverse corpus proportion (ICP).\n3. We apply Jensen-Shannon divergence and cosine similarity on our proposed venue representations to analyze the venues over time. Specifically, we ask the following questions: What are the popular topics in ACL and EMNLP in a particular year? Is the topical focus in EMNLP different from ACL? How\n1https://aclweb.org/anthology/\n2002\ndid the topical focus in each venue change over time?\nOrganization: We describe our novel venue representations and the measures used to compare them in Section 2. The details of our datasets and experiments are presented in Section 3 along with results and observations. We summarize related research in Section 4 before concluding the paper in Section 5."
  }, {
    "heading": "2 Methods",
    "text": "Let Y = {y1, y2 . . . yT } be the consecutive years in which the research proceedings are available from V , set of publication venues under consideration (V = {“ACL”, “EMNLP”} in this paper). If D is the set of all documents over the years, each document d ∈ D is associated with {Kd, y, v} where Kd refers to the content of d whereas v and y refer to the venue and year in which d was published."
  }, {
    "heading": "2.1 Venues as Probability Distributions",
    "text": "Let t1, t2 . . . tk denote the topics capturing the content of documents in D. Using probabilistic topic modeling and dimension reduction tools such as Latent Dirichlet Allocation or pLSA (Hofmann, 1999; Blei et al., 2003), we extract for each d ∈ D, P (ti|d), i = 1 . . . k, the multinomial distribution over the topics associated with d.\nThe venue-topic probability distribution P (ti|vy) for a given (venue, year) pair (v = l, y = m) can be computed using Dl,m, the set of documents published in venue l, in the year m. That is,\nPl,m(ti) = 1 |Dl,m| ∑\nd∈Dl,m P (ti|d) (1)\nNote that the above probabilistic representation facilitates a quantitative measure to compare two venues: the divergence between the probability distributions of the two venues. The Kullback−Leibler divergence (KLD) between two (discrete) probability distributions P and Q is given by: DKL(P ||Q) =\n∑ i P (i)log P (i)Q(i) . Due\nto the unsymmetric nature of KLD, we use the Jensen-Shannon divergence, a symmetric and finite measure (0 ≤ JSD(P ||Q) ≤ 1) based on KLD. Let M = 12 (P + Q),\nJSD(P ||Q) = 1 2 [DKL(P ||M) + DKL(Q||M)]"
  }, {
    "heading": "2.2 Venues as TP-ICP Vectors",
    "text": "Discrete probability distributions are often represented in computations as normalized vectors. For instance, the P (ti|v) values comprise the components of a k-dimensional vector. This topic proportion (TP) vector is similar to the normalized term frequency vector commonly used in Information Retrieval (IR) (Manning et al., 2008). TP values are fractions indicating the percentage of a given topic among all topics covered in a particular year. Thus these values are higher for topics that are the major focus in the venue for a particular year .\nWe also extend inverse document frequency, a popular concept that is used to weigh terms in IR (Manning et al., 2008) to describe Inverse Corpus Proportion or ICP. Our objective in defining ICP is to capture the importance of a topic by diminishing the effect of topics that are common across all years. Let TPv,y(i) represents the proportion of topic ti in venue v for year y, then ICP (ti) = log ( |Y |∑ y=1 |V |∑ v=1 k∑ j=1 TPv,y(j)\n|Y |∑ y=1 |V |∑ v=1 TPv,y(i)\n) = ( |D| |Y |∑ y=1 |V |∑ v=1 TPv,y(i) )\nsince k∑\nj=1 TP(j) = 1, TP being a probability dis-\ntribution vector and |Y | × |V | = |D|. The TPICP vector for a venue is defined as: [TP (1) × ICP (1), . . . TP (k) × ICP (k)] and captures in each component the weighted proportion of a topic in that venue for a year. This novel representation can be considered the topic-level counterpart of the popular TF-IDF representation in IR. Given two TP-ICP vectors P = [p1, p2, . . . pk] and Q = [q1, q2, . . . qk], the similarity between them using the cosine measure is given by:\ncosine(P,Q) =\nk∑ i=1 pi.qi\n||P ||2.||Q||2"
  }, {
    "heading": "2.3 Keyphrases for representing documents",
    "text": "Corpus analysis tools often use bag-of-words models and term frequencies for representing documents (Heinrich, 2005). However, research documents are often well-structured, and contain various sections with author information, citations,\nand content-related sections such as abstract, related work, and experiments. To best represent the topical content of these documents, we harness the latest work on keyphrase extraction for research documents and represent documents using keyphrases (Hasan and Ng, 2014).\nWe use the ExpandRank algorithm (Wan and Xiao, 2008) to extract top n-grams ∀d ∈ D. ExpandRank effectively combines PageRank values on word graphs with text similarity scores between documents to score n-grams for a document and was shown to outperform other unsupervised keyphrase extraction methods on research documents in absence of other information such as citations (Gollapalli and Caragea, 2014)."
  }, {
    "heading": "3 Experiments",
    "text": "Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 20142 using the Java-based crawler, Heritrix3. The text from the PDF documents was extracted using the PDFBox software4 after which simple rules similar to the ones used in CiteSeer (Li et al., 2006) were employed to extract the “body” of the research document5. The numbers of papers for each year at the end of this process are listed in Table 2. From these numbers,\n2 Since our goal is to compare the two venues, we start from 1996 when EMNLP branched off into a full conference from a workshop on Very Large Corpora although ACL proceedings are available from 1979.\n3 https://webarchive.jira.com/wiki/display/Heritrix/Heritrix 4 https://pdfbox.apache.org/ 5 Processed data available upon request.\nit appears that the paper “intake” in each conference has gone up overall during the last decade although occasionally the increase is due to colocation with related conferences such as IJCNLP and HLT6.\nWe construct the keyphrase-document matrix using top-100 keyphrases of each document extracted with ExpandRank. The LDA implementation provided in Mallet (McCallum, 2002) was used to extract topics from this matrix. The LDA algorithm was run along with hyperparameter optimization (Minka, 2003) for different numbers of topics between 10 . . . 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30."
  }, {
    "heading": "3.1 Results and Observations",
    "text": "The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we are able to extract coherent topics from the corpus using LDA on a documentkeyphrase matrix (AlSumait et al., 2009; Newman et al., 2010).\nTop research topics in NLP: We select five timepoints {1996, 2000, 2005, 2010, 2014} by splitting the 1996-2014 period into roughly-\n6 ACL was co-located with related conferences in the years 1997, 1998, 2006,\n2008, and 2009 and EMNLP in the years 2005, 2007, and 2012.\nequal parts and examine the top topics for ACL and EMNLP at these time points. We rank the topics in each conference by their TP-ICP values and list the top 3 topics in the right table of Figure 1. “Semantic relation extraction”, “sentiment analysis”, and “topic models” are the top research topics in NLP last year (2014) whereas in the year 1996, the topics “noun phrase extraction”, “summarization”, “corpus modeling”, and “speech recognition” dominated the NLP research arena. From the table, it can be seen that “information retrieval” (topicID: 18) ranks among the top topics in EMNLP for all three timepoints during 2000-2010 whereas “natural language generation” (topicID: 9) was consistently addressed during 1996-2005 in ACL.\nEMNLP versus ACL: We compare the venues using JSD and Cosine similarity measures in the middle plot of Figure 1. The plot shows decreasing divergence between the topical distributions over the years and increasing cosine similarity between the TP-ICP vectors for the venues. These trends indicate that over the two decades the two venues ACL and EMNLP seem to have “become like each other” although their topical focus was different during the initial years. Increasingly, both venues seem to publish papers on similar top-\nics. This behavior could be interpreted to mean that the NLP research field is more stable now with two of its leading conferences addressing problems on similar topics.\nChanging topical focus over the years: In the first plot of Figure 2, we show the JensenShannon divergence between the topic distributions of a particular venue for a given year y and (y − 1), the year preceding it. The curve indicates that in the years between 1997-2008, the rate of change from year to year is higher than in the years following 2008. We split the time period 1996-2014 into five roughly-equal parts to form the set {1996, 2000, 2005, 2010, 2014}. The JSD between the distribution in a particular year and the years preceding it in the above set is shown for ACL (middle plot) and EMNLP (right plot) in Figure 2. For example, the first cluster in the middle plot, shows the JSD values between the distributions for the years 2000, 2005, 2010, 2014 with the starting year 1996 for ACL. For both venues, the divergences of a given year are higher with the early starting years 1996 and 2000 than with the later starting years 2005 and 2010, indicating that the topics being addressed currently in NLP research are significantly different from those addressed a decade back."
  }, {
    "heading": "4 Related Work",
    "text": "Temporal analysis of corpora is an upcoming research topic in text mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009).\nIn contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the ACL Anthology during the years 1978-2006. They also noted that all the venues seem to converge in the topics they cover over the years based on the JSD between their topic distributions."
  }, {
    "heading": "5 Conclusions",
    "text": "We presented our study on research proceedings of approximately two decades from the leading NLP conference venues: EMNLP and ACL. We extracted coherent topics from this corpus by applying topic modeling on the corresponding keyphrase-document matrix. Next, the extracted topics were used to characterize each venue through probabilistic and vector representations and compared against each other and over the years using various similarity measures. To the best of our knowledge, we are the first to present insights related to the development of a research field by studying two leading conferences in the area using various techniques from NLP and IR."
  }],
  "year": 2015,
  "references": [{
    "title": "h-index: A review focused in its variants, computation and standardization for different scientific fields",
    "authors": ["S. Alonso", "F.J. Cabrerizo", "E. Herrera-Viedma", "F. Herrera."],
    "venue": "Journal of Informetrics, 3(4):273 – 289.",
    "year": 2009
  }, {
    "title": "Topic significance ranking of lda generative models",
    "authors": ["Loulwah AlSumait", "Daniel Barbar", "James Gentle", "Carlotta Domeniconi."],
    "venue": "Machine Learning and Knowledge Discovery in Databases, Lecture Notes in Computer Science.",
    "year": 2009
  }, {
    "title": "Latent dirichlet allocation",
    "authors": ["David M. Blei", "Andrew Y. Ng", "Michael I. Jordan."],
    "venue": "J. Mach. Learn. Res., pages 993–1022.",
    "year": 2003
  }, {
    "title": "Extracting keyphrases from research papers using citation networks",
    "authors": ["Sujatha Das Gollapalli", "Cornelia Caragea."],
    "venue": "AAAI.",
    "year": 2014
  }, {
    "title": "Studying the history of ideas using topic models",
    "authors": ["David Hall", "Daniel Jurafsky", "Christopher D. Manning."],
    "venue": "EMNLP.",
    "year": 2008
  }, {
    "title": "Automatic keyphrase extraction: A survey of the state of the art",
    "authors": ["Kazi Saidul Hasan", "Vincent Ng."],
    "venue": "ACL.",
    "year": 2014
  }, {
    "title": "Detecting topic evolution in scientific literature: how can citations help",
    "authors": ["Qi He", "Bi Chen", "Jian Pei", "Baojun Qiu", "Prasenjit Mitra", "C. Lee Giles"],
    "venue": "In CIKM,",
    "year": 2009
  }, {
    "title": "Parameter estimation for text analysis",
    "authors": ["G. Heinrich."],
    "venue": "Technical report.",
    "year": 2005
  }, {
    "title": "Probabilistic latent semantic indexing",
    "authors": ["Thomas Hofmann."],
    "venue": "SIGIR, pages 50–57.",
    "year": 1999
  }, {
    "title": "Discovery of activity patterns using topic models",
    "authors": ["Tâm Huynh", "Mario Fritz", "Bernt Schiele."],
    "venue": "International Conference on Ubiquitous Computing.",
    "year": 2008
  }, {
    "title": "Context sensitive topic models for author influence in document networks",
    "authors": ["Saurabh Kataria", "Prasenjit Mitra", "Cornelia Caragea", "C. Lee Giles."],
    "venue": "IJCAI, pages 2274–2280.",
    "year": 2011
  }, {
    "title": "Citeseerx: a scalable autonomous scientific digital library",
    "authors": ["Huajing Li", "Isaac G. Councill", "Levent Bolelli", "Ding Zhou", "Yang Song", "Wang-Chien Lee", "Anand Sivasubramaniam", "C. Lee Giles."],
    "venue": "InfoScale.",
    "year": 2006
  }, {
    "title": "Introduction to Information Retrieval",
    "authors": ["Christopher D. Manning", "Prabhakar Raghavan", "Hinrich Schutze."],
    "venue": "Cambridge University Press.",
    "year": 2008
  }, {
    "title": "Mallet: A machine learning for language toolkit",
    "authors": ["Andrew Kachites McCallum."],
    "venue": "http://mallet.cs.umass.edu.",
    "year": 2002
  }, {
    "title": "Estimating a dirichlet distribution",
    "authors": ["Thomas P. Minka."],
    "venue": "Technical report, Microsoft Research.",
    "year": 2003
  }, {
    "title": "Automatic evaluation of topic coherence",
    "authors": ["David Newman", "Jey Han Lau", "Karl Grieser", "Timothy Baldwin."],
    "venue": "Human Language Technologies.",
    "year": 2010
  }, {
    "title": "Topic modeling for sequences of temporal activities",
    "authors": ["Zhiyong Shen", "Ping Luo", "Yuhong Xiong", "Jun Sun", "Yidong Shen."],
    "venue": "ICDM, pages 980–985.",
    "year": 2009
  }, {
    "title": "Single document keyphrase extraction using neighborhood knowledge",
    "authors": ["Xiaojun Wan", "Jianguo Xiao."],
    "venue": "AAAI.",
    "year": 2008
  }, {
    "title": "Topics over time: A non-markov continuous-time model of topical trends",
    "authors": ["Xuerui Wang", "Andrew McCallum."],
    "venue": "SIGKDD.",
    "year": 2006
  }],
  "id": "SP:c2a96044b42eec78eeb0de7d84a121934db864fb",
  "authors": [{
    "name": "Sujatha Das Gollapalli",
    "affiliations": []
  }, {
    "name": "Xiao-Li Li",
    "affiliations": []
  }],
  "abstractText": "The conferences ACL (Association for Computational Linguistics) and EMNLP (Empirical Methods in Natural Language Processing) rank among the premier venues that track the research developments in Natural Language Processing and Computational Linguistics. In this paper, we present a study on the research papers of approximately two decades from these two NLP conferences. We apply keyphrase extraction and corpus analysis tools to the proceedings from these venues and propose probabilistic and vector-based representations to represent the topics published in a venue for a given year. Next, similarity metrics are studied over pairs of venue representations to capture the progress of the two venues with respect to each other and over time.",
  "title": "EMNLP versus ACL: Analyzing NLP Research Over Time"
}