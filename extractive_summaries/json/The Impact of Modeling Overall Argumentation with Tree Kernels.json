{
  "sections": [{
    "text": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2379–2389 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Argumentation theory has established a number of major argument models focusing on different aspects, such as the roles of an argument’s units (Toulmin, 1958), the inference scheme of an argument (Walton et al., 2008), or the support and attack relations between arguments (Freeman, 2011). The common ground of these models is that they conceptualize an argument as a conclusion (in terms of a claim) inferred from a set of pro and con premises (reasons), which in turn may be the conclusions of other arguments. For the overall argumentation of a monological argumentative text such as the one in Figure 1(a), this results in an implicit hierarchical structure with the text’s main claim at the lowest depth. In addition, the text has an explicit linguistic structure that can be seen as a regulated sequence of speech acts (van Eemeren and Grootendorst, 2004).\nFigure 1(b) illustrates the interplay of the two types of overall structure in form of a tree-like graph.\nNatural language processing research has largely adopted the outlined hierarchical models for mining arguments from text (Stab and Gurevych, 2014; Habernal and Gurevych, 2015; Peldszus and Stede, 2016). However, the adequacy of the resulting overall structure for downstream analysis tasks of computational argumentation has rarely been evaluated (see Section 2 for details). In fact, a computational approach that can capture patterns in hierarchical overall argumentation is missing so far. Even more, our previous work indicates that a sequential model of overall structure is preferable for analysis tasks such as stance classification or quality assessment (Wachsmuth and Stein, 2017).\nIn this paper, we ask and investigate what model of (monological) overall argumentation is important to tackle argumentation-related analysis tasks. To this end, we consider three corpora with fully\n2379\nannotated argument structure (Section 3). Each corpus allows studying one text classification task, two of which we hypothesize to benefit from modeling argumentation (myside bias, stance), the third not (genre). An empirical analysis of the corpora reveals class-specific patterns of how people argue (Section 4). In order to combine the explicit sequential and the implicit hierarchical structure of an argumentative text for the first time, we then adapt the approach of route kernels (Aiolli et al., 2009), modeling overall argumentation in form of a positional tree (Section 5).\nOn this basis, we design an experiment to evaluate the impact of the different types of argumentative structure (Section 6). In particular, we decompose our approach into four complementary modeling steps, both for a general model of overall argumentation and for the specific models of the given corpora. Using the structure annotated in the corpora, we systematically compare the effectiveness of all eight resulting models and two standard baselines in the three classification tasks.\nOur results provide strong evidence that both sequential and hierarchical structure are important. As indicated by related work, sequential structure nearly competes with hierarchical structure, at least based on the specific argument models. Even more impressively, modeling hierarchical structure practically solves the task of identifying argumentation with myside bias, achieving an outstanding accuracy of 97.1%. For stance classification, the combination captured by positional trees works best. In contrast, all types of structure fail in distinguishing genres, suggesting that they indeed capture properties of argumentation. We conclude that the impact of modeling overall structure on downstream analysis tasks is high, while the required type may vary.\nContributions To summarize, the main contributions of this paper are the following:\n1. Empirical insights into how people structure argumentative texts in overall terms.\n2. The first approach to model and analyze the sequential and hierarchical overall structure of argumentative texts in combination.\n3. Evidence that modeling overall structure impacts argumentation-related analysis tasks."
  }, {
    "heading": "2 Related Work",
    "text": "The study of overall argumentation traces back to Aristotle (2007) who outlined the impact of the\nsequential arrangement of the different parts of a speech. Conceptually, theory agrees that a monological argumentative text has an implicit tree-like hierarchical structure: Toulmin (1958) defines an argument as a claim supported by data that is reasoned by a warrant, which in turn may have a backing. In addition, a rebuttal may be given showing exceptions to the claim. The role of support and attack relations is investigated by Freeman (2011) who models dialectical arguments that discuss both a proponent’s and an opponent’s view on the main claim argued for. Walton et al. (2008) put the focus on the inference scheme that describes how an argument’s conclusion follows from its premises, which may themselves be conclusions of arguments.\nIn natural language processing, argumentation research deals with the mining of argument units and their relations from text (Mochales and Moens, 2011). Several corpora with annotated argument structure have been published in the last years. Many of the corpora adapt the hierarchical models from theory (Reed and Rowe, 2004; Habernal and Gurevych, 2015; Peldszus and Stede, 2016) or propose comparable models (Stab and Gurevych, 2014). Since we target monological overall argumentation, we use those that capture the complete structure of texts, as detailed in Section 3. Corpora focusing on dialogical argumentation (Walker et al., 2012), topic-related arguments (Rinott et al., 2015), or sequential structure (Wachsmuth et al., 2014b; Al Khatib et al., 2016) are out of scope.\nWe do not mine the structure of argumentative texts, but we exploit the previously mined structure to tackle downstream tasks of computational argumentation, namely, to classify the myside bias and stance of texts. For myside bias, Stab and Gurevych (2016) use features derived from discourse structure, whereas Faulkner (2014) and Sobhani et al. (2015) model arguments to classify stance. Ong et al. (2014) and we ourselves (Wachsmuth et al., 2016) do similar to assess the quality of persuasive essays, and Beigman Klebanov et al. (2016) examine how an essay’s content and structure influence quality. Other works predict the outcome of legal cases based on the applied types of reasoning (Brüninghaus and Ashley, 2003) or analyze inference schemes for given arguments (Feng and Hirst, 2011). In contrast to the local structure of single arguments employed by all these approaches, we study the impact of the global overall structure of complete monological argumentative texts.\nIn (Wachsmuth et al., 2017), we point out that the argumentation quality of a text is affected by interactions of its content at different levels of granularity, from single argument units over arguments to overall argumentation. Stede (2016) explores how different depths of overall argumentation can be identified, observing differences across genres. Unlike in our experiments, however, the genres considered there reflect diverging types of argumentation. Related to argumentation, Feng et al. (2014) build upon rhetorical structure theory (Mann and Thompson, 1988) to assess the coherence of texts, while Persing et al. (2010) score the organization of persuasive essays based on sequences of sentence and paragraph functions.\nWe introduced the first explicit computational model of overall argumentation in (Wachsmuth et al., 2014a). There, we compared the flow of local sentiment in a review to a set of learned flow patterns in order to classify global sentiment. Recently, we generalized the model in order to make flows applicable to any type of information relevant for argumentation-related analysis tasks (Wachsmuth and Stein, 2017). However, flows capture only sequential structure, whereas here we also model the hierarchical structure of overall argumentation. To this end, we make use of kernel methods.\nKernel methods are a popular approach for learning on structured data, with several applications in natural language processing (Moschitti, 2006b) including argument mining (Rooney et al., 2012). They employ a similarity function defined between any two input objects that are represented in a taskspecific implicit feature space. The evaluation of such a kernel function relies on the common features of the input objects (Cristianini and ShaweTaylor, 2000). The kernel function encodes knowledge of the task in the form of these features.\nSeveral kernel functions have been defined for structured data. To assess the impact of sequential argumentation, we refer to the function of Mooney and Bunescu (2006), which computes common subsequences of two input sequences. For trees, most existing approaches count common subtrees of a certain type (Collins and Duffy, 2001; Moschitti, 2006a; Kimura and Kashima, 2012), but they do not take the ordering of the nodes in the subtrees into account. In contrast, Aiolli et al. (2009) developed a kernel that combines the content of substructures with the relative positions inside trees, called the route kernel. Similarly, the tree kernel of Daumé III\nand Marcu (2004) includes positional information for document compression. For overall argumentation, we decided to use the route kernel in Section 5, as it makes the modeling of the sequential positions of an argument unit in a text straightforward. This allows us to capture both the sequential and the hierarchical structure at the same time. To our knowledge, no work has done this before.1\nNeural networks denote an alternative for learning on structured data. They become particularly effective when few prior knowledge about what is important to address a task at hand is available, because they can learn any feature representation in principle (Goodfellow et al., 2016). Due to this flexibility, however, large amounts of data are required for training an effective model, making neural networks inadequate for the small datasets that allow studying overall argumentation."
  }, {
    "heading": "3 Tasks and Datasets",
    "text": "We seek to study the impact of modeling overall argumentation on downstream tasks without the noise from argument mining errors. To this end, we rely on three ground-truth argument corpora. Each corpus is suitable for evaluating one text classification task and comes with a specific model of overall argumentation, as detailed in the following.\nMyside Bias on AAE-v2 The Argument Annotated Essays corpus was originally been presented by Stab and Gurevych (2014). We use version 2 of the corpus (available on the website of the authors), which consists of 402 persuasive student essays. In each essay, all main claims, claims, and premises are annotated as such. Each claim has a pro or con stance towards each instance of the main claim, whereas each premise supports or attacks a claim or another premise. Thereby, argumentation is modeled as one tree structure for each major claim.\nStab and Gurevych (2016) added a myside bias class to each essay, reflecting whether its argumentation is one-sided considering only arguments for the own stance (251 cases) or not (151 cases).\nStance on Arg-Microtexts The Arg-Microtexts corpus of Peldszus and Stede (2016) contains 112 short argumentative texts. They cover 18 different controversial topics and are annotated according to Freeman (2011): Each argument unit takes the role of the proponent or opponent of a main claim. What\n1While extensions of the route kernel idea have been published later on (Aiolli et al., 2011, 2015), we resort to the original version in this paper for simplicity.\nthe main claim is follows from a tree-like overall structure emerging from four types of relations: normal or example support from one unit to another, a rebuttal of units by other units, and undercutters where a relation is attacked by another unit.\nFor 88 texts, the stance towards a specified topic is labeled as pro (46) or con (42). We use these labels for classification, but we do not access the topic. This way, stance needs to be identified only based on a text itself — a very challenging task.2\nGenre on Web Discourse Finally, we consider the Argument Annotated User-Generated Web Discourse corpus of Habernal and Gurevych (2015). There, 340 texts are annotated according to a modified version of the specific model of Toulmin (1958) where claims are supported by premises or attacked by rebuttals. Rebuttals in turn may be attacked by refutations. Besides, emotional units not participating in the actual arguments are marked as pathos. The support and attack relations build up the overall argumentation of a text.\nThe corpus composes argumentative texts of four genres, namely, 5 articles, 216 comments to articles, 46 blog posts, and 73 forum posts. The genre is specified in form of a label for each text. Due to the low number, we ignore the articles below.\nTo give an idea of the sequential and hierarchical overall structure in each corpus, Table 1 presents statistics of the argument units, the arguments (in terms of relations between two or more units), and the depth of the resulting argumentation.\nWhile the size of the given corpora and the variety of tasks are limited, the only other available corpus with fully annotated argument structure that we are aware of is AraucariaDB (Reed and Rowe,\n2We do not include the topic, in order not to conflate the impact of modeling argumentation with the influence of the topic. The corpus is too small to analyze topic differences.\n2004). No downstream task can be tackled on AraucariaDB besides inference scheme classification (Feng and Hirst, 2011). As all schemes compose a conclusion and a set of premises (without more specific roles), analyzing overall structure hardly makes sense, which is why we omit the corpus."
  }, {
    "heading": "4 Insights into Overall Argumentation",
    "text": "Before we approach overall argumentation computationally, this section analyzes the three given corpora empirically to provide insights into how people argue in overall terms. For this, we unify the specific corpus models of overall argumentation outlined above in one general model."
  }, {
    "heading": "4.1 A Unified View of Overall Argumentation",
    "text": "The texts in all corpora are segmented into argument units, partly with non-argumentative spans in between that we ignore here for lack of relevance. To capture the sequential ordering of the segmentation, we assign a global index to each unit.\nAs described in Section 3, the specific models of all three corpora in the end consider an argument as a composition of one unit serving as the conclusion with one or more units that support or attack the conclusion (the premises). This composition is defined through multiple relations from one premise to one conclusion each. There is one exception, namely, the undercutter relations in the Arg-Microtexts corpus have a relation as their target. To obtain a unified form in the general model, we modify the undercutters such that they target the premise of the undercutted relation.\nIn all corpora, a premise may be the conclusion of another argument, while no argument unit serves as a premise in multiple arguments. This leads to a tree structure for each main claim of the associated text. A main claim corresponds to a unit that is not a premise. In AAE-v2 and in Web Discourse, more than one such unit may exist per text.\nDepending on the corpus, the distinction of support and attack is encoded through a specified relation type, a unit’s stance, or both. We unify these alternatives by modeling the stance of each unit towards its parent in the associated tree. This stance can be derived in all corpora.3 All other unit and relation types from the specific models are ignored, since there is no clear mapping between them.\n3Alternatively, the stance towards the main claim could be modeled. We decided against this alternative to avoid possibly wrong reinterpretations, e.g., it is unclear whether a unit that attacks its parent always supports a unit attacked by the parent.\nAll texts\nTexts with myside bias\nTexts without myside bias\nAll texts\nTexts with pro stance\nAll texts\nComments\nBlog posts\n(a) AAE-v2 (b) Arg-Microtexts (c) Web Discourse\n0 1 2 3\n0 1 2 3\n0 1 2 3\n0 1 2 3\n0 1\n0 1\n0 1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\n1 2 3 4 5 6 7\n1 2 3 4 5 6\n1 2 3 4 5 6 7 8\n1 2 3 4 5 6 7\n1 2 3 4 5 6 7 8720 21 22\n20 21 22\nGeneral Model As a result, we model the overall argumentation of an argumentative text as a forest of trees. Each node in a tree corresponds to an argument unit. It has an assigned stance (pro or con) as well as a global index that defines its position in the text. Each edge defines a relation from a premise (the child node) to a conclusion (the parent node). Each main claim defines the root of a tree.\nFigure 1(b) has already illustrated an instance of the general model. The general model is slightly less expressive than the specific models. We evaluate in Section 6 to what extent this reduces its use for tackling argumentation-related analysis tasks. The advantage of the general model is that it allows a comparison of patterns of overall argumentation across corpora, as we do in the following.4"
  }, {
    "heading": "4.2 Visualization of Argumentation Patterns",
    "text": "Based on the general model, we empirically analyze class-specific patterns of overall argumentation on the three corpora. To this end, we compute one “average graph” for all texts in each complete corpus and one such graph for all texts with a particular class (e.g., for all “no myside bias” texts in case of AAE-v2). In an average graph, each node is labeled with the relative frequency of the associated combination of position and depth in all texts (edges accordingly). We align positions\n4Besides, although not in the focus here, we also assume stance to be easier to detect in practice than fine-grained roles.\nof different texts based on their start node, due to our observation that the first argument unit overproportionally often represents the main claim.5 In addition the relative frequency, we determine the proportion of con to pro stance for each node.\nAs we aim to provide intuitive insights into how people argue in overall terms, we discuss the graphs in an informal visual way instead of listing exact numbers.6 In the visualizations in Figure 2, brightness captures (inverse) frequency, so darker nodes represent more frequent argument units. The diameter of the inner light-red part of each node reflects its proportion of con stance. Nodes with a relative frequency below 0.3% and/or an absolute frequency below 3 are pruned, along with all their associated edges.\nAAE-v2 Figure 2(a) stresses that most students state the main claim (depth 0, position 1) in a persuasive essay first. When the first argument unit is a premise of the main claim instead, it often attacks the main claim, as the large light-red proportion of the node at depth 1 and position 1 conveys. While, on average, texts with myside bias do not differ in length from those without, the latter show more con stance, especially at depth 1. Also, argumenta-\n5We also considered using the main claim as the fix point, but the resulting graphs would be much wider than the longest argumentation, which may be misleading.\n6We provide files with the exact frequencies of all nodes and edges at: http://www.arguana.com/software.html\ntion without myside bias shows more variance, as indicated, for instance, by the nodes at depth 0 and position 12 and 13 respectively. In contrast, clear patterns in the sequential ordering of pro and con stance are not recognizable in AAE-v2.\nArg-Microtexts According to the graphs in Figure 2(b), the position of the main claim varies in the microtexts. While the proportion of con stance seems rather similar between pro and con texts, our visualization reveals that their overall structure is “mirror-inverted” to a limited extent: Most pro texts start with the main claim (depth 0, position 1), discuss con stance later (red proportions increase to the right), and deepen the argumentation in a topdown fashion (most edges from top left to bottom right). Vice versa, con texts more often present the main claim later, attack it earlier, and seem to argue more bottom-up. This suggests that both sequential and hierarchical structure play a role here.\nWeb Discourse The web discourse texts, finally, comprise rather shallow argumentation across all genres. Slight structural differences can be seen, especially, the comments appear a little shorter and richer of pro stance on average. Besides, the blog posts have more con stance later. Still, the darker and thus more frequent nodes are at similar positions in all graphs. So, if at all, differences may be reflected in a sequential model of argumentation, which implicitly covers length. In terms of the hierarchical structure of the frequent nodes, the graphs of all genres are rather indistinguishable.\nAltogether, the visualizations give first support for the impact of modeling overall argumentation. In particular, we hypothesize that hierarchical overall structure is decisive for myside bias, whereas a combination of sequential and hierarchical structure helps to distinguish pro-stance from con-stance texts. In contrast, we expect that the impact on classifying genres in the Web Discourse corpus is low."
  }, {
    "heading": "5 Modeling Overall Argumentation",
    "text": "This section presents our kernel-based approaches for argumentation-related analysis tasks. They rely on a tree representation of overall argumentation."
  }, {
    "heading": "5.1 Representation of Overall Argumentation",
    "text": "We model the overall structure of an argumentative text in form of a positional tree T = (V,E) that, in principle, equals those exemplified in Figure 1 and analyzed above. Each node v ∈ V represents an argument unit and each edge e = (v1, v2) ∈ E a\nrelation between two units. Technically, we therefor map the forest of trees representing a text (see Section 4) to a single tree by adding a “virtual” root node v0 to V that is the parent of all tree roots.\nIn analysis tasks, we seek to compare sequential and hierarchical structures irrespective of the actual texts and the size of the associated trees. To this end, we represent labels and positions as follows:\nLabels The tree kernel approaches in natural language processing discussed in Section 2 include text (usually words) in the leaf nodes. In contrast, we label each node v ∈ V with the type of the associated argument unit only. Thereby, we almost fully abstract from the content of texts, which benefits the identification of common structures. In case of the general model, the only two labels are pro and con. In case of the specific models, we combine the role of a unit with the type of the relation the unit is the source of (if any). On Arg-Microtexts, for instance, this creates labels such as opponent-support or opponent-undercutter.\nPositions As we adapt the route kernels of Aiolli et al. (2009) below, we follow their representation of sequential structure with one exception. In particular, the authors assigned an index to each edge that numbers the child nodes of each node ascending from 1. Thereby, they encoded the relative positions of sibling nodes to each other. To capture the ordering of argument units in a text from left to right, we also model positions as indices of the edges in E. Unlike Aiolli et al. (2009), however, we use indices decreasing from -1 in the left direction of the parent node and ascending from 1 to the right (derived from the nodes’ global indices). While such a simple relabeling allows us to reuse their algorithm for computing kernels, it makes a decisive difference, namely, it encodes the relative positions of child nodes to their parent. This in turn implies the sequential structure of the whole tree.\nFigure 3(a) exemplifies the tree representation for the argument unit types of the general model, omitting the virtual root v0 for simplicity. Analogously, the types of the specific models of the three considered corpora could be used."
  }, {
    "heading": "5.2 Kernel-based Modeling Approaches",
    "text": "Based on the tree representation, we now introduce four approaches for modeling overall argumentation. Figure 3(b) illustrates the kernel representations of each approach. As discussed in Section 2,\nthe associated kernel function compares the representations of the trees T, T ′ of any two texts.\nLabel Frequencies (a1) Our simplest model of overall argumentation does not encode structure at all. Instead, it compares only the frequencies of each node label in T and T ′. We represent the model with a linear kernel, which in the end corresponds to a standard feature representation.\nLabel Sequences (a2) To encode sequential overall structure, we refer to the kernel of Mooney and Bunescu (2006), representing the sequential ordering of node labels in a tree by all contiguous subsequences. The similarity of two trees T and T ′ follows from the proportion of common subsequences, but longer subsequences are penalized by a decay factor. This approach can be seen as an imitation of our flow model (Wachsmuth and Stein, 2017).7\nLabel Tree Paths (a3) We capture hierarchical overall structure adapting the non-positional part of the route kernel of Aiolli et al. (2009), label paths.\n7We use a sequence kernel instead of flows in order to obtain a uniform setting. In Wachsmuth and Stein (2017), we also analyze flow abstractions (e.g., collapsing sequences of the same label). Here, we resort only to the original sequence.\nA label path ξ(vi, vj) denotes the sequence of labels of the nodes in the shortest path between vi, vj in a tree (including vi, vj). Following Aiolli et al. (2009), we consider only label paths starting at the root vi = v0, abbreviated here as ξ(vj). Implicitly, other paths may still be considered through the use of polynomial kernels with degree d > 1. As the authors, we compare any two paths with a function δ whose values is 1 when the paths are identical and 0 otherwise. Given two trees T = (V,E) and T ′ = (V ′, E′), we then define a normalized polynomial kernel Kξ(T, T ′) over all label paths as:(∑\nv∈V ∑ v′∈V ′ δ(ξ(v), ξ(v′)) |V | · |V ′| )d Positional Tree Paths (a4) In addition to label paths, Aiolli et al. (2009) define a route π(vi, vj) as the sequence of edge indices on the shortest path between any two nodes vi, vj in a tree, i.e., the sequence of local positions. As above, they restrict their view to routes starting at the root, which we denote as π(vj), and compare them using δ. To combine positional information with label information, the authors build the product of a kernel based on the label paths and a kernel based on routes. As a result, sequential and hierarchical overall structure are compared at the same time. For overall argumentation, we define the resulting normalized polynomial product kernel Kξπ(T, T ′) as:(∑\nv∈V ∑ v′∈V ′ δ(ξ(v), ξ(v′)) · δ(π(v), π(v′)) (|V | · |V ′|)2 )d Each approach, a1–a4, can be seen as representing one particular step of modeling overall argumentation; a4 combines the complementary steps of a2 and a3, both of which implicitly include a1."
  }, {
    "heading": "6 Evaluation",
    "text": "Finally, we evaluate all four approaches to model overall argumentation from Section 5 on the three tasks associated to the corpora from Section 3.8"
  }, {
    "heading": "6.1 Experimental Set-up",
    "text": "Our goal is to assess the theoretical impact of each introduced step of modeling overall argumentation as far as possible. To this end, we conduct a systematic experiment where we use the ground-truth argument structure in each corpus for the associated downstream task based on the following set-up:\n8The Java source code for reproducing the experiment results is available at: http://www.arguana.com/software.html\nApproaches The modeling steps are reflected by the approaches a1–a4 from Section 5. For each task, we measure the accuracy of all four approaches. We do this once for our general model of overall argumentation from Section 4 and once for the specific model annotated in the respective corpus, in order to assess the loss of resorting to our always applicable general model.\nBaselines As a basic task-intrinsic measure, we compare a1–a4 to the majority baseline that always predicts the majority class in the given corpus. In addition, we employ two standard feature types and combine them with a1–a4, in order to roughly assess the need for modeling argumentation:\nb1 POS n-grams. The frequency of each partof-speech 1- to 3-gram found in ≥ 5% of all texts. This style feature has been effective in argumentation-related analysis tasks (Persing and Ng, 2015; Wachsmuth et al., 2016).\nb2 Token n-grams. The frequency of each token 1- to 3-gram found in ≥ 5% of all texts. This content feature is strong in many text analysis tasks (Joachims, 1998; Pang et al., 2002).\nFrom the tackled tasks, only myside bias has been approached on the given datasets in previous work. While we mention the respective results for completeness below, a comparison is in fact unfair due to our resort to ground-truth argument structure.\nExperiments The evaluation of all approaches and baselines was done using the kernel-based machine learning platform KeLP (Filice et al., 2015), performing classification with the available implementation of LibSVM (Chang and Lin, 2011). As\nwe target the theoretically possible impact of modeling overall argumentation, we tested a number of hyperparameter configurations.9 We performed 10-fold cross-validation on the complete corpora and repeated each experiment 10 times, with instance shuffling in between. Then, we averaged the accuracy of each configuration over all folds and repetitions. To prevent the classifiers from using knowledge about the class distributions, we used fairness during training, i.e., each class was given an equal weight (Filice et al., 2014). Thus, the majority baseline is not a trivial competitor."
  }, {
    "heading": "6.2 Results",
    "text": "Table 2 presents the best obtained results of each evaluated approach for each task/corpus combination. To clarify the reliability of the differences between the results, the table includes the confidence level (starting at 95%) at which each approach is significantly better than all weaker approaches according to a two-tailed paired student’s t-test.10\nMyside Bias on AAE-v2 The highest accuracy reported for classifying myside bias is 77.0 (Stab and Gurevych, 2016). While the comparability is limited (see above), we see that label frequencies (a1) already achieve 83.4 and 85.7 for the general and specific model respectively, outperforming all baselines with 99.9% confidence. Matching the insights from Section 4, the sole proportion of attacks thus seems a good predictor of myside bias.\n9SVM C parameter: 0.01, 0.1, 1, 10, 100; sequence kernel decay factor: 0, 0.5, 1; polynomial tree kernel degree: 1, 2, 3.\n10While selecting the best result a posteriori gives an upper bound on the true effectiveness, we do this to assess to what extent each approach captures task-relevant information.\nLabel sequences (a2) further improve over a1, which underlines that also the sequential position of con stance and attack relations has an impact. a2 is particular strong under the specific model (94.7). Unlike the general model, this model reflects some hierarchical information via the roles of argument units, such as premise. a2 performs only slightly worse than the label tree paths (a3), indicating that an adequate sequential model can compete with a hierarchical model, as we hypothesized in previous work (Wachsmuth and Stein, 2017).\nNevertheless, a3 turns out best on AAE-v2, most likely due to its capability to capture the depth at which con stance occurs. Considering that no corpus annotation is perfect, the outstanding accuracy of 97.1 conveys an important finding: Modeling the tree structure of an argumentation basically solves the myside bias task without requiring other features. Neither the positional tree paths (a4) nor the combination with token n-grams (ba) can add to that. Also, there is no difference between the general and the specific model, underlining that the unit roles in AAE-v2 are implicitly covered by the hierarchical structure in the general model.\nStance on Arg-Microtexts The accuracy results for the given challenging variant of stance classification (see Section 3) are much lower. Under the general model, the label frequencies (49.7) do not even compete with the majority baseline (52.3). Notable gains are achieved by the label sequences under the specific model (62.3), slightly beating the label tree paths (61.9). Putting them together in the positional tree paths (a4) yields an accuracy of 66.7 and 67.8 respectively; more than the token n-grams (b2, 65.2). Combining a4 and b2 in ba in turn results in the best observed accuracy value (71.0 on the specific model).\nWe conclude that both sequential and hierarchical overall structure are important for the distinction of pro from con argumentation, supporting our hypothesis from Section 4. They complement content-oriented approaches, such as b2. Moreover, the fine-grained unit and relation types of the specific model annotated in Arg-Microtexts seem useful, consistently obtaining higher accuracy than the general model. Notice, though, that due to the small size of the corpus, only few reported gains are statistically significant, as shown in Table 2.\nGenre on Web Discourse Although Section 4 has made minor structural differences in Web Discourse visible, Table 2 shows that a1–a4 all fail in\ngenre classification: None of them beats the majority baseline (64.5), suggesting that no decisive discriminative patterns are learned. Both POS and token n-grams (b1–b2) significantly outperform a1– a4 at 99.9% confidence. While combining b2 with a2 (ba) minimally increases accuracy from 75.6 to 75.9, the results reveal that overall argumentation hardly impacts genre — as hypothesized."
  }, {
    "heading": "7 Conclusion",
    "text": "This paper provides answers to the question of how the overall structure of a monological argumentative text should be modeled in order to tackle downstream tasks of computational argumentation. We have adopted the idea of including positional information in tree kernels in order to capture the explicit sequential and the implicit hierarchical overall structure of the text at the same time. In systematic experiments, we have demonstrated the strong impact of modeling overall argumentation. Most impressively, we have found that hierarchical structure decides about myside bias alone, while the combination of sequential and hierarchical structure has turned out beneficial for classifying stance. The missing impact on genre supports that the presented approaches actually capture argumentationrelated properties of a text.\nSo far, however, we have restricted our view to ground-truth argument structure, leaving the integration of computational argument mining approaches to future work. While the noise from mining errors might qualify some of our findings, we also expect that larger corpora will allow us to discover more reliable and discriminative patterns. After all, our results underline the general importance of modeling overall argumentation."
  }],
  "year": 2017,
  "references": [{
    "title": "Route kernels for trees",
    "authors": ["Fabio Aiolli", "Giovanni Da San Martino", "Alessandro Sperduti."],
    "venue": "Proceedings of the 26th Annual International Conference on Machine Learning, pages 17–24.",
    "year": 2009
  }, {
    "title": "Extending tree kernels with topological information",
    "authors": ["Fabio Aiolli", "Giovanni Da San Martino", "Alessandro Sperduti."],
    "venue": "Proceedings of the 21th International Conference on Artificial Neural Networks - Volume Part I, pages 142–149.",
    "year": 2011
  }, {
    "title": "An efficient topological distance-based tree kernel",
    "authors": ["Fabio Aiolli", "Giovanni Da San Martino", "Alessandro Sperduti."],
    "venue": "IEEE Transactions on Neural Networks and Learning Systems, 26(5):1115–1120.",
    "year": 2015
  }, {
    "title": "A news editorial corpus for mining argumentation strategies",
    "authors": ["Khalid Al Khatib", "Henning Wachsmuth", "Johannes Kiesel", "Matthias Hagen", "Benno Stein."],
    "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational",
    "year": 2016
  }, {
    "title": "On Rhetoric: A Theory of Civic Discourse (George A",
    "authors": ["Aristotle."],
    "venue": "Kennedy, translator). Clarendon Aristotle series. Oxford University Press.",
    "year": 2007
  }, {
    "title": "Argumentation: Content, structure, and relationship with essay quality",
    "authors": ["Beata Beigman Klebanov", "Christian Stab", "Jill Burstein", "Yi Song", "Binod Gyawali", "Iryna Gurevych."],
    "venue": "Proceedings of the Third Workshop on Argument Mining (ArgMining2016),",
    "year": 2016
  }, {
    "title": "Predicting outcomes of case based legal arguments",
    "authors": ["Stefanie Brüninghaus", "Kevin D. Ashley."],
    "venue": "Proceedings of the 9th International Conference on Artificial Intelligence and Law, pages 233–242.",
    "year": 2003
  }, {
    "title": "LIBSVM: A library for support vector machines",
    "authors": ["Chih-Chung Chang", "Chih-Jen Lin."],
    "venue": "ACM Transactions on Intelligent Systems and Technology, 2(3):27:1–27:27.",
    "year": 2011
  }, {
    "title": "Convolution kernels for natural language",
    "authors": ["Michael Collins", "Nigel Duffy."],
    "venue": "Advances in Neural Information Processing Systems 14, pages 625–632. MIT Press.",
    "year": 2001
  }, {
    "title": "An Introduction to Support Vector Machines and Other Kernel-based Learning Methods, 1st edition",
    "authors": ["Nello Cristianini", "John Shawe-Taylor."],
    "venue": "Cambridge University Press, New York, NY, USA.",
    "year": 2000
  }, {
    "title": "A treeposition kernel for document compression",
    "authors": ["Hal Daumé III", "Daniel Marcu."],
    "venue": "Proceedings of the Fourth Document Understanding Conference.",
    "year": 2004
  }, {
    "title": "A Systematic Theory of Argumentation: The PragmaDialectical Approach",
    "authors": ["Frans H. van Eemeren", "Rob Grootendorst."],
    "venue": "Cambridge University Press, Cambridge, UK.",
    "year": 2004
  }, {
    "title": "Automated Classification of Argument Stance in Student Essays: A Linguistically Motivated Approach with an Application for Supporting Argument Summarization",
    "authors": ["Adam Robert Faulkner."],
    "venue": "Dissertation, City University of New York.",
    "year": 2014
  }, {
    "title": "Classifying arguments by scheme",
    "authors": ["Vanessa Wei Feng", "Graeme Hirst."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 987–996. Association for Computational",
    "year": 2011
  }, {
    "title": "The impact of deep hierarchical discourse",
    "authors": ["Vanessa Wei Feng", "Ziheng Lin", "Graeme Hirst"],
    "year": 2014
  }, {
    "title": "Effective kernelized online learning in language processing tasks",
    "authors": ["Simone Filice", "Giuseppe Castellucci", "Danilo Croce", "Roberto Basili."],
    "venue": "Proceedings of the 36th European Conference on IR Research on Advances in Information Retrieval - Vol-",
    "year": 2014
  }, {
    "title": "KeLP: A kernel-based learning platform for natural language processing",
    "authors": ["Simone Filice", "Giuseppe Castellucci", "Danilo Croce", "Roberto Basili."],
    "venue": "Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 19–24. Association for Com-",
    "year": 2015
  }, {
    "title": "Argument Structure: Representation and Theory",
    "authors": ["James B. Freeman."],
    "venue": "Springer.",
    "year": 2011
  }, {
    "title": "Deep Learning",
    "authors": ["Ian Goodfellow", "Yoshua Bengio", "Aaron Courville."],
    "venue": "MIT Press.",
    "year": 2016
  }, {
    "title": "Exploiting debate portals for semi-supervised argumentation mining in user-generated web discourse",
    "authors": ["Ivan Habernal", "Iryna Gurevych."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2127–",
    "year": 2015
  }, {
    "title": "Text categorization with suport vector machines: Learning with many relevant features",
    "authors": ["Thorsten Joachims."],
    "venue": "Proceedings of the 10th European Conference on Machine Learning, pages 137–142.",
    "year": 1998
  }, {
    "title": "Fast computation of subpath kernel for trees",
    "authors": ["Daisuke Kimura", "Hisashi Kashima."],
    "venue": "Proceedings of the 29th International Conference on Machine Learning.",
    "year": 2012
  }, {
    "title": "Rhetorical structure theory: Toward a functional theory of text organization",
    "authors": ["William C. Mann", "Sandra A. Thompson."],
    "venue": "Text, 8(3):243–281.",
    "year": 1988
  }, {
    "title": "Argumentation mining",
    "authors": ["Raquel Mochales", "Marie-Francine Moens."],
    "venue": "Artificial Intelligence and Law, 19(1):1–22.",
    "year": 2011
  }, {
    "title": "Subsequence kernels for relation extraction",
    "authors": ["Raymond J. Mooney", "Razvan C. Bunescu."],
    "venue": "Advances in Neural Information Processing Systems 18, pages 171–178. MIT Press.",
    "year": 2006
  }, {
    "title": "Efficient convolution kernels for dependency and constituent syntactic trees",
    "authors": ["Alessandro Moschitti."],
    "venue": "Proceedings of the 17th European Conference on Machine Learning, pages 318–329.",
    "year": 2006
  }, {
    "title": "Making tree kernels practical for natural language learning",
    "authors": ["Alessandro Moschitti."],
    "venue": "11th Conference of the European Chapter of the Association for Computational Linguistics.",
    "year": 2006
  }, {
    "title": "Ontology-based argument mining and automatic essay scoring",
    "authors": ["Nathan Ong", "Diane Litman", "Alexandra Brusilovsky."],
    "venue": "Proceedings of the First Workshop on Argumentation Mining, pages 24–28. Association for Computational Linguistics.",
    "year": 2014
  }, {
    "title": "Thumbs up? Sentiment classification using machine learning techniques",
    "authors": ["Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan."],
    "venue": "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002).",
    "year": 2002
  }, {
    "title": "An annotated corpus of argumentative microtexts",
    "authors": ["Andreas Peldszus", "Manfred Stede."],
    "venue": "Argumentation and Reasoned Action: 1st European Conference on Argumentation. College Publications.",
    "year": 2016
  }, {
    "title": "Modeling organization in student essays",
    "authors": ["Isaac Persing", "Alan Davis", "Vincent Ng."],
    "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 229–239. Association for Computational Linguistics.",
    "year": 2010
  }, {
    "title": "Modeling argument strength in student essays",
    "authors": ["Isaac Persing", "Vincent Ng."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing",
    "year": 2015
  }, {
    "title": "Araucaria: Software for argument analysis, diagramming and representation",
    "authors": ["Chris Reed", "Glenn Rowe."],
    "venue": "International Journal of AI Tools, 14:961– 980.",
    "year": 2004
  }, {
    "title": "Show me your evidence — An automatic method for context dependent evidence detection",
    "authors": ["Ruty Rinott", "Lena Dankin", "Carlos Alzate Perez", "M. Mitesh Khapra", "Ehud Aharoni", "Noam Slonim."],
    "venue": "Proceedings of the 2015 Conference on",
    "year": 2015
  }, {
    "title": "Applying kernel methods to argumentation mining",
    "authors": ["Niall Rooney", "Hui Wang", "Fiona Browne."],
    "venue": "Proceedings of the 25th International FLAIRS Conference, pages 272–275.",
    "year": 2012
  }, {
    "title": "From argumentation mining to stance classification",
    "authors": ["Parinaz Sobhani", "Diana Inkpen", "Stan Matwin."],
    "venue": "Proceedings of the 2nd Workshop on Argumentation Mining, pages 67–77. Association for Computational Linguistics.",
    "year": 2015
  }, {
    "title": "Annotating argument components and relations in persuasive essays",
    "authors": ["Christian Stab", "Iryna Gurevych."],
    "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1501–1510. Dublin",
    "year": 2014
  }, {
    "title": "Recognizing the absence of opposing arguments in persuasive essays",
    "authors": ["Christian Stab", "Iryna Gurevych."],
    "venue": "Proceedings of the Third Workshop on Argument Mining (ArgMining2016), pages 113–118. Association for Computational Linguistics.",
    "year": 2016
  }, {
    "title": "Towards assessing depth of argumentation",
    "authors": ["Manfred Stede."],
    "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 3308–3317. The COLING 2016 Organizing Committee.",
    "year": 2016
  }, {
    "title": "The Uses of Argument",
    "authors": ["Stephen E. Toulmin."],
    "venue": "Cambridge University Press.",
    "year": 1958
  }, {
    "title": "Using argument mining to assess the argumentation quality of essays",
    "authors": ["Henning Wachsmuth", "Khalid Al Khatib", "Benno Stein."],
    "venue": "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Pa-",
    "year": 2016
  }, {
    "title": "Computational argumentation quality assessment in natural language",
    "authors": ["Henning Wachsmuth", "Nona Naderi", "Yufang Hou", "Yonatan Bilu", "Vinodkumar Prabhakaran", "Alberdingk Tim Thijm", "Graeme Hirst", "Benno Stein."],
    "venue": "Proceedings of the 15th",
    "year": 2017
  }, {
    "title": "A universal model for discourse-level argumentation analysis",
    "authors": ["Henning Wachsmuth", "Benno Stein."],
    "venue": "Special Section of the ACM Transactions on Internet Technology: Argumentation in Social Media, 17(3):28:1–28:24.",
    "year": 2017
  }, {
    "title": "Modeling review argumentation for robust sentiment analysis",
    "authors": ["Henning Wachsmuth", "Martin Trenkmann", "Benno Stein", "Gregor Engels."],
    "venue": "Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Pa-",
    "year": 2014
  }, {
    "title": "A review corpus for argumentation analysis",
    "authors": ["Henning Wachsmuth", "Martin Trenkmann", "Benno Stein", "Gregor Engels", "Tsvetomira Palakarska."],
    "venue": "Proceedings of the 15th International Conference on Intelligent Text Processing and Computational Lin-",
    "year": 2014
  }, {
    "title": "A corpus for research on deliberation and debate",
    "authors": ["Marilyn Walker", "Jean Fox Tree", "Pranav Anand", "Rob Abbott", "Joseph King."],
    "venue": "Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC-2012), pages 812–",
    "year": 2012
  }, {
    "title": "Argumentation Schemes",
    "authors": ["Douglas Walton", "Christopher Reed", "Fabrizio Macagno."],
    "venue": "Cambridge University Press. 2389",
    "year": 2008
  }],
  "id": "SP:1b8ebdfad7eb714156aeb1ac26e9bf0aa6088929",
  "authors": [{
    "name": "Henning Wachsmuth",
    "affiliations": []
  }, {
    "name": "Giovanni Da San Martino",
    "affiliations": []
  }, {
    "name": "Dora Kiesel",
    "affiliations": []
  }, {
    "name": "Benno Stein",
    "affiliations": []
  }],
  "abstractText": "Several approaches have been proposed to model either the explicit sequential structure of an argumentative text or its implicit hierarchical structure. So far, the adequacy of these models of overall argumentation remains unclear. This paper asks what type of structure is actually important to tackle downstream tasks in computational argumentation. We analyze patterns in the overall argumentation of texts from three corpora. Then, we adapt the idea of positional tree kernels in order to capture sequential and hierarchical argumentative structure together for the first time. In systematic experiments for three text classification tasks, we find strong evidence for the impact of both types of structure. Our results suggest that either of them is necessary while their combination may be beneficial.",
  "title": "The Impact of Modeling Overall Argumentation with Tree Kernels"
}