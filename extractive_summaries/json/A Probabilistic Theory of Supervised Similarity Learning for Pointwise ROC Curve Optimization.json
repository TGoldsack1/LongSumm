{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Similarity (or distance) functions play a key role in many machine learning algorithms for problems ranging from classification (e.g., k-nearest neighbors) and clustering (e.g., k-means) to dimensionality reduction (van der Maaten & Hinton, 2008) and ranking (Chechik et al., 2010). The success of such methods are heavily dependent on the relevance\n1Télécom ParisTech, Paris, France 2IDEMIA, Colombes, France 3INRIA, France. Correspondence to: Robin Vogel <robin.vogel@telecom-paristech.fr>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nof the similarity function to the task and dataset of interest. This has motivated the research in similarity and distance metric learning (Bellet et al., 2015), a line of work which consists in automatically learning a similarity function from data. This training data often comes in the form of pairwise similarity judgments derived from labels, such as positive (resp. negative) pairs composed of two instances with same (resp. different) label. Most existing algorithms can then be framed as unconstrained optimization problems where the objective is to minimize some average loss function over the set of similarity judgments (see for instance Goldberger et al., 2004; Weinberger & Saul, 2009; Bellet et al., 2012, for methods tailored to classification). Some generalization bounds for this class of methods have been derived, accounting for the specific dependence structure found in the training similarity judgments (Jin et al., 2009; Bellet & Habrard, 2015; Cao et al., 2016; Jain et al., 2017; Verma & Branson, 2015). We refer to Kulis (2012) and Bellet et al. (2015) for detailed surveys on similarity and metric learning.\nIn this paper, we study similarity learning from the perspective of pairwise bipartite ranking, where the goal is to rank the elements of a database by decreasing order of the probability that they share the same label with some query data point. This problem is motivated by many concrete applications: for instance, biometric identification aims to check the claimed identity of an individual by matching her biometric information (e.g., a photo taken at an airport) with a large reference database of authorized people (e.g., of passport photos) (Jain et al., 2011). Given a similarity function and a threshold, the database elements are ranked in decreasing order of similarity score with the query, and the matching elements are those whose score is above the threshold. In this context, performance criteria are related to the ROC curve associated with the similarity function, i.e., the relation between the false positive rate and the true positive rate. Previous approaches have empirically tried to optimize the Area under the ROC curve (AUC) of the similarity function (McFee & Lanckriet, 2010; Huo et al., 2018), without establishing any generalization guarantees. The AUC is a global summary of the ROC curve which penalizes pairwise ranking errors regardless of the positions in the list. More local versions of the AUC (e.g., focusing\non the top of the list) are difficult to optimize in practice and lead to complex nonconvex formulations (Clémençon & Vayatis, 2007; Huo et al., 2018). In contrast, the performance criterion we consider in this work is pointwise ROC optimization, which aims at maximizing the true positive rate under a fixed false positive rate. This objective, formulated as a constrained optimization problem, naturally expresses the operational constraints present in many practical scenarios. For instance, in biometric applications such as the one outlined above, the verification system is typically set to keep the proportion of people falsely considered a match below a predefined acceptable threshold (see e.g., Jain et al., 2000; 2004).\nIn addition to proposing an appropriate probabilistic framework to study this novel perspective on similarity learning, we make the following key contributions:\nUniversal and fast learning rates. We derive statistical guarantees for the approach of solving the constrained optimization problem corresponding to the empirical version of our theoretical objective, based on a dataset of n labeled data points. As the empirical quantities involved are not i.i.d. averages but rather in the form of Ustatistics (Lee, 1990), our results rely on concentration bounds developed for U -processes (Clémençon et al., 2008). We first derive a learning rate of order O(1/ √ n) which holds without any assumption on the data distribution. We then show that one can obtain faster rates under a low-noise assumption on the data distribution, which has the form of a margin criterion involving the conditional quantile. We are unaware of previous results of this kind for constrained similarity/distance metric learning. Interestingly, we are able to illustrate the faster rates empirically through numerical simulations, which is rarely found in the literature on fast learning rates.\nScalability by sampling. We address scalability issues that arise from the very large number of negative pairs when the dataset and the number of classes are large. In particular, we show that using an approximation of the pairwise negative risk consisting of O(n) randomly sampled terms, known as an incomplete U -statistic (see Blom, 1976; Lee, 1990), is sufficient to maintain the universal learning rate of O(1/ √ n). We analyze two different choices of sampling strategies and discuss properties of the data distribution which can make one more accurate than the other. We further provide numerical experiments to illustrate the practical benefits of this strategy.\nThe rest of this paper is organized as follows. Section 2 introduces the proposed probabilistic framework for similarity learning and draws connections to existing approaches. In Section 3, we derive universal and fast learning rates for the minimizer of the empirical version of our problem. Section 4 addresses scalability issues through random sampling, and Section 5 presents some numerical experiments.\nDetailed proofs can be found in the supplementary material."
  }, {
    "heading": "2. Background and Preliminaries",
    "text": "In this section, we introduce the main notations and concepts involved in the subsequent analysis. We formulate the supervised similarity learning problem from the perspective of pairwise bipartite ranking, and highlight connections with some popular metric and similarity learning algorithms of the literature. Here and throughout, the indicator function of any event E is denoted by I{E}, the Dirac mass at any point x by δx, and the pseudo-inverse of any cdf F (u) on R by F−1(t) = inf{v ∈ R : F (v) ≥ t}."
  }, {
    "heading": "2.1. Probabilistic Framework for Similarity Learning",
    "text": "We consider the (multi-class) classification setting. The random variable Y denotes the output label with values in the discrete set {1, . . . , K}withK ≥ 1, andX is the input random variable, taking its values in a feature spaceX ⊂ Rd with d ≥ 1 and modeling some information hopefully useful to predict Y . We denote by µ(dx) the marginal distribution of X and by η(x) = (η1(x), . . . , ηK(x)) the posterior probability, where ηk(x) = P{Y = k | X = x} for x ∈ X and k ∈ {1, . . . , K}. The distribution of the random pair (X,Y ) is entirely characterized by P = (µ, η). The probability of occurrence of an observation with label k ∈ {1, . . . , K} is assumed to be strictly positive and denoted by pk = P{Y = k}, and the conditional distribution of X given Y = k is denoted by µk(dx). Equipped with these notations, we have µ = ∑K k=1 pkµk.\nOptimal similarity measures. The objective of similarity learning can be informally formulated as follows: the goal is to learn, from a training sample Dn = {(X1, Y1), . . . , (Xn, Yn)} composed of n ≥ 1 independent copies of (X,Y ), a (measurable) similarity measure S : X × X → R+ such that given two independent pairs (X,Y ) and (X ′, Y ′) drawn from P , the larger the similarity S(X,X ′) between two observations, the more likely they are to share the same label. The set of all similarity measures is denoted by S. The class S∗ of optimal similarity rules naturally corresponds to the set of strictly increasing transforms T of the pairwise posterior probability η(x, x′) = P{Y = Y ′ | (X,X ′) = (x, x′)}, where (X ′, Y ′) denotes an independent copy of (X,Y ):\n{T ◦ η |T : Im(η)→ R+ borelian, strictly increasing}, and where Im(η) denotes the support of η(X,X ′)’s distribution. With the notations previously introduced, we have η(x, x′) = ∑K k=1 ηk(x)ηk(x\n′) for all (x, x′) ∈ X 2. A similarity rule S∗ ∈ S∗ defines the optimal preorder1 ∗ on\n1A preorder on a set X is any reflexive and transitive binary relationship on X . A preorder is an order if, in addition, it is\nthe product space X × X : for any (x1, x2, x3, x4) ∈ X 4, x1 and x2 are more similar to each other than x3 and x4 iff η(x1, x2) ≥ η(x3, x4), and one writes (x3, x4) ∗ (x1, x2) in this case. For any x ∈ X , S∗ also defines a preorder ∗x on the input space X , permitting to rank optimally all possible observations by increasing degree of similarity to x: for all (x1, x2) ∈ X 2, x1 is more similar to x than x2 (one writes x2 ∗x x1) iff (x, x2) ∗ (x, x1), meaning that η(x, x2) ≤ η(x, x1). We point out that, despite its simplicity, this framework covers a wide variety of applications, such as the biometric identification problem mentioned earlier in the introduction.\nSimilarity learning as pairwise bipartite ranking. In view of the objective formulated above, similarity learning can be seen as a bipartite ranking problem on the product space X × X where, given two independent realizations (X,Y ) and (X ′, Y ′) of P , the input r.v. is the pair (X,X ′) and the binary label is Z = 2I{Y = Y ′} − 1. One may refer to e.g. Clémençon & Vayatis (2009) and the references therein for a statistical learning view of bipartite ranking. ROC analysis is the gold standard to evaluate the performance of a similarity measure S in this context, i.e. to measure how close the preorder induced by S is to ∗. The ROC curve of S is the PP-plot t ∈ R+ 7→ (FS,−(t), FS,+(t)), where, for all t ≥ 0,\nFS,−(t) = P{S(X,X ′) > t | Z = −1}, FS,+(t) = P{S(X,X ′) > t | Z = +1},\nwhere possible jumps are connected by line segments. Hence, it can be viewed as the graph of a continuous function α ∈ (0, 1) 7→ ROCS(α), where ROCS(α) = FS,+ ◦ F−1S,−(α) at any point α ∈ (0, 1) such that FS,−◦F−1S,−(α) = α. The curve ROCS reflects the ability of S to discriminate between pairs with same labels and pairs with different labels: the stochastically smaller than FS,− the distribution FS,+ is, the higher the associated ROC curve. Note that it corresponds to the type I error vs power plot of the statistical test I{S(X,X ′) > t} when the null hypothesis stipulates that X and X ′ have different marginal distribution (i.e., Y 6= Y ′). A similarity measure S1 is said to be more accurate than another similarity S2 when ROCS2(α) ≤ ROCS1(α) for any α ∈ (0, 1). A straightforward Neyman-Pearson argument shows that S∗ is the set of optimal elements regarding this partial order on S: ∀(S, S∗) ∈ S×S∗, ROCS(α) ≤ ROCS∗(α) = ROCη(α) for all α ∈ (0, 1). For simplicity, we will assume that the conditional cdf of η(X,X ′) given Z = −1 is invertible.\nPointwise ROC optimization. In many applications, one is interested in finding a similarity function which optimizes the ROC curve at a particular point α ∈ (0, 1). The superantisymmetrical.\nlevel sets of similarity functions in S∗ define the solutions of pointwise ROC optimization problems in this context. In the above framework, it indeed follows from Neyman Pearson’s lemma that the test statistic of type I error less than α with maximum power is the indicator function of the set R∗α = {(x, x′) ∈ X 2 : η(x, x′) ≥ Q∗α}, where Q∗α is the conditional quantile of the r.v. η(X,X ′) given Z = −1 at level 1− α. Restricting our attention to similarity functions bounded by 1, this corresponds to the unique solution of the following problem:\nmax S:X 2→[0,1], borelian\nR+(S) subject to R−(S) ≤ α, (1)\nwhere R+(S) = E[S(X,X ′) | Z = +1] is referred to as positive risk and R−(S) = E[S(X,X ′) | Z = −1] as the negative risk.\nRemark 1. (UNCONSTRAINED FORMULATION) The superlevel setR∗α of the pairwise posterior probability η(x, x′) is the measurable subset R of X 2 that minimizes the costsensitive classification risk:\np(1−Q∗α)P {(X,X ′) /∈ R | Z = +1}+ (1− p)Q∗αP {(X,X ′) ∈ R | Z = −1} ,\nwhere p = P{Z = +1} = ∑Kk=1 p2k. Notice however that the asymmetry factor, namely the quantile Q∗α, is unknown in practice, just like the r.v. η(X,X ′). For this reason, one typically considers the problem of maximizing\nR+(S)− λR−(S), (2)\nfor different values of the constant λ > 0. The performance in terms of ROC curve can only be analyzed a posteriori, and the value λ thus needs to be tuned empirically by model selection techniques."
  }, {
    "heading": "2.2. Connections to Existing Similarity and Metric Learning Approaches",
    "text": "We point out that the similarity learning framework described above can be equivalently described in terms of learning a dissimilarity measure (or pseudo distance metric) D : X × X → R+. In this case, the pointwise ROC optimization problem (1) translates into:\nmin D:X 2→[0,1]\nE [D(X,X ′) | Z = +1]\nsubject to E [D(X,X ′) | Z = −1] ≥ 1− α. (3)\nA large variety of practical similarity and distance metric learning algorithms have been proposed in the literature, all revolving around the same idea that a good similarity function should output large scores for pairs of points in the same class, and small scores for pairs with different label. They\ndiffer from one another by the class of metric/similarity functions considered, and by the kind of objective function they optimize (see Bellet et al., 2015, for a comprehensive review). In any case, ROC curves are commonly used to evaluate metric learning algorithms when the number of classes is large (see for instance Guillaumin et al., 2009; Kstinger et al., 2012; Shen et al., 2012), which makes our framework very relevant in practice. Several popular algorithms optimize an empirical version of Problems (1)-(3), often in their unconstrained version as in (2) (Liu et al., 2010; Xie & Xing, 2015). We argue here in favor of the constrained version as the parameter α has a direct correspondence with the point ROCS(α) of the ROC curve, unlike the unconstrained case (see Remark 1). This will be illustrated in our numerical experiments of Section 5.\nInterestingly, our framework sheds light on MMC, the seminal metric learning algorithm of Xing et al. (2002) originally designed for clustering with side information. MMC solves the empirical version of (3) with α fixed to 0. This is because MMC optimizes over a class of distance functions with unbounded values, hence modifying α does not change the solution (up to a scaling factor). We note that by choosing a bounded family of distance functions, one can use the same formulation to optimize the pointwise ROC curve."
  }, {
    "heading": "3. Statistical Guarantees for Generalization",
    "text": "Pointwise ROC optimization problems have been investigated from a statistical learning perspective by Scott & Nowak (2005) and Clémençon & Vayatis (2010) in the context of binary classification. The major difference with the present framework lies in the pairwise nature of the quantities appearing in Problem (1) and, consequently, in the complexity of its empirical version. In particular, natural statistical estimates for the positive risk R+(S) and the negative risk R−(S) (1) computed on the training sample Dn = {(X1, Y1), . . . , (Xn, Yn)} are given by:\nR̂+n (S) = 1\nn+ ∑ 1≤i<j≤n S(Xi, Xj) · I{Yi = Yj}, (4)\nR̂−n (S) = 1\nn− ∑ 1≤i<j≤n S(Xi, Xj) · I{Yi 6= Yj}, (5)\nwhere n+ = ∑\n1≤i<j≤n I{Yi = Yj} = n(n − 1)/2 − n−. It is important to note that these quantities are not i.i.d. averages, since several pairs involve each i.i.d. sample. This breaks the analysis carried out by Clémençon & Vayatis (2010, Section 5 therein) for the case of binary classification.\nWe can however observe that U+n (S) = 2n+/(n(n − 1))R̂+n (S) and U − n (S) = 2n−/(n(n − 1))R̂−n (S) are U - statistics of degree two with respective symmetric kernels h+((x, y), (x′, y′)) = S(x, x′) · I{y = y′} and\nh−((x, y), (x ′, y′)) = S(x, x′) · I{y 6= y′}.2 We will therefore be able to use existing representation tricks to derive concentration bounds for U -processes (collections of U -statistics indexed by classes of kernel functions), under appropriate complexity conditions, see e.g. (Dudley, 1999).\nWe thus investigate the generalization ability of solutions obtained by solving the empirical version of Problem (1), where we also restrict the domain to a subset S0 ⊂ S of similarity functions bounded by 1, and we assume S0 has controlled complexity (e.g. finite VC dimension). Finally, we replace the target level α by α + Φ, where Φ is some tolerance parameter that should be of the same order as the maximal deviation supS∈S0 |R̂−n (S)−R−(S)|. This leads to the following empirical problem:\nmax S∈S0\nR̂+n (S) subject to R̂ − n (S) ≤ α+ Φ. (6)\nFollowing Clémençon et al. (2008), we have the following lemma.\nLemma 1. (Clémençon et al., 2008, Corollary 3) Assume that S0 is a VC-major class of functions with finite VC dimension V < +∞. We have with probability larger than 1− δ: ∀n > 1,\nsup S∈S0 ∣∣∣Û+n (S)− E[Û+n (S)]∣∣∣ ≤ 2C√Vn + 2 √ log(1/δ)\nn− 1 , (7)\nwhere C is a universal constant, explicited in Bousquet et al. (2004, page 198 therein).\nA similar result holds for the U -process {Û−n (S) − U−(S)}S∈S0 . We are now ready to state our universal learning rate, describing the generalization capacity of solutions of the constrained optimization program (6) under specific conditions for the class S0 of similarity functions and a suitable choice of the tolerance parameter Φ. This result can be established by combining Lemma 1 with the derivations of Clémençon & Vayatis (2010, Theorem 10 therein). Details can be found in the supplementary material.\nTheorem 1. Suppose that the assumptions of Lemma 1 are fulfilled and that S(x, x′) ≤ 1 for all S ∈ S0 and any (x, x′) ∈ X 2. Assume also that there exists a constant κ ∈ (0, 1) such that κ ≤ ∑k=1 p2k ≤ 1 − κ. For all δ ∈ (0, 1) and n > 1, set\nΦn,δ = 2Cκ −1 √ V\nn + 2κ−1(1 + κ−1)\n√ log(3/δ)\nn− 1 ,\nand consider a solution Ŝn of the contrained minimization problem (6) with Φ = Φn,δ/2. Then, for any δ ∈ (0, 1),\n2We give the definition of U -statistics in the supplementary material for completeness.\nwe have simultaneously with probability at least 1 − δ: ∀n ≥ 1 + 4κ−2 log(3/δ),\nR+(Ŝn) ≥ ROCS∗(α)− Φn,δ/2 − {\nROCS∗(α)− sup S∈S0: R−(S)≤α\nR+(S) } , (8)\nand R−(Ŝn) ≤ α+ Φn,δ/2. (9)\nRemark 2. (ON BIAS AND MODEL SELECTION) We point out that the last term on the right hand side of (8) should be interpreted as the bias of the statistical learning problem (6), which depends on the richness of class S0. This term vanishes when I{(x, x′) ∈ R∗α} belongs to S0. Choosing a class yielding a similarity rule of highest true positive rate with large probability can be tackled by means of classical model selection techniques, based on resampling methods or complexity penalization (note that oracle inequalities can be straightforwardly derived from the same analysis).\nExcept for the minor condition stipulating that the probability of occurrence of “positive pairs” ∑K k=1 p 2 k stays bounded away from 0 and 1, the generalization bound stated in Theorem 1 holds whatever the probability distribution of (X,Y ). Beyond such universal results, we investigate situations where rates faster than O(1/ √ n) can be achieved by solutions of (6). Such fast rates results exist for binary classification under the so-called Mammen-Tsybakov noise condition, see e.g. Bousquet et al. (2004) for details. By means of a variant of the Bernstein inequality for U -statistics, we can establish fast rate bounds under the following condition on the data distribution. Noise assumption (NA). There exist a constant c and a ∈ [0, 1] such that, almost surely,\nEX′ [ |η(X,X ′)−Q∗α| −a] ≤ c. This noise condition is similar to that introduced by Mammen & Tsybakov (1995) for the binary classification framework, except that the threshold 1/2 is replaced here by the conditional quantile Q∗α. It characterizes “nice” distributions for the problem of ROC optimization at point α: it essentially ensures that the pairwise posterior probability is bounded away from Q∗α with high probability. Under the assumption, we can derive the following fast learning rates. Theorem 2. Suppose that the assumptions of Theorem 1 are satisfied, that condition NA holds true and that the optimal similarity rule S∗α(x, x\n′) = I{(x, x′) ∈ R∗α} belongs to S0. Fix δ > 0. Then, there exists a constant C ′, depending on δ, κ, Q∗α, a, c and V such that, with probability at least 1− δ,\nROCS∗(α)−R+(Ŝn) ≤ C ′n−(2+a)/4, and R−(Ŝn) ≤ α+ 2Φn,δ/2.\nRemark 3. (ON THE NA CONDITION) The noise condition is automatically fulfilled for any a ∈ (0, 1) when, for almost every point x with respect to the measure induced by X , η(x,X ′) has an absolutely continuous distribution and bounded density. This assumption means that the problem of ranking by similarity to an instance x is not too hard for any value of x, see supplementary material for more details.\nThe proof is based on the same argument as that of Clémençon & Vayatis (2010, Theorem 12 therein), except that it involves a sharp control of the fluctuations of the U -statistic estimates of the true positive rate excess ROCS∗(α)−R+(S) over the class S0. The reduced variance property of U -statistics plays a crucial role in the analysis, which essentially relies on the Hoeffding decomposition (see Hoeffding, 1948). Technical details can be found in the supplementary material."
  }, {
    "heading": "4. Scalability by Sampling Approximations",
    "text": "In the previous section, we analyzed the learning rates achieved by a minimizer of the empirical problem (6). In the large-scale setting, solving this problem can be computationally costly due to the very large number of training pairs. In particular, the positive and negative empirical risks R̂+n (S) and R̂−n (S) are sums over respectively ∑K k=1 nk(nk−1)/2\nand ∑ k<l nknl pairs. We focus here more specifically on the setting where we have a large number of (rather balanced) classes, as in our biometric identification motivating example where a class corresponds to an identity. In this regime, we are facing a highly imbalanced problem since the number of negative pairs becomes overwhelmingly large compared to the number of positive pairs. For instance, even for the MNIST dataset where the number of classes is only K = 10 and nk = 6000, there are already 10 times more negative pairs than positive pairs.\nA natural strategy, often used by metric learning practitioners (see e.g., Babenko et al., 2009; Wu et al., 2013; Xie & Xing, 2015), is to drastically subsample the negative pairs while keeping all positive pairs. In this section, we shed light on this popular practice by analyzing the effect of subsampling (conditionally upon the data) the negative pairs onto the generalization performance.\nA simple approach consists in replacing the empirical negative risk R̂−n (S) by the following approximation:\nR̄−B(S) := 1\nB ∑ (i,j)∈PB S(Xi, Xj),\nwhere PB is a set of cardinality B built by sampling with replacement in the set of negative training pairs ΛP = {(i, j) | i, j ∈ {1, . . . , n};Yi 6= Yj}. Conditioned upon the\nnk’s, R̄−B(S) can be viewed as an incomplete version of the U -statistic R̂−n (S) consisting of B pairs (Blom, 1976; Lee, 1990).\nDespite the simplicity of the above approximation, we also consider an alternative sampling strategy, which consists in sampling a number B of K-tuples containing one random sample of each class. Formally, this corresponds to the following approximation:\nR̃−B(S) := 1\nB ∑ (i1,...iK)∈TB hS(Xi1 , . . . , XiK ),\nwhere hS(X1, . . . , XK) = 1n− ∑ k<l nknlS(Xk, Xl) and TB is a set of cardinality B built by sampling with replacement in the set of K-tuples ΛT = {(i1, . . . , iK) | ik ∈ {1, . . . , nk}; k = 1, . . . ,K}. R̃−B(S) is also an incomplete version of R̂−n (S), with the alternative view of R̂−n (S) as a generalized K-sample U -statistic (Lee, 1990) of degree (1, . . . , 1) and kernel hS , see supplementary material for a full definition. Note that R̃−B(S) contains BK(K − 1)/2 pairs, balanced across all class pairs. R̄−B(S) and R̃ − B(S) are both unbiased estimates of R̂ − n (S), but their variances are different and one approximation might be better than the other in some regimes. The following result provides expressions for the variances of both incomplete estimators for a fixed budget of B0 sampled pairs, under a standard asymptotic framework.\nProposition 1. Let B0 be the number of pairs sampled in both schemes, and denote Vn = Var(R̂−n (S)). When B0/n→ 0, n→∞ and for all k ∈ {1, . . . ,K}, nk/n→ pk > 0, we have:\nVar(R̃−B(S))− Vn ∼ K(K − 1)\n2B0 Var(hS(X(1), . . . , X(k))),\nVar(R̄−B(S))− Vn ∼ B−10 Var(S(X,X ′) |Y 6= Y ′),\nwhere X(k) denotes X |Y = k for all k ∈ {1, . . . ,K}.\nProposition 1 states that if the variance of similarity scores on the negative pairs is high compared to the variance of a weighted average of similarity scores on all types (k, l) of negative pairs, then one should prefer tuple-based sampling (otherwise pair-based sampling is better). As an example, consider the case where the similarity scores on the negative pairs constructed from classes (k0, l0) are consistently higher than for other negative pairs. These high similarity pairs will not be sampled very often by the pair-based sampling method, in contrast to the tuple-based approach. In that scenario, the variance of S(X,X ′) |Y 6= Y ′ is high while the variance of hS ( X(1), . . . , X(k) ) is low, and the tuple-based method should be preferred. In practice, the\nproperties of the data should guide the choice of the sampling approach.\nWe now analyze the effect of sampling on the performance of the empirical risk minimizer. We consider tuple-based sampling (results of the same order can be obtained for pairbased sampling). Let S̃B be the minimizer of the following simpler empirical problem:\narg max S∈S0\nR̂+n (S) subject to R̃ − B(S) ≤ α+ Φn,δ,B . (10)\nWe have the following theorem, based on combining Theorem 1 with a result bounding the maximal deviation between R̂−n (S) and its incomplete version R̃ − B(S), see Clémençon et al. (2016).\nTheorem 3. Let N = min1≤k≤K nk and α ∈ (0, 1), assume that S∗ ∈ S0 and that S0 is a VC-major class of dimension V . For all (δ, n,B) ∈ (0, 1)× N∗ × N∗, set\nΦn,δ,B = 4\n√ V log(1 +N)\nN +\n√ log(2/δ)\nN\n+ √ 2 V log(1 + ∏K k=1 nk) + log(4/δ)\nB .\nThen we have simultaneously with probability at least 1− δ,\nR+(S̃B) ≥ R+∗ − 2Φn,δ,B and R−(S̃B) ≤ α+ 2Φn,δ,B .\nThis result is very similar to Theorem 1, with an additive error term in O( √ log n/B). Remarkably, this implies that it is sufficient to sample B = O(n) tuples (hence only O(nK2) pairs) to preserve the O( √ log n/n) learning rate achieved when using all negative pairs. This will be confirmed empirically in our numerical experiments.\nRemark 4 (Approximating the positive risk). When needed, sampling-based techniques can also be used to approximate the empirical positive risk R̂+n (S), with generalization results analogous to Theorem 3. Details are left to the reader."
  }, {
    "heading": "5. Illustrative Experiments",
    "text": "In this section, we present some experiments to illustrate our main results. We first illustrate how solving instances of Problem (6) allows to optimize for specific points of the ROC curve. We then provide some numerical evidence of the fast rates of Theorem 2. Finally, we illustrate our scalability results of Section 4 by showing that dramatically subsampling the negative empirical risk leads to negligible loss in generalization performance."
  }, {
    "heading": "5.1. Pointwise ROC Optimization",
    "text": "We illustrate on synthetic data that solving (6) for different values of α can optimize for different regions of the\nROC curve. Let X ⊂ Rd, and let S0 be the set of bilinear similarities with norm-constrained matrices\nS0 = { SA : (x, x\n′) 7→ 1 2\n( 1 + x>Ax′ ) ∣∣ ‖A‖2F ≤ 1} , where ‖A‖2F = ∑d i,j=1 a 2 ij . Note that when data is scaled (‖x‖ = 1 for all x ∈ X ), we have SA(x, x′) ∈ [0, 1] for all x, x′ ∈ X and all SA ∈ S0. In our simple experiment, we have K = 3 classes and observations belong to the sphere in R3. Denoting by θx,ci the angle between the element x and the centroid ci of class i, we set for all i ∈ {1, 2, 3},\nµi(x) ∝ I { θx,ci < π\n4\n} , pi = 1\n3\nand c1 = (cos(π/3), sin(π/3), 0), c2 = e2, c3 = e3 with ei vectors of the standard basis of R3. See Figure 1(a) for a graphical representation of the data.\nThe solutions of the problem can be expressed in closed form using Lagrangian duality. In particular, when the constraints are saturated, the solution SAα is an increasing transformation of sP−λαN with\nP = 1\n2n+ ∑ 1≤i<j≤n I {Yi = Yj} · ( XiX > j +XjX > i ) ,\nN = 1\n2n− ∑ 1≤i<j≤n I {Yi 6= Yj} · ( XiX > j +XjX > i ) ,\nand λα is a positive Lagrange multiplier decreasing in α, see supplementary material for details. By varying α, we tradeoff between the information contained in the positive pairs (α large, λα close to zero) and in the negative pairs (α small, λα large), which indeed results in optimizing different areas of the ROC curve, see Figure 1(b)."
  }, {
    "heading": "5.2. Fast Rates",
    "text": "Theorem 2 shows that when the noise assumption NA is verified, faster rates of generalization can be achieved. Showing\nthe existence of fast rates experimentally requires us to design a problem for which the η satisfies NA, which is not trivial due to the pairwise nature of the involved quantities. We emphasize that such empirical evidence of fast rates is rarely found in the literature.\nWe put ourselves in a simple scenario where X = [0, 1], µ = 1, K = 2 and p1 = p2 = 1/2. In that context, characterizing µ1(dx) is sufficient to have a fully defined problem. With m ∈ (0, 12 ), a ∈ (0, 1) and C ∈ (0, 12 ), we set\nµ1(x) = { 2C if x ∈ [0,m], 1− |2x− 1|(1−a)/a if x ∈ (m, 1/2],\nwhere C is chosen so that Q∗α = 1/2 and m is fixed in advance. Since ∫ µ1(dx) = 1, we chose µ1 symmetric in (1/2, 1) to satisfy that constraint. Figure 2 shows example distributions.\nGiven that µ = 1, the noise assumption with a close to 1 requires that there are sharp variations of η close to Q∗α. To induce the form of the function more easily, we fixed Q∗α = 1/2, which requires us to choose µ1 such that the value of the integral of η is controlled while η has the expected local property around 1/2. More details about the design of the experiment can be found in the supplementary material. When t is small enough, P (|η(X,X ′)−Q∗α| ≤ t)\nis of order −t a1−a log(t). Due to the logarithm term in the noise condition, we expect that the generalization speeds to be slightly worse than O(n−(2+a)/4).\nThe family S0 is composed of indicators of sets, which are parameterized by t ∈ (0, 1) (see supplementary material for a graphical representation). Each set contains the pairs (x, x′) such that one of the supremum distances between (x, x′) and (0, 0) or (1, 1) is smaller than t, which writes\n{x, x′ ∈ X | min(max(1− x, 1− x′),max(x, x′)) < t} .\nThe optimal set can thus always be identified, and R+(S) and R−(S) can be expressed analytically for some S ∈ S0. The empirical problem Eq. (6) is always solved neglecting the tolerance parameter Φ, i.e. setting Φ = 0.\nFigure 3 shows experiments for the case α = 0.26, m = 0.35 and a ∈ [0.1, 0.9]. For some a, the empirical 90- quantile of ROCS∗(α)−R+(Ŝn) is computed for different values of n on 1000 experiments and its logarithm is fitted to Ca× log(n) +Da to get the empirical generalization speed Ca. There is a clear downward trend when a increases, illustrating the fast rates in practice."
  }, {
    "heading": "5.3. Scalability by Sampling",
    "text": "We illustrate the results of Section 4 on MMC (Xing et al., 2002), a popular metric learning algorithm whose formulation is very close to the one we consider. We introduce the set of Mahalanobis distances dA indexed by a positive\nsemidefinite matrix A:\ndA(x, x ′) = √ (x− x′)>A(x− x′).\nMMC solves the following problem (using projected gradient ascent):\nmax A\n1\nn− ∑ 1≤i<j≤n I{Yi 6= Yj} · dA(Xi, Xj)\ns.t. 1\nn+ ∑ 1≤i<j≤n I{Yi = Yj} · d2A(Xi, Xj) ≤ 1\nA 0\nWe use MNIST dataset, composed of 70, 000 images representing the 0-9 handwritten digits, with classes roughly equally distributed. We randomly split it into a training set and a test set of 10, 000 instances. As done in previous work, the dimension of the features is reduced using PCA to keep 90% of the explained variance. We approximate the average over negative pairs by sampling K-tuples with B terms, as proposed in Section 4 (pair-based sampling performs similarly on this dataset). We aim to show that optimizing the criterion on the resulting smaller set of pairs does not significantly impact the learning rate (yet greatly reduces training time). We solve MMC on the training set for a varying number of training instances n and of K-tuples B, and report the objective and constraint values on the test set. The results, summarized in Figure 4, confirm the small performance loss due to subsampling, for a huge improvement in terms of computing time. Indeed, when n = 60, 000, the total number of negative pairs is almost 2 billions while B = 0.15n corresponds to sampling only 400, 000 pairs."
  }, {
    "heading": "6. Conclusion",
    "text": "We have introduced a rigorous probability framework to study similarity learning from the novel perspective of pairwise bipartite ranking and pointwise ROC optimization. We derived statistical guarantees for generalization in this context, and analyzed the impact of using sampling-based approximations. Our results are illustrated on a series of numerical experiments. Our study opens promising directions of future work. We are especially interested in extending our results to allow the rejection of queries from unseen classes (e.g., unknown identities) at test time (see for instance Bendale & Boult, 2015). This could be achieved by incorporating a loss function to encourage the score of all positive pairs to be above some fixed threshold, below which we would reject the query."
  }, {
    "heading": "Acknowledgments",
    "text": "This work was supported by IDEMIA. We would like to thank Anne Sabourin for her substantial feedback that has greatly improved this work, as well as the ICML reviewers for their constructive input."
  }],
  "year": 2018,
  "references": [{
    "title": "Similarity metrics for categorization: From monolithic to category specific",
    "authors": ["B. Babenko", "S. Branson", "S.J. Belongie"],
    "venue": "In ICCV,",
    "year": 2009
  }, {
    "title": "Robustness and Generalization for Metric",
    "authors": ["A. Bellet", "A. Habrard"],
    "venue": "Learning. Neurocomputing,",
    "year": 2015
  }, {
    "title": "Similarity Learning for Provably Accurate Sparse Linear Classification",
    "authors": ["A. Bellet", "A. Habrard", "M. Sebban"],
    "venue": "In ICML,",
    "year": 2012
  }, {
    "title": "Towards Open World Recognition",
    "authors": ["A. Bendale", "T.E. Boult"],
    "venue": "In CVPR,",
    "year": 2015
  }, {
    "title": "Some properties of incomplete U-statistics",
    "authors": ["G. Blom"],
    "venue": "Biometrika, 63(3):573–580,",
    "year": 1976
  }, {
    "title": "Introduction to statistical learning theory",
    "authors": ["O. Bousquet", "S. Boucheron", "G. Lugosi"],
    "venue": "In Advanced Lectures on Machine Learning,",
    "year": 2004
  }, {
    "title": "Generalization Bounds for Metric and Similarity Learning",
    "authors": ["Q. Cao", "Guo", "Z.-C", "Y. Ying"],
    "venue": "Machine Learning,",
    "year": 2016
  }, {
    "title": "Large Scale Online Learning of Image Similarity Through Ranking",
    "authors": ["G. Chechik", "V. Sharma", "U. Shalit", "S. Bengio"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "Ranking the best instances",
    "authors": ["S. Clémençon", "N. Vayatis"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2007
  }, {
    "title": "Tree-based ranking methods",
    "authors": ["S. Clémençon", "N. Vayatis"],
    "venue": "IEEE Transactions on Information Theory,",
    "year": 2009
  }, {
    "title": "Scaling-up Empirical Risk Minimization: Optimization of Incomplete U -statistics",
    "authors": ["S. Clémençon", "I. Colin", "A. Bellet"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Overlaying classifiers: A practical approach to optimal scoring",
    "authors": ["S. Clémençon", "N. Vayatis"],
    "venue": "Constructive Approximation,",
    "year": 2010
  }, {
    "title": "Ranking and Empirical Minimization of U-Statistics",
    "authors": ["S. Clémençon", "G. Lugosi", "N. Vayatis"],
    "venue": "The Annals of Statistics,",
    "year": 2008
  }, {
    "title": "Uniform Central Limit Theorems",
    "authors": ["R.M. Dudley"],
    "year": 1999
  }, {
    "title": "Neighbourhood Components Analysis",
    "authors": ["J. Goldberger", "S. Roweis", "G. Hinton", "R. Salakhutdinov"],
    "venue": "In NIPS,",
    "year": 2004
  }, {
    "title": "Is that you? Metric Learning Approaches for Face Identification",
    "authors": ["M. Guillaumin", "J. Verbeek", "C. Schmid"],
    "venue": "In CVPR,",
    "year": 2009
  }, {
    "title": "A class of statistics with asymptotically normal distribution",
    "authors": ["W. Hoeffding"],
    "venue": "The Annals of Mathematical Statistics,",
    "year": 1948
  }, {
    "title": "Cross-modal metric learning for auc optimization",
    "authors": ["J. Huo", "Y. Gao", "Y. Shi", "H. Yin"],
    "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
    "year": 2018
  }, {
    "title": "An introduction to biometric recognition",
    "authors": ["A.K. Jain", "A. Ross", "S. Prabhakar"],
    "venue": "IEEE Transactions on Circuits and Systems for Video Technology,",
    "year": 2004
  }, {
    "title": "Introduction to Biometrics",
    "authors": ["A.K. Jain", "A.A. Ross", "K. Nandakumar"],
    "year": 2011
  }, {
    "title": "Learning LowDimensional Metrics",
    "authors": ["L. Jain", "B. Mason", "R. Nowak"],
    "venue": "In NIPS,",
    "year": 2017
  }, {
    "title": "Regularized Distance Metric Learning: Theory and Algorithm",
    "authors": ["R. Jin", "S. Wang", "Y. Zhou"],
    "venue": "In NIPS,",
    "year": 2009
  }, {
    "title": "Large scale metric learning from equivalence constraints",
    "authors": ["M. Kstinger", "M. Hirzer", "P. Wohlhart", "P.M. Roth", "H. Bischof"],
    "venue": "In CVPR,",
    "year": 2012
  }, {
    "title": "Metric Learning: A Survey",
    "authors": ["B. Kulis"],
    "venue": "Foundations and Trends in Machine Learning,",
    "year": 2012
  }, {
    "title": "statistics: Theory and practice",
    "authors": ["Lee", "A.J. U"],
    "year": 1990
  }, {
    "title": "Constrained Metric Learning Via Distance Gap Maximization",
    "authors": ["W. Liu", "X. Tian", "D. Tao", "J. Liu"],
    "venue": "In AAAI,",
    "year": 2010
  }, {
    "title": "Asympotical minimax recovery of the sets with smooth boundaries",
    "authors": ["E. Mammen", "A.B. Tsybakov"],
    "venue": "The Annals of Statistics,",
    "year": 1995
  }, {
    "title": "Metric Learning to Rank",
    "authors": ["B. McFee", "G.R.G. Lanckriet"],
    "venue": "In ICML,",
    "year": 2010
  }, {
    "title": "A Neyman-Pearson approach to statistical learning",
    "authors": ["C. Scott", "R. Nowak"],
    "venue": "IEEE Transactions on Information Theory,",
    "year": 2005
  }, {
    "title": "Positive Semidefinite Metric Learning Using Boosting-like Algorithms",
    "authors": ["C. Shen", "J. Kim", "L. Wang", "A. van den Hengel"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "Visualizing Data using t-SNE",
    "authors": ["L. van der Maaten", "G. Hinton"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2008
  }, {
    "title": "Sample complexity of learning mahalanobis distance metrics",
    "authors": ["N. Verma", "K. Branson"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Distance Metric Learning for Large Margin Nearest Neighbor Classification",
    "authors": ["K.Q. Weinberger", "L.K. Saul"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2009
  }, {
    "title": "Online multimodal deep similarity learning with application to image retrieval",
    "authors": ["P. Wu", "S.C. Hoi", "H. Xia", "P. Zhao", "D. Wang", "C. Miao"],
    "venue": "In ACM Multimedia,",
    "year": 2013
  }, {
    "title": "Large Scale Distributed Distance Metric Learning",
    "authors": ["P. Xie", "E.P. Xing"],
    "venue": "Technical report,",
    "year": 2015
  }, {
    "title": "Distance Metric Learning with Application to Clustering with Side-Information",
    "authors": ["E.P. Xing", "A.Y. Ng", "M.I. Jordan", "S.J. Russell"],
    "venue": "In NIPS,",
    "year": 2002
  }],
  "id": "SP:461f00e4c0f5f9c75e862c9b6e5d5f721cdc2445",
  "authors": [{
    "name": "Robin Vogel",
    "affiliations": []
  }, {
    "name": "Aurélien Bellet",
    "affiliations": []
  }, {
    "name": "Stéphan Clémençon",
    "affiliations": []
  }],
  "abstractText": "The performance of many machine learning techniques depends on the choice of an appropriate similarity or distance measure on the input space. Similarity learning (or metric learning) aims at building such a measure from training data so that observations with the same (resp. different) label are as close (resp. far) as possible. In this paper, similarity learning is investigated from the perspective of pairwise bipartite ranking, where the goal is to rank the elements of a database by decreasing order of the probability that they share the same label with some query data point, based on the similarity scores. A natural performance criterion in this setting is pointwise ROC optimization: maximize the true positive rate under a fixed false positive rate. We study this novel perspective on similarity learning through a rigorous probabilistic framework. The empirical version of the problem gives rise to a constrained optimization formulation involving U -statistics, for which we derive universal learning rates as well as faster rates under a noise assumption on the data distribution. We also address the large-scale setting by analyzing the effect of sampling-based approximations. Our theoretical results are supported by illustrative numerical experiments.",
  "title": "A Probabilistic Theory of Supervised Similarity Learning for Pointwise ROC Curve Optimization"
}