{
  "sections": [{
    "text": "√ logn) speedup for\nthe Viterbi algorithm when there are few distinct transition probabilities in the HMM."
  }, {
    "heading": "1. Introduction",
    "text": "A Hidden Markov Model (HMM) is a simple model that describes a random process for generating a sequence of observations. A random walk is performed on an underlying graph (Markov Chain) and, at each step, an observation is drawn from a probability distribution that depends only on the current state (the node in the graph).\nHMMs are a fundamental statistical tool and one of the most important questions in the applications of HMMs is computing the most likely sequence of states visited by the random walk in the HMM given the sequence of observations. Andrew Viterbi proposed an algorithm (Viterbi, 1967) for this problem that computes the solution in\nAuthors ordered alphabetically. 1MIT, US. Correspondence to: Arturs Backurs <backurs@mit.edu>, Christos Tzamos <tzamos@mit.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nO(Tn2) time for any HMM with n states and an observation sequence of length T . This algorithm is known as the Viterbi algorithm and the problem of computing the most likely sequence of states is also known as the Viterbi Path problem.\nThe Viterbi algorithm has found wide applicability in machine learning. It is an important tool for structured prediction, used e.g., for structured perceptrons (Collins, 2002). Other applications include speech recognition (Rabiner, 1989; Nefian et al., 2002; Bengio, 2003), part-of-speech tagging (Collins, 2002), action planning (Attias, 2003), emotion recognition (Cohen et al., 2000), human activity classification (Mannini & Sabatini, 2010), and waveform classification (Kim & Smyth, 2006). Furthermore, it is often combined with other methods. For example, a combination of the Viterbi algorithm and neural networks is used for speech recognition (Mohamed et al., 2012; AbdelHamid et al., 2012; Bourlard & Morgan, 2012), handwriting recognition and protein secondary structure prediction (Lin et al., 2005; Peng et al., 2009). It also can be combined with Support Vector Machines (Altun et al., 2003). Finally, the Viterbi algorithm is used as a module in Graph Transformer Networks, with applications to speech recognition (LeCun et al., 1998; Collobert, 2011).\nThe quadratic dependence of the algorithm’s runtime on the number of states is a long-standing bottleneck that limits its applicability to problems with large state spaces, particularly when the number of observations is large. A lot of effort has been put into improving the Viterbi algorithm to lower either the time or space complexity. Many works achieve speedups by requiring structure in the input, either explicitly by considering restricted classes of HMMs (Felzenszwalb et al., 2004; Siddiqi & Moore, 2005) or implicitly by using heuristics that improve runtime in certain cases (Esposito & Radicioni, 2009; Kaji et al., 2010). For the general case, in (Lifshits et al., 2009; Mahmud & Schliep, 2011) it is shown how to speed up the Viterbi algorithm by O(log n) when the number of distinct observations is constant using the Four Russians method or similar ideas. More recently, in (Cairo et al., 2016), the same logarithmic speed-up was shown to be possible for the general case. Despite significant effort, only log-\narithmic improvements are known other than in very special cases. In contrast, the memory complexity can be reduced to almost linear in the number of states without significant overhead in the runtime (Grice et al., 1997; Tarnas & Hughey, 1998; Churbanov & Winters-Hilt, 2008).\nIn this work, we attempt to explain this apparent barrier for faster runtimes by giving evidence of the inherent hardness of the Viterbi Path problem. In particular, we show that getting a polynomial speedup1 would imply a breakthrough for fundamental graph problems. Our lower bounds are based on standard hardness assumptions for the All-Pairs Shortest Paths and the Min-Weight k-Clique problems and apply even in cases where the number of distinct observations is small.\nBefore formally stating our results, let us give some background on the Min-Weight k-Clique problem. This fundamental graph problem asks to find the minimum weight k-clique in the given undirected weighted graph on n nodes and O(n2) weighted edges. This is the parameterized version of the NP-hard Min-Weight Clique problem (Karp, 1972). The Min-Weight k-Clique is amongst the most wellstudied problems in theoretical computer science, and it is the canonical intractable problem in parameterized complexity.\nA naive algorithm solves the Min-Weight k-Clique in O(nk) time and the best known algorithm still runs in O(nk−o(1)) for any constant k. Obtaining a significantly faster algorithm for this problem is a longstanding open question.\nA conjecture in graph algorithms and parameterized complexity is that it there is no O(nk−ε) algorithm for any constant ε > 0. The special case of the conjecture with k = 3 says that finding the minimum weight triangle in a weighted graph cannot be solved in O(n3−δ) time for any constant δ > 0. There are many negative results that intuitively support this conjecture: a truly sub-\n1Getting an algorithm running in time, say O(Tn1.99).\ncubic algorithm for Min-Weight 3-Clique implies such algorithm for the All-Pairs Shortest Paths as well (Williams & Williams, 2010). The latter is a well studied problem and no truly subcubic algorithm is known for it despite significant effort (Williams, 2014). Unconditional lower bounds for k-Clique are known for various computational models, such as Ω(nk) for monotone circuits (Alon & Boppana, 1987). The planted Clique problem has also proven to be very challenging (e.g. (Alon et al., 2007; 1998; Hazan & Krauthgamer, 2011; Jerrum, 1992)). Max-Clique is also known to be hard to efficiently approximate within nontrivial factors (Håstad, 1999).\nWe complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM. We summarize our results in Table 1.\nOur results and techniques Our first lower bound shows that the Viterbi Path problem cannot be computed in time O(Tn2)1−ε for a constant ε > 0 unless the APSP conjecture is false. The APSP conjecture states that there is no algorithm for the All-Pairs Shortest Paths problem that runs in truly subcubic2 time in the number of vertices of the graph. We obtain the following theorem:\nTheorem 1. The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.\nThe proof of the theorem gives a reduction from All-Pairs Shortest Paths to the Viterbi Path problem. This is done by encoding the weights of the graph of the APSP instance as transition probabilities of the HMM or as probabilities of seeing observations from different states. The proof requires a large alphabet size, i.e. a large number of distinct observations, which can be as large as the number of total steps T .\nA natural question question to ask is whether there is a faster algorithm that solves the Viterbi Path problem when\n2Truly subcubic means O(n3−δ) for constant δ > 0.\nthe alphabet size is much smaller than T , say when T = n2 and the alphabet size is n. We observe that in such a case, the input size to the Viterbi Path problem is only O(n2): we only need to specify the transition probabilities of the HMM, the probabilities of each observation in each state and the sequence of observations. The Viterbi algorithm in this setting runs in Θ(Tn2) = Θ(n4) time. Showing a matching APSP based lower bound seems difficult because the runtime in this setting is quadratic in the input size while the APSP conjecture gives only N1.5 hardness for input size N . To our best knowledge, all existing reduction techniques based on the APSP conjecture do not achieve such an amplification of hardness. In order to get a lower bound for smaller alphabet sizes, we need to use a different hardness assumption.\nFor this purpose, we consider the k-Clique conjecture. It is a popular hardness assumption which states that it is not possible to compute a minimum weight k-clique on an edge-weighted graph with n vertices in time O(nk−ε) for constant k and ε > 0. With this assumption, we are able to extend Theorem 1 and get the following lower bound for the Viterbi Path problem on very small alphabets:\nTheorem 2. For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2.\nTo show the theorem, we perform a reduction from the Min-Weight k-Clique problem. Given a Min-Weight kClique instance, we create an HMM with two special nodes, a start node and an end node, and enforce the following behavior of the optimal Viterbi path: Most of the time it stays in the start or end node, except for a small number of steps, during which it traverses the rest of the graph to move from the start to the end node. The time at which the traversal happens corresponds to a clique in the original graph of the Min-Weight k-Clique instance. We penalize the traversal according to the weight of the corresponding k-clique and thus the optimal path will find the minimum weight k-clique. Transition probabilities of the HMM and probabilities of seeing observations from different states encode edge-weights of the Min-Weight k-Clique instance. Further, we encode the weights of smaller cliques into the sequence of observations according to the binary expansion of the weights.\nOur results of Theorems 1 and 2 imply that the Viterbi algorithm is essentially optimal even for small alphabets. We also study the extreme case of the Viterbi Path problem with unary alphabet where the only information available is the total number of steps T . We show a surprising behavior: when T ≤ n the Viterbi algorithm is essentially optimal, while there is a simple much faster algorithm when T > n. See Section 5 for more details.\nWe complement our lower bounds with an algorithm for Viterbi Path that achieves speedup 2Ω( √ logn) when there are few distinct transition probabilities in the underlying HMM. Such a restriction is mild in applications where one can round the transition probabilities to a small number of distinct values.\nTheorem 3. When there are fewer than 2ε √\nlogn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.\nWe achieve this result by developing an algorithm for online (min,+) matrix-vector multiplication for the case when the matrix has few distinct values. Our algorithm is presented in Section 7 and is based on a recent result for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017).\nThe results we presented above hold for dense HMMs. For sparse HMMs that have at most m edges out of the n2 possible ones, i.e. the transition matrix has at most m nonzero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time. The lower bounds that we presented above can be adapted directly for this case to show that no faster algorithm exists that runs in timeO(Tm)1−ε. See the corresponding discussion in Section 6."
  }, {
    "heading": "2. Preliminaries",
    "text": "Notation For an integer m, we denote the set {1, 2, . . . ,m} by [m].\nDefinition 1 (Hidden Markov Model). A Hidden Markov Model (HMM) consists of a directed graph with n distinct hidden states [n] with transition probabilities Ã(u, v) of going from state u to state v. In any given state, there is a probability distribution of symbols that can be observed and B̃(u, s) gives the probability of seeing symbol s on state u. The symbols come from an alphabet [σ] of size σ. An HMM can thus be represented by a tuple (Ã, B̃)."
  }, {
    "heading": "2.1. The Viterbi Path Problem",
    "text": "Given an HMM and a sequence of T observations, the Viterbi algorithm (Viterbi, 1967) outputs a sequence of T states that is most likely given the T observations. More precisely, let S = (s1, . . . , sT ) be the given sequence of T observations where symbol st ∈ [σ] is observed at time t = 1, . . . , T . Let ut ∈ [n] be the state of the HMM at time t = 1, . . . , T . The Viterbi algorithm finds a state sequence U = (u0, u1, . . . , uT ) starting at u0 = 1 that maximizes Pr[U |S]. The problem of finding the sequence U is known as the Viterbi Path problem. In particular, the Viterbi Path\nproblem solves the optimization problem\narg max u0=1,u1,...,uT T∏ t=1 [ Ã(ut−1, ut) · B̃(ut, st) ] .\nThe Viterbi algorithm solves this problem in O(Tn2) by computing for t = 1 . . . T the best sequence of length t that ends in a given state in a dynamic programming fashion. When run in a word RAM model with O(log n) bit words, this algorithm is numerically unstable because even representing the probability of reaching a state requires linear number of bits. Therefore, log probabilities are used for numerical stability since that allows to avoid underflows (Young et al., 1997; Amengual & Vidal, 1998; Li & Tang, 2009; Lee et al., 2007; Huang et al., 2001). To maintain numerical stability and understand the underlying combinatorial structure of the problem, we assume that the input is given in the form of log-probabilities, i.e. the input to the problem is A(u, v) = − log Ã(u, v) and B(u, s) = − log B̃(u, s) and focus our attention on the Viterbi Path problem defined by matrices A and B.\nDefinition 2 (Viterbi Path Problem). The VITERBI PATH problem is specified by a tuple (A,B, S) where A and B are n × n and n × σ matrices, respectively, and S = (s1, . . . , sT ) is a sequence of T = nΘ(1) observations s1, . . . , sT ∈ [σ] over an alphabet of size σ. Given an instance (A,B, S) of the VITERBI PATH problem, our goal is to output a sequence of vertices u0, u1, . . . , uT ∈ [n] with u0 = 1 that solves\narg min u0=1,u1,...,uT T∑ t=1 [A(ut−1, ut) +B(ut, st)] .\nWe can assume that log probabilities in matrices A and B are arbitrary positive numbers without the restriction that the corresponding probabilities must sum to 1. See Appendix C for a discussion.\nA simpler special case of the VITERBI PATH problem asks to compute the most likely path of length T without any observations.\nDefinition 3 (Shortest Walk Problem). Given an integer T and a weighted directed graph (with possible self-loops) on n vertices with edge weights specified by a matrixA, the SHORTEST WALK problem asks to compute a sequence of vertices u0 = 1, u1, . . . , uT ∈ [n] that solves\narg min u0=1,u1,...,uT T∑ t=1 A(ut−1, ut).\nIt is easy to see that the SHORTEST WALK problem corresponds to the VITERBI PATH problem when σ = 1 and B(u, 1) = 0 for all u ∈ [n]."
  }, {
    "heading": "2.2. Hardness assumptions",
    "text": "We use the hardness assumptions of the following problems.\nDefinition 4 (ALL-PAIRS SHORTEST PATHS (APSP) problem). Given an undirected graph G = (V,E) with n vertices and positive integer weights on the edges, find the shortest path between u and v for every u, v ∈ V .\nThe APSP conjecture states that the ALL-PAIRS SHORTEST PATHS problem requires Ω(n3)1−o(1) time in expectation.\nConjecture 1 (APSP conjecture). The ALL-PAIRS SHORTEST PATHS problem on a graph with n vertices and positive integer edge-weights bounded by nO(1) requires Ω(n3)1−o(1) time in expectation.\nThere is a long list of works showing conditional hardness for various problems based on the All-Pairs Shortest Paths conjecture (Roditty & Zwick, 2004; Williams & Williams, 2010; Abboud & Williams, 2014; Abboud et al., 2015b;c).\nDefinition 5 (MIN-WEIGHT k-CLIQUE problem). Given a complete graphG = (V,E) with n vertices and positive integer edge-weights, output the minimum total edge-weight of a k-clique in the graph.\nThis is a very well studied computational problem and despite serious efforts, the best known algorithm for this problem still runs in time O(nk−o(1)), which matches the runtime of the trivial algorithm up to subpolynomial factors. The k-Clique conjecture states that this problem requires Ω(nk)1−o(1) time and it has served as a basis for showing conditional hardness results for several problems on sequences (Abboud et al., 2015a; 2014; Bringmann et al., 2016) and computational geometry (Backurs et al., 2016).\nConjecture 2 (k-Clique conjecture). The MIN-WEIGHT k-CLIQUE problem on a graph with n vertices and positive integer edge-weights bounded by nO(k) requires Ω(nk)1−o(1) time in expectation.\nFor k = 3, the MIN-WEIGHT 3-CLIQUE problem asks to find the minimum weight triangle in a graph. This problem is also known as the MINIMUM TRIANGLE problem and under the 3-Clique conjecture it requires Ω(n3)1−o(1) time. The latter conjecture is equivalent to the APSP conjecture (Williams & Williams, 2010).\nWe often use the following variant of the MIN-WEIGHT k-CLIQUE problem:\nDefinition 6 (MIN-WEIGHT k-CLIQUE problem for k-partite graphs). Given a complete k-partite graph G = (V1 ∪ . . . ∪ Vk, E) with |Vi| = ni and positive integer weights on the edges, output the minimum total edgeweight of a k-clique in the graph.\nIf for all i, j we have that ni = n Θ(1) j , it can be shown that the MIN-WEIGHT k-CLIQUE problem for k-partite graphs\nrequires Ω (∏k\ni=1 ni\n)1−o(1) time assuming the k-Clique\nconjecture. We provide a simple proof of this statement in the appendix."
  }, {
    "heading": "3. Hardness of VITERBI PATH",
    "text": "We begin by presenting our main hardness result for the VITERBI PATH problem.\nTheorem 1. The VITERBI PATH problem requires Ω(Tn2)1−o(1) time assuming the APSP Conjecture.\nTo show APSP hardness, we will perform a reduction from the MINIMUM TRIANGLE problem (described in Section 2.2) to the VITERBI PATH problem. In the instance of the MINIMUM TRIANGLE problem, we are given a 3- partite graph G = (V1 ∪ V2 ∪ U, E) such that |V1| = |V2| = n, |U | = m. We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed graph G′ = ({1, 2} ∪ V1 ∪ V2, E′). E′ contains all the edges of G between V1 and V2, directed from V1 towards V2, edges from 1 towards all nodes of V1 of weight 0 and edges from all nodes of V2 towards 2 of weight 0. We also add a self-loops at nodes 1 and 2 of weight 0.\nWe create an instance of the VITERBI PATH problem (A,B, S) as described below. Figure 1 illustrates the construction of the instance.\n• Matrix A is the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and non-existent self-loops.\n• The alphabet of the HMM is U ∪ {⊥,⊥F } and thus matrix B has 2n + 2 rows and σ = m + 2 columns. For all v ∈ V1 ∪V2 and u ∈ U , B(v, u) is equal to the weight of the edge (v, u) in graphG. Moreover, for all v ∈ V1 ∪ V2, B(v,⊥) = +∞ (or a sufficiently large number) and for all v ∈ V1 ∪ V2 ∪ {1}, B(v,⊥F ) = +∞. Finally, all remaining entries corresponding to nodes 1 and 2 are 0.\n• Sequence S of length T = 3m + 1 is generated by appending the observations u, u and ⊥ for all u ∈ U and adding a ⊥F observation at the end.\nGiven the above construction, the theorem statement follows directly from the following claim.\nClaim 1. The weight of the solution to the VITERBI PATH instance is equal to the weight of the minimum triangle in the graph G.\nProof. The optimal path for the VITERBI PATH instance begins at node 1. It must end in node 2 since otherwise when observation ⊥F arrives we collect cost +∞. Similarly, whenever an observation ⊥ arrives the path must be either on node 1 or 2. Thus, the path first loops in node 1 and then goes from node 1 to node 2 during three consecutive observations u, u and ⊥ for some u ∈ U and stays in node 2 until the end. Let v1 ∈ V1 and v2 ∈ V2 be the two nodes visited when moving from node 1 to node 2. The only two steps of non-zero cost are:\n1. Moving from node 1 to node v1 at the first observation u. This costs A(1, v1) +B(v1, u) = B(v1, u).\n2. Moving from node v1 to node v2 at the second observation u. This costs A(v1, v2) +B(v2, u).\nThus, the overall cost of the path is equal to B(v1, u) + A(v1, v2) + B(v2, u), which is equal to the weight of the triangle (v1, v2, u) in G. Minimizing the cost of the path in this instance is therefore the same as finding the minimum weight triangle in G."
  }, {
    "heading": "4. Hardness of VITERBI PATH with small alphabet",
    "text": "The proof of Theorem 1 requires a large alphabet size, which can be as large as the number of total steps T . In the appendix, we show how to get a lower bound for the VITERBI PATH problem on alphabets of small size by using a different hardness assumption.\nTheorem 2. For any C, ε > 0, the VITERBI PATH problem on T = Θ(nC) observations from an alphabet of size Θ(nε) requires Ω(Tn2)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2."
  }, {
    "heading": "5. Complexity of VITERBI PATH for unary alphabet",
    "text": "In this section, we focus on the extreme case of VITERBI PATH with unary alphabet.\nTheorem 4. The VITERBI PATH problem requires Ω(Tn2)1−o(1) time when T ≤ n even if the size of the alphabet is σ = 1, assuming the APSP Conjecture.\nThe above theorem follows from APSP-hardness of the SHORTEST WALK problem that we present next.\nTheorem 5. The SHORTEST WALK problem requires Ω(Tn2)1−o(1) time when T ≤ n, assuming the APSP Conjecture.\nProof. We will perform a reduction from the MINIMUM TRIANGLE problem to the VITERBI PATH\nproblem. In the instance of the MINIMUM TRIANGLE problem, we are given a 3-partite undirected graph G = (V1 ∪ V2 ∪ U, E) with positive edge weights such that |V1| = |V2| = n, |U | = m. We want to find a triangle of minimum weight in the graph G. To perform the reduction, we define a weighted directed and acyclic graph G′ = ({1, 2} ∪ V1 ∪ V2 ∪ U ∪ U ′, E′). Nodes in U ′ are in one-to-one correspondence with nodes in U and |U ′| = m. E′ is defined as follows. We add all edges of G between nodes in U and V1 directed from U towards V1 and similarly, we add all edges of G between nodes in V1 and V2 directed from V1 towards V2. Instead of having edges between nodes in V2 and U , we add the corresponding edges of G between nodes in V2 and U ′ directed from V2 towards U ′. Moreover, we add additional edges of weight 0 to create a path P of m + 1 nodes, starting from node 1 and going through all nodes in U in some order. Finally, we create another path P ′ of m + 1 nodes going through all nodes in U ′ in the same order as their counterparts on path P and ending at node 2. These edges have weight 0 apart from the last one, entering node 2, which has weight −C (a sufficiently large negative constant)3.\nWe create an instance of the SHORTEST WALK problem by setting T = m+ 4 and A to be the weighted adjacency matrix of G′ that takes value +∞ (or a sufficiently large integer) for non-existent edges and self-loops.\nThe optimal walk of the SHORTEST WALK instance must include the edge of weight −C entering node 2 since otherwise the cost will be non-negative. Moreover, the walk\n3Since the definition of SHORTEST WALK doesn’t allow negative weights, we can equivalently set its weight to be 0 and add C to all the other edge weights.\nmust reach node 2 exactly at the last step since otherwise the cost will be +∞ as there are no outgoing edges from node 2. By the choice of T , the walk leaves path P at some node u ∈ U , then visits nodes v1 and v2 in V1 and V2, respectively, and subsequently moves to node u′ ∈ U ′ where u′ is the counterpart of u on path P ′. The total cost of the walk is thus the weight of the triangle (u, v1, v2) in G, minus C. Therefore, the optimal walk has cost equal to the weight of the minimum triangle up to the additive constant C.\nNotice that when T > n, the runtime of the Viterbi algorithm is no longer optimal. We now present a faster algorithm with a total running time log T · n3/2Ω( √ logn).\nAs we show in Section 7, the general VITERBI PATH problem reduces, according to Equation 2, to computing (min,+) matrix-vector products. In the case of unary alphabet, it corresponds to computing (min,+) matrixvector product T times as follows: A ⊕ A ⊕ ... ⊕ A ⊕ z. This can be equivalently performed by first computing all (min,+) matrix-matrix products A⊕T = A⊕A⊕ ...⊕A using exponentiation with repeated squaring and then multiplying the resulting matrix with the vector z. This requires only O(log T ) matrix (min,+)-multiplications. Using the currently best algorithm for (min,+) matrix product (Williams, 2014), we get an algorithm with total running time log T · n3/2Ω( √ logn)."
  }, {
    "heading": "6. Hardness for sparse HMMs",
    "text": "The VITERBI PATH lower-bounds we have provided apply to the case where the HMM has all n2 possible edges.\nFor sparse HMMs that have at most m edges out of the\nn2 possible ones, i.e. the transition matrix has at most m non-zero probabilities, the VITERBI PATH problem can be easily solved in O(Tm) time. The lower bounds that we presented in the paper can be adapted directly for this case to show that no faster algorithm exists that runs in time O(Tm)1−ε. This can be easily seen via a padding argument. Consider a hard instance for VITERBI PATH on a dense HMM with √ m states andm edges. Adding n− √ m additional states with self-loops, we obtain a sparse instance with n states and m + n − √ m = O(m) edges. Thus, any algorithm that computes the optimal Viterbi Path in O(Tm)1−ε time for the resulting instance would solve the original instance with √ m states in O ( T ( √ m)2\n)1−ε time contradicting the corresponding lower bound.\nThis observation directly gives the following lower bounds for VITERBI PATH problem, parametrized by the number m of edges in an HMM with n states.\nTheorem 6. The VITERBI PATH problem requires Ω(Tm)1−o(1) time for an HMM with m edges and n states, assuming the APSP Conjecture.\nTheorem 7. For any C, ε > 0, the VITERBI PATH problem on T = Θ(mC) observations from an alphabet of size Θ(mε) requires Ω(Tm)1−o(1) time assuming the k-Clique Conjecture for k = dCε e+ 2. Theorem 8. The VITERBI PATH problem requires Ω(Tm)1−o(1) time when T ≤ √ m even if the size of the alphabet is σ = 1, assuming the APSP Conjecture."
  }, {
    "heading": "7. A faster VITERBI PATH algorithm",
    "text": "In this section, we present a faster algorithm for the VITERBI PATH problem, when there are only few distinct transition probabilities in the underlying HMM. Theorem 3. When there are fewer than 2ε √\nlogn distinct transition probabilities for a constant ε > 0, there is a Tn2/2Ω( √ logn) randomized algorithm for the VITERBI PATH problem that succeeds whp.\nThe number of distinct transition probabilities is equal to the number of distinct entries in matrix Ã in Definition 1. The same is true for matrix A in the additive version of VITERBI PATH, in Definition 2. So, from the theorem statement we can assume that matrixA has at most 2ε √ logn different entries for some constant ε > 0.\nTo present our algorithm, we revisit the definition of VITERBI PATH. We want to compute a path u0 = 1, u1, . . . , uT that minimizes the quantity:\nmin u0=1,u1,...,uT T∑ t=1 [A(ut−1, ut) +B(ut, st)] . (1)\nDefining the vectors bt = B(·, st), we note that (1) is equal\nto the minimum entry in the vector obtained by a sequence of T (min,+) matrix-vector products4 as follows:\nA⊕ (. . . (A⊕ (A⊕ (A⊕z+ b1)+ b2)+ b3) . . .)+ bT (2)\nwhere z is a vector with entries z1 = 0 and zi = ∞ for all i 6= 1. Vector z represents the cost of being at node i at time 0. Vector (A ⊕ z + b1) represents the minimum cost of reaching each node at time 1 after seeing observation s1. After T steps, every entry i of vector (2) represents the minimum minimum cost of a path that starts at u0 = 1 and ends at uT = i after T observations. Taking the minimum of all entries gives the cost of the solution to the VITERBI PATH instance.\nTo evaluate (2), we design an online (min,+) matrixvector multiplication algorithm. In the online matrix-vector multiplication problem, we are given a matrix and a sequence of vectors in online fashion. We are required to output the result of every matrix-vector product before receiving the next vector. Our algorithm for online (min,+) matrix-vector multiplication is based on a recent algorithm for online Boolean matrix-vector multiplication by Green Larsen and Williams (Larsen & Williams, 2017):\nTheorem 9 (Green Larsen and Williams (Larsen & Williams, 2017)). For any matrix M ∈ {0, 1}n×n and any sequence of T = 2ω( √ logn) vectors v1, . . . , vT ∈ {0, 1}n, online Boolean matrix-vector multiplication of M and vi can be performed in n2/2Ω( √ logn) amortized time whp. No preprocessing is required.\nWe show the following theorem for online (min,+) matrix-vector multiplication, which gives the promised runtime for the VITERBI PATH problem5 since we are interested in the case where T and n are polynomially related, i.e. T = nΘ(1).\nTheorem 10. Let A ∈ Rn×n be a matrix with at most 2ε √\nlogn distinct entries for a constant ε > 0. For any sequence of T = 2ω( √ logn) vectors v1, . . . , vT ∈ Rn, online (min,+) matrix-vector multiplication of A and vi can be performed in n2/2Ω( √ logn) amortized time whp. No preprocessing is required.\nProof. We will show the theorem for the case where A ∈ {0,+∞}n×n. The general case where matrix A has d ≤ 2ε √\nlogn distinct values a1, ..., ad can be handled by creating d matrices A1, ..., Ad, where each matrix Ak has entries Akij = 0 if Aij = a\nk and +∞ otherwise. Then, vector 4A (min,+) product between a matrix M and a vector v is denoted by M ⊕ v and is equal to a vector u where ui = minj(Mi,j + vj).\n5Even though computing all (min,+) products does not directly give a path for the VITERBI PATH problem, we can obtain one at no additional cost by storing back pointers. This is standard and we omit the details.\nr = A⊕v can be computed by computing rk = Ak⊕v for every k and setting ri = mink(rki + a\nk). This introduces a factor of 2ε √ logn in amortized runtime but the final amortized runtime remains n2/2Ω( √\nlogn) if ε > 0 is sufficiently small. From now on we assume thatA ∈ {0,+∞}n×n and define the matrix Ā ∈ {0, 1}n×n whose every entry is 1 if the corresponding entry at matrix A is 0 and 0 otherwise.\nFor every query vector v, we perform the following:\n– Sort indices i1, ..., in such that vi1 ≤ ... ≤ vin in O(n log n) time. – Partition the indices into p = 2α √\nlogn sets, where set Sk contains indices i(k−1)dnp e+1, ..., ikdnp e.\n– Set r = (⊥, ...,⊥)T , where ⊥ indicates an undefined value.\n– For k = 1...p fill the entries of r as follows:\n- Let ISk be the indicator vector of Sk that takes value 1 at index i if i ∈ Sk and 0 otherwise. - Compute the Boolean matrix-vector product πk = Ā ISk using the algorithm from Theorem 9.\n- Set rj = mini∈Sk(Aj,i + vi) for all j ∈ [n] such that rj = ⊥ and πkj = 1.\n– Return vector r.\nRuntime of the algorithm per query The algorithm performs p = 2α √ logn Boolean matrix-vector multiplications, for a total amortized cost of p · n2/2Ω( √ logn) = n2/2Ω( √\nlogn) for a small enough constant α > 0. Moreover, to fill an entry rj the algorithm requires going through all elements in some set Sk for a total runtime ofO(|Sk|) = n/2Ω( √ logn). Thus, for all entries pj the total time required is n2/2Ω( √\nlogn). The runtime of the other steps is dominated by these two operations so the algorithm takes n2/2Ω( √ logn) amortized time per query.\nCorrectness of the algorithm To see that the algorithm correctly computes the (min,+) product A ⊕ v, observe that the algorithm fills in the entries of vector r from smallest to largest. Thus, when we set a value to entry rj we never have to change it again. Moreover, if the value rj gets filled at step k, it must be the case that πk ′\nj = 0 for all k′ < k. This means that for all indices i ∈ S1 ∪ ... ∪ Sk−1 the corresponding entry Aj,i was always +∞."
  }, {
    "heading": "Acknowledgments",
    "text": "We thank Piotr Indyk for many helpful discussions, for comments on an earlier version of the writeup and for suggestion on how to improve the presentation. We also thank\nthe anonymous reviewers for their careful reviews. This work was supported in part by an IBM PhD Fellowship, the NSF and the Simons Foundation."
  }],
  "year": 2017,
  "references": [{
    "title": "Popular conjectures imply strong lower bounds for dynamic problems",
    "authors": ["Abboud", "Amir", "Williams", "Virginia Vassilevska"],
    "venue": "In Foundations of Computer Science (FOCS),",
    "year": 2014
  }, {
    "title": "Consequences of faster alignment of sequences",
    "authors": ["Abboud", "Amir", "Williams", "Virginia Vassilevska", "Weimann", "Oren"],
    "venue": "In Automata, Languages, and Programming,",
    "year": 2014
  }, {
    "title": "If the Current Clique Algorithms are Optimal, so is Valiant’s Parser",
    "authors": ["Abboud", "Amir", "Backurs", "Arturs", "Williams", "Virginia Vassilevska"],
    "venue": "In Foundations of Computer Science (FOCS),",
    "year": 2015
  }, {
    "title": "Subcubic equivalences between graph centrality problems, APSP and diameter",
    "authors": ["Abboud", "Amir", "Grandoni", "Fabrizio", "Williams", "Virginia Vassilevska"],
    "venue": "In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2015
  }, {
    "title": "Matching triangles and basing hardness on an extremely popular conjecture",
    "authors": ["Abboud", "Amir", "Williams", "Virginia Vassilevska", "Yu", "Huacheng"],
    "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,",
    "year": 2015
  }, {
    "title": "Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition",
    "authors": ["Abdel-Hamid", "Ossama", "Mohamed", "Abdel-rahman", "Jiang", "Hui", "Penn", "Gerald"],
    "venue": "In Acoustics, Speech and Signal Processing (ICASSP),",
    "year": 2012
  }, {
    "title": "The monotone circuit complexity of boolean functions",
    "authors": ["Alon", "Noga", "Boppana", "Ravi B"],
    "year": 1987
  }, {
    "title": "Finding a large hidden clique in a random graph",
    "authors": ["Alon", "Noga", "Krivelevich", "Michael", "Sudakov", "Benny"],
    "venue": "Random Struct. Algorithms,",
    "year": 1998
  }, {
    "title": "Testing k-wise and almost k-wise independence",
    "authors": ["Alon", "Noga", "Andoni", "Alexandr", "Kaufman", "Tali", "Matulef", "Kevin", "Rubinfeld", "Ronitt", "Xie", "Ning"],
    "venue": "In Proceedings of the 39th Annual ACM Symposium on Theory of Computing,",
    "year": 2007
  }, {
    "title": "Hidden markov support vector machines",
    "authors": ["Altun", "Yasemin", "Tsochantaridis", "Ioannis", "Hofmann", "Thomas"],
    "venue": "In ICML,",
    "year": 2003
  }, {
    "title": "Efficient errorcorrecting viterbi parsing",
    "authors": ["Amengual", "Juan C", "Vidal", "Enrique"],
    "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
    "year": 1998
  }, {
    "title": "Planning by probabilistic inference",
    "authors": ["Attias", "Hagai"],
    "venue": "In AISTATS,",
    "year": 2003
  }, {
    "title": "Tight Hardness Results for Maximum Weight Rectangles",
    "authors": ["Backurs", "Arturs", "Dikkala", "Nishanth", "Tzamos", "Christos"],
    "venue": "In International Colloquium on Automata, Languages, and Programming,",
    "year": 2016
  }, {
    "title": "An asynchronous hidden markov model for audio-visual speech recognition",
    "authors": ["Bengio", "Samy"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2003
  }, {
    "title": "Connectionist speech recognition: a hybrid approach, volume 247",
    "authors": ["Bourlard", "Herve A", "Morgan", "Nelson"],
    "venue": "Springer Science & Business Media,",
    "year": 2012
  }, {
    "title": "A dichotomy for regular expression membership testing",
    "authors": ["Bringmann", "Karl", "Grønlund", "Allan", "Larsen", "Kasper Green"],
    "venue": "arXiv preprint arXiv:1611.00918,",
    "year": 2016
  }, {
    "title": "Decoding Hidden Markov Models Faster Than Viterbi Via Online Matrix-Vector (max,+)-Multiplication",
    "authors": ["Cairo", "Massimo", "Farina", "Gabriele", "Rizzi", "Romeo"],
    "venue": "In Thirtieth AAAI Conference on Artificial Intelligence,",
    "year": 2016
  }, {
    "title": "Implementing EM and Viterbi algorithms for Hidden Markov Model in linear memory",
    "authors": ["Churbanov", "Alexander", "Winters-Hilt", "Stephen"],
    "venue": "BMC bioinformatics,",
    "year": 2008
  }, {
    "title": "Emotion recognition from facial expressions using multilevel hmm",
    "authors": ["Cohen", "Ira", "Garg", "Ashutosh", "Huang", "Thomas S"],
    "venue": "In Neural information processing systems,",
    "year": 2000
  }, {
    "title": "Deep learning for efficient discriminative parsing",
    "authors": ["Collobert", "Ronan"],
    "venue": "In AISTATS,",
    "year": 2011
  }, {
    "title": "Carpediem: Optimizing the viterbi algorithm and applications to supervised sequential learning",
    "authors": ["Esposito", "Roberto", "Radicioni", "Daniele P"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2009
  }, {
    "title": "Reduced space sequence alignment. Computer applications in the biosciences: CABIOS",
    "authors": ["Grice", "J Alicia", "Hughey", "Richard", "Speck", "Don"],
    "venue": "Acta Mathematica,",
    "year": 1997
  }, {
    "title": "How hard is it to approximate the best nash equilibrium",
    "authors": ["Hazan", "Elad", "Krauthgamer", "Robert"],
    "venue": "SIAM J. Comput.,",
    "year": 2011
  }, {
    "title": "Spoken language processing: A guide to theory, algorithm, and system development",
    "authors": ["Huang", "Xuedong", "Acero", "Alex", "Hon", "Hsiao-Wuen", "Foreword By-Reddy", "Raj"],
    "year": 2001
  }, {
    "title": "Large cliques elude the metropolis process",
    "authors": ["Jerrum", "Mark"],
    "venue": "Random Struct. Algorithms,",
    "year": 1992
  }, {
    "title": "Reducibility among combinatorial problems",
    "authors": ["Karp", "Richard M"],
    "venue": "In Complexity of computer computations,",
    "year": 1972
  }, {
    "title": "Segmental hidden markov models with random effects for waveform modeling",
    "authors": ["Kim", "Seyoung", "Smyth", "Padhraic"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2006
  }, {
    "title": "Faster online matrix-vector multiplication",
    "authors": ["Larsen", "Kasper Green", "Williams", "Ryan"],
    "venue": "In Proceedings of the Twenty-Eighth Annual ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2017
  }, {
    "title": "Gradient-based learning applied to document recognition",
    "authors": ["LeCun", "Yann", "Bottou", "Léon", "Bengio", "Yoshua", "Haffner", "Patrick"],
    "venue": "Proceedings of the IEEE,",
    "year": 1998
  }, {
    "title": "Design of Speech Recognition Co-Processor for the Embedded Implementation",
    "authors": ["Lee", "Peng", "Dong", "Ming", "Liang", "Weiqian", "Liu", "Runsheng"],
    "venue": "In Electron Devices and Solid-State Circuits,",
    "year": 2007
  }, {
    "title": "Design a co-processor for Output Probability Calculation in speech recognition",
    "authors": ["Li", "Peng", "Tang", "Hua"],
    "venue": "In Circuits and Systems,",
    "year": 2009
  }, {
    "title": "Speeding up HMM decoding and training by exploiting sequence repetitions",
    "authors": ["Lifshits", "Yury", "Mozes", "Shay", "Weimann", "Oren", "ZivUkelson", "Michal"],
    "year": 2009
  }, {
    "title": "A simple and fast secondary structure prediction method using hidden neural networks",
    "authors": ["Lin", "Kuang", "Simossis", "Victor A", "Taylor", "Willam R", "Heringa", "Jaap"],
    "year": 2005
  }, {
    "title": "Speeding up Bayesian HMM by the four Russians method",
    "authors": ["Mahmud", "Md Pavel", "Schliep", "Alexander"],
    "venue": "In International Workshop on Algorithms in Bioinformatics,",
    "year": 2011
  }, {
    "title": "Machine learning methods for classifying human physical activity from on-body accelerometers",
    "authors": ["Mannini", "Andrea", "Sabatini", "Angelo Maria"],
    "year": 2010
  }, {
    "title": "Acoustic modeling using deep belief networks",
    "authors": ["Mohamed", "Abdel-rahman", "Dahl", "George E", "Hinton", "Geoffrey"],
    "venue": "IEEE Transactions on Audio, Speech, and Language Processing,",
    "year": 2012
  }, {
    "title": "A coupled hmm for audio-visual speech recognition",
    "authors": ["Nefian", "Ara V", "Liang", "Luhong", "Pi", "Xiaobo", "Xiaoxiang", "Liu", "Mao", "Crusoe", "Murphy", "Kevin"],
    "venue": "In Acoustics, Speech, and Signal Processing (ICASSP),",
    "year": 2002
  }, {
    "title": "Conditional neural fields",
    "authors": ["Peng", "Jian", "Bo", "Liefeng", "Xu", "Jinbo"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2009
  }, {
    "title": "A tutorial on hidden markov models and selected applications in speech recognition",
    "authors": ["Rabiner", "Lawrence R"],
    "venue": "Proceedings of the IEEE,",
    "year": 1989
  }, {
    "title": "On dynamic shortest paths problems",
    "authors": ["Roditty", "Liam", "Zwick", "Uri"],
    "venue": "Algorithms–ESA",
    "year": 2004
  }, {
    "title": "Fast inference and learning in large-state-space hmms",
    "authors": ["Siddiqi", "Sajid M", "Moore", "Andrew W"],
    "venue": "In Proceedings of the 22nd international conference on Machine learning,",
    "year": 2005
  }, {
    "title": "Reduced space hidden Markov model training",
    "authors": ["Tarnas", "Christopher", "Hughey", "Richard"],
    "year": 1998
  }, {
    "title": "Error bounds for convolutional codes and an asymptotically optimum decoding algorithm",
    "authors": ["Viterbi", "Andrew J"],
    "venue": "Information Theory, IEEE Transactions on,",
    "year": 1967
  }, {
    "title": "Faster all-pairs shortest paths via circuit complexity",
    "authors": ["Williams", "Ryan"],
    "venue": "In Proceedings of the 46th Annual ACM Symposium on Theory of Computing,",
    "year": 2014
  }, {
    "title": "Subcubic equivalences between path, matrix and triangle problems",
    "authors": ["Williams", "Virginia Vassilevska", "Ryan"],
    "venue": "In Foundations of Computer Science (FOCS),",
    "year": 2010
  }],
  "id": "SP:bb8371a61b3d2368be5e7c5866f5b2267597568a",
  "authors": [{
    "name": "Arturs Backurs",
    "affiliations": []
  }, {
    "name": "Christos Tzamos",
    "affiliations": []
  }],
  "abstractText": "The classic algorithm of Viterbi computes the most likely path in a Hidden Markov Model (HMM) that results in a given sequence of observations. It runs in time O(Tn) given a sequence of T observations from a HMM with n states. Despite significant interest in the problem and prolonged effort by different communities, no known algorithm achieves more than a polylogarithmic speedup. In this paper, we explain this difficulty by providing matching conditional lower bounds. Our lower bounds are based on assumptions that the best known algorithms for the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight k-Clique problem in edge-weighted graphs are essentially tight. Finally, using a recent algorithm by Green Larsen and Williams for online Boolean matrix-vector multiplication, we get a 2 √ logn) speedup for the Viterbi algorithm when there are few distinct transition probabilities in the HMM.",
  "title": "Improving Viterbi is Hard: Better Runtimes Imply Faster Clique Algorithms"
}