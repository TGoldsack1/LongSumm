{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Stochastic gradient algorithms (Robbins & Monro, 1951; Bottou & Cun, 2004; Srebro & Tewari, 2010; Moulines & Bach, 2011; Duchi et al., 2011) and online learning algorithms (e.g. (Bottou & Cun, 2004; Srebro & Tewari, 2010; Shalev-Shwartz et al., 2011; Hazan & Kale, 2012; Rakhlin et al., 2012a; Orabona, 2014)) can update the model sequentially with computationally cheap per-iteration costs, making them amenable for large-scale streaming data analysis. Most of the existing studies focus on classification error or prediction accuracy where the empirical objective function is a summation of losses over individual samples.\nHowever, accuracy is not suitable for important learning tasks such as imbalanced classification (Elkan, 2001). Area under the ROC curve (AUC) (Hanley & McNeil, 1982; Bradley, 1997; Fawcett, 2006) is a widely used metric\n1Department of Mathematics and Statistics, SUNY at Albany, Albany, NY, USA 2Department of Computer Science, SUNY at Albany, Albany, NY, USA. Correspondence to: Yiming Ying <yying@albany.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nfor measuring the performance in these tasks. In particular, minimization of the rank loss in bipartite ranking is equivalent to maximizing the AUC criterion (Kotlowski et al., 2011). There are considerable efforts (Herschtal & Raskutti, 2004; Rakotomamonjy, 2004; Joachims, 2005; Zhang et al., 2012) that have been devoted to developing batch AUC maximization algorithms. These appealing algorithms have a convergence rate ofO ( min ( 1 ε , 1√ λε )) , but have a high per-iteration cost of O(nd). Here, λ, n, and d are the regularization parameter, the number of samples, and the dimension of the data, respectively. Such algorithms train the model on the whole training data which are not suitable for analyzing massive streaming data that arrives sequentially.\nRecently, there is considerable progress on online learning algorithms (Zhao et al., 2011; Wang et al., 2012; Kar et al., 2013) for AUC maximization. Due to the fact that the empirical risk for AUC maximization is a summation of pairwise losses over pairs of samples, such algorithms, at time t, need to pair the currently-received data (xt, yt) with all previous data {(xi, yi) : i = 1, . . . , t − 1}. As such, one needs to access all previous examples which leads to expensive space and per-iteration complexity of O(td) for ddimensional data at iteration t. The studies (Zhao et al., 2011; Kar et al., 2013) introduced the technique of buffering to alleviate the above hurdle which reduces the periteration space and time complexity toO(Bd).However, to achieve good generalization performance, the size B needs to be sufficiently large which is typically of O( √ T ) if the size T of the finite training data is known. The work (Gao et al., 2013) requires to update the covariance matrix of the training data with the space and per-iteration complexity O(d2) which is inefficient for high-dimensional data.\nThe most recent work (Ying et al., 2016) reformulated the problem of AUC maximization with the least square loss as a stochastic saddle point problem (SPP). They proposed an online learning algorithm which conducts stochastic gradient descent/ascent on both the primal and dual variables. The convergence of such first-order primal-dual algorithms for solving stochastic SPPs is at most O( 1√\nt ) as argued\nin (e.g. Chen et al. (2014)). This is, however, inferior to the optimal rate of O( 1t ), up to a logarithmic term, of SGDs for the accuracy as a performance measure (Rakhlin et al., 2012a; Shamir & Zhang, 2013). In addition, the work\n(Ying et al., 2016) only considered smooth penalty terms (i.e., the Frobenius norm).\nIn this paper, we propose a novel stochastic proximal algorithm for AUC maximization which we refer to as SPAM. The algorithm SPAM applies to general non-smooth regularization terms. In particular, we show under the assumption of strong convexity that SPAM can achieve a convergence rate of O( log tt ). The time and space complexities of our new algorithm are of one datum. To the best of our knowledge, this is the first stochastic (online) algorithm for AUC maximization with convergence rate of O( log tt ) while per-iteration and space complexities are of one datum O(d).\nThe paper is organized as follows. The next section introduces the problem of AUC maximization and our proposed algorithm. Section 3 establishes the convergence of our algorithm. We validate the performance of our algorithm in Section 4. The paper is concluded in Section 5."
  }, {
    "heading": "2. Formulation and Algorithm",
    "text": "For a linear scoring function g(x) = w>x, its AUC score, denoted by AUC(w), is the probability of a random positive sample ranking higher than a random negative sample (Hanley & McNeil, 1982; Clémençon et al., 2008). To be specific, suppose z = (x, y) and z′ = (x′, y′) are independently drawn from an unknown distribution ρ on Z = X × Y , where X ⊆ Rd is a bounded domain and Y = {±1}. Then, the AUC score is given by\nAUC(w) = Pr(w>x ≥ w>x′|y = 1, y′ = −1) = E [ I[w>(x−x′)≥0] ∣∣y = 1, y′ = −1]. (1) In practice, one often replaces the indicator function I[·] by a convex surrogate loss φ : R → R+ which satisfies I[w>(x−x′)<0] ≤ φ(w>(x − x′)). Common choices are the least square loss, φ(s) = (1 − s)2, or the hinge loss, φ(s) = (1 − s)+. Throughout the paper, we focus on the least square loss as the hinge loss is not statistically consistent (Gao & Zhou, 2015). To summarize, we consider the following regularization framework for AUC maximization:\nmin w∈Rd\n{ p(1− p)E [ (1−w>(x− x′))2 ∣∣y = 1, y′ = −1] + Ω(w) } . (2)\nHere, p = Pr(y = 1) and Ω(·) is a convex penalty term. The constant p(1 − p) is introduced for simplicity of formulation to cancel the denominator appeared in the conditional expectation E [ (1 − w>(x −\nx′))2 ∣∣y = 1, y′ = −1] = 1p(1−p) ∫∫ (1 − w>(x − x′))2I[y=1]I[y′=−1]dρ(x, y)dρ(x′, y′). The paper (Ying\net al., 2016) considered the case when w is restricted to a bounded ball with radius R, i.e., Ω(w) = 0 if ‖w‖ ≤ R and Ω(w) = ∞ otherwise. Throughout this paper, we assume that Ω is strongly convex with parameter β > 0, i.e., for any w,w′ ∈ Rd, Ω(w) ≥ Ω(w′)+〈∂Ω(w′),w−w′〉+ β 2 ‖w −w\n′‖2. Examples of such penalty terms include the Frobenius norm, Ω(w) = β‖w‖2, or elastic net (Zou & Hastie, 2005), Ω(w) = β‖w‖2 + ν‖w‖1, where β and ν are positive regularization parameters."
  }, {
    "heading": "2.1. Equivalent Formulation",
    "text": "We can establish a similar theorem for formulation. Here, the proof is generalized from (Ying et al., 2016) for the general regularization framework (2). The present proof is much simpler and more intuitive.\nTheorem 1. The AUC optimization (2) in the linear case is equivalent to\nmin w,a,b max α∈R\n{ E[F (w, a, b, α; z)] + Ω(w) } , (3)\nwhere the expectation is with respect to z = (x, y), and F (w, a, b, α; z) = (1 − p)(w>x − a)2I[y=1] + p(w>x − b)2I[y=−1] + 2(1 + α)w>x(pI[y=−1] − (1 − p)I[y=1]) − p(1− p)α2.\nProof. Specifically, the double integral mainly comes from the multiplication of two single integrals:\nE[(1−w>(x− x′))2|y = 1, y′ = −1] = 1− 2E[w>x|y = 1] + 2E[w>x′|y′ = −1] + (E[w>x|y = 1]− E[w>x′|y′ = −1])2\n+ Var[w>x|y = 1]) + Var[w>x′|y′ = −1]). (4)\nObserve the fact that\n(E[w>x|y = 1]− E[w>x′|y′ = −1])2 = max α {−α2\n+ 2α(E[w>x′|y′ = −1]− E[w>x|y = 1])}. (5)\nIn addition,\nVar[w>x|y = 1] = min a E[(w>x− a)2|y = 1], (6)\nand\nVar[w>x′|y′ = −1] = min b E[(w>x′−b)2|y′ = −1]. (7)\nIt is easy to see that the optima for (6), (7), and (5) are respectively achieved at\na(w) = w>E[x|y = 1], b(w) = w>E[x|y = −1], (8)\nα(w) = w>(E[x|y′ = −1]− E[x|y = 1]). (9)\nAlgorithm 1 Stochastic Proximal AUC Maximization (SPAM)\nInput: Step sizes {ηt > 0 : t ∈ N} Initialize w1 ∈ Rd. for t = 1 to T do\nReceive sample zt = (xt, yt) Compute a(wt), b(wt), and α(wt) according to (8) and (9). ŵt+1 = wt − ηt∂1F (wt, a(wt), b(wt), α(wt); zt) wt+1 = proxηtΩ(ŵt+1)\nend for\nPutting the above observations together, one can see now that, for any w, there holds\np(1− p)E[(1−w>(x− x′))2|y = 1, y′ = −1] = p(1− p) + min\na,b max α\nE[F (w, a, b, α; z)].\nThis completes the proof.\nThe problem (3) is a standard stochastic saddle point problem (see e.g. (Nemirovski et al., 2009)). It is easy to show that its objective function is convex with respect to w, a, and b and concave with respect to α. We later refer to w, a, and b as primal variables and α as a dual variable."
  }, {
    "heading": "2.2. Proposed Algorithm and Interpretation",
    "text": "The algorithm proposed in (Ying et al., 2016) essentially performs stochastic gradient descent on the primal variables w, a, and b and stochastic gradient ascent on the dual variable α. The critical observation in this paper is that, for fixed w, the optima for a, b, and α in saddle formulation (3) has the exact formulations as given by (8) and (9).\nThis motivates us to conduct stochastic gradient descent only on w, while a, b, and α are then updated using equations (8) and (9), rather than doing stochastic gradient updates. More specifically, upon receiving data zt, we update w by\nwt+1 = wt − ηt∂1F (wt, a(wt), b(wt), α(wt); zt), (10)\nwhere ∂1F denotes the gradient with respect to the first argument and the ηt’s are the step sizes. To accommodate the possibly non-smooth penalty term Ω(·), the next step is to perform a proximal mapping. Specifically, the proximal mapping associated with a convex function Ω : Rd → R is defined as\nproxηtΩ(u) = arg min{ 1\n2 ‖u−w‖2 + ηtΩ(w)}. (11)\nThe pseudo-code of the proposed algorithm is outlined in Algorithm 1. This new online algorithm has per-iteration\nand storage cost of one datum. In the algorithm, it is assumed that the probability of class 1, i.e., p = Pr(y = 1), and E(x|y = 1) and E(x|y = −1) are known. In practice, using a portion of the training data, one can efficiently estimate p by the proportion of samples of class 1, and the population means E(x|y = 1) and E(x|y = −1) by sample means.\nBefore we present the rigorous convergence rate of SPAM, let us briefly illustrate the intuition as to why it can be expected to achieve a faster rate ofO( 1t ) in contrast toO( 1√ t ) of SOLAM in (Ying et al., 2016). To see this, let us present a simple but critical lemma as follows. For this purpose, let f(w) = p(1 − p)E [ (1 −w>(x − x′))2\n∣∣y = 1, y′ = −1] which is identical to mina,b maxα E[F (w, a, b, α; z)]. Lemma 1. Let wt be given by SPAM described in Algorithm 1. Then, we have that\n∂f(wt) = Ezt [∂1F (wt, a(wt), b(wt), α(wt); zt)],\nwhere Ezt [·] denotes the expectation with respect to zt = (xt, yt).\nProof. Denote by ∂iF the partial derivative of F with respect to the ith argument. Applying the chain rule gives\n∂wf(wt) = ∂wEzt [F (wt, a(wt), b(wt), α(wt); zt)] = Ezt [ ∂wF (wt, a(wt), b(wt), α(wt); zt) ] = Ezt [ ∂1F (wt, a(wt), b(wt), α(wt); zt)\n] + Ezt [ ∂2F (wt, a(wt), b(wt), α(w); zt) ∂wa(wt)\n] + Ezt [ ∂3F (wt, a(wt), b(wt), α(wt); zt) ∂wb(wt)\n] + Ezt [ ∂4F (wt, a(wt), b(wt), α(wt); zt)∂wα(wt) ] . (12)\nThe second inequality of interchanging differentiation and integration follows from the Leibniz’s Integral rule since F (wt, a(wt), b(wt), α(w); zt) is quadratic and the input space X is a bounded domain. In the last equality, the fact that wt only depends on {z1, z2, . . . , zt−1} implies that Ezt [ ∂2F (wt, a(wt), b(wt), α(w); zt) ∂wa(wt) ] =\n∂2Ezt [ F (wt, a(wt), b(wt), α(w); zt) ] [E(x|y = 1)].\nSince a(wt) is the minimizer of mina,b maxα Ezt [F (wt, a, b, α; zt)], the first order optimality condition gives, for any b and α, that ∂2Ezt [ F (wt, a(wt), b, α; zt) ] = 0. Therefore we have\nthat ∂2Ezt [ F (wt, a(wt), b(wt), α(wt); zt) ] = 0. Hence,\nEzt [ ∂2F (wt, a(wt), b(wt), α(w); zt) ∂wa(wt) ] = 0. Likewise, the third and fourth terms on the righthand side of (12) equal to zero. This completes the proof of the lemma.\nThe above lemma implies, conditioned on {z1, . . . , zt−1}, that ∂1F (wt, a(wt), b(wt), α(wt); zt) is an unbiased estimator of the true gradient ∂wf(wt). This strongly indicates that SPAM will have a fast convergence rate similar to SGD algorithms (Rakhlin et al., 2012a; Shalev-Shwartz, 2012) for a strongly convex objective function. We will leverage this intuition to prove the fast convergence rate in the next section.\nMore related work: We should point out that our proposed algorithm has similar spirit to the online forward-backward splitting (Duchi & Singer, 2009) and stochastic proximal gradient methods (Rosasco et al., 2014). However, there are two main differences between our proposed algorithm and their algorithms. Firstly, these algorithms focused on the accuracy performance where the objective function is a single summation/integral over individual samples. Secondly, the convergence proofs in (Duchi & Singer, 2009; Rosasco et al., 2014) critically depend on the boundedness assumptions: the iterates and the stochastic gradients are uniformly bounded or the conditional variance of the stochastic gradient is bounded by the square norm of the true gradient plus a constant, which may not be true and is difficult to verify in practice. Our proof techniques for the convergence of SPAM do not need these boundedness assumptions as shown in the next section. Lastly, the very recent work (Palaniappan & Bach, 2016) developed an appealing stochastic primal-dual algorithm for saddle point problems with convergence rate of O( 1T ) which, as a by-product, can be applied to AUC maximization with least square loss. However, their saddle point formulation is different from (3) and the algorithm there needs to assume strong convexity on both the primal and dual variables. In addition, the algorithm has per-iteration complexityO(n+d) where n is the total number of training samples and d is the dimension of the data."
  }, {
    "heading": "3. Convergence Analysis",
    "text": "Before we present the convergence rate of SPAM, let us introduce some notations. Recall that f(w) = p(1 − p)E [ (1 − w>(x − x′))2\n∣∣y = 1, y′ = −1]. Let w∗ denote the optimal solution of formulation (2), i.e.,\nw∗ = arg min w∈Rd {f(w) + Ω(w)}.\nDefine E[‖G(w∗; z)− ∂f(w∗)‖2] = σ2∗, (13)\nwhere, for notional simplicity, we denote G(w; z) = ∂1F (w, a(w), b(w), α(w); z). The convergence results are established based on the following two assumptions:\n• (A1) Assume that Ω(·) is β-strongly convex.\n• (A2) There exists an M > 0 such that ‖x‖ ≤ M for any x ∈ X .\nFurthermore, let Cβ,M := β128M4 , C̃β,M = β\n(1+ β 2\n128M4 )2\n,\nand C̄β,M = C̃β,MCβ,M = 128M 4β2\n(128M4+β2)2 . We use the conventional notation that for any T ∈ N, NT = {1, . . . , T}.\nThe proofs for Theorems 2 and 3 critically depend on the following lemma which clearly describes how ‖wt −w∗‖ evolves along time t.\nLemma 2. Under the assumptions of (A1) and (A2), let {wt : t ∈ NT+1} be generated by SPAM. Then, the following statements hold true.\n(i) For any t ∈ N there holds\nE[‖wt+1 −w∗‖2]\n≤ 1 + 128M 4η2t\n(1 + ηtβ)2 E[‖wt −w∗‖2] + 2σ2∗η2t . (14)\n(ii) If, furthermore, 0 < ηt ≤ Cβ,M := β\n128M4 for any\nt ∈ NT , then we have , for any t ∈ NT ,\nE[‖wt+1 −w∗‖2] ≤ ( 1− C̃β,M ηt ) E[‖wt −w∗‖2] + 2σ2∗η2t . (15)\nProof. Recall that w∗ is the optimal solution of (2). One can directly derive from the first-order optimality condition using subgradients that, for any ηt > 0,\nw∗ = proxηtΩ(w ∗ − ηt∂f(w∗)).\nThe above observation together with the definition of wt+1 in algorithm SPAM yields that\n‖wt+1 −w∗‖2\n= ‖proxηtΩ(ŵt+1)− proxηtΩ(w ∗ − ηt∂f(w∗)‖2. (16)\nNow since ηtΩ(w) is ηtβ-strongly convex due to (A1), then by Proposition 23.11 in (Bauschke & Combettes, 2011), proxηtΩ(·) is (1 + ηtβ)-cocoercive, i.e., for any u and w, there holds 〈u −w, proxηtΩ(u) − proxηtΩ(w)〉 ≥ (1 + ηtβ)‖proxηtΩ(u)− proxηtΩ(w)‖\n2. This, by CauchySchwartz inequality, implies that\n‖proxηtΩ(u)− proxηtΩ(w)‖ ≤ 1\n1 + ηtβ ‖u−w‖.\nPutting this back into (16), we get\n‖wt+1 −w∗‖2\n= ‖proxηtΩ(ŵt+1)− proxηtΩ(w ∗ − ηt∂f(w∗)‖2 ≤ 1 (1 + ηtβ)2 ‖ŵt+1 − (w∗ − ηt∂f(w∗))‖2 = 1\n(1 + ηtβ)2 ‖(wt −w∗)− ηt(G(wt, zt)− ∂f(w∗))‖2,\nwhere in the last equality we recall the notation that G(wt; zt) = ∂1F (wt, a(wt), b(wt), α(wt); zt). Now taking the expectation of both sides of the above inequality, and expanding out the right hand side, we have\nE[‖wt+1 −w∗‖2] ≤ 1\n(1 + ηtβ)2\n( E[‖wt −w∗‖2]\n− 2ηtE[〈wt −w∗, G(wt; zt)− ∂f(w∗)〉] + η2tE[‖G(wt; zt)− ∂f(w∗)‖2 ) . (17)\nWe first bound the middle term of the righthand side of (17). By Lemma 1, we know that\nE[〈wt −w∗, G(wt; zt)− ∂f(w∗)〉] = E[〈wt −w∗,Ezt [G(wt; zt)]− ∂f(w∗)〉] = E[〈wt −w∗, ∂f(wt)− ∂f(w∗)〉] ≥ 0, (18)\nwhere the last inequality follows from the convexity of f .\nFor the last term on the righthand side of (17), we proceed as follows: E[‖G(wt; zt)−∂f(w∗)‖2] ≤ 2E[‖G(wt; zt)− G(w∗; zt)‖2] + 2E[‖G(w∗; zt) − ∂f(w∗)‖2]. Note that G(wt; zt) is a linear function of wt. So by the assumption that ‖xt‖ ≤M , it is easy to see that\n‖G(wt; zt)−G(w∗; zt)‖ ≤ 4M2(1− p)‖wt −w∗‖I[yt=1] + 4M2p‖wt −w∗‖I[yt=−1] + 4M2|p− I[yt=1]|‖wt −w\n∗‖ ≤ 8M2‖wt −w∗‖. (19)\nFurthermore, from (13), we have E[‖G(w∗; zt) − ∂f(w∗)‖2] = Ezt [‖G(w∗; zt)− ∂f(w∗)‖2] = σ2∗. Hence,\nE[‖G(wt; zt)−∂f(w∗)‖2] ≤ 2(8M2)2E[‖wt −w∗‖2] + 2σ2∗. (20)\nPutting together (17), (18) and (20), we get\nE[‖wt+1 −w∗‖2]\n≤ 1 (1 + ηtβ)2\n( E[‖wt −w∗‖2]\n+ 2(8M2)2η2tE[‖wt −w∗‖2] + 2σ2∗η2t )\n≤ 1 + 128M 4η2t\n(1 + ηtβ)2 E[‖wt −w∗‖2] + 2σ2∗η2t . (21)\nThis finishes part (i) of the lemma.\nFor the second part of the lemma, notice that ηt ≤ Cβ,M := β 128M4 . The coefficient in (21) can be rewritten as follows:\n1 + 128M4η2t (1 + ηtβ)2\n= 1− ( 1− 1 + 128M 4η2t\n(1 + ηtβ)2 ) = 1− [2β + β\n2ηt − 128M4ηt]ηt (1 + ηtβ)2 . (22)\nApplying the assumption that ηt ≤ β\n128M4 gives that\n[2β + β2ηt − 128M4ηt] (1 + ηtβ)2 ηt ≥ β( 1 + β 2\n128M4 )2 ηt. (23) In addition, notice that β128M4 ≤ ( 1+ β 2 128M4 )2 β . This implies the assumption ηt ≤ β128M4 guarantees that 1 − β(\n1+ β 2\n128M4 )2 ηt ≥ 0. Combining together (22) with (23) yields the desired result in part (ii). This completes the proof of the lemma.\nThe following lemma is from (Smale & Yao, 2006) and will be used to prove Theorems 2 and 3. Lemma 3. For any 0 < ν ≤ 1, 0 < α < 1, t < T , and 0 < θ ≤ 1, the following estimations hold true.\n(i) ∑T j=t+1 j −α ≥ 11−α [(T + 1) 1−α − (t+ 1)1−α],\n(ii) ∑T−1 t=1 1 t2α exp { − ν ∑T j=t+1 j −α } ≤ 18νTα +\n9T 1−α (1−α)21−α exp{− ν(1−2α−1) 1−α (T + 1) 1−α},\n(iii) e−cx ≤ ( b ce )b x−b for x > 0, c > 0 and b > 0.\nWe now present the convergence analysis. Theorem 2. Under the assumptions (A1), (A2), and choosing step sizes with some θ ∈ (0, 1) in the form of { ηt = Cβ,M tθ : t ∈ N }\n, the algorithm SPAM achieves the following:\nE[‖wT+1 −w∗‖2] ≤ [ exp ( C̄β,M\n1− θ )( θ C̄β,Me ) θ 1−θE[‖w1 −w∗‖2]\n+ 2σ2∗C 2 β,M ( 9 (1− θ)21−θ ( 1 C̄β,M (1− 2θ−1)e ) 1 1−θ\n+ 18 C̄β,M + 1 )] T−θ.\nProof. Denote rt = E[‖wt − w∗‖2]. The choice of the step sizes ηt = Cβ,M tθ\nsatisfies the condition in Lemma 2, i.e. ηt ≤ Cβ,M . Recall that Cβ,M = β128M4 , C̃β,M =\nβ\n(1+ β 2\n128M4 )2\n, and C̄β,M = C̃β,MCβ,M which guarantees\nthat 1 − C̃β,Mηt ≥ 1 − C̃β,MCβ,M = 1 − C̄β,M ≥ 0 for any t ∈ NT . Then, it is easy to see from (15) that, after T iterations, there holds\nrT+1 ≤ r1 T∏ k=1 ( 1− C̃β,Mηk ) + 2σ2∗\nT−1∑ k=1 T∏ i=k+1 ( 1− C̃β,M ηi ) η2k + 2σ 2 ∗η 2 T . (24)\nThe first term on the right hand side can be bounded using the fact that 1− x ≤ exp(−x) for all x ∈ R, giving that\nr1 T∏ k=1 ( 1− C̃β,Mηk ) = r1 T∏ k=1 ( 1− C̃β,MCβ,M/kθ ) ≤ r1 exp ( − C̄β,M\nT∑ k=1 1 kθ ) , (25)\nwhere C̄β,M = C̃β,MCβ,M = 128M 4β2\n(128M4+β2)2 .Applying part (i) in Lemma 3 gives that\nr1 exp ( − C̄β,M T∑ k=1 1 kθ ) ≤ r1 exp ( C̄β,M 1− θ [ 1− (T + 1)1−θ\n]) = r1 exp ( C̄β,M 1− θ ) exp ( − C̄β,M 1− θ (T + 1)1−θ ) .\nApplying part (iii) in Lemma 3 with b = θ1−θ , x = (T + 1)1−θand c = C̄β,M1−θ yields that\nexp ( − C̄β,M\n1− θ (T + 1)1−θ\n) ≤ ( θ\nC̄β,Me\n) θ 1−θ\n(T + 1)−θ.\nPutting the above two inequalities back into (25), we have\nr1 T∏ k=1 ( 1− C̃β,Mηk ) ≤ r1 exp ( C̄β,M 1− θ )( θ C̄β,Me ) θ 1−θ T−θ. (26)\nTo bound the second term on the righthand side of (24), we proceed again as in the first term:\nT−1∑ k=1 T∏ i=k+1 ( 1− C̃β,Mηi ) η2k\n= C2β,M T−1∑ k=1 1 k2θ T∏ i=k+1 ( 1− C̄β,M iθ )\n≤ C2β,M T−1∑ k=1 1 k2θ exp ( − C̄β,M T∑ i=k+1 1 iθ ) . (27)\nApplying Lemma 3 (ii) with ν = C̄β,M and α = θ gives that the above is bounded by T−1∑ k=1 1 k2θ exp ( − C̄β,M T∑ i=k+1 1 iθ\n) ≤ 9T 1−θ\n(1− θ)(21−θ) exp\n( − C̄β,M (1− 2 θ−1)\n1− θ (T + 1)1−θ ) + 18\nC̄β,MT θ . (28)\nAnd again, applying Lemma 3 (iii) with b = 11−θ , x = (T + 1)1−θ and c = C̄β,M (1−2 θ−1)\n1−θ to (28) gives that\nexp ( − C̄β,M (1− 2 θ−1)\n1− θ (T + 1)1−θ ) ≤ ( 1 C̄β,M (1− 2θ−1)e ) 1 1−θ (T + 1)−1. (29)\nPutting (28) and (29) back into (27), we have\n2σ2∗ T−1∑ k=1 T∏ i=k+1 ( 1− C̃β,M ηi ) η2k\n≤ 2σ2∗C2β,M [ 9 (1− θ)21−θ ( 1 C̄β,M (1− 2θ−1)e ) 1 1−θ\n+ 18\nC̄β,M\n] T−θ. (30)\nThe last term on the righthand side of (24) is straightforward: 2σ2∗η 2 T ≤ 2σ2∗C2β,MT−θ. This, in combination of (26) and (30), yields the desired result.\nThis theorem indicates the last output of SPAM achieves the convergence rate ofO(T−θ) with polynomial decaying step sizes in the form of ηt = O(t−θ) for θ ∈ (0, 1). For θ = 1, we can obtain the following result.\nTheorem 3. Under the assumptions of (A1), (A2), and choosing step sizes {ηt = [C̃β,M (t + 1)]−1 : t ∈ N}, the algorithm SPAM achieves the following:\nE[‖wT+1 −w∗‖2]\n≤ ( t0E[‖wt0 −w∗‖2] ) 1 T + 4σ2∗\nC̃2β,M\nlog T\nT .\nwhere t0 = max ( 2, ⌈ 1 + (128M 4+β2)2\n128M4β2\n⌉) .\nProof. The condition that t ≥ t0 guarantees the assumption in part (ii) of Lemma 2 that ηt = [ C̃β,M (t+ 1) ]−1 ≤ Cβ,M is satisfied. Now by letting rt = E[‖wt −w∗‖2] we have\nrt+1 ≤ ( 1− C̃β,M ηt ) rt + 2σ 2 ∗η 2 t . (31)\nThen, we have\nrT+1 ≤ rt0 T∏\nk=t0\n( 1− C̃β,Mηk ) + 2σ2∗η 2 T\n+ 2σ2∗ T−1∑ k=t0 T∏ i=k+1 ( 1− C̃β,Mηi ) η2k. (32)\nThe first term on the right hand side of the above inequality can be estimated as follows: rt0 ∏T k=t0 (1 − C̃β,Mηk) =\nrt0 ∏T k=t0 k k+1 = t0rt0 T+1 ≤ t0rt0 T . For the second term on the righthand side of (32), there holds 2σ2∗ηT =\n2σ2∗ C̃2β,M (T+1) 2 ≤ 2σ 2 ∗ C̃2β,MT . To bound the\nthird term on the righthand side of (32), we can do the following ∑T−1 k=t0 ∏T i=k+1(1 − C̃β,Mηi)η2k =\nC̃−2β,M ∑T−1 k=t0 ∏T−1 i=k+1 ( 1 − 1i+1 ) 1 (k+1)2 = C̃−2β,M 1 T ∑T−1 k=t0 1 k+1 ≤ C̃ −2 β,M log(T−1)−log t0 T ≤ C̃−2β,M log T T . Putting all the above estimations together yields the desired result.\nThe convergence of SPAM proved in the above theorem shows that it can achieve O( log TT ). The convergence rate ofO( 1T ) could be obtained using averaging schemes developed by (Lacoste-Julien et al., 2012; Rakhlin et al., 2012b; Shamir & Zhang, 2013).\nThe term E[‖wt0 − w∗‖2] can indeed be estimated as follows if ηt = [C̃β,M (t + 1)]−1 for t ∈ N. From part (i) of Lemma 2, we have, for any t ∈ N, E[‖wt+1 − w∗‖2] ≤ 1+128M 4η2t (1+ηtβ)2\nE[‖wt − w∗‖2] + 2σ2∗η2t ≤ (1 + 128M4η2t )E[‖wt − w∗‖2] + 2σ2∗η 2 t . Therefore, E[‖wt0 − w∗‖2] ≤ ∏t0−1 k=1 (1 +\n128M4η2k) + 2σ 2 ∗ ∑t0−1 k=1 ∏t0−1 j=k (1 + 128M\n4η2j )η 2 k ≤(∏t0−1\nk=1 (1+128M 4η2k) )( 1+2σ2∗ ∑t0−1 k=1 η 2 k ) .Notice that∏t0−1\nk=1 (1+128M 4η2k) ≤ exp\n( 128M4\nC̃2β,M\n∑t0−1 k=1 (k+1) −2 ) ≤\nexp ( 128M4\nC̃2β,M ). and 2σ2∗\n∑t0−1 k=1 η 2 k =\n2σ2∗ C̃2β,M\n∑t0−1 k=1 (k +\n1)−2 ≤ 2σ 2 ∗\nC̃2β,M . Hence, one can have the following bound\ndepending on β and M :\nE[‖wt0 −w∗‖2] ≤ 2σ2∗\nC̃2β,M + exp (128M4 C̃2β,M )."
  }, {
    "heading": "4. Experiments",
    "text": "In this section, we report the experimental evaluation of SPAM by comparing it against existing algorithms for AUC optimization.\nIn particular, we use SPAM-L2 to denote SPAM with the Frobenius norm, i.e., Ω(w) = β2 ‖w‖\n2. The solution to the proximal step using the Frobenius norm is very straight forward. The other version, SPAM-NET, uses the elastic net norm (Zou & Hastie, 2005), i.e., Ω(w) = β2 ‖w‖\n2 + β1‖w‖1. The proximal step can be written as\narg min w {1 2 ∥∥∥∥w − ŵt+1ηtβ + 1 ∥∥∥∥2 + ηtβ1ηtβ + 1‖w‖1},\nfor which the optimal solution is the soft-thresholding operator (e.g. Parikh et al. (2014)).\nWe compare our algorithms with both batch and online AUC optimization algorithms. To ensure a fair comparison with (Ying et al., 2016), the algorithm SOLAM was modified to include the Frobenius-norm regularization term instead of the original bounded restriction on the norm of ‖w‖. We also compare our algorithm against the one-pass AUC optimization algorithm (Gao et al., 2013) with the least square loss and the OAMseq and OAMgra algorithms (Zhao et al., 2011) with hinge loss. Lastly, we include the B-LS-SVM algorithm (Joachims, 2006), a batch learning algorithm for AUC maximization with least square loss.\nTable 1 summarizes the details of each of the data sets we used for comparison. All of these datasets are available to download from the LIBSVM (Chang & Lin, 2011) and UCI machine learning repository (Frank & Asuncion, 2010). It is worthy of noting that some of the datasets are multi-class. We converted them to binary data by randomly partitioning the data into two groups, where each group includes the same number of classes.\nWe used 80% of the data for training and the remaining 20% for testing. The results are based on 20 runs for each dataset for which we used to calculate the average AUC score and standard deviation. To determine the proper parameters for each dataset, we conduct 5-fold cross validation on the training sets to determine the parameter β ∈ 10[−5:5] for SPAM-L2 and β1 ∈ 10[−5:5] for SPAMNET. All experiments were conducted with MATLAB and the MATLAB codes for the compared methods were obtained from the authors.\nClassification performance on all of the data sets is summarized in Table 2. SPAM-L2 and SPAM-NET both achieve a similar performance as the other state of the art AUC maximization algorithms in both the online and batch settings. This validates the algorithms we proposed in this paper. The data set sector shows the advantage of using elastic net. Next, we compared the CPU running time of SPAM-\nL2 versus SOLAM and the OPAUC algorithm. We did not compare the running time of SPAM against OAM (Zhao et al., 2011) since it used hinge loss. It was observed that the running time is inferior to OPAUC as shown in (Gao et al., 2013) and to SOLAM (Ying et al., 2016).\nThe main advantage of SPAM is the running efficiency. As we pointed out in the introduction, it has a faster convergence rate of O( 1t ) than SOLAM’s convergence rate of O( 1√\nt ), and its per-iteration running time and space complexity are linear in data dimension. The running time performance against OPAUC and SOLAM is depicted in Figure 1 on splice, usps and a9a datasets. Theses results show that SPAM demonstrates a competitive performance while achieving a faster rate of performance."
  }, {
    "heading": "5. Conclusion",
    "text": "In this paper, we proposed a novel stochastic proximal algorithm (SPAM) for AUC maximization with general penalty terms. We showed that the algorithm can achieve a convergence rate of O(1/T ) up to a logarithmic term for\nstrongly convex objective functions while the space and per-iteration complexity are of one datum.\nThere are several directions for future work. Firstly, it would be very interesting to extend the ideas of this paper to design stochastic variance reduction algorithms (Johnson & Zhang, 2013) and stochastic primal-dual algorithms (Zhang & Xiao, 2017) for AUC maximization, which can achieve the linear convergence rate. Secondly, it remains unclear to us whether SPAM can achieve convergence rate O(1/T ) without strong convexity (e.g. SPAM-L2 with β = 0). One possible approach is to adapt the proof techniques in (Bach & Moulines, 2013; Yang & Lin, 2015) to the setting of AUC maximization."
  }, {
    "heading": "Acknowledgement",
    "text": "Yiming Ying is supported by the Simons Foundation (#422504) and the 2016-2017 Presidential Innovation Fund for Research and Scholarship (PIFRS) program from SUNY Albany. Siwei Lyu is supported by the National Science Foundation (NSF, Grant IIS1537257)."
  }],
  "year": 2018,
  "references": [{
    "title": "Non-strongly-convex smooth stochastic approximation with convergence rate o (1/n)",
    "authors": ["F. Bach", "E. Moulines"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2013
  }, {
    "title": "Convex analysis and monotone operator theory in Hilbert spaces, volume 408",
    "authors": ["H H Bauschke", "Combettes", "P L"],
    "year": 2011
  }, {
    "title": "Large scale online learning",
    "authors": ["L. Bottou", "Y.L. Cun"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2004
  }, {
    "title": "The use of the area under the roc curve in the evaluation of machine learning algorithms",
    "authors": ["Bradley", "A P"],
    "venue": "Pattern recognition,",
    "year": 1997
  }, {
    "title": "Libsvm: a library for support vector machines",
    "authors": ["Chang", "C.-C", "Lin", "C.-J"],
    "venue": "ACM transactions on intelligent systems and technology (TIST),",
    "year": 2011
  }, {
    "title": "Optimal primal-dual methods for a class of saddle point problems",
    "authors": ["Y Chen", "G Lan", "Y. Ouyang"],
    "venue": "SIAM Journal on Optimization,",
    "year": 2014
  }, {
    "title": "Ranking and empirical minimization of u-statistics",
    "authors": ["S. Clémençon", "G. Lugosi", "N. Vayatis"],
    "venue": "The Annals of Statistics,",
    "year": 2008
  }, {
    "title": "Efficient online and batch learning using forward backward splitting",
    "authors": ["J Duchi", "Y. Singer"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2009
  }, {
    "title": "Adaptive subgradient methods for online learning and stochastic optimization",
    "authors": ["J. Duchi", "E. Hazan", "Y. Singer"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2011
  }, {
    "title": "The foundations of cost-sensitive learning",
    "authors": ["C. Elkan"],
    "venue": "In International joint conference on artificial intelligence,",
    "year": 2001
  }, {
    "title": "An introduction to roc analysis",
    "authors": ["T. Fawcett"],
    "venue": "Pattern recognition letters,",
    "year": 2006
  }, {
    "title": "Uci machine learning repository [http://archive",
    "authors": ["Frank", "Andrew", "Asuncion", "Arthur"],
    "venue": "ics. uci. edu/ml]. irvine, ca: University of california. School of information and computer science,",
    "year": 2010
  }, {
    "title": "One-pass auc optimization",
    "authors": ["W. Gao", "R. Jin", "S. Zhu", "Zhou", "Z.-H"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "On the consistency of auc pairwise optimization",
    "authors": ["Gao", "Wei", "Zhou", "Zhi-Hua"],
    "venue": "In IJCAI, pp",
    "year": 2015
  }, {
    "title": "The meaning and use of the area under a receiver operating characteristic (roc",
    "authors": ["J.A. Hanley", "B.J. McNeil"],
    "venue": "curve. Radiology,",
    "year": 1982
  }, {
    "title": "Projection-free online learning",
    "authors": ["E. Hazan", "S. Kale"],
    "venue": "In Proceedings of the 29th International Coference on International Conference on Machine Learning,",
    "year": 2012
  }, {
    "title": "Optimising area under the roc curve using gradient descent",
    "authors": ["A Herschtal", "B. Raskutti"],
    "venue": "In Proceedings of the twenty-first international conference on Machine learning,",
    "year": 2004
  }, {
    "title": "A support vector method for multivariate performance measures",
    "authors": ["Joachims", "Thorsten"],
    "venue": "In Proceedings of the 22nd international conference on Machine learning,",
    "year": 2005
  }, {
    "title": "Training linear svms in linear time",
    "authors": ["Joachims", "Thorsten"],
    "venue": "Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2006
  }, {
    "title": "Accelerating stochastic gradient descent using predictive variance reduction",
    "authors": ["Johnson", "Rie", "Zhang", "Tong"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2013
  }, {
    "title": "On the generalization ability of online learning algorithms for pairwise loss functions",
    "authors": ["P. Kar", "B. Sriperumbudur", "P. Jain", "H. Karnick"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "Bipartite ranking through minimization of univariate loss",
    "authors": ["W Kotlowski", "K J Dembczynski", "E. Huellermeier"],
    "venue": "In Proceedings of the 28th International Conference on Machine Learning",
    "year": 2011
  }, {
    "title": "A simpler approach to obtaining an o (1/t) convergence rate for the projected stochastic subgradient method",
    "authors": ["Lacoste-Julien", "Simon", "Schmidt", "Mark", "Bach", "Francis"],
    "venue": "arXiv preprint arXiv:1212.2002,",
    "year": 2012
  }, {
    "title": "Non-asymptotic analysis of stochastic approximation algorithms for machine learning",
    "authors": ["Moulines", "Eric", "Bach", "Francis R"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2011
  }, {
    "title": "Robust stochastic approximation approach to stochastic programming",
    "authors": ["A. Nemirovski", "A. Juditsky", "G. Lan", "A. Shapiro"],
    "venue": "SIAM Journal on optimization,",
    "year": 2009
  }, {
    "title": "Simultaneous model selection and optimization through parameter-free stochastic learning",
    "authors": ["F. Orabona"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Stochastic variance reduction methods for saddle-point problems",
    "authors": ["Palaniappan", "Balamurugan", "Bach", "Francis"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Making gradient descent optimal for strongly convex stochastic optimization",
    "authors": ["A. Rakhlin", "O. Shamir", "K. Sridharan"],
    "venue": "In Proceedings of the 29th International Conference on Machine Learning",
    "year": 2012
  }, {
    "title": "Making gradient descent optimal for strongly convex stochastic optimization",
    "authors": ["A Rakhlin", "O Shamir", "K. Sridharan"],
    "venue": "In Proceedings of the 29th International Conference on Machine Learning,",
    "year": 2012
  }, {
    "title": "Optimizing auc with support vector machine",
    "authors": ["Rakotomamonjy", "Alain"],
    "venue": "In European Conference on Artificial Intelligence Workshop on ROC Curve and AI,",
    "year": 2004
  }, {
    "title": "A stochastic approximation method",
    "authors": ["H. Robbins", "S. Monro"],
    "venue": "The annals of mathematical statistics,",
    "year": 1951
  }, {
    "title": "Convergence of stochastic proximal gradient algorithm",
    "authors": ["Rosasco", "Lorenzo", "Villa", "Silvia", "Vũ", "Bang Công"],
    "venue": "arXiv preprint arXiv:1403.5074,",
    "year": 2014
  }, {
    "title": "Pegasos: Primal estimated sub-gradient solver for svm",
    "authors": ["S. Shalev-Shwartz", "Y. Singer", "N. Srebro", "A. Cotter"],
    "venue": "Mathematical programming,",
    "year": 2011
  }, {
    "title": "Stochastic gradient descent for non-smooth optimization: Convergence results and optimal averaging schemes",
    "authors": ["O Shamir", "T. Zhang"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "Online learning algorithms",
    "authors": ["S. Smale", "Y. Yao"],
    "venue": "Foundations of computational mathematics,",
    "year": 2006
  }, {
    "title": "Stochastic optimization for machine learning",
    "authors": ["N. Srebro", "A. Tewari"],
    "venue": "ICML Tutorial,",
    "year": 2010
  }, {
    "title": "Generalization bounds for online learning algorithms with pairwise loss functions",
    "authors": ["Y. Wang", "R. Khardon", "D. Pechyony", "R. Jones"],
    "venue": "In Conference on Learning Theory, pp",
    "year": 2012
  }, {
    "title": "Rsg: Beating subgradient method without smoothness and strong convexity",
    "authors": ["Yang", "Tianbao", "Lin", "Qihang"],
    "venue": "arXiv preprint arXiv:1512.03107,",
    "year": 2015
  }, {
    "title": "Stochastic online auc maximization",
    "authors": ["Y. Ying", "L. Wen", "S. Lyu"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Smoothing multivariate performance measures",
    "authors": ["X. Zhang", "A. Saha", "Vishwanathan", "SVN"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "Stochastic primal-dual coordinate method for regularized empirical risk minimization",
    "authors": ["Zhang", "Yuchen", "Xiao", "Lin"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Online auc maximization",
    "authors": ["P. Zhao", "R. Jin", "T. Yang", "S.C. Hoi"],
    "venue": "In Proceedings of the 28th international conference on machine learning (ICML-11),",
    "year": 2011
  }, {
    "title": "Regularization and variable selection via the elastic net",
    "authors": ["H Zou", "T. Hastie"],
    "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
    "year": 2005
  }],
  "id": "SP:6a26831ad30d48bf9eeb15a097bba8558a6cfddd",
  "authors": [{
    "name": "Michael Natole Jr.",
    "affiliations": []
  }, {
    "name": "Yiming Ying",
    "affiliations": []
  }, {
    "name": "Siwei Lyu",
    "affiliations": []
  }],
  "abstractText": "Stochastic optimization algorithms such as stochastic gradient descent (SGD) update the model sequentially with cheap per-iteration costs, making them amenable for large-scale data analysis. Most of the existing studies focus on the classification accuracy. However, these can not be directly applied to the important problems of maximizing the Area under the ROC curve (AUC) in imbalanced classification and bipartite ranking. In this paper, we develop a novel stochastic proximal algorithm for AUC maximization which is referred to as SPAM. Compared with the previous literature, our algorithm SPAM applies to a non-smooth penalty function, and achieves a convergence rate of O( log t t ) for strongly convex functions while both space and per-iteration costs are of one datum.",
  "title": "Stochastic Proximal Algorithms for AUC Maximization"
}