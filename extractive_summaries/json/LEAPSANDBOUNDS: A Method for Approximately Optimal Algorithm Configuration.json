{
  "sections": [{
    "heading": "1. Introduction",
    "text": "For computational problems of major practical interest (satisfiability, planning, etc.) the computing science community has developed a large number of highly configurable “solvers.” The reason is that while the hardest problem instances take a long time to solve by any of the solvers, the instances that one encounters in practical applications may exhibit specific properties so that the appropriate solver\n1DeepMind, London, UK. 2On leave from Imperial College London, London, UK. 3On leave from University of Alberta, Edmonton, AB, Canada. Correspondence to: Gellért Weisz <gellert@google.com>, András György <agyorgy@google.com>, Csaba Szepesvári <szepi@google.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nwith an appropriate configuration may finish much faster. The plethora of solvers and their configurations, which for simplicity of presentation we will just treat as configurations from this point on, is explained by the diversity of applications. Which configuration to use in a specific application can then be treated as a learning problem, where an application is identified with an unknown distribution over problem instances that one can sample from, the learning algorithm can run any configuration on any sampled instance until a timeout of its choice, and the goal is to find a configuration with nearly optimal expected runtime while using the least amount of time during the search.1 There has been much practical success on designing such blackbox configuration search methods, especially in the context of satisfiability problems. Examples of successful methods include ParamILS (Hutter, 2007; Hutter et al., 2009), SMAC (Hutter et al., 2011; 2013), irace (Birattari et al., 2002; López-Ibánez et al., 2011), and GGA (Ansótegui et al., 2009; 2015). These methods themselves rely on many heuristics and as such lack theoretical guarantees.\nRecently, Kleinberg et al. (2017) explored this problem, presenting a general-purpose configuration optimizer called Structured Procrastination, with guarantees on both (i) how close to the optimal configuration the algorithm’s result is, and (ii) how long it takes to find such a configuration. For (ii), Kleinberg et al. (2017) prove that the expected runtime of their algorithm is within a logarithmic factor of the optimal runtime in a worst-case sense. Furthermore, they show that the gap between worst-case runtimes of existing algorithms (SMAC, ROAR, ParamILS, GGA, irace) and their solution can be arbitrarily large. Structured Procrastination attempts to refine the runtime guarantee for the empirically fastest solver and solves tasks in increasing order of difficulty, postponing difficult tasks until all simpler tasks have been solved. The main novelty of their work is that it comes with theoretical guarantees (lower and upper bounds on the runtime), but no empirical illustration is provided.\nThis paper builds on the results of Kleinberg et al. (2017), and our problem statement closely follows theirs. Our\n1Related, but different problems are considered, e.g., by Luby et al. (1993); Adam (2001); Mnih et al. (2008); Audibert & Bubeck (2010); György & Kocsis (2011); Li et al. (2016).\nmain technical contributions are as follows: We present an (arguably simpler) algorithm (LEAPSANDBOUNDS) that finds an approximately optimal configuration with a worstcase runtime bound that improves upon that of Kleinberg et al. (2017), while we consider a broader class of problems (we don not need their global runtime cap). We also present instance-dependent runtime bounds that show that LEAPSANDBOUNDS finishes faster if the runtime of the configurations over different problem instances has small variance. Experiments were carried out to assess practical performance of both Structured Procrastination and LEAPSANDBOUNDS on configuring the open-source minisat solver. LEAPSANDBOUNDS runs every configuration for less time than Structured Procrastination, and returns significantly faster. Finally, to facilitate further research and enable direct comparison to our results, our large-scale measurements on running times of the minisat solver are published together with the paper.2\nThe rest of the paper is organized as follows: The problem is introduced formally in Section 2. For clarity, the most basic version of our algorithm is presented first in Section 3, and its performance is analyzed in Section 4. Improvements to our method, together with their analyses, are presented in Section 5. Experimental results are presented in Section 6, followed by some notes on parallel implementation in Section 7. Finally, conclusions are drawn in Section 8."
  }, {
    "heading": "2. Problem Statement",
    "text": "Following Kleinberg et al. (2017), the algorithm configuration problem is defined by a tuple (N ,Γ, R, κ0) as follows:3 Here, N is a family of configurations and Γ is a distribution over input instances.4 For now, we consider the case when N is a finite set. If we have a benchmark set of instances, we let Γ be the uniform distribution over these benchmark instances. For configuration i ∈ N and instance j, R(i, j) ∈ [0,∞] is the execution time of configuration i on instance j. Finally, κ0 > 0 is the minimum runtime: For all i, j pairs, R(i, j) ≥ κ0.\nWe let R(i) = EJ∼Γ [R(i, J)] denote the average runtime of configuration i on instances distributed according to Γ, and define OPT = miniR(i) as the mean runtime of an optimal configuration. Our goal is to find such an optimal, or at least nearly optimal configuration while spending as little time as possible–proportional to the runtime of the optimal configuration–on this task. For this, a search algorithm can (i) sample instances J at random from Γ; (ii) enumerate\n2https://github.com/deepmind/ leaps-and-bounds\n3Compared to their problem statement, we removed the global runtime cap from the definition as it is not required for our results.\n4For randomized solvers, input instances can mean (input instance, random seed) pairs.\nthe configurations in N ; (iii) run a configuration i on an instance j until it finishes, or the execution time exceeds a fixed timeout τ ≥ 0, chosen by the search algorithm. Practically, this means observing R(i, j, τ) .= min(R(i, j), τ) after time R(i, j, τ), and also whether the calculation has finished with a solution or it timed out.\nThe main difficulty in organizing the search is that some configurations may take a long, or even infinite time to execute on some instances. Since an algorithm that claims to find a near-optimal configuration must verify that no other configuration can finish significantly faster than the chosen configuration, the total runtime is at least proportional to n×OPT, where n = |N | is the number of configurations to be tested. Since knowing the mean runtime up to a multiplicative accuracy of (1 + ε) requires Ω(1/ε2) samples even when the runtime distributions are light-tailed, relaxing the requirement to find a configuration i with runtime R(i) ≤ (1 + ε)OPT, we get that the total runtime is at least Ω(n × OPT/ε2). The situation worsens for heavy-tailed runtime distributions: If the runtime of an algorithm is b > 1 with probability 1/b and 0 otherwise, with b unknown, all sampling methods need to see at least one positive runtime to estimate the expected runtime up to any fixed accuracy. Thus, any sampling method needs to use at least Ω(b) time, despite that the expected runtime is constant 1 (independently of b). This implies that in the face of heavy-tailed runtime distributions, the runtime of any sound configuration search algorithm would be unbounded in the worst-case, regardless the value of OPT, n and ε. Since heavy tailed runtime distributions are quite common in practice, rather than constraining the problem by ruling these out, following Kleinberg et al. (2017), we relax the search criterion to that of finding an (ε, δ)-optimal configuration. Introducing the τ -capped version of R(i) as Rτ (i) = EJ∼Γ [R(i, J, τ)], we have the following definition for (ε, δ)-optimality:\nDefinition 1 ((ε, δ)-optimality). A configuration i∗ is (ε, δ)optimal if there exists some threshold τ such that Rτ (i∗) ≤ (1 + ε)OPT, and PrJ∼Γ (R(i∗, J) > τ) ≤ δ. Otherwise, we say i∗ is (ε, δ)-suboptimal.\nIn words, given (ε, δ), a sound configuration search algorithm must find a configuration i whose τ -capped mean runtime is at most (1 + ε)OPT, with a τ larger than the δquantile of the runtime distribution of configuration i. This is a reasonable criterion when OPT is reasonably small.5\nIn this paper we introduce the algorithm LEAPSANDBOUNDS that identifies an (ε, δ)-optimal configuration with\n5If some problem instances are hopelessly hard, the expected runtime of even an optimal configuration can be infinite, in which case any configuration becomes (ε, δ)-optimal. To alleviate this problem, it would be more meaningful to define (ε, δ)-optimality with respect to the optimal capped runtime; this is left for future work (see Section 8 for more details).\nprobability 1 − ζ for a failure parameter ζ and has an expected runtime of O ( OPT nε2δ log ( n log OPT ζ )) . The method of Kleinberg et al. (2017) has an additional assumption that all runtimes of any configuration on any instance sampled from Γ are below a maximum κ̄ that must also be known by the algorithm. While this renders the runtime distributions light-tailed, a nice feature of their method is that its runtime O ( OPT nε2δ log ( n log κ̄ ζδε2 )) has only a mild dependence on κ̄. LEAPSANDBOUNDS does not require a runtime cap and we shave off a few terms from their bound: We replace the doubly logarithmic dependence on κ̄ with an identical dependence on the practically much smaller OPT, and remove logarithmic terms that depend on δ−1 and ε−2. Kleinberg et al. (2017) also prove that the minimum worstcase runtime for any algorithm is Ω ( OPT nε2δ ) , so both methods are within a logarithmic factor of the optimum.\nThe above results make sense when n = |N | is small enough to allow running each algorithm configuration. Similarly to Kleinberg et al. (2017), LEAPSANDBOUNDS can be extended to the case of an arbitrarily large number of configurations: by sampling n configurations randomly from the set of all configurations, the probability that none of the fastest γ fraction of configurations have been sampled is at most Ce−nγ for a universal constant C > 0. Thus, by letting n = ⌈ 1 γ log(C/ζ) ⌉ , with probability 1− 2ζ, LEAPSANDBOUNDS returns an (ε, δ)-optimal configuration with respect to a configuration from the fastest γ fraction of configurations from the entire space."
  }, {
    "heading": "3. Algorithm",
    "text": "The main problem in finding a near-optimal solver configuration is that solving some instances may take arbitrarily long. To alleviate the problem, (ε, δ)-optimality only considers the mean of runtimes capped at a timeout, ensuring that at most a δ fraction of the worst instances run longer than this timeout. This makes estimating the average runtime of a configuration (over random instances) possible through sampling. The main issue with sampling is that computing the average runtime over the samples can be slowed down arbitrarily if we accidentally select a problem instance with a very large running time. This could be avoided if an oracle told us the runtime threshold τ in the definition of (ε, δ)optimality, but this is not available of course. To solve the problem, we present a configuration optimization algorithm called LEAPSANDBOUNDS (Algorithm 1).\nLEAPSANDBOUNDS attempts to guess a rough value of OPT, starting from a low value. Calling its guess θ, the algorithm then tries to find a configuration with a mean runtime less than θ. If this succeeds, it returns the configuration with the smallest mean found. Otherwise, θ is doubled and a new phase is started. The simplest way of measuring\nAlgorithm 1 LEAPSANDBOUNDS 1: Inputs:\nSet N of n algorithm configurations Precision parameter ε ∈ (0, 13 ) Quantile parameter δ ∈ (0, 1) Failure probability parameter ζ ∈ (0, 1) Lower runtime bound κ0 > 0 Instance distribution Γ\n2: Initialize: θ ← 167 κ0, k ← 0, J ← empty list 3: while True do 4: k ← k + 1 . phase count 5: b← ⌈ 44 log ( 6nk(k+1)\nζ\n) 1 δε2 ⌉ . instance bound\n6: Add b− |J | new instances sampled from Γ to J 7: for i ∈ N do 8: Q̄i ←RUNTIMEEST (i,J , δ, θ) 9: end for\n10: if mini Q̄i < θ then 11: return argmini Q̄i 12: end if 13: θ ← 2θ 14: end while\nthe mean runtime while guaranteeing (ε, δ)-optimality is to take runtime samples with timeout θδ and reject any algorithm that times out for any instance. Then, a concentration bound on the measurements could be used to ensure that the mean is close to the empirical mean. If the mean is less than θ, Markov’s inequality can be used to bound the tail probability for (ε, δ)-optimality. However, by rejecting any configuration that ever times out, we fail to measure the capped mean–which could be significantly lower–, and thus the algorithm may not stop at the right time. To fix this, we would ideally allow a δ fraction of runs to time out, but we use 34δ instead, to achieve a high-confidence tail bound with a Chernoff bound (replacing Markov’s inequality). Still, the measurements could take a long time: if we perform b measurements for a reliable mean estimation with timeout τ , then we spend up to bτ time. A key observation is that if we spend more than bθ time on measurements, the average would have to be above θ, and we would reject the configuration. Thus, we can specify an overall time budget of T = bθ, and reject any configuration early if they run over this limit. These ideas are embodied in our algorithm (RUNTIMEEST)."
  }, {
    "heading": "4. Theoretical Analysis",
    "text": "In this section we explore the theoretical properties of LEAPSANDBOUNDS. We show that the estimates computed by the algorithm are reliable with high probability. Then we prove that if the estimates are reliable, the running time cannot be too large and the algorithm returns an (ε, δ)-optimal\nAlgorithm 2 The RUNTIMEEST subroutine 1: Inputs:\nConfiguration i Instance list J = (J1, . . . , Jb) of length b Quantile parameter δ ∈ (0, 1) Average runtime bound θ\n2: Initialize: T ← bθ . overall runtime budget τ ← 4θ3δ . individual runtime budget j ← 1 . instance index 3: while True do 4: Run configuration i on Jj with timeout min{T, τ} 5: Qj ← R(i, Jj ,min{T, τ}) 6: T ← T −Qj 7: // Stopping rules: 8: if T = 0 then . Stop if overall budget zero 9: return θ 10: else if j = b then . Stop after b = |J | samples 11: return Q̄ = 1/b ∑b m=1Qm . Return mean 12: end if 13: j ← j + 1 14: end while\nsolution. We start with a few important observations about RUNTIMEEST.\n4.1. Guarantees for algorithm RUNTIMEEST\nConsider the execution of RUNTIMEEST with the inputs (i,J , θ, b). Noting that the loop is stopped if the budget T0 = bθ gets exhausted, it follows that the total runtime of the (optimized) algorithm is bounded by bθ:\nLemma 2. The runtime of one call to RUNTIMEEST is O(bθ).\nWith T0 = bθ, for j ≥ 1, define Tj = Tj−1 − Qj = bθ − (Q1 + · · · + Qj). If the budget bθ is not exhausted (i.e., Tb = bθ − (Q1 + · · · + Qb) > 0), each instance Jj runs within its min{Tj−1, τ} ≤ τ individual budget, and so Qj = R(i, Jj) = R(i, Jj , τ) =: Rj . Clearly, Tb > 0 is equivalent to Q̄ < θ. Furthermore, in any case, Qj = R(i, Jj ,min(Tj−1, τ)) ≤ Rj . Defining R̄ = (R1 + · · · + Rb)/b, we can summarize these findings as follows:\nLemma 3. If RUNTIMEEST returns with Q̄<θ, then ∀j,Qj=Rj and Q̄=R̄. Otherwise, ∀j,Qj≤Rj and Q̄≤R̄.\nLet us now turn to analyzing Algorithm 1. For this, we need some extra notation."
  }, {
    "heading": "4.2. Notation",
    "text": "Let θk, τk and bk denote the respective values of θ, τ and b in phase k (Line 6 of Algorithm 1), noting that τk = 4θk3δ . Let Jj denote the jth instance (ever) sampled in Line 6 of\nAlgorithm 1. Note that for k large enough so that bk ≥ j, Jj is the jth instance that is passed on to RUNTIMEEST by Algorithm 1 in phase k (for any configuration i). Let Ri,j,k = R(i, Jj , τk) be the τk-capped runtime of configuration i on instance Jj and let R̄i,k be the average of these values: R̄i,k = 1bk ∑bk j=1Ri,j,k. Similarly, let Q̄i,k be the return value of algorithm RUNTIMEEST in phase k for configuration i, which is also the mean of (Qi,j,k)j , the runtimes observed at Line 5 of RUNTIMEEST. Let σ̂2i,k be the empirical variance of (Ri,j,k)j : σ̂2i,k = 1 bk ∑bk j=1(Ri,j,k − R̄i,k)2."
  }, {
    "heading": "4.3. Good events",
    "text": "Let pi,k = PrJ∼Γ (R(i, J) > τk) denote the probability that configuration i does not finish on instance j in time τk. Next we define two events that ensure that the algorithm works well. First, let\nE1,i,k = {Q̄i,k = θk} ∪ {pi,k ≤ δ};\nif E1,i,k holds then if Algorithm 1 returns, the probability that the corresponding configuration fails to solve a random task within τk time is small (note that Q̄i,k ≤ θk).\nThe next event guarantees that the average capped running time is close to its expectation: let\nE2,i,k = {|R̄i,k −Rτk(i)| ≤ Ci,k} with\nCi,k = σ̂i,k\n√ 2 log(6nk(k+1)ζ )\nbk +\n3τk log( 6nk(k+1)\nζ )\nbk .\nThe main result of this section is to show that E1,i,k and E2,i,k hold with high probability for all i and k simultaneously:\nLemma 4. Let E = ⋂ i∈{1,...,n},k∈Z+ (E1,i,k ∩ E2,i,k). Then, Pr(E) ≥ 1− ζ.\nTo prove the lemma, we individually bound the probabilities that the events do not hold:\nLemma 5. Pr(Ec1,i,k) ≤ ζ 2nk(k+1) .\nProof. If pi,k ≤ δ, then Pr(Ec1,i,k) = 0 and the statement holds trivially. For the rest of this proof, we assume that pi,k > δ. From the algorithm, we have that bk ≥ 32δ log( 2nk(k+1) ζ ). Define Bi,j,k as the Bernoulli random variable indicating whether configuration i on input Jj takes more time than τk to finish (value 1), or not (value 0). For δ̂i,k = 1bk ∑bk j=1Bi,j,k, observe that E(δ̂i,k) = pi,k. If the algorithm returns with Q̄i,k < θ, as necessary for event Ec1,i,k, then R̄i,k = Q̄i,k according to Lemma 3. Noting that Bi,j,k = I [Ri,j ≥ τk], we have 4θ3δ ∑ j Bi,j,k ≤ ∑ j Ri,j (since τk = 4θ3δ ). Therefore, 4θ 3δ δ̂i,k ≤ R̄i,k = Q̄i,k < θ, so δ̂i,k ≤ 34δ.\nApplying a Chernoff bound on the bk independent Bernoulli random variables Bi,j,k, the probability of the latter event can be bounded, giving\nPr(Ec1,i,k) = Pr(Q̄i,k < θ) ≤ Pr ( δ̂i,k ≤ 3\n4 δ ) ≤ Pr ( δ̂i,k ≤ 3\n4 E(δ̂i,k)\n) ≤ exp ( −E(δ̂i,k)bk\n32\n)\n< exp ( − 1\n32 δbk\n) ≤ ζ\n2nk(k + 1) ,\nwhere the second and second to last inequalities follow from E(δ̂i,k) > δ.\nLemma 6. Pr(Ec2,i,k) ≤ ζ 2nk(k+1) .\nProof. The samples (Ri,j,k)j are independent and identically distributed with mean R̄i,k and expectation Rτk(i). Thus, the lemma holds by the empirical Bernstein bound (cf. Audibert et al., 2009, Theorem 1 and Appendix A).\nNow Lemma 4 follows from Lemmas 5 and 6 and the union bound (details are given in Appendix B)."
  }, {
    "heading": "4.4. Bounding the average runtime",
    "text": "Note that when the algorithm finishes, Q̄i,k = R̄i,k. Hence, in this section we focus on R̄i,k and its deviation from its mean. In particular, we show that |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i) holds on event E when phase k is preterm. Here, a phase k is called preterm if miniRτk(i) ≥ 716θk. The idea is that if a phase is preterm then the best capped expected runtime is large compared to the guess on the optimal runtime. We then show that on E, any phase executed by the algorithm is preterm.\nSince on E, |Rτk(i) − R̄i,k| ≤ Ci,k by the definition of E, we need to bound Ci,k. We start with a bound on the empirical variance σ̂2i,k. Lemma 7. For any preterm phase k, σ̂2i,k ≤ 3221δ (R̄i,k + Rτk(i)) 2.\nProof. First we show that for any c > 0, σ̂2i,k ≤ c ( R̄i,k +\nτk 2c\n)2 . (1)\nNotice that σ̂2i,k = 1 bk ∑bk j=1(Ri,j,k − R̄i,k)2 ≤\n1 bk ∑bk j=1R 2 i,j,k ≤ 1bk ∑bk j=1 τk Ri,j,k = τk R̄i,k because R̄i,k ≤ τk by definition. Now (1) follows from the obvious R̄i,kτk ≤ c ( R̄i,k + τk 2c )2 .\nBy the assumption on k, θk ≤ 167 Rτk(i). Since τk = 4θk 3δ , this means that τk ≤ 64 21δRτk(i). Thus, applying (1) with c = 3221δ completes the proof as σ̂ 2 i,k ≤\n32 21δ ( R̄i,k + 21δ 64 τk )2 ≤ 3221δ (R̄i,k +Rτk(i))2.\nCombining the above result with the upper bound τk = 4θk 3δ ≤ 64 21δRτk(i), which holds for any preterm phase k, simple algebra yields the following bound on Ci,k (the full proof is given in Appendix C):6\nLemma 8. For any preterm phase k, it holds that Ci,k ≤ ε 3 (R̄i,k +Rτk(i)).\nNow we give the promised bound on |Rτk(i)− R̄i,k|. Lemma 9. Assume E holds and Ci,k ≤ ε3 (R̄i,k +Rτk(i)). Then, |Rτk(i)− R̄i,k| ≤ 37εRτk(i) for all configurations i.\nProof. Let us define x such that R̄i,k = (1 + x)Rτk(i). Because E2,i,k holds, |x|Rτk(i) = |Rτk(i)− R̄i,k| ≤ Ci,k ≤ ε 3 (R̄i,k +Rτk(i)) = ε 3 (1 + 2x)Rτk(i). So |x| ≤ ε 3 (1 + 2x). If x < 0, then x ≥ − ε/31+2ε/3 > − 3 7ε. If x ≥ 0, then x ≤ ε/31−2ε/3 ≤ 3 7ε because ε ≤ 1 3 .\nIn the analysis of the correctness and the running time of the algorithm, we only need the slightly weaker corollary of Lemma 8 and Lemma 9 (which also holds for another variant of our algorithm, as opposed to Lemma 8):\nCorollary 10. Assume E holds and phase k is preterm. Then, for each i, if R̄i,k < θk, then |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i); otherwise, if R̄i,k≥θk, then θk< (1+ 3 7ε)Rτk(i)."
  }, {
    "heading": "4.5. Correctness and runtime",
    "text": "In this section we show that Algortihm 1 returns an (ε, δ)optimal configuration, and give an upper bound on its running time. First we show the following result promised earlier:\nLemma 11. If E holds then every phase k executed is preterm.\nProof. The first phase is preterm as 716θ1 = κ0 ≤ Rτ1(i). For a phase k ≥ 2 that is executed, since the algorithm did not return in phase k − 1, by Lemma 3, R̄i,k−1 ≥ Q̄i,k−1 = θk−1. If E holds and phase k − 1 was preterm, by Corollary 10, θk−1 < (1 + 37ε)Rτk−1(i). Moreover,\n7 16θk = 7 8θk−1 ≤ 7 8 (1+ 3 7ε)Rτk−1(i) ≤ Rτk−1(i) ≤ Rτk(i),\nsince ε ≤ 13 . By induction, any phase executed is preterm.\nLemma 12. If E holds and Algorithm 1 returns with a configuration I in phase K, then I is (ε, δ)-optimal.\nProof. We prove the statement by contradiction. Thus, assume I is (ε, δ)-suboptimal. At stopping, Q̄I,K < θK , hence on E, pI,K = PrJ∼Γ(R(I, J) > τK) ≤ δ must hold.\n6The multiplicative constant in the proof is not optimized carefully to promote simplicity. Nevertheless, in our experiments the empirical effect of this constant is negligible.\nSince I is (ε, δ)-suboptimal, it follows that there exists an instance j such thatRτK (I) > (1+ε)R(j) > (1+ε)RτK (j). Take such an index j. Since Algorithm 1 returned I instead of j, Q̄I,K ≤ Q̄j,K . By Lemma 3, θk > Q̄I,K = R̄I,K and R̄j,K ≥ Q̄j,K . Applying Corollary 10 and Lemma 11, if R̄j,K < θk, then (1+ 37ε)RτK (j) ≥ R̄j,K ≥ Q̄j,K ≥ Q̄I,K . Otherwise, (1 + 37ε)Rτk(i) ≥ θk ≥ Q̄I,K . Using this,\nRτK (j)(1 + 3 7ε) ≥ Q̄I,K = R̄I,K > RτK (I)(1− 3 7ε)\n> RτK (j)(1 + ε)(1− 37ε).\nTherefore, 1 + 37ε > (1 + ε)(1 − 3 7ε) which leads to a contradiction since ε ≤ 13 .\nTheorem 13. Algorithm 1 identifies an (ε, δ)-optimal solution in time O ( OPT nε2δ log( n log OPT ζ ) ) with probability at least 1− ζ, where OPT = miniR(i).\nProof. By Lemma 4, E holds with probability at least 1− ζ . The rest of the proof assumes that E holds.\nLet i∗ = argminiR(i). If θk ≥ (1 + 37ε)OPT ≥ (1 + 3 7ε)Rτk(i\n∗), then only the first case of Corollary 10 can hold. Together with Lemma 11, we have that Q̄i∗,k ≤ R̄i∗,k ≤ (1 + 37ε)Rτk(i\n∗) ≤ θk, so Algorithm 1 terminates for θk ≥ (1 + 37ε)OPT. Let the total number of phases of the outer loop of Algorithm 1 be L. Then L = O(log OPT).\nThe for loop on Line 7 of Algorithm 1 adds a factor of n to the runtime. By Lemma 2, calling algorithm RUNTIMEEST on Line 8 adds a factor of bkθk to the runtime. Now bk ≤ ⌈( 44 log(6nL(L+1)ζ ) 1 δε2 )⌉ =\nO (\n1 ε2δ log( 6n log2 OPT ζ )\n) = O ( 1 ε2δ log( 6n log OPT ζ ) ) , so\nsubstituting θk = 167 κ02 k, the total runtime becomes\nO  ⌈ log2 ( (1+ 37 ε) OPT κ0 )⌉∑ k=1 κ02 k · n ε2δ log ( 6n log OPT ζ ) = O ( OPT n\nε2δ log\n( n log OPT\nζ\n)) .\nBy Lemma 12, when the algorithm returns, it returns with an (ε, δ)-optimal configuration.\n5. Optimizing RUNTIMEEST Our runtime analysis presented in the previous section used a worst-case upper bound for σ̂i,k. Some instances may allow faster runtimes if we modify RUNTIMEEST to stop earlier in scenarios where the empirical variance is lower than this worst case bound. To do this, building on the approach of Mnih et al. (2008), we change the stopping rules of algorithm RUNTIMEEST and add two more rules as\nAlgorithm 3 Stopping rules 1: Q̄← 1j ∑j m=1Qm\n2: σ̂2 ← 1j ∑j m=1 ( Qm − Q̄ )2 3: dj,k ← 4nk(k + 1)j(j + 1)/ζ 4: c← √ σ̂2\n2 log(3dj,k) j + 3τ log(3dj,k) j\n5: LB← Q̄− c 6: if T = 0 then . Stop if overall budget zero 7: return θ 8: end if 9: if j = b then . Stop after b = |J | samples\n10: return Q̄ . Return mean of Q 11: end if 12: if (1 + 37ε)LB ≥ θ and Q̄ > θ then . LB too large 13: return θ 14: end if 15: if j ≥ ⌈ 32 δ log dj,k ⌉ and c ≤ ε3 ( Q̄+ LB ) then 16: return Q̄ . Return mean of Q 17: end if\ngiven in Algorithm 3. The code shown here should replace Lines 8–12 of RUNTIMEEST.\nWe outline a proof sketch that this algorithm is still correct and has the same runtime bound. We define the running averages in iteration j of RUNTIMEEST as Q̄i,j,k and R̄i,j,k. As before, we define an event, as a union of other events, that guarantees that the empirical estimates behave well. We keep the previously defined events E1,i,k and E2,i,k; note that E1,i,k corresponds to the estimate Q̄i,b,k. However, we need a similar event to E1,i,k for all iterations j: E′i,j,k = {Q̄i,k ≥ θk} ∪ {pi,k ≤ δ} ∪ {j < ⌈ 32 δ log dj,k ⌉ }.\nLet E = ⋂ i∈{1,...,n},j,k∈Z+ ( E1,i,k ∩ E2,i,k ∩ E′i,j,k ) . Similarly to the previous section, it is easy to show that Pr(E) ≥ 1 − 3ζ/2. If E holds and the algorithm returns with an average runtime less than θk, then E1,i,k and E′i,j,k guarantee that Pr(R(i, j) > τk) ≤ δ (independently of which stopping condition was activated). Since the original stopping rule is still in place, the runtime of algorithm RUNTIMEEST with the additional stopping rules is still O(bkθk). Similarly, it is easy to verify that Lemma 3 still holds.\nFurthermore, by a slight modification of Theorem 2 of Mnih (2008), one can show that with probability at least 1− ζ/2, |Rτk(i) − R̄i,j,k| ≤ ci,j,k holds for all i, j, k, and ci,j,k ≤ ε 3 ( Q̄i,j,k + LBi,j,k ) ≤ ε3 ( R̄i,j,k +Rτk(i) ) holds7 for all\nj ≥ C·max\n( σ2i,k\nε2R2τk(i) , τk εRτk(i)\n)( log 1\nζ ′ + log\n1\nεRτk(i)\n) ,\nwhereC is a universal constant, and Q̄i,j,k ≤ R̄i,j,k. Denote 7Here, Lemma 3 was used additionally in the last inequality.\nthis event by E′; then Pr(E′) ≥ 1− ζ/2.8\nApplying Lemma 9, E′ also implies that\n|Rτk(i)− R̄i,j,k| ≤ 37εRτk(i).\nThus, if E ∪ E′ holds, then Corollary 10 holds: if Algorithm 3 returns either because it went through all the bk samples or because of Line 12, then |Rτk(i) − R̄i,k| ≤ 3 7εRτk(i), which implies the first part of the corollary; otherwise Algorithm 3 returns in line 10, implying that the algorithm returns with θk and (1 + 37ε)Rτk > θk. Then the runtime bound and the correctness guarantee of Theorem 13 follows as before.\nOn the other hand, if the variances of the runtimes over instances are low enough, it is possible to prove an improved runtime bound for the whole algorithm. For ζ ′ = ζ4nk(k+1) , there exists a constant C such that if\nj ≥ C · 1δ ( log 1δ + log 1 ζ′ ) , then j ≥ ⌈ 32 δ log dj,k ⌉ holds. Together with the previous lower bound on j and by upper bounding τk ≤ 6421δRτk(i), by the definition of a preterm phase (see Lemma 8), with probability at least 1− 2ζ , RUNTIMEEST evaluates at most\nC·max\n( σ2i,k\nε2R2τk(i) ,\n1\nεδ ,\n1 δ log 1 δ\n)( log 1\nζ ′ + log\n1\nεRτk(i) ) samples in any phase k for configuration i before the stopping conditions on Line 15 are be satisfied. This bound is usually much lower than the previous bk =⌈ 44 log ( 6nk(k+1)\nζ\n) 1 δε2 ⌉ : if the variance of runtimes is\nsufficiently low, this scales as ε−1 rather than ε−2 (the δ−1 log δ−1 term is negligible).\nMnih et al. (2008) also describe EBGStop, a slightly improved version of empirical Bernstein stopping, which applies Bernstein inequalities to bound the means of an exponentially increasing number of samples. This allows us to effectively replace log 1εRτk (i) with log log 1εRτk (i) in the bound presented above. We use this version of the algorithm in our experiments. For completeness, the pseudocode of this version is given in Appendix D."
  }, {
    "heading": "6. Experiments",
    "text": "To run experiments, we gathered a benchmark set of runtimes of different configurations on generated SAT problems. We used minisat9 (Sorensson & Een, 2005) as the SAT solver. The SAT problems were generated using CNFuzzDD,10 of which only those 20118 were kept that\n8The original event behind E′ guarantees, via Bernstein’s inequality, that the estimates for the means and variances are accurate enough.\n9We used version 2013/09/25. http://minisat.se/ 10http://fmv.jku.at/cnfuzzdd/\ntook at least about a second to solve for minisat with the default parameters. This was done so that the data reflects what happens when instances are nontrivial to solve. 972 different configurations were tested for minisat, which are described in Appendix E. The solver minisat was run with each configuration and instance combination. The unit of computation, κ0, is one second of CPU time, and the experiments were ran with a timeout of 15 CPU minutes.11 To get a sense of this data, the capped mean runtimes Rτ (i) for each configuration are shown in Fig. 1 in a sorted order. Here, the timeout τ was set separately for each configuration so that the tail probability PrJ∼Γ(R(i, J) > τ) was approximately δ; the running times are shown for different values of δ (δ = 0 corresponds to the mean runtimes). From this, we can see a large difference between configurations. For a particularly “fast” configuration, Fig. 2 shows the distribution of runtimes on different instances. Note that because of the global time limit for executions, the final bucket includes runs that may take arbitrarily long.\nThe benchmark set of runtimes is used to quickly simulate runs of Structured Procrastination and LEAPSANDBOUNDS, as follows. A simulated environment acts as an oracle,\n11Our measurements have been scaled such that the unit of computation roughly corresponds to a second on commodity hardware as of 2018 rather than our machines. In this unit, about 83 CPU years were spent in total to generate this data.\nreturning precomputed values of R(i, j, τ) when queried, accumulating the total time the algorithm under test would have run for.\nBoth LEAPSANDBOUNDS and Structured Procrastination often run the same configuration on the same instance with an increased time limit. Thus, both algorithms can benefit largely when the environment allows pausing and resuming of executions. This can be implemented either by saving the state of the execution when the actual runtime limit is reached, or by reloading the state from automatically saved checkpoints. However, resuming execution comes with an additional memory requirement, and may not always be feasible or preferable to restarts. Thus, we report our experiments for both cases.\nAfter each phase, in Line 13 of LEAPSANDBOUNDS, we double θ. In fact, this multiplier is arbitrary, and changing it only affects the worst-case runtime up to a constant factor. In practice, a smaller multiplier, making smaller steps in θ, typically overshoots the best average runtime less, thereby decreasing the total runtime for environments that allow resuming runs. On the other hand, a smaller multiplier leads to more phases, introducing more overheads in resuming jobs and increasing the total runtime if resuming is not allowed by rerunning portions of jobs more frequently. The value of the multiplier can be optimized by taking these effects into account, e.g., by measuring the overheads related to switching and resuming jobs. For simplicity, and since this information is not included in our benchmark dataset, in the experiments below the value of the multiplier was set to 1.25 (see Appendix F for more details).\nWe simulated LEAPSANDBOUNDS and Structured Procrastination on our benchmark dataset with parameters ε = 0.2, δ = 0.2, and ζ = 0.1. Fig. 3 shows that LEAPSANDBOUNDS runs every configuration for a significantly shorter amount of time than Structured Procrastination. The configurations are sorted in the same order as in Fig. 1, for δ = 0.2. Paradoxically, both algorithms run the faster configurations significantly longer. This is because both algorithms quickly\nreject slow configurations, whereas they both run fast configurations many more times to ensure (ε, δ)-optimality. In total, LEAPSANDBOUNDS runs for 933.50 CPU days in the environment that does not support resuming execution, and 368.50 days in one that does. The corresponding runtime measurements for Structured Procrastination are 1850.46 and 1169.36, respectively. Both algorithms return with configuration 898, which has the best average runtime below a δ = 0.2 quantile, out of all configurations."
  }, {
    "heading": "7. Parallelization",
    "text": "One benefit of the simplicity of LEAPSANDBOUNDS is that it is embarrassingly parallel. This is due to the fact that there is little dependency between the runtime measurements that need to be carried out. In phase k, when θk = 167 κ02 k, runs\nof the form R ( i, j, κ02 k+6\n21δ\n) are carried out. The core of\nour argument is that this parallelizes over i, j, and k, but there are three further considerations. First, to implement the overall runtime bound of RUNTIMEEST, for any fixed i and k, the runs of R ( i, j, κ02 k+6\n21δ\n) should be terminated\nonce the summed running times of these reach the overall budget bkθk. This could be implemented either via interprocess communication or by starting these runs at once on p processors and terminating them after bkθk/p time. Second, a new phase k of Algorithm 1 should only be started once Q̄i,k is available for all i ∈ N . Thus, runs should be started in increasing order of k, for each i. Third, the optional empirical Bernstein stopping, as described in Section 5, adds a dependency between runs of different j. This could be resolved either by not parallelizing over j, or by running only a small number of parallel runs over j and checking the stopping conditions after they finish."
  }, {
    "heading": "8. Conclusions and Future Work",
    "text": "We have introduced an algorithm applying empirical Bernstein stopping with the goal of finding approximately optimal configurations, and provided guarantees for its worstcase runtime as well as correctness. Our runtime guarantee is tighter than that of Structured Procrastination, which, to our knowledge, is the only other method solving this problem. Empirical evaluations suggest that LEAPSANDBOUNDS outperforms Structured Procrastination in realistic, non-adversarial scenarios too, which depends crucially on leveraging the gap between worst-case and realistic scenarios by using empirical Bernstein stopping.\nThe optimality of the configuration returned by LEAPSANDBOUNDS is, in fact, with respect to configurations with timeout τK for the final phase K. An important direction of future work is to get guarantees with respect to the best configuration for the fastest (1− δ′)-proportion of instances for any δ′ < δ."
  }],
  "year": 2018,
  "references": [{
    "title": "Learning while searching for the best alternative",
    "authors": ["K. Adam"],
    "venue": "Journal of Economic Theory,",
    "year": 2001
  }, {
    "title": "A genderbased genetic algorithm for the automatic configuration of algorithms",
    "authors": ["C. Ansótegui", "M. Sellmann", "K. Tierney"],
    "venue": "In International Conference on Principles and Practice of Constraint Programming,",
    "year": 2009
  }, {
    "title": "Model-based genetic algorithms for algorithm configuration",
    "authors": ["C. Ansótegui", "Y. Malitsky", "H. Samulowitz", "M. Sellmann", "K. Tierney"],
    "venue": "In International Joint Conference on Artificial Intelligence,",
    "year": 2015
  }, {
    "title": "Best arm identification in multi-armed bandits",
    "authors": ["Audibert", "J.-Y", "S. Bubeck"],
    "venue": "In Conference on Learning Theory, pp",
    "year": 2010
  }, {
    "title": "Explorationexploitation tradeoff using variance estimates in multiarmed bandits",
    "authors": ["Audibert", "J.-Y", "R. Munos", "C. Szepesvári"],
    "venue": "Theoretical Computer Science,",
    "year": 1876
  }, {
    "title": "A racing algorithm for configuring metaheuristics",
    "authors": ["M. Birattari", "T. Stützle", "L. Paquete", "K. Varrentrapp"],
    "venue": "In Annual Conference on Genetic and Evolutionary Computation,",
    "year": 2002
  }, {
    "title": "Efficient multi-start strategies for local search algorithms",
    "authors": ["A. György", "L. Kocsis"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 2011
  }, {
    "title": "On the potential of automatic algorithm configuration",
    "authors": ["F. Hutter"],
    "venue": "In SLS-DS2007: Doctoral Symposium on Engineering Stochastic Local Search Algorithms,",
    "year": 2007
  }, {
    "title": "ParamILS: an automatic algorithm configuration framework",
    "authors": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown", "T. Stützle"],
    "venue": "Journal of Artificial Intelligence Research,",
    "year": 2009
  }, {
    "title": "Sequential model-based optimization for general algorithm configuration",
    "authors": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown"],
    "venue": "In International Conference on Learning and Intelligent Optimization,",
    "year": 2011
  }, {
    "title": "Bayesian optimization with censored response data",
    "authors": ["F. Hutter", "H.H. Hoos", "K. Leyton-Brown"],
    "venue": "CoRR, abs/1310.1947,",
    "year": 2013
  }, {
    "title": "Efficiency through procrastination: Approximately optimal algorithm configuration with runtime guarantees",
    "authors": ["R. Kleinberg", "K. Leyton-Brown", "B. Lucier"],
    "venue": "In International Joint Conference on Artificial Intelligence,",
    "year": 2017
  }, {
    "title": "Efficient hyperparameter optimization and infinitely many armed bandits",
    "authors": ["L. Li", "K.G. Jamieson", "G. DeSalvo", "A. Rostamizadeh", "A. Talwalkar"],
    "venue": "CoRR, abs/1603.06560,",
    "year": 2016
  }, {
    "title": "The irace package, iterated race for automatic algorithm configuration",
    "authors": ["M. López-Ibánez", "J. Dubois-Lacoste", "T. Stützle", "M. Birattari"],
    "venue": "Technical report, Technical Report TR/IRIDIA/2011-004, IRIDIA, Université Libre de Bruxelles, Belgium,",
    "year": 2011
  }, {
    "title": "Efficient stopping rules",
    "authors": ["V. Mnih"],
    "venue": "Master’s thesis, University of Alberta,",
    "year": 2008
  }, {
    "title": "Empirical Bernstein stopping",
    "authors": ["V. Mnih", "C. Szepesvári", "Audibert", "J.-Y"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2008
  }, {
    "title": "13-a sat solver with conflict-clause minimization",
    "authors": ["N. Sorensson", "Een", "N. Minisat v"],
    "year": 2005
  }],
  "id": "SP:607862ca9a75ee982513be12a90ec05bd01e3641",
  "authors": [{
    "name": "Gellért Weisz",
    "affiliations": []
  }, {
    "name": "András György",
    "affiliations": []
  }, {
    "name": "Csaba Szepesvári",
    "affiliations": []
  }],
  "abstractText": "We consider the problem of configuring generalpurpose solvers to run efficiently on problem instances drawn from an unknown distribution. The goal of the configurator is to find a configuration that runs fast on average on most instances, and do so with the least amount of total work. It can run a chosen solver on a random instance until the solver finishes or a timeout is reached. We propose LEAPSANDBOUNDS, an algorithm that tests configurations on randomly selected problem instances for longer and longer time. We prove that the capped expected runtime of the configuration returned by LEAPSANDBOUNDS is close to the optimal expected runtime, while our algorithm’s running time is near-optimal. Our results show that LEAPSANDBOUNDS is more efficient than the recent algorithm of Kleinberg et al. (2017), which, to our knowledge, is the only other algorithm configuration method with non-trivial theoretical guarantees. Experimental results on configuring a public SAT solver on a new benchmark dataset also stand witness to the superiority of our method.",
  "title": "LEAPSANDBOUNDS: A Method for Approximately Optimal Algorithm Configuration"
}