{
  "sections": [{
    "heading": "1. Introduction",
    "text": "As a cornerstone of unsupervised learning, clustering has been widely used in knowledge discovery problems (Jain\n1Northeastern University, Boston, MA 2Brigham and Women’s Hospital, Harvard Medical School, Boston, MA. Correspondence to: Yale Chang <ychang@coe.neu.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\net al., 1999). Given data matrix and a notion of similarity between samples, clustering aims to categorize data into different clusters so that samples in the same cluster are similar and samples in different clusters are dissimilar. Thus, depending on users’ notions of similarity, the same dataset can be clustered in different ways, also known as views (Niu et al., 2010). For example, face images can be clustered based on pose or identity; marbles can be clustered based on shape or color. However, how to properly define similarity between samples in a knowledge discovery problem is nontrivial. To help solve this challenge, semi-supervised clustering utilizes expert supervision to guide the clustering towards the right solution (Wagstaff & Cardie, 2000; Basu et al., 2008). Supervision is usually in the form of pairwise constraints between samples, including must-link (ML) and cannot-link (CL) constraints.\nInstead of supervision from one expert, it is becoming more common for supervision to be available from multiple experts as data can be shared and processed by increasingly larger audiences (e.g., crowdsourcing (Howe, 2008) mechanisms such as Amazon Mechanical Turk and large collaborative consortiums (Zhang et al., 2011)). In an exploratory data analysis setting, where ground truths are not known, different experts might provide supervision (pairwise contraints) with varying views in mind. For example, one expert might be thinking of similarity/clustering based on pose and another expert might be providing inputs based on identity on the face image problem. Moreover, because experts are not oracles, their inputs are prone to errors as well. In this paper, we address a new clustering paradigm: how to discover multiple clustering structures in the data given potentially diverse constraints from multiple uncertain experts.\nOur objective of finding multiple clustering structures given inputs from multiple experts is motivated by discovering subtypes (clusters) of a complex lung disease called Chronic Obstructive Pulmonary Disease (COPD). COPD is currently the third leading cause of death in the US (Murphy et al., 2013). Although traditionally being called one disease, doctors believe there exist multiple disease subtypes and providing personalized clinical care to patients according to their disease subtypes can lead to more effective treatments. We have collected constraints provided by multiple experts in the consortium. The experts had var-\nied backgrounds: 1) clinicians tend to provide constraints by comparing patients’ clinical measurements; and 2) radiologists tend to provide constraints based on examining patients’ computed tomography (CT) images. On the one hand, experts have disagreements on whether to put a pair of patients in the same group because they are focusing on different aspects of patients. On the other hand, experts of similar backgrounds (clinicians, radiologists) tend to provide shared views of clustering data albeit with noisy constraints. Because the various experts might have different views of clustering data, it does not make sense to learn a single consensus clustering solution; rather, we need to discover the multiple consensus clustering solutions in the different views.\nOne naive way to generate multiple clustering solutions from multiple uncertain experts is to separately apply semisupervised clustering (Bilenko et al., 2004; Davis et al., 2007; Basu et al., 2008) using constraints from each expert. The potential drawbacks of this strategy are 1) the clustering performance often drastically degrades in the presence of noisy constraints due to uncertainty of one expert; and 2) the resulting clustering solutions can be highly redundant due to the existence of similar expert views.\nThere are a few existing approaches that can combine constraints from multiple experts but they are mostly designed to generate one clustering solution. Semi-crowdsourced clustering (SemiCrowd) combines constraints provided by multiple experts through filtering out uncertain pairs in the average sample similarity matrix (Yi et al., 2012). However, this approach can only generate one clustering solution. Similar to SemiCrowd, most consensus clustering methods are designed to generate one clustering solution (Strehl & Ghosh, 2002; Fern & Brodley, 2004; Topchy et al., 2005; Ghosh & Acharya, 2011). Another disadvantage is that consensus clustering methods do not work when only a small number of pairwise constraints are available.\nThere are a few multiple alternative clustering approaches that can output multiple clustering solutions (Caruana et al., 2006; Cui et al., 2007; Jain et al., 2008; Niu et al., 2010; 2012). However, all these methods are unsupervised; none of these methods are able to utilize expert inputs.\nThere are a few existing crowdsourcing approaches that learns an underlying grouping of experts (Tian & Zhu, 2012; Kajino et al., 2013; Moreno et al., 2015). However, they are all designed for classification problems, where experts provide labels on samples queried. In our clustering task, experts can not provide labels because how to define different clusters is still unknown and yet to be discovered. Instead, they can provide pairwise constraints by comparing sample pairs using their domain knowledge. Therefore, these classification-based approaches above cannot be used in our clustering task.\nContributions. To address this new clustering paradigm, we build a Bayesian probabilistic model for learning multiple alternative consensus clustering views from experts’ constraints, we call Multiple Clustering Views from the Crowd (MCVC). Multiple experts are automatically assigned to different latent views and constraints provided by each expert is assumed to be noisy perturbations of the clustering associated with that expert’s view. Thus, multiple clustering structures can be discovered. Furthermore, by explicitly modeling the uncertainty of each expert, experts with higher accuracies are assigned higher weights, leading to improved quality of the learned clustering structure in each view. The clustering structure for each expert view is modeled by a discriminative clustering model (Gomes et al., 2010), which has the advantages of 1) naturally introducing uncertainties in cluster assignments; 2) avoiding making assumptions on the generative process of clusters; and 3) being able to cluster samples that do not appear in the training set. We demonstrate that our MCVC outperforms competing alternatives on synthetic, benchmark data, and a real-world disease subtyping problem."
  }, {
    "heading": "2. Proposed Approach",
    "text": "We collect data matrix X ∈ Rn×d, where n is the number of samples and d is the number of features, and pairwise constraints provided by M experts S(1:M), where S(m) ∈ {0, 1,NULL}n×n represents the constraints provided by them-th expert. For sample pair (xi, xj), S (m) ij = 1 means the m-th expert provides must-link (ML) constraint; S(m)ij = 0 means cannot-link (CL) constraint; S (m) ij = NULL means no constraint is provided. Our objective is to utilize constraints collected from these M experts to guide the clustering algorithm to discover multiple clustering structures in the data."
  }, {
    "heading": "2.1. Multiple Alternative Clustering Views",
    "text": "We assume there exist multiple alternative expert views and the constraints provided by experts in each view are perturbations of the clustering solution associated with that view 1. Let cm represent the latent view to which the mth expert is assigned to. Furthermore, Z(cm) are the latent clusters for each cm view. Since we do not know the underlying number of possible expert views, we automatically learn the number of expert views by assuming a Dirichlet\n1Note that “view” in multi-view clustering (Bickel & Scheffer, 2004) means coming from different sources or feature sets; whereas, “view” in our case follows the terminology in multiple alternative clusterings which means different interpretation or point of view of the data. Multi-view clustering only finds ONE clustering solution from multiple feature sets which are given. In contrast, our goal is to find MULTIPLE clustering solutions/views which are latent.\nprocess (Ferguson, 1973) prior on cm."
  }, {
    "heading": "2.2. Model Uncertainties of Experts’ Constraints",
    "text": "Since clustering is widely used for knowledge discovery, experts might not be certain on the constraints they provided. To incorporate the assumption that different experts may have different levels of expertises when providing constraints, we assume the uncerntainty of the m-th expert can be characterized by accuracy parameters (αm, βm), where αm represents the m-th expert’s sensitivity and βm represents specificity. Sensitivity is defined as the probability of providing ML constraints for sample pairs from the same cluster in the ground truth. Specificity is defined as the probability of providing CL constraints for sample pairs from different clusters in the ground truth. We model the conditional likelihood of S(m) given cm (the latent view) and Z(cm) (the latent cluster in each view) by a Bernoulli distribution as follows:\np(S (m) ij = 1|Z (cm) i = Z (cm) j , αm) = αm (1)\np(S (m) ij = 0|Z (cm) i 6= Z (cm) j , βm) = βm (2)"
  }, {
    "heading": "2.3. Discriminative Clustering",
    "text": "We consider the following when choosing the clustering model: 1) Since we need to model uncertainties of experts, instead of generating hard clustering results, the assignments to clusters should be associated with probabilities; 2) We should avoid making strong assumptions on the generative process of clusters, which can be easily violated in practice; 3) We should be able to cluster samples outside the training set. The discriminative clustering model (Gomes et al., 2010) satisfies all these requirements. Instead of assuming the generative process of data X , discriminative clustering directly models the conditional distribution of cluster label given data. We model the conditional distribution of the latent cluster label, Z(cm), given weight W (cm) and offset b(cm) with a multiple logistic regression model:\np(Z (cm) i = k|W (cm), b(cm);X) =\new (cm)T k xi+b (cm) k∑K\nj=1 e w\n(cm)T j xi+b (cm) j\n(3)\nwhere w(cm)k is the k-th column of W (cm) ∈ Rd×K and b (cm) k is the k-th row of b (cm) ∈ RK×1."
  }, {
    "heading": "2.4. Prior Distributions",
    "text": "We describe the prior distributions of parameters used in our model. To incorporate the assumptions that experts’ accuracies should be far away from random guess (αm = βm = 0.5), we put Beta priors on αm, βm and set their\nparameters to make most of their probability densities be far away from 0.5 and close to 1.\np(αm) = Beta(τ (m) α10 , τ (m) α20 ) (4) p(βm) = Beta(τ (m) β10 , τ (m) β20 ) (5)\nTo automatically learn the number of expert views, we assume a Dirichlet process prior on cm and utilize the stickbreaking construction as follows (Blei et al., 2006): νg ∼ Beta(1, γ); πg ∼ νg g−1∏ j=1 (1− νj); cm ∼ Cat(π1:∞)\nTherefore, p(cm|ν1:∞) can be written as\np(cm|ν1:∞) = ∞∏ g=1 πcmgg = ∞∏ g=1 ( νg g−1∏ j=1 (1− νj) )cmg (6)\nwhere cmg = 1 if cm = g and cmg = 0 otherwise.\nWe assume the prior distributions of both weight W (g) and offset b(g) are factorized Gaussian distributions.\np(W (g)) = d∏ i=1 K∏ j=1 N (µ(g)Wij0, σ (g)2 Wij0 ) (7)\np(b(g)) = K∏ i=1 N (µ(g)bi0, σ (g)2 bi0 ) (8)"
  }, {
    "heading": "2.5. Joint Distribution",
    "text": "The overall joint distribution of observations and latent variables for our model is:\np(S(1:M), α1:M , β1:M , c1:M , ν1:∞, Z (1:∞),W (1:∞), b(1:∞))\n= M∏ m=1 p(S(m)|αm, βm, cm, Z(1:∞))p(αm)p(βm) (9)\np(cm|ν1:∞) ∞∏ g=1 p(Z(g)|W (g), b(g);X)p(W (g))p(b(g))p(νg)\nThe respective graphical model is shown in Figure 1."
  }, {
    "heading": "3. Variational Inference",
    "text": "Our learning objective is to maximize the marginal likelihood of observed constraints, which is intractable. Thus, we apply variational inference. Given variational distribution q(h; θ), where h is the collection of latent variables and θ is their parameters. the log of the marginal likelihood log p(S(1:M)) can be decomposed as\nlog p(S(1:M)) = Lq(h;θ) +KL [ q(h; θ) | p(h|S(1:M)) ] ≥ Lq(h;θ) (10)\nwhere the inequality holds due to the nonnegativity of the the Kullback-Liebler (KL) divergence. Lq(h;θ) is called the evidence lower bound (ELBO) of log p(S(1:M)):\nLq(h;θ) = Eq(h;θ) [ log p(h, S(1:M))− log q(h; θ) ] (11)\nIn variational inference, the learning objective becomes maximizing Lq(h;θ) w.r.t. variational parameters θ.\nLet h = {α1:M , β1:M , c1:M , ν1:G, Z(1:G),W (1:G), b(1:G)}, where G is the number of components of the truncated Dirichlet Process (Blei et al., 2006). We apply mean-field and assume q(h; θ) can be factorized as follows:\nq(α1:M , β1:M , c1:M , ν1:G, Z (1:G),W (1:G), b(1:G))\n= M∏ m=1 [q(αm) · q(βm) · q(cm)] ·\nG∏ g=1 [ q(νg) n∏ i=1 q(Z (g) i ) d∏ i=1 K∏ j=1 q(W (g) ij ) K∏ i=1 q(b (g) i ) ] (12)\nwhere the marginal distribution of each random variable is\nq(αm) = Beta(τ (m) α1 , τ (m) α2 ) (13) q(βm) = Beta(τ (m) β1 , τ (m) β2 ) (14)\nq(cm) = Cat(φm,:) (15)\nq(νg) = Beta(τ (g) ν1 , τ (g) ν2 ) (16)\nq(Z (g) i ) = Cat(η (g) i,: ) (17)\nq(W (g) ij ) = N (µ (g) Wij , σ (g)2 Wij ) (18)\nq(b (g) i ) = N (µ (g) bi , σ (g)2 bi ) (19)\nWe use θ to denote all the variational parameters, which consist of {τ (m)α1 , τ (m) α2 , τ (m) β1 , τ (m) β2 , φm,:} (m = 1 · · ·M ) and {τ (g)ν1 , τ (g) ν2 , η (g) i,: , µ (g) Wij , σ (g) Wij , µ(g)bi , σ (g) bi } (g = 1 · · ·G). Besides the simplex constraints on the parameters of the categorical distribution, both the parameters of the Beta distribution and the standard deviation of Gaussian distribution should have positive constraints.\nWe derive the closed-form formula of Lq(h;θ) as a function of θ and put the detailed steps in the supplementary materials due to space constraints. Since ELBO Lq(h;θ) can be written as a function of variational parameters θ, we can directly maximize Lq(h;θ) using gradient-based optimization approaches. The gradient ∂Lq(h;θ)∂θ can be automatically computed using reverse-mode differentiation (Maclaurin et al., 2015). We choose to use a limited-memory projected quasi-Newton algorithm (PQN) to optimize our objective because it has both superlinear convergence rate and linear memory requirement (Schmidt et al., 2009). Because our objective Lq(h;θ) is not concave, we provide multiple initializations θ(0) to the optimization algorithm and choose the one resulting in the maximal objective value. We set the number of random initializations to be 50 in all experiments and the results are stable across different runs."
  }, {
    "heading": "4. Experimental Results",
    "text": "In this section, we aim to demonstrate our MCVC can automatically 1) assign multiple experts to different views; and 2) improve the quality of clustering solution in each view by assigning higher weights to uncertain experts of higher accuracies. We also analyze how 3) the settings of the number of clusters; and 4) the constraints provided by irrelevant experts affect the performance of MCVC."
  }, {
    "heading": "4.1. Competing Alternatives",
    "text": "For aim 1), we construct two views of experts based on two different ways to cluster the data. These two expert views are treated as the ground truth of assigning multiple experts to different views. Then we compare our MCVC against an adapted version of meta clustering (Caruana et al., 2006).\nMeta Spectral Clustering (MetaClust): The original meta clustering approach cannot handle multiple experts’ constraints. Instead of using the data matrix to generate multiple clustering solutions as input, we directly use the constraint sets provided by multiple experts as input. Meta clustering first computes the similarity between experts by computing the rand index (Rand, 1971) between the constraint sets they provide. Given the resulting similarity matrix between experts, instead of hierarchical clustering as in the original paper, we apply spectral clustering (Ng et al., 2001) to assign multiple experts to different views. We determine the number of expert views by maximizing the gap between the consecutive eigenvalues of the graph Laplacian (Von Luxburg, 2007).\nFor aim 2), we first construct one view of experts based on one way to cluster the data. The underlying clustering structure is treated as the ground truth of clustering samples. Then we compare our MCVC against the following alternatives in generating clusters of high quality.\nSemiCrowd: SemiCrowd (Yi et al., 2012) combines multiple expert constraints by filtering out uncertain pairs in the average similarity matrix, applying matrix completion, and then learning a distance metric for clustering.\nSemi-supervised Clustering: Given a set of pairwise constraints, semi-supervised clustering either learns a better distance metric for clustering or guides the clustering algorithm to satisfy those constraints. We use Informationtheoretic Metric Learning (ITML) (Davis et al., 2007) and Metric Pairwise Constrained KMeans (MPCKMeans) (Bilenko et al., 2004) as the representatives of those two strategies due to their superior performances compared to alternatives. Since semi-supervised clustering can only take one set of constraints as input, we combine constraints from multiple experts through majority voting (a sample pair is given ML constraint if the majority of experts provide ML constraints for them and CL constraint otherwise).\nConsensus Clustering: Most consensus clustering algorithms only work with cluster labels instead of pairwise constraints. However, Cluster-based Similarity Partitioning Algorithm (CSPA) (Strehl & Ghosh, 2002), a consensus clustering approach that only need average similarity matrix between samples as input, can be used in our setup.\nWe provide the parameter setting details for all methods in the supplementary materials due to space constraint."
  }, {
    "heading": "4.2. Synthetic and Benchmark Experiments",
    "text": "Synthetic Dataset: To help understand the algorithms, we generate a synthetic data that has multiple alternative clustering views. We generate a synthetic dataset containing 600 samples and six features. The scatterplots between pairwise features in this dataset are shown in Figure 2. First, there exist three clusters in the subspace spanned by the first two features, which we denote as Y1. In all these three figures, the red, blue and green colors represent the true cluster indicator of Y1. Second, there exist an alternative clustering structure in the subspace spanned by the third and fourth features, which we denote as Y2. Note that Y2 and Y1 are very distinct. Third, the subspace spanned by the fifth and sixth feature does not contain well-separated clusters and we consider these as noisy features.\nWebKB Dataset: The WebKB dataset (web, 1998) con-\ntains webpages collected from four universities. After removing stop words and extracting the top 200 words with most frequent occurrences, we obtain a data matrix with 1041 samples and 200 features. The data can be clustered according to either owner types (course, faculty, project, student), which we treat as Y1, or universities (Cornell, Austin, Washington, Wisconsin), which we use as Y2.\nFace Dataset: The Face dataset (Lichman, 2013) consists of 640 face images of people taken with varying poses (straight, left, right, up). Each image has 960 raw pixels. We apply principal component analysis (PCA) and keep 20 principal components (explaining 80% variance). Thus, we obtain a data matrix with 640 samples and 20 features. The data can be clustered based on pose (Y1) or identity (Y2).\nSimulating Constraints from Multiple Experts: For synthetic and benchmark datasets, we do not have access to real-world constraints provided by experts. Therefore, we simulate these constraints. Given a ground-truth clustering solution Y , the number of ML constraints nML, the number of CL constraints nCL, and accuracy parameters of M experts α1:M , β1:M , we can generate the constraints provided by the m-th expert as follows: 1) randomly sample nML ML constraints and nCL CL constraints from Y ; 2) randomly flip nML(1 − αm) ML pairs to CL pairs and flip nCL(1− βm) CL pairs to ML pairs."
  }, {
    "heading": "4.2.1. TASK 1: LEARNING THE VARIOUS LATENT VIEWS FROM MULTIPLE EXPERTS",
    "text": "In this subsection, we test the performance of our MCVC on automatically learning the latent views from multiple experts. We simulate noisy constraints provided by multiple expert from two latent views, Y1 and Y2 as follows: 1) the first view consists of experts 1-5, who provide constraints based on clustering solution Y1 and have accuracy parameters α1:5 = β1:5 = (0.95, 0.9, 0.85, 0.8, 0.75); 2) the second view consists of experts 6-10, who provide constraints based on clustering solution Y2 and have accuracy parameters α6:10 = β6:10 = (0.75, 0.8, 0.85, 0.9, 0.95).\nWe compare the performance of our MCVC and meta spectral clustering (MetaClust) in recovering the ground-truth expert views as the number of constraints, ncon, is varied from 200 to a large number that makes the performances of both approaches become stable. We repeat the constraints generation process ten times to avoid the randomness of a single run. As a result, we obtain ten constraint sets for a fixed number of constraints. Given one constraint set, we run MCVC and MetaClust to generate two possibly different ways to group experts, which are denoted as LMCVC and LMetaClust respectively. We measure performance based on the normalized mutual information (NMI) (Strehl & Ghosh, 2002) between LMCVC, LMetaClust\nand LTrue, the ground-truth expert views. NMI measures the similarity between two partitions. In our case, higher NMI values indicate better performance. For a fixed number of constraints, one constraint set, and one approach, we obtain ten NMI values. We plot the mean and standard deviation for every set of ten NMI values of each approach as we vary the number of constraints as shown in Figure 3.\nWe have the following observations: 1) On the synthetic dataset, our MCVC can consistently recover the groundtruth expert views; 2) On WebKB and Face, the performance of MCVC improves as the number of constraints increases and can recover the ground-truth expert views when the number of constraints becomes large enough; 3) On WebKB and Face, when the number of constraints is too small, as is shown in the left part of each figure, MCVC will be dominated by the priors and therefore cannot perfectly recover the expert views. 4) On all three datasets, meta clustering fails to recover the ground-truth expert views."
  }, {
    "heading": "4.2.2. TASK 2: DISCOVER CLUSTERING SOLUTION IN",
    "text": "AN EXPERT VIEW\nIn this subsection, we test the performance of our MCVC against competing methods in learning the clustering structure given constraints provided by multiple experts from one view. We simulate noisy constraints provided by multiple expert based on one ground-truth view, Y1. We consider two different settings for their accuracy parameters: 1) experts have unequal accuracies α1:5 = β1:5 = (0.95, 0.9, 0.85, 0.8, 0.75); 2) experts have equal and high accuracies α1:5 = β1:5 = (0.95, 0.95, 0.95, 0.95, 0.95).\nOur objective is to show that through learning different accuracies of multiple uncertain experts, our MCVC can generate better clustering results compared to competing alternatives (SemiCrowd, ITML, MPCKMeans and CSPA).\nWe vary the total number of ML/CL constraints provided by each expert from 200 to 2000 (as described in the previous subsection). For each fixed number of constraints, we randomly generate 10 constraint sets. For each constraint set, we run all approaches and obtain their clustering solu-\ntions. We measure performance based on NMI between the resulting clustering solutions and the ground-truth solution Y1. For a fixed number of constraints, one constraint set, and one approach, we obtain 10 NMI values. We plot the mean and standard deviation for every set of 10 NMI values for each approach as we vary the number of constraints as shown in Figure 4. To compare the performance of different approaches, we apply the Kruskal-Wallis test (Kruskal & Wallis, 1952), which can be used to test whether two groups of samples are drawn from the same distribution, on their corresponding groups of NMI values.\nFrom the left figures, where the accuracy parameters are set to be unequal, we have the following observations: I) Our MCVC consistently outperforms all competing alternatives. II) The performances of semi-supervised clustering approaches, including ITML and MPCKMeans, do not consistently improve as the number of constraints increases. III) The performance of SemiCrowd increases as the number of constraints increases. This means it can ef-\nfectively reduce the noise in the constraints. However, it does not work well when the number of constraints is too small. IV) consensus clustering (CSPA) fails because the number of constraints is too small to be used to construct accurate sample similarity matrix.\nFrom the right figures, where the accuracy parameters are set to be equal and have high values, we have the following observations: V) Our MCVC consistently outperforms SemiCrowd, ITML and CSPA but does not consistently outperform MPCKMeans.\nBy comparing the right against the left figures, we have the following observations: VI) MPCKMeans works well only when all the experts have high accuracies; it fails when not all experts have high accuaracies (as shown on the left figures). VII) Both ITML and SemiCrowd do not benefit much from higher percentage of correct constraints; VIII) Our MCVC perfoms well in both settings.\nExplanation: Our MCVC has good performance in the unequal accuracies case because it can learn the accuracy parameters of different experts and assign higher weights to more accurate experts and lower weights to uncertain experts respectively. On the synthetic dataset, the posterior distributions of accuracy parameters α1:5, β1:5 computed from MCVC are shown in Figure 5.\nAs we can see, the modes of their distributions are very close to their true values. In our MCVC, the constraints from the m-th expert are assigned weight ωm = log αmβm(1−αm)(1−βm) when combining the constraints fromM experts (we put the derivation details in the supplementary materials). Therefore, higher accuracies (αm, βm) naturally lead to higher weights. Thus, our MCVC becomes robust to noisy constraints in the unequal accuracies case."
  }, {
    "heading": "4.2.3. SENSITIVITY ANALYSIS: TO THE NUMBER OF CLUSTERS AND TO IRRELEVANT EXPERTS",
    "text": "Number of Clusters: To investigate how the setting of K, the number of clusters, affects the performance of our\nMCVC, we vary K from 2 to 8 and run MCVC on the synthetic dataset using two expert views constructed from the procedures described in subsection 4.2.1. The number of constraints is fixed to be 2000 and the constraints generation process is repeated 10 times. First, for any value of K, MCVC can correctly assign experts to two views and also generate two clustering solutions. Second, to evaluate how the clustering performances are affected by K, we compute the NMI between the two output clustering solutions and Y1, Y2 respectively.\nThe errorbar plot is shown in Figure 6 (a). As we can see, our MCVC is very robust to the setting of K as long as K ≥ K∗, where K∗ is the maximal number of clusters among all clustering views and K∗ = 3 for our synthetic data. In problems where K∗ is unknown, we can set K to be some large value to increase the possibility that K ≥ K∗. However, in practice, we also observe that more constraints are needed to effectively train the model when K becomes large because there will be a larger number of parameters.\nIrrelevant Experts: We define irrelevant experts as those who provide constraints based on a notion of similarity that is not supported by any feature in the data. To demonstrate how the existence of irrelevant experts affect the performance of our MCVC, we simulate three expert views using the synthetic data: 1) the first two views are the same as those described in subsection 4.2.1; and 2) the third view consists of five irrelevant experts who provide constraints based on a random clustering solution Y3 and have accuracy parameters α11:15 = β11:15 = (0.95, 0.9, 0.85, 0.8, 0.75). We generate 2000 constraints from each expert. First, the first two expert views can still be perfectly recovered by our MCVC. Second, the irrelevant experts (experts 11-15) are either assigned to the first two expert views or new expert views.\nWe plot the posterior distributions of accuracy parameters for all 15 experts in Figure 6 (b,c). As we can see, the\ndensities of irrelevant experts’ accuracy parameters (red curves) concentrate around 0.5, which indicates the constraints from those experts are treated as random guesses and assigned near zero weights by MCVC. In practice, we can identify irrelevant experts by checking whether the modes of their accuracy parameters’ posteriors are close to 0.5. Therefore, our MCVC is robust to irrelevant experts."
  }, {
    "heading": "4.3. COPD Subtyping Experiment",
    "text": "Chronic Obstructive Pulmonary Disease (COPD) is a complex lung disease characterized by increasing breathlessness. Although being called one disease, doctors believe there exist different disease subtypes. The identification of different disease subtypes (clusters) can lead to tailored medical care for each patient.\nDataset: We collected 39 features from 987 COPD patients, including clinical measurements, demographics, lung function and measures from CT chest imaging.\nExperts’ Constraints: We also collected constraints provided by 29 experts, including clinicians and radiologists. We need to utilize experts’ constraints to guide the clustering algorithm. However, the key challenge is that different experts disagree on whether to put a pair of patients in the same cluster. We suspect there exist different expert views and experts in each view provide constraints based on a shared way to cluster the data. The discovery of these expert views and their corresponding clustering solutions can provide more options for further investigation.\nEvaluation: Since ground truth is not known, we can no longer use NMI to compare the performances of competing approaches. However, there are some key genetic variables that are known to be related to COPD, including copdScore (Busch et al., 2017), HHIP (Pillai et al., 2009), MMP12 (Cho et al., 2014). A clustering solution is considered as useful/relevant if patients in different clusters show significant differences on these genetic variables.\nWe randomly split the dataset into half training set and half testing set. All approaches are learned using the training set and the constraints from multiple experts. The learned models can be used to cluster test samples and generate clustering solutions. To evaluate each solution, we compute its associated p-values on these genetic variables by applying Kruskal-Wallis test on copdScore (continuous) and χ2 test on HHIP and MMP12 (discrete). We use P < 0.05 to identify significant differences in these genetic variables.\nMethods and Results: We first apply our MCVC and obtain 12 expert views. After removing irrelevant experts and views containing only one expert, there are 5 expert views left. Our physician collaborators identify 2 interesting expert views by analyzing the cluster characteristics of their associated clustering solutions, which are de-\nnoted as MCVC-A and MCVC-B respectively: 1) Solution MCVC-A contains emphysema-dominant and airwaydominant clusters, where emphysema cluster means the destruction of lung tissue and airway cluster means the increase of airway wall thickness. 2) Solution MCVC-B contains clusters of different levels of disease severity.\nFor competing approaches, we first run meta clustering and all 29 experts were lumped into one view. Then we apply SemiCrowd, ITML and MPCKMeans to combine the data matrix and constraints from all experts.\nThe p-values of solutions provided by our MCVC and competing approaches are shown in Table 1. As we can see, solutions provided by MCVC and MPCKMeans contain different clusters that show significant differences on all three COPD-related genetic variables. In contrast, both ITML and SemiCrowd are not significantly correlated with all three genetic variables. There’s some overlap between solution MPCKMeans and solution MCVC-B (with NMI value 0.39). However, solution MCVC-A can only be discovered by our approach. This way of clustering COPD patients is consistent with some COPD investigators’ latest discovery of COPD subtypes (Castaldi et al., 2014)."
  }, {
    "heading": "5. Conclusions",
    "text": "In this paper, we build a probabilistic model to discover multiple ways to cluster the data given potentially diverse inputs from multiple uncertain experts. This is achieved by automatically assigning multiple experts to different views and learning the clustering structure associated with each expert view. The quality of clustering solution in each expert view are improved by assigning higher weights to experts of higher accuracies. Experimental results on synthetic data, benchmark datasets and a real-world disease subtyping problem demonstrate that our MCVC outperforms its competing alternatives, including meta clustering, semi-supervised clustering, semi-crowdsourced clustering and consensus clustering."
  }, {
    "heading": "6. Acknowledgements",
    "text": "We would like to acknowledge support for this project from the NIH grant NIH/NHLBI RO1HL089856, RO1HL089857 and NSF/IIS-1546428."
  }],
  "year": 2017,
  "references": [{
    "title": "Constrained clustering: Advances in algorithms, theory, and applications",
    "authors": ["Basu", "Sugato", "Davidson", "Ian", "Wagstaff", "Kiri"],
    "year": 2008
  }, {
    "title": "Multi-view clustering",
    "authors": ["Bickel", "Steffen", "Scheffer", "Tobias"],
    "venue": "In IEEE International Conference on Data Mining,",
    "year": 2004
  }, {
    "title": "Integrating constraints and metric learning in semisupervised clustering",
    "authors": ["Bilenko", "Mikhail", "Basu", "Sugato", "Mooney", "Raymond J"],
    "venue": "In Proceedings of the Twenty-first International Conference on Machine Learning,",
    "year": 2004
  }, {
    "title": "Variational inference for dirichlet process mixtures",
    "authors": ["Blei", "David M", "Jordan", "Michael I"],
    "venue": "Bayesian Analysis,",
    "year": 2006
  }, {
    "title": "Meta clustering",
    "authors": ["Caruana", "Rich", "Elhawary", "Mohamed", "Nguyen", "Nam", "Smith", "Casey"],
    "venue": "In IEEE International Conference on Data Mining, pp",
    "year": 2006
  }, {
    "title": "Nonredundant multi-view clustering via orthogonalization",
    "authors": ["Cui", "Ying", "Fern", "Xiaoli Z", "Dy", "Jennifer G"],
    "venue": "In IEEE International Conference on Data Mining, pp",
    "year": 2007
  }, {
    "title": "Information-theoretic metric learning",
    "authors": ["Davis", "Jason V", "Kulis", "Brian", "Jain", "Prateek", "Sra", "Suvrit", "Dhillon", "Inderjit S"],
    "venue": "In Proceedings of the Twenty-Fourth International Conference on Machine Learning,",
    "year": 2007
  }, {
    "title": "A bayesian analysis of some nonparametric problems",
    "authors": ["Ferguson", "Thomas S"],
    "venue": "The Annals of Statistics,",
    "year": 1973
  }, {
    "title": "Solving cluster ensemble problems by bipartite graph partitioning",
    "authors": ["Fern", "Xiaoli Zhang", "Brodley", "Carla E"],
    "venue": "In Proceedings of the Twenty-first International Conference on Machine learning,",
    "year": 2004
  }, {
    "title": "Cluster ensembles. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery",
    "authors": ["Ghosh", "Joydeep", "Acharya", "Ayan"],
    "year": 2011
  }, {
    "title": "Discriminative clustering by regularized information maximization",
    "authors": ["Gomes", "Ryan G", "Krause", "Andreas", "Perona", "Pietro"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2010
  }, {
    "title": "Crowdsourcing: How the power of the crowd is driving the future of business",
    "authors": ["Howe", "Jeff"],
    "venue": "Random House,",
    "year": 2008
  }, {
    "title": "Data clustering: a review",
    "authors": ["Jain", "Anil K", "Murty", "M Narasimha", "Flynn", "Patrick J"],
    "venue": "ACM Computing Surveys,",
    "year": 1999
  }, {
    "title": "Simultaneous unsupervised learning of disparate clusterings",
    "authors": ["Jain", "Prateek", "Meka", "Raghu", "Dhillon", "Inderjit S"],
    "venue": "Statistical Analysis and Data Mining,",
    "year": 2008
  }, {
    "title": "Clustering crowds",
    "authors": ["Kajino", "Hiroshi", "Tsuboi", "Yuta", "Kashima", "Hisashi"],
    "venue": "In AAAI Conference on Artificial Intelligence,",
    "year": 2013
  }, {
    "title": "Use of ranks in one-criterion variance analysis",
    "authors": ["Kruskal", "William H", "Wallis", "W Allen"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1952
  }, {
    "title": "Autograd: Reverse-mode differentiation of native python",
    "authors": ["D Maclaurin", "D Duvenaud", "M Johnson", "Adams", "RP"],
    "venue": "http://github. com/HIPS/autograd,",
    "year": 2015
  }, {
    "title": "Bayesian nonparametric crowdsourcing",
    "authors": ["Moreno", "Pablo G", "Artés-Rodrı́guez", "Antonio", "Teh", "Yee Whye", "Perez-Cruz", "Fernando"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2015
  }, {
    "title": "Deaths: final data",
    "authors": ["Murphy", "Sherry L", "Xu", "Jiaquan", "Kochanek", "Kenneth D"],
    "venue": "National Vital Statistics System,",
    "year": 2010
  }, {
    "title": "On spectral clustering: Analysis and an algorithm",
    "authors": ["Ng", "Andrew Y", "Jordan", "Michael I", "Weiss", "Yair"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2001
  }, {
    "title": "Multiple non-redundant spectral clustering views",
    "authors": ["Niu", "Donglin", "Dy", "Jennifer G", "Jordan", "Michael I"],
    "venue": "In Proceedings of the Twenty-seventh International Conference on Machine Learning,",
    "year": 2010
  }, {
    "title": "A nonparametric bayesian model for multiple clustering with overlapping feature views",
    "authors": ["Niu", "Donglin", "Dy", "Jennifer G", "Ghahramani", "Zoubin"],
    "venue": "In Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics,",
    "year": 2012
  }, {
    "title": "Objective criteria for the evaluation of clustering methods",
    "authors": ["Rand", "William M"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1971
  }, {
    "title": "Cluster ensembles—a knowledge reuse framework for combining multiple partitions",
    "authors": ["Strehl", "Alexander", "Ghosh", "Joydeep"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2002
  }, {
    "title": "Learning from crowds in the presence of schools of thought",
    "authors": ["Tian", "Yuandong", "Zhu", "Jun"],
    "venue": "In Proceedings of the Eighteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp",
    "year": 2012
  }, {
    "title": "Clustering ensembles: Models of consensus and weak partitions",
    "authors": ["Topchy", "Alexander", "Jain", "Anil K", "Punch", "William"],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
    "year": 2005
  }, {
    "title": "A tutorial on spectral clustering",
    "authors": ["Von Luxburg", "Ulrike"],
    "venue": "Statistics and Computing,",
    "year": 2007
  }, {
    "title": "Clustering with instancelevel constraints",
    "authors": ["Wagstaff", "Kiri", "Cardie", "Claire"],
    "venue": "AAAI Conference on Artificial Intelligence,",
    "year": 2000
  }, {
    "title": "Semi-crowdsourced clustering: Generalizing crowd labeling by robust distance metric learning",
    "authors": ["Yi", "Jinfeng", "Jin", "Rong", "Jain", "Shaili", "Yang", "Tianbao", "Anil K"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2012
  }, {
    "title": "International cancer genome consortium data portala onestop shop for cancer genomics",
    "authors": ["Zhang", "Junjun", "Baran", "Joachim", "Cros", "Anthony", "Guberman", "Jonathan M", "Haider", "Syed", "Hsu", "Jack", "Liang", "Yong", "Rivkin", "Elena", "Wang", "Jianxin", "Whitty", "Brett"],
    "year": 2011
  }],
  "id": "SP:bc6a0690c1236e1e89d239a6b2731debd4637c05",
  "authors": [{
    "name": "Yale Chang",
    "affiliations": []
  }, {
    "name": "Junxiang Chen",
    "affiliations": []
  }, {
    "name": "Michael H. Cho",
    "affiliations": []
  }, {
    "name": "Peter J. Castaldi",
    "affiliations": []
  }, {
    "name": "Edwin K. Silverman",
    "affiliations": []
  }, {
    "name": "Jennifer G. Dy",
    "affiliations": []
  }],
  "abstractText": "Expert input can improve clustering performance. In today’s collaborative environment, the availability of crowdsourced multiple expert input is becoming common. Given multiple experts’ inputs, most existing approaches can only discover one clustering structure. However, data is multi-faceted by nature and can be clustered in different ways (also known as views). In an exploratory analysis problem where ground truth is not known, different experts may have diverse views on how to cluster data. In this paper, we address the problem on how to automatically discover multiple ways to cluster data given potentially diverse inputs from multiple uncertain experts. We propose a novel Bayesian probabilistic model that automatically learns the multiple expert views and the clustering structure associated with each view. The benefits of learning the experts’ views include 1) enabling the discovery of multiple diverse clustering structures, and 2) improving the quality of clustering solution in each view by assigning higher weights to experts with higher confidence. In our approach, the expert views, multiple clustering structures and expert confidences are jointly learned via variational inference. Experimental results on synthetic datasets, benchmark datasets and a real-world disease subtyping problem show that our proposed approach outperforms competing baselines, including meta clustering, semisupervised clustering, semi-crowdsourced clustering and consensus clustering.",
  "title": "Multiple Clustering Views from Multiple Uncertain Experts"
}