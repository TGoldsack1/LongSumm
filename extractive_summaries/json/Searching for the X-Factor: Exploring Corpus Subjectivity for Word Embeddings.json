{
  "sections": [{
    "text": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers), pages 1212–1221 Melbourne, Australia, July 15 - 20, 2018. c©2018 Association for Computational Linguistics\n1212\nWe explore the notion of subjectivity, and hypothesize that word embeddings learnt from input corpora of varying levels of subjectivity behave differently on natural language processing tasks such as classifying a sentence by sentiment, subjectivity, or topic. Through systematic comparative analyses, we establish this to be the case indeed. Moreover, based on the discovery of the outsized role that sentiment words play on subjectivity-sensitive tasks such as sentiment classification, we develop a novel word embedding SentiVec which is infused with sentiment information from a lexical resource, and is shown to outperform baselines on such tasks."
  }, {
    "heading": "1 Introduction",
    "text": "Distributional analysis methods such as Word2Vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) have been critical for the success of many large-scale natural language processing (NLP) applications (Collobert et al., 2011; Socher et al., 2013; Goldberg, 2016). These methods employ distributional hypothesis (i.e., words used in the same contexts tend to have similar meaning) to derive distributional meaning via context prediction tasks and produce dense word embeddings.\nWhile there have been active and ongoing research on improving word embedding methods (see Section 5), there is a relative dearth of study on the impact that an input corpus may have on the quality of the word embeddings. The previous preoccupation centers around corpus size, i.e., a larger corpus is perceived to be richer in statistical information. For instance, popular corpora include Wikipedia, Common Crawl, and Google News.\nWe postulate that there may be variations across corpora owing to factors that affect language use. Intuitively, the many things we write (a work email, a product review, an academic publication, etc.) may each involve certain stylistic, syntactic, and lexical choices, resulting in meaningfully different distributions of word cooccurrences. Consequently, such factors may be encoded in the word embeddings, and input corpora may be differentially informative towards various NLP tasks.\nIn this work, we are interested in the notion of subjectivity. Some NLP tasks, such as sentiment classification, revolve around subjective expressions of likes or dislikes. Others, such as topic classification, revolve around more objective elements of whether a document belongs to a topic (e.g., science, politics). Our central hypothesis is that word embeddings learnt from input corpora of contrasting levels of subjectivity perform differently when classifying sentences by sentiment, subjectivity, or topic. As the first contribution, we outline an experimental scheme to explore this hypothesis in Section 2, and conduct a series of controlled experiments in Section 3 establishing that there exists a meaningful difference between word embeddings derived from objective vs. subjective corpora. We further systematically investigate factors that could potentially explain the differences.\nUpon discovering from the investigation that sentiment words play a particularly important role in subjectivity-sensitive NLP tasks, such as sentiment classification, as the second contribution, in Section 4 we develop SentiVec, a novel word embedding method infused with information from lexical resources such as a sentiment lexicon. We further identify two alternative lexical objectives: Logistic SentiVec based on discriminative logistic regression, and Spherical SentiVec based on soft clustering effect of von Mises-Fisher distributions. In Section 6, the proposed word embeddings show\nevident improvements on sentiment classification, as compared to the base model Word2Vec and other baselines using the same lexical resource."
  }, {
    "heading": "2 Data and Methodology",
    "text": "We lay out the methodology for generating word embeddings of contrasting subjectivity, whose effects are tested on several text classification tasks."
  }, {
    "heading": "2.1 Generating Word Embeddings",
    "text": "As it is difficult to precisely quantify the degree of subjectivity of a corpus, we resort to generating word embeddings from two corpora that contrast sharply in subjectivity, referring to them as the Objective Corpus and the Subjective Corpus.\nObjective Corpus As virtually all contents are written by humans, an absolutely objective corpus (in the philosophical sense) may prove elusive. There are however exemplars where, by construction, a corpus aspires to be as objective as possible, and probably achieves that in practical terms. We postulate that one such corpus is Wikipedia. Its list of policies and guidelines1, assiduously enforced by an editorial team, specify that an article must be written from a neutral point of view, which among other things means “representing fairly, proportionately, and, as far as possible, without editorial bias, all of the significant views that have been published by reliable sources on a topic.”. Moreover, it is a common resource for training distributional word embeddings and adopted widely by the research community to solve various NLP problems. Hence, in this study, we use Wikipedia as the Objective Corpus.\nSubjective Corpus By extension, one may then deem a corpus subjective if its content does not at least meet Wikipedia’s neutral point of view requirement. In other words, if the content is replete with personal feelings and opinions. We posit that product reviews would be one such corpus. For instance, Amazon’s Community Guideline2 states that “Amazon values diverse opinions”, and that “Content you submit should be relevant and based on your own honest opinions and experience.”. Reviews consist of expressive content written by customers, and may not strive for the neutrality of an encyclopedia. We rely on a\n1https://en.wikipedia.org/wiki/ Wikipedia:List_of_policies_and_ guidelines\n2https://www.amazon.com/gp/help/ customer/display.html?nodeId=201929730\nlarge corpus of Amazon reviews from various categories (e.g., electronics, jewelry, books, and etc.) (McAuley et al., 2015) as the Subjective Corpus.\nWord Embeddings For the comparative analysis in Section 3, we employ Word2Vec (reviewed below) to generate word embeddings from each corpus. Later on in Section 4, we will propose a new word embedding method called SentiVec.\nFor Word2Vec, we use the Skip-gram model to train distributional word embeddings on the Objective Corpus and the Subjective Corpus respectively. Skip-gram aims to find word embeddings that are useful for predicting nearby words. The objective is to maximize the context probability:\nlogL(W ;C) = ∑ w∈W ∑ w′∈C(w) log P(w′|w), (1)\nwhere W is an input corpus and C(w) is the context of token w. The probability of context word w′, given observed word w is defined via softmax:\nP(w′|w) = exp (vw ′ · vw)∑\nŵ∈V exp (vŵ · vw) , (2)\nwhere vw and vw′ are corresponding embeddings and V is the corpus vocabulary. Though theoretically sound, the formulation is computationally impractical and requires tractable approximation.\nMikolov et al. (2013) propose two efficient procedures to optimize (1): Hierarchical Softmax and Negative Sampling (NS). In this work we focus on the widely adopted NS. The intuition is that a “good” model should be able to differentiate observed data from noise. The differentiation task is defined using logistic regression; the goal is to tell apart real context-word pair (w′, w) from randomly generated noise pair (ŵ, w). Formally,\nlogL[w‘,w] = log σ (vw′ · vw) + k∑ i=1 log σ (−vŵi · vw),\n(3)\nwhere σ( · ) is a sigmoid function, and {ŵi}ki=1 are negative samples. Summing up all the contextword pairs, we derive the NS Skip-gram objective:\nlogLword2vec(W ;C) = ∑ w∈W ∑ w′∈C(w) logL[w‘,w]. (4)\nTraining word embeddings with Skip-gram, we keep the same hyperparameters across all the runs: 300 dimensions for embeddings, k = 5 negative samples, and window of 5 tokens. The Objective\nand Subjective corpora undergo the same preprocessing, i.e., discarding short sentences (< 5 tokens) and rare words (< 10 occurrences), removing punctuation, normalizing Unicode symbols."
  }, {
    "heading": "2.2 Evaluation Tasks",
    "text": "To compare word embeddings, we need a common yardstick. It is difficult to define an inherent quality to word embeddings. Instead, we put them through several evaluation tasks that can leverage word embeddings and standardize their formulations as binary classification tasks. To boil the comparisons down to the essences of word embeddings (which is our central focus), we rely on standardized techniques so as to attribute as much of the differences as possible to the word embeddings. We use logistic regression for classification, and represent a text snippet (e.g., a sentence) in the feature space as the average of the word embeddings of tokens in the snippet (ignoring out-ofvocabulary tokens). The evaluation metric is the average accuracy from 10-fold cross validation.\nThere are three evaluation tasks of varying degrees of hypothetical subjectivity, as outlined below. Each may involve multiple datasets.\nSentiment Classification Task This task classifies a sentence into either positive or negative. We use two groups of datasets as follows.\nThe first group consists of 24 datasets from UCSD Amazon product data3 corresponding to various product categories. Each review has a rating from 1 to 5, which is transformed into positive (ratings 4 or 5) or negative (ratings 1 or 2) class. For each dataset respectively, we sample 5000 sentences each from the positive and negative reviews. Note that these sentences used for this evaluation task have not participated in the generation of word embeddings. Due to space constraint, in most cases we present the average accuracy across the datasets, but where appropriate we enumerate the results for each dataset.\nThe second is Cornell’s sentence polarity dataset v1.04 (Pang and Lee, 2005), made up of 5331 each of positive and negative sentences from Rotten Tomatoes movie reviews. The inclusion of this out-of-domain evaluation dataset is useful for examining whether the performance of word embeddings from the Subjective Corpus on the first\n3http://jmcauley.ucsd.edu/data/amazon/ 4http://www.cs.cornell.edu/people/\npabo/movie-review-data/rt-polaritydata. README.1.0.txt\ngroup above may inadvertently be affected by indomain advantage arising from its Amazon origin.\nSubjectivity Classification Task This task classifies a sentence into subjective or objective. The dataset is Cornell’s subjectivity dataset v1.05, consisting of 5000 subjective sentences derived from Rotten Tomatoes (RT) reviews and 5000 objective sentences derived from IMDB plot summaries (Pang and Lee, 2004). This task is probably less sensitive to the subjectivity within word embeddings than sentiment classification, as determining whether a sentence is subjective or objective should ideally be an objective undertaking.\nTopic Classification Task We use the 20 Newsgroups dataset6 (“bydate” version), whereby the newsgroups are organized into six subject matter groupings. We extract the message body and split them into sentences. Each group’s sentences then form the in-topic class, and we randomly sample an equivalent number of sentences from the remaining newsgroups to form the out-of-topic class. This results in six datasets, each corresponding to a binary classification task. In most cases, we present the average results, and where appropriate we enumerate the results for each dataset. Hypothetically, this task is the least affected by the subjectivity within word embeddings."
  }, {
    "heading": "3 Comparative Analyses of Subjective vs. Objective Corpora",
    "text": "We conduct a series of comparative analyses under various setups. For each, we compare the performance in the evaluation tasks when using the Objective Corpus and the Subjective Corpus. Table 1 shows the results for this series of analyses.\nInitial Condition Setup I seeks to answer whether there is any difference between word embeddings derived from the Objective Corpus and the Subjective Corpus. The word embeddings were trained on the whole data respectively. Table 1 shows the corpus statistics and classification accuracies. Evidently, the Subjective word embeddings outperform the Objective word embeddings on all the evaluation tasks. The margins are largest for sentiment classification (86.5% vs. 81.5% or +5% Amazon, and 78.2% vs. 75.4% or +2.8% on Rotten Tomatoes or RT). For subjectivity and topic classifications, the differences are smaller.\n5http://www.cs.cornell.edu/people/ pabo/movie-review-data/subjdata.README. 1.0.txt\n6http://qwone.com/˜jason/20Newsgroups/\nAs earlier hypothesized, the sentiment classification task is more sensitive to subjectivity within word embeddings than the other tasks. Therefore, training word embeddings on a subjective corpus may confer an advantage for such tasks. On the other hand, the corpus statistics show a substantial difference in corpus size, which could be an alternative explanation for the outperformance by the Subjective Corpus if the larger corpus contains more informative distributional statistics.\nControlling for Corpus Size In Setup II, we keep the number of sentences in both corpora the same, by randomly downsampling sentences in the Subjective Corpus. This procedure consequently reduces the number of types and tokens (see Table 1, Setup II, Corpus Statistics). Note that the number of tokens in the Subjective corpus is now fewer than in the Objective, the latter suffers no change. Yet, even after a dramatic reduction in size, the Subjective embeddings still outperform the Objective significantly on both datasets of the sentiment classification task (+4% on Amazon and +2.5% on RT), while showing similar performance on subjectivity and topic classifications.\nThis bolsters the earlier observation that sentiment classification is more sensitive to subjectivity. While there is a small effect due to corpus size difference, the gap in performance between Subjective and Objective embeddings on sentiment classification is still significant and cannot be explained away by the corpus size alone.\nControlling for Vocabulary While the Subjective Corpus has a much smaller vocabulary (i.e., # types), we turn a critical eye on whether its apparent advantage lies in having access to special word types that do not exist in the Objective Corpus. In Setup III, we keep the training vocabulary the same for both, removing the types that are\npresent in one corpus but not in the other, so that out-of-vocabulary words are ignored in the training phase. Table 1, Setup III, shows significant reduction in types for both corpora. Yet, the outperformance by the Subjective embeddings on the sentiment classification task still stands (+3.8% on Amazon and +2.3% on RT). Moreover, it is so for both Amazon and Rotten Tomatoes datasets, implying that it is not due to close in-domain similarity between the corpora used for training the word embeddings and the classification tasks.\nSignificant Words To get more insights on the difference between the Subjective and Objective corpora, we analyze the mistakes word embeddings make on the development folds. At this point we focus on the sentiment classification task and specifically on the Amazon data, which indicates the largest performance differences in the controlled experiments (see Table 1, Setup III).\nAs words are still the main unit of information in distributional word embeddings, we extract words strongly associated with misclassified sentences. We employed log-odds ratio with informative Dirichlet prior method (Monroe et al., 2008) to quantify this association. It is used to contrast the words in misclassified vs. correctly classified sentences, and accounts for the variance of words and their prior counts taken from a large corpus.\nTable 2 shows the top 25 words most associated with the misclassified sentences, sorted by their association scores. On average 50% of the mistakes overlap for both word embeddings, therefore, some of the words are included in both lists. 40 − 44% of these words carry positive or negative sentiment connotations in general (see the underlined words in Table 2), while other words like return or send may carry sentiment connotation in e-commerce context. We check if a word carries sentiment connotation using sentiment lexicon compiled by Hu and Liu (2004), including 6789 words along with positive or negative labels.\nWe also observe linguistic negations (i.e., not, Don’t). For instance, the word most associated with the Objective-specific mistakes (excluding the Subjective misclassified sentences) is not, which suggests that perhaps Subjective word embedding accommodates better understanding of linguistic negations, which may partially explain the difference. However, our methodology as outlined in Section 2.2 permits exchangeable word order and is not intended to analyze structural interaction between words. We focus on further analysis of sentiment words, leaving linguistic negations in word embeddings for future investigation.\nControlling for Sentiment Words To control for the “amount” of sentiment in the Subjective and Objective corpora, we use sentiment lexicon compiled by Hu and Liu (2004). For each corpus, we create two subcorpora: With Sentiment contains only the sentences with at least one word from the sentiment lexicon, while Without Sentiment is the complement. We match the corpora on the number of sentences, downsampling the larger corpus, train word embeddings on each subcorpus, and proceed with the classification experiments. Table 3 shows the results, including that of random word embeddings for reference. Sentiment lexicon has a significant impact on the performance of sentiment and subjectivity classifications, and a smaller impact on topic classification. Without sentiment, the Subjective embeddings prove more robust, still outperforming the Objective on sentiment classification, while the Objective performs close to random word embeddings on Amazon .\nIn summary, evidences from the series of controlled experiments support the existence of some X-factor to the Subjective embeddings, which confers superior performance in subjectivity-sensitive tasks such as sentiment classification."
  }, {
    "heading": "4 Sentiment-Infused Word Embeddings",
    "text": "To leverage the consequential sentiment information, we propose a family of methods, called SentiVec, for training distributional word embeddings that are infused with information on the sentiment polarity of words. The methods are built upon Word2Vec optimization algorithm and make use of available lexical sentiment resources such as SentiWordNet (Baccianella et al., 2010), sentiment lexicon by Hu and Liu (2004), and etc.\nSentiVec seeks to satisfy two objectives, namely context prediction and lexical category prediction:\nlogL = logLword2vec(W ;C) + λ logLlex(W,L), (5)\nwhere Lword2vec(W ;C) is the Skip-gram objective as in (4); Llex(W,L) is a lexical objective for corpus W and lexical resource L; and λ is a tradeoff parameter. Lexical resource L = {Xi}ni=1 comprises of n word sets, each Xi contains words of the same category. For sentiment classification, we consider positive and negative word categories."
  }, {
    "heading": "4.1 Logistic SentiVec",
    "text": "Logistic SentiVec admits lexical resource in the form of two disjoint word sets, L = {X1, X2}, X1 ∩X2 = ∅. The objective is to tell apart which word set of L word w belongs to:\nlogLlex(W,L) (6) = ∑ w∈X1 log P(w ∈ X1) + ∑ w∈X2 log P(w ∈ X2).\nWe further tie these probabilities together, and cast the objective as a logistic regression problem:\nP(w ∈ X1) = 1− P(w ∈ X2) = σ(vw · τ), (7)\nwhere vw is a word embedding and τ is a direction vector. Since word embeddings are generally invariant to scaling and rotation when used as downstream feature representations, τ can be chosen randomly and fixed during training. We\nexperiment with randomly sampled unit length directions. For simplicity, we also scale embedding vw to its unit length when computing vw ·τ , which now equals to cosine similarity between vw and τ .\nWhen vw is completely aligned with τ , the cosine similarity between them is 1, which maximizes P(w ∈ X1) and favors words in X1. When vw is opposite to τ , the cosine similarity equals to −1, which maximizes P(w ∈ X2) and predicts vectors from X2. Orthogonal vectors have cosine similarity of 0, which makes both w ∈ X1 and w ∈ X2 equally probable. Optimizing (6) makes the corresponding word embeddings ofX1 andX2 gravitate to the opposite semispaces and simulates clustering effect for the words of the same category, while the Word2Vec objective prevents words from collapsing to the same directions.\nOptimization The objective in (6) permits simple stochastic gradient ascent optimization and can be combined with negative sampling procedure for Skip-gram in (5). The gradient for unnormalized embedding vw is solved as follows:( logL[w∈X1](D,L) )′ vwi = (log P (x ∈ X1))′vwi\n= 1\n‖vw‖2 σ ( −vw · τ ‖vw‖ )( τi ‖vw‖ − vwi vw · τ ‖vw‖ ) (8)\nThe optimization equation for vw, when w ∈ X2, can be derived analogously."
  }, {
    "heading": "4.2 Spherical SentiVec",
    "text": "Spherical SentiVec extends Logistic SentiVec by dealing with any number of lexical categories, L = {Xi}ni=1. As such, the lexical objective takes on generic form:\nlogLlex(W,L) = n∑ i=1 ∑ w∈Xi log P (w ∈ Xi), (9)\nEach P (w ∈ Xi) defines embedding generating process. We assume each length-normalized vw for w of L is generated w.r.t. a mixture model of von Mises-Fisher (vMF) distributions. vMF is a probability distribution on a multidimensional sphere, characterized by parameters µ (mean direction) and κ (concentration parameter). Sampled points are concentrated around µ; the greater the κ, the closer the sampled points are to µ. We consider only unimodal vMF distributions, restricting concentration parameters to be strictly positive. Hereby, each Xi ∈ L is assigned to vMF\ndistribution parameters (µi, κi) and the membership probabilities are defined as follows:\nP(w ∈ Xi) = P (vw;µi, κi) = 1 Zκi eκiµi·vw ,\n(10)\nwhere Zκ is the normalization factor. The Spherical SentiVec lexical objective forces words of every Xi ∈ L to gravitate towards and concentrate around their direction mean µi. As in Logistic SentiVec, it simulates clustering effect for the words of the same set. In comparison to the direction vector of Logistic SentiVec, mean directions of Spherical SentiVec when fixed can substantially influence word embeddings training and must be carefully selected. We optimize the mean directions along with the word embeddings using alternating procedure resembling K-means clustering algorithm. For simplicity, we keep concentration parameters tied, κ1 = κ2 = ... = κn = κ, and treat κ as a hyperparameter of this algorithm.\nOptimization We derive optimization procedure for updating word embeddings assuming fixed direction means. Like Logistic SentiVec, Spherical SentiVec can be combined with the negative sampling procedure of Skip-gram. The gradient for unnormalized word embedding vw is solved by the following equation:\n( logL[w∈Xi] (W,L) )′ vwj = κi\n( µij ‖vw‖ − vwj vw·µi‖vw‖ ) ‖vw‖2\n(11)\nOnce word embedding vw (w ∈ Xi) is updated, we revise direction mean µi w.r.t. maximum likelihood estimator:\nµi = ∑ w∈Xi vw∥∥∥∑w∈Xi vw∥∥∥ . (12)\nUpdating the direction means in such a way ensures that the lexical objective is non-decreasing. Assuming the stochastic optimization procedure for Lword2vec complies with the same nondecreasing property, the proposed alternating procedure converges."
  }, {
    "heading": "5 Related Work",
    "text": "There have been considerable research on improving the quality of distributional word embeddings. Bolukbasi et al. (2016) seek to debias word embeddings from gender stereotypes. Rothe and Schütze (2017) incorporate WordNet\nlexeme and synset information. Mrkšic et al. (2016) encode antonym-synonym relations. Liu et al. (2015) encode ordinal relations such as hypernym and hyponym. Kiela et al. (2015) augment Skip-gram to enforce lexical similarity or relatedness constraints, Bollegala et al. (2016) modify GloVe optimization procedure for the same purpose. Faruqui et al. (2015) employ semantic relations of PPDB, WordNet, FrameNet to retrofit word embeddings for various prediction tasks. We use this Retrofitting method7 as a baseline.\nSocher et al. (2011) derive multi-word embeddings for sentiment distribution prediction, while we focus on lexical distributional analysis. Maas et al. (2011) and Tang et al. (2016) use documentlevel sentiment annotations to fit word embeddings, but document annotation might not always be available for distributional analysis on neutral corpora such as Wikipedia. SentiVec relies on simple sentiment lexicon instead. Refining (Yu et al., 2018) aligns the sentiment scores taken from lexical resource and the cosine similarity scores of corresponding word embeddings. The method generally requires fine-grained sentiment scores for the words, which may not be available in some settings. We use Refining as a baseline and adopt coarse-grained sentiment lexicon for this method.\nVillegas et al. (2016) compare various distributional word embeddings arising from the same corpus for sentiment classification, whereas we focus on the differentiation in input corpora and propose novel sentiment-infused word embeddings."
  }, {
    "heading": "6 Experiments",
    "text": "The objective of experiments is to study the efficacy of Logistic SentiVec and Spherical SentiVec word embeddings on the aforementioned text classification tasks. One natural baseline is Word2Vec, as SentiVec subsumes its context prediction objective, while further incorporating lexical category prediction. We include two other baselines that can leverage the same lexical resource but in manners different from SentiVec, namely: Retrofitting (Faruqui et al., 2015) and Refining (Yu et al., 2018). For these methods, we generate their word embeddings based on Setup III (see Section 3). All the methods were run multiple times with various hyperparameters, optimized via grid-search; for each we present the best performing setting.\n7Original code is available at: https://github. com/mfaruqui/retrofitting\nFirst, we discuss the sentiment classification task. Table 4 shows the unfolded results for the 24 classification datasets of Amazon, as well as for Rotten Tomatoes. For each classification dataset (row), and for the Objective and Subjective embedding corpora respectively, the best word embedding methods are shown in bold. An asterisk indicates statistically significant8 results at 5% in comparison to Word2Vec. Both SentiVec variants outperform Word2Vec in the vast majority of the cases. The degree of outperformance is higher for the Objective than the Subjective word embeddings. This is a reasonable trend given our previous findings in Section 3. As the Objective Corpus encodes less information than the Subjective Corpus for sentiment classification, the former is more likely to benefit from the infusion of sentiment information from additional lexical resources. Note that the sentiment infusion into the word embeddings comes from separate lexical resources, and does not involve any sentiment classification label.\nSentiVec also outperforms the two baselines that benefit from the same lexical resources. Retrofitting does not improve upon Word2Vec, with the two embeddings essentially indistinguishable (the difference is only noticeable at the second decimal point). Refining makes the word embeddings perform worse on the sentiment classification task. One possible explanation is that Refining normally requires fine-grained labeled lexicon, where the words are scored w.r.t. the sentiment scale, whereas we use sentiment lexicon of two labels (i.e., positive or negative). SentiVec accepts coarse-grained sentiment lexicons, and potentially could be extended to deal with fine-grained labels.\nAs previously alluded to, topic and subjectivity classifications are less sensitive to the subjectivity within word embeddings than sentiment classification. One therefore would not expect much, if any, performance gain from infusion of sentiment information. However, such infusion should not subtract or harm the quality of word embeddings either. Table 5 shows that the unfolded results for topic classification on the six datasets, and the result for subjectivity classification are similar across methods. Neither the SentiVec variants, nor Retrofitting and Refining, change the subjectivity and topic classification capabilities much, which means that the used sentiment lexicon is targeted only at the sentiment subspace of embeddings.\n8We use paired t-test to compute p-value.\nIllustrative Changes in Embeddings To give more insights on the difference between SentiVec and Word2Vec, we show “flower” diagrams in Figure 1 for Logistic SentiVec and Figure 2 for Spherical SentiVec. Each is associated with a reference word (e.g., good for Figure 1a), and indicates relative changes in cosine distances between the reference word and the testing words surrounding the “flower”. Every testing word is associated with a “petal” or black axis extending from the center of the circle. The “petal” length is proportional to the relative distance change in two word embeddings: κ =\ndSentiV ec(wref ,wtesting) dword2vec(wref ,wtesting)\n, where dSentiV ec and dword2vec are cosine distances between reference wref and testing wtesting words in SentiVec and Word2Vec embeddings correspondingly. If the distance remains unchanged (κ = 1), then the “petal” points at the circumference; if the reference and testing words are closer in the SentiVec embedding\nthan they are in Word2Vec (κ < 1), the “petal” lies inside the circle; when the distance increases (κ > 1), the “petal” goes beyond the circle.\nThe diagrams are presented for Objective Embeddings9. We use three reference words: good (positive), bad (negative), time (neutral); as well as three groups of testing words: green for words randomly sampled from positive lexicon (Sector I-II), red for words randomly sampled from negative lexicon (Sector II-III), and gray for frequent neutral common nouns (Sector III-I).\nFigure 1 shows changes produced by Logistic SentiVec. For the positive reference word (Figure 1a), the average distance to the green words is shortened, whereas the distance to the red words increases. The reverse is observed for the negative reference word (Figure 1b). This observation\n9The diagrams for Subjective Embeddings show the same trend, with the moderate changes.\ncomplies with the lexical objective (7) of Logistic SentiVec, which aims to separate the words of two different classes. Note that the gray words suffer only moderate change with respect to positive and negative reference words. For the neutral reference word (Figure 1c), the distances are only moderately affected across all testing groups.\nFigure 2 shows that Spherical SentiVec tends to make embeddings more compact than Logistic SentiVec. As the former’s lexical objective (9) is designed for clustering, but not for separation, we look at the comparative strength of the clustering effect on the testing words. For the positive reference word (Figure 2a), the largest clustering effect is achieved for the green words. For the negative reference word (Figure 2b), as expected, the red words are affected the most. The gray words suffer the least change for all the reference words.\nIn summary, SentiVec effectively provides an advantage for subjectivity-sensitive task such as sentiment classification, while not harming the performance of other text classification tasks."
  }, {
    "heading": "7 Conclusion",
    "text": "We explore the differences between objective and subjective corpora for generating word embeddings, and find that there is indeed a difference in the embeddings’ classification task performances. Identifying the presence of sentiment words as one key factor for the difference, we propose a novel method SentiVec to train word embeddings that are infused with the sentiment polarity of words derived from a separate sentiment lexicon. We further identify two lexical objectives: Logistic SentiVec and Spherical SentiVec. The proposed word embeddings show improvements in sentiment classification, while maintaining their performance on subjectivity and topic classifications."
  }, {
    "heading": "Acknowledgments",
    "text": "This research is supported by the National Research Foundation, Prime Minister’s Office, Singapore under its NRF Fellowship Programme (Award No. NRF-NRFF2016-07)."
  }],
  "year": 2018,
  "references": [{
    "title": "Sentiwordnet 3.0: an enhanced lexical resource for sentiment analysis and opinion mining",
    "authors": ["Stefano Baccianella", "Andrea Esuli", "Fabrizio Sebastiani"],
    "venue": "In LREC",
    "year": 2010
  }, {
    "title": "Joint word representation learning using a corpus and a semantic lexicon",
    "authors": ["Danushka Bollegala", "Mohammed Alsuhaibani", "Takanori Maehara", "Ken-ichi Kawarabayashi."],
    "venue": "Proceedings of AAAI.",
    "year": 2016
  }, {
    "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
    "authors": ["Tolga Bolukbasi", "Kai-Wei Chang", "James Y Zou", "Venkatesh Saligrama", "Adam T Kalai."],
    "venue": "Proceedings of NIPS.",
    "year": 2016
  }, {
    "title": "Natural language processing (almost) from scratch",
    "authors": ["Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."],
    "venue": "JMLR 12(Aug).",
    "year": 2011
  }, {
    "title": "Retrofitting word vectors to semantic lexicons",
    "authors": ["Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A Smith."],
    "venue": "Proceedings of NAACL-HLT .",
    "year": 2015
  }, {
    "title": "A primer on neural network models for natural language processing",
    "authors": ["Yoav Goldberg."],
    "venue": "JAIR 57.",
    "year": 2016
  }, {
    "title": "Mining and summarizing customer reviews",
    "authors": ["Minqing Hu", "Bing Liu."],
    "venue": "Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. ACM.",
    "year": 2004
  }, {
    "title": "Specializing word embeddings for similarity or relatedness",
    "authors": ["Douwe Kiela", "Felix Hill", "Stephen Clark."],
    "venue": "Proceedings of EMNLP.",
    "year": 2015
  }, {
    "title": "Learning semantic word embeddings based on ordinal knowledge constraints",
    "authors": ["Quan Liu", "Hui Jiang", "Si Wei", "Zhen-Hua Ling", "Yu Hu."],
    "venue": "Proceedings of ACL-IJCNLP. volume 1.",
    "year": 2015
  }, {
    "title": "Learning word vectors for sentiment analysis",
    "authors": ["Andrew L Maas", "Raymond E Daly", "Peter T Pham", "Dan Huang", "Andrew Y Ng", "Christopher Potts."],
    "venue": "Proceedings of ACL-HLT .",
    "year": 2011
  }, {
    "title": "Image-based recommendations on styles and substitutes",
    "authors": ["Julian McAuley", "Christopher Targett", "Qinfeng Shi", "Anton Van Den Hengel."],
    "venue": "Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information",
    "year": 2015
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Ad-",
    "year": 2013
  }, {
    "title": "Fightin’words: Lexical feature selection and evaluation for identifying the content of political conflict",
    "authors": ["Burt L Monroe", "Michael P Colaresi", "Kevin M Quinn."],
    "venue": "Political Analysis 16(4).",
    "year": 2008
  }, {
    "title": "Counter-fitting word vectors to linguistic constraints",
    "authors": ["Nikola Mrkšic", "Diarmuid OSéaghdha", "Blaise Thomson", "Milica Gašic", "Lina Rojas-Barahona", "Pei-Hao Su", "David Vandyke", "Tsung-Hsien Wen", "Steve Young."],
    "venue": "Proceedings of NAACL-HLT .",
    "year": 2016
  }, {
    "title": "A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts",
    "authors": ["Bo Pang", "Lillian Lee."],
    "venue": "Proceedings of ACL.",
    "year": 2004
  }, {
    "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
    "authors": ["Bo Pang", "Lillian Lee."],
    "venue": "Proceedings of ACL.",
    "year": 2005
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."],
    "venue": "Proceedings of EMNLP.",
    "year": 2014
  }, {
    "title": "Autoextend: Combining word embeddings with semantic resources",
    "authors": ["Sascha Rothe", "Hinrich Schütze."],
    "venue": "Computational Linguistics 43(3).",
    "year": 2017
  }, {
    "title": "Semi-supervised recursive autoencoders for predicting sentiment distributions",
    "authors": ["Richard Socher", "Jeffrey Pennington", "Eric H Huang", "Andrew Y Ng", "Christopher D Manning."],
    "venue": "Proceedings of EMNLP.",
    "year": 2011
  }, {
    "title": "Recursive deep models for semantic compositionality over a sentiment treebank",
    "authors": ["Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D Manning", "Andrew Ng", "Christopher Potts."],
    "venue": "Proceedings of EMNLP.",
    "year": 2013
  }, {
    "title": "Sentiment embeddings with applications to sentiment analysis",
    "authors": ["Duyu Tang", "Furu Wei", "Bing Qin", "Nan Yang", "Ting Liu", "Ming Zhou."],
    "venue": "IEEE TKDE 28(2).",
    "year": 2016
  }, {
    "title": "Vector-based word representations for sentiment analysis: a comparative study",
    "authors": ["Marı́a Paula Villegas", "Marı́a José Garciarena Ucelay", "Juan Pablo Fernández", "Miguel A Álvarez Carmona", "Marcelo Luis Errecalde", "Leticia Cagnina"],
    "venue": "XXII",
    "year": 2016
  }, {
    "title": "Refining word embeddings using intensity scores for sentiment analysis",
    "authors": ["L.C. Yu", "J. Wang", "K.R. Lai", "X. Zhang."],
    "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing 26(3).",
    "year": 2018
  }],
  "id": "SP:d3c72df0ffd5fde1e8a29f16b2b7af8eed97b2ee",
  "authors": [{
    "name": "Maksim Tkachenko",
    "affiliations": []
  }, {
    "name": "Chong Cher Chia",
    "affiliations": []
  }, {
    "name": "Hady W. Lauw",
    "affiliations": []
  }],
  "abstractText": "We explore the notion of subjectivity, and hypothesize that word embeddings learnt from input corpora of varying levels of subjectivity behave differently on natural language processing tasks such as classifying a sentence by sentiment, subjectivity, or topic. Through systematic comparative analyses, we establish this to be the case indeed. Moreover, based on the discovery of the outsized role that sentiment words play on subjectivity-sensitive tasks such as sentiment classification, we develop a novel word embedding SentiVec which is infused with sentiment information from a lexical resource, and is shown to outperform baselines on such tasks.",
  "title": "Searching for the X-Factor: Exploring Corpus Subjectivity for Word Embeddings"
}