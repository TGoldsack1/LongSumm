{
  "sections": [{
    "text": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 64–74, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "For the majority of the state-of-the-art parsers that routinely reach ninety percent performance plateau in capturing tree structures, the question of what next crucially arises. Indeed, it has long been thought that the bottleneck preventing the advent of accurate syntax-to-semantic interfaces lies in the quality of the preceding phase of analysis: the better the parse, the better the output. The truth is that most of the structures used to train current parsing models are degraded versions of a more informative data set: the Wall Street journal section of the Penn treebank (PTB, (Marcus et al., 1993)) which is often stripped of its richer set of annotations (i.e. traces and functional labels are removed), while, for reasons of efficiency and availability, projective dependency trees are often given preference over richer graph structures (Nivre and Nilsson, 2005; Sagae\nand Tsujii, 2008). This led to the emergence of surface syntax-based parsers (Charniak, 2000; Nivre, 2003; Petrov et al., 2006) whose output cannot by themselves be used to extract full-fledged predicateargument structures. For example, control verb constructions, it-cleft structures, argument sharing in ellipsis coordination, etc. are among the phenomena requiring a graph to be properly accounted for. The dichotomy between what can usually be parsed with high accuracy and what lies in the deeper syntactic description has initiated a line of research devoted to closing the gap between surface syntax and richer structures. For most of the previous decade, the term deep syntax was used for rich parsing models built upon enriched versions of a constituency treebank, either with added HPSG or LFG annotation or CCG (almost) full rewrites (Miyao and Tsujii, 2005; Cahill et al., 2004; Hockenmaier, 2003). Its use now spreads by misnomer to models that provide more abstract structures, capable of generalizing classical functional labels to more semantic (in a logical view) arguments, potentially capable of neutralizing diathesis distinctions and of providing accurate predicate-argument structures. Although the building of syntax-to-semantic interface seems inextricably linked to an efficient parsing stage, inspirational works on semantic role labelling (Toutanova et al., 2005) and more recently on broad coverage semantic parsing (Du et al., 2014) that provide stateof-the-art results without relying on surface syntax, lead us to question the usefulness of syntactic parses for predicate-argument structure parsing.\nIn this study, we investigate the impact of syntactic features on a transition-based graph parser by testing on two treebanks. We take advantage of the recent release for the SemEval 2014 shared task on semantic dependency parsing, by Oepen et\n64\nal. (2014) of two semantic-based treebanks, derived from two HPSG resources, the DeepBank (DM, (Flickinger et al., 2012)) and the Enju’s predicate argument structure (PAS, (Miyao and Tsujii, 2005)), to investigate the impact of syntactic features on a transition-based graph parser. Our results show that surface syntactic features significantly improve the parsing of predicate-argument structures. More specifically, we show that adding syntactic context improves the recognition of long distance dependencies and elliptical constructions. We finally discuss the usefulness of our approach, when applied on a second-order model based on dual decomposition (Martins and Almeida, 2014), showing that our use of syntactic features enhances this model accuracy and provides state-of-the-art performance."
  }, {
    "heading": "2 Deep Syntax and Underspecified Semantic Corpora",
    "text": "DeepBank Corpus Semantic dependency graphs in the DM Corpus are the result of a two-step simplification of the underspecified logical-form meaning representations, based on Minimal Recursion Semantic (MRS, (Copestake et al., 1995; Copestake et al., 2005)), derived from the manually annotated DeepBank treebank (Flickinger et al., 2012). First, Oepen and Lønning (2006) define a conversion from original MRS formulae to variable-free Elementary Dependency Structures (EDS), which (a) maps each predication in the MRS logical-form meaning representation to a node in a dependency graph and (b) transforms argument relations represented by shared logical variables into directed dependency links between graph nodes. Then, in a second conversion step, the EDS graphs are further reduced into strict bi-lexical form, i.e. a set of directed, binary dependency relations holding exclusively between lexical units (Ivanova et al., 2012). Even though both conversion steps are, by design, lossy, DM semantic dependency graphs present a true subset of the information encoded in the full, original MRS data set.\nPredicate-Argument Structure Corpus Enju Predicate-Argument Structures (PAS Corpus) are derived from the automatic HPSG-style annotation of the Penn Treebank (Miyao and Tsujii, 2004) that was primarily used for the development of the Enju parsing system (Miyao and Tsujii, 2005). The\nPAS data set is an extraction of predicate-argument structures from the Enju HPSG treebank and contains word-to-word semantic dependencies. Each dependency type is made of two elements: a coarse part-of-speech of the head predicate dependent (e.g. verb and adjective), and the argument (e.g. ARG1 and ARG2).\nAlthough both are derived from HSPG resources (a hand-crafted grammar for DM, a treebank-based one for PAS), they differ in their core linguistic choices (functional heads vs lexical heads, coordination scheme, etc.) leading to different views of the predicate argument structure for the same sentence (Ivanova et al., 2012). Thus, even though both corpora may appear to contain a similar number of dependency labels, as shown in Table 1, their annotation schemes depict a deeply divergent linguistic reality exposed by two very different distributions. In DM, 9 labels account for almost 95% of all dependencies whereas a label set twice as large covers the same percentage for PAS, as shown in Table 2. Furthermore, semantically empty elements are widespread in the DeepBank (around 21.5%), compared to a low rate of 4.3% in PAS. In other words, the latter is somewhat more dense and consequently more syntactic. This is due to the fact that PAS integrates markers for infinitives, auxiliaries, and most punctuation marks into its graphs, whereas DM considers them as semantically void. DM corpus is clearly heading toward more semantic analysis while the PAS corpus aims at providing a more abstract deep syntax analysis than regular surface syntax trees. Both treebanks are used in their bilexical dependency formats."
  }, {
    "heading": "DM LABELS % PAS LABELS %",
    "text": ""
  }, {
    "heading": "3 Transition-based Graphs Parsing",
    "text": "Shift-reduce transition-based parsers essentially rely on configurations formed of a stack and a buffer, with stack transitions used to move from a configuration to the next one, until reaching a final configuration. Following Kübler et al. (2009), we define a configuration by c = (σ, β,A) where σ denotes a stack of words wi, β a buffer of words, and A a set of dependency arcs of the form (wi, r, wj), with wi the head, wj the dependent, and r a label in some set R. As shown in Figure 1, besides the usual shift and reduce transitions (lR & rR) of the arc-standard strategy, we introduced the new left and right attach (lA & rA) transitions for adding new dependencies (while keeping the dependent on the stack) and a pop0 transition to remove a word from the stack after attachment of its dependents. All the transitions that add an edge must also satisfy the condition that the newly created edge does not introduce a cycle or\nmultiple edges between the same pair of nodes. It is to be noted that the pop0 action may also be used to remove words with no heads.\nWe base our work on the the DAG parser of Sagae and Tsujii (2008) (henceforth S&T) which we extended with the set of actions displayed above (Figure 1) to cope with partially connected planar graphs, and we gave it the ability to take advantage of an extended set of features. Finally, for efficiency reasons (memory consumption and speed), we replaced the original Maxent model with an averaged structured perceptron (Freund and Schapire, 1999; Collins, 2002)."
  }, {
    "heading": "4 Feature Design",
    "text": ""
  }, {
    "heading": "4.1 Baseline Features",
    "text": "We define Wordβi (resp. Lemmaβi and POSβi) as the word (resp. lemma and part-of-speech) at position i in the queue. The same goes for σi, which is the position i in the stack. Let di,j be the distance between Wordσi and Wordσj . We also define d′i,j , the distance between Wordβi and Wordσj . In addition, we define leftPOSσi (resp. leftLabelσi) the part-of-speech (resp. the label if any) of the word immediately to the left of σi, and the same goes for rightPOSσi (resp. rightLabelσi). Finally, a is the previous action predicted by the parser. Table 3 lists our baseline features. Xσi, σj , σk means that we use Xσi, Xσj , Xσk as unigram features as well as bigram and trigram features."
  }, {
    "heading": "4.2 Syntactic Features",
    "text": "We combined the previous features with different types of syntactic features (constituents and dependencies), our intuition being that syntax and semantic are interdependent, and that syntactic features should therefore help predicate-argument parsing. In fact, we considered that the low density of syntactic information (compared to regular dependency treebanks) would be counterbalanced by\nadding more context. We considered the following pieces of information in particular.\nConstituent Tree Fragments These consist of fragments of syntactic trees predicted by the Petrov et al. (2006) parser in a 10-way jackknife setting. They can be used as enhanced POS or as features.\nSpinal Elementary Trees A full set of parses was reconstructed from the tree fragments using a slightly tweaked version of the CONLL 2009 shared task processing tools (Hajič et al., 2009). We then extracted a spine grammar (Seddah, 2010) using the head percolation table of the Bikel (2002) parser, slightly modified to avoid certain determiners being marked as heads in certain configurations. The resulting spines were assigned in a deterministic way (red part in Figure 2).\nPredicted MATE Dependency Labels These consist of the dependency labels predicted by the MATE parser (Bohnet, 2010), trained on a Stanford surface dependency version of the Penn Treebank. We combined the labels with a distance δ = t − h where t is the token position and h the head position (brown labels and δ in Figure 2). In addition, we expanded these features with the part-of-speech of the head of a given token (HPOS). The idea is to evaluate the informativeness of more abstract syntactic features since a <LABEL,HPOS> pair can be seen as generalizing many constituent subtrees.\nConstituent Head Paths. Inspired by Björkelund et al. (2013), we used MATE dependencies to extract the shortest path between a token and its lexical head and included the path length w (in terms of traversed nodes) as a feature (blue part in Figure 2). The global idea is to use the phrase-based features to provide different kinds of syntactic context and the dependency-based features to provide generalisations over the functional label governing a token. The spines are seen as deterministic supertags, bringing a vertical context.\nWe report, in Table 4, the counts for each syntactic feature on each set."
  }, {
    "heading": "5 Experiments",
    "text": "Experimental Setup Both DM and PAS treebanks consist of texts from the PTB and which were either automatically derived from the original annotations or annotated with a hand-crafted grammar (see above). We use them in their bi-lexical dependency format, aligned at the token level as provided by Oepen et al. (2014)1. The following split is used: sections 00-19 for training, 20 for the dev. set and 21 for test2. All predicted parses are evaluated against the gold standard with labeled precision, recall and f-measure metrics.\nResults Our experiments are based on the evaluation of the combinations of the 4 main types of syntactic features described in section 4: tree fragments (BKY), predicted mate dependencies (BN) and their extension with POS heads (BN(HPOS)), spinal elementary trees (SPINES) and head paths (PATHS).\nThe results are shown in Tables 5 and 6. All improvements from the baseline are significant with a p-value p < 0.05. There was no significant difference of the same p value between our two best mod-\n1This alignment entailed the removal of all unparsed sentences.\n2We used the same unusual split as in (Oepen et al., 2014) to be able to conduct meaningful comparisons with others.\nels for each of the treebanks. 3\nAs expected from the rapid overview of our datasets exposed earlier in section 2, the use of each single feature alone increases the performance over the baseline by 0.5 points for the BN feature in DM to 1.44 for PATHS, and by 1.10 for the SPINES to 1.85 for the PATHS features in PAS. Looking at the conjunction of two classes in the DM table, it seems that dependency-based features benefit from the extra context brought by constituents features, reaching an increase of 2.21 points for BKY+BN(HPOS). Interestingly, the maximum gain is brought by the addition of topologically different phrase-based features such as SPINES (+2.80, inherently vertical) or BKY (+2.76, often wider) to the previous best. Regarding PAS, similar trends can be observed, although the gains are more distributed. As opposed to DM where the conjunction of more features led to inferior results, here using a four-features class provides the second best improvement (ALL(HPOS) = BKY+BN(HPOS)+SPINES+PATHS), +2.82) while removing the SPINES slightly increases the score (+2.92). In fact, adding too many features to the model slightly degrades our scores, at least with regard to DM which has a larger label set than PAS.\nResults show that syntactic information improves our parser performances. As each feature represents one unique piece of information, they benefit from being combined in order to provide more structural information."
  }, {
    "heading": "6 Results Analysis",
    "text": "Following Mcdonald and Nivre (2007), we conducted an error analysis based on the two best models and the baseline for each corpus. As shown in section 5, syntactic features greatly improve semantic parsing. However, it is interesting to explore more precisely what kind of syntactic information boosts or penalizes our predictions. We consider, among other factors, the impact in terms of distance between the head and the dependent (edge length) and the labels. We also explore several linguistic phenomena well known to be difficult to recover.\n3We tested the statistical significance between our best models and the baseline with the paired bootstrap test (BergKirkpatrick et al., 2012)."
  }, {
    "heading": "6.1 Breakdown by Labels",
    "text": "In Figures 3(a) and 4(a), we detail the scores for the five most frequent labels.\nAs observed in the charts, the scores are higher for the most frequent labels on both corpora, especially when dealing with verbal arguments. There are also two interesting cases for DM: the predictions of _and_c and ARG3 edges show an improvement by at least 5 points (Figures 3(b) & 4(b)), showing that the recovery of coordination structures and the disambiguation of less frequent or more distant arguments is achieved by adding non-local features."
  }, {
    "heading": "6.2 Length Factor",
    "text": "Longer sentences are notoriously difficult to parse for most parsing models. Figures 3(c) and 4(c) show the F1-measure of our models with respect to sentence length (in bins of size 10: 1-10, 11-20, etc.) for the DM and PAS corpora.\nIt is worth noting that we greatly improve the scores for longer sentences. The use of paths and of the output of a graph-based parser (Bohnet, 2010) favors the capture of complex dependencies and enhances the learning of these constructions for our local transition-based parser. However, we also observe that the features are not able to completely stop the loss of F1-score for longer sentences. The slopes of the curves in the different charts show the same trend: the longer the sentence, the lower the score."
  }, {
    "heading": "6.3 Linguistic Factors",
    "text": "We now center our analysis on long-distance dependencies (LDDs), by focusing our attention on edges length, i.e. the distance between two words linked by an edge. We will then concentrate on subject ellipsis, in a treatment of LDDs more similar to the linguistic definition of Cahill et al. (2004).\nLong-distance Dependencies (LDDs) For many systems, LDDs are difficult to recover because they are generally under-represented in the training corpus and the constructions involved in LDDs often require deep linguistic knowledge to be recovered. In\nFigure 7, we report the distribution of long-distance dependencies by bins of size 5 up to 40. They only account for 15% of all the dependencies in both corpora. The longest dependencies consist of the first and second arguments of the verb as well as coordination links. In the case of elided coordination structures, we have long-distance dependencies when two coordinated verbs share the same first or second argument, which explains the distribution of lengths.\nBINS 5-10 11-15 16-20 21-25 26-40\nDM 2907 734 329 141 92 PAS 3705 1007 408 175 127\nTable 7: Number of LDDs edges (dev. set).\nAs outlined in Figures 3(d) and 4(d), we can see that without structural information such as spines, surfacic dependencies or paths, the longest dependencies have low F1-scores. When using these features, our models tend to perform better, with a gain of up to 25 points for high-dependency lengths (bins between 16-20 and 21-25).\nIn Table 8, we show the global improvement when considering edge lengths between 5 and 40. For both corpora, the improvement is the same (around 9 points), showing that structural information is the key to better predictions. Looking into this improvement more closely, we found that PATHS combined with BN tend to be crucial, whereas SPINES\nmay sometimes penalize the models. Even though, BN+SPINES+PATHS is the best model for DM, a spine is only a partial projection which lacks attachment information. Spines alone only therefore provide a local context and are unable to cope well with LDDs.\nCoordination Structures We now focus on structures with subject ellipsis. We extracted them by using a simple graph pattern, i.e. two verbs with a shared ARG1 and a coordination dependency.\nOur best models’ scores are displayed in Tables 9. Once again, our models improve the F1 score, but not in the same proportion. DM considers the conjunction as a semantically empty word and attaches an edge _and_c between the two verbs to mark the coordination. Consequently this edge is more difficult to predict, because it is less informative, our baseline model relying on tokens, lemmas and POS.\nWe note that the difference in the number of evaluated dependencies in both corpora comes from an annotation scheme divergence between PAS and DM regarding subject ellipsis. DM opts for coordinate structures with a chain of dependencies rooted at the first conjunct, the coordinating conjunctions being therefore semantically empty. In PAS, the final coordinating conjunction and each coordinating conjunction is a two-place predicate, taking left and right conjuncts as its arguments.\nThe gain of 6.30 points for DM (Table 9(a), resp. +3 for PAS) indicates that, when an annotation scheme is designed to have many semantically empty words, using syntactic information tends to enhance the parser accuracy. This gives a clear insight into what type of information is required to\nparse semantic graphs: the greater the distance between the head and the dependent, the larger the context needed to disambiguate the attachments."
  }, {
    "heading": "6.4 Ruling out the Structural Factor Bias",
    "text": "PAS DM\nOverlap +2.87 +2.67 Rest +2.70 +2.74 It may argued that the improvement we noticed could stem from a potentially strong overlap between surface trees and predicate-argument structures, both in terms of edges and labels. In fact, the conversion from surfacic parses into predicate-argument structures requires a large amount of edges relabeling (for instance, when nsubj is relabeled to ARG1). We tested this hypothesis by computing the number of common edges between MATE predictions and DM and PAS. The overlap corresponds to about 22% of all edges in PAS and 27% in DM. Although important, it does not represent the majority of dependencies in our corpora, because most of edges are not present in surface predictions. We evaluated the improvement of the overlap as well as for the rest. Results show that our best models perform roughly the same on both sets. Interestingly, as opposed to PAS’s model, DM’s model performs better on the non-overlap part. This suggests that the use of PTB-based features is somehow not optimal when applied on a none PTB-based treebank, such as DM which comes from a handcrafted grammar."
  }, {
    "heading": "7 Discussion",
    "text": "Our point was to prove that providing more syntactic context, in the form of phrased-based tree fragments and surface dependencies, helps transition-\nbased parsers to predict predicate-argument structures, especially for LDDs. Yet, compared to stateof-the-art systems, our results built on the S&T parser score lower than the top performers (Table 10). However, we are currently extending a more advanced lattice-aware transition-based parser (DSR) with beams (Villemonte De La Clergerie, 2013) that takes advantage of cutting-edge techniques (dynamic programming, averaged perceptron with early updates, etc. following (Goldberg et al., 2013; Huang et al., 2012)) 4, which proves effective by reaching the state-of-the-art on PAS, outperforming Thomson et al. (2014) and second to the model of Martins and Almeida (2014). 5\nThe point here is that using the same syntactic features as our base system exhibits the same improvement over a now much stronger baseline. We can conjecture that the ambiguities added by the relative scarcity of the deep annotations is efficiently handled by a more complete exploration of the search space, made possible by beam optimization.\nWe can also wonder whether the lower improvement brought to DM parsing by the PTB-based syntactic features does not come from the fact that the DM corpus and the PTB have divergent annotation\n4It uses a different set of transitions, notably pop actions instead of left and right reduce, and a swap that allow limited amount of non-planarity. Such a set raises issues with beams (several paths leading to a same item, final items reached with paths of various lengths, . . . ), overcome by adding a ’noop’ action only applied on final items to balance path lengths.\n5Leaving aside the multiple (19) ensemble models of Du et al. (2014), because of the impracticability of the approach.\nschemes. In that aspect, PTB syntactic features may add some noise to the learning process, because they give more weight to conflicting decisions that led to correct structures in one but not in the other scheme.\nBy using features which, to a certain extent, (i) extend the domain of locality available at a given node and (ii) generalize some structural and functional contexts otherwise unavailable, we tried to overcome the main issue of transition-based parsers: they remain local in the sense that they lack a global view of the whole sentence.\nImpact Beyond Transition-based Parser Of course, it can be argued that improving over a somewhat weak baseline is of limited interest. Our point was to investigate how the direct parsing of relatively sparse graph structures would benefit from the inclusion of more context via the use of topologically different syntactic pieces of information. However in that work, we mostly focused on transition based-parsing, which raises the question of the impact of our feature-set on a much more powerful and state-of-the-art model such as the TURBOSEMANTICPARSER developed by Martins and Almeida (2014).\nTo this end, we extended the T.PARSER so that it could cope with our syntactic features and studied the interaction of our best feature set with second order features (i.e. grand-parents and co-parents). Results in Table 11 show that the gain brought by adding syntactic features (+2.14 on DM over the baseline) is higher than the sole use of second order ones (+1.09). Furthermore, the gain brought by\nthe second-order features is reduced by half when used jointly with our feature set (+1.09 vs +0.57 with them). However, although we could assess that the need of second order models is thus alleviated, the conjunction of both types of features still improves the parser performance by an overall gain of 1.62 points on DM (1.18 on PAS), suggesting that both feature sets contribute to different types of “structures”. In short, the use of syntactic features is also relevant with a strong baseline, as they provide a global view to graph-based models, establishing a new state-of-the-art on these corpora.\nBaseline = arc-factored + siblings\nRelated Work A growing interest for semantic parsing has emerged over the past few years, with the availability of resources such as PropBank and NomBank (Palmer et al., 2005; Meyers et al., 2004) built on top of the Penn Treebank. The shallow semantic annotations they provide were among the targets of successful shared tasks on semantic role labeling (Surdeanu et al., 2008; Carreras and Màrquez, 2005). Actually, the conjoint use of such annotations with surface syntax dependencies bears some resemblance with predicate-argument structure parsing like we presented here. However, they diverge in that Propbank/Nombank annotations\ndo not form connected graphs by themselves, as they only cover argument identification and nominal predicates. The range of phenomena they describe is also limited, compared to a full predicate-argument analysis as provided by DM and PAS (Oepen et al., 2014). More importantly, as pointed out by Yi et al. (2007), being verb-specific, Propbank’s roles do not generalize well beyond the ARG0 argument (i.e. the subject/agent role) leading to inconsistencies. However, the advent of such semantic-based resources have ignited a fruitful line of research, of which the use of heterogeneous sources of information to boost parsing performance has been investigated over the past decade (Chen and Rambow, 2003; Tsuruoka et al., 2004) with a strong regain of interest raised by the work of Moschitti et al. (2008), Henderson et al. (2008), Sagae (2009)."
  }, {
    "heading": "8 Conclusion",
    "text": "We described the use and combination of several kinds of syntactic features to improve predicateargument parsing. To do so, we tested our approach of injecting surface-syntax features by thoroughly evaluating their impact on one transitionbased graph parser, then validating on two more efficient parsers, over two deep syntax and semantic treebanks. Results of the syntax-enhanced semantic parsers exhibit a constant improvement, regardless of the annotation scheme and the parser used. The question is now to establish whether will this be verified in other semantic data sets? From the parsing of deep syntax treebanks a la Meaning Text Theory (Ballesteros et al., 2014), to Framenet semantic parsing (Das et al., 2014) or data-driven approaches closer to ours (Flanigan et al., 2014), it is difficult to know which models will predominate from this bubbling field and what kind of semantic data sets will benefit the most from syntax."
  }, {
    "heading": "Acknowledgements",
    "text": "We would like to thank Kenji Sagae and André F. T. Martins for making their parsers available and for kindly answering our questions. We also thank our anonymous reviewers for their comments. This work was partly funded by the Program \"Investissements d’avenir\" managed by Agence Nationale de la Recherche ANR-10-LABX-0083 (Labex EFL)."
  }],
  "year": 2015,
  "references": [{
    "title": "Deep-syntactic parsing",
    "authors": ["Miguel Ballesteros", "Bernd Bohnet", "Simon Mille", "Leo Wanner."],
    "venue": "In Proc. of COLING, Dublin, Ireland.",
    "year": 2014
  }, {
    "title": "An Empirical Investigation of Statistical Significance in NLP",
    "authors": ["Taylor Berg-Kirkpatrick", "David Burkett", "Dan Klein."],
    "venue": "Proc. of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,",
    "year": 2012
  }, {
    "title": "Design of a multi-lingual, parallel-processing statistical parsing engine",
    "authors": ["Daniel M. Bikel."],
    "venue": "Proc. of the second international conference on Human Language Technology Research, pages 178–182. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA.",
    "year": 2002
  }, {
    "title": "re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task",
    "authors": ["Anders Björkelund", "Ozlem Cetinoglu", "Richárd Farkas", "Thomas Mueller", "Wolfgang Seeker."],
    "venue": "Proc. of the Fourth Workshop on Statistical Parsing of",
    "year": 2013
  }, {
    "title": "Very high accuracy and fast dependency parsing is not a contradiction",
    "authors": ["Bernd Bohnet."],
    "venue": "Proc. of the 23rd International Conference on Computational Linguistics, pages 89–97.",
    "year": 2010
  }, {
    "title": "Long-Distance Dependency Resolution in Automatically Acquired Wide-Coverage PCFG-Based LFG Approximations",
    "authors": ["Aoife Cahill", "Michael Burke", "Ruth O’Donovan", "Josef van Genabith", "Andy Way"],
    "venue": "In Proc. of ACL,",
    "year": 2004
  }, {
    "title": "Introduction to the conll-2005 shared task: Semantic role labeling",
    "authors": ["Xavier Carreras", "Lluís Màrquez."],
    "venue": "Proc. of the Ninth Conference on Computational Natural Language Learning, pages 152–164.",
    "year": 2005
  }, {
    "title": "A maximum-entropy-inspired parser",
    "authors": ["Eugene Charniak."],
    "venue": "Proc. of the 1st Annual Meeting of the North American Chapter of the ACL (NAACL), Seattle.",
    "year": 2000
  }, {
    "title": "Use of deep linguistic features for the recognition and labeling of semantic arguments",
    "authors": ["John Chen", "Owen Rambow."],
    "venue": "Proc. of the 2003 conference on Empirical methods in natural language processing, pages 41–48. Association for Computational Linguis-",
    "year": 2003
  }, {
    "title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms",
    "authors": ["Michael Collins."],
    "venue": "Proc. of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, pages 1–8.",
    "year": 2002
  }, {
    "title": "Translation using minimal recursion semantics",
    "authors": ["Ann Copestake", "Dan Flickinger", "Rob Malouf", "Susanne Riehemann", "Ivan Sag."],
    "venue": "Proc. of the Sixth",
    "year": 1995
  }, {
    "title": "Minimal recursion semantics: An introduction",
    "authors": ["Ann Copestake", "Dan Flickinger", "Carl Pollard", "Ivan A Sag."],
    "venue": "Research on Language and Computation, 3(2-3):281–332.",
    "year": 2005
  }, {
    "title": "Frame-semantic parsing",
    "authors": ["Dipanjan Das", "Desai Chen", "André FT Martins", "Nathan Schneider", "Noah A Smith."],
    "venue": "Computational Linguistics, 40(1):9–56.",
    "year": 2014
  }, {
    "title": "Peking: Profiling syntactic tree parsing techniques for semantic graph parsing",
    "authors": ["Yantao Du", "Fan Zhang", "Weiwei Sun", "Xiaojun Wan."],
    "venue": "Proc. of the 8th International Workshop on Semantic Evaluation, pages 459–464.",
    "year": 2014
  }, {
    "title": "A discriminative graph-based parser for the abstract meaning representation",
    "authors": ["Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith."],
    "venue": "in Proc. of ACL, Baltimore, US.",
    "year": 2014
  }, {
    "title": "DeepBank: a dynamically annotated treebank of the wall street journal",
    "authors": ["Daniel Flickinger", "Yi Zhang", "Valia Kordoni."],
    "venue": "Proc. of the Eleventh International Workshop on Treebanks and Linguistic Theories, pages 85–96.",
    "year": 2012
  }, {
    "title": "Large margin classification using the perceptron algorithm",
    "authors": ["Yoav Freund", "Robert E. Schapire."],
    "venue": "Machine learning, 37(3):277–296.",
    "year": 1999
  }, {
    "title": "Efficient implementation of beam-search incremental parsers",
    "authors": ["Yoav Goldberg", "Kai Zhao", "Liang Huang."],
    "venue": "Proc. of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), Sophia, Bulgaria.",
    "year": 2013
  }, {
    "title": "The conll-2009 shared task: Syntactic and semantic dependencies",
    "authors": ["Jan Hajič", "Massimiliano Ciaramita", "Richard Johansson", "Daisuke Kawahara", "Maria Antònia Martí", "Lluís Màrquez", "Adam Meyers", "Joakim Nivre", "Sebastian Padó", "Jan Štěpánek"],
    "year": 2009
  }, {
    "title": "A latent variable model of synchronous parsing for syntactic and semantic dependencies",
    "authors": ["James Henderson", "Paola Merlo", "Gabriele Musillo", "Ivan Titov."],
    "venue": "Proc. of the Twelfth Conference on Computational Natural Language Learning, pages 178–182.",
    "year": 2008
  }, {
    "title": "Data and models for statistical parsing with Combinatory Categorial Grammar",
    "authors": ["Julia Hockenmaier."],
    "venue": "Ph.D. thesis.",
    "year": 2003
  }, {
    "title": "Structured perceptron with inexact search",
    "authors": ["Liang Huang", "Suphan Fayong", "Yang Guo."],
    "venue": "Proc. of HLT-NAACL 2012, pages 142–151.",
    "year": 2012
  }, {
    "title": "Who did what to whom?: A",
    "authors": ["Angelina Ivanova", "Stephan Oepen", "Lilja Øvrelid", "Dan Flickinger"],
    "year": 2012
  }, {
    "title": "Dependency Parsing",
    "authors": ["Sandra Kübler", "Ryan McDonald", "Joakim Nivre."],
    "venue": "Morgan and Claypool Publishers.",
    "year": 2009
  }, {
    "title": "Building a large annotated corpus of English: The Penn Treebank",
    "authors": ["Mitchell Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz."],
    "venue": "Computational Linguistics, 19(2):313–330.",
    "year": 1993
  }, {
    "title": "Priberam: A turbo semantic parser with second order features",
    "authors": ["T. André F. Martins", "C. Mariana S. Almeida."],
    "venue": "Proc. of the 8th International Workshop on Semantic Evaluation, pages 471–476.",
    "year": 2014
  }, {
    "title": "Characterizing the errors of data-driven dependency parsing models",
    "authors": ["Ryan Mcdonald", "Joakim Nivre."],
    "venue": "Proc. of the Conference on Empirical Methods in Natural Language Processing and Natural Language Learning.",
    "year": 2007
  }, {
    "title": "Annotating noun argument structure for nombank",
    "authors": ["Adam Meyers", "Ruth Reeves", "Catherine Macleod", "Rachel Szekely", "Veronika Zielinska", "Brian Young", "Ralph Grishman."],
    "venue": "LREC, volume 4, pages 803–806.",
    "year": 2004
  }, {
    "title": "Deep Linguistic Analysis for the Accurate Identification of Predicate-Argument Relations",
    "authors": ["Yusuke Miyao", "Jun’ichi Tsujii"],
    "venue": "In Proc. of the 18th International Conference on Computational Linguistics,",
    "year": 2004
  }, {
    "title": "Probabilistic disambiguation models for wide-coverage HPSG parsing",
    "authors": ["Yusuke Miyao", "Jun’ichi Tsujii"],
    "venue": "In Proc. of ACL",
    "year": 2005
  }, {
    "title": "Tree kernels for semantic role labeling",
    "authors": ["Alessandro Moschitti", "Daniele Pighin", "Roberto Basili."],
    "venue": "Computational Linguistics, 34(2):193–224.",
    "year": 2008
  }, {
    "title": "Pseudo-projective dependency parsing",
    "authors": ["Joakim Nivre", "Jens Nilsson."],
    "venue": "Proc. of the 43rd Annual Meeting on Association for Computational Linguistics, pages 99–106. Association for Computational Linguistics.",
    "year": 2005
  }, {
    "title": "An efficient algorithm for projective dependency parsing",
    "authors": ["Joakim Nivre."],
    "venue": "Proc. of the 8th International Workshop on Parsing Technologies (IWPT. Citeseer.",
    "year": 2003
  }, {
    "title": "Discriminant-based mrs banking",
    "authors": ["Stephan Oepen", "Jan Tore Lønning."],
    "venue": "Proc. of the 5th international conference on language resources and evaluation (lrec 2006).",
    "year": 2006
  }, {
    "title": "Semeval 2014 task 8: Broad-coverage semantic dependency parsing",
    "authors": ["Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Dan Flickinger", "Jan Hajic", "Angelina Ivanova", "Yi Zhang."],
    "venue": "Proc. of the 8th International Workshop on Semantic",
    "year": 2014
  }, {
    "title": "The proposition bank: An annotated corpus of semantic roles",
    "authors": ["Martha Palmer", "Daniel Gildea", "Paul Kingsbury."],
    "venue": "Computational Linguistics, 31(1):71– 106.",
    "year": 2005
  }, {
    "title": "Learning accurate, compact, and interpretable tree annotation",
    "authors": ["Slav Petrov", "Leon Barrett", "Romain Thibaux", "Dan Klein."],
    "venue": "Proc. of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computa-",
    "year": 2006
  }, {
    "title": "Shift-reduce dependency DAG parsing",
    "authors": ["Kenji Sagae", "Jun’ichi Tsujii"],
    "venue": "In Proc. of the 22nd International Conference on Computational Linguistics (Coling",
    "year": 2008
  }, {
    "title": "Analysis of discourse structure with syntactic dependencies and data-driven shift-reduce parsing",
    "authors": ["Kenji Sagae."],
    "venue": "Proc. of the 11th International Conference on Parsing Technologies, pages 81–84. Association for Computational Linguistics.",
    "year": 2009
  }, {
    "title": "Exploring the spinal-stig model for parsing french",
    "authors": ["Djamé Seddah."],
    "venue": "Proc. of the Seventh conference on International Language Resources and Evaluation (LREC’10).",
    "year": 2010
  }, {
    "title": "The conll2008 shared task on joint parsing of syntactic and semantic dependencies",
    "authors": ["Mihai Surdeanu", "Richard Johansson", "Adam Meyers", "Lluís Màrquez", "Joakim Nivre."],
    "venue": "Proc. of the Twelfth Conference on Computational Natural Language Learning,",
    "year": 2008
  }, {
    "title": "CMU: Arc-Factored, Discriminative Semantic Dependency Parsing",
    "authors": ["Sam Thomson", "Brendan O’Connor", "Jeffrey Flanigan", "David Bamman", "Jesse Dodge", "Swabha Swayamdipta", "Nathan Schneider", "Chris Dyer", "A. Noah Smith"],
    "venue": "In Proc. of the 8th International",
    "year": 2014
  }, {
    "title": "Joint learning improves semantic role labeling",
    "authors": ["Kristina Toutanova", "Aria Haghighi", "Christopher D Manning."],
    "venue": "Proc. of the 43rd Annual Meeting on Association for Computational Linguistics, pages 589–596.",
    "year": 2005
  }, {
    "title": "Towards efficient probabilistic hpsg parsing: integrating semantic and syntactic preference to guide the parsing",
    "authors": ["Yoshimasa Tsuruoka", "Yusuke Miyao", "Jun’ichi Tsujii"],
    "venue": "In Proc. of the IJCNLP-04 Workshop on Beyond Shallow Analyses. Citeseer",
    "year": 2004
  }, {
    "title": "Exploring beambased shift-reduce dependency parsing with DyALog: Results from the SPMRL 2013 shared task",
    "authors": ["Éric Villemonte De La Clergerie."],
    "venue": "4th Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL’2013).",
    "year": 2013
  }, {
    "title": "Can semantic roles generalize across genres? In HLTNAACL, pages 548–555",
    "authors": ["Szu-Ting Yi", "Edward Loper", "Martha Palmer."],
    "venue": "74",
    "year": 2007
  }],
  "id": "SP:a103cf359db606ba79c792a080e3c9f95056c8da",
  "authors": [{
    "name": "Corentin Ribeyre",
    "affiliations": []
  }, {
    "name": "Eric Villemonte de la Clergerie",
    "affiliations": []
  }, {
    "name": "Djamé Seddah",
    "affiliations": []
  }],
  "abstractText": "Parsing full-fledged predicate-argument structures in a deep syntax framework requires graphs to be predicted. Using the DeepBank (Flickinger et al., 2012) and the PredicateArgument Structure treebank (Miyao and Tsujii, 2005) as a test field, we show how transition-based parsers, extended to handle connected graphs, benefit from the use of topologically different syntactic features such as dependencies, tree fragments, spines or syntactic paths, bringing a much needed context to the parsing models, improving notably over long distance dependencies and elided coordinate structures. By confirming this positive impact on an accurate 2nd-order graphbased parser (Martins and Almeida, 2014), we establish a new state-of-the-art on these data sets.",
  "title": "Because Syntax Does Matter: Improving Predicate-Argument Structures Parsing with Syntactic Features"
}