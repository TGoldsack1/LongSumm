{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1795–1804, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "Learning word meanings is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014).\nAlthough cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the word dog refers to all kinds of dogs, and not to a specific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available for dog (because all dogs are also animals). We use the term “word generalization” to refer to this problem of associating a word with the meaning at an appropriate category level, given some sample of experiences with the word.\nPrevious research has argued that children use a specific bias or constraint – the basic-level assumption – to focus their word generalizations appropriately (Markman, 1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings.\nXu and Tenenbaum (2007) (X&T henceforth) studied the word generalization problem in a set of experiments in which children and adults were asked to determine which level of a taxonomy a novel word referred to. X&T further examined this behavioral data through computational modelling. They proposed a Bayesian model that, given a few exemplars of a novel word, matches human behaviour in how it maps the word to its\n1795\nmeanings in a taxonomic category. The Bayesian model of X&T is important in providing insight into how people might reason about samples of data that exemplify categories. However, it relies on having complete, built-in knowledge about the taxonomic hierarchy, including both the detailed composition of categories and the values for between-object similarities, drawn from adult similarity judgments. Furthermore, the X&T model does not address the issue of word generalization in the broader context of word learning: While their model reasons over samples of data associated with a word label, it does not develop a meaning representation of the word over time, as a child must do. It is important to understand how word generalization occurs when embedded in the natural process of learning a word meaning and in the context of more limited category knowledge.\nWe address these issues by providing a unified account of word learning and word generalization within a computational model of crosssituational learning. Unlike the X&T model, our model is an incremental learner that gradually acquires the meaning of words, and uses these developing meanings in determining the appropriate extension of a word to elements of a taxonomy. Our model has general knowledge of category structure without having an elaborated taxonomy encoding known object similarities. Moreover, in the absence of any bias toward generalization to particular kinds of categories, the model exhibits the observed “basic-level bias” due to general mechanisms of productivity that have been proposed to apply to many aspects of linguistic knowledge (e.g., Bybee, 1985; Croft and Cruse, 2004).1\nIn what follows, we first describe the human experiments of X&T, and then present our computational model and the experiments that simulate the X&T data."
  }, {
    "heading": "2 Novel Word Generalization in People",
    "text": "X&T perform a set of empirical studies to investigate how children and adults generalize novel words learned from a few examples to the appro-\n1Computational cognitive models are often categorized with respect to Marr’s levels of analysis, i.e., their degree of abstraction (Marr, 1982). The model of X&T is at the computational level, providing a Bayesian framework for the problem of word generalization. In contrast, our model investigates more detailed mechanisms and thus lies between the algorithmic and computational levels of analysis.\npriate level of meaning in a taxonomy. In each training trial of an experiment, participants hear a novel word (such as fep) and observe one or more instances exemplifying the word (in the form of pictures for adults and toy objects for children). The conditions vary in that the make-up of the set of training instances is representative of different levels of a taxonomy (e.g., all Dalmatians vs. various kinds of dogs vs. various kinds of animals). In the testing phase, participants are asked to select all objects that they think are feps from a set of test items. Both children and adults make various inferences about what a fep is depending on the levels of the taxonomy from which the training instances are drawn.\nSpecifically, X&T use a taxonomy with animals, vehicles, and vegetables, from which instances are drawn to produce the training conditions in Fig. 1(a). For example, in one training condition, participants are shown a Dalmatian, a poodle, and a beagle in three consecutive trials, hearing the word fep to refer to each object. After training, participants are asked to select all feps from the set of test objects, which includes items from all 3 superordinate categories. As illustrated in Fig. 1(b), each test object is assessed as one of the following types of match to the training data:\n• a subordinate match: an object of the same subordinate category as a training object (e.g., Dalmatians in Fig. 1)\n• a basic-level match: an object of the same basic-level category as a training object (e.g., a dog, but not the same breed as one in training [which would be a subordinate match])\n• a superordinate match: an object of the same superordinate category as the training objects (e.g., another kind of animal, but not one seen in training [which would be a subordinate or basic-level match])\nX&T report the percentage of test objects of each type of match that are selected by participants within each training condition; see Fig. 2. (For example, the reported value for “super. match” would be 75% if participants on average chose 3 of the 4 superordinate matches in the test set.)\nConsider first the data from adults. After seeing a single object (1-example condition – e.g., a Dalmatian), adults show a strong basic-level bias – i.e., they tend to generalize the word fep to refer to both Dalmatians (subordinate matches) and to\nother dogs (basic-level matches), but not to other animals (superordinate matches). But with 3 instances of a Dalmatian (3-subordinate condition), this behaviour is attenuated – the number of basiclevel matches is much lower. For the 3-basic-level and 3-superordinate conditions, the adults show generalization up to categories consistent with the evidence – i.e., at the basic and superordinate levels, respectively.\nInterestingly, children also show a basic-level bias, but differ from adults in that it is less pronounced – e.g., they are less likely than adults to select basic-level matches (other dogs) having seen a single Dalmatian or having seen 3 Dalmatians. In the other conditions, children’s behaviour is similar to adults, but shows somewhat less generalization to unseen types of objects (e.g., other kinds of dogs/animals than those in training). (a) Adult data:"
  }, {
    "heading": "3 The Word Learning Framework",
    "text": "Our computational model is based on the crosssituational word learner of Fazly et al. (2010) (henceforth, FAS), which accounts for a range of observed patterns in child and adult vocabulary ac-\nquisition. Here we give an overview of the FAS model; the next section explains extensions to handle the novel word generalization task.\nA naturalistic language learning scenario consists of both linguistic data (what a child a hears) and non-linguistic data (what a child perceives). This input is modeled as a sequence of utterance– scene (U–S) pairs, where an utterance is a group of words and a scene is a set of semantic features representing the meaning of those words:\nU : { look, a, fep, . . . } S: { PERCEPTION, LOOK, . . . , DALMATIAN, DOG, . . . }\nGiven such input, for each word w, the model of FAS learns a probability distribution over all semantic features, Pt(.|w), which represents the word’s meaning at time t. Initially, at time t = 0, P0(.|w) is a uniform distribution. The word meanings are incrementally learned using an algorithm that implements cross-situational learning: for each pair of a wordw and a semantic feature f , the model learns Pt(f |w) from co-occurrences of w and f across all the utterance–scene pairs seen up to time t, as follows.\nGiven an utterance–scene pair U–S at time t, and drawing on its learned knowledge of word meanings up to time t−1, the model of FAS calculates an alignment probability for each wj–fi pair. This probability reflects how strongly the feature fi is associated with wj compared to its association with other words in U :\nPt(aij |U, fi) = Pt−1(fi|wj)∑ w′∈U Pt−1(fi|w′) (1)\nwhere aij indicates the mapping between the word wj and the semantic feature fi.\nThese probabilities are incrementally accumulated for each wj–fi pair, capturing the overall strength of association of wj and fi at time t:\nassoct(fi, wj) = assoct−1(fi, wj) + Pt(aij |U, fi)\n(2)\nThe (normalized) association scores then serve as the basis for the incremental adjustment of the meaning probabilities of all features fi for each word wj seen in the input at time t:\nPt(fi|wj) = assoct(fi, wj) + γ∑ fm∈M assoct(fm, wj) + k γ (3)\nHereM is the group of all features that the model has observed, k is the expected number of such features, and γ is a small smoothing parameter, which determines the prior probability of observing a new feature.\nSmoothing entails that features previously unseen with a word (all fi such that assoct(fi, wj) = 0) have a small but non-zero probability. That is, when fi is unseen with wj , Eqn. (3) reduces to:\nP ut (fi|wj) = γ∑\nfm∈M assoct(fm, wj) + k γ\n(4)\nThis unseen probability, P ut , reflects the learner’s “openness” to the word being associated with new features (Nematzadeh et al., 2011): a higher or lower P ut (fi|wj) will affect how strongly a previously unseen fi can be associated with wj in the alignment process (Eqn. (1)). We return to this property of the model below, as it relates to the behaviour of our model in making generalizations."
  }, {
    "heading": "4 Extensions to the Model",
    "text": "We assume that the representation of meaning can be abstracted to features that correspond to different levels of categorization. For example, a Dalmatian in an input scene is represented as {DALMATIAN, DOG, ANIMAL} and a Bulldog as {BULLDOG, DOG, ANIMAL}, where we use FEATURENAME to refer to all the features that are specific to that level of object category. (Note that we could replace each of these features with the appropriate “true” set of features, but use the more compact representation for simplicity.) To acquire the meaning of the word Dalmatian, the model must learn a probability distribution in which P (f |Dalmatian) is relatively high for the features DALMATIAN, DOG, and ANIMAL, and low for features such as BULLDOG, CAT, and VEGETABLE.\nIntroducing Feature Groups. In the FAS model, all the features for a word are dependent: increasing the probability of any feature results in decreasing the probability of others. However, this\ninteraction is not always desirable, as many features regularly co-occur in the world. This is especially an issue for features from a category hierarchy, where features of a subordinate category should not compete with features of the parent. That is, while a higher probability of DALMATIAN features (e.g., black spotted coat) may lessen the likelihood of BULLDOG features (e.g., wrinkles), it should not decrease the probability of DOG features (e.g., having 4 legs).\nTo address this, we extend the model by using feature groups that collect together sets of features that sensibly compete. Each feature group is comprised of all features at the same level of specificity in the category hierarchy, which are therefore mutually exclusive, such as DOG, CAT, and BIRD (i.e., different kinds of animals). Instead of learning a single probability distribution over all features as the meaning of a word, the extended model learns a set of probability distributions for a word, one for each feature group (i.e., one per level of the hierarchy). Features within a group thereby compete for the probability mass associated with a word, but those from across groups (e.g., DALMATIAN and DOG) can freely co-occur without competing.\nThe model does not know a priori all the features in a group, but when presented with a newly observed feature, it can identify the appropriate group for it. In taking this approach, we assume the learner can distinguish the level of specificity of features perceived in the scene. For example, in the scene representations {DALMATIAN, DOG, ANIMAL} and {SIAMESE, CAT, ANIMAL}, the learner can recognize that DOG and CAT are at the same level of the hierarchy (kinds of animals) and that DALMATIAN and SIAMESE are at the same, more specific level in the hierarchy (finer-grained breeds of animals). Our assumption is that children (at this stage in their development) can identify a degree of similarity among concepts that enables them to recognize that Dalmatians and Siamese are distinguished by similar properties (such as fur color), which differ from more distinguishing properties at higher taxonomic levels (such as number of legs). The model has no other prior knowledge of the category structure. For example, it is not built into the model that DALMATIAN is a type of DOG, only that it is more specific than DOG; any association between them would be learned from their pattern of co-occurrence with a word over time.\nNote that, in contrast to the model of X&T, our model does not start with a full taxonomy (it does not know, for example, that Dalmatians and poodles are hyponyms of dogs) and it does not have built-in knowledge of similarities among concepts. Still, it encodes some taxonomic knowledge in the feature groups, and an important future direction will be to show that this knowledge is learnable from the input.\nCalculating Feature Group Probabilities. To appropriately split the probability mass within a feature group G (but not across feature groups), we use a new formulation of Eqn. (3) to update the meaning probabilities for fi ∈ G as follows:\nPt(fi|wj) = assoct(fi, wj) + γG∑ fm∈G assoct(fm, wj) + kGγG (5)\nwhere kG is the expected number of features in G, and the smoothing factor γG reflects the prior belief in observing a feature f in G.2\nWith this new formulation, the probability of a feature fi previously unseen with wordwj now reduces to (cf. Eqn. (4)):\nP ut (fi|wj) = γG∑\nfm∈G assoct(fm, wj) + kGγG\n(6)\nfor fi ∈ G. Note that the smoothing factor γG depends on G, and thus the openness of the word to be associated with new (previously unseen) features can vary depending on the feature group.\nThis unseen probability is very important to the model’s generalization behaviour. Generalization involves the model accepting that a learned word can refer to objects not seen with it before: e.g., in the experiments here, we would expect that the learned meaning for fep after seeing three animals such as a dog, a penguin, and a sheep could also accommodate the meaning of a different animal such as a cat. This ability of the model to associate new meaning features with a word depends precisely on the unseen probability formulation: the higher the unseen probability for a feature and a word, the more the feature will be acceptable as a generalization of the word.\nType-Token Effects on Generalization. The unseen probability is sensitive to how many instances of features from a group have already been\n2Each feature group forms a Categorical distribution with kG categories (Cat(θ1, ..., θkG )), where the θi are drawn from a prior Dirichlet distribution Dir(γ1, ..., γ kG ) at time t = 0, and the θi are updated at time t to be the expected value of the posterior Dirichlet distribution, given in Eqn. (5) or Eqn. (6).\nseen with a word wj : As the model observes more instances (tokens) of features from G with wj , the corresponding assoct score(s) increase, thereby increasing the denominator in Eqn. (6) and decreasing P ut . Thus the tendency to generalize wj to more features in G – i.e., to accept additional features as part of the meaning of wj – will decrease as the model has more evidence of (observed) features in that group occurring with wj .\nGeneralization of a category to include new kinds of items is typically a function of both token and type frequency (e.g., Bybee, 1985; Croft and Cruse, 2004): a category with more diverse types is more easily extended to new cases. While the evolving association scores capture the effect of observing more feature tokens, our model as given does not distinguish the number of different types of features seen within a group (e.g., two DOGs vs. one DOG and one CAT).\nWe address this issue by having γG depend on the number of observed types of features in the group:\nγ tG = γ 0 G × type(G, t)2 (7)\nwhere type(G, t) is the number of different kinds of features seen in that group (e.g., DOG and CAT are two different feature types from the same group) up through time t. In this way, the P ut of a feature that occurs in a group with more observed feature types is higher than the P ut in a group with fewer observed types.\nThus both the type frequency of features in G and their token frequency of co-occurrence with word wj will influence – the first positively and the second negatively – how readily wj can refer to objects with previously unseen features from G."
  }, {
    "heading": "5 Experimental Set-up",
    "text": "We model X&T’s behavioural experiments with our computational word learner as extended above.3 Following X&T, we use a three-tiered category hierarchy, and the four training conditions and assessment of three types of test matches as described in Figure 1.\nTraining the model. In each condition, the model processes a sequence of 3 utterance-scene pairs, and updates Pt(fi|wj) after each pair using Eqns. (5) and (6). The utterance-scene pair in each trial consists of the novel word coupled with the scene representation of a training object from the\n3Link to our code/data: github.com/eringrant/ word_learning/tree/hypothesis-space.\ncategory hierarchy. The object’s scene representation is given as a set of four features, each taken from one of four feature groups: one feature corresponding to each of the subordinate, basic, and superordinate levels of the hierarchy, and a unique “instance” feature, as shown in Table 1. (The “instance” feature is added to simulate the variations in the different objects of the same subordinate category in the X&T experiments.)\nTesting the model. After training on a novel word, in order to assess its level of generalization within the category hierarchy, we compare the model’s learned meaning of the word to test objects that constitute various types of matches to the training conditions: i.e., subordinate matches, basic-level matches, and superordinate matches. Table 2 gives an example of each type of match:\nTo assess whether the model generalizes the learned meaning of a word w to the various types of test matches, we first consider the probability of a test object Y at time t given the learned meaning of w:\nPt(Y |w) = ∏\nyi∈Y Pt(yi|w) (8)\nwhere yi are the features in Y , and Pt(yi|w) is calculated using Eqn. (5) for features yi observed with w during training, and using Eqn. (6) for yi not observed with w. (Recall that Eqn. (5) reduces to Eqn. (6) when a feature has not been seen with the word.) From Pt(Y |w), we subtract the predictive probability of the test object before the model has observed any data, P0(Y |w), which gives us its increase in preference attributable to the word\nlearning trials.4\nCalculating Pt(Y |w)−P0(Y |w) is informative about one test object, but we need to measure generalization of the learned word to all the objects of a certain type of match – i.e., subordinate, basiclevel, or superordinate. We formulate the probability of generalization to a type of test match as the relative average increase in preference for test items of that type of match, using the ShepardLuce choice rule (Shepard, 1958; Luce, 1959):\nPgen(m|w) = avgY ∈m [Pt(Y |w)-P0(Y |w)]∑ m′ avgY ′∈m′ [Pt(Y ′|w)-P0(Y ′|w)]\nwhere m is the set of test objects at a certain level of match, andm′ ranges over subordinate matches, basic-level matches, and superordinate matches.\nUsing Pgen(m|w) to communicate our models results has the advantage of using the learned word meanings in a very direct way to assess the preference for the various types of test matches in the X&T experiments. However, the disadvantage is that this measure is not directly comparable to the reported figures from the human data, which are the percentage of test objects selected of a particular type of match. Hence, in presenting our results below, we focus on the general patterns of preferences indicated by the different measures. Parameters. To model children, whom we assume to have no bias towards generalization to specific category levels, we equate all parameters k G and γ G across all feature groups, reflecting that all category levels are treated equivalently. Here we use values of k G = 100 and initial values of γ G = 0.5 for all G as the “child” parameter settings.5 In contrast, we assume that adults, through word learning experience, have accumulated biases that reflect observed differences in feature groups. More specifically, we assume that the probability of observing a new feature for a group G depends on the degree of specificity of that group: That is, over time, it is less likely to observe a completely new kind of animal, e.g., than a new breed of dog. We simulate these biases by us-\n4P0(Y |w) = ∏G 1kG is the prior probability of any object instance, given parameters drawn from the Dirichlet prior, because Eqn. (6) yields the value 1\nkG when all assoct scores are\n0 – i.e., no features from G have been observed with the word. 5To determine the parameters for the “child” learner, we examined a number of settings with equal parameter values for all the feature groups, and observed similar results in these settings. (We did not perform an exhaustive search over the parameter space.)\ning various values for the parameter γ G, which determines the prior probability of a word being observed with new (previously unseen) features in G (cf. Eqn. (6)). We assume that the expected number of features (k G) is the same across groups. We perform a non-exhaustive search on the parameter space of γ G to select a set of values that yield the patterns of X&T’s adult experiments. The “adult” parameter values are given in Table 3:6"
  }, {
    "heading": "6 Experimental Results",
    "text": "We present results of the model using both child settings (Figure 3b) and adult settings (Figure 3a). Recall that these values do not correspond to the percentages reported in the human data; to evaluate the patterns of generalization, we look at the relative preference for the various types of test match. Note also that since the generalization probabilities sum to 1.0 within each of the 4 training conditions, we can only compare the pattern of generalization across conditions (and not the actual value of the probabilities).\nWe discuss each of the child and adult sets of results in detail below."
  }, {
    "heading": "6.1 The Child Learner",
    "text": "Recall that in the simulations of a child, we use equal values across all feature groups for the k G and initial γ G parameter settings, to reflect that the learner has no bias towards generalization to specific category levels.\nLooking at the results in Figure 3b, we can see that the child learner generally replicates the patterns of results observed in X&T’s experiment on children (cf. Figure 2b). Given multiple training items (the 3-subord., 3-basic, and 3-super. conditions), the model, like children, generalizes to the lowest level category in the hierarchy that is consistent with the training items, roughly equally preferring items from that category or lower, with slight preference for the lower categories. In contrast, after seeing a single training example (the\n6For a certain range of such parameter settings – i.e., with gradually decreasing γ G , which determines the prior probability of a word being observed with new (previously unseen) features in G (cf. Eqn. (6)). for feature groups at successively higher levels in the hierarchy — the model produces similar results to the presented adult learner.\n(a) Adult data:\n1-ex. condition), the model shows some tendency to generalize to the basic-level, demonstrating a small but notable basic-level bias — e.g., the tendency to consider the word as referring to any dogs (but less so to other animals) after seeing just a single example of a particular kind of dog. As in children, the difference in the model between the preference for subordinate vs. basic-level matches is much smaller when trained on 1 instance as opposed to 3 subordinates. (In Figure 3b, compare the difference between the 1st bar [subord. match] and 2nd bar [basic match] of the 1-ex. training condition to that of the 3-subord. training condition.)\nInterestingly, our child learner exhibits the observed basic-level bias in the absence of any difference in the model in how it treats different category levels. The observed pattern arises from a type/token frequency interaction of the kind often noted to influence generalization of linguistic categories (e.g., Bybee, 1985; Croft and Cruse, 2004): here, the interaction between the token frequency of word–feature pairs in the input and the type frequency of different features within a group of dependent features. For example, having seen 3 types of animals (“3 super.” condition), the model can readily accommodate that fep refers to another kind of animal, in contrast to the “3 basic” condition, where it has seen the same number of tokens but only a single feature type from the feature\ngroup at that level (3 dogs). We can also clearly see the inverse impact of token frequencies on generalization: the more examples of a single subordinate type are seen, the less the model accepts that fep refers to a different kind of subordinate (the “3-subord.” vs. “1-ex.” conditions). That is, with only 1 token of DALMATIAN, the model can generalize to other types of dogs more readily than when it has seen 3 tokens of DALMATIAN.\nIn general, interactions between the type and token frequencies of the different feature groups interact to yield the observed patterns in the model. These results indicate that properties of the input data coupled with the model’s handling of feature groups can account for children’s word generalization behaviour, without the need for an explicit basic-level bias."
  }, {
    "heading": "6.2 The Adult Learner",
    "text": "Adult participants in X&T exhibited a stronger tendency than children to generalize to the basiclevel category, especially after seeing a single exemplar. We explore whether the model can simulate an adult learner as well. As discussed in Section 5, by varying the parameters γ G , we can incorporate biases towards different category levels that we assume an adult has learned. More specifically, we set γ G to successively larger values for more specific feature groups G, to ensure successively greater generalization in lower levels of the hierarchy (see Table 3). As shown in Figure 3a, our model (using such settings of the parameters) replicates the patterns of X&T’s adult experiments (cf. Figure 2a), including a stronger basic-level bias than that shown by children. That is, in the 1-ex. and 3-subord. conditions, the difference between the 1st bar [subord. match] and 2nd bar [basic match] is smaller for the adult settings of the model (Figure 3a) than for the child settings (Figure 3b), mimicking the stronger basic-level bias found in adults."
  }, {
    "heading": "6.3 Variations in Basic-level Generalization",
    "text": "Research shows that people’s degree of basic-level generalization depends on the overall category of the objects. Specifically, Abbott et al. (2012) perform the same set of experiments as X&T on adults, exploring three additional superordinate categories (clothing, containers, and seats). Their results are shown in Figure 4; for space reasons, we focus here on the training conditions with 1- example or 3-subordinates, which are the locus\nof the basic-level effect. The results show that people exhibit no basic-level generalization for containers, moderate generalization for clothing, and strong generalization for seats (compare Figures 4a, 4b and 4c).\nInterestingly, the computational experiments of Abbott et al. (2012) also reveal that the Bayesian model of X&T mimics varying levels of basiclevel generalization in the 1-example cases, but does not capture the differences that people exhibit across the categories in the 3-subordinate condition (compare “3 subord.” in Figures 4 and 5): unlike people, here the X&T model does not exhibit basic-level generalization for any of the categories.\nAbbott et al. (2012) note that a domain like containers may not follow a “natural taxonomy” in having a clear basic-level category. This suggestion is compatible with our view that a basic-level bias arises in response to the particular pattern of co-occurrence of features across the category hierarchy. We looked more closely at the training stimuli of their experiment, and observe that the examples of the category “containers” (with the least basic-level generalization) vary greatly, while those of “clothing” and “seats” are less differentiated. Examples from “containers” include a cigar box, trash can, and mailbox, whereas “seats” are restricted to different types of chair (such as a dining chair and an armchair; see Table 1 in Abbott et al. (2012)).\nBased on this observation, we hypothesize that people generalize less to a basic-level category when their mental representations for that category’s instances have more distinguishing features. Specifically, we assume that people differentiate the given instances of the category “containers” more than those for “clothing” and “seats”. We model this difference in the granularity of representations by varying the number of feature groups used in representing an object. Recall that in our earlier experiments, each object was represented as a set of features drawn from 4 different feature groups. We take this representation as the least fine-grained representation and use it for the category “seats”. We assume that the objects from the categories “clothing” and “containers” (that exhibit less basic-level generalization) are represented with more feature groups (8 and 12, respectively).\nFigure 6 shows the results of running our model\non these three categories using the “adult” parameter settings. As expected, the generalization to the basic-level category is high for the least distinguished category “seats”, moderate for the category “clothing”, and low for the most distinguished category “containers”.7\nOur results suggest that the observed variation across categories in basic-level generalization could arise from differences in the granularity of representations of categories. This is particularly interesting since the model of X&T, despite encoding an elaborated taxonomy, does not capture the observed behaviour across all training conditions."
  }, {
    "heading": "7 Conclusions",
    "text": "A key challenge faced by children in vocabulary acquisition is learning which of many possible meanings is appropriate for a word, based largely on ambiguous situational evidence. One aspect of this is what we term the “word generalization” problem, which refers to how children associate a word such as dog with a meaning at the appropriate category level in a taxonomy of objects, such as Dalmatians, dogs, or animals.\nWe present extensions to a cross-situational learner that enable the first computational study of word generalization that is integrated within a word learning model. The model mimics child behavior found by Xu and Tenenbaum (2007): it shows a “basic-level” bias – a preference for word meanings that refer to basic-level objects (like dogs), in contrast to higher-level (animals) or lower-level (Dalmatians) categories – and does so\n7Similar results obtain using “child” parameter settings, but (as expected) the basic-level generalization is lower.\nunder parameter settings that treat all levels of category the same in the model (i.e., with no built-in basic-level bias). Other (unequal) parameter settings, which could reflect learned knowledge leading to differential treatment of categories, yield behavior that mimics that of adults, who show a stronger basic-level bias. Moreover, similarly to people (Abbott et al., 2012), our model exhibits variations in generalization to the basic level for different types of objects, a behavior that the model of Xu and Tenenbaum (2007) does not fully replicate.\nOverall, the results of our model arise from the interaction of type and token frequencies of features in the input data, which impact the model’s evolving word representations. This mechanism in the model captures the type-token influence often observed to underlie people’s generalization of linguistic categories – i.e., their linguistic productivity (e.g., Bybee, 1985; Croft and Cruse, 2004).\nOne shortcoming of the current model is its built-in ability to “detect” in the input that DOG and CAT features are more specific than ANIMAL features. The next step is to consider how the model might learn these relationships from its evolving knowledge of co-occurring features.\nFinally, a similar problem to that of word generalization in humans arises in computational linguistics: how to appropriately generalize a set of concepts to an overarching concept that subsumes the set. For example, this problem underlies one way to determine the selectional preferences of a verb: extract the set of nouns that occur as objects of the verb, map them to the concept nodes in a hierarchy such as WordNet, and then determine the best overarching WordNet category for capturing the salient properties of the object nouns overall (e.g., Li and Abe, 1998; Clark and Weir, 2001). An interesting future direction is to explore how an extension of our work can be applied to such problems in computational linguistics."
  }, {
    "heading": "8 Acknowledgements",
    "text": "We would like to thank Jackie Chi Kit Cheung and the anonymous reviewers for their valuable feedback. We gratefully acknowledge the support of NSERC of Canada, and of an Ontario Graduate Scholarship to the first author."
  }],
  "year": 2015,
  "references": [{
    "title": "Constructing a hypothesis space from the web for large-scale bayesian word learning",
    "authors": ["Joshua T. Abbott", "Joseph L. Austerweil", "Thomas L. Griffiths."],
    "venue": "Proceedings of the 34th Annual Conference of the Cognitive Science Society.",
    "year": 2012
  }, {
    "title": "Morphology: A study of the relation between meaning and form",
    "authors": ["Joan L. Bybee."],
    "venue": "Benjamins, Philadelphia.",
    "year": 1985
  }, {
    "title": "Class-based probability estimation using a semantic hierarchy",
    "authors": ["Stephen Clark", "David Weir."],
    "venue": "Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pages",
    "year": 2001
  }, {
    "title": "Cognitive linguistics",
    "authors": ["William Croft", "Alan Cruse."],
    "venue": "Cambridge University Press.",
    "year": 2004
  }, {
    "title": "A probabilistic computational model of cross-situational word learning",
    "authors": ["Afsaneh Fazly", "Afra Alishahi", "Suzanne Stevenson."],
    "venue": "Cognitive Science, 34(6):1017–1063.",
    "year": 2010
  }, {
    "title": "A Bayesian framework for cross-situational word-learning",
    "authors": ["Michael C. Frank", "Noah D. Goodman", "Joshua B. Tenenbaum."],
    "venue": "NIPS’07, volume 20.",
    "year": 2007
  }, {
    "title": "Early object labels: The case for a developmental lexical principles framework",
    "authors": ["Roberta M. Golinkoff", "Carolyn B. Mervis", "Kathryn Hirsh-Pasek."],
    "venue": "Journal of child language, 21(01):125–155.",
    "year": 1994
  }, {
    "title": "An associative model of adaptive inference for learning word–referent mappings",
    "authors": ["George Kachergis", "Chen Yu", "Richard M. Shiffrin."],
    "venue": "Psychonomic Bulletin & Review, pages 1–8.",
    "year": 2012
  }, {
    "title": "Word clustering and disambiguation based on co-occurrence data",
    "authors": ["Hang Li", "Naoki Abe."],
    "venue": "Proceedings of the 17th International Conference on Computational Linguistics - Volume 2, COLING ’98, pages 749–755. Association for Computational",
    "year": 1998
  }, {
    "title": "Individual choice behaviour",
    "authors": ["Robert D. Luce."],
    "venue": "Wiley, NY.",
    "year": 1959
  }, {
    "title": "Categorization and naming in children: Problems of induction",
    "authors": ["Ellen M. Markman."],
    "venue": "Mit Press.",
    "year": 1991
  }, {
    "title": "Vision: A computational investigation into the human representation and processing of visual information",
    "authors": ["David Marr"],
    "year": 1982
  }, {
    "title": "A computational study of late talking in word-meaning acquisition",
    "authors": ["Aida Nematzadeh", "Afsaneh Fazly", "Suzanne Stevenson."],
    "venue": "Proceedings of the 33th Annual Conference of the Cognitive Science Society, pages 705–710.",
    "year": 2011
  }, {
    "title": "Learnability and Cognition: The acquisition of Argument Structure",
    "authors": ["Steven Pinker."],
    "venue": "Cambridge, Mass.: MIT Press.",
    "year": 1989
  }, {
    "title": "Word and Object",
    "authors": ["Willard Van Orman Quine."],
    "venue": "MIT Press.",
    "year": 1960
  }, {
    "title": "Basic objects in natural categories",
    "authors": ["Eleanor Rosch", "Carolyn B. Mervis", "Wayne D. Gray", "David M", "Penny Boyes-Braem."],
    "venue": "Cognitive Psychology.",
    "year": 1976
  }, {
    "title": "On the Internal Structure of Perceptual and Semantic Categories, pages 111–144",
    "authors": ["Eleanor Rosch"],
    "year": 1973
  }, {
    "title": "Stimulus and response generalization: Tests of a model relating generalization to distance in psychological space",
    "authors": ["Roger N. Shepard."],
    "venue": "Journal of Experimental Psychology, 55(6):509.",
    "year": 1958
  }, {
    "title": "A computational study of cross-situational techniques for learning word-tomeaning mappings",
    "authors": ["Jeffery M. Siskind."],
    "venue": "Cognition, 61:39–91.",
    "year": 1996
  }, {
    "title": "Infants rapidly learn word-referent mappings via cross-situational statistics",
    "authors": ["Linda B. Smith", "Chen Yu."],
    "venue": "Cognition, 106(3):1558–1568.",
    "year": 2008
  }, {
    "title": "Word learning as Bayesian inference",
    "authors": ["Fei Xu", "Joshua B. Tenenbaum."],
    "venue": "Psychological Review, 114(2):245–272.",
    "year": 2007
  }, {
    "title": "Rapid word learning under uncertainty via cross-situational statistics",
    "authors": ["Chen Yu", "Linda B. Smith."],
    "venue": "Psychological Science, 18(5):414–420.",
    "year": 2007
  }, {
    "title": "The role of partial knowledge in statistical word learning",
    "authors": ["Daniel Yurovsky", "Damian C. Fricker", "Chen Yu", "Linda B. Smith."],
    "venue": "Psychonomic bulletin & review, 21(1):1–22.",
    "year": 2014
  }],
  "id": "SP:f5c61a0f24dab0a5584d71ecd80531f07b79031a",
  "authors": [{
    "name": "Aida Nematzadeh",
    "affiliations": []
  }, {
    "name": "Erin Grant",
    "affiliations": []
  }, {
    "name": "Suzanne Stevenson",
    "affiliations": []
  }],
  "abstractText": "A key challenge in vocabulary acquisition is learning which of the many possible meanings is appropriate for a word. The word generalization problem refers to how children associate a word such as dog with a meaning at the appropriate category level in a taxonomy of objects, such as Dalmatians, dogs, or animals. We present the first computational study of word generalization integrated within a word-learning model. The model simulates child and adult patterns of word generalization in a word-learning task. These patterns arise due to the interaction of type and token frequencies in the input data, an influence often observed in people’s generalization of linguistic categories.",
  "title": "A Computational Cognitive Model of Novel Word Generalization"
}