{
  "sections": [{
    "text": "Keywords Distributed learning · Multi-task learning · Acceleration"
  }, {
    "heading": "1 Introduction",
    "text": "Multi-task learning (MTL) (Caruana 1997) aims to jointly learn multiple machine learning tasks by exploiting their commonality to boost the generalization performance of each task. Similar to many standard machine learning techniques, in MTL, a single machine is assumed to be able to access all training data over different tasks. However, in practice, especially in the context of smart city, training data for different tasks is owned by different organizations and geo-distributed over different local machines, and centralizing the data may result in expensive cost of data transmission and cause privacy and security issues. Take personal-\nEditors: Kee-Eung Kim and Jun Zhu.\nB Sinno Jialin Pan sinnopan@ntu.edu.sg\nQiang Zhou zhouqiang@u.nus.edu\nYu Chen chenyu@ntu.edu.sg\n1 Nanyang Technological University, Singapore, Singapore\nized healthcare as a motivating example. In this context, learning a personalized healthcare prediction model from each user’s personal data including his/her profile and various sensor readings from his/her mobile device is considered as a different task. On one hand, the personal data may be too sparse to learn a precise prediction model for each task, and thus MTL is desired. On the other hand, some of the users may not be willing to share their personal data, which results in a failure of applying standard MTL methods. Thus, a distributed MTL algorithm is more preferred. However, if frequent communication is required for the distributed MTL algorithm to obtain an optimal prediction model for each task, users have to pay for expensive cost on data transmission, which is not practical. Therefore, designing a communication-efficient MTL algorithm in the distributed computing environment is crucial to address the aforementioned problem.\nThough a number of distributed machine learning frameworks have been proposed, most of them are focused on single task learning problems (Li et al. 2014; Boyd et al. 2011; Jaggi et al. 2014; Ma et al. 2015). In particular, COCOA+ as a general distributed machine learning framework has been proposed for strongly convex learning problems (Smith et al. 2017b; Ma et al. 2015; Jaggi et al. 2014). To handle non-strongly regularizers (e.g., 1-norm), Smith et al. (2015, 2017b) extended COCOA+ by directly solving the primal problem instead of its dual problem. However, in their proposed method, data needs to be distributed by features rather than instances. In our problem setting, we suppose the training data for different tasks is originally geo-distributed over different machines. In this case, to use the method proposed in Smith et al. (2015, 2017b), one has to first centralize the data of all the tasks and then re-distribute the data w.r.t. different sets of features, which is impractical.\nIn this paper, different from previous methods, we focus on the MTL formulation with a 2,1-norm regularization on the weight matrix over all the tasks, and offer a communicationefficient distributed optimization framework to solve it. Specifically, we have two main contributions: (1) We first present an efficient distributed optimization method that enjoys a fast convergence rate for solving the 2,1-norm regularizedMTL problem. To achieve this, we carefully design a subproblem for each local worker by incorporating an extrapolation step on the dual variables. We theoretically prove that with the well-designed local subproblem, our proposedmethod obtains a faster convergence rate than COCOA+ (Ma et al. 2015; Smith et al. 2017b), especially on ill-conditioned problems. Recently, Ma et al. (2017) also attempted to improve the convergence rate of COCOA+. However, our acceleration scheme is different from theirs. Specifically, with a strongly convex regularizer, the acceleration (Ma et al. 2017) can only be done for Lipschitz continuous losses, while our method is able to improve the convergence rate for both smooth and Lipschitz continuous losses. (2) To further reduce the communication cost at each round when handling extremely high-dimensional data, we propose a dynamic feature screening approach to progressively eliminate the features that are associated with zeros values in the optimal solution. Consequently, the communication cost can be substantially reduced as there are only a few features associated with nonzero values in the solution due to the effect of the sparsity regularization. Note that there exist several data or feature screening approaches for single task learning or MTL problems. We believe that this is the first proposed to reduce communication cost in distributed optimization.\nRecently, there have been several attempts at developing distributed optimization frameworks for MTL. Baytas et al. (2016) and Xie et al. (2017) proposed asynchronous proximal gradient based algorithms for distributed MTL. Their proposed methods, however, are communication-heavy as gradients need to be frequently communicated among machines. Wang et al. (2016) proposed a Distributed debiased Sparse Multi-task Lasso (DSML) algorithm. In DSML, there is only one round of communication between the local workers and the master. However, it requires the local workers to perform heavy computation (i.e., esti-\nmating a d × d sparse matrix) to obtain a debiased lasso solution. More importantly, DSML makes a stronger assumption to ensure support recovery. More recently, to provide tradeoff between local computation and global communication, COCOA+ has been extended for multi-task relationship learning by Liu et al. (2017). Later, this problem is further studied in Smith et al. (2017a) by considering statistical and systems challenges. Note that our work is different from Liu et al. (2017) and Smith et al. (2017a) in two ways: (1) Our proposed method enjoys a faster convergence rate than that analyzed in Liu et al. (2017) and Smith et al. (2017a) since their rates are the same as COCOA+. (2) We study different MTL models. Specifically, Liu et al. (2017) and Smith et al. (2017a) studied task-relationship based MTL model (Zhang and Yeung 2010) while our problem is feature based MTL. They are different as discussed in Zhang and Yang (2017). Moreover, as our work focuses on feature-based MTL model with sparsity (Obozinski et al. 2010, 2011; Wang and Ye 2015), it enables us to design a tailored feature screening technique to further reduce the communication cost. Unlike our framework, decentralized MTL methods have also been studied in Wang et al. (2018), Bellet et al. (2018), Vanhaesebrouck et al. (2017) and Zhang et al. (2018). However, these approaches may incur heavier communication cost because frequent communications are often required between tasks in MTL."
  }, {
    "heading": "2 Notation and preliminaries",
    "text": "Throughout this paper, w∈Rd K and W∈Rd×K denote a vector and a matrix, respectively, and G denotes a set.\n– [m] def= {i | 1 ≤ i ≤ m, i ∈ N}, {G j }d j=1: G j def= {(k − 1)d + j | k ∈ [K ]}, [x]+ def=\nmax(x, 0). – wi and Wi j : the i th and (i, j)th entries of w andW, respectively. – Wi·: the i th row of W, wG def= {wi | i ∈ G },WG · def= {Wi· | i ∈ G }. – 0: a vector or matrix with all its entries equal to 0, I: identity matrix. – ‖w‖ def= √〈w,w〉: 2-norm of w, ‖W‖F def= √ tr[W W]: Frobenius norm ofW. – ‖w‖2,1 def= ∑d j=1 ‖wG j ‖ and ‖W‖2,1 def= ∑dj=1 ‖W j·‖: 2,1-norm of w and W, respec-\ntively.\nDefinition 1 A function f (·) is L-Lipschitz continuous with respect to ‖ · ‖, if ∀w, ŵ ∈ Rd it holds that | f (ŵ) − f (w)| ≤ L‖ŵ − w‖.\nDefinition 2 A function f (·) is L-smooth with respect to ‖ · ‖, if ∀w, ŵ ∈ Rd it holds that f (ŵ) ≤ f (w) + 〈∇ f (w), ŵ − w〉 + L‖ŵ − w‖2/2.\nDefinition 3 A function f (·) is γ -strongly convex with respect to ‖ · ‖, if ∀w, ŵ ∈ Rd it holds that f (ŵ) ≥ f (w) + 〈∇ f (w), ŵ − w〉 + γ ‖ŵ − w‖2 /2.\nDefinition 4 For function f (·), its convex conjugate f ∗(·) is defined as f ∗(α) def= supw {〈α,w〉 − f (w)}.\nLemma 1 (Hiriart-Urruty andLemaréchal 1993)Assume that function f is closed and convex. If f is (1/γ )-smooth w.r.t. ‖ · ‖, then f ∗ is γ -strongly convex w.r.t. the dual norm ‖ · ‖∗."
  }, {
    "heading": "3 Problem setup",
    "text": "For simplicity, we consider the setting with K tasks distributed over K workers.1 For each task k, we have nk labeled instances {xki , yki } nk i=1 stored locally on worker k, where x k i ∈Rd is the i th input, and yki is the corresponding output. Our goal is to jointly learn different models in terms of wk ∈Rd , k ∈[K ] for each task. For ease of presentation, we define – n\ndef=∑Kk=1 nk : the total number of training instances over all the tasks. – Xk def= [xk1, . . . , xknk ] ∈Rd×nk and yk def= [yk1 , . . . , yknk ] ∈Rnk : the input and output for\ntask k. – W def= [w1, . . . ,wK ] ∈ Rd×K : the weight matrix over all the tasks. – A def= diag(X1, . . . ,XK )∈Rd K×n , w def= [(w1) , . . . , (wK ) ] ∈ Rd K .\nWe focus on the following MTL formulation with sparsity regularization (Obozinski et al. 2010, 2011; Lee et al. 2010; Wang and Ye 2015):\nmin W\n1 n f (w) + λ\n( ρ‖W‖2,1 + 1 − ρ\n2 ‖W‖2F\n) , (1)\nwhere f (w) def= ∑Kk=1 ∑nk i=1 fki (〈xki ,wk〉 ) , fki (〈xki ,wk〉 ) is the loss function of the kth task on the i th data point (xki , y k i ) and ρ ∈(0, 1). The group sparsity regularization ‖W‖2,1 aims to improve the generalization performance for each task by selecting important features, whose effect to the overall objective is controlled by the parameter λ. Note that the regularization term ‖W‖2F is not only to control the complexity of each linear model but also to facilitate distributed optimization.2 One can rewrite (1) as the following vectorization form,\nmin w\n{ P(w) def= 1\nn f (w) + λg(w)\n} , (2)\nwhere g(w) def= ρ∑dj=1 ‖wG j ‖ + (1−ρ)‖w‖2/2."
  }, {
    "heading": "3.1 Dual problem",
    "text": "Compared to the primal problem, it is well-known that there is a dual variable associated with each training instance in its dual problem. This property makes the dual problem more tractable for distributed optimization if training instances are stored on different workers. Let α=[α11, . . . , αKnK ] ∈Rn . As derived in “Appendix A”, the dual problem of (2) is\nmin α\n{ D(α)\ndef= 1 n f ∗(−α) + λg∗ ( Aα λn )} , (3)\n1 In general, the numbers of tasks and workers can be different. 2 Note that in this work we assume the regularizer is strongly convex which is the same as in COCOA+. As discussed in Sect. 1, for non-strongly convex regularizer, though an extension of COCOA+ has been proposed in Smith et al. (2015, 2017b), it is not practical for real-world scenarios as data needs to be geo-distributed by features rather than instances over local workers. In fact, our proposedmethod can also be applied to accelerate the approach proposed in Smith et al. (2015, 2017b). However, how to develop a distributed optimization algorithm when data is geo-distributed by instances and the regularizer of the objective is non-strongly convex is still an open problem. We leave this to our future study.\nwhere f ∗(−α) def=∑Kk=1 ∑nk i=1 f ∗ki (−αki ), f ∗ki (·) is the conjugate function of fki (·) and\ng∗ ( Aα λn ) def= d∑\nj=1\n{ g∗j (AG j·α\nλn\n) def= [‖AG j·α‖ − ρλn ]2 + 2(1 − ρ)λ2n2 } .\nLet w and α be optimal solutions to (2) and (3), respectively. One can obtain a primal solution w(α) from any dual feasible α via w(α) def= ∇g∗(Aα/(λn)). (4) Thus, the duality gap at α is G(α) def= P(w(α)) − (−D(α)) = P(w(α)) + D(α)."
  }, {
    "heading": "4 Efficient distributed optimization",
    "text": "For ease of presentation, we further introduce some additional notations. Let {Pk}Kk=1 be a partition of [n] such that αP k ∈R nk are the dual variables associated with the training instances of the kth task. For k ∈[K ], A∈Rd K×n and z∈Rn , we define – Âk ∈ Rd K×n : (Âk)·i\ndef= A·i if i ∈ Pk , otherwise 0. – α̂k ∈ Rn : (α̂k)i\ndef= αi if i ∈ Pk , otherwise 0, αk ∈ Rnk : αk def= αP k , f ∗ k (−α̂k) def=∑\ni∈P k f ∗ ki (−αki ).\nRecall that we assume {Xk, yk}Kk=1 to be stored over K local workers. Therefore, it is highly desirable to develop a communication-efficient distributed optimization method to solve (3). Note that one can adopt COCOA+ (Ma et al. 2015; Smith et al. 2017b) to solve the dual problem, which is similar to the idea of adopting COCOA+ for distributed multitask relationship learning (Liu et al. 2017; Smith et al. 2017a). However, in this way, the convergence rate of such a COCOA+-based approach fails to reach the best one as discussed in Arjevani and Shamir (2015). To address this problem, we present an efficient distributed optimization method to solve (3) with a faster convergence rate compared with the COCOA+based approach. The high-level idea of the proposed method is summarized in Algorithm 1, and the details are discussed as follows.\nAlgorithm 1 Efficient Distributed Optimization for (3) 1: Input: {xki , yki } nk i=1, k ∈[K ] distributed on K workers, strong convexity parameterμ, which will be formally\ndefined in Sect. 5. 2: Initialize:α0 def=0, u1 def=α0, θ0 def=√ϑη if μ>0 otherwise θ0 def= 1. 3: for t = 1 to T do 4: Send w(ut ) = ∇g∗ ( Aut /(λn) ) to all workers 5: for k ∈ [K ] in parallel over workers do 6: Update αkt via solving (5) 7: Send Aα̂kt to the master 8: end for 9: Set θt via (7) 10: Update Aut+1 via (8) 11: end for\nIn order to minimize (3) with respect to α in a distributed environment, one needs to design a subproblem for each worker such that the objective value of (3) decreases when\neach worker minimizes its local subproblem by only accessing its local data. In (3), the term f ∗(·) is separable for examples on different workers but g∗(·) is not. Note that g∗(·) is a smooth function. By Definition 2, it has a quadratic upper bound based on a reference point u that is separable. By making use of this upper bound, one can design a subproblem for each worker such that D(α) decreases if each worker minimizes its local subproblem. Let η\ndef= (1 − ρ)λn2. The following subproblem is used for the kth worker at the t th iteration: α̂kt\ndef= argmin α̂kt ∈Rn\nLk ( α̂kt ; ûkt ,w(ut ) ) , (5)\nwhere ut is a reference point at the t th iteration and\nLk ( α̂kt ; ûkt ,w(ut ) ) def= 1 n f ∗k (−α̂kt )+ λ K g∗ (Aut λn ) + 1 n 〈 w(ut ),A ( α̂kt − ûkt )〉\n+ 1 2η ∥∥A ( α̂kt − ûkt )∥∥2. (6)\nIt can be proved that D(αt ) ≤ ∑K k=1Lk ( α̂kt ; ûkt ,w(ut ) ) holds for any ut . Therefore, D(α) can be minimized by employing each local worker to solve its own local subproblem 5. With w(ut ), each subproblem can be minimized by only accessing the corresponding local data (Xk, yk).\nIn the literature of distributed optimization, e.g., COCOA+-based approaches (Ma et al. 2015; Smith et al. 2017a, b; Liu et al. 2017), the reference point ut is set to be the solution of last iteration αt−1. It leads to that the convergence rate of COCOA+-based approachs fails to reach the best one as discussed in Arjevani and Shamir (2015). In contrast, ut in our proposed method is set as follows,\nut+1 = αt + ( 1 − θt−1 ) θt−1\nθt + θ2t−1 ( αt − αt−1 ) ,\nwhere θt is the solution of θ2t = ( 1 − θt ) θ2t−1 + ϑηθt , (7)\nwhere ϑ def= μ/n. The definition of ut+1 implies\nAut+1= K∑\nk=1\n{ Aα̂kt + θt−1 ( 1−θt−1 )\nθt + θ2t−1 ( Aα̂kt − Aα̂kt−1 )} . (8)\nSpecifically, ut+1 is obtained based on an extrapolation from αt and αt−1. This is similar to Nesterov’s acceleration technique (Nesterov 2013). As we will see, this technique yields a faster convergence rate compared to COCOA+-based approaches (Ma et al. 2015; Smith et al. 2017a, b; Liu et al. 2017). Recently, Zheng et al. (2017) presented an accelerated distributed alternating dual maximization algorithm for single task learning, where an extrapolation is applied on the primal variable for acceleration. For smooth losses, they only proved the accelerated convergence rate in terms of primal suboptimality while we also prove it for duality gap, resulting in a stronger result.\nRemark 1 In each iteration of Algorithm 1, w(ut ) and {Aα̂kt }Kk=1 are communicated between master andworkers. By the definitions ofA and α̂kt , we note that ( w(ut )\n)k∈Rd andXkαkt ∈Rd are actually communicated betweenmaster and the kth worker. Therefore, its communication cost for each iteration is the same as COCOA+ in which ( w(αt ) )k∈Rd and Xkαkt ∈Rd are\ncommunicated. Note that w(ut+1) depends on Aαt but also Aαt−1, therefore we can keep a copy of Aαt−1 on the master until iteration t . In this way, no extra communication cost is induced in each iteration by our method for acceleration."
  }, {
    "heading": "5 Convergence analysis",
    "text": "In this section, we analyze the convergence rate of the proposed method and show that it is faster than COCOA+-based approaches. All the proofs can be found in “Appendix”. In our analysis, we assume that all f ∗ki , k ∈[K ], i ∈[nk] are μ-strongly convex (μ ≥ 0) with respect to the norm ‖ · ‖. According to Lemma 1, it is equivalent to assuming that all fki , for k ∈[K ] and i ∈[nk] are (1/μ)-smooth with respect to the norm ‖ · ‖. Since μ is allowed to be 0, our analysis also covers the case that all f ∗ki , for k ∈ [K ] and i ∈ [nk] are only generally convex (i.e., μ = 0), which implies that all fki for k ∈ [K ] and i ∈ [nk] are Lipschitz continuous instead of smooth. To facilitate analysis, we also assume that Lk ( α̂kt ; ûkt ,w(ut ) ) is exactly solved for any k ∈ [K ] and t ≥ 1. By defining ζt\ndef= θ2t /η, (7) becomes ζt = ( 1 − θt ) ζt−1 + ϑθt . (9)\nFor any t ≥ 1 and k ∈ [K ], v̂kt is defined as v̂kt def= α̂kt−1 + ( α̂kt − α̂kt−1 )/ θt , k ∈ [K ]. (10)\nIn addition, the suboptimality on dual objective function tD is defined as t D def= D(αt ) − D(α ), t ≥ 0. By using the above notations, the following lemma shows that there is an upper bound for the suboptimality tD . As we will see, this is the foundation for analyzing the convergence rate of duality gap.\nLemma 2 Consider applying Algorithm 1 to solve (3), the following inequality holds for any t ≥ 1,\ntD + Rt ≤ γt ( 0D + R0 ) , (11)\nwhere Rt = ζt2 ∑K k=1 ∥∥A ( α̂k − v̂kt )∥∥2, γt = ∏t i=1 ( 1 − θi ) for any t ≥ 1 and γ0 = 1.\nIt can be found that the form of γt determines the convergence rate of Algorithm 1. Therefore, next, we study the convergence rate by using the upper bound of γt under different settings of the loss function."
  }, {
    "heading": "5.1 Convergence rate for smooth losses",
    "text": "By applying Lemma 2, the following lemma characterizes the effect of iterations of Algorithm 1 when the loss functions fki ’s are (1/μ)-smooth for any k ∈ [K ] and i ∈ [nk]. Lemma 3 Assume the loss functions fki ’s are (1/μ)-smooth for any k ∈[K ] and i ∈[nk]. If θ0= √ ϑη and (1 − ρ)λμn ≤1, then the following inequality holds for any t ≥ 1\ntD ≤ ( 1 −√(1 − ρ)λμn )t( 0D + R0 ) . (12)\nLet σmax def= maxα =0 ‖Aα‖2/‖α‖2. By applying Lemma 3, the next theorem shows the\ncommunication complexities for smooth losses in terms of dual objective and duality gap.\nTheorem 1 Assume the loss functions fki ’s are (1/μ)-smooth for any k ∈ [K ] and i ∈ [nk]. If θ0= √ ϑη and (1 − ρ)λμn ≤1, then after T iterations in Algorithm 1 with\nT ≥ √\n1 (1 − ρ)λμn log (( 1 + σmax ) 0D D ) ,\nD ( αT )− D(α ) ≤ D holds. Furthermore, after T iterations with\nT ≥ √\n1 (1−ρ)λμn log (( 1 + σmax ) (1 − ρ)λμn + σmax (1 − ρ)λμn 0D\nG\n) ,\nit holds that P ( w(αT )) − (−D(αT )) ≤ G.\nFollowing Zhang and Xiao (2017), we define the condition number κ as κ def= maxk,i ‖xki ‖2/(λμ). With the above analysis, the communication complexity of our method is linear with respect to √ κ , while it is linear with κ for COCOA+-based approaches (Ma et al. 2015; Smith et al. 2017b). The value of κ is typically the order of n as λ is usually set to the order of 1/n (Bousquet and Elisseeff 2002). Therefore, our method is expected to converge faster than COCOA+-based approaches."
  }, {
    "heading": "5.2 Convergence rate for Lipschitz continuous losses",
    "text": "Next, we present the convergence rate of the Algorithm 1 when the loss function is just general convex and Lipschitz continuous.\nTheorem 2 Assume the loss functions fki ’s are generally convex and L-Lipschitz continuous for any k ∈[K ], i ∈[nk]. If θ0=1, the following inequality holds for any t ≥1\ntD ≤ 1 (t + 2)2 ( 4 0D + 8L2σmax (1 − ρ)λn2 ) . (13)\nAfter T iterations in Algorithm 1 with\nT ≥ √\n8L2σmax (1 − ρ)λn2 D + 4 0 D D − 2, (14)\nit holds that D ( αT )− D(α ) ≤ D.\nRemark 2 For generally convex loss function, the dual objective obtained by Algorithm 1 decreses in O(1/t2) instead of O(1/t) for COCOA+. Therefore, the complexity for obtaining D-suboptimal solution is √ 1/ D that is faster than that of COCOA+ (i.e., 1/ D)."
  }, {
    "heading": "6 Further reduce communication cost via dynamic feature screening",
    "text": "In Sect. 4, we present an acceleration method for distributed optimization of (3) that reduces the communication cost in terms of iteration of communications. As discussed in Remark 1, the communication cost of our method in each iteration is linear with the number of features d , that is the same as previous distributed optimization methods for sparsity-regularized problems. It can be expensive for high-dimensional data. To address this issue, we present\na method to reduce the communication cost for each iteration by exploiting the sparsity of w (Bonnefoy et al. 2015; Fercoq et al. 2015; Ndiaye et al. 2017). It is well-known that the 2,1-norm regularization is able to produce a row sparse pattern on W (Obozinski et al. 2011, 2010; Yuan et al. 2006; Zou and Hastie 2005). In other words, (w )G j will be 0 for most Gj , j ∈ [d]. Thereafter, we refer the j th feature as an inactive feature if (w )G j = 0, otherwise an active feature. The key idea of feature screening is to identify inactive features before sending the updated information to workers (Line 4 in Algorithm 1). In this way, the communication cost can be reduced since it is linear with the number active features.\nTo identify inactive features, we need to exploit the KKT condition of (2)\n( α )k i ∈ ∂ fki (〈 xki ,w k 〉) ,∀k ∈ [K ], i ∈ [nk], (15) AG j·α λn ∈ (1 − ρ)(w ) G j + ρ∂∥∥(w )G j ∥∥,∀ j ∈ [d]. (16)\nBy checking the subgradient of ‖ · ‖, it implies (w )G j =0 if ‖(w )G j ‖<1. Combining this fact with (16), we have ∥∥AG j·α ∥∥ < ρλn ⇒ (w )G j = 0. (17)\nAlgorithm 2 Dynamic Feature Screening for (3) 1: Input: { Aα̂kt }K k=1 2: Compute duality gap G(αt ) 3: for all currently active features do 4: Identify inactive feature via solving (19) 5: end for\nIt can be shown that one can obtain the exact optimum even without considering these inactive features during optimization. Therefore, one can reduce the communication cost by discarding these inactive features, thus less information needs to be communicated. To use (17) to identify inactive features, one needs to haveα that is unknownbefore the optimization problem (3) is solved. Next, we show that a feasible setF can be constructed for α by using the strong convexity of D(α). Crucial Value λmax: In view of (17) and (15), there exists a crucial value λmax such that w =0 for any λ ≥ λmax. Let r=[ f ′11(0), . . . , f ′K nK(0)]∈R\nn , (15) implies that α =r when w =0. By substituting α into (17), we obtain λmax=max j∈[d] ‖AG j r‖/(ρn). It is trivial to obtain a closed form solution w = 0 and α = r if λ ≥ λmax. Therefore, we only focus on the cases when λ < λmax.\nFeasible Set of α : Lemma 1 implies D(α) is strongly convex if fki ’s are smooth for all k and i . By using this fact, the dual optimal solution α can be bounded in terms of α and its duality gap G(α) as stated in the following lemma.\nLemma 4 Assume the loss functions fki’s are (1/μ)-smooth for any k ∈[K ], i ∈[nk]. For any dual feasible solution α, it holds that α ∈F def= { θ | ‖θ − α‖ ≤ √2G(α)n/μ}.\nBy using Lemma 4, (17) can be relaxed as\nmax θ∈F\n‖AG j ·θ ∥∥ < ρλn ⇒ (w )G j = 0. (18)\nIn other words, we need to solve the following problem\nmax θ\n∥∥AG j ·θ ∥∥, s.t. ‖θ − α‖ ≤ √2G(α)n/μ. (19)\nAlthough it is non-convex, the global optimum of (19) can be obtained by using the result in Gay (1981). Let us define H ∈ RK×K , g ∈ RK , υ j ,I j , I j and s ∈ RK as – H def= −diag(2‖X1j·‖2, . . . , 2 ∥∥XKj· ∥∥2),g def= −2[∥∥X1j· ∥∥∣∣〈X1j·,α1 〉∣∣, . . . , ∥∥XKj· ∥∥∣∣〈XKj·,αK\n〉∣∣] . – υ j def= maxk∈[K ] ∥∥Xkj· ∥∥2, I j def= { k ∣∣ ∥∥Xkj· ∥∥2 = υ j , k ∈ [K ] } , I j def= [K ] \\ I j . – sk def= ∥∥Xkj· ∥∥∣∣〈Xkj·,αk 〉∣∣\nυ j − ∥∥Xkj·\n∥∥2 if k ∈ I j , otherwise sk def= 0.\nBy using the above notations, the solution of (19) is given in the following lemma.\nLemma 5 If υ j =0, the maximum value of (19) is 0. Otherwise, the upper bound is K∑\nk=1\n〈 Xkj·,α k 〉2+ nG(α) μ ϑ − 1 2 〈g, s 〉 ,\nwhere ϑ and s are defined as follows: (a) ϑ =2υ j and s = s+̂s if 1) ∃ ŝ∈RK with ŝI j =0 and ‖ s+̂s‖=√2G(α)n/μ, and 2) 〈 Xt· j , θ t 〉 =0,∀t ∈I j . (b) Otherwise, ϑ >2υ j is solution of ‖ (H+ϑ I)−1 g‖=√2G(α)n/μ, and s =−(H+ϑ I)−1g. To perform screening every p iterations, one can simply add the following three lines before line 4 in Algorithm 1.\n– if t%p = 0 then – Call Algorithm 2 – end if\nCosts of Screening:Note that the screening is performed on the master every p iterations.\n– By carefully examining the detailed screening rule, the master actually only needs Aαt when evaluating screening rule. Even without screening, the Aαt needs to be computed and sent to the master in each iteration as stated in Algorithm 1 and Remark 1. Therefore, the feature screening does not induce extra communication cost. – Regarding the computational cost, we note that the screening problem is dependent on the number of active features that is atmost d (there are less and less feature due to screening). As shown in Lemma 5, the screening problem for each feature is a one dimension variable optimization problem. It either has a closed form solution (Case 1) or can be efficiently solved by using Newton’s method (Case 2) that usually takes less than 5 iterations to meet the accuracy 10−15. – More importantly, by screening out inactive features, it can substantially save optimization problem, especially on local computation. Recall that the local SDCA computation complexity is O(Hd)where H is the local SDCA iteration number and its is usuallymore than 105. Compared to local SDCA computation cost, the cost of screening is negligible.\nWe note that Ndiaye et al. (2015) also presented a feature screening method for multitask learning. However, in their work, all tasks are assumed to share the same training data while our method allows each task to has its own training data. Consequently, the feature screening problem (19) becomes non-convex instead of convex, which is different from and\nmore challenging than that studied in Ndiaye et al. (2015). In addition, Wang and Ye (2015) developed a static screening rule that exploits the solution at another regularization parameter and only performs screening before the optimization procedure. By contrast, our screening rule is a dynamicwith aweaker assumption to exploit the latest solution to repeatedly perform screening during optimization. Therefore, our screening is more practical and performs better empirically.\nDifference between Our Proposed Method and COCOA+ We denote the proposed method by DMTLS . There are two main differences between DMTLS and COCOA+. First, DMTLS constructs the subproblem 5 by using the extrapolation of the solutions in last two iterations that is able to achieve accelerated convergence rate. In contrast, COCOA+ only uses the solution of last iteration. Second, DMTLS presents a dynamic feature screening method to reduce the communication cost for each iteration by exploiting the sparsity of the model."
  }, {
    "heading": "7 Experiments",
    "text": ""
  }, {
    "heading": "7.1 Experimental setting",
    "text": "In previous sections, we present our method by focusing on distributed MTL. We hereby conduct experiments to show the advantages of the proposed method for MTL. In fact, our approach can also be extended for distributed single task learning (STL) and the details are provided in the “Appendix”.\nTo demonstrate the advantages of DMTLS , we compare DMTLS with a COCOA+-based approach (Ma et al. 2015; Smith et al. 2017b) and its extension MOCHA (Smith et al. 2017a) to solve the dual problem (3). In our experiments, the squared loss is used for regression, and the smoothed hinge loss (Shalev-Shwartz and Zhang 2013) is used for classification with μ = 0.5 for all experiments. It is clear to see that fki is (1/μ)-smooth. For ease of comparison, the local subproblem is solved by using SDCA (Shalev-Shwartz and Zhang 2013) for all methods. The number of iterations for SDCA is set to H =104 for all datasets.\nWe run all experiments on a local server with 64 worker cores. A distributed environment is simulated on the machine by using distributed platform Petuum (Xing et al. 2015),3 and workers for each task are assigned to isolated processes that communicate solely through the platform. Regarding the performance, we evaluate the number of communication iterations required by different methods to obtain a solution with prescribed duality gap. Due to the limitation of computational resources, we are not able to perform experiments on a real distributed environment. However, the results (i.e., the number of communication iterations) reported in this paper does not depend on the environment that it runs on. Compared to COCOA+, the additional computation incurred by our method is negligible: the computation complexity of each iteration of COCOA+ is O(H×d). The additional computations required by our method for acceleration and feature screening is O(d) and O(d), respectively. This cost is negligible compared to that of SDCA because H is usually around 105.\nWe conduct experiments on the following three datasets (Table 1). Synthetic Data contains K =10 regression tasks and generated by using yki = 〈xki ,wk〉+ . The number of examples for each task is randomly generated, which ranges from 903 to 1098. xki ∈R50,000 is drawn from N (0, I) and ∼ N (0, 0.5I). To obtain a W with row\n3 Note that our method can be implemented in other distributed platforms.\nsparsity, we randomly select 400 dimensions from [d] and generate them from N (0, I) for all tasks. For each task, extra noise from N (0, 0.5I) is added to W. News20 (Lang 1995) is a collection of around 20,000 documents from 20 different newsgroups. To construct a multi-task learning problem, we create 5 binary classification tasks using data of all the 5 groups from comp as positive examples. For the negative examples, we choose data from misc.forsale, rec.autos, rec.motorcycles, rec.sport.baseball and rec.sport.hockey. The number of training examples for each task ranges from 1163 to 1190, and the number of features is 34,967. MDS (Blitzer et al. 2007) includes product reviews on 25 domains in Amazon. We use 22 domains each of which has more than 100 examples for multitask binary sentiment classification. To simulate MTL, we randomly select 1000 examples as training data for the domain withmore than 1000 examples. Consequently, the number training examples for each domain ranges from 220 to 1000. The number of features of is 10,000."
  }, {
    "heading": "7.2 Results of faster convergence rate",
    "text": "In order to test the convergence rate of DMTLS , we compare it with the COCOA+-based approach to solving (3) under varying values of λ. In view of Sect. 6, we chose λ=10−2λmax and λ=10−3λmax to solve (3). We set α0=0 for all methods and ρ =0.9 for all experiments.\nFigure 1 shows the comparison results in terms of the numbers of iterations for communication used by DMTLS and COCOA+ to obtain a solution meeting a prescribed duality gap. From the Fig. 1, we can observe that:\n– DMTLS is significantly faster than COCOA+ in terms of the number of iterations to meet a prescribed duality gap. Take the synthetic dataset and News20 for example, to obtain a solution atλ=10−3λmaxwith duality gap 10−5, DMTLS obtains speedups of a factor of 6.64 and 6.94 over COCOA+ on the two datasets, respectively. – Generally, the speedup obtained by DMTLS is more significant for small values of λ. For example, when λ = 10−2λmax, DMTLS converges 4.81 and 4.05 times faster than COCOA+ on the synthetic dataset and News20, respectively. In contrast, the speedups is improved up to 7.00 and 5.70 times faster than COCOA+ when λ = 10−3λmax. – The improvement is more pronounced when a higher precision is used as the stopping criterion. Take News20 with λ = 10−3λmax for example, the speedups of DMTLS over COCOA+ are 4.00, 4.94, 5.70 and 6.94 when the duality gaps are 10−2, 10−3, 10−4 and 10−5, respectively."
  }, {
    "heading": "7.3 Robust to straggler",
    "text": "In Smith et al. (2017a), MOCHA is proposed to improve COCOA+ to handle systems heterogeneity, e.g., straggler. That means some workers are considerably slower than others and\nthe stragglers fail to return prescribed accurate solution for some iterations. Here, we compare our method with COCOA+ equipped with handling system heterogeneity as presented in Smith et al. (2017a) on News20 and show that our method converges faster even if there exist stragglers. Specifically, we perform experiments under the setting of Smith et al. (2017a) by using different values of H for different workers to simulate the effect of stragglers. The value of H for each iteration is draw from [0.9nmin, nmin] to simulate low variability environment and [0.5nmin, nmin] to simulate high variability environment, where nmin = mink nk .\nAs shown in Fig. 2, our method is still able to substantially reduce the number of communication for both low and high variability environments. This shows that empirically DMTLS is robust to straggler although our analysis assumes that the local subproblem needs to be exactly solved."
  }, {
    "heading": "7.4 Results of reduced communication cost",
    "text": "To demonstrate the effect of dynamic screening for reducing communication cost, we perform a warm start cross validation experiment on News20 and MDS. Specifically, we solve (3) with 50 various values of λ, {λi }50i=1, which are equally distributed on the logarithmic grid from 0.01λmax to 0.3λmax sequentially (i.e., the solution of λi is used as the initialization of λi−1). To evaluate the total communication cost for the 50 values of λ, we calculate the total number of vectors of dimension d used for communication for each worker. We experiment on the following two settings: 1) DMTLS without dynamic screening (Without DS), and 2) DMTLS with dynamic screening (With DS). Figure 3 presents the total communication cost used by DMTLS without and with dynamic screening to solve (3) over {λi }50i=1 on News20 and MDS.\nFrom Fig. 3, we can observe that:\n– The communication cost has been substantially reduced by the proposed dynamic screening because the most inactive features have been progressively identified and discarded during optimization. For example, when the prescribed duality is 10−7, the communi-\ncation cost reduction by the proposed method is 83.32% and 67.43% on News20 and MDS, respectively. – This advantage of dynamic screening is more significant when a higer precision is used as the stopping criterion. On News20, the speedup increases from 5.99 to 8.63 when the duality gap changes from 10−7 to 10−8. This is because more inactive features can be screened out when a more accurate solution is obtained. – More importantly, the proposed dynamic screening is more pronounced for the problem with higher dimension. Take the duality gap of 10−8 for example, the speedups\nobtained by dynamic screening are 8.63 and 4.14 on News20 and MDS, respectively, where News20 is of much higher dimensionality than MDS."
  }, {
    "heading": "8 Conclusion",
    "text": "In this paper, we present a new distributed optimization method, DMTLS , for MTL with matrix sparsity regularization. We provide theoretical convergence analysis for DMTLS . We also propose a data screening method to further reduce the communication cost. We carefully design and conduct extensive experiments on both synthetic and real-world datasets to verify the faster convergence rate and the reduced communication cost of DMTLS in comparison with two state-of-the-art baselines, COCOA+ and MOCHA.\nAcknowledgements This work is supported by NTU Singapore Nanyang Assistant Professorship (NAP) Grant M4081532.020 and Singapore MOE AcRF Tier-2 Grant MOE2016-T2-2-060."
  }, {
    "heading": "Appendix A: Dual problem",
    "text": "By introducing zki for each fki , one can rewrite (2) as\nmin w\n1\nn\nK∑\nk=1\nnk∑ i=1 fki (−zki )\n+ λ ( ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 ) s.t. 〈xki ,wk〉 + zki = 0, k ∈ [K ], i ∈ [nk].\nLet − 1n αki be the Lagrangian multiplier for the (k, i)th constraint. For convenience, let\nz = [z11, . . . , zKnK ] ∈ Rn and α = [α11, . . . , αKnK ] ∈ Rn .\nThen, the Lagrangian is\nL ( w, z,α ) = 1 n\nK∑\nk=1\nnK∑ i=1 fki (−zki ) + λ ( ρ d∑ j=1 ‖wG j ‖ + 1 − ρ 2 ‖w‖2 )\n− 1 n\nK∑\nk=1\nnK∑ i=1 αki ( 〈xki ,wk〉 + zki )\n= 1 n\nK∑\nk=1\nnK∑\ni=1\n( fki (−zki ) − αki zki ) + λ ( ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 )\n− 1 n 〈Aα,w〉 .\nThe dual problem can be obtained by taking the infimum with respect to both w and z\ninf w,z L(w, z,α) = 1 n inf z\nK∑\nk=1\nnK∑\ni=1\n( fki (−zki ) − αki zki )\n+ inf w\n{ λ ( ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 ) − 1 n 〈Aα,w〉 } .\nwhere\n1 n inf z\nK∑\nk=1\nnK∑\ni=1\n( fki (−zki ) − αki zki ) = −1\nn sup z\nK∑\nk=1\nnK∑\ni=1\n( αki z k i − fki (−zki ) )\n= −1 n\nK∑\nk=1\nnK∑ i=1 f ∗ki (−αki ). (20)\nλ inf w\n{ ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 − 1 λn 〈Aα,w〉 }\n= −λ sup w\n{ 1\nλn 〈Aα,w〉 −\n( ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 )} = −λg∗ (Aα λn ) .\nRegarding the explicit form of g∗ (Aα\nλn\n) , it can be shown that\ng∗ (Aα\nλn\n) = inf\nw\n{ ρ d∑\nj=1 ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 − 1 λn 〈Aα,w〉 } .\nThe optimality condition of the above problem implies\n0 ∈ (1 − ρ)wG j + ρ∂‖wG j ‖ − 1 λn AG j ·α, j ∈ [d]. (21)\nThe definition of subgradient implies\nwG j = 0 if 1 λn ‖AG j ·α‖ < ρ.\nOtherwise, we have\n0 = (1 − ρ)wG j + ρ wG j ‖wG j ‖ − 1 λn AG j ·α.\nwhich implies\n‖wG j ‖ = ‖AG j ·α‖ − ρλn (1 − ρ)λn and wG j = ‖AG j ·α‖ − ρλn (1 − ρ)‖AG j ·α‖ 1 λn AG j ·α.\nCombining these two cases together, we obtain\nwG j = [‖AG j ·α‖ − ρλn ] + (1 − ρ)‖AG j ·α‖ 1 λn AG j ·α, ∀ j ∈ [d]. (22)\nThen, the conjugate of g(w) is\ng∗ (Aα\nλn\n) = d∑\nj=1 ρ‖wG j ‖ +\n1 − ρ 2 ‖w‖2 − 1 λn 〈α,Xw〉 = d∑\nj=1\n[‖AG j ·α‖ − ρλn ]2 +\n2(1 − ρ)λ2n2 .\nTherefore, the dual problem of (2) is\nmax α −1 n\nK∑\nk=1\nnK∑ i=1 f ∗ki (−αki ) − λ d∑ j=1\n[‖AG j ·α‖ − ρλn ]2 +\n2(1 − ρ)λ2n2 .\nLetw and α denote the primal and dual optimal solutions, respectively. From (20) and (21) the KKT condition of (2) establishes\n( α )k i ∈ ∂ fki (〈xki ,wk 〉 ) ,∀k ∈ [K ], i ∈ [nk] and\n1\nλn AG j ·α ∈ (1 − ρ)w G j + ρ∂‖w G j ‖, j ∈ [d]."
  }, {
    "heading": "Appendix B: Convergence analysis",
    "text": "To facilitate the proof, we first introduce some useful notations and technical Lemmas. It is easy to verify that ûkt can be rewritten as\nûkt = α̂kt−1 + θtζt−1 ζt−1 + ϑθt ( v̂kt−1 − α̂kt−1 ) , k ∈ [K ]. (23)\nFor any t ≥ 0, we define β t as β t def= ( ut − αt ) /η ⇒ αt = ut − ηβ t ∀k ∈ [K ].\nLemma 6 (Dünner et al. 2016) Consider the following pair of optimization problems, which are dual to each other:\nmin α∈Rn\n{ D(α) def= f ∗(−α) + g∗(Aα)} and min w∈Rd { P(w) def= f (Aw) + g(w)},\nwhere f ∗ is μ-strongly convex with respect to a norm ‖·‖ f ∗ and g∗ is 1/β-smooth with respect to a norm ‖ · ‖g∗ . Let σmax = maxα =0 ‖Aα‖2g∗/‖α‖2f ∗ . Suppose an arbitrary optimization algorithm is applied to the first problem and it produces a sequence of (possibly random) iterates {αt }∞t=0 such that there exits C ∈ (0, 1], D ≥ 0 such that\nE [ D(αt ) − D(α ) ] ≤ (1 − C)t D. Then, for any\nt ≥ 1 C\nlog D(σmax + μβ)\nμβ ,\nit holds that E [ P(w(αt )) − (−D(αt )) ] ≤ .\nRemark 3 This lemma enables us transfer the convergence rate of objective function to the convergence rate of duality gap.\nLemma 7 For any t ≥ 1, the following identities hold θtζt−1\nζt\n( ûkt − v̂kt−1 ) = (α̂kt−1 − ûkt )\n(24)\nζt v̂ k t = (1 − θt )ζt−1̂vkt−1 + ϑθt ûkt − θt β̂kt (25) ζt\n2\n(∥∥A ( α̂k − v̂kt )∥∥2 − ∥∥A(ûkt − v̂kt )∥∥2 )\n− (1 − θt )ζt−1 2 (∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2 )\n= ϑθt 2 ∥∥A ( α̂k − ûkt )∥∥2 + θt 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉 (26)\nζt 2 ∥∥A ( ûkt − v̂kt )∥∥2 − (1 − θt ) 〈 A ( α̂kt−1 − ûkt ) ,Aβ̂ k t 〉− η 2 ∥∥Aβ̂kt ∥∥2\n= (1 − θt )ζt−1 2 ( 1 − ϑθt\nζt\n)∥∥A ( ûkt − v̂kt−1 )∥∥2. (27)\nProof First, we show that (24) can be proved by using the definition of ûkt and ζt .\n(ζt−1 + ϑθt )̂ukt = (ζt−1 + ϑθt )̂αkt−1 + θtζt−1 ( v̂kt−1 − α̂kt−1 )\n⇒ ((1 − θt )ζt−1 + ϑθt ) ûkt + θtζt−1ûkt = ( (1 − θt )ζt−1 + ϑθt ) α̂kt−1 + θtζt−1̂vkt−1 ⇒ θtζt−1 ( ûkt − v̂kt−1 ) = ζt ( α̂kt−1 − ûkt ) ,\nwhich implies θtζt−1 ( ûkt − v̂kt−1 ) /ζt = ( α̂kt−1 − ûkt ) . Next, (25) can be shown by using β̂ k t and ζt = θ2t /η. Following from the definition of v̂kt , we have\nv̂kt = α̂kt−1+ 1\nθt\n( α̂kt −α̂kt−1 ) = α̂kt−1+ 1\nθt\n( ûkt −ηβ̂kt −α̂kt−1 ) = 1 θt ( ûkt −(1−θt )̂αkt−1 )− θt ζt β̂ k t ,\nwhich implies\nζt v̂ k t =\n1\nθt\n( ζt û k t − ζt (1 − θt )̂αkt−1 )− θt β̂kt\n= 1 − θt θt ( ζt 1 − θt ûkt − ζt α̂kt−1 ) − θt β̂kt = 1 − θt θt ( (1 − θt )ζt−1 + ϑθt 1 − θt ûkt − ζt α̂kt−1 ) − θt β̂kt = 1 − θt θt ( (ζt−1 + ϑθt )̂ukt − ζt α̂kt−1 ) − 1 − θt θt ( ϑθt − ϑθt 1 − θt ) ûkt − θt β̂kt\n= (1 − θt )ζt−1̂vkt−1 + ϑθt ûkt − θt β̂kt . To proved (26), we need to use (24) and (25). By using the definition of ζt and (25), one can show that\nζt 2\n(∥∥A ( α̂k − v̂kt )∥∥2 − ∥∥A(ûkt − v̂kt )∥∥2 )\n= 1 2ζt\n(∥∥A ( ζt α̂ k − ζt v̂kt )∥∥2 − ∥∥A(ζt ûkt − ζt v̂kt )∥∥2 )\n= 1 2ζt\n(∥∥∥A (( (1 − θt )ζt−1 + ϑθt ) α̂k − ( (1 − θt )ζt−1̂vkt−1 + ϑθt ûkt − θt β̂kt ))∥∥∥ 2\n− ∥∥∥A (( (1 − θt )ζt−1 + ϑθt ) ûkt − ( (1 − θt )ζt−1̂vkt−1 + ϑθt ûkt − θt β̂kt ))∥∥∥ 2)\n= 1 2ζt\n(∥∥∥(1 − θt )ζt−1A ( α̂k − v̂kt−1 )+ ϑθtA ( α̂k − ûkt )+ θtAβ̂kt ∥∥∥ 2\n− ∥∥∥(1 − θt )ζt−1A ( ûkt − v̂kt−1 )+ θtAβ̂kt ∥∥∥ 2)\n= 1 2ζt\n( (1 − θt )2ζ 2t−1 ∥∥A ( α̂k − v̂kt−1 )∥∥2 + ϑ2θ2t ∥∥A ( α̂k − ûkt )∥∥2\n− (1 − θt )2ζ 2t−1 ∥∥A ( ûkt − v̂kt−1 )∥∥2 + 2ϑθt (1 − θt )ζt−1 〈 A ( α̂k − v̂kt−1 ) ,A ( α̂k − ûkt )〉 + 2θt (1 − θt )ζt−1 〈 A ( α̂k − v̂kt−1 ) ,Aβ̂ k t 〉 + 2ϑθ2t 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉− 2θt (1 − θt )ζt−1 〈 A ( ûkt − v̂kt−1 ) ,Aβ̂ k t 〉)\n= 1 2ζt ( 1 − θt ) ζt−1 ( ζt − ϑθt )(∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2 )\n+ 1 2ζt ϑθt ( ζt − (1 − θt )ζt−1 )∥∥A ( α̂k − ûkt )∥∥2 + 1 ζt ϑθt (1 − θt )ζt−1 〈 A ( α̂k − v̂kt−1 ) ,A ( α̂k − ûkt )〉 + 1 ζt θt (1 − θt )ζt−1 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉+ 1 ζt ϑθ2t 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉\n= (1 − θt )ζt−1 2 (∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2)+ ϑθt 2 ∥∥A ( α̂k − ûkt )∥∥2\n− ϑθt (1 − θt )ζt−1 2ζt (〈 A (( α̂k + ûkt − 2̂vkt−1 )+ (α̂k − ûkt ) − 2(α̂k − v̂kt−1 )) ,A ( α̂k − ûkt )〉)\n+ θt ζt ( (1 − θt )ζt−1 + ϑθt )〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉\n= (1 − θt )ζt−1 2 (∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2 )\n+ ϑθt 2 ∥∥A ( α̂k − ûkt )∥∥2 + θt 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉 ,\nwhich can be rewritten as\nζt 2\n(∥∥A ( α̂k − v̂kt )∥∥2 − ∥∥A(ûkt − v̂kt )∥∥2 )\n− (1 − θt )ζt−1 2 (∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2 )\n= ϑθt 2 ∥∥A ( α̂k − ûkt )∥∥2 + θt 〈 A ( α̂k − ûkt ) ,Aβ̂ k t 〉 .\nFinally, we prove (27) by using (24) and (25).\nζt 2 ∥∥A ( ûkt − v̂kt )∥∥2 = ζt 2 ∥∥A ( ζt û k t − ζt v̂kt )∥∥2\n= 1 2ζt ∥∥A ((\n(1 − θt )ζt−1 + ϑθt )̂ukt − (1 − θt )ζt−1̂vkt−1 − ϑθt ûkt + θt β̂kt )∥∥2\n= 1 2ζt ∥∥A ( (1 − θt )ζt−1 ( ûkt − v̂kt−1 )+ θt β̂kt )∥∥2 = (1 − θt ) 2ζ 2t−1\n2ζt\n∥∥A ( ûkt − v̂kt−1 )∥∥2\n+ θt (1 − θt )ζt−1 ζt 〈 A ( ûkt − v̂kt−1 ) ,Aβ̂ k t 〉+ θ 2 t 2ζt ∥∥Aβ̂kt ∥∥2.\nBy using (24), we obtain\nζt 2 ∥∥A ( ûkt − v̂kt )∥∥\n= (1 − θt ) ζt−1(ζt − ϑθt )\n2ζt\n∥∥A ( ûkt − v̂kt−1 )∥∥2 + (1 − θt ) 〈 A ( α̂kt−1 − ûkt ) ,Aβ̂ k t 〉\n+ η 2 ∥∥Aβ̂kt ∥∥2\n= (1 − θt ) ζt−1 2\n( 1 − ϑθt\nζt\n)∥∥A ( ûkt − v̂kt−1 )∥∥2\n+ (1 − θt ) 〈 A ( α̂kt−1 − ûkt ) ,Aβ̂ k t 〉+ η 2 ∥∥Aβ̂kt ∥∥2.\nThis completes the proof.\nB.1 Proof of Lemma 2\nLemma 2 Consider applying Algorithm 1 to solve (3), the following inequality holds for any t ≥ 1,\ntD + Rt ≤ γt ( 0D + R0 ) , (11)\nwhere Rt = ζt2 ∑K k=1 ∥∥A ( α̂k − v̂kt )∥∥2, γt = ∏t i=1 ( 1 − θi ) for any t ≥ 1 and γ0 = 1.\nProof Following from the optimality condition of α̂kt , the following holds for any k ∈ [K ]\n0 ∈ Lk ( α̂kt ; ûkt ,w(ut ) )\n⇒ 0 ∈ −1 n ∂ f ∗k (− α̂kt )+ 1 n ( Âk ) ∇g∗ (Aut λn ) + 1 η ( Âk ) A ( α̂kt − ûkt )\n⇒ −1 n ( Âk ) ∇g∗ (Aut λn ) − 1 η ( Âk ) A ( α̂kt − ûkt ) ∈ −1 n ∂ f ∗k (− α̂kt ) . (28)\nBy using the fact f ∗ is μ-strongly convex, the following inequality holds for any z ∈ Rn\n1 n f ∗(−αt ) ≤ 1 n f ∗(−z) − 1 n 〈∂ f ∗(−αt ),αt − z〉 − μ 2n ‖z − αt‖2\n= 1 n f ∗(−z) − 1 n\nK∑\nk=1\n〈 ∂ f ∗k (− α̂kt ) , α̂kt − ẑk 〉− ϑ 2 ‖z − αt‖2.\nSubstituting (28) into the above inequality, we obtain\n1 n f ∗(−αt ) ≤ 1 n f ∗(−z) − 1 n\nK∑\nk=1\n〈( Âk ) ∇g∗ (Aut λn ) , ( α̂kt − ẑk )〉\n− 1 η\nK∑\nk=1\n〈( Âk ) A ( α̂kt − ûkt ) , ( α̂kt − ẑk )〉− ϑ 2 ‖z − αt‖2\n= 1 n f ∗(−z) − 1 n\nK∑\nk=1\n〈 ∇g∗ (Aut\nλn\n) ,A ( α̂kt − ẑk )〉− 1 η K∑\nk=1\n〈 A ( α̂kt − ûkt ) ,A ( α̂kt − ẑk )〉\n− ϑ 2 ‖z − αt‖2\n= 1 n f ∗(−z) − 1 n\n〈 ∇g∗ (Aut\nλn\n) ,A ( αt − z )〉− 1 η K∑\nk=1\n〈 A ( α̂kt − ûkt ) ,A ( α̂kt − ẑk )〉\n− ϑ 2 ‖z − αt‖2.\nBy using the fact that g∗ is 1/(1− ρ)-smooth and convex, the following inequality holds for any z ∈ Rn\nλg∗ (Aαt\nλn\n)\n≤ λg∗ (Aut\nλn\n) + λ 〈 ∇g∗ (Aut\nλn\n) , A(αt − ut )\nλn\n〉 + λ 2(1 − ρ) ∥∥∥ A(αt − ut ) λn ∥∥∥ 2\n≤ λg∗ (Az\nλn\n) − λ 〈 ∇g∗ (Aut\nλn\n) , A(z − ut )\nλn\n〉\n+ λ 〈 ∇g∗ (Aut\nλn\n) , A(αt − ut )\nλn\n〉 + λ 2(1 − ρ) ∥∥∥ A(αt − ut ) λn ∥∥∥ 2\n= λg∗ (Az\nλn\n) − 1\nn\n〈 ∇g∗ (Aut\nλn\n) ,A(z − αt ) 〉 + λ 2(1 − ρ) ∥∥∥ A(αt − ut ) λn ∥∥∥ 2\n≤ λg∗ (Az\nλn\n) − 1\nn\n〈 ∇g∗ (Aut\nλn\n) ,A(z − αt ) 〉 + λ 2(1 − ρ)λ2n2 K∑\nk=1\n∥∥A(̂αkt − ûkt ) ∥∥2\n= λg∗ (Az\nλn\n) − 1\nn\n〈 ∇g∗ (Aut\nλn\n) ,A(z − αt ) 〉 + 1\n2η\nK∑\nk=1\n∥∥A(̂αkt − ûkt ) ∥∥2,\nwhere the last inequality is obtained by using the fact thatA is a block diagonal matrix. Thus,\nD(αt ) = 1 n f ∗(−αt ) + λg∗ (Aαt λn )\n≤ 1 n f ∗(−z) − 1 n\n〈 ∇g∗ (Aut\nλn\n) ,A ( αt − z )〉− 1 η K∑\nk=1\n〈 A ( α̂kt − ûkt ) ,A ( α̂kt − ẑk )〉\n− ϑ 2\n‖z − αt‖2 + λg∗ (Az\nλn\n) − 1\nn\n〈 ∇g∗ (Aut\nλn\n) ,A(z − αt ) 〉\n+ 1 2η\nK∑\nk=1\n∥∥A(̂αkt − ûkt ) ∥∥2\n= D(z) − 1 η\nK∑\nk=1\n〈 A ( α̂kt − ûkt ) ,A ( α̂kt − ûkt + ûkt − ẑk )〉\n+ 1 2η\nK∑\nk=1\n∥∥A(̂αkt − ûkt ) ∥∥2 − ϑ\n2 ‖z − αt‖2\n= D(z) − 1 η\nK∑\nk=1\n〈 A ( α̂kt − ûkt ) ,A ( ûkt − ẑk )〉− 1 2η\nK∑\nk=1\n∥∥A(̂αkt − ûkt ) ∥∥2\n− ϑ 2 ‖z − αt‖2\n= D(z) − K∑\nk=1\n〈 Aβ̂ k t ,A ( ẑk − ûkt )〉− η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 − ϑ\n2 ‖z − αt‖2,\nwhich implies\nD(z) ≥ D(αt ) + K∑\nk=1\n〈 Aβ̂ k t ,A ( ẑk − ûkt )〉+ η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 + ϑ\n2 ‖z − αt‖2. (29)\nSubstituting z = α and z = αt−1 into (29), we obtain\nD(α ) ≥ D(αt ) + K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂k − ûkt )〉+ η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 + ϑ\n2 ‖α − αt‖2\nD(αt−1) ≥ D(αt ) + K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂kt−1 − ûkt )〉+ η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 + ϑ\n2 ‖αt−1 − αt‖2.\nCombining these two inequalities together with coefficients θt and (1− θt ), respectively, we obtain\nθt D(α ) + (1 − θt )D(αt−1)\n≥ D(αt ) + K∑\nk=1\n〈 Aβ̂ k t ,A ( θt α̂ k + (1 − θt )̂αkt−1 − ûkt )〉+ η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2\n+ ϑθt 2\n‖α − αt‖2 + ϑ(1 − θt )\n2 ‖αt−1 − αt‖2,\nwhich is equivalent to\nD(αt ) − D(α ) ≤(1 − θt ) ( D(αt−1) − D(α ) )− K∑\nk=1\n〈 Aβ̂ k t ,A ( θt α̂ k + (1 − θt )̂αkt−1 − ûkt )〉\n− η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 − ϑθt\n2 ‖α − αt‖2 − ϑ(1 − θt ) 2 ‖αt−1 − αt‖2\n= (1 − θt ) ( D(αt−1) − D(α ) )− (1 − θt ) K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂kt−1 − ûkt )〉\n− θt K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂k − ûkt )〉\n− η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2 − ϑθt\n2 ‖α − αt‖2 − ϑ(1 − θt ) 2 ‖αt−1 − αt‖2.\nSubstituting (26) into the above inequality, we obtain\nD(αt ) − D(α )\n≤ (1 − θt ) ( D(αt−1) − D(α ) )− (1 − θt ) K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂kt−1 − ûkt )〉\n− ϑθt 2\nK∑\nk=1\n∥∥A ( α̂k − ûkt )∥∥2\n− ζt 2\nK∑\nk=1\n(∥∥A ( α̂k − v̂kt )∥∥2 − ∥∥A(ûkt − v̂kt )∥∥2 )\n− η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2\n− ϑ(1 − θt ) 2 ‖αt−1 − αt‖2 + (1 − θt )ζt−1 2 K∑\nk=1\n(∥∥A ( α̂k − v̂kt−1 )∥∥2 − ∥∥A(ûkt − v̂kt−1 )∥∥2 )\n− ϑθt 2 ‖α − αt‖2,\nwhich is equivalent to\n( D(αt ) − D(α ) )+ ζt 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt )∥∥2\n≤ (1 − θt ) (\nD(αt−1) − D(α ) + ζt−1 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt−1 )∥∥2\n−ζt−1 2\nK∑\nk=1\n∥∥A ( ûkt − v̂kt−1\n)∥∥2 )\n+ ζt 2\nK∑\nk=1\n∥∥A ( ûkt − v̂kt )∥∥2 − (1 − θt ) K∑\nk=1\n〈 Aβ̂ k t ,A ( α̂kt−1 − ûkt )〉− η 2\nK∑\nk=1\n∥∥Aβ̂kt ∥∥2\n− ϑθt 2\nK∑\nk=1\n∥∥A ( α̂k − ûkt )∥∥2 − ϑθt 2 ‖α − αt‖2 − ϑ(1 − θt ) 2 ‖αt−1 − αt‖2.\nSubstituting (27) into the above inequality, we obtain\n( D(αt ) − D(α ) )+ ζt 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt )∥∥2\n≤ (1 − θt ) (\nD(αt−1) − D(α ) + ζt−1 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt−1 )∥∥2\n− ζt−1 2\nK∑\nk=1\n∥∥A ( ûkt − v̂kt−1 )∥∥2 )\n+ (1 − θt )ζt−1 2 ( 1 − ϑθt\nζt\n)∥∥A ( ûkt − v̂kt−1 )∥∥2\n− ϑθt 2\nK∑\nk=1\n∥∥A ( α̂k − ûkt )∥∥2 − ϑθt 2 ‖α − αt‖2\n− ϑ(1 − θt ) 2 ‖αt−1 − αt‖2\n= (1 − θt ) (\nD(αt−1) − D(α ) + ζt−1 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt−1 )∥∥2 )\n− (1 − θt )ζt−1 2 ϑθt\nζt\n∥∥A ( ûkt − v̂kt−1 )∥∥2\n− ϑθt 2\nK∑\nk=1\n∥∥A ( α̂k − ûkt )∥∥2 − ϑθt 2 ‖α − αt‖2 − ϑ(1 − θt ) 2 ‖αt−1 − αt‖2,\nwhich can be rewritten as\n( D(αt ) − D(α ) )+ ζt 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt )∥∥2\n≤ (1 − θt ) (\nD(αt−1) − D(α ) + ζt−1 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt−1 )∥∥2 )\n− (1 − θt )ζt−1 2 ϑθt\nζt\n∥∥A ( ûkt − v̂kt−1 )∥∥2\n− ϑθt 2\nK∑\nk=1\n∥∥A ( α̂k − ûkt )∥∥2 − ϑθt 2 ‖α − αt‖2 − ϑ(1 − θt ) 2 ‖αt−1 − αt‖2.\nThis implies\n( D(αt ) − D(α ) )+ K∑\nk=1\nζt 2 ∥∥A ( α̂k − v̂kt )∥∥2\n≤ (1 − θt ) (\nD(αt−1) − D(α ) + ζt−1 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt−1 )∥∥2 ) .\nApplying the above inequality for i = 1 to t , we obtain ( D(αt ) − D(α )\n)+ ζt 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt )∥∥2\n≤ t∏\ni=1 (1 − θi )\n( D(α0) − D(α ) + ζ0\n2\n∥∥A ( α̂k − v̂k0 )∥∥2 ) ,\nBy using the definition of γt , the above inequality can be rewritten as\n( D(αt ) − D(α ) )+ ζt 2\nK∑\nk=1\n∥∥A ( α̂k − v̂kt )∥∥2 ≤ γt ( D(α0) − D(α ) + ζ0\n2\n∥∥A ( α̂k − v̂k0 )∥∥2 ) .\nThis completes the proof.\nB.2 Convergence analysis for smooth losses\nB.2.1 Proof of Lemma 3\nLemma 3 Assume the loss functions fki ’s are (1/μ)-smooth for any k ∈[K ] and i ∈[nk]. If θ0= √ ϑη and (1 − ρ)λμn ≤1, then the following inequality holds for any t ≥ 1\ntD ≤ ( 1 −√(1 − ρ)λμn )t( 0D + R0 ) . (12)\nProof It can be proved by using Lemma 2. From Lemma 1, we know that fki are μ-strongly convex for any k ∈ [K ], i ∈ [nk] since fki is (1/μ)-smooth. If ζt−1 ≥ ϑ , then ζt = (1− θt )ζt−1 + ϑθt ≥ (1− θt )ϑ + θtϑ = ϑ . There we have ζt ≥ ϑ holds for any t ≥ 1 since ζ0 ≥ ϑ . Hence,\nθ2t /η = ζt ⇒ θt ≥ √ ηζt ⇒ θt ≥ √ ηϑ = √(1 − ρ)λμn. Then, γt can be bounded\nγt = t∏\ni=1 (1 − θi ) ≤\n( 1 −√(1 − ρ)λμn)t .\nSubstituting this result and v0 = α0 into (11), we obtain\nD(αt ) − D(α ) ≤ ( 1 −√(1 − ρ)λμn)t ( D(α0) − D(α ) + ζ0\n2\n∥∥A(α − α0) ∥∥2 ) .\nThis completes the proof.\nB.2.2 Proof of Theorem 1\nTheorem 1 Assume the loss functions fki ’s are (1/μ)-smooth for any k ∈ [K ] and i ∈ [nk]. If θ0= √ ϑη and (1 − ρ)λμn ≤1, then after T iterations in Algorithm 1 with\nT ≥ √\n1 (1 − ρ)λμn log (( 1 + σmax ) 0D D ) ,\nD ( αT )− D(α ) ≤ D holds. Furthermore, after T iterations with\nT ≥ √\n1 (1−ρ)λμn log (( 1 + σmax ) (1 − ρ)λμn + σmax (1 − ρ)λμn 0D\nG\n) ,\nit holds that P ( w(αT )) − (−D(αT )) ≤ G.\nProof It is easy to see that D(α) is ϑ-strongly convex since fki is (1/μ)-smooth for any k ∈ [K ], i ∈ [nk]. It implies\nD(α0) ≥ D(α ) + ϑ 2 ‖α0 − α ‖2 ⇒ ‖α0 − α ‖2 ≤ 2 ϑ ( D(α0) − D(α ) ) = 2 ϑ 0D .\nBy using this result, (12) can be rewrite as\ntD = D(αt ) − D(α ) ≤ ( 1 −√(1 − ρ)λμn)t ( D(α0) − D(α ) + ζ0\n2 ‖A(α − α0)‖2\n)\n≤ (1 −√(1 − ρ)λμn)t ( 0D + ζ0\n2 σmax‖α − α0‖2\n)\n≤ (1 −√(1 − ρ)λμn)t ( 0D + ζ0\n2 σmax\n2 ϑ 0D\n)\n= (1 −√(1 − ρ)λμn)t (1 + σmax) 0D ≤ exp(−t√(1 − ρ)λμn)(1 + σmax) 0D,\nwhere the last upper bound will be smaller than D if\nt ≥ √\n1 (1 − ρ)λμn log ( (1 + σmax) 0D\nD\n) .\nBy applying Lemma 6, we know that for any\nT ≥ √\n1 (1 − ρ)λμn log (1 + σmax) 0D\n( σmax (1−ρ)λn2 + ϑ )\nϑ G\n⇒ T ≥ √\n1 (1 − ρ)λμn log ( (1 + σmax) (1 − ρ)λμn + σmax (1 − ρ)λμn 0D\nG\n) ,\nit holds that D(αT ) − P ( w(αT )) ≤ G .\nB.3 Convergence analysis for Lipschitz continuous losses: Proof of Theorem 2\nTheorem 2 Assume the loss functions fki ’s are generally convex and L-Lipschitz continuous for any k ∈[K ], i ∈[nk]. If θ0=1, the following inequality holds for any t ≥1\ntD ≤ 1 (t + 2)2 ( 4 0D + 8L2σmax (1 − ρ)λn2 ) . (13)\nAfter T iterations in Algorithm 1 with\nT ≥ √\n8L2σmax (1 − ρ)λn2 D + 4 0 D D − 2, (14)\nit holds that D ( αT )− D(α ) ≤ D.\nProof It can be proved by using Lemma 2. It is easy to see that f ∗ki are general convex (i.e., μ = 0) since fki are L-Lipschitz continuous for any k ∈ [K ], i ∈ [nk]. By using the definition of ζt and the fact thatμ = 0, we obtain γt = (1−θt )γt−1 = ζt/ζt−1γt−1. Applying the above identity from i = 1 to t , we obtain γt = λ0ζt/ζ0 = ζt/ζ0. In addition, we can obtain θt = ( γt−1 − γt ) /γt−1 from γt = (1 − θt )γt−1. Therefore,\n1 γt − 1 γt−1 = 2γt−1 − 2\n√ γtγt−1\n2γt−1 √ γt ≥ 2γt−1 − (γt−1 + γt ) 2γt−1 √ γt\n= θt 2 √ γt = θt 2 √ ζt/ζ0 .\nBy using θ2t /η = ζt , we obtain 1/γt − 1/γt−1 ≥ 0.5 √ ηζ0 = 0.5 √\nζ0(1 − ρ)λn2. Combing the above inequality from i = 1 to i = t , we obtain\n1√ γt − 1√ γ0 ≥ t 2 √ ηζ0 ⇒ γt ≤ 4( t √ ηζ0 + 2 )2 = 4 ( t √ ζ0(1 − ρ)λn2 + 2 )2 .\nSubstituting this results into (11), we obtain\nD(αt ) − D(α ) ≤ 4\n( t √ ζ0(1 − ρ)λn2 + 2 )2\n( D(α0) − D(α ) + ζ0\n2\nK∑\nk=1\n∥∥A ( α̂k − v̂k0 )∥∥2 )\nSince θ0 = 1, we have ζ0 = θ20 /η = 1/((1 − ρ)λn2). Substituting the value of ζ0 into (13), we obtain\nD(αt ) − D(α ) ≤ 4\n( t √ ζ0(1 − ρ)λn2 + 2 )2\n(\nD(α0) − D(α ) + ζ0\n2\nK∑\nk=1\n∥∥A ( α̂k − α̂k0\n)∥∥2 )\n= 4 (t + 2)2\n( 0D +\n1 2(1 − ρ)λn2 ‖A(α − α0)‖ 2 )\n≤ 4 (t + 2)2\n( 0D +\n1 2(1 − ρ)λn2 σmax‖α − α0‖ 2 )\n≤ 1 (t + 2)2\n( 4 0D + 8L2σmax (1 − ρ)λn2 ) ,\nwhere the last upper bound will be smaller than D if\nT ≥ √\n8L2σmax (1 − ρ)λn2 D + 4 0D D − 2.\nThis completes the proof."
  }, {
    "heading": "Appendix C: More details of dynamic feature screening",
    "text": "C.1 Proof of Lemma 4\nLemma 4 Assume the loss functions fki’s are (1/μ)-smooth for any k ∈[K ], i ∈[nk]. For any dual feasible solution α, it holds that α ∈F def= { θ | ‖θ − α‖ ≤ √2G(α)n/μ}.\nProof Since fki are (1/μ)-smooth for any k ∈ [K ], i ∈ [nk], it implies that D(α) is (μ/n)strongly convex.\nD(α) a≥ D (α )+ 〈∂ D (α ) ,α − α 〉+ μ 2n ∥∥α − α ∥∥2\n⇒ −D(α) ≤ −D (α )− 〈∂ D (α ) ,α − α 〉− μ 2n ∥∥α − α ∥∥2 ⇒ −D(α) b≤ P(w(α)) − 〈∂ D (α ) ,α − α\n〉− μ 2n ∥∥α − α ∥∥2\n⇒ −D(α) c≤ P(w(α)) − μ 2n ∥∥α − α ∥∥2 ,\nwhere (a) follows from D(α) is (μ/n)-strongly convex , (b) is obtained by applying the weakly duality theorem, and (c) follows from the optimality of α . Therefore, we obtain\n∥∥α − α ∥∥ ≤ √2nG(α)/μ ⇒ α ∈ B(α, √ 2nG(α)/μ).\nThis completes the proof.\nBefore proving Lemma 5, we first introduce the following lemma.\nLemma 8 (Gay 1981) Let us consider the following minimization problem\nmin s∈Rn\n{ ψ(s) def= 1 2 〈s,Hs〉 + 〈g, s〉 } s.t. ‖Ds‖ ≤ δ, (30)\nwhere H ∈ Rn×n be a symmetric matrix, D ∈ Rn×n is an nonsingular matrix, and δ > 0. Then, s minimizes ψ(s) over the constraint set if and only if there exists a ϑ ≥ 0 such that\nH + ϑ D D 0 (31) ( H + ϑ D D ) s = −g (32)\n‖Ds ‖ = δ if ϑ > 0. (33) This ϑ is unique.\nNext, we prove Lemma 5 by using Lemma 8.\nLemma 5 If υ j =0, the maximum value of (19) is 0. Otherwise, the upper bound is K∑\nk=1\n〈 Xkj·,α k 〉2+ nG(α) μ ϑ − 1 2 〈g, s 〉 ,\nwhere ϑ and s are defined as follows: (a) ϑ =2υ j and s = s+̂s if 1) ∃ ŝ∈RK with ŝI j =0 and ‖ s+̂s‖=√2G(α)n/μ, and 2) 〈 Xt· j , θ t 〉 =0,∀t ∈I j . (b) Otherwise, ϑ >2υ j is solution of ‖ (H+ϑ I)−1 g‖=√2G(α)n/μ, and s =−(H+ϑ I)−1g. Proof Let z = θ − α, then (19) is equivalent to\nmax z\n∥∥AG j ·(z + α) ∥∥2 s.t. ‖z‖ ≤ √2G(α)n/μ,\nThe objective can be relaxed as following\n∥∥AG j ·(z + α) ∥∥2 =\nK∑\nk=1\n〈 Xkj ·, (z k + αk)〉2,\n= K∑\nk=1\n(〈 Xkj ·, z k 〉2 + 2〈Xkj ·, zk 〉〈 Xkj ·,α k 〉+ 〈Xkj ·,αk 〉2) ,\n≤ K∑\nk=1\n(∥∥Xkj · ∥∥2‖zk‖2 + 2∣∣〈Xkj ·,αk 〉∣∣∥∥Xkj · ∥∥‖zk‖ ) + K∑\nk=1\n〈 Xkj ·,α k 〉2.\nLet s ∈ RK with st = ‖zk‖, we then define ψ(s) as ψ(s) = 12 〈s,Hs〉 + 〈g, s〉. By using the relaxed objective function, (19) becomes\nmax ‖s‖≤√2G(α)n/μ\n−ψ(s) + K∑\nk=1\n〈 Xkj ·,α k 〉2 = − min ‖s‖≤√2G(α)n/μ ψ(s) + K∑\nk=1\n〈 Xkj ·,α k 〉2,\nwhere min‖s‖≤√2G(α)n/μ ψ(s) can be rewritten in the form of (30) by defining D = I and δ = √2G(α)n/μ. Then, Lemma 8 implies there exists a unique ϑ such that\nH + ϑ I 0 ⇒ ϑ ≥ max k∈[K ] 2\n∥∥Xkj · ∥∥2 ⇒ ϑ ≥ 2υ j ,\nwhich implies ϑ ≥> 0 since υ j > 0. Then, the problem can be considered as two cases ϑ = 2υ j and ϑ ≥ 2υ j . Given ϑ and s , ψ(s ) can be formulated by using (32) and (33)\nψ (s ) = 1 2 〈s ,Hs 〉 + 〈g, s 〉 = 1 2 〈s , (H + ϑ I) s 〉 + 〈g, s 〉 − ϑ 2 ‖s ‖2\n= − 1 2 〈s , g〉 + 〈g, s 〉 − ϑ 2 δ2 = 1 2 〈g, s 〉 − nG(α) μ ϑ ,\nwhich implies the upper bound of (19) is\nK∑\nk=1\n〈 Xkj ·,α k 〉2 − ψ (s ) = K∑\nk=1\n〈 Xkj ·,α k 〉2 + nG(α) μ ϑ − 1 2 〈g, s 〉 .\nNext, we show the values of s when ϑ = 2υ j and ϑ ≥ 2υ j , respectively.\nCase 1: ϑ = 2υ j . In this case, (32) and (33) imply (H + 2υ j I)s = −g and ‖s ‖ = δ that is equivalent to Therefore, if all above conditions hold then ϑ = 2υ j , otherwise we have ϑ that is discussed in the following. Case 2: ϑ > 2υ j . In this case, H + ϑ I is an invertible matrix. From (32) and (33), we obtain (H + ϑ ) s = −g and ‖s ‖ = δ, which implies s = − (H + ϑ I)−1 g and ∥∥(H+ ϑ I )−1g\n∥∥ = √2G(α)n/μ. This completes the proof.\nLemma 5 shows that there exists a global optimum ϑ , however, we need some algorithm to obtain the value for the case of ϑ > 2υ j . Note that ϑ ∈ (2υ j ,∞) is the unique solution of\nϕ(ϑ) = 1‖ (H + ϑI)−1 g‖ − √ μ 2G(α)n = 0.\nThe above equation can be efficiently solved by using Newton’s method. Besides Newton’s method, ϑ can also be efficiently solved by using bisection method."
  }, {
    "heading": "Appendix D: More details on single task learning",
    "text": "In this section, we providemore details on the extension of ourmethod to single task learning. Specifically, we consider the following 1-norm regularized learning problem [i.e., elastic net (Zou and Hastie 2005)]\nmin w∈Rp\n1\nn\nK∑\nk=1\nnk∑\ni=1 fki (〈xki ,w〉 )+ λ ( ρ‖w‖1 + 1 − ρ 2 ‖w‖2 ) . (34)\nThen, the local subproblem for each worker is\nLk ( α̂k;ut ) def= 1 n f ∗k (−α̂k)+ 1 n 〈 ∇g∗ (Aut λn ) ,A ( α̂k −̂ukt )〉\n+ σ ′\n2η\n∥∥A(̂αk −̂ukt ) ∥∥2 + λ K g∗ (Aut λn ) ,\nwhere η def= (1 − ρ)λn2 and a safe value for σ ′ is σ ′ = K (Ma et al. 2015). We compare the performance of our method with COCOA+ on two datasets (Table 2) with smoothed hinge loss (Shalev-Shwartz and Zhang 2013)\nfki (z k i ) =\n⎧ ⎪⎨\n⎪⎩\n0 if yki z k i ≥ 1 1 − yki zki − μ2 if yki zki ≤ 1 − μ 1 2μ ( 1 − yki zki )2 otherwise\nwhere μ is set to μ = 0.5.\nWe compare the performance of our method with COCOA+ on two datasets in Table 2 with smoothed hinge loss (Shalev-Shwartz and Zhang 2013). In our experiments, 8 workers are used (i.e., K = 8) and ρ = 0.9 for both datasets. The SDCA (Shalev-Shwartz and Zhang 2013) is used as local solver for both methods and H is set to H = 5 ×105. We evaluate two methods for λ = 10−2λmax and λ = 10−3λmax. Figure 4 shows the comparison in terms of the number iterations for communication used by our method and COCOA+ to obtain a solution meeting a prescribed duality gap. In addition, we also evaluate the effect of dynamic screening for further reduced communication cost. The setting is the same as that presented in Sect. 7.4. Figure 5 presents the total communication cost used by our method without and\nwith dynamic screening to solve (34) on RCV1 and URL. As observed, the proposed method performs as well as it works for MTL."
  }],
  "year": 2019,
  "references": [{
    "title": "Personalized and private peer-to-peer machine",
    "authors": ["A. ICDM. Bellet", "R. Guerraoui", "M. Taziki", "M. Tommasi"],
    "year": 2018
  }, {
    "title": "Learningbounds for domain adaptation",
    "authors": ["J. AISTATS. Blitzer", "K. Crammer", "A. Kulesza", "F. Pereira", "J. Wortman"],
    "year": 2007
  }, {
    "title": "algorithms for the lasso and group-lasso",
    "authors": ["O. Bousquet", "A. Elisseeff"],
    "venue": "IEEE Transactions on Signal Processing,",
    "year": 2002
  }, {
    "title": "Distributed optimization and statistical",
    "authors": ["S.P. 499–526. Boyd", "N. Parikh", "E. Chu", "B. Peleato", "J. Eckstein"],
    "year": 2011
  }, {
    "title": "Multitask learning",
    "authors": ["R. Caruana"],
    "venue": "Machine Learning,",
    "year": 1997
  }, {
    "title": "Mind the duality gap: Safer rules for the lasso",
    "authors": ["O. ICML (pp 783–792). Fercoq", "A. Gramfort", "J. Salmon"],
    "year": 2015
  }, {
    "title": "Computing optimal locally constrained steps",
    "authors": ["D. ICML. Gay"],
    "venue": "SIAM Journal on Scientific and Statistical",
    "year": 1981
  }, {
    "title": "Convex analysis and minimization algorithms II: Advanced",
    "authors": ["J.B. Hiriart-Urruty", "C. Lemaréchal"],
    "year": 1993
  }, {
    "title": "Communication efficient distributed machine learning",
    "authors": ["M. NIPS. Li", "D.G. Andersen", "A.J. Smola", "K. Yu"],
    "year": 2014
  }, {
    "title": "Distributed multi-task relationship learning",
    "authors": ["S. NIPS. Liu", "S.J. Pan", "Q. Ho"],
    "year": 2017
  }, {
    "title": "primal–dual optimization framework for structured machine learning",
    "authors": ["C. Ma", "V. Smith", "M. Jaggi", "M.I. Jordan", "P. Richtárik", "M. Takác"],
    "year": 2015
  }, {
    "title": "Gap safe screening rules for sparse multi-task and",
    "authors": ["E. ICML. Ndiaye", "O. Fercoq", "A. Gramfort", "J. Salmon"],
    "year": 2015
  }, {
    "title": "Gap safe screening rules for sparsity enforcing",
    "authors": ["E. NIPS. Ndiaye", "O. Fercoq", "A. Gramfort", "J. Salmon"],
    "year": 2017
  }, {
    "title": "Federated multi-task learning",
    "authors": ["C. Chiang", "M. Sanjabi", "A.S. Talwalkar"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Cocoa: A general framework",
    "authors": ["V. Smith", "S. Forte", "C. Ma", "M. Takáč", "M.I. Jordan", "M. Jaggi"],
    "year": 2017
  }, {
    "title": "Decentralized collaborative learning of personalized",
    "authors": ["P. 230:49. Vanhaesebrouck", "A. Bellet", "M. Tommasi"],
    "year": 2017
  }, {
    "title": "Distributed multi-task learning",
    "authors": ["J. AISTATS. Wang", "M. Kolar", "N. Srebro"],
    "year": 2016
  }, {
    "title": "Distributed stochastic multi-task learning with graph",
    "authors": ["W. ICML. Wang", "J. Wang", "M. Kolar", "N. Srebro"],
    "year": 2018
  }, {
    "title": "Privacy-preserving distributed multi-task learning",
    "authors": ["L. Xie", "I.M. Baytas", "K. Lin", "J. Zhou"],
    "year": 2017
  }, {
    "title": "Petuum: A new platform for distributed",
    "authors": ["E.P. SIGKDD. Xing", "Q. Ho", "W. Dai", "J.K. Kim", "J. Wei", "S Lee"],
    "year": 2015
  }, {
    "title": "Model selection and estimation in regression with grouped",
    "authors": ["A. Ekici", "Z. Lu", "R. Monteiro"],
    "venue": "IEEE Transactions on Big Data,",
    "year": 2006
  }, {
    "title": "A survey on multi-task learning",
    "authors": ["Q. Yang"],
    "venue": "mization. Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "A general distributed dual coordinate optimization",
    "authors": ["S. UAI. Zheng", "J. Wang", "F. Xia", "W. Xu", "T. Zhang"],
    "year": 2017
  }, {
    "title": "Regularization and variable selection via the elastic net",
    "authors": ["T. Hastie"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2005
  }],
  "id": "SP:e18d5f485493ba6f4720adb07a117fda4fb683a7",
  "authors": [{
    "name": "Qiang Zhou",
    "affiliations": []
  }, {
    "name": "Yu Chen",
    "affiliations": []
  }, {
    "name": "Sinno Jialin Pan",
    "affiliations": []
  }, {
    "name": "Jun Zhu",
    "affiliations": []
  }],
  "abstractText": "This work focuses on distributed optimization for multi-task learning with matrix sparsity regularization. We propose a fast communication-efficient distributed optimization method for solving the problem. With the proposed method, training data of different tasks can be geo-distributed over different local machines, and the tasks can be learned jointly through the matrix sparsity regularization without a need to centralize the data. We theoretically prove that our proposed method enjoys a fast convergence rate for different types of loss functions in the distributed environment. To further reduce the communication cost during the distributed optimization procedure, we propose a data screening approach to safely filter inactive features or variables. Finally, we conduct extensive experiments on both synthetic and real-world datasets to demonstrate the effectiveness of our proposed method.",
  "title": "Communication-efficient distributedmulti-task learning with matrix sparsity regularization"
}