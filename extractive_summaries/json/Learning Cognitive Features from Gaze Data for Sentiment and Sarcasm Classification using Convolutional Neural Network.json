{
  "sections": [{
    "text": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, pages 377–387 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-1035"
  }, {
    "heading": "1 Introduction",
    "text": "Detection of sentiment and sarcasm in usergenerated short reviews is of primary importance for social media analysis, recommendation and dialog systems. Traditional sentiment analyzers and\nsarcasm detectors face challenges that arise at lexical, syntactic, semantic and pragmatic levels (Liu and Zhang, 2012; Mishra et al., 2016c). Featurebased systems (Akkaya et al., 2009; Sharma and Bhattacharyya, 2013; Poria et al., 2014) can aptly handle lexical and syntactic challenges (e.g. learning that the word deadly conveys a strong positive sentiment in opinions such as Shane Warne is a deadly bowler, as opposed to The high altitude Himalayan roads have deadly turns). It is, however, extremely difficult to tackle subtleties at semantic and pragmatic levels. For example, the sentence I really love my job. I work 40 hours a week to be this poor. requires an NLP system to be able to understand that the opinion holder has not expressed a positive sentiment towards her / his job. In the absence of explicit clues in the text, it is difficult for automatic systems to arrive at a correct classification decision, as they often lack external knowledge about various aspects of the text being classified.\nMishra et al. (2016b) and Mishra et al. (2016c) show that NLP systems based on cognitive data (or simply, Cognitive NLP systems) , that leverage eye-movement information obtained from human readers, can tackle the semantic and pragmatic challenges better. The hypothesis here is that human gaze activities are related to the cognitive processes in the brain that combine the “external knowledge” that the reader possesses with textual clues that she / he perceives. While incorporating behavioral information obtained from gaze-data in NLP systems is intriguing and quite plausible, especially due to the availability of low cost eye-tracking machinery (Wood and Bulling, 2014; Yamamoto et al., 2013), few methods exist for text classification, and they rely on handcrafted features extracted from gaze data (Mishra et al., 2016b,c). These systems have limited capabilities due to two reasons: (a) Manually designed gaze based features may not adequately\n377\ncapture all forms of textual subtleties (b) Eyemovement data is not as intuitive to analyze as text which makes the task of designing manual features more difficult. So, in this work, instead of handcrafting the gaze based and textual features, we try to learn feature representations from both gaze and textual data using Convolutional Neural Network (CNN). We test our technique on two publicly available datasets enriched with eyemovement information, used for binary classification tasks of sentiment polarity and sarcasm detection. Our experiments show that the automatically extracted features often help to achieve significant classification performance improvement over (a) existing systems that rely on handcrafted gaze and textual features and (b) CNN based systems that rely on text input alone. The datasets used in our experiments, resources and other relevant pointers are available at http://www.cfilt.iitb.ac.in/ cognitive-nlp\nThe rest of the paper is organized as follows. Section 2 discusses the motivation behind using readers’ eye-movement data in a text classification setting. In Section 3, we argue why CNN is preferred over other available alternatives for feature extraction. The CNN architecture is proposed and discussed in Section 4. Section 5 describes our experimental setup and results are discussed in Section 6. We provide a detailed analysis of the results along with some insightful observations in Section 7. Section 8 points to relevant literature followed by Section 9 that concludes the paper.\nTerminology A fixation is a relatively long stay of gaze on a visual object (such as words in text) where as a sacccade corresponds to quick shifting of gaze between two positions of rest. Forward and backward saccades are called progressions and regressions respectively. A scanpath is a line graph that contains fixations as nodes and saccades as edges."
  }, {
    "heading": "2 Eye-movement and Linguistic Subtleties",
    "text": "Presence of linguistic subtleties often induces (a) surprisal (Kutas and Hillyard, 1980; Malsburg et al., 2015), due to the underlying disparity /context incongruity or (b) higher cognitive load (Rayner and Duffy, 1986), due to the presence of lexically and syntactically complex structures. While surprisal accounts for irregular saccades (Malsburg et al., 2015), higher cognitive\nload results in longer fixation duration (Kliegl et al., 2004).\nMishra et al. (2016b) find that presence of sarcasm in text triggers either irregular saccadic patterns or unusually high duration fixations than non-sarcastic texts (illustrated through example scanpath representations in Figure 1). For sentiment bearing texts, highly subtle eyemovement patterns are observed for semantically/pragmatically complex negative opinions (expressing irony, sarcasm, thwarted expectations, etc.) than the simple ones (Mishra et al., 2016b). The association between linguistic subtleties and eye-movement patterns could be captured through sophisticated feature engineering that considers both gaze and text inputs. In our work, CNN takes the onus of feature engineering."
  }, {
    "heading": "3 Why Convolutional Neural Network?",
    "text": "CNNs have been quite effective in learning filters for image processing tasks, filters being used to transform the input image into more informative feature space (Krizhevsky et al., 2012). Filters learned at various CNN layers are quite similar to handcrafted filters used for detection of edges, contours, and removal of redundant backgrounds. We believe, a similar technique can also be applied to eye-movement data, where the learned filters will, hopefully, extract informative cognitive features. For instance, for sarcasm, we expect the network to learn filters that detect long distance saccades (refer to Figure 2 for an analogical il-\nlustration). With more number of convolution filters of different dimensions, the network may extract multiple features related to different gaze attributes (such as fixations, progressions, regressions and skips) and will be free from any form of human bias that manually extracted features are susceptible to."
  }, {
    "heading": "4 Learning Feature Representations: The CNN Architecture",
    "text": "Figure 3 shows the CNN architecture with two components for processing and extracting features from text and gaze inputs. The components are explained below."
  }, {
    "heading": "4.1 Text Component",
    "text": "The text component is quite similar to the one proposed by Kim (2014) for sentence classification. Words (in the form of one-hot representation) in the input text are first replaced by their embeddings of dimension K (ith word in the sentence represented by an embedding vector xi ∈ RK). As per Kim (2014), a multi-channel variant of CNN (referred to as MULTICHANNELTEXT) can be implemented by using two channels of embeddingsone that remains static throughout training (referred to as STATICTEXT), and the other one that gets updated during training (referred to as NONSTATICTEXT). We separately experiment with static, non-static and multi-channel variants.\nFor each possible input channel of the text component, a given text is transformed into a tensor of fixed length N (padded with zero-tensors wherever\nnecessary to tackle length variations) by concatenating the word embeddings.\nx1:N = x1 ⊕ x2 ⊕ x3 ⊕ ...⊕ xN (1)\nwhere ⊕ is the concatenation operator. To extract local features1, convolution operation is applied. Convolution operation involves a filter, W ∈ RHK , which is convolved with a window of H embeddings to produce a local feature for the H words. A local feature, ci is generated from a window of embeddings xi:i+H−1 by applying a non linear function (such as a hyperbolic tangent) over the convoluted output. Mathematically,\nci = f(W.xi:i+H−1 + b) (2)\nwhere b ∈ R is the bias and f is the non-linear function. This operation is applied to each possible window of H words to produce a feature map (c) for the window size H .\nc = [c1, c2, c3, ..., cN−H+1] (3)\nA global feature is then obtained by applying max pooling operation2 (Collobert et al., 2011) over the feature map. The idea behind max-pooling is to capture the most important feature - one with the highest value - for each feature map.\nWe have described the process by which one feature is extracted from one filter (red bordered portions in Figure 3 illustrate the case of H = 2). The model uses multiple filters for each filter size to obtain multiple features representing the text. In the MULTICHANNELTEXT variant, for a window of H words, the convolution operation is separately applied on both the embedding channels. Local features learned from both the channels are concatenated before applying max-pooling."
  }, {
    "heading": "4.2 Gaze Component",
    "text": "The gaze component deals with scanpaths of multiple participants annotating the same text. Scanpaths can be pre-processed to extract two sequences3 of gaze data to form separate channels of input: (1) A sequence of normalized4 durations of fixations (in milliseconds) in the order in which\n1features specific to a region in case of images or window of words in case of text\n2mean pooling does not perform well. 3like text-input, gaze sequences are padded where necessary 4scaled across participants using min-max normalization to reduce subjectivity\nthey appear in the scanpath, and (2) A sequence of position of fixations (in terms of word id) in the order in which they appear in the scanpath. These channels are related to two fundamental gaze attributes such as fixation and saccade respectively. With two channels, we thus have three possible configurations of the gaze component such as (i) FIXATION, where the input is normalized fixation duration sequence, (ii) SACCADE, where the input is fixation position sequence, and (iii) MULTICHANNELGAZE, where both the inputs channels are considered.\nFor each possible input channel, the input is in the form of a P × G matrix (with P → number of participants and G → length of the input sequence). Each element of the matrix gij ∈ R, with i ∈ P and j ∈ G, corresponds to the jth gaze attribute (either fixation duration or word id, depending on the channel) of the input sequence of the ith participant. Now, unlike the text component, here we apply convolution operation across two dimensions i.e. choosing a two dimensional convolution filter W ∈ RJK (for simplicity, we have kept J = K, thus , making the dimension of W , J2). For the dimension size of J2, a local feature cij is computed from the window of gaze elements gij:(i+J−1)(j+J−1) by,\ncij = f(W.gij:(i+J−1)(j+J−1) + b) (4)\nwhere b ∈ R is the bias and f is a non-linear func-\ntion. This operation is applied to each possible window of size J2 to produce a feature map (c),\nc =[c11, c12, c13, ..., c1(G−J+1),\nc21, c22, c23, ..., c2(G−J+1), ...,\nc(P−J+1)1, c(P−J+1)2, ..., c(P−J+1)(G−J+1)]\n(5)\nA global feature is then obtained by applying max pooling operation. Unlike the text component, max-pooling operator is applied to a 2D window of local features size M × N (for simplicity, we set M = N , denoted henceforth as M2). For the window of size M2, the pooling operation on c will result in as set of global features ĉJ = max{cij:(i+M−1)(j+M−1)} for each possible i, j.\nWe have described the process by which one feature is extracted from one filter (of 2D window size J2 and the max-pooling window size of M2). In Figure 3, red and blue bordered portions illustrate the cases of J2 = [3, 3] and M2 = [2, 2] respectively. Like the text component, the gaze component also uses multiple filters for each filter size to obtain multiple features representing the gaze input. In the MULTICHANNELGAZE variant, for a 2D window of J2, the convolution operation is separately applied on both fixation duration and saccade channels and local features learned from both the channels are concatenated before maxpooling is applied.\nOnce the global features are learned from both the text and gaze components, they are merged\nand passed to a fully connected feed forward layer (with number of units set to 150) followed by a SoftMax layer that outputs the the probabilistic distribution over the class labels.\nThe gaze component of our network is not invariant of the order in which the scanpath data is given as input- i.e., the P rows in the P × G can not be shuffled, even if each row is independent from others. The only way we can think of for addressing this issue is by applying convolution operations to all P × G matrices formed with all the permutations of P , capturing every possible ordering. Unfortunately, this makes the training process significantly less scalable, as the number of model parameters to be learned becomes huge. As of now, training and testing are carried out by keeping the order of the input constant."
  }, {
    "heading": "5 Experiment Setup",
    "text": "We now share several details regarding our experiments below."
  }, {
    "heading": "5.1 Dataset",
    "text": "We conduct experiments for two binaryclassification tasks of sentiment and sarcasm using two publicly available datasets enriched with eye-movement information. Dataset 1 has been released by Mishra et al. (2016a). It contains 994 text snippets with 383 positive and 611 negative examples. Out of the 994 snippets, 350 are sarcastic. Dataset 2 has been used by Joshi et al. (2014) and it consists of 843 snippets comprising movie reviews and normalized tweets out of which 443 are positive, and 400 are negative. Eye-movement data of 7 and 5 readers is available for each snippet for dataset 1 and 2 respectively."
  }, {
    "heading": "5.2 CNN Variants",
    "text": "With text component alone we have three variants such as STATICTEXT, NONSTATICTEXT and MULTICHANNELTEXT (refer to Section 4.1). Similarly, with gaze component we have variants such as FIXATION, SACCADE and MULTICHANNELGAZE (refer to Section 4.2). With both text and gaze components, 9 more variants could thus beexperimented with."
  }, {
    "heading": "5.3 Hyper-parameters",
    "text": "For text component, we experiment with filter widths (H) of [3, 4]. For the gaze component, 2D filters (J2) set to [3× 3], [4× 4] respectively. The\nmax pooling 2D window, M2, is set to [2× 2]. In both gaze and text components, number of filters is set to 150, resulting in 150 feature maps for each window. These model hyper-parameters are fixed by trial and error and are possibly good enough to provide a first level insight into our system. Tuning of hyper-parameters might help in improving the performance of our framework, which is on our future research agenda."
  }, {
    "heading": "5.4 Regularization",
    "text": "For regularization dropout is employed both on the embedding and the penultimate layers with a constraint on l2-norms of the weight vectors (Hinton et al., 2012). Dropout prevents co-adaptation of hidden units by randomly dropping out - i.e., setting to zero - a proportion p of the hidden units during forward propagation. We set p to 0.25."
  }, {
    "heading": "5.5 Training",
    "text": "We use ADADELTA optimizer (Zeiler, 2012), with a learning rate of 0.1. The input batch size is set to 32 and number of training iterations (epochs) is set to 200. 10% of the training data is used for validation."
  }, {
    "heading": "5.6 Use of Pre-trained Embeddings:",
    "text": "Initializing the embedding layer with of pretrained embeddings can be more effective than random initialization (Kim, 2014). In our experiments, we have used embeddings learned using the movie reviews with one sentence per review dataset (Pang and Lee, 2005). It is worth noting that, for a small dataset like ours, using a small data-set like the one from (Pang and Lee, 2005) helps in reducing the number model parameters resulting in faster learning of embeddings. The results are also quite close to the ones obtained using word2vec facilitated by Mikolov et al. (2013)."
  }, {
    "heading": "5.7 Comparison with Existing Work",
    "text": "For sentiment analysis, we compare our systems’s accuracy (for both datasets 1 and 2) with Mishra et al. (2016c)’s systems that rely on handcrafted text and gaze features. For sarcasm detection, we compare Mishra et al. (2016b)’s sarcasm classifier with ours using dataset 1 (with available gold standard labels for sarcasm). We follow the same 10-fold train-test configuration as these existing works for consistency."
  }, {
    "heading": "6 Results",
    "text": "In this section, we discuss the results for different model variants for sentiment polarity and sarcasm detection tasks."
  }, {
    "heading": "6.1 Results for Sentiment Analysis Task",
    "text": "Table 1 presents results for sentiment analysis task. For dataset 1, different variants of our CNN architecture outperform the best systems reported by Mishra et al. (2016c), with a maximum F-score improvement of 3.8%. This improvement is statistically significant of p < 0.05 as confirmed by McNemar test. Moreover, we observe an F-score improvement of around 5% for CNNs with both gaze and text components as compared to CNNs with only text components (similar to the system by Kim (2014)), which is also statistically significant (with p < 0.05).\nFor dataset 2, CNN based approaches do not perform better than manual feature based approaches. However, variants with both text and gaze components outperform the ones with only text component (Kim, 2014), with a maximum Fscore improvement of 2.9%. We observe that for dataset 2, training accuracy reaches 100 within 25 epochs with validation accuracy stable around 50%, indicating the possibility of overfitting. Tuning the regularization parameters specific to dataset 2 may help here. Even though CNN might\nnot be proving to be a choice as good as handcrafted features for dataset 2, the bottom line remains that incorporation of gaze data into CNN consistently improves the performance over onlytext-based CNN variants."
  }, {
    "heading": "6.2 Results for Sarcasm Detection Task",
    "text": "For sarcasm detection, our CNN model variants outperform traditional systems by a maximum margin of 11.27% (Table 2). However, the improvement by adding the gaze component to the CNN network is just 1.34%, which is statistically insignificant over CNN with text component. While inspecting the sarcasm dataset, we observe a clear difference between the vocabulary of sarcasm and non-sarcasm classes in our dataset. This, perhaps, was captured well by the text component, especially the variant with only non-static embeddings."
  }, {
    "heading": "7 Discussion",
    "text": "In this section, some important observations from our experiments are discussed."
  }, {
    "heading": "7.1 Effect of Embedding Dimension Variation",
    "text": "Embedding dimension has proven to have a deep impact on the performance of neural systems (dos Santos and Gatti, 2014; Collobert et al., 2011).\nWe repeated our experiments by varying the embedding dimensions in the range of [50-300]5 and observed that reducing embedding dimension improves the F-scores by a little margin. Small embedding dimensions are probably reducing the chances of over-fitting when the data size is small. We also observe that for different embedding dimensions, performance of CNN with both gaze and text components is consistently better than that with only text component."
  }, {
    "heading": "7.2 Effect of Static / Non-static Text Channels",
    "text": "Non-static embedding channel has a major role in tuning embeddings for sentiment analysis by bringing adjectives expressing similar sentiment close to each other (e.g, good and nice), where as static channel seems to prevent over-tuning of embeddings (over-tuning often brings verbs like love closer to the pronoun I in embedding space, purely due to higher co-occurrence of these two words in sarcastic examples)."
  }, {
    "heading": "7.3 Effect of Fixation / Saccade Channels",
    "text": "For sentiment detection, saccade channel seems to be handing text having semantic incongruity (due\n5a standard range (Liu et al., 2015; Melamud et al., 2016)\nto the presence of irony / sarcasm) better. Fixation channel does not help much, may be because of higher variance in fixation duration. For sarcasm detection, fixation and saccade channels perform with similar accuracy when employed separately. Accuracy reduces with gaze multichannel, may be because of higher variation of both fixations and saccades across sarcastic and nonsarcastic classes, as opposed to sentiment classes."
  }, {
    "heading": "7.4 Effectiveness of the CNN-learned Features",
    "text": "To examine how good the features learned by the CNN are, we analyzed the features for a few example cases. Figure 4 presents some of the example test cases for the task of sarcasm detection. Example 1 contains sarcasm while examples 2, 3 and 4 are non-sarcastic. To see if there is any difference in the automatically learned features between text-only and combined text and gaze variants, we examine the feature vector (of dimension 150) for the examples obtained from different model variants. Output of the hidden layer after merge layer is considered as features learned by the network. We plot the features, in the form of color-bars, following Li et al. (2016) - denser col-\nors representing feature with higher magnitude. In Figure 4, we show only two representative model variants viz., MULTICHANNELTEXT and MULTICHANNELTEXT+ MULTICHANNELGAZE. As one can see, addition of gaze information helps to generate features with more subtle differences (marked by blue rectangular boxes) for sarcastic and non-sarcastic texts. It is also interesting to note that in the marked region, features for the sarcastic texts exhibit more intensity than the nonsarcastic ones - perhaps capturing the notion that sarcasm typically conveys an intensified negative opinion. This difference is not clear in feature vectors learned by text-only systems for instances like example 2, which has been incorrectly classified by MULTICHANNELTEXT. Example 4 is incorrectly classified by both the systems, perhaps due to lack of context. In cases like this, addition of gaze information does not help much in learning more distinctive features, as it becomes difficult for even humans to classify such texts."
  }, {
    "heading": "8 Related Work",
    "text": "Sentiment and sarcasm classification are two important problems in NLP and have been the focus of research for many communities for quite some time. Popular sentiment and sarcasm detection systems are feature based and are based on unigrams, bigrams etc. (Dave et al., 2003; Ng et al., 2006), syntactic properties (Martineau and Finin, 2009; Nakagawa et al., 2010), semantic properties (Balamurali et al., 2011). For sarcasm detection, supervised approaches rely on (a) Unigrams and Pragmatic features (González-Ibánez et al., 2011; Barbieri et al., 2014; Joshi et al., 2015) (b) Stylistic patterns (Davidov et al., 2010) and patterns related to situational disparity (Riloff et al., 2013) and (c) Hastag interpretations (Liebrecht et al., 2013; Maynard and Greenwood, 2014). Recent systems are based on variants of deep neural network built on the top of embeddings. A few representative works in this direction for sentiment analysis are based on CNNs (dos Santos and Gatti, 2014; Kim, 2014; Tang et al., 2014), RNNs (Dong et al., 2014; Liu et al., 2015) and combined archi-\ntecture (Wang et al., 2016). Few works exist on using deep neural networks for sarcasm detection, one of which is by (Ghosh and Veale, 2016) that uses a combination of RNNs and CNNs.\nEye-tracking technology is a relatively new NLP, with very few systems directly making use of gaze data in prediction frameworks. Klerke et al. (2016) present a novel multi-task learning approach for sentence compression using labeled data, while, Barrett and Søgaard (2015) discriminate between grammatical functions using gaze features. The closest works to ours are by Mishra et al. (2016b) and Mishra et al. (2016c) that introduce feature engineering based on both gaze and text data for sentiment and sarcasm detection tasks. These recent advancements motivate us to explore the cognitive NLP paradigm."
  }, {
    "heading": "9 Conclusion and Future Directions",
    "text": "In this work, we proposed a multimodal ensemble of features, automatically learned using variants of CNNs from text and readers’ eye-movement data, for the tasks of sentiment and sarcasm classification. On multiple published datasets for which gaze information is available, our systems could often achieve significant performance improvements over (a) systems that rely on handcrafted gaze and textual features and (b) CNN based systems that rely on text input alone. An analysis of the learned features confirms that the combination of automatically learned features is indeed capable of representing deep linguistic subtleties in text that pose challenges to sentiment and sarcasm classifiers. Our future agenda includes: (a) optimizing the CNN framework hyper-parameters (e.g., filter width, dropout, embedding dimensions, etc.) to obtain better results, (b) exploring the applicability of our technique for documentlevel sentiment analysis and (c) applying our framework to related problems, such as emotion analysis, text summarization, and questionanswering, where considering textual clues alone may not prove to be sufficient."
  }, {
    "heading": "Acknowledgments",
    "text": "We thank Anoop Kunchukuttan, Joe Cheri Ross, and Sachin Pawar, research scholars of the Center for Indian Language Technology (CFILT), IIT Bombay for their valuable inputs."
  }],
  "year": 2017,
  "references": [{
    "title": "Subjectivity word sense disambiguation",
    "authors": ["Cem Akkaya", "Janyce Wiebe", "Rada Mihalcea."],
    "venue": "Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1Volume 1. ACL, pages 190–199.",
    "year": 2009
  }, {
    "title": "Harnessing wordnet senses for supervised sentiment classification",
    "authors": ["AR Balamurali", "Aditya Joshi", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing. pages 1081–1091.",
    "year": 2011
  }, {
    "title": "Modelling sarcasm in twitter, a novel approach",
    "authors": ["Francesco Barbieri", "Horacio Saggion", "Francesco Ronzano."],
    "venue": "ACL 2014 page 50.",
    "year": 2014
  }, {
    "title": "Using reading behavior to predict grammatical functions",
    "authors": ["Maria Barrett", "Anders Søgaard."],
    "venue": "Proceedings of the Sixth Workshop on Cognitive Aspects of Computational Language Learning. Association for Computational Linguistics, Lisbon, Por-",
    "year": 2015
  }, {
    "title": "Natural language processing (almost) from scratch",
    "authors": ["Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."],
    "venue": "Journal of Machine Learning Research 12(Aug):2493–2537.",
    "year": 2011
  }, {
    "title": "Mining the peanut gallery: Opinion extraction and semantic classification of product reviews",
    "authors": ["Kushal Dave", "Steve Lawrence", "David M Pennock."],
    "venue": "Proceedings of the 12th international conference on World Wide Web. ACM, pages 519–528.",
    "year": 2003
  }, {
    "title": "Semi-supervised recognition of sarcastic sentences in twitter and amazon",
    "authors": ["Dmitry Davidov", "Oren Tsur", "Ari Rappoport."],
    "venue": "Proceedings of the Fourteenth Conference on Computational Natural Language Learning. Association for Computational",
    "year": 2010
  }, {
    "title": "Adaptive recursive neural network for target-dependent twitter sentiment classification",
    "authors": ["Li Dong", "Furu Wei", "Chuanqi Tan", "Duyu Tang", "Ming Zhou", "Ke Xu."],
    "venue": "ACL (2). pages 49–54.",
    "year": 2014
  }, {
    "title": "Deep convolutional neural networks for sentiment analysis of short texts",
    "authors": ["Cı́cero Nogueira dos Santos", "Maira Gatti"],
    "venue": "In Proceedings of COLING",
    "year": 2014
  }, {
    "title": "Fracking sarcasm using neural network",
    "authors": ["Aniruddha Ghosh", "Tony Veale."],
    "venue": "Proceedings of NAACL-HLT . pages 161–169.",
    "year": 2016
  }, {
    "title": "Identifying sarcasm in twitter: a closer look",
    "authors": ["Roberto González-Ibánez", "Smaranda Muresan", "Nina Wacholder."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies:",
    "year": 2011
  }, {
    "title": "Improving neural networks by preventing coadaptation of feature detectors",
    "authors": ["Geoffrey E Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan R Salakhutdinov."],
    "venue": "arXiv preprint arXiv:1207.0580 .",
    "year": 2012
  }, {
    "title": "Measuring sentiment annotation complexity of text",
    "authors": ["Aditya Joshi", "Abhijit Mishra", "Nivvedan Senthamilselvan", "Pushpak Bhattacharyya."],
    "venue": "ACL (Daniel Marcu 22 June 2014 to 27 June 2014). ACL.",
    "year": 2014
  }, {
    "title": "Harnessing context incongruity for sarcasm detection",
    "authors": ["Aditya Joshi", "Vinita Sharma", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of 53rd Annual Meeting of the Association for Computational Linguistics, Beijing, China page 757.",
    "year": 2015
  }, {
    "title": "Convolutional neural networks for sentence classification",
    "authors": ["Yoon Kim."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics, Doha, Qatar, pages 1746–",
    "year": 2014
  }, {
    "title": "Improving sentence compression by learning to predict gaze",
    "authors": ["Sigrid Klerke", "Yoav Goldberg", "Anders Søgaard."],
    "venue": "arXiv preprint arXiv:1604.03357 .",
    "year": 2016
  }, {
    "title": "Length, frequency, and predictability effects of words on eye movements in reading",
    "authors": ["Reinhold Kliegl", "Ellen Grabner", "Martin Rolfs", "Ralf Engbert."],
    "venue": "European Journal of Cognitive Psychology 16(12):262–284.",
    "year": 2004
  }, {
    "title": "Imagenet classification with deep convolutional neural networks",
    "authors": ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey E Hinton."],
    "venue": "Advances in neural information processing systems. pages 1097–1105.",
    "year": 2012
  }, {
    "title": "Reading senseless sentences: Brain potentials reflect semantic incongruity",
    "authors": ["Marta Kutas", "Steven A Hillyard."],
    "venue": "Science 207(4427):203–205.",
    "year": 1980
  }, {
    "title": "Visualizing and understanding neural models in nlp",
    "authors": ["Jiwei Li", "Xinlei Chen", "Eduard Hovy", "Dan Jurafsky."],
    "venue": "Proceedings of NAACL-HLT . pages 681– 691.",
    "year": 2016
  }, {
    "title": "The perfect solution for detecting sarcasm in tweets# not",
    "authors": ["Christine Liebrecht", "Florian Kunneman", "Antal van den Bosch."],
    "venue": "WASSA 2013 page 29.",
    "year": 2013
  }, {
    "title": "A survey of opinion mining and sentiment analysis",
    "authors": ["Bing Liu", "Lei Zhang."],
    "venue": "Mining text data, Springer, pages 415–463.",
    "year": 2012
  }, {
    "title": "Fine-grained opinion mining with recurrent neural networks and word embeddings",
    "authors": ["Pengfei Liu", "Shafiq R Joty", "Helen M Meng."],
    "venue": "EMNLP. pages 1433–1443.",
    "year": 2015
  }, {
    "title": "Determinants of scanpath regularity in reading",
    "authors": ["Titus Malsburg", "Reinhold Kliegl", "Shravan Vasishth."],
    "venue": "Cognitive science 39(7):1675–1703.",
    "year": 2015
  }, {
    "title": "Delta tfidf: An improved feature space for sentiment analysis",
    "authors": ["Justin Martineau", "Tim Finin."],
    "venue": "ICWSM 9:106.",
    "year": 2009
  }, {
    "title": "Who cares about sarcastic tweets? investigating the impact of sarcasm on sentiment analysis",
    "authors": ["Diana Maynard", "Mark A Greenwood."],
    "venue": "Proceedings of LREC.",
    "year": 2014
  }, {
    "title": "The role of context types and dimensionality in learning word embeddings",
    "authors": ["Oren Melamud", "David McClosky", "Siddharth Patwardhan", "Mohit Bansal."],
    "venue": "NAACL HLT 2016. pages 1030–1040.",
    "year": 2016
  }, {
    "title": "Linguistic regularities in continuous space word representations",
    "authors": ["Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig."],
    "venue": "HLT-NAACL. volume 13, pages 746–751.",
    "year": 2013
  }, {
    "title": "Predicting readers’ sarcasm understandability by modeling gaze behavior",
    "authors": ["Abhijit Mishra", "Diptesh Kanojia", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of AAAI.",
    "year": 2016
  }, {
    "title": "Harnessing cognitive features for sarcasm detection",
    "authors": ["Abhijit Mishra", "Diptesh Kanojia", "Seema Nagar", "Kuntal Dey", "Pushpak Bhattacharyya."],
    "venue": "ACL 2016 page 156.",
    "year": 2016
  }, {
    "title": "Leveraging cognitive features for sentiment analysis",
    "authors": ["Abhijit Mishra", "Diptesh Kanojia", "Seema Nagar", "Kuntal Dey", "Pushpak Bhattacharyya."],
    "venue": "CoNLL 2016 page 156.",
    "year": 2016
  }, {
    "title": "Dependency tree-based sentiment classification using crfs with hidden variables",
    "authors": ["Tetsuji Nakagawa", "Kentaro Inui", "Sadao Kurohashi."],
    "venue": "NAACLHLT . Association for Computational Linguistics, pages 786–794.",
    "year": 2010
  }, {
    "title": "Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews",
    "authors": ["Vincent Ng", "Sajib Dasgupta", "SM Arifin."],
    "venue": "Proceedings of the COLING/ACL on Main conference poster sessions. Association for Compu-",
    "year": 2006
  }, {
    "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
    "authors": ["Bo Pang", "Lillian Lee."],
    "venue": "Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics. Association for Computational",
    "year": 2005
  }, {
    "title": "Sentic patterns: Dependency-based rules for concept-level sentiment analysis",
    "authors": ["Soujanya Poria", "Erik Cambria", "Gregoire Winterstein", "Guang-Bin Huang."],
    "venue": "Knowledge-Based Systems 69:45–63.",
    "year": 2014
  }, {
    "title": "Lexical complexity and fixation times in reading: Effects of word frequency, verb complexity, and lexical ambiguity",
    "authors": ["Keith Rayner", "Susan A Duffy."],
    "venue": "Memory & Cognition 14(3):191–201. 386",
    "year": 1986
  }, {
    "title": "Sarcasm as contrast between a positive sentiment and negative situation",
    "authors": ["Ellen Riloff", "Ashequl Qadir", "Prafulla Surve", "Lalindra De Silva", "Nathan Gilbert", "Ruihong Huang."],
    "venue": "Proceedings of Empirical Methods in Natural Language Processing.",
    "year": 2013
  }, {
    "title": "Detecting domain dedicated polar words",
    "authors": ["Raksha Sharma", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of the International Joint Conference on Natural Language Processing.",
    "year": 2013
  }, {
    "title": "Deepface: Closing the gap to human-level performance in face verification",
    "authors": ["Yaniv Taigman", "Ming Yang", "Marc’Aurelio Ranzato", "Lior Wolf"],
    "venue": "In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",
    "year": 2014
  }, {
    "title": "Coooolll: A deep learning system for twitter sentiment classification",
    "authors": ["Duyu Tang", "Furu Wei", "Bing Qin", "Ting Liu", "Ming Zhou."],
    "venue": "Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014). pages 208–212.",
    "year": 2014
  }, {
    "title": "Dimensional sentiment analysis using a regional cnn-lstm model",
    "authors": ["Jin Wang", "Liang-Chih Yu", "K. Robert Lai", "Xuejie Zhang."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). Asso-",
    "year": 2016
  }, {
    "title": "Eyetab: Model-based gaze estimation on unmodified tablet computers",
    "authors": ["Erroll Wood", "Andreas Bulling."],
    "venue": "Proceedings of the Symposium on Eye Tracking Research and Applications. ACM, pages 207–210.",
    "year": 2014
  }, {
    "title": "Development of a mobile tablet pc with gaze-tracking function",
    "authors": ["Michiya Yamamoto", "Hironobu Nakagawa", "Koichi Egawa", "Takashi Nagamatsu."],
    "venue": "Human Interface and the Management of Information. Information and Interaction for",
    "year": 2013
  }, {
    "title": "Adadelta: an adaptive learning rate method",
    "authors": ["Matthew D Zeiler."],
    "venue": "arXiv preprint arXiv:1212.5701 . 387",
    "year": 2012
  }],
  "id": "SP:a38bb9badba14cc12c597dd77fdd63767614cbc4",
  "authors": [{
    "name": "Abhijit Mishra",
    "affiliations": []
  }, {
    "name": "Kuntal Dey",
    "affiliations": []
  }, {
    "name": "Pushpak Bhattacharyya",
    "affiliations": []
  }],
  "abstractText": "Cognitive NLP systemsi.e., NLP systems that make use of behavioral data augment traditional text-based features with cognitive features extracted from eye-movement patterns, EEG signals, brain-imaging etc.. Such extraction of features is typically manual. We contend that manual extraction of features may not be the best way to tackle text subtleties that characteristically prevail in complex classification tasks like sentiment analysis and sarcasm detection, and that even the extraction and choice of features should be delegated to the learning system. We introduce a framework to automatically extract cognitive features from the eye-movement / gaze data of human readers reading the text and use them as features along with textual features for the tasks of sentiment polarity and sarcasm detection. Our proposed framework is based on Convolutional Neural Network (CNN). The CNN learns features from both gaze and text and uses them to classify the input text. We test our technique on published sentiment and sarcasm labeled datasets, enriched with gaze information, to show that using a combination of automatically learned text and gaze features often yields better classification performance over (i) CNN based systems that rely on text input alone and (ii) existing systems that rely on handcrafted gaze and textual features.",
  "title": "Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network"
}