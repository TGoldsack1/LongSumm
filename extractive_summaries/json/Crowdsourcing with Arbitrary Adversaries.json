{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Crowdsourcing is an omnipresent phenomenon: it has emerged as an integral part of the machine learning pipeline in recent years, and one reason for the great advances in deep learning is the presence of large data sets that have been labeled by the crowd (e.g., Deng et al., 2009; Krizhevsky, 2009). Crowdsourcing is also at the heart of peer grading systems (e.g., Alfaro & Shavlovsky, 2014), which help with rising enrollment at universities, and online rating systems (e.g., Liao et al., 2014), which many of us rely on when choosing the next restaurant, to provide just a few examples.\nA crowdsourcing scenario consists of a set of workers and a set of tasks that need to be solved. A data curator utilizing crowdsourcing can aim at estimating various quantities of interest. The first goal might be to estimate the true labels or answers for the tasks at hand. Typically, additional constraints are involved here such as a worker not being willing\n1Department of Computer Science, Rutgers University, Piscataway Township, New Jersey, USA. Correspondence to: Matthäus Kleindessner <matthaeus.kleindessner@rutgers.edu>, Pranjal Awasthi <pranjal.awasthi@rutgers.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nto solve too many tasks and the data curator wanting to get high-quality labels at a low price. The canonical example of this case is the Amazon Mechanical TurkTM. There one cannot track specific workers as they are fleeting. However, in scenarios such as peer grading or online rating systems, a second goal might be to estimate worker qualities, especially if workers can be reused at a later time.\nIn a seminal paper, Dawid & Skene (1979) proposed a formal model that involves worker quality parameters for crowdsourcing scenarios in the context of classification. The Dawid-Skene model has become a standard theoretical framework and has led to a flurry of research over the past few years (Liu et al., 2012; Raykar & Yu, 2012; Li et al., 2013; Gao et al., 2016; Zhang et al., 2016; Khetan et al., 2017), in particular in its special symmetric form usually referred to as one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; Dalvi et al., 2013; Gao & Zhou, 2013; Karger et al., 2014; Bonald & Combes, 2017; Ma et al., 2017). In its general form for binary classification problems, the DawidSkene model assumes that for each worker, the probability of providing the wrong label only depends on the true label of the task, but not on the task itself. Moreover, given the true label, the responses provided by different workers are independent. The one-coin model additionally assumes that for each worker, the probability of providing the wrong label is the same for both classes. We will formally introduce the one-coin model in Section 2. A discussion of prior work work is provided in Section 5 and Appendix A.\nThe crucial limitation of the Dawid-Skene and one-coin model is the assumption that workers’ error probabilities are task-independent. In particular, this excludes the possibility of colluding adversaries (other than those that provide the wrong label all of the time), which might make these models a poor approximation of the real world encountered in such applications as peer grading or online rating. In this paper, we study a significant extension of the one-coin model that allows for arbitrary, highly colluding adversaries. We provide an algorithm for estimating the workers’ error probabilities and prove that it asymptotically recovers the true error probabilities. Using our estimates of the error probabilities in weighted majority votes, we also provide strategies to estimate ground-truth labels of the tasks. Experiments on both synthetic and real data show that our approach clearly outperforms existing methods in the presence of adversaries."
  }, {
    "heading": "2. Setup and problem formulation",
    "text": "We first describe a general model for crowdsourcing with non-adaptive workers and binary classification tasks: there are n workers w1, . . . , wn and an i.i.d. sample of m tasklabel pairs ((xi, yi))mi=1 ∼ Dm, where D is a joint probability distribution over tasks x ∈ X and corresponding labels y ∈ {−1,+1}. There is a variable gij ∈ {0, 1}, i ∈ [m], j ∈ [n], indicating whether worker wj is presented with task xi (for k ∈ N, we use [k] to denote the set {1, . . . , k}). If wj is presented with xi, that is gij = 1, wj provides an estimate wj(xi) ∈ {−1,+1} of the ground-truth label yi. Let A ∈ {−1, 0,+1}m×n be a matrix that stores all the responses collected from the workers: Aij = wj(xi) if gij = 1 and Aij = 0 if gij = 0.\nWe assume that each worker wj follows some (probabilistic or deterministic) strategy such that wj(xi) only depends on xi. In particular, given xi, any two different workers’ responses wj(xi) and wk(xi) and the ground-truth label yi are independent. Let εwj (x, y) ∈ [0, 1] be the conditional error probability that, given x and y, wj(x) does not equal y, that is\nεwj (x, y) := Prwj |(x,y)[wj(x) 6= y | (x, y)]. (1)\nNote that the unconditional probability of wj(x) being incorrect, before seeing x and y, is given by\nPr(x,y)∼D,wj [wj(x) 6= y] = E(x,y)∼D[εwj (x, y)] =: εwj .\nNow one may study the following questions:\n(i) Given only the matrix A, how can we estimate the ground-truth labels y1, . . . , ym?\n(ii) Given only the matrix A, how can we estimate the workers’ unconditional error probabilities εw1 , . . . , εwn?\n(iii) If we can choose gij (either in advance of collecting workers’ responses or adaptively while doing so), how should we choose it such that we can achieve (i) or (ii) with a minimum number of collected responses?\nIn case of εwj (x, y) as defined in (1) being constant on X × {−1,+1}, that is εwj (x, y) ≡ εwj , for all j ∈ [n], our model boils down to what is usually referred to as the one-coin model (e.g., Szepesvari, 2015), for which (i) to (iii) have been studied extensively (see Section 5 and Appendix A for references and a detailed discussion). With this paper we initiate the study of a significant extension of the one-coin model. We will allow almost half of the workers to deviate from the one-coin model and for such a worker wj , the conditional error probability εwj (x, y) to be a completely arbitrary random variable. In other words, we will allow for arbitrary adversaries, for which not only error\nprobabilities can be high, but for which error probabilities can be arbitrarily correlated. We mainly study (ii) in this scenario. We then make use of existing results for the onecoin model to answer (i) satisfactorily for our purposes. We do not deal with (iii), but instead assume that gij has been specified in advance."
  }, {
    "heading": "3. General outline of our approach",
    "text": "In this section we want to present the general outline of our approach. A key insight is that the unconditional probability of workers wj and wk being agreeing is given by\nPr(x,y)∼D,wj ,wk [wj(x) = wk(x)] = 1− εwj − εwk+ 2εwjεwk + 2 Cov(x,y)∼D[εwj (x, y), εwk(x, y)].\n(2)\nCov(x,y)∼D[εwj (x, y), εwk(x, y)] denotes the covariance between random variables εwj (x, y) and εwk(x, y), that is\nCov(x,y)∼D[εwj (x, y), εwk(x, y)] = E(x,y)∼D[(εwj (x, y)− εwj ) · (εwk(x, y)− εwk)].\nA proof of (2) can be found in Appendix B. The probability on the left-hand side of (2) can be easily estimated from A by the ratio of the number of tasks that wj and wk agreed on to the number of tasks they were both presented with:\nPr[wj(x) = wk(x)] ≈ ∑m i=1 gijgik1{Aij = Aik}∑m\ni=1 gijgik =: pjk.\n(3)\nThis suggests to solve the system of equations\n1− εj − εk + 2εjεk + 2cjk = pjk, 1 ≤ j < k ≤ n, (4)\nin the unknowns εl, l ∈ [n], and cjk, 1 ≤ j < k ≤ n, in order to obtain estimates of the workers’ unconditional error probabilities εw1 , . . . , εwn . However, there is a catch: in general, the system (4) is not identifiable and has several solutions. We will assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities smaller than one half. A worker wj following the one-coin model implies\nCov(x,y)∼D[εwj (x, y), εwk(x, y)] = 0, ∀k 6= j, (5)\nand hence under this assumption we can restrict the search for solutions of (4) to εl, l ∈ [n], and cjk, 1 ≤ j < k ≤ n, with the property that1\n∃L ⊆ [n] with |L| ≥ n/2 + 2 such that ∀j ∈ L : (εj < 1/2 ∧ [∀k 6= j : cjk = 0]) . (6)\n1Throughout the paper, we set cjk = ckj if j > k. We also assume pjk = pkj .\nNote that we never assume to know which workers follow the one-coin model, which corresponds to using the existential quantifier for the set L in (6) rather than considering a “fixed” L. We can show that the system (4) has at most one solution with property (6). We also provide evidence that our assumption of n2 + 2 of the workers following the one-coin model and having error probabilities smaller than one half is a necessary condition for guaranteeing the identifiability of system (4). If the workers satisfy our assumption and pjk on the right-hand side of (4) are actually true agreement probabilities, then εl = εwl and cjk = Cov[εwj (x, y), εwk(x, y)] is the unique solution of (4) that satisfies (6). But if pjk are not exactly true agreement probabilities, there might be no solution of (4) with property (6) at all. We prove that if estimates pjk are not too bad, we can solve (4) together with (6) approximately, and our approximate solution is guaranteed to be close to true error probabilities εw1 , . . . , εwn and covariances Cov[εwj (x, y), εwk(x, y)], j < k. This answers (ii) from Section 2 and is the main contribution of our paper: Main result. Assume that at least n2 + 2 of the workers follow the one-coin model and have error probabilities not greater than γTR < 12 . If |Pr[wj(x) = wk(x)] − pjk| ≤ β for all j 6= k and β sufficiently small, we can compute estimates ε̂w1 , . . . , ε̂wn of εw1 , . . . , εwn such that\n|εwi − ε̂wi | ≤ C(γTR) · β1/4.\nWe answer (i) from Section 2 and provide two ways to predict ground-truth labels y1, . . . , ym by taking weighted majority votes over the responses provided by the workers. In these majority votes, the weights depend on our estimates of true error probabilities εw1 , . . . , εwn ."
  }, {
    "heading": "4. Details and analysis",
    "text": ""
  }, {
    "heading": "4.1. Estimating agreement probabilities",
    "text": "If gij has been specified in advance, we have the following guarantee on the quality of the estimates pjk (see (3)): Lemma 1. Assume ∑m i=1 gijgik > 0, j 6= k. Let δ > 0 and\nβjk = min\n{ 1, [ ln(2n2/δ)/ ( 2 ∑m\ni=1 gijgik\n)]1/2} .\nThen we have with probability at least 1− δ over the sample ((xi, yi)) m i=1 and the randomness in workers’ strategies that\n|Pr[wj(x) = wk(x)]− pjk| ≤ βjk, 1 ≤ j < k ≤ n.\nProof. A straightforward application of Hoeffding’s inequality and the union bound yields the result."
  }, {
    "heading": "4.2. Identifiability and approximate solution",
    "text": "If all workers follow the one-coin model, that is εwj (x, y) ≡ εwj for all j ∈ [n], we have\nCov(x,y)∼D[εwj (x, y), εwk(x, y)] = 0, 1 ≤ j < k ≤ n, and system (4) reduces to\n1− εj − εk + 2εjεk = pjk, 1 ≤ j < k ≤ n, (7)\nin the unknowns εl, l ∈ [n]. It is well known that, in general, even (7) is not identifiable. For example, if pjk = 1 for all 1 ≤ j < k ≤ n, there are the two solutions εl = 0, l ∈ [n], and εl = 1, l ∈ [n], corresponding to either all perfect or all completely erroneous workers. On the other hand, the system (7) is identifiable if we assume that on average workers are better than random guessing, that is 1 n ∑n j=1 εwj < 1 2 , and there are at least three informative workers with εwj 6= 12 (Bonald & Combes, 2017).\nClearly, these two conditions do not guarantee identifiability of the general system (4). The next lemma shows that even if we additionally assume half of the workers to follow the one-coin model, the system (4) is not identifiable. Here we only state an informal version of the lemma. A detailed version and its proof can be found in Appendix B.\nLemma 2. There exists an instance of the system (4), where n is even, that has two different solutions. In both solutions, it holds that εl < 12 , l ∈ [n]. Furthermore:\n(a) In the first solution, cjk = 0 for all j ∈ [n2 ] and k 6= j, and εl is small if l ∈ [n2 ] and big if l ∈ [n] \\ [ n 2 ]. (b) In the second solution, cjk = 0 for all j ∈ [n]\\ [n2 ] and k 6= j, and εl is small if l ∈ [n] \\ [n2 ] and big if l ∈ [ n 2 ].\nWe want to mention that a solution of (4) does not necessarily correspond to actual workers, that is given εl, l ∈ [n], and cjk, 1 ≤ j < k ≤ n, there might be no collection of workers w1, . . . , wn such that εwl = εl and Cov[εwj (x, y), εwk(x, y)] = cjk. By the BhatiaDavis inequality (Bhatia & Davis, 2010) it holds that Var[εwj (x, y)] ≤ εwj − ε 2wj . Hence, a necessary condition for a solution to correspond to actual workers is that |cjk| ≤ (εj−ε 2j )1/2(εk−ε 2k )1/2 (in addition to εl ∈ [0, 1]). The two solutions in Lemma 2 correspond to actual workers.\nFrom now on we assume that at least n2 + 2 workers follow the one-coin model and have error probabilities smaller than one half:2\nAssumption A. There exists L ⊆ [n] with |L| ≥ n/2 + 2 such that for all j ∈ L, the worker wj follows the one-coin model with error probability εwj < 1/2.\nThis corresponds to considering (4) together with the constraint (6). The system (4) together with (6) is identifiable:\nProposition 1. There exists at most one solution of system (4) that has property (6).\n2All results of Section 4.2 hold true if we assume, more generally, the existence of L ⊆ [n] with |L| ≥ n\n2 + 2 such that (5)\ntogether with εwj < 1 2 holds for all j ∈ L.\nProof. Assuming there are two solutions (εS1l )l∈[n], (c S1jk )1≤j<k≤n and (ε S2 l )l∈[n], (c S2 jk )1≤j<k≤n with L1 and L2 satisfying (6), there have to be pairwise different i1, i2, i3 ∈ L1 ∩ L2. It is easy to see that (εS1i1 , ε S1 i2 , εS1i3 ) and (εS2i1 , ε S2 i2 , εS2i3 ) and consequently also all the other components of the two solutions have to coincide. Details can be found in Appendix B.\nIf pjk at the right-hand side of (4) are true agreement probabilities, the true error probabilities εw1 , . . . , εwn and covariances Cov[εwj (x, y), εwk(x, y)], j < k, make up the unique solution of (4) that satisfies (6), but if pjk are not exactly true agreement probabilities, there might be no solution of (4) that satisfies (6) at all. Our goal is then to find a solution of (4) that satisfies (6) approximately and to show that our approximate solution has to be close to εw1 , . . . , εwn and Cov[εwj (x, y), εwk(x, y)], j < k. As a first step towards this goal we need a generalization of Proposition 1:\nProposition 2. Let γ < 1/2 and ν < 1/8− γ/2 + γ2/2. If there exist two solutions (εSil )l∈[n], (c Si jk )1≤j<k≤n, i ∈ {1, 2}, of system (4) (where pjk ∈ [0, 1]) with the property that εSil ∈ [0, 1], l ∈ [n], and\n∃Li ⊆ [n] with |Li| ≥ n/2 + 2 such that ∀j ∈ Li : ( εSij ≤ γ ∧ [ ∀k 6= j : |c Sijk | ≤ ν ]) , (8)\nthen∣∣εS1l − εS2l ∣∣ ≤ G(γ, ν)√ν, ∣∣c S1jk − c S2jk ∣∣ ≤ 3G(γ, ν)√ν for l ∈ [n], j < k, where G(γ, ν)→ G(γ) > 0 as ν → 0.\nThe proof of Proposition 2, which provides an explicit expression for G(γ, ν), can be found in Appendix B.\nIn a next step, we assume that we are given pairwise different i1, i2, i3 ∈ [n] such that wi1 , wi2 , wi3 follow the onecoin model with εwi1 , εwi2 , εwi3 < 1/2. In this case, assuming that estimates pjk are close to true agreement probabilities, we can construct a solution of (4) that is guaranteed to be close to the true error probabilities and covariances (and hence approximately satisfies (6)). This is made precise in the next lemma (its proof can be found in Appendix B).\nLemma 3. Let γTR < 1/2 and consider the system (4) with p TRjk ∈ [0, 1] as right-hand side. Assume there exists a solution3 (εTRl )l∈[n], (c TR jk )1≤j<k≤n with the property that εTRl ∈ [0, 1] and\n∃LTR ⊆ [n] with |LTR| ≥ n/2 + 2 such that ∀j ∈ LTR : ( εTRj ≤ γTR ∧ [ ∀k 6= j : c TRjk = 0 ]) . (9)\nNow consider the system (4) with pjk ∈ [0, 1] as right-hand side. Assume that |p TRjk − pjk| ≤ β for all j 6= k, where\n3By Proposition 1, this solution is unique.\nβ satisfies β < 1/2− 2γTR + 2γ2TR. Let i1, i2, i3 ∈ [n] be pairwise different and set\nB := −2 + 4pi1i3 , C := 1 + 2pi1i2pi2i3 − pi1i2 − pi1i3 − pi2i3 ,\nεRi2 := 1 2 − √ B + 4C 2 √ B , εSi2 := min(γTR,max(0, ε R i2))\n(10)\nand for all l 6= i2 and for all 1 ≤ j < k ≤ n\nεRl := pi2l − 1 + εSi2\n2εSi2 − 1 ,\nεSl :=\n{ min(γTR,max(0, ε R l )) if l ∈ {i1, i3}\nmin(1,max(0, εRl )) if l /∈ {i1, i3} ,\nc Sjk := pjk − (1− εSj − εSk + 2εSj εSk )\n2 .\n(11)\nIf all expressions are defined (i.e., B > 0, B + 4C ≥ 0 and εSi2 6= 1 2 ), then (ε S l )l∈[n], (c S jk)1≤j<k≤n is a solution of (4) with pjk as right-hand side. If i1, i2, i3 ∈ LTR, then all expressions are defined and∣∣εTRl − εSl ∣∣ ≤ H(γTR, β)√β, l ∈ [n],∣∣c TRjk − c Sjk∣∣ ≤ 3H(γTR, β)√β + β/2, j < k, (12) where H(γTR, β)→ H(γTR) > 0 as β → 0.\nIn Lemma 3, for constructing the solution (εSl )l∈[n], (c Sjk)1≤j<k≤n as defined in (10) and (11) we need to know γTR < 1/2, which is an upper bound on the error probabilities of at least n2 + 2 workers that follow the one-coin model. In practice, we might choose γTR depending on the difficulty of the tasks or simply set it conservatively, for example as γTR = 0.45. If i1, i2, i3 ∈ LTR, then (12) implies that (εSl )l∈[n], (c S jk)1≤j<k≤n satisfies (8) with\nγ = γTR +H(γTR, β) √ β, ν = 3H(γTR, β) √ β + β/2.\n(13)\nIf we know the value of β (using Lemma 1, we easily obtain an upper bound β that holds with high probability), we can compute these quantities. This suggests the following strategy for obtaining estimates of εw1 , . . . , εwn and Cov[εwj (x, y), εwk(x, y)], j < k: we sample pairwise different i1, i2, i3 ∈ [n] uniformly at random and construct (εSl )l∈[n], (c S jk)1≤j<k≤n as defined in (10) and (11). If one of the expressions is not defined, we can immediately discard (i1, i2, i3). Otherwise, we check whether (εSl )l∈[n], (c Sjk)1≤j<k≤n satisfies (8) with γ and ν as specified in (13). If it does, since (εTRl )l∈[n], (c TR jk + (pjk− p TRjk )/2)1≤j<k≤n is a solution of (4) with pjk as right-hand side that satisfies\nproperty (8) too, Proposition 2 guarantees that ∣∣εTRl − εSl ∣∣ ≤√3H(γTR, β)√β + β2 · G ( γTR +H(γTR, β) √ β, 3H(γTR, β) √ β + β\n2\n) ∼ β1/4\n(14)\nfor all l ∈ [n] and a similar bound on |c TRjk − c Sjk|, j < k. If (εSl )l∈[n], (c S jk)1≤j<k≤n does not satisfy (8), we discard (i1, i2, i3) and start anew. Note that under our Assumption A, the probability of choosing i1, i2, i3 such that i1, i2, i3 ∈ LTR is greater than 1/8. In expectation we have to discard (i1, i2, i3) for not more than eight times before finding a solution that satisfies (8) and hence (14).\nAssuming that every worker is presented with every task, that is gij = 1 for all i ∈ [m] and j ∈ [n], it follows from Lemma 1 and (14) that m has to scale as ln(n2/δ)/ρ8 in order that the described strategy is guaranteed to yield, with probability at least 1 − δ, estimates εS1 , . . . , εSn satisfying |εTRl − εSl\n∣∣ ≤ ρ, l ∈ [n]. This is significantly larger than the rate m ∼ ln(n2/δ)/ρ2 required by the TE algorithm, which solves the estimation problem for the error probabilities in the one-coin model and is claimed to be minimax optimal (Bonald & Combes, 2017). We suspect that our rate with its dependence on ρ−8 is not optimal and consider it to be an interesting follow-up question to study the minimax rate for our extension of the one-coin model.\nAlthough the convergence rate that we can guarantee for the described strategy is slow, we might still hope that the strategy performs better in practice. However, there is an issue that we have to overcome. Unless β is very small, γ and ν as specified in (13) are too big for being meaningful, that is any solution (εSl )l∈[n], (c S jk)1≤j<k≤n as defined in (10) and (11) will satisfy (8) with these values. We will not discard any (i1, i2, i3), regardless of whether i1, i2, i3 ∈ LTR holds or not. We deal with this issue by adapting the strategy as follows: let P ⊆ {(i1, i2, i3) : i1, i2, i3 ∈ [n] pairwise different}. For every p = (i1, i2, i3) ∈ P , we construct (εSl (p))l∈[n], (c Sjk(p))1≤j<k≤n as defined in (10) and (11). We set Qp = [n] unless γ as specified in (13) is smaller than one, in which case we set Qp = {l ∈ [n] : εSl (p) ≤ γ} and discard any solution (εSl (p))l∈[n], (c S jk(p))1≤j<k≤n for which |Qp| < n2 + 2. Let ν p be the dn2 + 2e-th smallest element of {maxk∈[n]\\{l} |c Slk (p)| : l ∈ Qp}. Then we finally return the solution (εSl (p0))l∈[n], (c S jk(p0)))1≤j<k≤n for which νp is smallest, that is p0 = argminp ν p.\nIf γ is small enough, it follows from Proposition 2 that∣∣εTRl − εSl (p0)∣∣ ≤√max{νp0 , β/2} · G ( γTR +H(γTR, β) √ β,max{νp0 , β/2} ) . (15)\nNote that if P contains at least one triple of indices i1, i2, i3 ∈ LTR, then νp0 ≤ 3H(γTR, β) √ β + β2 , so that the guarantee (15) is at least as good as (14). We also expect νp0 to be smaller the larger P is. Hence, we should choose P as large as we can afford due to computational reasons, but in practice, there is one more aspect that we have to consider. Depending on how gij has been chosen, there might be workers wj and wk that were presented with only a few common tasks or no common tasks at all. In this case, the estimate pjk of the agreement probability between wj and wk is only poor and there is no uniform bound β on |p TRjk −pjk| (where p TRjk are true agreement probabilities). We can deal with this aspect by choosing P in a way such that for all p ∈ P , all estimates pjk that are involved in the computation of (εSl (p))l∈[n] are somewhat reliable. We present a concrete implementation of this in Algorithm 1 below."
  }, {
    "heading": "4.3. Predicting ground-truth labels",
    "text": "Once we have estimates ε̂w1 , . . . , ε̂wn of the true error probabilities εw1 , . . . , εwn , we predict ground-truth labels yi by taking a weighted majority vote over the responses collected for the task xi. Our estimate for yi is given by\nŷi = sign {∑n\nl=1 f(ε̂wl) ·Ail\n} , (16)\nwhere f : [0, 1]→ [−∞,+∞]. Ties are broken uniformly at random. We consider two choices for the function f .\nIt is well-known that if all workers follow the one-coin model with known error probabilities εw1 , . . . , εwn , groundtruth labels are balanced, that is Pr(x,y)∼D[y = +1] = Pr(x,y)∼D[y = −1], and gij are independent Bernoulli random variables with common success probability α > 0, then the optimal estimator for the ground-truth label yi is given by the weighted majority vote (16) with f(ε̂wl) replaced by f(εwl) = ln ((1− εwl)/εwl) (Nitzan & Paroush, 1982; Berend & Kontorovich, 2015; Bonald & Combes, 2017). Hence, a common approach for the one-coin model is to first estimate the true error probabilities and then to estimate ground-truth labels by using the majority vote (16) with f(ε̂wl) = ln ((1− ε̂wl)/ε̂wl) (Bonald & Combes, 2017; Ma et al., 2017). We propose to use the same majority vote, but restricted to answers from workers that we believe to follow the one-coin model. Using the notation from Section 4.2, this means that we set f(ε̂wl) = ln ((1− ε̂wl)/ε̂wl) for l ∈ Qp0 with maxk∈[n]\\{l} |c Slk (p0)| ≤ νp0 and f(ε̂wl) = 0 otherwise.\nAlternatively, we suggest to set f(ε̂wl) = 1 − 2ε̂wl for l ∈ [n]. With this choice of f we make use of the responses provided by all workers. The same choice has been used for the one-coin model too (Dalvi et al., 2013). A third option would be to set f(ε̂wl) = 1− 2ε̂wl for l ∈ Qp0 with maxk∈[n]\\{l} |c Slk (p0)| ≤ νp0 and f(ε̂wl) = 0 otherwise, but we do not consider this choice any further."
  }, {
    "heading": "4.4. Algorithm",
    "text": "In the interests of clarity, we present our approach as self contained Algorithm 1. Choosing P as the set of triples such that involved pairs of workers have been provided with at least ten or three common tasks might seem somewhat arbitrary here. Indeed, one could introduce two parameters to the algorithm instead. Without optimizing for these parameters, we chose them as ten and three in all our experiments on real data, and hence we state Algorithm 1 as is.\nOur analysis best applies to the setting of a full matrix A (or variables gij that are independent Bernoulli random variables with common success probability, as it is assumed by Bonald & Combes, 2017, for example). In this case, which we consider in our experiments on synthetic data, choosing P as stated in Algorithm 1 reduces to choosing P as the set of all triples of pairwise different indices. If the number of workers n is small, this is the best one can do. If n is large, it is infeasible to choose P as the set of all triples though since the running time of Algorithm 1 is in O(n2(m + |P |)). If n is large and A full, one should sample P uniformly at random. For |P | ≥ ln δ/ ln(7/8) our error guarantee (14) holds with probability at least 1− δ then (compare with Section 4.2)."
  }, {
    "heading": "5. Related work",
    "text": "We briefly survey related work here. A complete discussion can be found in Appendix A. As discussed in Sections 1 and 2, in crowdsourcing one might be interested in estimating ground-truth labels and/or worker qualities given the response matrix A, but also in optimal task assignment. In their seminal paper, Dawid & Skene (1979) proposed an EM based algorithm to address the first two goals. Since then numerous works have followed addressing all three goals for the Dawid-Skene and one-coin model (Ghosh et al., 2011; Karger et al., 2011a;b; 2013; 2014; Dalvi et al., 2013; Gao & Zhou, 2013; Gao et al., 2016; Zhang et al., 2016; Bonald & Combes, 2017; Ma et al., 2017). There have also been efforts to study generalizations of the Dawid-Skene model (Jaffe et al., 2016; Khetan & Oh, 2016; Shah et al., 2016) as well as to explicitly deal with adversaries (Raykar & Yu, 2012; Jagabathula et al., 2017). However, none of the prior work can handle a number of arbitrary adversaries almost as large as the number of reliable workers as we do."
  }, {
    "heading": "6. Experiments",
    "text": "On both synthetic and real data, we compared our proposed Algorithm 1 to straightforward majority voting for predicting labels (referred to as Maj) and the following methods from the literature: the spectral algorithms by Ghosh et al. (2011) (GKM), Dalvi et al. (2013) (RoE and EoR) and Karger et al. (2013) (KOS), the two-stage procedure by\nAlgorithm 1 Input: crowdsourced labels stored in A ∈ {−1, 0,+1}m×n, upper bound 0 < γTR < 12 on the error probabilities of dn2 + 2e workers that follow the one-coin model, confidence parameter 0 < δ < 1 Output: estimates (εFl )l∈[n], (c Fjk )j<k, (ŷi)i∈[m] of error probabilities, covariances and ground-truth labels\nI Estimating agreement probabilities set gij = 1{Aij 6= 0}, i ∈ [m], j ∈ [n] set qjk = ∑m i=1 gijgik, j, k ∈ [n] set pjk as in (3), j, k ∈ [n] (pjk = NaN if qjk = 0)\nI Estimating error probabilities and covariances set β = [ ln(2n2/δ)/ ( 2 minj,k∈[n] qjk )]1/2 ∈ (0,+Inf ] set γ as in (13) if γ /∈ [0, 1] then\nset γ = 1 end if set P = { (i1, i2, i3) : i1, i2, i3 ∈ [n] pairwise different\nand qjk ≥ 10, j, k ∈ {i1, i2, i3}, and qi2j ≥ 3, j 6= i2 }\nset νold = Inf, (εFl )l∈[n] = 0, (c F jk )1≤j<k≤n = 0, L = ∅ for (i1, i2, i3) ∈ P do if not all expressions in (10) or (11) are defined then\nbreak end if compute (εSl )l∈[n], (c S jk)1≤j<k≤n as in (10) and (11) set Q = {l ∈ [n] : εSl ≤ γ} set ν = dn2 + 2e-th smallest element of {maxk∈[n]\\{l} |c Slk | : l ∈ Q} (ν = NaN ifQ = ∅) if |Q| ≥ n2 + 2 AND ν < νold then set (εFl )l∈[n] = (ε S l )l∈[n], (c F jk )j<k = (c S jk)j<k\nset L = {l ∈ Q : maxk∈[n]\\{l} |c Slk | ≤ ν} set νold = ν\nend if end for\nI Estimating ground-truth labels set f(ε̂wl) = ln ((1− ε̂wl)/ε̂wl) ∈ [−Inf,+Inf], l ∈ L,\nand f(ε̂wl) = 0, l ∈ [n] \\ L (alternatively set f(ε̂wl) = 1− 2ε̂wl , l ∈ [n]) set ŷi as in (16), i ∈ [m]\nZhang et al. (2016) (S-EM1 and S-EM10, where we run one or ten iterations of the EM algorithm) and the recent method by Bonald & Combes (2017) (TE). We used the Matlab implementation of KOS, S-EM1 and S-EM10 made available by Zhang et al. (2016). In our implementations of the other methods, we adapted GKM, RoE and EoR as to assume that the average error of the workers is smaller than one half rather than assuming that the error of the first worker is. We always called Algorithm 1 with parameters γTR = 0.4 and δ = 0.1, which resulted in γ being set to 1\nin the execution of the algorithm in all our experiments. We refer to Algorithm 1 with the logarithmic weights in (16) as Alg. 1 and and with the linear weights as Alt-Alg. 1. In the following, all results are average results obtained from running an experiment for 100 times."
  }, {
    "heading": "6.1. Synthetic data",
    "text": "In our first experiment, we consider n = 50 workers and m = 5000 tasks with balanced ground-truth labels. Every worker is presented with every task. For 0 ≤ t ≤ 25, we choose t workers at random. These workers are corrupted workers that all provide the same random response to every task, which is incorrect with error probability 0.5. The remaining n − t workers provide responses according to the one-coin model, where the error probability of each of these workers is 0.4. Figure 1 shows the prediction error for estimating ground-truth labels and the estimation error for estimating error probabilities in both the maximum norm and the normalized 1-norm for the various methods as a function of t. The prediction error is given by 1m ∑m i=1 1{yi 6= ŷi} for ground-truth labels yi and estimates ŷi and the estimation error is given by maxl∈[n] |εwl − ε̂wl | or 1n ∑n l=1 |εwl − ε̂wl | for true error probabilities εwl and estimates ε̂wl . The methods Maj and KOS, by default, do not provide estimates of the workers’ error probabilities. We adapt these two methods in order to return estimates of the error probabilities too as follows: if the method returns label estimates ŷ1, . . . , ŷm and worker wl provides responses A1l, . . . , Aml 6= 0, then the method\nreturns 1m ∑m i=1 1{ŷi 6= Ail} as estimate ε̂wl of εwl .\nOur Algorithm 1 is the only method that can handle up to 23 = n2 − 2 corrupted workers (in accordance with our theoretical results). Its estimation error is constant as the number of corrupted workers increases from 0 to 23. Its prediction error depends on which weights we use in (16): the prediction error of Alg. 1 is constant in this range too, the one of Alt-Alg. 1 is slightly increasing. If only a few workers are corrupted, Alt-Alg.1 performs better than Alg. 1, while it is the other way round if more than 13 workers are corrupted. The methods from the literature predict ground-truth labels as badly as random guessing already in the presence of only six corrupted workers. All these methods are outperformed by majority voting. We do not have an explanation for the non-monotonic behavior of the estimation error of SEM10 in the maximum norm. In Appendix C we present similar experiments, in which the error probability of the workers following the one-coin model is smaller or the error probabilities of the corrupted workers are less correlated. Still, the overall picture there is the same.\nOne might wonder whether one can combine the considered methods from the literature with one of the algorithms by Jagabathula et al. (2017) in order to first sort the corrupted workers out and then apply the method only to the remaining workers and their responses. However, those algorithms cannot deal with the corrupted workers considered in this experiment, which are perfectly colluding, at all. Even though provided with the correct number t of corrupted workers as input, when t ≥ 3, the soft-penalty algorithm by Jagabathula et al. (2017) was not able to identify any of the corrupted workers in any of the 100 runs of the experiment.\nIn our next experiment, we study the convergence rate of Algorithm 1. We consider n = 50 workers, out of which t = 23 are corrupted in the same way as above. Figure 2 shows the prediction and estimation error of Algorithm 1 as a function of the number of tasks m varying from 5000 to 20000. The prediction error of Alg. 1 decreases only slightly as m increases, the prediction error of Alt-Alg. 1 decreases more significantly. Most interesting is the decay of the estimation error. Apparently, in this experiment it\ndecreases at a rate ofm−1/2 rather than at a rate ofm−1/8 as suggested by our upper bound (compare with Section 4.2)."
  }, {
    "heading": "6.2. Real data",
    "text": "We performed experiments on six publicly available data sets that are are commonly used in the literature (cf. Snow et al., 2008, Zhang et al., 2016, and Bonald & Combes, 2017). All six data sets come with ground truth labels for each task. For most of the data sets the matrix A, which stores the collected responses, is highly sparse. In order to reduce sparseness, we removed workers that provided fewer than 50 labels. For two of the data sets, we merged classes in order to end up with binary classification problems in the same way as Bonald & Combes (2017) did (Dog: {0, 2} vs {1, 3}; Web: {0, 1, 2} vs {3, 4}). Table 2 in Appendix C provides the characteristic values of the data sets. Note that only for the Bird data set every worker provided a label for every task whereas for the other ones A is still rather sparse. Figure 5 in Appendix C shows for each data set a histogram of the error probabilities of the workers (computed over those tasks that a worker was presented with). Figure 6 shows a heat map of the matrix (|Cov[εwj (x, y), εwk(x, y)]|)nj,k=1 (computed over those tasks that two workers were jointly presented with).\nTable 1 shows the prediction error for the various methods and data sets. There is no method that performs best on all data sets. Overall, S-EM10 seems to be the method of choice. Our Algorithm 1 can compete with the other methods, and on four out of the six data sets, the prediction error of Alt-Alg. 1 is smaller or larger only by 0.01 than the prediction error of S-EM10. Alg. 1 performs slightly worse than Alt-Alg. 1. The poor performance of our method on\nthe Bird data set might be explained by the fact that there the workers clearly deviate from our model: as Figure 6 shows, there are no n2 + 2 workers that follow the one-coin model.\nWe performed another experiments on these data sets by corrupting some of the workers (chosen at random). Like in the experiments of Section 6.1, the corrupted workers provide the same random response to every task. Figure 3 shows the prediction errors for the various methods and the first three data sets as functions of the number of corrupted workers. Similar plots for the other data sets are shown in Figure 7 in Appendix C. On none of the data sets, any method can handle more corrupted workers than Alt-Alg. 1."
  }, {
    "heading": "7. Discussion",
    "text": "In this work, we studied an extension of the well-known one-coin model for crowdsourcing that allows for colluding adversaries. Our results show that even if almost half of the workers are adversarial, one can consistently estimate the workers’ error probabilities with an efficient algorithm.\nFor future work, it would be interesting to relax the assumption that the reliable workers follow the one-coin model and to allow for task-dependent error probabilities also for them. It would also be interesting to see whether our approach can be extended to multiclass classification problems. Another direction concerns improving the sufficient rate m ∼ ρ−8 , which we obtained for our algorithm for recovering worker qualities up to error ρ. In the absence of adversaries one can achieve a rate m ∼ ρ−2, and we would like to understand whether this gap is inherent or an artifact of our algorithm/proof. Finally, we wonder about the role of adaptive task assignment in our extension of the one-coin model."
  }, {
    "heading": "Acknowledgements",
    "text": "This research is supported by a Rutgers Research Council Grant and a Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) postdoctoral fellowship."
  }],
  "year": 2018,
  "references": [{
    "title": "Crowdgrader: A tool for crowdsourcing the evaluation of homework assignments",
    "authors": ["L. Alfaro", "M. Shavlovsky"],
    "venue": "Technical Symposium on Computer Science Education (SIGCSE),",
    "year": 2014
  }, {
    "title": "A finite sample analysis of the naive bayes classifier",
    "authors": ["D. Berend", "A. Kontorovich"],
    "venue": "Journal of Machine Learning Research (JMLR),",
    "year": 2015
  }, {
    "title": "A better bound on the variance",
    "authors": ["R. Bhatia", "C. Davis"],
    "venue": "The American Mathematical Monthly,",
    "year": 2010
  }, {
    "title": "A minimax optimal algorithm for crowdsourcing",
    "authors": ["T. Bonald", "R. Combes"],
    "venue": "In Neural Information Processing Systems (NIPS),",
    "year": 2017
  }, {
    "title": "Aggregating crowdsourced binary ratings",
    "authors": ["N. Dalvi", "A. Dasgupta", "R. Kumar", "V. Rastogi"],
    "venue": "In World Wide Web Conference (WWW),",
    "year": 2013
  }, {
    "title": "Maximum likelihood estimation of observer error-rates using the EM algorithm",
    "authors": ["A. Dawid", "A. Skene"],
    "venue": "Applied Statistics,",
    "year": 1979
  }, {
    "title": "Imagenet: A large-scale hierarchical image database",
    "authors": ["J. Deng", "W. Dong", "R. Socher", "Li", "L.-J", "K. Li", "L. Fei-Fei"],
    "venue": "In Conference on Computer Vision and Pattern Recognition (CVPR),",
    "year": 2009
  }, {
    "title": "Minimax optimal convergence rates for estimating ground truth from crowdsourced labels",
    "authors": ["C. Gao", "D. Zhou"],
    "venue": "[stat.ML],",
    "year": 2013
  }, {
    "title": "Exact exponent in optimal rates for crowdsourcing",
    "authors": ["C. Gao", "Y. Lu", "D. Zhou"],
    "venue": "In International Conference on Machine Learning (ICML),",
    "year": 2016
  }, {
    "title": "Who moderates the moderators? Crowdsourcing abuse detection in usergenerated content",
    "authors": ["A. Ghosh", "S. Kale", "P. McAfee"],
    "venue": "In Conference on Electronic Commerce (EC),",
    "year": 2011
  }, {
    "title": "Unsupervised ensemble learning with dependent classifiers",
    "authors": ["A. Jaffe", "E. Fetaya", "B. Nadler", "T. Jiang", "Y. Kluger"],
    "venue": "In International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2016
  }, {
    "title": "Identifying unreliable and adversarial workers in crowdsourced labeling tasks",
    "authors": ["S. Jagabathula", "L. Subramanian", "A. Venkataraman"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Iterative learning for reliable crowdsourcing systems",
    "authors": ["D. Karger", "S. Oh", "D. Shah"],
    "venue": "In Neural Information Processing Systems (NIPS),",
    "year": 2011
  }, {
    "title": "Budget-optimal crowdsourcing using low-rank matrix approximations",
    "authors": ["D. Karger", "S. Oh", "D. Shah"],
    "venue": "In Allerton Conference on Communication, Control, and Computing,",
    "year": 2011
  }, {
    "title": "Efficient crowdsourcing for multi-class labeling",
    "authors": ["D. Karger", "S. Oh", "D. Shah"],
    "venue": "In ACM Sigmetrics,",
    "year": 2013
  }, {
    "title": "Budget-optimal task allocation for reliable crowdsourcing systems",
    "authors": ["D. Karger", "S. Oh", "D. Shah"],
    "venue": "Operations Research,",
    "year": 2014
  }, {
    "title": "Learning from noisy singly-labeled data",
    "authors": ["A. Khetan", "Z. Lipton", "A. Anandkumar"],
    "venue": "[cs.LG],",
    "year": 2017
  }, {
    "title": "Learning multiple layers of features from tiny images",
    "authors": ["A. Krizhevsky"],
    "venue": "Technical report, University of Toronto,",
    "year": 2009
  }, {
    "title": "Ensuring quality in crowdsourced search relevance evaluation: The effects of training question distribution",
    "authors": ["J. Le", "A. Edmonds", "V. Hester", "L. Biewald"],
    "venue": "In SIGIR workshop on crowdsourcing for search evaluation (CSE),",
    "year": 2010
  }, {
    "title": "Error rate bounds in crowdsourcing models",
    "authors": ["H. Li", "B. Yu", "D. Zhou"],
    "venue": "[stat.ML],",
    "year": 2013
  }, {
    "title": "Ranking reputation and quality in online rating systems",
    "authors": ["H. Liao", "A. Zeng", "R. Xiao", "Ren", "Z.-M", "Chen", "D.-B", "Zhang", "Y.-C"],
    "venue": "PLoS ONE,",
    "year": 2014
  }, {
    "title": "Variational inference for crowdsourcing",
    "authors": ["Q. Liu", "J. Peng", "A. Ihler"],
    "venue": "In Neural Information Processing Systems (NIPS),",
    "year": 2012
  }, {
    "title": "Optimal decision rules in uncertain dichotomous choice situations",
    "authors": ["S. Nitzan", "J. Paroush"],
    "venue": "International Economic Review,",
    "year": 1982
  }, {
    "title": "Eliminating spammers and ranking annotators for crowdsourced labeling tasks",
    "authors": ["V. Raykar", "S. Yu"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "A permutation-based model for crowd labeling: Optimal estimation and robustness",
    "authors": ["N. Shah", "S. Balakrishnan", "M. Wainwright"],
    "venue": "[cs.LG],",
    "year": 2016
  }, {
    "title": "Cheap and fast — but is it good? Evaluating non-expert annotations for natural language tasks",
    "authors": ["R. Snow", "B. O’Connor", "D. Jurafsky", "A. Ng"],
    "venue": "In Conference on Empirical Methods in Natural Language Processing (EMNLP),",
    "year": 2008
  }, {
    "title": "A statistical analysis of the aggregation of crowdsourced labels",
    "authors": ["D. Szepesvari"],
    "venue": "Master’s thesis, University of Waterloo,",
    "year": 2015
  }, {
    "title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing",
    "authors": ["Y. Zhang", "X. Chen", "D. Zhou", "M. Jordan"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Learning from the wisdom of crowds by minimax entropy",
    "authors": ["D. Zhou", "S. Basu", "Y. Mao", "J. Platt"],
    "venue": "In Neural Information Processing Systems (NIPS),",
    "year": 2012
  }],
  "id": "SP:8423bffcadb398119aad7987fbb92096362ec297",
  "authors": [{
    "name": "Matthäus Kleindessner",
    "affiliations": []
  }, {
    "name": "Pranjal Awasthi",
    "affiliations": []
  }],
  "abstractText": "Most existing works on crowdsourcing assume that the workers follow the Dawid-Skene model, or the one-coin model as its special case, where every worker makes mistakes independently of other workers and with the same error probability for every task. We study a significant extension of this restricted model. We allow almost half of the workers to deviate from the one-coin model and for those workers, their probabilities of making an error to be task-dependent and to be arbitrarily correlated. In other words, we allow for arbitrary adversaries, for which not only error probabilities can be high, but which can also perfectly collude. In this adversarial scenario, we design an efficient algorithm to consistently estimate the workers’ error probabilities.",
  "title": "Crowdsourcing with Arbitrary Adversaries"
}