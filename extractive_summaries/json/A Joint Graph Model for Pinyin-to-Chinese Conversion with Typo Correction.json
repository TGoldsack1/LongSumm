{
  "sections": [{
    "text": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1512–1523, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": ""
  }, {
    "heading": "1.1 Chinese Input Method",
    "text": "The daily life of Chinese people heavily depends on Chinese input method engine (IME), no matter whether one is composing an E-mail, writing an article, or sending a text message. However, every Chinese word inputted into computer or cellphone cannot be typed through one-to-one mapping of key-to-letter inputting directly, but has to go through an IME as there are thousands of Chinese characters for inputting while only 26 letter keys are available in the keyboard. An IME is an essential software interface that maps Chinese characters into English letter combinations. An ef-\n∗This work was partially supported by the National Natural Science Foundation of China (Grant No.60903119, Grant No.61170114, and Grant No.61272248), the National Basic Research Program of China (Grant No.2013CB329401), the Science and Technology Commission of Shanghai Municipality (Grant No.13511500200), and the European Union Seventh Framework Program (Grant No.247619).\n†Corresponding author\nficient IME will largely improve the user experience of Chinese information processing.\nNowadays most of Chinese IMEs are pinyin based. Pinyin is originally designed as the phonetic symbol of a Chinese character (based on the standard modern Chinese, mandarin) , using Latin letters as its syllable notation. For example, the pinyin of the Chinese character “爱”(love) is “ài”. Most characters usually have unique pinyin representations, while a few Chinese characters may be pronounced in several different ways, so they may have multiple pinyin representations. The advantage of pinyin IME is that it only adopts the pronunciation perspective of Chinese characters so that it is simple and easy to learn. But there are only less than 500 pinyin syllables in standard modern Chinese, compared with over 6,000 commonly used Chinese characters, which leads to serious ambiguities for pinyin-to-charactermapping. Modern pinyin IMEsmostly use a “sentencebased” decoding technique (Chen and Lee, 2000) to alleviate the ambiguities. “Sentence based” means that IME generates a sequence of Chinese characters upon a sequence of pinyin inputs with respect to certain statistical criteria."
  }, {
    "heading": "1.2 Typos and Chinese Spell Checking",
    "text": "Written in Chinese characters but not alphabets, spell checking for Chinese language is quite different from the same task for other languages. Since Chinese characters are entered via IME, those user-made typos do not immediately lead to spelling errors. When a user types a wrong letter, IME will be very likely to fail to generate the expected Chinese character sequence. Normally, the user may immediately notice the inputting error and then make corrections, which usually means doing a bunch of extra operations like cursor\n1512\nmovement, deletion and re-typing. Thus there are two separated sub-tasks for Chinese spell checking: 1. typo checking for user typed pinyin sequences which should be a built-in module in IME, and 2. spell checking for Chinese texts in its narrow sense, which is typically a module of word processing applications (Yang et al., 2012b). These two terms are often confused especially in IME related works such as (Chen and Lee, 2000) and (Wu et al., 2009).\nPinyin typos have always been a serious problem for Chinese pinyin IMEs. The user may fail to input the completely right pinyin simply because he/she is a dialect speaker and does not know the exact pronunciation for the expected character. This may be a very common situation since there are about seven quite different dialects in Chinese, among which being spoken languages, six are far different from the standard modern Chinese, mandarin. With the boom of smart-phones, pinyin typos worsen due to the limited size of soft keyboard, and the lack of physical feedback on the touch screen. However, existing practical IMEs only provide small patches to deal with typos such as Fuzzy Pinyin (Wu and Chen, 2004) and other language specific errors (Zheng et al., 2011b).\nTypo checking and correction has an important impact on IME performance. When IME fails to correct a typo and generate the expected sentence, the user will have to takemuch extra effort to move the cursor back to the mistyped letter and correct it, which leads to very poor user experience (Jia and Zhao, 2013)."
  }, {
    "heading": "2 Related Works",
    "text": "The very first approach for Chinese input with typo correction was made by (Chen and Lee, 2000), which was also the initial attempt of “sentence-based” IME. The idea of “statistical input method” was proposed by modeling PTC conversion as a hidden Markov model (HMM), and using Viterbi (Viterbi, 1967) algorithm to decode the sequence. They solved the typo correction problem by decomposing the conditional probability P (H|P ) of Chinese character sequence H given pinyin sequence P into a language model P (wi|wi−1) and a typing model P (pi|wi). The typing model that was estimated on real user input data was for typo correction. However, real user input data can be very noisy and not very convenient to obtain. As we will propose a joint model\nin this paper, such an individual typing model is not necessarily built in our approach.\n(Zheng et al., 2011a) developed an IME system with typo correction called CHIME using noisy channel error model and language-specific features. However their model depended on a very strong assumption that input pinyin sequence should have been segmented into pinyin words by the user. This assumption does not really hold in modern “sentence-based” IMEs. We release this assumption since our model solves segmentation, typo correction and PTC conversion jointly.\nBesides the common HMM approach for PTC conversion, there are also variousmethods such as: support vector machine (Jiang et al., 2007), maximum entropy (ME) model (Wang et al., 2006), conditional random field (CRF) (Li et al., 2009) and statistical machine translation (SMT) (Yang et al., 2012a; Wang et al., 2013c; Zhang and Zhao, 2013), etc.\nSpell checking or typo checking was first proposed for English (Peterson, 1980). (Mays et al., 1991) addressed that spell checking should be done within a context, i.e., a sentence or a long phrase with a certain meaning, instead of only in one word. A recent spell correction work is (Li et al., 2006), where a distributional similarity was introduced for spell correction of web queries.\nEarly attempts for Chinese spelling checking could date back to (Chang, 1994) where character tables for similar shape, pronunciation, meaning, and input-method-code characters were proposed. More recently, the 7th SIGHANWorkshop on Chinese Language Processing (Yu et al., 2013) held a shared task on Chinese spell checking. Various approaches were made for the task including language model (LM) based methods (Chen et al., 2013), ME model (Han and Chang, 2013), CRF (Wang et al., 2013d; Wang et al., 2013a), SMT (Chiu et al., 2013; Liu et al., 2013), and graph model (Jia et al., 2013), etc."
  }, {
    "heading": "3 Pinyin Input Method Model",
    "text": ""
  }, {
    "heading": "3.1 From English Letter to Chinese Sentence",
    "text": "It is a rather long journey from the first English letter typed on the keyboard to finally a completed Chinese sentence generated by IME. We will first take an overview of the entire process.\nThe average length of pinyin syllables is about 3 letters. There are about 410 pinyin syllables used in the current pinyin system. Each pinyin sylla-\nble has a bunch of corresponding Chinese characters which share the same pronunciation represented by the syllable. The number of those homophones ranges from 1 to over 300. Chinese characters then form words. But word in Chinese is a rather vague concept. Without word delimiters, linguists have argued on what a Chinese word really is for a long time and that is why there is always a primary word segmentation treatment in most Chinese language processing tasks (Zhao et al., 2006; Huang and Zhao, 2007; Zhao and Kit, 2008; Zhao et al., 2010; Zhao and Kit, 2011; Zhao et al., 2013). A Chinese word may contain from 1 to over 10 characters due to different word segmentation conventions. Figure 1 demonstrates the relationship of pinyin andword, from pinyin letters “nihao” to the word “你好 (hello)”. Typically, an IME takes the pinyin input, segments it into syllables, looks up corresponding words in a dictionary and generates a sentence with the candidate words."
  }, {
    "heading": "3.2 Pinyin Segmentation and Typo Correction",
    "text": "Non-Chinese users may feel confused or even surprised if they know that when typing pinyin through an IME, Chinese IME users will never enter delimiters such as “Space” key to segment either pinyin syllables or pinyin words, but just input the entire un-segmented pinyin sequence. For example, if one wants to input “你好世界 (Hello world)”, he will just type “nihaoshijie” instead of segmented pinyin sequence “ni hao shi jie”. Nevertheless, pinyin syllable segmentation is a much easier problem compared to Chinese word segmentation. Since pinyin syllables have a very limited vocabulary and follow a set of regularities strictly, it is convenient to perform pinyin sylla-\nble segmentation by using rules. But as the pinyin input is not segmented, it is nearly impossible to adopt previous spell checking methods for English to pinyin typo checking, although techniques for English spell checking have been well developed. A bit confusing but interesting, pinyin typo correction and segmentation come as two sides of one problem: when a pinyin sequence is mistyped, it is unlikely to be correctly segmented; when it is segmented in an awkward way, it is likely to be mistyped.\nInspired by (Yang et al., 2012b) and (Jia et al., 2013), we adopt the graph model for Chinese spell checking for pinyin segmentation and typo correction, which is based on the shortest path word segmentation algorithm (Casey and Lecolinet, 1996). The model has two major steps: segmentation and correction."
  }, {
    "heading": "3.2.1 Pinyin Segmentation",
    "text": "The shortest path segmentation algorithm is based on the idea that a reasonable segmentation should minimize the number of segmented units. For a pinyin sequence p1p2 . . . pL, where pi is a letter, first a directed acyclic graph (DAG) GS = (V, E) is built for pinyin segmentation step. The vertex set V consists of the following parts:\n• Virtual start vertex S0 and end vertex SE ; • Possible legal syllables fetched from dictionary Dp according to the input pinyin sequence:\n{Si,j |Si,j = pi . . . pj ∈ Dp}; • The letter itself as a fallback no matter if it is a legal pinyin syllable or not:\n{Si|Si = pi}. The vertex weights wS are all set to 0. The edges are from a syllable to all syllables next to it:\nE = {E(Si,j → Sj+1,k)|Si,j , Sj+1,k ∈ V}. The edge weight the negative logarithm of conditional probability P (Sj+1,k|Si,j) that a syllable Si,j is followed by Sj+1,k, which is give by a bigram language model of pinyin syllables:\nWE(Si,j→Sj+1,k) = − logP (Sj+1,k|Si,j) The shortest path P ∗ on the graph is the path P with the least sum of weights:\nP ∗ = argmin (v,E)∈G∧(v,E)∈P ∑ v wv + ∑ E WE .\nComputing the shortest path from S0 to SE on GS yields the best segmentation. This is the single source shortest path (SSSP) problem on DAG which has an efficient algorithm by preprocessing the DAG with topology sort, then traversing vertices and edges in topological order. It has the time complexity of O(|V|+ |E|). For example, one intends to input “你好世界 (Hello world)” by typing “nihaoshijie”, but mistyped as “mihaoshijiw”. The graph for this input is shown in Figure 2. The shortest path, i.e., the best segmentation is “mi hao shi ji w”. We will continue to use this example in the rest of this paper."
  }, {
    "heading": "3.2.2 Pinyin Typo Correction",
    "text": "Next in the correction step, for the segmented pinyin sequence S1, S2, . . . , SM , a graph Gc is constructed to perform typo correction. The vertex set V consists of the following parts:\n• Virtual start vertex S′0 and end vertex S′E with vertex weights of 0;\n• All possible syllables similar to original syllable in Gs. If the adjacent syllables can be merged into a legal syllable, the merged syllable is also added into V:\n{S′i,j |S′i,j = S′i . . . S′j ∈ Dp, S′k ∼ Sk, k = i ≤ j},\nwhere the similarity ∼ is measured in Levenshtein distance (Levenshtein, 1966). Syllables with Levenshtein distance under a certain threshold are considered as similar:\nL(Si, Sj) < T ↔ Si ∼ Sj .\nThe vertex weight is the Levenshtein distance multiply by a normalization parameter:\nwS′i,j = β j∑\nk−i L(S′k, Sk).\nSimilar toGs, the edges are from one syllable to all syllables next to it and edge weights are the conditional probabilities between them. Computing the shortest path from S′0 to S′E on Gc yields the best typo correction result. In addition, the result has been segmented so far. Considering our running example, the graph Gc is shown in Figure 3, and the typo correction result is “mi hao shi jie”.\nMerely using the above model, the typo correction result is not satisfying yet, no matter how much effort is paid. The major reason is that the basic semantic unit of Chinese language is actually word (tough vaguely defined) which is usually composed of several characters. Thus the conditional probability between characters does not make much sense. In addition, a pinyin syllable usually maps to dozens or even hundreds of corresponding homophonic characters, which makes the conditional probability between syllablesmuch more noisy. However, using pinyin words instead of syllables is not a wise choice because pinyin word segmentation is not so easy a task as syllable segmentation. To make typo correction better, we consider to integrate it with PTC conversion using a joint model."
  }, {
    "heading": "3.3 Hidden Markov Model for Pinyin-to-Chinese Conversion",
    "text": "PTC conversion has long been viewed as a decoding problem using HMM. We continue to follow this formalization. The best Chinese character sequence W ∗ for a given pinyin syllable sequence S is the one with the highest conditional probability P (W |S) that W ∗ = argmax\nW P (W |S)\n= argmax W P (W )P (S|W ) P (S)\n= argmax W\nP (W )P (S|W )\n= argmax w1,ww,...,wM ∏ wi P (wi|wi−1) ∏ wi P (si|wi)\nIn the HMM for pinyin IME, observation states are pinyin syllables, hidden states are Chinese words, emission probability is P (si|wi), and transition probability is P (wi|wi−1). Note the transition probability is the conditional probability between words instead of characters. PTC conversion is to decode the Chinese word sequence from the pinyin sequence. The Viterbi algorithm (Viterbi, 1967) is used for the decoding.\nThe shortest path algorithm for typo correction and Viterbi algorithm for PTC conversion are very closely related. It has been strictly proven by (Forney, 1973) that the sequence decoding problem on HMM is formally identical to finding a shortest path on a certain graph, which can be constructed in the following manner.\nConsider a first order HMM with all possible observations O = {o1, o2, . . . , oM}, hidden states S = {s1, s2, . . . , sN}, a special start state s0, emission probabilities (Esi,ok) = P (ok|si), transition probabilities (Tsi,sj ) = P (sj |si), and start probabilities (Ssi) = P (si|s0). For an observation sequence of T time periods Y = {y1, y2, . . . , yT |yt ∈ O, t = 1, . . . , T}, the decoding problem is to find the best corresponding hidden state sequence X∗ with the highest probability, i.e.,\nX∗ = argmax x1,xt∈S\nSx1Ex1,y1 T∏\nt=2\nExt,ytTxt−1,xt . (1)\nThenwewill construct a DAGG = (V, E) upon the HMM. The vertex set V includes:\n• Virtual start vertex v0 and end vertex vE with vertex weight of 0;\n• Normal vertices vxt , where t = 1, . . . , T , and ∀xt ∈ S. The vertex weight is the negative logarithm of emission probability:\nwvxt = − log Ext,yt .\nThe edge set E includes:\n• Edges from the start vertexE(v0 → vx1)with edge weight\nWE(v0→vx1 ) = − logSx1 ,\nwhere ∀x1 ∈ S; • Edges to the end vertex E(vxT → vE) with vertex weights of 0;\n• Edges between adjacent time periods E(vxt−1 → vxt) with edge weight\nWE(vxt−1→vxt ) = − log Txt−1,xt ,\nwhere t = 2, . . . , T , and ∀xt, xt−1 ∈ S.\nThe shortest path P ∗ from v0 to vE is the one with the least sum of vertex and edge weights, i.e.,\nP ∗ = argmin vxt∈V T∑ t=1 (wvxt + WE(vxt−1→vxt ))\n= argmin vx1 ,vxt∈V\n{− logSx1 − log Ex1,y1\n+ T∑\nt=2\n(− log Ext,yt − log Txt−1,xt)}\n= argmax vx1 ,vxt∈V\nSx1Ex1,y1 T∏\nt=2\nExt,ytTxt−1,xt . (2)\nThe optimization goal of P ∗ in Equation (2) is identical to that of X∗ in Equation (1)."
  }, {
    "heading": "3.4 Joint Graph Model For Pinyin IME",
    "text": "Given HMM decoding problem is identical to SSSP problem on DAG, we propose a joint graph model for PTC conversion with typo correction. The joint graph model aims to find the global optimal for both PTC conversion and typo correction on the entire input pinyin sequence. The graph G = (V, E) is constructed based on graph Gc for typo correction in Section 3.2. The vertex set V consists of the following parts:\n• Virtual start vertex V0 and end vertex VE with vertex weight of 0;\n• Adjacent pinyin syllables in Gc are merged into pinyin words. Corresponding Chinese words are fetched from a PTC dictionary Dc, which is a dictionary maps pinyin words to Chinese words, and added as vertices:\n{Vi,j |∀Vi,j ∈ Dc[S′i . . . S′j ], i ≤ j};\nThe vertex weight consists of two parts: 1. the vertex weights of syllables in Gc, and 2. the emission probability:\nwVi,j =β j∑\nk=i\nL(S′k, Sk)\n− γ logP (S′i . . . S′j |Vi,j);\nIf the corresponding pinyin syllables in Gc have an edge between them, the vertices in G also have an edge:\nE = {E(Vi,j → Vj+1,k)|E(Si,j → Sj+1,k) ∈ Gc}.\nThe edge weights are the negative logarithm of the transition probabilities:\nWE(Vi,j→Vj+1,k) = − logP (Vj+1,k|Vi,j)\nAlthough the model is formulated on first order HMM, i.e., the LM used for transition probability is a bigram one, it is easy to extend the model to take advantage of higher order n-gram LM, by tracking longer history while traversing the graph.\nComputing the shortest path from V0 to VE onG yields the best pinyin-to-Chinese conversion with typo correction result. Considering our running example, the graph G is shown in Figure 4.\nThe joint graph is rather huge and density. According to our empirical statistics, when setting threshold T = 2, for a sentence of M characters, the joint graph will have |V| = M × 1, 000, and |E| = M × 1, 000, 000. 3.5 K-Shortest Paths To reduce the scale of graph G, we filter graph Gc by searching itsK-shortest paths first to getG′c and construct G on top of G′c. Figure 5 shows the 3- shortest paths filtered graphG′c and Figure 6 shows the correspondingG for our running example. The scale of graph may be thus drastically reduced.\nAn efficient heap data structure is required in K-shortest paths algorithm (Eppstein, 1998) for\nbacktracking the best paths to current vertex while traversing. The heap is implemented as a priority queue of size K sorted according to path length that should support efficient push and pop operations. Fibonacci heap (Fredman and Tarjan, 1987) is adopted for the heap implementation since it has a push complexity of O(1) which is better than the O(K) for other heap structures.\nAnother benefit provided by K-shortest paths is that it can be used for generating N -best candidates of PTC conversion, which may be helpful for further performance improvement."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Corpora, Tools and Experiment Settings",
    "text": "The corpus for evaluation is the one provided in (Yang et al., 2012a), which is originally extracted from the People’s Daily corpus and labeled with pinyin. The corpus has already been split into training T, development D and test T sets as shown in Table 1.\nSRILM (Stolcke, 2002) is adopted for languagemodel training andKenLM (Heafield, 2011; Heafield et al., 2013) for language model query. The Chinese part of the corpus is segmented into words before LM training. Maximum matching word segmentation is used with a large word vocabulary V extracted from web data provided by (Wang et al., 2013b). The pinyin part is segmented according to the Chinese part. This vocabulary V also serves as the PTC dictionary. The original vocabulary is not labeled with pinyin, thus we use the PTC dictionary of sunpinyin1 which is an open source Chinese pinyin IME, to label the\n1http://code.google.com/p/sunpinyin/\nvocabulary V with pinyin. The emission probabilities are estimated using the lexical translation module of MOSES (Koehn et al., 2007) as “translation probability” from pinyin to Chinese."
  }, {
    "heading": "4.2 Evaluation Metrics",
    "text": "Wewill use conventional sequence labeling evaluation metrics such as sequence accuracy and character accuracy2.\nChinese characters in a sentence may be separated by digits, punctuation and alphabets which are directly inputted without the IME. We follow the so-called term Max Input Unit (MIU), the longest consecutive Chinese character sequence proposed by (Jia and Zhao, 2013). We will mainly consider MIU accuracy (MIU-Acc) which is the ratio of the number of completely corrected generated MIUs over the number of all MIUs, and character accuracy (Ch-Acc), but the sentence accuracy (S-Acc) will also be reported in evaluation results.\nWe will also report the conversion error rate (ConvER) proposed by (Zheng et al., 2011a), which is the ratio of the number of mistyped pinyin word that is not converted to the right Chinese word over the total number of mistyped pinyin words3."
  }, {
    "heading": "4.3 Baseline System without Typo Correction",
    "text": "Firstly we build a baseline system without typo correction which is a pipeline of pinyin syllable segmentation and PTC conversion. The baseline system takes a pinyin input sequence, segments it into syllables, and then converts it to Chinese character sequence.\nThe pinyin syllable segmentation already has very high (over 98%) accuracy with a trigram LM using improved Kneser-Ney smoothing. According to our empirical observation, emission probabilities are mostly 1 since most Chinese words have unique pronunciation. So in this step we set γ = 0. We consider different LM smoothing methods including Kneser-Ney (KN), improved Kneser-Ney (IKN), and Witten-Bell (WB). All of the three smoothing methods for bigram and trigram LMs are examined both using back-off mod-\n2We only work on the PTC conversion part of IME, thus we are unable to use existing evaluation systems (Jia and Zhao, 2013) for full Chinese IME functions.\n3Other evaluation metrics are also proposed by (Zheng et al., 2011a) which is only suitable for their system since our system uses a joint model\nels and interpolated models. The number of N - best candidates for PTC conversion is set to 10. The results on D are shown in Figure 7 in which the “-i” suffix indicates using interpolated model. According to the results, we then choose the trigram LM using Kneser-Ney smoothing with interpolation.\nThe choice of the number of N -best candidates for PTC conversion also has a strong impact on the results. Figure 8 shows the results onDwith differentNs, of which theN axis is drawn in logarithmic scale. We can observe that MIU-Acc slightly decreases while N goes up, but Ch-Acc largely increases. We therefore chooseN = 10 as trade-off.\nThe parameter γ determines emission probability. Results with different γ on D is shown in Figure 9, of which the γ axis is drawn in logarithmic scale. γ = 0.03 is chosen at last.\nWe compare our baseline system with several practical pinyin IMEs including sunpinyin and Google Input Tools (Online version)4. The results on D are shown in Table 2.\n4http://www.google.com/inputtools/try/"
  }, {
    "heading": "4.4 PTC Conversion with Typo Correction",
    "text": "Based upon the baseline system, we build the joint system of PTC conversion with typo correction.\nWe simulate user typos by randomly generating errors automatically on the corpus. The typo rate is set according to previous Human-Computer Interaction (HCI) studies. Due to few works have been done on modeling Chinese text entry, we have to refer to those corresponding results on English (Wobbrock and Myers, 2006; MacKenzie and Soukoreff, 2002; Clarkson et al., 2005), which show that the average typo rate is about 2%. (Zheng et al., 2011a) performed an experiment that 2,000 sentences of 11,968 Chinese words were entered by 5 native speakers. The collected data consists of 775 mistyped pinyin words caused by one edit operation, and 85 caused by two edit operations. As we observe on T that the average pinyin word length is 5.24, then typo rate in the experiment of (Zheng et al., 2011a) can be roughly estimated as:\n775 + 85× 2 11968× 5.24 = 1.51%,\nwhich is similar to the conclusion on English. Thus we generate corpora from D with typo rate of 0% (0-P), 2% (2-P), and 5% (5-P) to evaluate the system.\nAccording to (Zheng et al., 2011a) most mistyped pinyin words are caused by one edit operation. Since pinyin syllable is much shorter than\npinyin word, this ratio can be higher for pinyin syllables. From our statistics on T, with 2% randomly generated typos, Pr(L(S′, S) < 2) = 99.86%. Thus we set the threshold T for L to 2.\nWe first set K-shortest paths filter to K = 10 and tune β. Results with different β are shown in Figure 10. With β = 3.5, we select K. Re-\nsults with different K are shown in Figure 11. We choose K = 20 since there is no significant improvement when K > 20.\nThe selection of K also directly guarantees the running time of the joint model. With K = 20, on a normal PC with Intel Pentium Dual-Core E6700 CPU, the PTC conversion rate is over 2000 characters-per-minute (cpm), which is much faster than the normal typing rate of 200 cpm.\nWith all parameters optimized, results on T\nusing the proposed joint model are shown in Table 3 and Table 4. Our results are compared to the baseline system without typo correction and Google Input Tool. Since sunpinyin does not have typo correction module and performs much poorer than our baseline system, we do not include it in the comparison. Though no direct proofs can be found to indicate if Google Input Tool has an independent typo correction component, its outputs show that such a component is unlikely available.\nSince Google Input Tool has to be accessed through a web interface and the network connection cannot be guaranteed. we only take a subset of 10K sentences of T to perform the experiments, and the results are shown in Table 3.\nThe scores reported in (Zheng et al., 2011a) are not listed in Table 4 since the data set is different. They reported a ConvER of 53.56%, which is given here for reference.\nAdditionally, to further inspect the robustness of ourmodel, performance with typo rate ranges from 0% to 5% is shown in Figure 12. Although the performance decreases while typo rate goes up, it is still quite satisfying around typo rate of 2% which is assumed to be the real world situation."
  }, {
    "heading": "5 Conclusion",
    "text": "In this paper, we have developed a joint graph model for pinyin-to-Chinese conversion with typo correction. This model finds a joint global optimal for typo correction and PTC conversion on the entire input pinyin sequence. The evaluation results show that our model outperforms both previous academic systems and existing commercial products. In addition, the joint model is efficient enough for practical use."
  }],
  "year": 2014,
  "references": [{
    "title": "A Survey of Methods and Strategies in Character Segmentation",
    "authors": ["References Richard G. Casey", "Eric Lecolinet."],
    "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on, 18(7):690–706.",
    "year": 1996
  }, {
    "title": "A Pilot Study on Automatic Chinese Spelling Error Correction",
    "authors": ["Chao-Huang Chang."],
    "venue": "Journal of Chinese Language and Computing, 4:143–149.",
    "year": 1994
  }, {
    "title": "A New Statistical Approach To Chinese Pinyin Input",
    "authors": ["Zheng Chen", "Kai-Fu Lee."],
    "venue": "Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 241–247, Hong Kong, October.",
    "year": 2000
  }, {
    "title": "A Study of Language Modeling for Chinese Spelling Check",
    "authors": ["Kuan-YuChen", "Hung-Shin Lee", "Chung-HanLee", "HsinMin Wang", "Hsin-Hsi Chen."],
    "venue": "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 79–83,",
    "year": 2013
  }, {
    "title": "Chinese Spelling Checker Based on Statistical Machine Translation",
    "authors": ["Hsun-wen Chiu", "Jian-cheng Wu", "Jason S. Chang."],
    "venue": "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 49–53, Nagoya, Japan, October.",
    "year": 2013
  }, {
    "title": "An Empirical Study of Typing Rates onmini-QWERTYKeyboards",
    "authors": ["Edward Clarkson", "James Clawson", "Kent Lyons", "Thad Starner."],
    "venue": "InCHI ’05 Extended Abstracts onHuman Factors in Computing Systems, CHI EA ’05, pages 1288–1291, New York,",
    "year": 2005
  }, {
    "title": "Finding the K Shortest Paths",
    "authors": ["David Eppstein."],
    "venue": "SIAM Journal on computing, 28(2):652–673.",
    "year": 1998
  }, {
    "title": "The Viterbi Algorithm",
    "authors": ["Jr G. David Forney."],
    "venue": "Proceedings of the IEEE, 61(3):268–278.",
    "year": 1973
  }, {
    "title": "Fibonacci Heaps and Their Uses in Improved Network Optimization Algorithms",
    "authors": ["Michael L. Fredman", "Robert Endre Tarjan."],
    "venue": "Journal of the ACM (JACM), 34(3):596–615, July.",
    "year": 1987
  }, {
    "title": "A Maximum Entropy Approach to Chinese Spelling Check",
    "authors": ["Dongxu Han", "Baobao Chang."],
    "venue": "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 74–78, Nagoya, Japan, October. Asian Federation of Nat-",
    "year": 2013
  }, {
    "title": "Scalable Modified Kneser-Ney Language Model Estimation",
    "authors": ["Kenneth Heafield", "Ivan Pouzyrevsky", "Jonathan H. Clark", "Philipp Koehn."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 690–696,",
    "year": 2013
  }, {
    "title": "KenLM: Faster and Smaller Language Model Queries",
    "authors": ["Kenneth Heafield."],
    "venue": "Proceedings of the",
    "year": 2011
  }, {
    "title": "Chinese Word Segmentation: A Decade Review",
    "authors": ["Changning Huang", "Hai Zhao."],
    "venue": "Journal of Chinese Information Processing, 21(3):8–20.",
    "year": 2007
  }, {
    "title": "KySS 1.0: a Framework for Automatic Evaluation of Chinese Input Method Engines",
    "authors": ["Zhongye Jia", "Hai Zhao"],
    "venue": "In Proceedings of the Sixth International Joint Conference on Natural Language Processing,",
    "year": 2013
  }, {
    "title": "Graph Model for Chinese Spell Checking",
    "authors": ["Zhongye Jia", "Peilu Wang", "Hai Zhao."],
    "venue": "Proceedings of the Seventh SIGHAN Workshop on Chinese Language Processing, pages 88–92, Nagoya, Japan, October. Asian Federation of Natural Language Pro-",
    "year": 2013
  }, {
    "title": "PinYin-to-Character Conversion Model based on Support Vector Machines",
    "authors": ["Wei Jiang", "Yi Guan", "Xiaolong Wang", "BingQuan Liu."],
    "venue": "Journal of Chinese information processing, 21(2):100–105.",
    "year": 2007
  }, {
    "title": "Binary Codes Capable of Correcting Deletions, Insertions and Reversals",
    "authors": ["Vladimir I. Levenshtein."],
    "venue": "Soviet physics doklady, volume 10, page 707.",
    "year": 1966
  }, {
    "title": "Exploring Distributional Similarity Based Models for Query Spelling Correction",
    "authors": ["Mu Li", "Muhua Zhu", "Yang Zhang", "Ming Zhou."],
    "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the",
    "year": 2006
  }, {
    "title": "A Conditional Random Fields Approach to Chinese Pinyin-to-Character Conversion",
    "authors": ["Lu Li", "Xuan Wang", "Xiao-Long Wang", "Yan-Bing Yu."],
    "venue": "Journal of Communication and Computer, 6(4):25–31.",
    "year": 2009
  }, {
    "title": "A Hybrid Chinese Spelling Correction Using LanguageModel and StatisticalMachine Translation with Reranking",
    "authors": ["Xiaodong Liu", "Kevin Cheng", "Yanyan Luo", "Kevin Duh", "Yuji Matsumoto."],
    "venue": "InProceedings of the Seventh SIGHAN Workshop on Chi-",
    "year": 2013
  }, {
    "title": "A Character-level Error Analysis Technique for Evaluating Text Entry Methods",
    "authors": ["I. Scott MacKenzie", "R.William Soukoreff."],
    "venue": "Proceedings of the Second Nordic Conference on Human-computer Interaction, NordiCHI ’02, pages 243–246, NewYork,",
    "year": 2002
  }, {
    "title": "Context Based Spelling Correction",
    "authors": ["Eric Mays", "Fred J Damerau", "Robert L Mercer."],
    "venue": "Information Processing & Management, 27(5):517–522.",
    "year": 1991
  }, {
    "title": "Computer Programs for Detecting and Correcting Spelling Errors",
    "authors": ["James L. Peterson."],
    "venue": "Commun. ACM, 23(12):676–687, December.",
    "year": 1980
  }, {
    "title": "SRILM-An Extensible Language Modeling Toolkit",
    "authors": ["Andreas Stolcke."],
    "venue": "Proceedings of the international conference on spoken language processing, volume 2, pages 901–904.",
    "year": 2002
  }, {
    "title": "Error Bounds for Convolutional Codes and an Asymptotically Optimum Decoding Algorithm",
    "authors": ["Andrew J. Viterbi."],
    "venue": "Information Theory, IEEE Transactions on, 13(2):260–269.",
    "year": 1967
  }, {
    "title": "A Maximum Entropy Approach to Chinese Pin YinTo-Character Conversion",
    "authors": ["Xuan Wang", "Lu Li", "Lin Yao", "Waqas Anwar."],
    "venue": "Systems, Man and Cybernetics, 2006. SMC’06. IEEE International Conference on, volume 4, pages 2956–2959. IEEE.",
    "year": 2006
  }, {
    "title": "Automatic Chinese Confusion Words ExtractionUsing Conditional RandomFields and the Web",
    "authors": ["Chun-Hung Wang", "Jason S. Chang", "Jian-Cheng Wu."],
    "venue": "Proceedings of the Seventh SIGHANWorkshop on Chinese Language Processing, pages 64–",
    "year": 2013
  }, {
    "title": "A New Word Language Model Evaluation Metric for Character Based Languages",
    "authors": ["Peilu Wang", "Ruihua Sun", "Hai Zhao", "Kai Yu."],
    "venue": "Chinese Computational Linguistics and Natural Language Processing Based on Naturally Annotated Big Data,",
    "year": 2013
  }, {
    "title": "Converting Continuous-Space Language Models into N-Gram Language Models for Statistical Machine Translation",
    "authors": ["Rui Wang", "Masao Utiyama", "Isao Goto", "Eiichro Sumita", "Hai Zhao", "Bao-Liang Lu."],
    "venue": "Proceedings of the 2013 Conference on Em-",
    "year": 2013
  }, {
    "title": "Conditional Random Field-based Parser and Language Model for Traditional Chinese Spelling Checker",
    "authors": ["Yih-Ru Wang", "Yuan-Fu Liao", "Yeh-Kuang Wu", "Liang-Chun Chang."],
    "venue": "Proceedings of the Seventh SIGHAN Workshop on Chinese Lan-",
    "year": 2013
  }, {
    "title": "Analyzing the Input Stream for Character- Level Errors in Unconstrained Text Entry Evaluations",
    "authors": ["Jacob O.Wobbrock", "Brad A.Myers."],
    "venue": "ACM Trans. Comput.-Hum. Interact., 13(4):458–489, December.",
    "year": 2006
  }, {
    "title": "Fault-tolerant Romanized Input Method for Non-roman Characters, August 25",
    "authors": ["Jun Wu", "Liren Chen."],
    "venue": "US Patent App. 10/928,131.",
    "year": 2004
  }, {
    "title": "Systems and Methods for Translating Chinese Pinyin to Chinese Characters, January 13",
    "authors": ["Jun Wu", "Hulcan Zhu", "Hongjun Zhu."],
    "venue": "US Patent 7,478,033.",
    "year": 2009
  }, {
    "title": "A Machine Translation Approach for Chinese WholeSentence Pinyin-to-Character Conversion",
    "authors": ["Shaohua Yang", "Hai Zhao", "Bao-liang Lu."],
    "venue": "Proceedings of the 26th Pacific Asia Conference on Language, Information, and Computation, pages 333–",
    "year": 2012
  }, {
    "title": "Spell Checking for Chinese",
    "authors": ["ShaohuaYang", "Hai Zhao", "XiaolinWang", "Bao-liang Lu."],
    "venue": "International Conference on Language Resources and Evaluation, pages 730–736, Istanbul, Turkey, May.",
    "year": 2012
  }, {
    "title": "Improving Function Word Alignment with Frequency and Syntactic Information",
    "authors": ["Jingyi Zhang", "Hai Zhao."],
    "venue": "Proceedings of the Twenty-Third international joint conference on Artificial Intelligence, pages 2211–2217. AAAI Press.",
    "year": 2013
  }, {
    "title": "Exploiting Unlabeled Text with Different Unsupervised Segmentation Criteria for Chinese Word Segmentation",
    "authors": ["Hai Zhao", "Chunyu Kit."],
    "venue": "Research in Computing Science, 33:93–104.",
    "year": 2008
  }, {
    "title": "Integrating Unsupervised and Supervised Word Segmentation: The Role of Goodness Measures",
    "authors": ["Hai Zhao", "Chunyu Kit."],
    "venue": "Information Sciences, 181(1):163–183.",
    "year": 2011
  }, {
    "title": "An Improved Chinese Word Segmentation System with Conditional Random Field",
    "authors": ["Hai Zhao", "Chang-Ning Huang", "Mu Li."],
    "venue": "Proceedings of the Fifth SIGHANWorkshop on Chinese Language Processing, pages 162–165, Sydney, Australia, July.",
    "year": 2006
  }, {
    "title": "A Unified Character-Based Tagging Framework for Chinese Word Segmentation",
    "authors": ["Hai Zhao", "Chang-Ning Huang", "Mu Li", "Bao-Liang Lu."],
    "venue": "ACM Transactions on Asian Language Information Processing (TALIP), 9(2):5.",
    "year": 2010
  }, {
    "title": "An Empirical Study on Word Segmentation for Chinese Machine Translation",
    "authors": ["Hai Zhao", "Masao Utiyama", "Eiichiro Sumita", "BaoLiang Lu."],
    "venue": "Computational Linguistics and Intelligent Text Processing, pages 248–263. Springer.",
    "year": 2013
  }, {
    "title": "CHIME: An Efficient Error-tolerant Chinese Pinyin Input Method",
    "authors": ["Yabin Zheng", "Chen Li", "Maosong Sun."],
    "venue": "Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence - Volume Volume Three, IJCAI’11, pages",
    "year": 2011
  }, {
    "title": "Why Press Backspace? Understanding User Input Behaviors in Chinese Pinyin Input Method",
    "authors": ["Yabin Zheng", "Lixing Xie", "Zhiyuan Liu", "Maosong Sun", "Yang Zhang", "Liyun Ru."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Compu-",
    "year": 2011
  }],
  "id": "SP:4503c3b75bf515098184d993790639c26f75da3a",
  "authors": [{
    "name": "Zhongye Jia",
    "affiliations": []
  }, {
    "name": "Hai Zhao",
    "affiliations": []
  }],
  "abstractText": "It is very import for Chinese language processing with the aid of an efficient input method engine (IME), of which pinyinto-Chinese (PTC) conversion is the core part. Meanwhile, though typos are inevitable during user pinyin inputting, existing IMEs paid little attention to such big inconvenience. In this paper, motivated by a key equivalence of two decoding algorithms, we propose a joint graph model to globally optimize PTC and typo correction for IME. The evaluation results show that the proposed method outperforms both existing academic and commercial IMEs.",
  "title": "A Joint Graph Model for Pinyin-to-Chinese Conversion with Typo Correction"
}