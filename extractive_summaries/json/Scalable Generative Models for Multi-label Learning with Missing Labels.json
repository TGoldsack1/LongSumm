{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Multi-label learning (Gibaja & Ventura, 2015; 2014) is the problem of assigning to an object a subset of labels from a potentially very large label vocabulary (Prabhu & Varma, 2014; Jain et al., 2016; Babbar & Schölkopf, 2017). In contrast to binary or multi-class classification, in multilabel learning, each example is associated with a binary label vector (potentially very large), denoting the presence/absence (relevance/irrelevance) of each label. Multilabel learning has applications in several domains such as computer vision (Wang et al., 2016), computational adver-\n*Equal contribution 1Department of Computer Science and Enginerring, IIT Kanpur, Kanpur 208016, UP, India. Correspondence to: Vikas Jain <vikasj@iitk.ac.in>, Nirbhay Modhe <nirbhaym@iitk.ac.in>, Piyush Rai <piyush@cse.iitk.ac.in>\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\ntising and recommender systems (Prabhu & Varma, 2014; Jain et al., 2016), etc.\nSeveral state-of-the-art methods for multi-label learning are based on certain structural assumptions on the binary label matrix. Some of the key structural assumptions that have been used in prior work include low-rank assumption (Yu et al., 2014), locally low-rank assumption (Bhatia et al., 2015), and low-rank plus sparse assumption (Xu et al., 2016), and clusters/topics of labels assumption (Cissé et al., 2016; Rai et al., 2015). Models based on these assumptions are broadly dubbed as embedding based methods for multi-label learning and offer two key advantages: (1) The relatedness/correlation among labels can be easily modeled/captured, and (2) the label vector for each example can be represented as a low-dimensional embedding, which faciliates developing computationally scalable models for multi-label learning. A more detailed discussion of prior work is provided in the Related Work section.\nDespite the considerable recent interest and progress on the problem of multi-label learning (Yu et al., 2014; Bhatia et al., 2015; Wang et al., 2016; Cissé et al., 2016), a number of important issues still remain. One of such issues, especially for the embdding based methods, is the ambiguity regarding the zeros vs unobserved (missing) entries in the binary label vector of each example. Since, in practice, the true value (0/1) for only a small subset of all the labels can be obtained, the zeros in the label vector do not necessarily represent negative labels. A typical heuristic employed by multi-label learning algorithms is to simply treat all such the zeros in the label vector as are true negatives (Yu et al., 2014). Another heuristic is to assign different weights to the zeros and ones in the binary label matrix (Yu et al., 2017), which is inspired by matrix factorization based collaborative filtering models that learn from implicit (binary) feedback data (Hu et al., 2008). However, a more principled strategy to address this issue is highly desirable.\nAnother important desideratum is scalability, especially in the case of extreme multi-label learning problems (Prabhu & Varma, 2014; Jain et al., 2016; Babbar & Schölkopf, 2017), which are characterized by a massive number of labels, features, and examples. Although a number of recent multi-label learning models have been proposed that can scale to large-scale problems, these models usually require\nlarge computational resources to truly scale to massive data sets (Babbar & Schölkopf, 2017; Bhatia et al., 2015; Jain et al., 2016). Moreover, most of the scalable multi-label learning algorithms only operate in batch setting and are usually not designed to work (Prabhu & Varma, 2014; Bhatia et al., 2015; Jain et al., 2016) in online settings with continuous stream of training examples.\nIn this paper, we present a scalable, generative framework for multi-label learning, that not only bring to bear the modeling flexibility of probabilistic, generative models for the multi-label learning problem (Kapoor et al., 2012; Rai et al., 2015), but is also designed to handle the abovementioned challenges in a principled way. Our framework is based on a latent factor model for the binary label matrix, and has the following distinguishing aspects: (1) It naturally handles the issue of missing vs negative labels via a principled generative model with a exposure model (Liang et al., 2016) for the label matrix; (2) It is accompanied by a simple and scalable inference procedure (both via Gibbs sampling and via fast point estimation); and (3) Inference can also be easily performed in an online fashion, enabling us to apply it on large-scale problems, even when using moderate computational resources."
  }, {
    "heading": "2. The Model",
    "text": "In the multi-label learning problem, we assume that we are givenN training examples {(x1,y1), . . . , (xN ,yN )} with xn ∈ RD and yn ∈ {0, 1}L, n = 1, . . . , N . We will denote X = {x1, . . . ,xN} ∈ RN×D to be the feature matrix and Y = {y1, . . . ,yN} ∈ {0, 1}N×L to be the label matrix. Given training data {X,Y}, the goal in multi-label learning is to learn a model that can predict the label vector y∗ ∈ {0, 1}L for a new test input x∗ ∈ RD.\nNote that an entry yn` = 0 in the label matrix Y may not necessarily mean a negative label but could simply mean that this label is missing (and its true value could be 0 or 1). As we shall show, our generative model can infer the missingness of a label yn` = 0 by associating another binary latent variable ξn` (called exposure variable). These exposure variables will be incorporated in a latent factor model (Sec. 2.1) for the label matrix Y and are jointly learned along with the rest of the model parameters."
  }, {
    "heading": "2.1. An Exposure-based Latent Factor Model for the Binary Label Matrix",
    "text": "We model the binary label matrix Y using a latent factor model. Specifically, we assume that each training example n = 1, . . . , N is associated with a latent factor un ∈ RK and each label ` = 1, . . . , L is associated with a latent factor v` ∈ RK . We further condition un on the feature vector xn ∈ RD of example n by as-\nsuming that the prior distribution of un is conditioned on xn, as p(un|xn) = N (un|Wxn, λ−1u IK). Here, W = [w1, . . . ,wK ]\n> ∈ RK×D which denotes the matrix of regression weights that map the feature vectorxn to the mean of the Gaussian prior on un. We further assume a zeromean Gaussian prior p(v`) = N (v`|0, λ−1v IK) on label latent factors v`, ` = 1, . . . , L. Note that, although we do not consider it here, our model can also be easily extended to incorporate label features (if available) by conditioning Gaussian prior on v` on those label features, in the same manner we condition the prior on un on input features.\nThe complete generative story for each label yn` of the binary label matrix Y is given by\nun|xn ∼ N (un|Wxn, λ−1u IK) (1) v` ∼ N (v`|0, λ−1v IK) (2) ξn` ∼ Bernoulli(µn`) (3)\nyn` ∼\n{ Bernoulli ( yn`|σ(u>n v`) ) , if ξn` = 1\nδ0, if ξn` = 0 (4)\nwhere σ(z) = 1/(1 + exp(−z)) denotes the logistic function. Note that we have associated a binary exposure latent variable ξn` with each label yn` such that ξn` = 0 implies that yn` is 0 because it is missing (not exposed), and ξn` = 1 implies that yn` is exposed (and could be 0 or 1 depending on the outcome of the Bernoulli draw). In Eq. 4, δ0 denotes a point-mass at zero, which means that, if ξn` = 0, then yn` is zero with probability 1. Otherwise, we draw the observed label yn` from a Bernoulli distribution as yn` ∼ Bernoulli(yn`|σ(u>n v`)). Note that, effectively, each yn` is being modeled using a mixture of two distributions - a Bernoulli with probability given by the sigmoid σ(u>n v`)) and a point-mass at 0.\nyn` ∼ ξn`Bern ( yn`|σ(u>n v`) ) + (1− ξn`)I[yn` = 0] (5)\nNote that the latent variable ξn` decides which of the two distributions from this mixture generates yn`. Figure 1 shows our model in the plate notation. Also note that if yn` = 1 then ξn` = 1 with probability 1 and therefore ξn` only needs to be inferred for entries for which yn` = 0.\nThe generative model specified in Eq (1)-(4) has two additional parameters: W = [w1, . . . ,wK ]> ∈ RK×D which denotes the matrix of regression weights that map each input feature vector xn to the corresponding latent factor un ∈ RK , and a probability parameter µn` ∈ (0, 1) which denotes the probability of the label yn` being exposed (but note that yn` can be 0 or 1, depending on the outcome of Bernoulli(yn`|σ(u>n v`))). We refer to µn` as the exposure probability of label ` for example n.\nWe assume each regression weight vector wk to have a Gaussian prior, i.e., wk ∼ N (wk|0, λ−1w ID). Note that the spherical covariance of this prior can also be replaced by a more flexible diagonal covariance, which will give the model ability to perform feature selection.\nFor the exposure probability µn`, we consider two types of priors. In the first case, we simply assume µn` = µ`, ∀n, which means that the probability that a label ` is observed is the same for all the examples (i.e., the label exposure for the label ` is global, not example specific). In this case, we assume a Beta prior on µ`, i.e., µ` ∼ Beta(α1, α2). In the second case, we assume access to some contexual information (often available in applications such as recommender systems) that we may have for each example-label pair (n, `), in form of some given covariates φn` ∈ RM . Given these covariates, we model the label exposure probability as µn` = σ(β>φn`), where β ∈ RM is a vector of regression coefficients. We assume a Gaussian prior on β, i.e., β ∼ N (β|0, λ−1β IM )"
  }, {
    "heading": "3. Inference",
    "text": "Although the generative model specified in Eq. 1-4 is not readily conjugate because the logistic-Bernoulli likelihood is not conjugate to the Gaussian prior on the latent factors, we can leverage data-augmentation techniques (Polson et al., 2013) to make the model locally conjugate. This enables us to develop a simple Gibbs sampling algorithm for doing inference in our model. The conjugacy also allows us to design an online expectation maximization (EM) algorithm (Cappé & Moulines, 2009), which enables us to apply our model on large-scale problems.\nWe handle the non-conjugate logistic-Bernoulli likelihood using the Pólya-gamma augmentation technique (Polson et al., 2013), which is based on the following identity\n(exp(ψ)a\n(1 + exp(ψ))b = 2−b exp (κψ) ∫ ∞ 0 exp ( −ωψ2/2 ) p(ω)dω\nwhere κ = a − b/2 and p(ω) = PG(b, 0) denotes the Pólya-gamma distribution (Polson et al., 2013). This identity allows us to write any likelihood of the form\n(exp(ψ)a\n(1+exp(ψ))b (e.g., Bernoulli, binomial, negative-binomial) as a Gaussian distribution, when conditioned on a PG random variable ω|ψ ∼ PG(b, ψ). Specifically, using PG augmentation, we can write the logistic-Bernoulli likelihood\nfrom Eq. 4 as a Gaussian when conditioned on ωn` ∼ PG(1,u>n v`). In particular, ψn` = u > n v`, conditioned on ωn`, becomes a Gaussian p(ψn`|ωn`) ∝ exp ( κn`ψn` − 1\n2 ωn`ψ\n2 n`\n) (6)\nwhere κn` = yn` − 0.5. This likelihood with the Gaussian priors on the latent factors un and v` results in Gaussian posteriors onun and v`. When doing EM, this also leads to subproblems that are like least square regression problems."
  }, {
    "heading": "3.1. Gibbs Sampling",
    "text": "Using the PG augmentation, we can derive the posterior distributions of all the latent variables in our model, and perform Gibbs sampling for doing inference in our model. Due to conjugacy, the inference updates are straightforward to derive as are summarized below.\nSampling ξn`: Note that if yn` = 1 then ξn` = 1 with probability one, and therefore need not be inferred. For yn` = 0, we sample ξn` from the posterior\np(ξn` = 1|.) ∝ µn`σ(−u>n v`) (7) p(ξn` = 0|.) ∝ (1− µn`)× 1 (8)\nSampling µn`: For the case when µn` = µ`, ∀n, with Beta(α1, α2) prior on each µ`, the posterior will be\np(µn`|.) = Beta(α1 + N∑ n=1 ξn`, α2 +N − N∑ n=1 ξn`) (9) Note that, if we parameterize each µn` as µn` = σ(β>φn`) where φn` is the interaction feature vector for the examplelabel pair, and the regresssion weight β is assumed to have a Gaussian prior, the model is not conjugate. However, using the PG augmentation allows us to easily derive a closed-form Gaussian posterior for β.\nSampling un: Given the PG variables Ωn,: = {ωn`}L`=1 and the other latent variables, the posterior of un will be un ∼ N (un|µun ,Σun) where the covariance is given by Σun = ( ∑L `=1 ξn`ωn`v`v > ` + λuIK)\n−1 and the mean is given by µun = Σun( ∑L `=1 ξn`κn`v` + λuWxn). Note that if a label ` is inferred as not exposed for example n, i.e., ξn` = 0, it does not contribute to the update of un.\nSampling v`: Given Ω:,` = {ωn`}Nn=1 and the other latent variables, the posterior v` will be v` ∼ N (v`|µv` ,Σv`) where covariance Σv` = ( ∑N n=1 ξn`ωn`unu > n +λvIK) −1\nand the mean µv` = Σv`( ∑N n=1 ξn`κn`un). Note that if an example n is inferred as not exposed to label `, i.e., ξn` = 0, it does not contribute to the update of v`.\nSampling W: Each row {wk}Kk=1 of the regression weights matrix W = [w1, . . . ,wK ]> ∈ RK×D will have a Gaussian posterior given by wk ∼ N (wk|µwk ,Σwk) where covariance Σwk = (X >X + λwID) −1, the mean µwk = Σwk(X >U), and U = [u1, . . . ,uN ] ∈ RK×N ."
  }, {
    "heading": "3.2. Scalable Inference via EM and Online EM",
    "text": "Although the Gibbs sampler (Sec. 3.1) is easy to derive and implement in practice, sampling tends to be slow in practice and convergence may be slow. We therefore present an online expectation maximization algorithm (Cappé & Moulines, 2009) for doing efficient inference in our model. We first show the batch EM updates for our model parameters and then describe the online EM algorithm which can process the training data in small mini-batches of examples, and results in faster convergence in practice."
  }, {
    "heading": "3.2.1. THE EM ALGORITHM",
    "text": "The EM algorithm for our model alternates between computing the expectations of the local latent variables, namely the Pólya-gamma variables {ωn`} and the binary exposure latent variables {ξn`} in the E step, and then using these expectations to estimate the other model parameters un, v`, W, and exposure probabilities {µn`} in the M step.\nThe E Step: The E step involves computing the expectations of the latent variables {ωn`} and {ξn`}, given the current values of the other model parameters un, v`, W, and µn` estimated in the previous M step. The E step update equations are given below:\n• Expectations of Pólya-gamma variables {ωn`}, ∀n, ` are known to be available in closed form (Scott & Sun, 2013), and are given by\nηn` = E[ωn`|ψn`] = 1\n2ψn` tanh ( ψn` 2 ) (10)\nwhere ψn` = u>n v` is computed using the estimates of un and vm from the previous M step. • Expectations of each of the binary exposure variables ξn`, ∀n, `, are given by\npn` = E[ξn`|ψn`] = µn`σ(−ψn`)\nµn`σ(−ψn`) + (1− µn`) (11)\nThe M Step: Given the expectations of the latent variables computed in the E step, the M step maximizes the following expected complete data log-likelihood plus logprior terms, which we denote as Q(U,V,W,µ), where U = {un}Nn=1, V = {v`}L`=1, W, and µ = {µn`}, ∀n, `\nQ(U,V,W,µ) = − 1\n2 ∑ n,` pn` (κn` − ηn`u>n v`) 2 ηn`\n+ ∑ n,` log Bernoulli(pn`|µn`)− λu N∑ n=1 ||un −Wxn||2 − λv L∑\n`=1 ||v`||2 − λw||W||2 + ∑ n,` log Beta(µn`|α1, α2) (12)\nNote that the first term in the objective function given in Eq. 12 is due to the logistic likelihood transformed into a Gaussian (using PG augmentation). This term is akin to a weighted least squares objective where each label being\nassociated with a weight pn` = E[ξn`|ψn`]. Intuitively, in the first term, the contribution of each label yn` to the loglikelihood gets modulated based on its expected exposure.\nMaximizing Q(U,V,W,µ) w.r.t. each of the model parameters U,V,W,µ, fixing the rest, yields closed-form updates for each of these. The updates are as follows: • Estimating each of the latent factors {un}Nn=1 is a\nweighted ridge-regression problem with solution\nun = Σun ( L∑ `=1 pn`κn`v` + λuWxn ) (13)\nwhere Σun = ( ∑L `=1 pn`ηn`v`v > ` + λuIK)\n−1. Note that the updates for {un}Nn=1 are all independent of each other and are easily parallelizable.\n• Estimating each of the label latent factors {v`}L`=1 is a weighted ridge-regression problem with solution\nv` = Σv` ( N∑ n=1 pn`κn`un ) (14)\nwhere Σv` = (∑N n=1 pn`ηn`unu > n + λvIK )−1 . Again, note that the updates for {vn}L`=1 are all independent of each other and are easily parallelizable.\n• Estimating the regression weight matrix W is equivalent to solving a vector-valued linear regression problem un ≈Wxn, ∀n, with the following updates\nW> = (X>X + λwID) −1(X>U) (15)\nNote that solving Eq. (15) exactly requires inverting a D × D matrix which will be expensive for large D. However, the EM algorithm does not require solving for W exactly in each M step. We therefore solve for W efficient using gradient based methods, such as conjugate-gradient (CG) method (Bertsekas, 1999), which allows us to also leverage the sparsity in the feature matrix X. Typically, a small number of CG iterations are sufficient in practice.\n• Given pn` from the E step, the updates for µn` for the case when µn` = µ`, ∀n, is simply the MAP solution\nµ` = α1 +\n∑N n=1 pn` − 1\nα1 + α2 +N − 2 (16)\nFor the other case when each µn` in modeled as µn` = σ(β>φn`) with a Gaussian prior on β, estimating β reduces to solving a regression problem with the training data being {φn`, pn`}, ∀n, `, where φn` is the given feature vector for the input-label pair n, ` and pn` is estimated in the E step. Ignoring the prior term (equivalent to `2 regularizer on β), we can estimate β iteratively using gradient-descent updates\nβ = β − τ NL ∑ n,` (σ(β>φn`)− pn`)φn` (17)\nwhere τ denotes the learning rate."
  }, {
    "heading": "3.2.2. ONLINE EM",
    "text": "The EM algorithm described in Section 3.2.1 is more efficient than the Gibbs sampler described in Section 3.1. It is also highly parallelizable since the updates for {u}Nn=1 and {v`}L`=1 can be easily parallelized, and solve for W efficiently using CG updates. However, it is a batch procedure and requires going over the entire training data in every iteration. For large-scale multi-label learning problems, which are characterized by large N , D, and L, the batch setting may not be feasible in practice, especially when having access to moderate computational resources and storage.\nWe therefore present an efficient online version of the EM algorithm for our model which allows it to scale up to massive-sized data sets even on machines with moderate hardware. As we show in our experiments, this enables us to apply our model to be run efficiently on massive data sets (e.g., one of the data sets we experiment with has more than 600k examples with about 50k features per example) even on a standard laptop with very moderate hardware.\nThe online EM algorithm works by maintaining sufficient statistics of all the model parameters and updates these sufficient statistics with every mini-batch of data. For each mini-batch of training examples, the E step computes the relevant expectations associated with these observations and then uses the expectations to update the sufficient statistics of the parameters to be estimated in the M step.\nFor example, noting that the sufficient statistics for updating the label latent factors v` = A−1b are given by A =∑N n=1 pn`ηn`unu > n +λvIK and b = ∑N n=1 pn`κn`un, we can update A and b using a small mini-batch containingNb examples as {(xn,yn)} Nb n=1 as follows\nA(t+1) = (1− γt)A(t) + γtA(new) (18) b(t+1) = (1− γt)b(t) + γtb(new) (19)\nwhere A(new) = ( ∑Nb n=1 pn`ηn`unu > n + λvIK), and\nb(new) = ∑Nb n=1 pn`κn`un are computing using only the current mini-batch. The sufficient statistics of the other model parameters can also be updated in the same manner. Here γt is a decaying learning rate (or a forgetting factor), which also acts as a trade-off between the contribution from the old sufficient statistics computed thus far and the sufficient statistics contribution from the new minibatch of data. We set γt = (a0 + t)− with a0 = 1 and to be close to 0.5 (Cappé & Moulines, 2009)."
  }, {
    "heading": "3.2.3. PREDICTION",
    "text": "Given a new test input x∗, we first predict its latent factor u∗ ∈ RK as Wx∗ and then predict each entry of its label vector y∗ as E[y∗`|u∗,v`] = σ(u>∗ v`). If we are only interested in the top few labels, fast search methods such as maximum inner product search (Fraccaro et al., 2016) can be used to reduce the computational cost at test time."
  }, {
    "heading": "4. Related Work",
    "text": "A prominent line of work on multi-label learning has been based on models that learn a low-dimensional embedding of the label vectors (Chen & Lin, 2012; Yu et al., 2014; Rai et al., 2015; Bhatia et al., 2015). Note that this amounts to assuming that the label matrix is low-rank.\nSince many real-world data sets have a large number of rare labels, sometimes the low-rank assumption may not be appropriate. To address this issue, (Bhatia et al., 2015) proposed a method which assumes the label matrix to be locally low-rank. One way to impose this assumption is to learn embeddings that only try to preserve distances in a small neighborhood of each example. Another approach to handle the rare labels is to assume that the label matrix is a sum of a low-rank and a sparse matrix (Xu et al., 2016).\nNote that our latent factor model is equivalent to imposing a low-rank assumption on the label matrix, and is therefore similar in spirit to the label-embedding approaches. However, unlike the existing label-embedding based approaches, our generative framework has a principled mechanism to handle/infer the unobserved labels. Moreover, none of the existing label-embedding methods can work in online fashion, and scaling up these methods to largescale problems requires large computational resources. In addition, our model readily allows incorporating the label features (if available) by a simple modification to the prior on the label latent factors.\nApart from the label-embedding based multi-label learning methods, tree-based methods for multi-label learning (Agrawal et al., 2013; Prabhu & Varma, 2014; Jain et al., 2016) are also popular due to being fast at test time, especially when the number of labels is large. However, these models usually have high training costs and cannot be trained easily in an online fashion, unlike our model. On the other hand, for faster predictions at test time, our framework model can easily be adapting by replacing the Gaussian prior on the label latent factors v` by a von MisesFisher prior (Fraccaro et al., 2016), which naturally facilitates using maximum inner-product search techniques, without the requirement of any post-processing.\nAmong other models to address the missing labels problem in multi-label learning, recently, (Kanehira & Harada, 2016) proposed a ranking based framework for learning from positive and unlabeled data in the context of multilabel learning. Although this is similar in spirit to our model in terms of not treating the unobserved labels as zeros, the approach in (Kanehira & Harada, 2016) is fundamentally different than ours. Moreover, their setting is not amenable to online learning, nor does it leverage the lowrank structure of label matrices with a huge number of labels. Other approaches that try to handle missing labels in-\nclude (Bucak et al., 2011) which uses group LASSO adaptation of a multi-label ranking objective, and (Kong et al., 2014), which learns a model using a positive and unlabeled (PU) stochastic gradient descent procedure. However, it works in batch setting, uses stacking to leverage label correlations, and does not scale to large number of labels.\nOne-class matrix factorization (OCMF) is also an approach (Yu et al., 2017) to solve the missing labels problem by assigning different (but fixed) weights to the ones and zeros. In contrast to this method, our generative framework can learn the weight for each label by modeling these weights as latent variables. In another recent work, (Liang et al., 2016) proposed an exposure model for recommender system problems posed as matrix factorization of implicit feedback data. Their approach of modeling the exposure similar in spirit to our framework.\nSome of the early works on generative models for multilabel learning problems include models specifically designed for image annotation problems (Barnard et al., 2003; Feng et al., 2004). Other recent attempts on doing multilabel learning in more general problem settings include models such as Bayesian compressive sensing (Kapoor et al., 2012) and multi-label learning using Bayesian nonnegative matrix factorization (Rai et al., 2015). However, these models do not have a mechanism to distinguish between unobserved and negative labels, have complicated inference, and do not scale to large-scale problems.\nOur generative framework is also amenable for various interesting extensions. For example, it can be be extended to a mixture of latent factor models, which can handle the situation when the label matrix is not low-rank but a mixture of several low-rank matrices. Note that such an extension would be a fully generative counter-part of the model in (Bhatia et al., 2015) which learns a locally low-rank model but has to rely on an ad-hoc clustering step beforehand, which is known to be unstable in practice (Bhatia et al., 2015). Another nice aspect of our framework is that is naturally allows active learning (Kapoor et al., 2012; Vasisht et al., 2014) where we can selectively ask for most informative labels for an unannotated example. Moreover, our framework is flexible and inference in our model can be performed in a fully Bayesian manner (e.g., MCMC or variational inference) as well as fast point estimation methods such as (online) EM, that we used in this work.\nTo summarize, our generative framework offers a flexible way to model the label generation mechanism for real-world multi-label data sets, which most of the existing models currently lack. We can model label missingness/observability rigorously under our framework and infer the model parameters easily using a simple inference procedure. Moreover, the simplicity of the inference procedure makes it easy to design scalable inference algorithms,\nsuch as online EM for our model, which enables updating the model whenever fresh training data is available. This is in contrast to some of the other state-of-the-art multi-label learning methods, which although scalable (Bhatia et al., 2015; Prabhu & Varma, 2014; Jain et al., 2016), are not suitable to be applied in such online settings."
  }, {
    "heading": "5. Experiments",
    "text": "We evaluate our framework on a number of benchmark data sets and compare it with several state-of-the-art methods. Our baselines include both label-embedding methods as well as tree-based methods. The statistics of data sets we use in our experiments are summarized in Table 1.\nWe report both quantitative results (in terms of label prediction accuracies) as well as some qualitative results, namely looking at the relationship of empirical label frequencies and label exposure. Note that the label frequency for a given label denotes how many examples had this label as 1, while label exposure µ` ∈ (0, 1) in general refers to how popular the label ` is.\nIn our experiments, we compare with the following stateof-the-art baselines.\n• LEML: This is a low-rank embedding based multilabel learning model (Yu et al., 2014). LEML assumes the label matrix Y to be modeled as Y ≈ UV where U = XW. LEML considers various types of loss functions such as squared loss, logistic loss, hinge loss, etc. Interestingly, note that LEML with logistic loss can be seen as a special non-probabilistic case of our model when also considering λu → ∞, and the label exposure model turned off.\n• BCS: Bayesian Compressive Sensing (BCS) is a generative model (Kapoor et al., 2012) for the label vector. It assumes a compressive sensing model for the label vectors and is essentially a low-rank model.\n• FastXML: This is a fast tree-based multi-label learning model which uses an ensemble of trees (Prabhu & Varma, 2014).\n• PfasterXML: This is an extension of FastXML and uses propensity-weighted scores to improve performance on rare labels (Jain et al., 2016).\n• PD-Sparse: This model takes a different approach as compared to label-embedding methods and uses a margin-maximizing loss for the multi-label learning problem (Yen et al., 2016).\nFor the baselines, the reported results are either obtained using publicly available implementations (with the recommended hyperparameter settings), or the publicly known best results. We refer to our model as GenEML (for Generative Exposure-based model for Multi-label Learning)\nHyperparameter Settings: For our model, we set the hyperparameters λu and λv to 0.001, which works well on all the data sets we experimented with. We select the other two hyperparameters λw and K (number of latent factors) using cross-validation. On small-/medium-scale data, both EM and online EM perform comparably and we only report the results using online EM. On large data sets, we only use online EM. On the small and medium-scale data, we however also show a separate experiment comparing EM and online EM for our model in terms of convergence speed versus accuracy. For the conjugate gradient (CG) method used by the M step of our inference algorithm, we run 5 iterations, which was found to be sufficient. For online EM, for each data set, we use mini-batch sizes of 1024 and 4096 and report the one which gives better results."
  }, {
    "heading": "5.1. Quantitative Results",
    "text": ""
  }, {
    "heading": "5.1.1. BENEFIT OF EXPOSURE MODEL",
    "text": "In our first experiment, we assess the benefit of using the exposure model. For this, we apply our model with and without exposure on a synthetic data set. For this experiment, we generate a synthetic data set with N=500, D=100, and L=20 and use varying degrees of exposure probabilities µ` ∈ {0.01, 0.05, 0.1, 0.3, 0.5, 0.9} for the different labels ` = 1, . . . , 20. We also create a test set with 500 test examples.\nThe results are shown in Table 2. As the results show, our model with exposure turned on outperforms the model when the exposure is turned off. This clearly demonstrate the benefit of the exposure model when a significant fraction of labels are missing (i.e., not exposed). Our model also outperforms LEML which does not have a mechanism to model label exposure."
  }, {
    "heading": "5.1.2. PREDICTION ACCURACIES",
    "text": "In our next set of experiments, in Table 3 we compare our model (with exposure on) with the other baselines, in terms of Precision@1, Precision@3, and Precision@5 scores. As Table 3 shows, our model outperforms the other baselines in most of the cases, except for the RCV and Wikipedia data, on which our model is outperformed by LEML and/or PfasterXML. Note, however, that these stateof-the-art baselines use batch inference methods whereas we only ran our model in the online setting on a moderate 4 core processor with 8GB RAM. Moreover, our results may further improve with a more careful hyperparameter tuning (including selection of minibatch size). The point of the large-scale data experiment was to mainly show that the our model can be feasibly run on such large-scale data sets, on standard machines with moderate computational resources. Most of the other existing models for multi-label learning are infeasible to run under such restrictive settings."
  }, {
    "heading": "5.1.3. BATCH EM VS ONLINE EM",
    "text": "The online version of our EM algorithm is scalable and faster than its batch counterpart. Fig 2 shows that online EM converges faster and to a precision score which is very similar to the batch EM on Bibtex and Mediamill datasets.\nFurthermore, online inference is also more effecient, storage-wise, due the need of maintaining just the sufficient statistics as in Eq 19 for the updates of each latent factor un and v`. For very large datasets, the size of the the sufficient statistics (a D ×D covariance matrix) for updating the regression weight matrix W might not be feasible to store and update. Therefore, we use cheap, first-order gradient based updates for finding an approximate solution to the update equation of W in each iteration of the EM algorithm (note that we need not solve for W exactly; the EM algorithm just requires a few steps of updates for W in the M step). This further reduces the memory requirement of our model, while also speeding up inference due to faster computation of gradients as compared to CG updates."
  }, {
    "heading": "5.2. Qualitative Results",
    "text": "Finally, we do some qualitative analyses of our model’s behavior. We investigate whether the global frequency of a label necessarily correlates to its exposure probability.\nWhile it may be the case for some data sets where high label frequency implies a high inferred label exposure probability (e.g., see Fig. 3 for Bibtex and Mediamill data), it need not be the case with other data sets. For example, for Movielens data, each user-movie (example-label) pair has an some context information (user and movie features) available for it. As we show in Fig 4, the inferred exposure probability (which depends on the context features) of the same movie (label) indeed turns out to be different for different users (examples).\nFig. 4 shows the plot of inferred exposure probabilities µnl for two users (one female, one male) plotted against the label frequencies (movie popularities).\nAs Fig. 4 shows, our model infers that, a popular movie (shown in red dot in Fig 4) has a high exposure probability for the left user (Female, 25, Healthcare/Doctor) while it has a low exposure probability for the right user (Male, 35, artist). This example illustrates that a high label frequency does not necessarily imply a high exposure probability, which can be context (user in this case) dependent."
  }, {
    "heading": "6. Conclusion",
    "text": "We presented a flexible and scalable generative framework for multi-label learning. Our framework is based on a latent\nfactor model for the label matrix and does not assume that the zeros in the label matrix are necessarily negative labels. We use a set of label exposure latent variables to model this, and infer these exposure probabilities from data. Incorporating these latent variables leads to improve multi-label classification accuracies, and also enables doing interesting qualitative analyses. Our model admits a simple inference procedure which can be implemeted using Gibbs sampling or EM. We further develop a highly scalable online EM algorithm for performing inference in our model, which allows our model to be applied on large-scale data sets, even on standard machines with moderate hardware. The generative framework makes it easy to extend our model in many interesting ways. For example, it can be extended to a mixture of latent factor models, which will allow handling the cases where a single low-rank model does not adequately capture the structure of the label matrix.\nAcknowledgements: PR acknowledges support from Extreme Classification research grant from Microsoft Research India, DST-SERB Early Career Research Award, Dr. Deep Singh and Daljeet Kaur Fellowship, and Research-I Foundation, IIT Kanpur."
  }],
  "year": 2017,
  "references": [{
    "title": "Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages",
    "authors": ["Agrawal", "Rahul", "Gupta", "Archit", "Prabhu", "Yashoteja", "Varma", "Manik"],
    "venue": "In WWW,",
    "year": 2013
  }, {
    "title": "DiSMEC- distributed sparse machines for extreme multi-label classification",
    "authors": ["R. Babbar", "B. Schölkopf"],
    "venue": "In WSDM,",
    "year": 2017
  }, {
    "title": "Sparse local embeddings for extreme multilabel classification",
    "authors": ["Bhatia", "Kush", "Jain", "Himanshu", "Kar", "Purushottam", "Varma", "Manik", "Prateek"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Multi-label learning with incomplete class assignments",
    "authors": ["Bucak", "Serhat Selcuk", "Jin", "Rong", "Jain", "Anil K"],
    "venue": "In CVPR,",
    "year": 2011
  }, {
    "title": "On-line expectation– maximization algorithm for latent data models",
    "authors": ["Cappé", "Olivier", "Moulines", "Eric"],
    "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
    "year": 2009
  }, {
    "title": "Feature-aware label space dimension reduction for multi-label classification",
    "authors": ["Chen", "Yao-Nan", "Lin", "Hsuan-Tien"],
    "venue": "In NIPS,",
    "year": 2012
  }, {
    "title": "Adios: Architectures deep in output space",
    "authors": ["Cissé", "Moustapha", "Al-Shedivat", "COM Maruan", "Bengio", "Samy"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "Multiple bernoulli relevance models for image and video annotation",
    "authors": ["SL Feng", "Manmatha", "Raghavan", "Lavrenko", "Victor"],
    "venue": "In CVPR,",
    "year": 2004
  }, {
    "title": "Indexable probabilistic matrix factorization for maximum inner product search",
    "authors": ["Fraccaro", "Marco", "Paquet", "Ulrich", "Winther", "Ole"],
    "venue": "In AAAI,",
    "year": 2016
  }, {
    "title": "Multilabel learning: A review of the state of the art and ongoing research",
    "authors": ["Gibaja", "Eva", "Ventura", "Sebastián"],
    "venue": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery,",
    "year": 2014
  }, {
    "title": "A tutorial on multilabel learning",
    "authors": ["Gibaja", "Eva", "Ventura", "Sebastián"],
    "venue": "ACM Comput. Surv.,",
    "year": 2015
  }, {
    "title": "Collaborative filtering for implicit feedback datasets",
    "authors": ["Hu", "Yifan", "Koren", "Yehuda", "Volinsky", "Chris"],
    "venue": "In ICDM,",
    "year": 2008
  }, {
    "title": "Extreme multi-label loss functions for recommendation, tagging, ranking & other missing label applications",
    "authors": ["Jain", "Himanshu", "Prabhu", "Yashoteja", "Varma", "Manik"],
    "year": 2016
  }, {
    "title": "Multi-label ranking from positive and unlabeled data",
    "authors": ["Kanehira", "Atsushi", "Harada", "Tatsuya"],
    "venue": "In CVPR,",
    "year": 2016
  }, {
    "title": "Multilabel classification using bayesian compressed sensing",
    "authors": ["Kapoor", "Ashish", "Viswanathan", "Raajay", "Jain", "Prateek"],
    "venue": "In NIPS,",
    "year": 2012
  }, {
    "title": "Large-scale multi-label learning with incomplete label assignments",
    "authors": ["Kong", "Xiangnan", "Wu", "Zhaoming", "Li", "Li-Jia", "Zhang", "Ruofei", "Yu", "Philip S", "Hang", "Fan", "Wei"],
    "venue": "In SDM,",
    "year": 2014
  }, {
    "title": "Modeling user exposure in recommendation",
    "authors": ["Liang", "Dawen", "Charlin", "Laurent", "McInerney", "James", "Blei", "David M"],
    "venue": "In WWW,",
    "year": 2016
  }, {
    "title": "Bayesian inference for logistic models using pólya–gamma latent variables",
    "authors": ["Polson", "Nicholas G", "Scott", "James G", "Windle", "Jesse"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2013
  }, {
    "title": "FastXML: a fast, accurate and stable tree-classifier for extreme multi-label learning",
    "authors": ["Prabhu", "Yashoteja", "Varma", "Manik"],
    "venue": "In KDD,",
    "year": 2014
  }, {
    "title": "Large-scale bayesian multi-label learning via topicbased label embeddings",
    "authors": ["Rai", "Piyush", "Hu", "Changwei", "Henao", "Ricardo", "Carin", "Lawrence"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Expectation-maximization for logistic regression",
    "authors": ["Scott", "James G", "Sun", "Liang"],
    "venue": "arXiv preprint arXiv:1306.0040,",
    "year": 2013
  }, {
    "title": "Active learning for sparse bayesian multilabel classification",
    "authors": ["Vasisht", "Deepak", "Damianou", "Andreas", "Varma", "Manik", "Kapoor", "Ashish"],
    "venue": "In KDD,",
    "year": 2014
  }, {
    "title": "CNN-RNN: A unified framework for multi-label image classification",
    "authors": ["Wang", "Jiang", "Yang", "Yi", "Mao", "Junhua", "Huang", "Zhiheng", "Chang", "Xu", "Wei"],
    "year": 2016
  }, {
    "title": "Robust extreme multilabel learning",
    "authors": ["Xu", "Chang", "Tao", "Dacheng", "Chao"],
    "venue": "In KDD,",
    "year": 2016
  }, {
    "title": "PD-sparse: A primal and dual sparse approach to extreme multiclass and multilabel classification",
    "authors": ["Yen", "Ian EH", "Huang", "Xiangru", "Zhong", "Kai", "Ravikumar", "Pradeep", "Dhillon", "Inderjit S"],
    "year": 2016
  }, {
    "title": "Large-scale multi-label learning with missing labels",
    "authors": ["Yu", "Hsiang-Fu", "Jain", "Prateek", "Kar", "Purushottam", "Dhillon", "Inderjit S"],
    "venue": "In ICML,",
    "year": 2014
  }, {
    "title": "A unified algorithm for one-class structured matrix factorization with side information",
    "authors": ["Yu", "Hsiang-Fu", "Huang", "Hsin-Yuan", "Dhillon", "Inderjit S", "Lin", "Chih-Jen"],
    "venue": "In AAAI,",
    "year": 2017
  }],
  "id": "SP:9988f2b32152991b7e930fbbb61b48bbd743970c",
  "authors": [{
    "name": "Vikas Jain",
    "affiliations": []
  }, {
    "name": "Nirbhay Modhe",
    "affiliations": []
  }, {
    "name": "Piyush Rai",
    "affiliations": []
  }],
  "abstractText": "We present a scalable, generative framework for multi-label learning with missing labels. Our framework consists of a latent factor model for the binary label matrix, which is coupled with an exposure model to account for label missingness (i.e., whether a zero in the label matrix is indeed a zero or denotes a missing observation). The underlying latent factor model also assumes that the low-dimensional embeddings of each label vector are directly conditioned on the respective feature vector of that example. Our generative framework admits a simple inference procedure, such that the parameter estimation reduces to a sequence of simple weighted leastsquare regression problems, each of which can be solved easily, efficiently, and in parallel. Moreover, inference can also be performed in an online fashion using mini-batches of training examples, which makes our framework scalable for large data sets, even when using moderate computational resources. We report both quantitative and qualitative results for our framework on several benchmark data sets, comparing it with a number of state-of-the-art methods.",
  "title": "Scalable Generative Models for Multi-label Learning with Missing Labels"
}