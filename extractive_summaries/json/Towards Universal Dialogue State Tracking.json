{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2780–2786 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n2780"
  }, {
    "heading": "1 Introduction",
    "text": "A task-oriented spoken dialogue system (SDS) is a system that can continuously interact with a human to accomplish a predefined task through speech. It usually consists of three modules: input, output, and control. The control module is also referred to as dialogue management (Young et al., 2010; Yu et al., 2014). It has two missions: dialogue state tracking (DST) and decision making. At each dialogue turn, a state tracker maintains the internal state of the system based on the information received from the input module. Then a machine action is chosen based on the dialogue state according to a dialogue policy to direct the dialogue (Chen et al., 2018).\nThe dialogue state is an encoding of the machine’s understanding of the whole conversation. Traditionally, it is usually factorized into three distinct components (Young et al., 2013): the user’s goal, the user’s action, and the dialogue history.\nAmong them, the user’s goal is most important, which is often simply represented by slot-value pairs. In this paper, we focus on the tracking of the user’s goal.\nRecently, the dialogue state tracking challenges (DSTCs) (Williams et al., 2013; Henderson et al., 2014a,d) are organized to provide shared tasks for comparing DST algorithms. A various of models are proposed, e.g. rule-based models (Wang and Lemon, 2013; Sun et al., 2014a; Yu et al., 2015, 2016; Sun et al., 2016b), generative statistical models (Thomson and Young, 2010; Young et al., 2010, 2013), and discriminative statistical models (Lee and Eskenazi, 2013; Lee, 2013; Sun et al., 2014b; Xie et al., 2015; Sun et al., 2016a; Xie et al., 2018). And the state-of-the-art one is the deep learning-based approach. However, most of these models have some limitations. First, some models can only work on a fixed domain ontology, i.e. the slots and values are defined in advance, and can’t change dynamically. However, this is not flexible in practice (Xu and Hu, 2018). For example, in the tourist information domain, new restaurants or hotels are often added, which results in the change of the ontology. Second, in many approaches the models for every slot are different. Therefore, the number of parameters is proportional to the number of slots. Third, some models extract features based on text delexicalisation (Henderson et al., 2014b), which depends on predefined semantic dictionaries. In large scale domains, it’s hard to manually construct the semantic dictionaries for all slots and values (Mrkšić et al., 2017).\nTo tackle these challenges, here we propose a universal dialogue state tracker, StateNet. For each state slot, StateNet generates a fixed-length representation of the dialogue history, and then compares the distances between this representation and the value vectors in the candidate set for making prediction. The set of candidate values\ncan change dynamically. StateNet only needs the following three parts of the data: (1) the original ASR information (or the transcript) of the user utterance; (2) the information of the machine act; (3) the literal names of the slots and the values. The manually-tagging of the user utterance is not needed as a part of the data. StateNet shares parameters among all slots, through which we can not only transfer knowledge among slots but also reduce the number of parameters."
  }, {
    "heading": "2 StateNet: A Universal Dialogue State Tracker",
    "text": "For each dialogue turn, StateNet takes the multiple n-gram user utterance representation, rnu, the n-gram machine act representation, rna , the value set, Vs, and the word vector of the slot, s, as the input. Then StateNet applies the Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) to track the inner dialogue states among the dialogue turns. And for each slot, StateNet outputs a corresponding probability distribution, ps, over the set of possible values, Vs, at each of the dialogue turn,\nps = StateNet(rnu, r n a , s,Vs).\nThe general model architecture is shown in Figure 1."
  }, {
    "heading": "2.1 User Utterance Representation",
    "text": "At the t-th dialogue turn, the user utterance, Ut, may consist of l number of words, ui, with their corresponding word vectors, ui, (1 ≤ i ≤ l). The user utterance may also have its corresponding mbest ASR hypotheses with the normalized confidence scores (Chen et al., 2017), qj ,(1 ≤ j ≤ m).\nIn this case, we can calculate the weighted word vectors, u′i,\nu′i = m∑ j=1 qjui,j ,\nwhere ui,j represents the word vector ui presented at the j-th ASR hypothesis, and the zero vectors are padded at the end of all the hypotheses that are shorter than the longest one to have a same length of the utterance.\nBased on the weighted word vectors generalizing the information from the ASR hypothesis, we can then construct the n-gram weighted word vectors, as proposed by Mrkšić et al. (2017),\nu′ n i = u ′ i ⊕ ...⊕ u′i+n−1,\nwhere⊕ is the concatenation operator between the word vectors.\nAn n-gram user utterance representation is then constructed through a sum of the n-gram weighted word vectors,\nrnu = l−n+1∑ i=1 u′ n i ."
  }, {
    "heading": "2.2 Multi-scale Receptors Layer",
    "text": "For each gram k of the user utterance representation, rku, (1 ≤ k ≤ n), the Multi-scale Receptors Layer has c number of linear neural networks\n(with the same number of neurons, Nc). Each of them takes the representation as input and is expected to work as the specialized receptor to amplify the signals from some of the word vectors in the utterance representation,\nr̂ku = ⊕cj=1(W j kr k u + b j k),\nwhere Wjk means the weight of the j-th linear layer, bjk means the corresponding bias, and ⊕ is the concatenation operator between the neurons of these linear layers. Note that each receptor does not necessarily has to be a single linear neural network and can be sophisticated with multiple layers and non-linearity for better detection performance. Here we only use the linear layer to provide a baseline of this kind of structure design.\nThese c number of linear layers (or receptors) for different grams (or scales) of the representation r̂ku is then summed together to be layer-normalized (Ba et al., 2016). After that, the ReLU activation function is applied, followed by a linear layer with the size Nc that maps all the receptors to a user feature vector, fu,\nfu = Linear(ReLU(LayerNorm( n∑\nk=1\nr̂ku)))."
  }, {
    "heading": "2.3 Machine Act Representation",
    "text": "We represent the machine act in the m order ngram of bag of words, rma , based on the vocabularies generalized from the machine acts in the training set of a given data set. The machine act feature, fa, is then simply generated through a linear layer of size Nc with the ReLU activation function,\nfa = ReLU(Linear(rma ))."
  }, {
    "heading": "2.4 Slot Information Decoding",
    "text": "Since a slot, e.g. area or food, is usually indicated as a word or a short word group, then it can be represented as a single word vector (with multiple word vectors summed together), s. A single linear layer with the size 2Nc is applied to the word vector s, followed by the ReLU non-linear layer,\nfs = ReLU(Linear(s)).\nThe turn-level feature vector, is, is then generated through a point-wise multiplication ⊗ between the slot feature and the concatenation of the user feature and the machine act feature,\nis = fs ⊗ (fu ⊕ fa).\nIn this way, the turn-level feature vector is intended to amplify the large magnitude signals that are from both the user and machine act feature vector and the slot feature vector."
  }, {
    "heading": "2.5 Fixed-length Value Prediction",
    "text": "Given the turn-level feature vector, is, we can now track the dialogue state throughout the dialogue turns by LSTM. For the current turn t, the LSTM takes the is and the previous hidden state, qt−1, as the input. We can then obtain a fixed-length value prediction vector, os, whose length is equal to Nw, i.e. the dimension of the word vectors which are fed into the model,\nos = ReLU(Linear(LSTM(is,qt−1))),\nwhere the linear layer has Nw neurons. In this way, the prediction of the model is independent of the number of the given values, so it is possible for the model to perform parameter sharing among each of the slots. The fixed-length prediction can somehow be interpreted as a word vector that is ready for the calculation of the similarity between the prediction and the true value label."
  }, {
    "heading": "2.6 2-Norm Distance",
    "text": "For a specific semantic slot, since there may be no corresponding value in a given dialogue turn, thus we always add a literally “none” value to the value set for the model to track this state. For the evaluation of the similarity between the prediction and the value, we calculate the 2-Norm distance between the prediction vector and each of the word vectors of the values in the value set. Softmax function is performed with respect to all the negative relative distances to give a distribution of probabilities for the values, vi ∈ Vs,\nps(vi) = Softmax(−||os − vi||),\nwhere vi is the representation vector of vi. If the slot value vi consists of more than one word, vi will then be the summation of all corresponding word vectors. When training the model, we minimize the Cross-Entropy (CE) loss between the output probabilities and the given label.\nStateNet requires the user utterance, the semantic slots, and slot values to be able to be expressed in words and have their corresponding word vectors. We use the fixed word embedding for every word, and do not fine-tune the word embeddings in the model. Since the word embeddings\nare distributed on a fixed-dimension vector space and hold rich semantic information, StateNet may have the ability to track the dialogue state for any new slot or value, as long as the corresponding word embedding can be found. This is the reason why we call the StateNet a universal dialogue state tracker."
  }, {
    "heading": "3 Experiments",
    "text": "Experiments are conducted to assess the performance on joint goal. Two datasets are used by us for training and evaluation. One is the second Dialogue State Tracking Challenge (DSTC2) dataset (Henderson et al., 2014a), and the other is the second version of Wizard-of-Oz (WOZ 2.0) dataset (Wen et al., 2017). Both of them are the conversations between users and a machine system. The user’s goal is to find a suitable restaurant around Cambridge. The ontology of these two datasets is identical, which is composed of three informable slots: food, pricerange and area. The main difference between them is that in WOZ 2.0, users typed instead of using speech directly. This means the users can use far more sophisticated language than they can in the DSTC2, which is a big challenge for the language understanding ability of the model. Thus, it allows WOZ 2.0 to be more indicative of the model’s actual performance since it is immune to ASR errors.\nBased on the model structure as described in Section 2, we implement three kinds of dialogue state tracker. The difference among them lies in the utilization of parameter sharing and parameter initialization.\n• StateNet: It doesn’t have shared parameters among different slots. In other words, three models for three slots are trained separately using RMSProp optimizer, learning rate set to 0.0005. And its parameters are not initialized with any pre-trained model. • StateNet PS: Parameter sharing is con-\nducted among three slots. For each slot in a batch, we infer the model with the slot information and the same dialogue information. The losses are calculated based on the corresponding value set. After each slot is inferred, we back-propagate all the losses and do the optimization. So we just train one model in total using RMSProp optimizer, learning rate set to 0.0005. As a result, the amount of model parameters\nis one third of that of StateNet, which means StateNet PS can significantly save the memory usage during inferring. • StateNet PSI: Parameter sharing is\nconducted within this model, same as StateNet PS, but its parameters are initialized with a pre-trained model. For pre-training, we only allow the model to track one single slot and make predictions on its value set. After the training ends, we save the model parameters and use them to initialize the model parameters for the training of the multi-slot tracking. The pre-trained model with the best performance on the validation set is selected for initialization. Here, we choose the food slot for pre-training since StateNet has the lowest prediction accuracy on the food slot. StateNet PSI is trained using Adam optimizer and learning rate is set to 0.001. Since the model has obtained the basic knowledge from the pre-trained model, then a more aggressive learning process is preferred. Adam with a higher learning rate can help a lot compared to RMSProp optimizer.\nThe hyperparameters are identical for all three models, Nc = 128, Nw = 300, n = 2,m = 3. We use c = 4 for the number of the receptors for each slot, where the number is determined through the grid search. The word embeddings used by us is the semantically specialised Paragram-SL999 vectors (Wieting et al., 2015) with the dimension of 300, which contain richer semantic contents compared to other kinds of word embeddings. Implemented with the MXNet deep learning framework of Version 1.1.0, the model is trained with a batch size of 32 for 150 epochs on a single NVIDIA GTX 1080Ti GPU.\nThe results in Table 1 show the effectiveness of parameter sharing and initialization. StateNet PS outperforms StateNet, and StateNet PSI performs best among all 3 models. It is because the parameter sharing can not only prevent the model diverging from the right learning process but also transfer necessary knowledge among different slots. And the parameter initialization provides the model with the opportunity to gain some basic while essential semantic information at the very beginning since the food slot is the most important and difficult one. Besides, StateNet PSI beats all the mod-\nels reported in the previous literature, whether the model with delexicalisation (Henderson et al., 2014b,c; Rastogi et al., 2017) or not (Mrkšić et al., 2017; Perez and Liu, 2017; Xu and Hu, 2018; Ramadan et al., 2018; Zhong et al., 2018).\nWe also test StateNet PSI with different pre-trained models, as shown in Table 2. The fact that the food initialization has the best performance verifies our selection of the slot with the worst performance for pre-training. This is because the good performance on joint goal requires a model to make correct predictions on all of the slots. A slot on which the model has the worst accuracy, i.e. the most difficult slot, will dramatically limit the overall model performance on the metric of the joint goal accuracy. Thus, the initialization with a model pre-trained on the most difficult slot can improve the performance of the model on its weakness slot and boost the joint goal accuracy, while the initialization of a strength slot may not help much for the overall accuracy but in turn causes the over-fitting problem of the slot itself."
  }, {
    "heading": "4 Conclusion",
    "text": "In this paper, we propose a novel dialogue state tracker that has the state-of-the-art accuracy as well as the following three advantages: 1) the model does not need manually-tagged user utterance; 2) the model is scalable for the slots that need tracking, and the number of the model parameters will not increase as the number of the slots increases, because the model can share parameters among different slots; 3) the model is independent of the number of slot values, which means for a given slot, the model can make the prediction on a new value as long as we have the corresponding word vector of this new value. If there are a great number of values for a certain slot, to reduce the computational complexity, we can utilize a fixed-size candidate set (Rastogi et al., 2017), which dynamically changes as the dialogue goes on. Experiment results demonstrate the effectiveness of parameter sharing & initialization.\nOur future work is to evaluate the performance of our models in the scenario where there are new slots and more unobserved slot values, and to evaluate the domain-transferring ability of our models."
  }, {
    "heading": "Acknowledgments",
    "text": "The corresponding author is Kai Yu. This work has been supported by the National Key Research and Development Program of China (Grant No. 2017YFB1002102) and the China NSFC project (No. 61573241). Experiments have been carried out on the PI supercomputer at Shanghai Jiao Tong University."
  }],
  "year": 2018,
  "references": [{
    "title": "Layer normalization",
    "authors": ["Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E Hinton."],
    "venue": "arXiv preprint arXiv:1607.06450.",
    "year": 2016
  }, {
    "title": "Structured dialogue policy with graph neural networks",
    "authors": ["Lu Chen", "Bowen Tan", "Sishan Long", "Kai Yu."],
    "venue": "Proceedings of the 27th International Conference on Computational Linguistics, pages 1257–1268.",
    "year": 2018
  }, {
    "title": "Confidence measures for ctc-based phone synchronous decoding",
    "authors": ["Zhehuai Chen", "Yimeng Zhuang", "Kai Yu."],
    "venue": "IEEE International Conference on Acoustics, Speech and Signal Processing(ICASSP), pages 4850–4854.",
    "year": 2017
  }, {
    "title": "The second dialog state tracking challenge",
    "authors": ["Matthew Henderson", "Blaise Thomson", "Jason D Williams."],
    "venue": "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 263–272, Philadelphia,",
    "year": 2014
  }, {
    "title": "Robust dialog state tracking using delexicalised recurrent neural networks and unsupervised adaptation",
    "authors": ["Matthew Henderson", "Blaise Thomson", "Steve Young."],
    "venue": "Proceedings of IEEE Spoken Language Technology Workshop (SLT).",
    "year": 2014
  }, {
    "title": "Word-based dialog state tracking with recurrent neural networks",
    "authors": ["Matthew Henderson", "Blaise Thomson", "Steve Young."],
    "venue": "Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL),",
    "year": 2014
  }, {
    "title": "The third dialog state tracking challenge",
    "authors": ["Mettew Henderson", "Blaise Thomson", "Jason D. Williams."],
    "venue": "Proceedings of IEEE Spoken Language Technology Workshop (SLT).",
    "year": 2014
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural computation, 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Structured discriminative model for dialog state tracking",
    "authors": ["Sungjin Lee."],
    "venue": "Proceedings of the SIGDIAL 2013 Conference, pages 442–451, Metz, France. Association for Computational Linguistics.",
    "year": 2013
  }, {
    "title": "Recipe for building robust spoken dialog state trackers: Dialog state tracking challenge system description",
    "authors": ["Sungjin Lee", "Maxine Eskenazi."],
    "venue": "Proceedings of the SIGDIAL 2013 Conference, pages 414–422, Metz, France. Association for Computa-",
    "year": 2013
  }, {
    "title": "Neural belief tracker: Data-driven dialogue state tracking",
    "authors": ["Nikola Mrkšić", "Diarmuid Ó Séaghdha", "Tsung-Hsien Wen", "Blaise Thomson", "Steve Young."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
    "year": 2017
  }, {
    "title": "Dialog state tracking, a machine reading approach using memory network",
    "authors": ["Julien Perez", "Fei Liu."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, vol-",
    "year": 2017
  }, {
    "title": "Large-scale multi-domain belief tracking with knowledge sharing",
    "authors": ["Osman Ramadan", "Paweł Budzianowski", "Milica Gasic."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), vol-",
    "year": 2018
  }, {
    "title": "Scalable multi-domain dialogue state tracking",
    "authors": ["Abhinav Rastogi", "Dilek Hakkani-Tur", "Larry Heck."],
    "venue": "arXiv preprint arXiv:1712.10224.",
    "year": 2017
  }, {
    "title": "A generalized rule based tracker for dialogue state tracking",
    "authors": ["Kai Sun", "Lu Chen", "Su Zhu", "Kai Yu."],
    "venue": "Proceedings of IEEE Spoken Language Technology Workshop (SLT).",
    "year": 2014
  }, {
    "title": "The SJTU system for dialog state tracking challenge",
    "authors": ["Kai Sun", "Lu Chen", "Su Zhu", "Kai Yu"],
    "year": 2014
  }, {
    "title": "Recurrent polynomial network for dialogue state tracking",
    "authors": ["Kai Sun", "Qizhe Xie", "Kai Yu."],
    "venue": "Dialogue & Discourse, 7(3):65–88.",
    "year": 2016
  }, {
    "title": "Hybrid dialogue state tracking for real world human-to-human dialogues",
    "authors": ["Kai Sun", "Su Zhu", "Lu Chen", "Siqiu Yao", "Xueyang Wu", "Kai Yu."],
    "venue": "Proc. InterSpeech, pages 2060–2064, San Francisco, America.",
    "year": 2016
  }, {
    "title": "Bayesian update of dialogue state: A POMDP framework for spoken dialogue systems",
    "authors": ["Blaise Thomson", "Steve Young."],
    "venue": "Computer Speech & Language, 24(4):562–588.",
    "year": 2010
  }, {
    "title": "A simple and generic belief tracking mechanism for the dialog state tracking challenge: On the believability of observed information",
    "authors": ["Zhuoran Wang", "Oliver Lemon."],
    "venue": "Proceedings of the SIGDIAL 2013 Conference, pages 423–432, Metz, France. As-",
    "year": 2013
  }, {
    "title": "A networkbased end-to-end trainable task-oriented dialogue system",
    "authors": ["Tsung-Hsien Wen", "David Vandyke", "Nikola Mrkšić", "Milica Gasic", "Lina M. Rojas Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young."],
    "venue": "EACL, pages 438–449, Valencia, Spain.",
    "year": 2017
  }, {
    "title": "From paraphrase database to compositional paraphrase model and back",
    "authors": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu", "Dan Roth."],
    "venue": "Transactions of the Association for Computational Linguistics, 3:345–358.",
    "year": 2015
  }, {
    "title": "The dialog state tracking challenge",
    "authors": ["Jason Williams", "Antoine Raux", "Deepak Ramachandran", "Alan Black."],
    "venue": "Proceedings of the SIGDIAL 2013 Conference, pages 404–413, Metz, France. Association for Computational Linguistics.",
    "year": 2013
  }, {
    "title": "Cost-sensitive active learning for dialogue state tracking",
    "authors": ["Kaige Xie", "Cheng Chang", "Liliang Ren", "Lu Chen", "Kai Yu."],
    "venue": "Proceedings of the 19th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pages 209–",
    "year": 2018
  }, {
    "title": "Recurrent polynomial network for dialogue state tracking with mismatched semantic parsers",
    "authors": ["Qizhe Xie", "Kai Sun", "Su Zhu", "Lu Chen", "Kai Yu."],
    "venue": "Proceedings of the 16th Annual Meeting of the Special Interest Group on Discourse and Dialogue,",
    "year": 2015
  }, {
    "title": "An end-to-end approach for handling unknown slot values in dialogue state tracking",
    "authors": ["Puyang Xu", "Qi Hu."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1.",
    "year": 2018
  }, {
    "title": "The hidden information state model: A practical framework for POMDP-based spoken dialogue management",
    "authors": ["Steve Young", "Milica Gašić", "Simon Keizer", "François Mairesse", "Jost Schatzmann", "Blaise Thomson", "Kai Yu."],
    "venue": "Computer Speech & Lan-",
    "year": 2010
  }, {
    "title": "POMDP-based statistical spoken dialog systems: A review",
    "authors": ["Steve Young", "Milica Gasic", "Blaise Thomson", "Jason D. Williams."],
    "venue": "Proceedings of the IEEE, 101(5):1160–1179.",
    "year": 2013
  }, {
    "title": "Cognitive technology in task-oriented dialogue systems: Concepts, advances and future",
    "authors": ["Kai Yu", "Lu Chen", "Bo Chen", "Kai Sun", "Su Zhu."],
    "venue": "Chinese Journal of Computers, 37(18):1–17.",
    "year": 2014
  }, {
    "title": "Evolvable dialogue state tracking for statistical dialogue management",
    "authors": ["Kai Yu", "Lu Chen", "Kai Sun", "Qizhe Xie", "Su Zhu."],
    "venue": "Frontiers of Computer Science, 10(2):201–215.",
    "year": 2016
  }, {
    "title": "Constrained markov bayesian polynomial for efficient dialogue state tracking",
    "authors": ["Kai Yu", "Kai Sun", "Lu Chen", "Su Zhu."],
    "venue": "IEEE/ACM Transactions on Audio, Speech and Language Processing, 23(12):2177–2188.",
    "year": 2015
  }, {
    "title": "Global-locally self-attentive encoder for dialogue state tracking",
    "authors": ["Victor Zhong", "Caiming Xiong", "Richard Socher."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1,",
    "year": 2018
  }],
  "id": "SP:28403e776f774cc63e324163f6600075bde9c328",
  "authors": [{
    "name": "Liliang Ren",
    "affiliations": []
  }, {
    "name": "Kaige Xie",
    "affiliations": []
  }, {
    "name": "Lu Chen",
    "affiliations": []
  }, {
    "name": "Kai Yu",
    "affiliations": []
  }],
  "abstractText": "Dialogue state tracking is the core part of a spoken dialogue system. It estimates the beliefs of possible user’s goals at every dialogue turn. However, for most current approaches, it’s difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don’t work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.",
  "title": "Towards Universal Dialogue State Tracking"
}