{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 93–104 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n93\nWe present Swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-theart language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research."
  }, {
    "heading": "1 Introduction",
    "text": "When we read a story, we bring to it a large body of implicit knowledge about the physical world. For instance, given the context “on stage, a woman takes a seat at the piano,” shown in Table 1, we can easily infer what the situation might look like: a woman is giving a piano performance, with a crowd watching her. We can furthermore infer her likely next action: she will most likely set her fingers on the piano keys and start playing.\nThis type of natural language inference requires commonsense reasoning, substantially broadening the scope of prior work that focused primarily on\nlinguistic entailment (Chierchia and McConnellGinet, 2000). Whereas the dominant entailment paradigm asks if two natural language sentences (the ‘premise’ and the ‘hypothesis’) describe the same set of possible worlds (Dagan et al., 2006; Bowman et al., 2015), here we focus on whether a (multiple-choice) ending describes a possible (future) world that can be anticipated from the situation described in the premise, even when it is not strictly entailed. Making such inference necessitates a rich understanding about everyday physical situations, including object affordances (Gibson, 1979) and frame semantics (Baker et al., 1998).\nA first step toward grounded commonsense inference with today’s deep learning machinery is to create a large-scale dataset. However, recent work has shown that human-written datasets are susceptible to annotation artifacts: unintended stylistic patterns that give out clues for the gold labels (Gururangan et al., 2018; Poliak et al., 2018). As a result, models trained on such datasets with hu-\nman biases run the risk of over-estimating the actual performance on the underlying task, and are vulnerable to adversarial or out-of-domain examples (Wang et al., 2018; Glockner et al., 2018).\nIn this paper, we introduce Adversarial Filtering (AF), a new method to automatically detect and reduce stylistic artifacts. We use this method to construct Swag: an adversarial dataset with 113k multiple-choice questions. We start with pairs of temporally adjacent video captions, each with a context and a follow-up event that we know is physically possible. We then use a state-of-theart language model fine-tuned on this data to massively oversample a diverse set of possible negative sentence endings (or counterfactuals). Next, we filter these candidate endings aggressively and adversarially using a committee of trained models to obtain a population of de-biased endings with similar stylistic features to the real ones. Finally, these filtered counterfactuals are validated by crowd workers to further ensure data quality.\nExtensive empirical results demonstrate unique contributions of our dataset, complementing existing datasets for natural langauge inference (NLI) (Bowman et al., 2015; Williams et al., 2018) and commonsense reasoning (Roemmele et al., 2011; Mostafazadeh et al., 2016; Zhang et al., 2017). First, our dataset poses a new challenge of grounded commonsense inference that is easy for humans (88%) while hard for current state-ofthe-art NLI models (<60%). Second, our proposed adversarial filtering methodology allows for cost-effective construction of a large-scale dataset while substantially reducing known annotation artifacts. The generality of adversarial filtering allows it to be applied to build future datasets, ensuring that they serve as reliable benchmarks.\n2 Swag: Our new dataset\nWe introduce a new dataset for studying physically grounded commonsense inference, called Swag.1 Our task is to predict which event is most likely to occur next in a video. More formally, a model is given a context c = (s,n): a complete sentence s and a noun phrase n that begins a second sentence, as well as a list of possible verb phrase sentence endings V = {v1, . . . ,v4}. See Figure 1 for an example triple (s,n,vi). The model must then select the most appropriate verb phrase vî ∈ V .\n1Short for Situations With Adversarial Generations.\nOverview Our corpus consists of 113k multiple choice questions (73k training, 20k validation, 20k test) and is derived from pairs of consecutive video captions from ActivityNet Captions (Krishna et al., 2017; Heilbron et al., 2015) and the Large Scale Movie Description Challenge (LSMDC; Rohrbach et al., 2017). The two datasets are slightly different in nature and allow us to achieve broader coverage: ActivityNet contains 20k YouTube clips containing one of 203 activity types (such as doing gymnastics or playing guitar); LSMDC consists of 128k movie captions (audio descriptions and scripts). For each pair of captions, we use a constituency parser (Stern et al., 2017) to split the second sentence into noun and verb phrases (Figure 1).2 Each question has a human-verified gold ending and 3 distractors."
  }, {
    "heading": "3 A solution to annotation artifacts",
    "text": "In this section, we outline the construction of Swag. We seek dataset diversity while minimizing annotation artifacts, conditional stylistic patterns such as length and word-preference biases. For many NLI datasets, these biases have been shown to allow shallow models (e.g. bag-of-words) obtain artificially high performance.\nTo avoid introducing easily “gamed” patterns, we present Adversarial Filtering (AF), a generallyapplicable treatment involving the iterative refinement of a set of assignments to increase the entropy under a chosen model family. We then discuss how we generate counterfactual endings, and\n2We filter out sentences with rare tokens (≤3 occurrences), that are short (l ≤ 5), or that lack a verb phrase.\nAlgorithm 1 Adversarial filtering (AF) of negative samples. During our experiments, we set Neasy = 2 for refining a population ofN− = 1023 negative examples to k = 9, and used a 80%/20% train/test split.\nwhile convergence not reached do • Split the dataset D randomly up into training and testing portions Dtr and Dte. • Optimize a model fθ on Dtr. for index i in Dte do • Identify easy indices: Aeasyi = {j ∈ Ai : fθ(x + i ) > fθ(x − i,j)}\n• Replace N easy easy indices j ∈ Aeasyi with adversarial indices k 6∈ Ai satisfying fθ(x − i,k) > fθ(x − i,j).\nend for end while\nfinally, the models used for filtering."
  }, {
    "heading": "3.1 Formal definition",
    "text": "In this section, we formalize what it means for a dataset to be adversarial. Intuitively, we say that an adversarial dataset for a model f is one on which f will not generalize, even if evaluated on test data from the same distribution. More formally, let our input space be X and the label space be Y . Our trainable classifier f , taking parameters θ is defined as fθ : X → R|Y|. Let our dataset of size N be defined as D = {(xi, yi)}1≤i≤N , and let the loss function over the dataset be L(fθ,D). We say that a dataset is adversarial with respect to f if we expect high empirical error I over all leave-one-out train/test splits (Vapnik, 2000):\nI(D, f) = 1 N N∑ i=1 L(fθ?i , {(xi, yi)}), (1)\nwhere θ?i = argmin θ L(fθ,D \\ {(xi, yi)}), (2)\nwith regularization terms omitted for simplicity."
  }, {
    "heading": "3.2 Adversarial filtering (AF) algorithm",
    "text": "In this section, we outline an approach for generating an adversarial dataset D, effectively maximizing empirical error I with respect to a family of trainable classifiers f . Without loss of generality, we consider the situation where we have N contexts, each associated with a single positive example (x+i , 1)∈X ×Y , and a large population of context-specific negative examples (x−i,j , 0)∈X ×Y , where 1≤j≤N− for each i. For instance, the negative examples could be incorrect relations in knowledge-base completion (Socher et al., 2013), or all words in a dictionary for a\nsingle-word cloze task (Zweig and Burges, 2011). Our goal will be to filter the population of negative examples for each instance i to a size of k N−. This will be captured by returning a set of assignments A, where for each instance the assignment will be a k-subset Ai = [1 . . . N−]k. The filtered dataset will then be:\nDAF = {(xi, 1), {(x−i,j , 0)}j∈Ai}1≤i≤N (3)\nUnfortunately, optimizing I(DAF , f) is difficult as A is global and non-differentiable. To address this, we present Algorithm 1. On each iteration, we split the data into dummy ‘train’ and ‘test’ splits. We train a model f on the training portion and obtain parameters θ, then use the remaining test portion to reassign the indices of A. For each context, we replace some number of ‘easy’ negatives in A that fθ classifies correctly with ‘adversarial’ negatives outside ofA that fθ misclassifies.\nThis process can be thought of as increasing the overall entropy of the dataset: given a strong model fθ that is compatible with a random subset of the data, we aim to ensure it cannot generalize to the held-out set. We repeat this for several iterations to reduce the generalization ability of the model family f over arbitrary train/test splits."
  }, {
    "heading": "3.3 Generating candidate endings",
    "text": "To generate counterfactuals for Swag, we use an LSTM (Hochreiter and Schmidhuber, 1997) language model (LM), conditioned on contexts from video captions. We first pretrain on BookCorpus (Zhu et al., 2015), then finetune on the video caption datasets. The architecture uses standard best practices and was validated on held-out perplexity of the video caption datasets; details are in the appendix. We use the LM to sample N−=1023 unique endings for a partial caption.3\nImportantly, we greedily sample the endings, since beam search decoding biases the generated endings to be of lower perplexity (and thus easily distinguishable from found endings). We find this process gives good counterfactuals: the generated endings tend to use topical words, but often make little sense physically, making them perfect for our task. Further, the generated endings are marked as “gibberish” by humans only 9.1% of the time (Sec 3.5); in that case the ending is filtered out.\n3To ensure that the LM generates unique endings, we split the data into five validation folds and train five separate LMs, one for each set of training folds. This means that each LM never sees the found endings during training."
  }, {
    "heading": "3.4 Stylistic models for adversarial filtering",
    "text": "In creating Swag, we designed the model family f to pick up on low-level stylistic features that we posit should not be predictive of whether an event happens next in a video. These stylistic features are an obvious case of annotation artifacts (Cai et al., 2017; Schwartz et al., 2017).4 Our final classifier is an ensemble of four stylistic models: 1. A multilayer perceptron (MLP) given LM perplexity features and context/ending lengths. 2. A bag-of-words model that averages the word embeddings of the second sentence as features. 3. A one-layer CNN, with filter sizes ranging from 2-5, over the second sentence. 4. A bidirectional LSTM over the 100 most common words in the second sentence; uncommon words are replaced by their POS tags. We ensemble the models by concatenating their final representations and passing it through an MLP. On every adversarial iteration, the ensemble is trained jointly to minimize cross-entropy.\nThe accuracies of these models (at each iteration, evaluated on a 20% split of the test dataset before indices of A get remapped) are shown in Figure 2. Performance decreases from 60% to close to random chance; moreover, confusing the perplexity-based MLP is not sufficient to lower performance of the ensemble. Only once the other stylistic models are added does the ensemble accuracy drop substantially, suggesting that our approach is effective at reducing stylistic artifacts.\n4A broad definition of annotation artifacts might include aspects besides lexical/stylistic features: for instance, certain events are less likely semantically regardless of the context (e.g. riding a horse using a hose). For this work, we erred more conservatively and only filtered based on style."
  }, {
    "heading": "3.5 Human verification",
    "text": "The final data-collection step is to have humans verify the data. Workers on Amazon Mechanical Turk were given the caption context, as well as six candidate endings: one found ending and five adversarially-sampled endings. The task was twofold: Turkers ranked the endings independently as likely, unlikely, or gibberish, and selected the best and second best endings (Fig 3).\nWe obtained the correct answers to each context in two ways. If a Turker ranks the found ending as either best or second best (73.7% of the time), we add the found ending as a gold example, with negatives from the generations not labelled best or gibberish. Further, if a Turker ranks a generated ending as best, and the found ending as second best, then we have reason to believe that the generation is good. This lets us add an additional training example, consisting of the generated best ending as the gold, and remaining generations as negatives.5 Examples with ≤3 nongibberish endings were filtered out.6\nWe found after 1000 examples that the annotators tended to have high agreement, also generally choosing found endings over generations (see Table 2). Thus, we collected the remaining 112k examples with one annotator each, periodically verifying that annotators preferred the found endings."
  }, {
    "heading": "4 Experiments",
    "text": "In this section, we evaluate the performance of various NLI models on Swag. Recall that models\n5These two examples share contexts. To prevent biasing the test and validation sets, we didn’t perform this procedure on answers from the evaluation sets’ context.\n6To be data-efficient, we reannotated filtered-out examples by replacing gibberish endings, as well as generations that outranked the found ending, with candidates from A.\nfor our dataset take the following form: given a sentence and a noun phrase as context c = (s,n), as well as a list of possible verb phrase endings V = {v1, . . . ,v4}, a model fθ must select a verb î that hopefully matches igold:\nî = argmax i fθ(s,n,vi) (4)\nTo study the amount of bias in our dataset, we also consider models that take as input just the ending verb phrase vi, or the entire second sentence (n,vi). For our learned models, we train f by minimizing multi-class cross-entropy. We consider three different types of word representations: 300d GloVe vectors from Common Crawl (Pennington et al., 2014), 300d Numberbatch vectors retrofitted using ConceptNet relations (Speer et al., 2017), and 1024d ELMo contextual representations that show improvement on a variety of NLP tasks, including standard NLI (Peters et al., 2018). We follow the final dataset split (see Section 2) using two training approaches: training on the found data, and the found and highly-ranked generated data. See the appendix for more details."
  }, {
    "heading": "4.1 Unary models",
    "text": "The following models predict labels from a single span of text as input; this could be the ending only, the second sentence only, or the full passage. a. fastText (Joulin et al., 2017): This library models a single span of text as a bag of n-grams, and tries to predict the probability of an ending being correct or incorrect independently.7 b. Pretrained sentence encoders We consider two types of pretrained RNN sentence encoders, SkipThoughts (Kiros et al., 2015) and InferSent\n7The fastText model is trained using binary cross-entropy; at test time we extract the prediction by selecting the ending with the highest positive likelihood under the model.\n(Conneau et al., 2017). SkipThoughts was trained by predicting adjacent sentences in book data, whereas InferSent was trained on supervised NLI data. For each second sentence (or just the ending), we feed the encoding into an MLP. c. LSTM sentence encoder Given an arbitrary span of text, we run a two-layer BiLSTM over it. The final hidden states are then max-pooled to obtain a fixed-size representation, which is then used to predict the potential for that ending."
  }, {
    "heading": "4.2 Binary models",
    "text": "The following models predict labels from two spans of text. We consider two possibilties for these models: using just the second sentence, where the two text spans are n,vi, or using the context and the second sentence, in which case the spans are s, (n,vi). The latter case includes many models developed for the NLI task. d. Dual Bag-of-Words For this baseline, we treat each sentence as a bag-of-embeddings (c,vi). We model the probability of picking an ending i using a bilinear model: softmaxi(cWvTi ). 8 e. Dual pretrained sentence encoders Here, we obtain representations from SkipThoughts or InferSent for each span, and compute their pairwise compatibility using either 1) a bilinear model or 2) an MLP from their concatenated representations. f. SNLI inference Here, we consider two models that do well on SNLI (Bowman et al., 2015): Decomposable Attention (Parikh et al., 2016) and ESIM (Chen et al., 2017). We use pretrained versions of these models (with ELMo embeddings) on SNLI to obtain 3-way entailment, neutral, and contradiction probabilities for each example. We then train a log-linear model using these 3-way probabilities as features. g. SNLI models (retrained) Here, we train ESIM and Decomposable Attention on our dataset: we simply change the output layer size to 1 (the potential of an ending vi) with a softmax over i."
  }, {
    "heading": "4.3 Other models",
    "text": "We also considered the following models: h. Length: Although length was used by the adversarial classifier, we want to verify that human validation didn’t reintroduce a length bias. For this baseline, we always choose the shortest ending. i. ConceptNet As our task requires world knowledge, we tried a rule-based system on top of the\n8We also tried using an MLP, but got worse results.\nConceptNet knowledge base (Speer et al., 2017). For an ending sentence, we use the spaCy dependency parser to extract the head verb and its dependent object. The ending score is given by the number of ConceptNet causal relations9 between synonyms of the verb and synonyms of the object. j. Human performance To benchmark human performance, five Mechanical Turk workers were asked to answer 100 dataset questions, as did an ‘expert’ annotator (the first author of this paper). Predictions were combined using a majority vote."
  }, {
    "heading": "4.4 Results",
    "text": "We present our results in Table 3. The best model that only uses the ending is the LSTM sequence model with ELMo embeddings, which obtains 43.6%. This model, as with most models studied, greatly improves with more context: by 3.1% when given the initial noun phrase, and by an ad-\n9We used the relations ‘Causes’, ‘CapableOf’, ‘ReceivesAction’, ‘UsedFor’, and ‘HasSubevent’. Though their coverage is low (30.4% of questions have an answer with≥1 causal relation), the more frequent relations in ConceptNet, such as ‘IsA’, at best only indirectly relate to our task.\nditional 4% when also given the first sentence. Further improvement is gained from models that compute pairwise representations of the inputs. While the simplest such model, DualBoW, obtains only 35.1% accuracy, combining InferSent sentence representations gives 40.5% accuracy (InferSent-Bilinear). The best results come from pairwise NLI models: when fully trained on Swag, ESIM+ELMo obtains 59.2% accuracy.\nWhen comparing machine results to human results, we see there exists a lot of headroom. Though there likely is some noise in the task, our results suggest that humans (even untrained) converge to a consensus. Our in-house “expert” annotator is outperformed by an ensemble of 5 Turk workers (with 88% accuracy); thus, the effective upper bound on our dataset is likely even higher."
  }, {
    "heading": "5 Analysis",
    "text": "5.1 Swag versus existing NLI datasets The past few years have yielded great advances in NLI and representation learning, due to the availability of large datasets like SNLI and MultiNLI\n(Bowman et al., 2015; Williams et al., 2018). With the release of Swag, we hope to continue this trend, particularly as our dataset largely has the same input/output format as other NLI datasets. We observe three key differences between our dataset and others in this space:\nFirst, as noted in Section 1, Swag requires a unique type of temporal reasoning. A state-of-theart NLI model such as ESIM, when bottlenecked through the SNLI notion of entailment (SNLIESIM), only obtains 36.1% accuracy.10 This implies that these datasets necessitate different (and complementary) forms of reasoning.\nSecond, our use of videos results in wide coverage of dynamic and temporal situations Compared with SNLI, with contexts from Flickr30K (Plummer et al., 2017) image captions, Swag has more active verbs like ‘pull’ and ‘hit,’ and fewer static verbs like ‘sit’ and ‘wear’ (Figure 4).11\nThird, our dataset suffers from few lexical biases. Whereas fastText, a bag of n-gram model, obtains 67.0% accuracy on SNLI versus a 34.3% baseline (Gururangan et al., 2018), fastText obtains only 29.0% accuracy on Swag.12"
  }, {
    "heading": "5.2 Error analysis",
    "text": "We sought to quantify how human judgments differ from the best studied model, ESIM+ELMo. We randomly sampled 100 validation questions\n10The weights of SNLI-ESIM pick up primarily on entailment probability (0.59), as with neutral (0.46), while contradiction is negatively correlated (-.42).\n11Video data has other language differences; notably, character names in LSMDC were replaced by ‘someone’\n12The most predictive individual words on SWAG are infrequent in number: ‘dotted‘ with P(+|dotted) = 77% with 10.3 counts, and P(−|similar) = 81% with 16.3 counts. (Counts from negative endings were discounted 3x, as there are 3 times as many negative endings as positive endings).\nthat ESIM+ELMo answered incorrectly, for each extracting both the gold ending and the model’s preferred ending. We asked 5 Amazon Mechanical Turk workers to pick the better ending (of which they preferred the gold endings 94% of the time) and to select one (or more) multiple choice reasons explaining why the chosen answer was better.\nThe options, and the frequencies, are outlined in Table 4. The most common reason for the turkers preferring the correct answer is situational (52.3% of the time), followed by weirdness (17.5%) and plausibility (14.4%). This suggests that ESIM+ELMo already does a good job at filtering out weird and implausible answers, with the main bottleneck being grounded physical understanding. The ambiguous percentage is also relatively low (12.0%), implying significant headroom."
  }, {
    "heading": "5.3 Qualitative examples",
    "text": "Last, we show several qualitative examples in Table 5. Though models can do decently well by identifying complex alignment patterns between the two sentences (e.g. being “up a tree” implies that “tree” is the end phrase), the incorrect model predictions suggest this strategy is insuffi-\ncient. For instance, answering “An old man rides a small bumper car” requires knowledge about bumper cars and how they differ from regular cars: bumper cars are tiny, don’t drive on roads, and don’t work in parking lots, eliminating the alternatives. However, this knowledge is difficult to extract from existing corpora: for instance, the ConceptNet entry for Bumper Car has only a single relation: bumper cars are a type of vehicle. Other questions require intuitive physical reasoning: e.g, for “he pours the raw egg batter into the pan,” about what happens next in making an omelet."
  }, {
    "heading": "5.4 Where to go next?",
    "text": "Our results suggest that Swag is a challenging testbed for NLI models. However, the adversarial models used to filter the dataset are purely stylistic and focus on the second sentence; thus, subtle artifacts still likely remain in our dataset. These patterns are ostensibly picked up by the NLI models (particularly when using ELMo features), but the large gap between machine and human performance suggests that more is required to solve the dataset. As models are developed for commonsense inference, and more broadly as the field of NLP advances, we note that AF can be used again to create a more adversarial version of Swag using better language models and AF models."
  }, {
    "heading": "6 Related Work",
    "text": "Entailment NLI There has been a long history of NLI benchmarks focusing on linguistic entailment (Cooper et al., 1996; Dagan et al., 2006; Marelli et al., 2014; Bowman et al., 2015; Lai et al., 2017; Williams et al., 2018). Recent NLI datasets in particular have supported learning broadly-applicable sentence representations (Conneau et al., 2017); moreover, models trained on these datasets were used as components\nfor performing better video captioning (Pasunuru and Bansal, 2017), summarization (Pasunuru and Bansal, 2018), and generation (Holtzman et al., 2018), confirming the importance of NLI research. The NLI task requires a variety of commonsense knowledge (LoBue and Yates, 2011), which our work complements. However, previous datasets for NLI have been challenged by unwanted annotation artifacts, (Gururangan et al., 2018; Poliak et al., 2018) or scale issues. Our work addresses these challenges by constructing a new NLI benchmark focused on grounded commonsense reasoning, and by introducing an adversarial filtering mechanism that substantially reduces known and easily detectable annotation artifacts.\nCommonsense NLI Several datasets have been introduced to study NLI beyond linguistic entailment: for inferring likely causes and endings given a sentence (COPA; Roemmele et al., 2011), for choosing the most sensible ending to a short story (RocStories; Mostafazadeh et al., 2016; Sharma et al., 2018), and for predicting likelihood of a hypothesis by regressing to an ordinal label (JOCI; (Zhang et al., 2017)). These datasets are relatively small: 1k examples for COPA and 10k cloze examples for RocStories.13 JOCI increases the scale by generating the hypotheses using a knowledge graph or a neural model. In contrast to JOCI where the task was formulated as a regression task on the degree of plausibility of the hypothesis, we frame commonsense inference as a multiple choice question to reduce the potential ambiguity in the labels and to allow for direct comparison between machines and humans. In addition, Swag’s use of adversarial filtering increases diversity of situations and counterfactual generation quality.\n13For RocStories, this was by design to encourage learning from the larger corpus of 98k sensible stories.\nLast, another related task formulation is sentence completion or cloze, where the task is to predict a single word that is removed from a given context (Zweig and Burges, 2011; Paperno et al., 2016).14 Our work in contrast requires longer textual descriptions to reason about.\nVision datasets Several resources have been introduced to study temporal inference in vision. The Visual Madlibs dataset has 20k image captions about hypothetical next/previous events (Yu et al., 2015); similar to our work, the test portion is multiple-choice, with counterfactual answers retrieved from similar images and verified by humans. The question of ‘what will happen next?’ has also been studied in photo albums (Huang et al., 2016), videos of team sports, (Felsen et al., 2017) and egocentric dog videos (Ehsani et al., 2018). Last, annotation artifacts are also a recurring problem for vision datasets such as Visual Genome (Zellers et al., 2018) and Visual QA (Jabri et al., 2016); recent work was done to create a more challenging VQA dataset by annotating complementary image pairs (Goyal et al., 2016).\nReducing gender/racial bias Prior work has sought to reduce demographic biases in word embeddings (Zhang et al., 2018) as well as in image recognition models (Zhao et al., 2017). Our work has focused on producing a dataset with minimal annotation artifacts, which in turn helps to avoid some gender and racial biases that stem from elicitation (Rudinger et al., 2017). However, it is not perfect in this regard, particularly due to biases in movies (Schofield and Mehr, 2016; Sap et al., 2017). Our methodology could potentially be extended to construct datasets free of (possibly intersectional) gender or racial bias.\nPhysical knowledge Prior work has studied learning grounded knowledge about objects and verbs: from knowledge bases (Li et al., 2016), syntax parses (Forbes and Choi, 2017), word embeddings (Lucy and Gauthier, 2017), and images and dictionary definitions (Zellers and Choi, 2017). An alternate thread of work has been to learn scripts: high-level representations of event chains (Schank and Abelson, 1975; Chambers and Jurafsky, 2009). Swag evaluates both of these strands.\n14Prior work on sentence completion filtered negatives with heuristics based on LM perplexities. We initially tried something similar, but found the result to still be gameable."
  }, {
    "heading": "7 Conclusion",
    "text": "We propose a new challenge of physically situated commonsense inference that broadens the scope of natural language inference (NLI) with commonsense reasoning. To support research toward commonsense NLI, we create a large-scale dataset Swag with 113k multiple-choice questions. Our dataset is constructed using Adversarial Filtering (AF), a new paradigm for robust and cost-effective dataset construction that allows datasets to be constructed at scale while automatically reducing annotation artifacts that can be easily detected by a committee of strong baseline models. Our adversarial filtering paradigm is general, allowing potential applications to other datasets that require human composition of question answer pairs."
  }, {
    "heading": "Acknowledgements",
    "text": "We thank the anonymous reviewers, members of the ARK and xlab at the University of Washington, researchers at the Allen Institute for AI, and Luke Zettlemoyer for their helpful feedback. We also thank the Mechanical Turk workers for doing a fantastic job with the human validation. This work was supported by the National Science Foundation Graduate Research Fellowship (DGE-1256082), the NSF grant (IIS1524371, 1703166), the DARPA CwC program through ARO (W911NF-15-1-0543), the IARPA DIVA program through D17PC00343, and gifts by Google and Facebook. The views and conclusions contained herein are those of the authors and should not be interpreted as representing endorsements of IARPA, DOI/IBC, or the U.S. Government."
  }],
  "year": 2018,
  "references": [{
    "title": "The berkeley framenet project",
    "authors": ["Collin F Baker", "Charles J Fillmore", "John B Lowe."],
    "venue": "Proceedings of the 17th international conference on Computational linguistics-Volume 1, pages 86–90. Association for Computational Linguistics.",
    "year": 1998
  }, {
    "title": "A large annotated corpus for learning natural language inference",
    "authors": ["Samuel R. Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D. Manning."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Process-",
    "year": 2015
  }, {
    "title": "Pay attention to the ending: Strong neural baselines",
    "authors": ["Zheng Cai", "Lifu Tu", "Kevin Gimpel"],
    "year": 2017
  }, {
    "title": "Unsupervised Learning of Narrative Schemas and Their Participants",
    "authors": ["Nathanael Chambers", "Dan Jurafsky."],
    "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-",
    "year": 2009
  }, {
    "title": "Enhanced lstm for natural language inference",
    "authors": ["Qian Chen", "Xiaodan Zhu", "Zhen-Hua Ling", "Si Wei", "Hui Jiang", "Diana Inkpen."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), vol-",
    "year": 2017
  }, {
    "title": "Meaning and Grammar (2Nd Ed.): An Introduction to Semantics",
    "authors": ["Gennaro Chierchia", "Sally McConnell-Ginet"],
    "year": 2000
  }, {
    "title": "Supervised learning of universal sentence representations from natural language inference data",
    "authors": ["Alexis Conneau", "Douwe Kiela", "Holger Schwenk", "Loı̈c Barrault", "Antoine Bordes"],
    "venue": "In Proceedings of the 2017 Conference on Empirical Methods in Nat-",
    "year": 2017
  }, {
    "title": "A framework for computational semantics (fracas)",
    "authors": ["Robin Cooper", "Dick Crouch", "JV Eijckl", "Chris Fox", "JV Genabith", "J Japars", "Hans Kamp", "David Milward", "Manfred Pinkal", "Massimo Poesio"],
    "year": 1996
  }, {
    "title": "The pascal recognising textual entailment challenge",
    "authors": ["Ido Dagan", "Oren Glickman", "Bernardo Magnini."],
    "venue": "Machine learning challenges. evaluating predictive uncertainty, visual object classification, and recognising tectual entailment, pages 177–",
    "year": 2006
  }, {
    "title": "Who let the dogs out? modeling dog behavior from visual data",
    "authors": ["Kiana Ehsani", "Hessam Bagherinezhad", "Joseph Redmon", "Roozbeh Mottaghi", "Ali Farhadi."],
    "venue": "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
    "year": 2018
  }, {
    "title": "What will happen next? forecasting player moves in sports videos",
    "authors": ["Panna Felsen", "Pulkit Agrawal", "Jitendra Malik."],
    "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3342–3351.",
    "year": 2017
  }, {
    "title": "Verb physics: Relative physical knowledge of actions and objects",
    "authors": ["Maxwell Forbes", "Yejin Choi."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 266–276.",
    "year": 2017
  }, {
    "title": "The ecological approach to visual perception",
    "authors": ["JJ Gibson."],
    "venue": "Houghton Mifflin Comp.",
    "year": 1979
  }, {
    "title": "Breaking nli systems with sentences that require simple lexical inferences",
    "authors": ["Max Glockner", "Vered Shwartz", "Yoav Goldberg."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),",
    "year": 2018
  }, {
    "title": "Making the V in VQA matter: Elevating the role of image understanding in Visual Question Answering",
    "authors": ["Yash Goyal", "Tejas Khot", "Douglas Summers-Stay", "Dhruv Batra", "Devi Parikh."],
    "venue": "arXiv preprint arXiv:1612.00837.",
    "year": 2016
  }, {
    "title": "Annotation artifacts in natural language inference data",
    "authors": ["Suchin Gururangan", "Swabha Swayamdipta", "Omer Levy", "Roy Schwartz", "Samuel Bowman", "Noah A. Smith."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the",
    "year": 2018
  }, {
    "title": "Activitynet: A large-scale video benchmark for human activity understanding",
    "authors": ["Fabian Caba Heilbron", "Victor Escorcia", "Bernard Ghanem", "Juan Carlos Niebles."],
    "venue": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recog-",
    "year": 2015
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural Comput., 9(8):1735– 1780.",
    "year": 1997
  }, {
    "title": "Learning to write with cooperative discriminators",
    "authors": ["Ari Holtzman", "Jan Buys", "Maxwell Forbes", "Antoine Bosselut", "David Golub", "Yejin Choi."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume",
    "year": 2018
  }, {
    "title": "Revisiting visual question answering baselines",
    "authors": ["Allan Jabri", "Armand Joulin", "Laurens van der Maaten."],
    "venue": "European conference on computer vision, pages 727–739. Springer.",
    "year": 2016
  }, {
    "title": "Bag of tricks for efficient text classification",
    "authors": ["Armand Joulin", "Edouard Grave", "Piotr Bojanowski", "Tomas Mikolov."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Pa-",
    "year": 2017
  }, {
    "title": "Skip-thought vectors",
    "authors": ["Ryan Kiros", "Yukun Zhu", "Ruslan R Salakhutdinov", "Richard Zemel", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."],
    "venue": "Advances in neural information processing systems, pages 3294–3302.",
    "year": 2015
  }, {
    "title": "Dense-Captioning Events in Videos",
    "authors": ["Ranjay Krishna", "Kenji Hata", "Frederic Ren", "Li Fei-Fei", "Juan Carlos Niebles."],
    "venue": "International Conference on Computer Vision (ICCV).",
    "year": 2017
  }, {
    "title": "Natural language inference from multiple premises",
    "authors": ["Alice Lai", "Yonatan Bisk", "Julia Hockenmaier."],
    "venue": "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 100–109, Taipei, Tai-",
    "year": 2017
  }, {
    "title": "Commonsense knowledge base completion",
    "authors": ["Xiang Li", "Aynaz Taheri", "Lifu Tu", "Kevin Gimpel."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1445–1455, Berlin, Germany.",
    "year": 2016
  }, {
    "title": "Types of common-sense knowledge needed for recognizing textual entailment",
    "authors": ["Peter LoBue", "Alexander Yates."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short",
    "year": 2011
  }, {
    "title": "Are distributional representations ready for the real world? evaluating word vectors for grounded perceptual meaning",
    "authors": ["Li Lucy", "Jon Gauthier."],
    "venue": "Proceedings of the First Workshop on Language Grounding for Robotics, pages 76–85.",
    "year": 2017
  }, {
    "title": "A sick cure for the evaluation of compositional distributional semantic models",
    "authors": ["Marco Marelli", "Stefano Menini", "Marco Baroni", "Luisa Bentivogli", "Raffaella bernardi", "Roberto Zamparelli."],
    "venue": "Proceedings of the Ninth International Conference on Lan-",
    "year": 2014
  }, {
    "title": "A corpus and evaluation framework for deeper understanding of commonsense stories",
    "authors": ["Nasrin Mostafazadeh", "Nathanael Chambers", "Xiadong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen."],
    "venue": "NAACL.",
    "year": 2016
  }, {
    "title": "The lambada dataset: Word prediction requiring a broad discourse context",
    "authors": ["Denis Paperno", "Germán Kruszewski", "Angeliki Lazaridou", "Ngoc Quan Pham", "Raffaella Bernardi", "Sandro Pezzelle", "Marco Baroni", "Gemma Boleda", "Raquel Fernandez"],
    "year": 2016
  }, {
    "title": "A decomposable attention model for natural language inference",
    "authors": ["Ankur Parikh", "Oscar Täckström", "Dipanjan Das", "Jakob Uszkoreit."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2249–2255.",
    "year": 2016
  }, {
    "title": "Multitask video captioning with video and entailment generation",
    "authors": ["Ramakanth Pasunuru", "Mohit Bansal."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1273–1283, Van-",
    "year": 2017
  }, {
    "title": "Multireward reinforced summarization with saliency and entailment",
    "authors": ["Ramakanth Pasunuru", "Mohit Bansal."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
    "year": 2018
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher Manning."],
    "venue": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
    "year": 2014
  }, {
    "title": "Deep contextualized word representations",
    "authors": ["Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association",
    "year": 2018
  }, {
    "title": "Flickr30k entities: Collecting region-to-phrase correspondences for richer image-to-sentence models",
    "authors": ["Bryan A. Plummer", "Liwei Wang", "Chris M. Cervantes", "Juan C. Caicedo", "Julia Hockenmaier", "Svetlana Lazebnik."],
    "venue": "Int. J. Comput. Vision,",
    "year": 2017
  }, {
    "title": "Hypothesis Only Baselines in Natural Language Inference",
    "authors": ["Adam Poliak", "Jason Naradowsky", "Aparajita Haldar", "Rachel Rudinger", "Benjamin Van Durme."],
    "venue": "Joint Conference on Lexical and Computational Semantics (StarSem).",
    "year": 2018
  }, {
    "title": "Choice of Plausible Alternatives: An Evaluation of Commonsense Causal Reasoning",
    "authors": ["Melissa Roemmele", "Cosmin Adrian Bejan", "Andrew S Gordon."],
    "venue": "AAAI Spring Symposium: Logical Formalizations of Commonsense Reasoning.",
    "year": 2011
  }, {
    "title": "Movie Description",
    "authors": ["Anna Rohrbach", "Atousa Torabi", "Marcus Rohrbach", "Niket Tandon", "Christopher Pal", "Hugo Larochelle", "Aaron Courville", "Bernt Schiele."],
    "venue": "International Journal of Computer Vision, 123(1):94–120.",
    "year": 2017
  }, {
    "title": "Social bias in elicited natural language inferences",
    "authors": ["Rachel Rudinger", "Chandler May", "Benjamin Van Durme."],
    "venue": "Proceedings of the First ACL",
    "year": 2017
  }, {
    "title": "Connotation frames of power and agency in modern films",
    "authors": ["Maarten Sap", "Marcella Cindy Prasettio", "Ari Holtzman", "Hannah Rashkin", "Yejin Choi."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages",
    "year": 2017
  }, {
    "title": "Scripts, plans, and knowledge",
    "authors": ["Roger C. Schank", "Robert P. Abelson."],
    "venue": "Proceedings of the 4th International Joint Conference on Artificial Intelligence - Volume 1, IJCAI’75, pages 151–157, San Francisco, CA, USA. Morgan Kaufmann Publishers",
    "year": 1975
  }, {
    "title": "Genderdistinguishing features in film dialogue",
    "authors": ["Alexandra Schofield", "Leo Mehr."],
    "venue": "Proceedings of the Fifth Workshop on Computational Linguistics for Literature, pages 32–39.",
    "year": 2016
  }, {
    "title": "The effect of different writing tasks on linguistic style: A case study of the ROC story cloze task",
    "authors": ["Roy Schwartz", "Maarten Sap", "Ioannis Konstas", "Li Zilles", "Yejin Choi", "Noah A. Smith."],
    "venue": "Proc. of CoNLL.",
    "year": 2017
  }, {
    "title": "Tackling the story ending biases in the story cloze test",
    "authors": ["Rishi Sharma", "James Allen", "Omid Bakhshandeh", "Nasrin Mostafazadeh."],
    "venue": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),",
    "year": 2018
  }, {
    "title": "Reasoning with neural tensor networks for knowledge base completion",
    "authors": ["Richard Socher", "Danqi Chen", "Christopher D Manning", "Andrew Ng."],
    "venue": "Advances in neural information processing systems, pages 926–934.",
    "year": 2013
  }, {
    "title": "Conceptnet 5.5: An open multilingual graph of general knowledge",
    "authors": ["Robert Speer", "Joshua Chin", "Catherine Havasi"],
    "venue": "In AAAI Conference on Artificial Intelligence,",
    "year": 2017
  }, {
    "title": "A minimal span-based neural constituency parser",
    "authors": ["Mitchell Stern", "Jacob Andreas", "Dan Klein."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 818–827.",
    "year": 2017
  }, {
    "title": "The Nature of Statistical Learning Theory, 2 edition",
    "authors": ["Vladimir Vapnik."],
    "venue": "Information Science and Statistics. Springer-Verlag, New York.",
    "year": 2000
  }, {
    "title": "Glue: A multi-task benchmark and analysis platform for natural language understanding",
    "authors": ["Alex Wang", "Amapreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R Bowman."],
    "venue": "arXiv preprint arXiv:1804.07461.",
    "year": 2018
  }, {
    "title": "A broad-coverage challenge corpus for sentence understanding through inference",
    "authors": ["Adina Williams", "Nikita Nangia", "Samuel Bowman."],
    "venue": "Proceedings of the 2018 Conference of the North American",
    "year": 2018
  }, {
    "title": "Visual Madlibs: Fill in the blank Image Generation and Question Answering",
    "authors": ["Licheng Yu", "Eunbyung Park", "Alexander C. Berg", "Tamara L. Berg."],
    "venue": "ICCV.",
    "year": 2015
  }, {
    "title": "Zero-shot activity recognition with verb attribute induction",
    "authors": ["Rowan Zellers", "Yejin Choi."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing (EMNLP).",
    "year": 2017
  }, {
    "title": "Neural motifs: Scene graph parsing with global context",
    "authors": ["Rowan Zellers", "Mark Yatskar", "Sam Thomson", "Yejin Choi."],
    "venue": "Conference on Computer Vision and Pattern Recognition.",
    "year": 2018
  }, {
    "title": "Mitigating unwanted biases with adversarial learning",
    "authors": ["Brian Hu Zhang", "Blake Lemoine", "Margaret Mitchell."],
    "venue": "Conference on Artificial Intelligence, Ethics and Society.",
    "year": 2018
  }, {
    "title": "Ordinal Common-sense Inference",
    "authors": ["Sheng Zhang", "Rachel Rudinger", "Kevin Duh", "Benjamin Van Durme."],
    "venue": "Transactions of the Association for Computational Linguistics, 5:379–395.",
    "year": 2017
  }, {
    "title": "Men also like shopping: Reducing gender bias amplification using corpus-level constraints",
    "authors": ["Jieyu Zhao", "Tianlu Wang", "Mark Yatskar", "Vicente Ordonez", "Kai-Wei Chang."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural",
    "year": 2017
  }, {
    "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
    "authors": ["Yukun Zhu", "Ryan Kiros", "Richard Zemel", "Ruslan Salakhutdinov", "Raquel Urtasun", "Antonio Torralba", "Sanja Fidler."],
    "venue": "arXiv preprint",
    "year": 2015
  }, {
    "title": "The microsoft research sentence completion challenge",
    "authors": ["Geoffrey Zweig", "Christopher JC Burges."],
    "venue": "Technical report, Citeseer.",
    "year": 2011
  }],
  "id": "SP:af5c4b80fbf847f69a202ba5a780a3dd18c1a027",
  "authors": [{
    "name": "Rowan Zellers",
    "affiliations": []
  }, {
    "name": "Yonatan Bisk",
    "affiliations": []
  }, {
    "name": "Roy Schwartz",
    "affiliations": []
  }, {
    "name": "Yejin Choi",
    "affiliations": []
  }],
  "abstractText": "Given a partial description like “she opened the hood of the car,” humans can reason about the situation and anticipate what might come next (“then, she examined the engine”). In this paper, we introduce the task of grounded commonsense inference, unifying natural language inference and commonsense reasoning. We present Swag, a new dataset with 113k multiple choice questions about a rich spectrum of grounded situations. To address the recurring challenges of the annotation artifacts and human biases found in many existing datasets, we propose Adversarial Filtering (AF), a novel procedure that constructs a de-biased dataset by iteratively training an ensemble of stylistic classifiers, and using them to filter the data. To account for the aggressive adversarial filtering, we use state-of-theart language models to massively oversample a diverse set of potential counterfactuals. Empirical results demonstrate that while humans can solve the resulting inference problems with high accuracy (88%), various competitive models struggle on our task. We provide comprehensive analysis that indicates significant opportunities for future research.",
  "title": "Swag: A Large-Scale Adversarial Dataset for Grounded Commonsense Inference"
}