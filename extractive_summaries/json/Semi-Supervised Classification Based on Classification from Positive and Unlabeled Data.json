{
  "sections": [{
    "text": "ods developed so far use unlabeled data for regularization purposes under particular distributional assumptions such as the cluster assumption. In contrast, recently developed methods of classification from positive and unlabeled data (PU classification) use unlabeled data for risk evaluation, i.e., label information is directly extracted from unlabeled data. In this paper, we extend PU classification to also incorporate negative data and propose a novel semi-supervised classification approach. We establish generalization error bounds for our novel methods and show that the bounds decrease with respect to the number of unlabeled data without the distributional assumptions that are required in existing semi-supervised classification methods. Through experiments, we demonstrate the usefulness of the proposed methods."
  }, {
    "heading": "1. Introduction",
    "text": "Collecting a large amount of labeled data is a critical bottleneck in real-world machine learning applications due to the laborious manual annotation. In contrast, unlabeled data can often be collected automatically and abundantly, e.g., by a web crawler. This has led to the development of various semi-supervised classification algorithms over the past decades.\nTo leverage unlabeled data in training, most of the existing semi-supervised classification methods rely on particular assumptions on the data distribution (Chapelle et al., 2006). For example, the manifold assumption supposes that samples are distributed on a low-dimensional manifold in the data space (Belkin et al., 2006). In the existing framework, such a distributional assumption is encoded as a reg-\n1The University of Tokyo, Japan 2RIKEN, Japan. Correspondence to: Tomoya Sakai <sakai@ms.k.u-tokyo.ac.jp>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nularizer for training a classifier and biases the classifier toward a better one under the assumption. However, if such a distributional assumption contradicts the data distribution, the bias behaves adversely, and the performance of the obtained classifier becomes worse than the one obtained with supervised classification (Cozman et al., 2003; Sokolovska et al., 2008; Li & Zhou, 2015; Krijthe & Loog, 2017).\nRecently, classification from positive and unlabeled data (PU classification) has been gathering growing attention (Elkan & Noto, 2008; du Plessis et al., 2014; 2015; Jain et al., 2016), which trains a classifier only from positive and unlabeled data without negative data. In PU classification, the unbiased risk estimators proposed in du Plessis et al. (2014; 2015) utilize unlabeled data for risk evaluation, implying that label information is directly extracted from unlabeled data without restrictive distributional assumptions, unlike existing semi-supervised classification methods that utilize unlabeled data for regularization. Furthermore, theoretical analysis (Niu et al., 2016) showed that PU classification (or its counterpart, NU classification, classification from negative and unlabeled data) is likely to outperform classification from positive and negative data (PN classification, i.e., ordinary supervised classification) depending on the number of positive, negative, and unlabeled samples. It is thus naturally expected that combining PN, PU, and NU classification can be a promising approach to semisupervised classification without restrictive distributional assumptions.\nIn this paper, we propose a novel semi-supervised classification approach by considering convex combinations of the risk functions of PN, PU, and NU classification. Without any distributional assumption, we theoretically show that the confidence term of the generalization error bounds decreases at the optimal parametric rate with respect to the number of positive, negative, and unlabeled samples, and the variance of the proposed risk estimator is almost always smaller than the plain PN risk function given an infinite number of unlabeled samples. Through experiments, we analyze the behavior of the proposed approach and demonstrate the usefulness of the proposed semi-supervised classification methods."
  }, {
    "heading": "2. Background",
    "text": "In this section, we first introduce the notation commonly used in this paper and review the formulations of PN, PU, and NU classification."
  }, {
    "heading": "2.1. Notation",
    "text": "Let random variables x ∈ Rd and y ∈ {+1,−1} be equipped with probability density p(x, y), where d is a positive integer. Let us consider a binary classification problem from x to y, given three sets of samples called the positive (P), negative (N), and unlabeled (U) data:\nXP := {xPi }nPi=1 i.i.d.∼ pP(x) := p(x | y = +1), XN := {xNi }nNi=1 i.i.d.∼ pN(x) := p(x | y = −1), XU := {xUi }nUi=1 i.i.d.∼ p(x) := θPpP(x) + θNpN(x),\nwhere\nθP := p(y = +1), θN := p(y = −1)\nare the class-prior probabilities for the positive and negative classes such that θP + θN = 1.\nLet g : Rd → R be an arbitrary real-valued decision function for binary classification, and classification is performed based on its sign. Let ℓ : R → R be a loss function such that ℓ(m) generally takes a small value for large margin m = yg(x). Let RP(g), RN(g), RU,P(g), and RU,N(g) be the risks of classifier g under loss ℓ:\nRP(g) := EP[ℓ(g(x))], RN(g) := EN[ℓ(−g(x))], RU,P(g) := EU[ℓ(g(x))], RU,N(g) := EU[ℓ(−g(x))],\nwhere EP, EN, and EU denote the expectations over pP(x), pN(x), and p(x), respectively. Since we do not have any samples from p(x, y), the true risk R(g) = Ep(x,y)[ℓ(yg(x))], which we want to minimize, should be recovered without using p(x, y) as shown below."
  }, {
    "heading": "2.2. PN Classification",
    "text": "In standard supervised classification (PN classification), we have both positive and negative data, i.e., fully labeled data. The goal of PN classification is to train a classifier using labeled data.\nThe risk in PN classification (the PN risk) is defined as\nRPN(g) := θP EP[ℓ(g(x))] + θN EN[ℓ(−g(x))] = θPRP(g) + θNRN(g), (1)\nwhich is equal to R(g), but p(x, y) is not included. If we use the hinge loss function ℓH(m) := max(0, 1 −m), the PN risk coincides with the risk of the support vector machine (Vapnik, 1995)."
  }, {
    "heading": "2.3. PU Classification",
    "text": "In PU classification, we do not have labeled data for the negative class, but we can use unlabeled data drawn from marginal density p(x). The goal of PU classification is to train a classifier using only positive and unlabeled data. The basic approach to PU classification is to discriminate P and U data (Elkan & Noto, 2008). However, naively classifying P and U data causes a bias.\nTo address this problem, du Plessis et al. (2014; 2015) proposed a risk equivalent to the PN risk but where pN(x) is not included. The key idea is to utilize unlabeled data to evaluate the risk for negative samples in the PN risk. Replacing the second term in Eq. (1) with1\nθN EN[ℓ(−g(x))] = EU[ℓ(−g(x))]− θP EP[ℓ(−g(x))],\nwe obtain the risk in PU classification (the PU risk) as\nRPU(g) := θP EP[ℓ̃(g(x))] + EU[ℓ(−g(x))] = θPR C P(g) +RU,N(g), (2)\nwhere RCP(g) := EP[ℓ̃(g(x))] and ℓ̃(m) = ℓ(m)− ℓ(−m) is a composite loss function.\nNon-Convex Approach: If the loss function satisfies\nℓ(m) + ℓ(−m) = 1, (3)\nthe composite loss function becomes ℓ̃(m) = 2ℓ(m) − 1. We thus obtain the non-convex PU risk as\nRN-PU(g) := 2θPRP(g) +RU,N(g)− θP. (4)\nThis formulation can be seen as cost-sensitive classification of P and U data with weight 2θP (du Plessis et al., 2014).\nThe ramp loss used in the robust support vector machine (Collobert et al., 2006),\nℓR(m) := 1\n2 max(0,min(2, 1−m)), (5)\nsatisfies the condition (3). However, the use of the ramp loss (and any other losses that satisfy the condition (3)) yields a non-convex optimization problem, which may be solved locally by the concave-convex procedure (CCCP) (Yuille & Rangarajan, 2002; Collobert et al., 2006; du Plessis et al., 2014).\nConvex Approach: If a convex surrogate loss function satisfies\nℓ(m)− ℓ(−m) = −m, (6) 1The equation comes from the definition of the marginal den-\nsity p(x) = θPpP(x) + θNpN(x).\nthe composite loss function becomes a linear function ℓ̃(m) = −m (see Table 1 in du Plessis et al., 2015). We thus obtain the convex PU risk as\nRC-PU(g) := θPR L P(g) +RU,N(g),\nwhere RLP(g) := EP[−g(x)] is the risk with the linear loss ℓLin(m) := −m. This formulation yields the convex optimization problem that can be solved efficiently."
  }, {
    "heading": "2.4. NU Classification",
    "text": "As a mirror of PU classification, we can consider NU classification. The risk in NU classification (the NU risk) is given by\nRNU(g) := θN EN[ℓ̃(−g(x))] + EU[ℓ(g(x))] = θNR C N(g) +RU,P(g),\nwhere RCN(g) := EN[ℓ̃(−g(x))] is the risk function with the composite loss. Similarly to PU classification, the nonconvex and convex NU risks are expressed as\nRN-NU(g) := 2θNRN(g) +RU,P(g)− θN, (7) RC-NU(g) := θNR L N(g) +RU,P(g), (8)\nwhere RLN(g) := EN[g(x)] is the risk with the linear loss."
  }, {
    "heading": "3. Semi-Supervised Classification Based on PN, PU, and NU Classification",
    "text": "In this section, we propose semi-supervised classification methods based on PN, PU, and NU classification."
  }, {
    "heading": "3.1. PUNU Classification",
    "text": "A naive idea to build a semi-supervised classifier is to combine the PU and NU risks. For γ ∈ [0, 1], let us consider a linear combination of the PU and NU risks:\nRγPUNU(g) := (1− γ)RPU(g) + γRNU(g).\nWe refer to this combined method as PUNU classification.\nIf we use a loss function satisfying the condition (3), the non-convex PUNU risk RγN-PUNU(g) can be expressed as\nRγN-PUNU(g) = 2(1− γ)θPRP(g) + 2γθNRN(g) + EU[(1− γ)ℓ(−g(x)) + γℓ(g(x))] − (1− γ)θP − γθN.\nHere, R 1/2 N-PUNU(g) agrees with RPN(g) due to the condition (3). Thus, when γ = 1/2, PUNU classification is reduced to ordinary PN classification.\nOn the other hand, γ = 1/2 is still effective when the condition (6) is satisfied. Its riskRγC-PUNU(g) can be expressed as\nRγC-PUNU(g) = (1− γ)θPRLP(g) + γθNRLN(g) + EU[(1− γ)ℓ(g(x)) + γℓ(−g(x))].\nHere, (1 − γ)ℓ(g(x)) + γℓ(−g(x)) can be regarded as a loss function for unlabeled samples with weight γ.\nWhen γ = 1/2, unlabeled samples incur the same loss for the positive and negative classes. On the other hand, when 0 < γ < 1/2, a smaller loss is incurred for the negative class than the positive class. Thus, unlabeled samples tend to be classified into the negative class. The opposite is true when 1/2 < γ < 1."
  }, {
    "heading": "3.2. PNU Classification",
    "text": "Another possibility of using PU and NU classification in semi-supervised classification is to combine the PN and PU/NU risks. For γ ∈ [0, 1], let us consider linear combinations of the PN and PU/NU risks:\nRγPNPU(g) := (1− γ)RPN(g) + γRPU(g), RγPNNU(g) := (1− γ)RPN(g) + γRNU(g).\nIn practice, we combine PNPU and PNNU classification and adaptively choose one of them with a new trade-off parameter η ∈ [−1, 1] as\nRηPNU(g) := { RηPNPU(g) (η ≥ 0), R−ηPNNU(g) (η < 0).\nWe refer to the combined method as PNU classification. Clearly, PNU classification with η = −1, 0,+1 corresponds to NU, PN, and PU classification. As η gets large/small, the effect of the positive/negative classes is more emphasized.\nIn the theoretical analyses in Section 4, we denote the combinations of the PN risk with the non-convex PU/NU risks by RγN-PNPU and R γ N-PNNU, and that with the convex PU/NU risks by RγC-PNPU and R γ C-PNNU."
  }, {
    "heading": "3.3. Practical Implementation",
    "text": "We have so far only considered the true risks R (with respect to the expectations over true data distributions). When a classifier is trained from samples in practice, we use the empirical risks R̂ where the expectations are replaced with corresponding sample averages.\nMore specifically, in the theoretical analysis in Section 4 and experiments in Section 5, we use a linear-in-parameter model given by g(x) = ∑b\nj=1 wjφj(x) = w ⊤φ(x),\nwhere ⊤ denotes the transpose, b is the number of basis\nfunctions, w = (w1, . . . , wb) ⊤ is a parameter vector, and φ(x) = (φ1(x), . . . , φb(x)) ⊤ is a basis function vector. The parameter vector w is learned in order to minimize the ℓ2-regularized empirical risk:\nmin w\nR̂(g) + λw⊤w,\nwhere λ ≥ 0 is the regularization parameter."
  }, {
    "heading": "4. Theoretical Analyses",
    "text": "In this section, we theoretically analyze the behavior of the empirical versions of the proposed semi-supervised classification methods. We first derive generalization error bounds and then discuss variance reduction. Finally, we discuss whether PUNU or PNU classification is more promising. All proofs can be found in Appendix A."
  }, {
    "heading": "4.1. Generalization Error Bounds",
    "text": "Let G be a function class of bounded hyperplanes: G = {g(x) = 〈w,φ(x)〉 | ‖w‖ ≤ Cw, ‖φ(x)‖ ≤ Cφ},\nwhere Cw and Cφ are certain positive constants. Since ℓ2regularization is always included, we can naturally assume that the empirical risk minimizer g belongs to a certain G. Denote by ℓ0-1(m) = (1 − sign(m))/2 the zero-one loss and I(g) = Ep(x,y)[ℓ0-1(yg(x))] the risk of g for binary classification, i.e., the generalization error of g. In the following, we study upper bounds of I(g) holding uniformly for all g ∈ G. We respectively focus on the (scaled) ramp and squared losses for the non-convex and convex methods due to limited space. Similar results can be obtained with a little more effort if other eligible losses are used. For convenience, we define a function as\nχ(cP, cN, cU) = cPθP/ √ nP + cNθN/ √ nN + cU/ √ nU.\nNon-Convex Methods: A key observation is that ℓ0-1(m) ≤ 2ℓR(m), and consequently I(g) ≤ 2R(g). Note that by definition we have\nRγN-PUNU(g) = R γ N-PNPU(g) = R γ N-PNNU(g) = R(g).\nThe theorem below can be proven using the Rademacher analysis (see, for example, Mohri et al., 2012; Ledoux & Talagrand, 1991).\nTheorem 1 Let ℓR(m) be the loss for defining the empirical risks. For any δ > 0, the following inequalities hold separately with probability at least 1− δ for all g ∈ G: I(g) ≤ 2R̂γN-PUNU(g) + Cw,φ,δ · χ(2− 2γ, 2γ, |2γ − 1|), I(g) ≤ 2R̂γN-PNPU(g) + Cw,φ,δ · χ(1 + γ, 1− γ, γ), I(g) ≤ 2R̂γN-PNNU(g) + Cw,φ,δ · χ(1− γ, 1 + γ, γ), where Cw,φ,δ = 2CwCφ + √ 2 ln(3/δ).\nTheorem 1 guarantees that when ℓR(m) is used, I(g) can be bounded from above by two times the empirical risks, i.e., 2R̂γN-PUNU(g), 2R̂ γ N-PNPU(g), and 2R̂ γ N-PNNU(g), plus the corresponding confidence terms of order\nOp(1/ √ nP + 1/ √ nN + 1/ √ nU).\nSince nP, nN, and nU can increase independently, this is already the optimal convergence rate without any additional assumption (Vapnik, 1998; Mendelson, 2008).\nConvex Methods: Analogously, we have ℓ0-1(m) ≤ 4ℓS(m) for the squared loss. However, it is too loose when |m| ≫ 0. Fortunately, we do not have to use ℓS(m) if we work on the generalization error rather than the estimation error. To this end, we define the truncated (scaled) squared loss ℓTS(m) as\nℓTS(m) = { ℓS(m) 0 < m ≤ 1, ℓ0-1(m)/4 otherwise,\nso that ℓ0-1(m) ≤ 4ℓTS(m) is much tighter. For ℓTS(m), RC-PU(g) and RC-NU(g) need to be redefined as follows (see du Plessis et al., 2015):\nRC-PU(g) := θPR ′ P(g) +RU,N(g), RC-NU(g) := θNR ′ N(g) +RU,P(g),\nwhere R′P(g) and R ′ N(g) are simply RP(g) and RN(g) w.r.t. the composite loss ℓ̃TS(m) = ℓTS(m) − ℓTS(−m). The condition ℓ̃TS(m) 6= −m means the loss of convexity, but the equivalence is not lost; indeed, we still have\nRγC-PUNU(g) = R γ C-PNPU(g) = R γ C-PNNU(g) = R(g).\nTheorem 2 Let ℓTS(m) be the loss for defining the empirical risks (where RC-PU(g) and RC-NU(g) are redefined). For any δ > 0, the following inequalities hold separately with probability at least 1− δ for all g ∈ G:\nI(g) ≤ 4R̂γC-PUNU(g) + C ′w,φ,δ · χ(1− γ, γ, 1), I(g) ≤ 4R̂γC-PNPU(g) + C ′w,φ,δ · χ(1, 1− γ, γ), I(g) ≤ 4R̂γC-PNNU(g) + C ′w,φ,δ · χ(1− γ, 1, γ),\nwhere C ′w,φ,δ = 4CwCφ + √ 2 ln(4/δ).\nTheorem 2 ensures that when ℓTS(m) is used (for evaluating the empirical risks rather than learning the empirical risk minimizers), I(g) can be bounded from above by four times the empirical risks plus confidence terms in the optimal parametric rate. As ℓTS(m) ≤ ℓS(m), Theorem 2 is valid (but weaker) if all empirical risks are w.r.t. ℓS(m)."
  }, {
    "heading": "4.2. Variance Reduction",
    "text": "Our empirical risk estimators proposed in Section 3 are all unbiased. The next question is whether their variance can be smaller than that of R̂PN(g), i.e., whether XU can help reduce the variance in estimating R(g). To answer this question, pick any g of interest. For simplicity, we assume that nU → ∞, to illustrate the maximum variance reduction that could be achieved. Due to limited space, we only focus on the non-convex methods.\nSimilarly to RP(g) and RN(g), let σ 2 P(g) and σ 2 N(g) be the corresponding variance:\nσ2P(g) := VarP[ℓ(g(x))], σ 2 N(g) := VarN[ℓ(−g(x))],\nwhere VarP and VarN denote the variance over pP(x) and pN(x). Moreover, denote by ψP = θ 2 Pσ 2 P(g)/nP and ψN = θ 2 Nσ 2 N(g)/nN for short, and let Var be the variance over pP(x P 1 ) · · · pP(xPnP) · pN(xN1 ) · · · pN(xNnN) · p(xU1 ) · · · p(xUnU).\nTheorem 3 Assume nU → ∞. For any fixed g, let\nγN-PUNU = argmin γ\nVar[R̂γN-PUNU(g)] = ψP\nψP + ψN . (9)\nThen, we have γN-PUNU ∈ [0, 1]. Further, Var[R̂γN-PUNU(g)] < Var[R̂PN(g)] for all γ ∈ (2γN-PUNU − 1/2, 1/2) if ψP < ψN, or for all γ ∈ (1/2, 2γN-PUNU − 1/2) if ψP > ψN.2\nTheorem 3 guarantees that the variance is always reduced by R̂γN-PUNU(g) if γ is close to γN-PUNU, which is optimal for variance reduction. The interval of such good γ values has the length min{|ψP − ψN|/(ψP + ψN), 1/2}. In particular, if 3ψP ≤ ψN or ψP ≥ 3ψN, the length is 1/2.\nTheorem 4 Assume nU → ∞. For any fixed g, let\nγN-PNPU= argmin γ Var[R̂γN-PNPU(g)]= ψN − ψP ψP + ψN , (10)\nγN-PNNU= argmin γ Var[R̂γN-PNNU(g)]= ψP − ψN ψP + ψN . (11)\nThen, we have γN-PNPU ∈ [0, 1] if ψP ≤ ψN or γN-PNNU ∈ [0, 1] if ψP ≥ ψN. Additionally, Var[R̂γN-PNPU(g)] < Var[R̂PN(g)] for all γ ∈ (0, 2γN-PNPU) if ψP < ψN, or Var[R̂ γ N-PNNU(g)] < Var[R̂PN(g)] for all γ ∈ (0, 2γN-PNNU) if ψP > ψN.\nTheorem 4 implies that the variance of R̂PN(g) is reduced by either R̂γN-PNPU(g) if ψP ≤ ψN or R̂ γ N-PNNU(g)\n2Being fixed means g is determined before seeing the data for evaluating the empirical risk. For example, if g is trained by some learning method, and the empirical risk is subsequently evaluated on the validation/test data, g is regarded as fixed in the evaluation.\nif ψP ≥ ψN, where γ should be close to γN-PNPU or γN-PNNU. The range of such good γ values is of length min{2|ψP − ψN|/(ψP + ψN), 1}. In particular, if 3ψP ≤ ψN, R̂ γ N-PNPU(g) given any γ ∈ (0, 1) can reduce the variance, and if ψP ≥ 3ψN, R̂γN-PNNU(g) given any γ ∈ (0, 1) can reduce the variance.\nAs a corollary of Theorems 3 and 4, the minimum variance achievable by R̂γN-PUNU(g), R̂ γ N-PNPU(g), and R̂γN-PNNU(g) at their optimal γN-PUNU, γN-PNPU, and γN-PNNU is exactly the same, namely, 4ψPψN/(ψP+ψN). Nevertheless, R̂γN-PNPU(g) and R̂ γ N-PNNU(g) have a much wider range of nice γ values than R̂γN-PUNU(g).\nIf we further assume that σP(g) = σN(g), the condition in Theorems 3 and 4 as to whether ψP ≤ ψN or ψP ≥ ψN will be independent of g. Also, it will coincide with the condition in Theorem 7 in Niu et al. (2016) where the minimizers of R̂PN(g), R̂PU(g) and R̂NU(g) are compared.\nA final remark is that learning is uninvolved in Theorems 3 and 4, such that ℓ(m) can be any loss that satisfies ℓ(m) + ℓ(−m) = 1, and g can be any fixed decision function. For instance, we may adopt ℓ0-1(m) and pick some g resulted from some other learning methods. As a consequence, the variance of ÎPN(g) over the validation data can be reduced, and then the cross-validation should be more stable, given that nU is sufficiently large. Therefore, even without being minimized, our proposed risk estimators are themselves of practical importance."
  }, {
    "heading": "4.3. PUNU vs. PNU Classification",
    "text": "We discuss here which approach, PUNU or PNU classification, is more promising according to state-of-the-art theoretical comparisons (Niu et al., 2016), which are based on estimation error bounds.\nLet ĝPN, ĝPU, and ĝNU be the minimizers of R̂PN(g), R̂PU(g), and R̂NU(g), respectively. Let αPU,PN := (θP/ √ nP + 1/ √ nU)/(θN/ √ nN) and αNU,PN := (θN/ √ nN + 1/ √ nU)/(θP/ √ nP). The finite-sample comparisons state that if αPU,PN > 1 (αNU,PN > 1), PN classification is more promising than PU (NU) classification, i.e., R(ĝPN) < R(ĝPU) (R(ĝPN) < R(ĝNU)); otherwise PU (NU) classification is more promising than PN classification (cf. Section 3.2 in Niu et al., 2016).\nSuppose that nU is not sufficiently large against nP and nN. According to the finite-sample comparisons, PN classification is most promising, and either PU or NU classification is the second best, i.e., R(ĝPN) < R(ĝPU) < R(ĝNU) or R(ĝPN) < R(ĝNU) < R(ĝPU). On the other hand, if nU is sufficiently large (nU → ∞, which is faster than nP, nN → ∞), we have the asymptotic comparisons: α∗PU,PN = limnP,nN,nU→∞ αPU,PN, α ∗ NU,PN =\nlimnP,nN,nU→∞ αNU,PN, and α ∗ PU,PN ·α∗NU,PN = 1. From the last equation, if α∗PU,PN < 1, then α ∗\nNU,PN > 1, implying that PU (PN) classification is more promising than PN (NU) classification, i.e., R(ĝPU) < R(ĝPN) < R(ĝNU). Similarly, when α∗PU,PN > 1 and α ∗\nNU,PN < 1, R(ĝNU) < R(ĝPN) < R(ĝPU) (cf. Section 3.3 in Niu et al., 2016).\nIn real-world applications, since we do not know whether the number of unlabeled samples is sufficiently large or not, a practical approach is to combine the best methods in both the finite-sample and asymptotic cases. PNU classification is the combination of the best methods in both cases, but PUNU classification is not. In addition, PUNU classification includes the worst one in its combination in both cases. From this viewpoint, PNU classification would be more promising than PUNU classification, as demonstrated in the experiments shown in the next section."
  }, {
    "heading": "5. Experiments",
    "text": "In this section, we first numerically analyze the proposed approach and then compare the proposed semi-supervised classification methods against existing methods. All experiments were carried out using a PC equipped with two 2.60GHz Intel® Xeon® E5-2640 v3 CPUs."
  }, {
    "heading": "5.1. Experimental Analyses",
    "text": "Here, we numerically analyze the behavior of our proposed approach. Due to limited space, we show results on two out of six data sets and move the rest to Appendix C.\nCommon Setup: As a classifier, we use the Gaussian kernel model: g(x) = ∑n\ni=1 wi exp(−‖x− xi‖2/(2σ2)), where n = nP + nN, {wi}ni=1 are the parameters, {xi}ni=1 = XP∪XN, and σ > 0 is the Gaussian bandwidth. The bandwidth candidates are {1/8, 1/4, 1/2, 1, 3/2, 2} × median(‖xi − xj‖ni,j=1). The classifier trained by minimizing the empirical PN risk is denoted by ĝPN. The number of labeled samples for training is 20, where the classprior was 0.5. In all experiments, we used the squared loss for training. We note that the class-prior of test data was the same as that of unlabeled data.\nVariance Reduction in Practice: Here, we numerically investigate how many unlabeled samples are sufficient in practice such that the variance of the empirical PNU risk is smaller than that of the PN risk: Var[R̂ηPNU(g)] < Var[R̂PN(g)] given a fixed classifier g.\nAs the fixed classifier, we used the classifier ĝPN, where the hyperparameters were determined by five-fold crossvalidation. To compute the variance of the empirical PN and PNU risks, Var[R̂PN(ĝPN)] and Var[R̂ η PNU(ĝPN)], we repeatedly drew additional nVP = 10 positive, n V N = 10\nnegative, and nVU unlabeled samples from the rest of the data set. The additional samples were also used for approximating σ̂P(ĝPN) and σ̂N(ĝPN) to compute η, i.e., γ in Eqs.(10) and (11).\nFigure 1 shows the ratio between the variance of the empirical PNU risk and that of the PN risk, Var[R̂ηPNU(ĝPN)]/Var[R̂PN(ĝPN)]. The number of unlabeled samples for validation nVU increases from 10 to 300. We see that with a rather small number of unlabeled samples, the ratio becomes less than 1. That is, the variance of the empirical PNU risk becomes smaller than that of the PN risk. This implies that although the variance reduction is proved for an infinite number of unlabeled samples, it can be observed under a finite number of samples in practice.\nCompared to when θP = 0.3 and 0.7, the effect of variance reduction is small when θP = 0.5. This is because if we assume σP(g) ≈ σN(g), when nP ≈ nN and θP = 0.5, we have γN-PNPU ≈ γN-PNNU ≈ 0 (because ψP ≈ ψN. See Theorem 4). That is, the PNU risk is dominated by the PN risk, implying that Var[R̂ηPNU(g)] ≈ Var[R̂PN(g)]. Note that the class-prior is not the only factor for variance reduction; for example, if θP = 0.5, nP ≫ nN, and σP(g) ≈ σN(g), then γN-PNPU 6≈ 0 (because ψP ≪ ψN) and the variance reduction will be large.\nPNU Risk in Validation: As discussed in Section 4, the empirical PNU risk will be a reliable validation score due to its having smaller variance than the empirical PN risk. We show here that the empirical PNU risk is a promising alternative to a validation score.\nTo focus on the effect of validation scores only, we trained two classifiers by using the same risk, e.g, the empirical PN risk. We then tune the classifiers with the empirical PN and PNU risks denoted by ĝPNPN and ĝ PNU PN , respectively. The number of validation samples was the same as in the previous experiment.\nFigure 2 shows the ratio between the misclassification rate of ĝPNUPN and that of ĝ PN PN . The number of unlabeled samples for validation increases from 10 to 300. With a rather small number of unlabeled samples, the ratio becomes less than 1, i.e., ĝPNUPN achieves better performance than ĝ PN PN . In particular, when θP = 0.3 and 0.7, ĝ PNU PN improved substantially; the large improvement tends to give the large variance reduction (cf. Figure 1). This result shows that the use of the empirical PNU risk for validation improved the classification performance given a relatively large size of unlabeled data."
  }, {
    "heading": "5.2. Comparison with Existing Methods",
    "text": "Next, we numerically compare the proposed methods against existing semi-supervised classification methods.\nCommon Setup: We compare our methods against five conventional semi-supervised classification methods: entropy regularization (ER) (Grandvalet & Bengio, 2004), the Laplacian support vector machine (LapSVM) (Belkin et al., 2006; Melacci & Belkin, 2011), squared-loss mutual information regularization (SMIR) (Niu et al., 2013), the weakly labeled support vector machine (WellSVM) (Li et al., 2013), and the safe semi-supervised support vector machine (S4VM) (Li & Zhou, 2015).\nAmong the proposed methods, PNU classification and\nTable 1. Average and standard error of the misclassification rates of each method over 50 trials for benchmark data sets. Boldface numbers denote the best and comparable methods in terms of average misclassifications rate according to a t-test at a significance level of 5%. The bottom row gives the number of best/comparable cases of each method.\nData set nL PNU PUNU ER LapSVM SMIR WellSVM S4VM Banana 10 30.1 (1.0) 32.1 (1.1) 35.8 (1.0) 36.9 (1.0) 37.7 (1.1) 41.8 (0.6) 45.3 (1.0) d = 2 50 19.0 (0.6) 26.4 (1.2) 20.6 (0.7) 21.3 (0.7) 21.1 (1.0) 42.6 (0.5) 38.7 (0.9) Phoneme 10 32.5 (0.8) 33.5 (1.0) 33.4 (1.2) 36.5 (1.5) 36.4 (1.2) 28.4 (0.6) 33.7 (1.4) d = 5 50 28.1 (0.5) 32.8 (0.9) 27.8 (0.6) 27.0 (0.8) 28.6 (1.0) 26.8 (0.4) 25.1 (0.2)\nMagic 10 31.7 (0.8) 34.1 (0.9) 34.2 (1.1) 37.9 (1.3) 36.0 (1.2) 30.1 (0.8) 33.3 (0.9) d = 10 50 29.9 (0.8) 33.4 (0.9) 30.9 (0.5) 31.0 (0.9)30.8 (0.9) 28.8 (0.8) 29.2 (0.4) Image 10 29.8 (0.9) 31.7 (0.8) 33.7 (1.1) 36.6 (1.2) 36.7 (1.2) 34.7 (1.1) 35.9 (1.0) d = 18 50 20.7 (0.8) 26.6 (1.1) 20.8 (0.8) 20.3 (1.0)20.9 (0.9) 27.2 (1.0) 23.2 (0.7) Susy 10 44.6 (0.6) 45.0 (0.6) 47.7 (0.4) 48.2 (0.4)45.1 (0.7) 48.0 (0.3) 46.8 (0.3) d = 18 50 38.9 (0.6) 41.5 (0.6) 37.9 (0.7) 43.1 (0.6) 43.9 (0.8) 43.8 (0.7) 42.1 (0.4) German 10 40.8 (0.9) 42.4 (0.7) 43.6 (0.9) 45.9 (0.7) 46.2 (0.8) 42.4 (0.8) 42.0 (0.7) d = 20 50 36.2 (0.8) 39.0 (0.8) 38.9 (0.6) 40.6 (0.6) 38.4 (1.1) 38.5 (1.0) 34.9 (0.5)\nWaveform 10 17.4 (0.6) 18.0 (0.9) 18.5 (0.6) 24.9 (1.4)18.0 (1.0) 16.7 (0.6) 20.8 (0.8) d = 21 50 16.3 (0.6) 23.7 (1.2) 14.2 (0.4) 18.1 (0.8)15.4 (0.6) 15.5 (0.5) 15.3 (0.3)\nijcnn1 10 43.6 (0.6) 40.3 (1.0) 49.7 (0.1) 49.2 (0.3) 44.0 (1.0) 45.9 (0.7) 49.3 (0.8) d = 22 50 34.5 (0.8) 37.1 (0.9) 35.5 (0.8) 33.4 (1.1) 49.4 (0.3) 46.2 (0.8) 48.6 (0.4) g50c 10 11.4 (0.6) 12.5 (0.6) 23.3 (2.3) 39.8 (1.6) 21.9 (1.3) 6.6 (0.4) 27.0 (1.4) d = 50 50 12.5 (1.1) 10.1 (0.6) 8.7 (0.4) 22.5 (1.5) 10.6 (0.6) 7.4 (0.4) 12.1 (0.5) covtype 10 46.2 (0.4) 46.0 (0.4) 46.0 (0.5) 47.1 (0.5) 47.9 (0.5) 46.9 (0.6) 46.4 (0.4) d = 54 50 41.3 (0.5) 42.3 (0.5) 41.0 (0.4) 41.5 (0.5) 46.2 (0.8) 43.6 (0.6) 40.8 (0.4)\nSpambase 10 27.2 (0.9) 28.1 (1.1) 31.8 (1.4) 39.7 (1.4) 30.9 (1.3) 23.8 (0.8) 36.1 (1.5) d = 57 50 23.4 (1.0) 26.6 (1.0) 22.1 (0.7) 28.5 (1.3) 20.9 (0.5) 19.1 (0.4) 24.5 (0.9)\nSplice 10 38.3 (0.8) 39.3 (0.8) 43.9 (0.8) 47.9 (0.5) 41.6 (0.7) 42.0 (1.0) 42.4 (0.6) d = 60 50 30.6 (0.8) 34.7 (0.9) 30.9 (0.8) 38.8 (1.0)30.6 (0.9) 40.9 (0.8) 35.9 (0.7) phishing 10 24.2 (1.2) 25.8 (1.0) 27.3 (1.6) 37.2 (1.6) 27.6 (1.6) 27.5 (1.4) 31.7 (1.3) d = 68 50 15.8 (0.6) 18.3 (0.8) 15.4 (0.5) 21.1 (1.3)14.7 (0.8) 17.2 (0.7) 16.7 (0.8)\na9a 10 31.4 (0.9) 31.3 (1.0) 34.3 (1.2) 41.0 (1.1) 37.3 (1.3) 33.1 (1.2) 34.3 (1.2) d = 83 50 27.9 (0.6) 29.9 (0.8) 28.6 (0.7) 33.3 (1.0)26.9 (0.7) 28.9 (0.8) 26.2 (0.4) Coil2 10 38.7 (0.8) 40.1 (0.8) 42.8 (0.7) 43.9 (0.8) 43.2 (0.8) 39.1 (0.9) 44.0 (0.8) d = 241 50 23.2 (0.6) 30.5 (0.9) 23.6 (0.9) 22.8 (0.9) 25.1 (0.9) 22.6 (0.8) 25.4 (0.8)\nw8a 10 35.9 (0.9) 33.6 (1.0) 41.6 (1.0) 46.6 (0.8) 39.4 (0.9) 42.1 (0.8) 43.0 (0.8) d = 300 50 28.1 (0.7) 27.6 (0.6) 27.0 (0.9) 38.7 (0.8)28.0 (0.9) 33.7 (0.8) 35.2 (1.0) #Best/Comp. 23 13 11 4 9 13 7\nPUNU classification with the squared loss were tested.3\nData Sets: We used sixteen benchmark data sets taken from the UCI Machine Learning Repository (Lichman, 2013), the Semi-Supervised Learning book (Chapelle et al., 2006), the LIBSVM (Chang & Lin, 2011), the ELENA Project,4 and a paper by Chapelle & Zien (2005).5 Each feature was scaled to [0, 1]. Similarly to the setting in Section 5.1, we used the Gaussian kernel model for all methods. The training data is {xi}ni=1 = XP ∪XN ∪XU, where n = nP+nN+nU. We selected all hyper-parameters with validation samples of size 20 (nVP = n V N = 10). For training, we drew nL labeled and nU = 300 unlabeled samples. The class-prior of labeled data was set at 0.7 and that of unlabeled samples was set at θP = 0.5 that were assumed to be known. In practice, the class-prior, θP, can be estimated\n3In preliminary experiments, we tested other loss functions such as the ramp and logistic losses and concluded that the difference in loss functions did not provide noticeable difference.\n4https://www.elen.ucl.ac.be/neural-\nnets/Research/Projects/ELENA/elena.htm 5http://olivier.chapelle.cc/lds/\nby methods proposed, e.g., by Blanchard et al. (2010), Ramaswamy et al. (2016), or Kawakubo et al. (2016).\nTable 1 lists the average and standard error of the misclassification rates over 50 trials and the number of best/comparable performances of each method in the bottom row. The superior performance of PNU classification over PUNU classification agrees well with the discussion in Section 4.3. With the g50c data set, which well satisfies the low-density separation principle, the WellSVM achieved the best performance. However, in the Banana data set, where the two classes are highly overlapped, the performance of WellSVM was worse than the other methods. In contrast, PNU classification achieved consistently better/comparable performance and its performance did not degenerate considerably across data sets. These results show that the idea of using PU classification in semisupervised classification is promising.\nFigure 3 plots the computation time, which shows that the fastest computation was achieved using the proposed methods with the square loss.\nImage Classification: Finally, we used the Places 205 data set (Zhou et al., 2014), which contains 2.5 million images in 205 scene classes. We used a 4096-dimensional feature vector extracted from each image by AlexNet under the framework of Caffe,6 which is available on the project website7. We chose two similar scenes to construct binary classification tasks (see the description of data sets in Appendix B.3). We drew 100 labeled and nU unlabeled samples from each task; the class-prior of labeled and unlabeled data were respectively set at 0.5 and θP = mP/(mP + mN), where mP and mN respectively denote the number of total samples in positive and negative scenes. We used a linear\n6http://caffe.berkeleyvision.org/ 7http://places.csail.mit.edu/\nclassifier g(x) = w⊤x+w0, where w is the weight vector and w0 is the offset (in the SMIR, the linear kernel model is used; see Niu et al. (2013) for details).\nWe selected hyper-parameters in PNU classification by applying five-fold cross-validation with respect to Rη̄PNU(g) with the zero-one loss, where η̄ was set at Eq.(10) or Eq.(11) with σP(g) = σN(g). The class-prior p(y = +1) = θP was estimated using the method based on energy distance minimization (Kawakubo et al., 2016).\nTable 2 lists the average and standard error of the misclassification rates over 30 trials, where methods taking more than 2 hours were omitted and indicated as N/A. The results show that PNU classification was most effective. The average computation times are shown in Figure 4, revealing again that PNU classification was the fastest method."
  }, {
    "heading": "6. Conclusions",
    "text": "In this paper, we proposed a novel semi-supervised classification approach based on classification from positive and unlabeled data. Unlike most of the conventional methods, our approach does not require strong assumptions on the data distribution such as the cluster assumption. We theoretically analyzed the variance of risk estimators and showed that unlabeled data help reduce the variance without the conventional distributional assumptions. We also established generalization error bounds and showed that the confidence term decreases with respect to the number of positive, negative, and unlabeled samples without the conventional distributional assumptions in the optimal parametric order. We experimentally analyzed the behavior of the proposed methods and demonstrated that one of the proposed methods, termed PNU classification, was most effective in terms of both classification accuracy and computational efficiency. It was recently pointed out that PU classification can behave undesirably for very flexible models and a modified PU risk has been proposed (Kiryo et al., 2017). Our future work is to develop a semi-supervised classification method based on the modified PU classification."
  }, {
    "heading": "Acknowledgements",
    "text": "TS was supported by JSPS KAKENHI 15J09111. GN was supported by the JST CREST program and Microsoft Research Asia. MCdP and MS were supported by the JST CREST program."
  }],
  "year": 2017,
  "references": [{
    "title": "Manifold regularization: A geometric framework for learning from labeled and unlabeled examples",
    "authors": ["M. Belkin", "P. Niyogi", "V. Sindhwani"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2006
  }, {
    "title": "Semi-supervised novelty detection",
    "authors": ["G. Blanchard", "G. Lee", "C. Scott"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "LIBSVM: A library for support vector machines",
    "authors": ["Chang", "C.-C", "Lin", "C.-J"],
    "venue": "ACM Transactions on Intelligent Systems and Technology,",
    "year": 2011
  }, {
    "title": "Semi-supervised classification by low density separation",
    "authors": ["O. Chapelle", "A. Zien"],
    "venue": "In AISTATS, pp",
    "year": 2005
  }, {
    "title": "Trading convexity for scalability",
    "authors": ["R. Collobert", "F. Sinz", "J. Weston", "L. Bottou"],
    "venue": "In ICML, pp",
    "year": 2006
  }, {
    "title": "Semisupervised learning of mixture models",
    "authors": ["F.G. Cozman", "I. Cohen", "M.C. Cirelo"],
    "venue": "In ICML, pp",
    "year": 2003
  }, {
    "title": "Analysis of learning from positive and unlabeled data",
    "authors": ["M.C. du Plessis", "G. Niu", "M. Sugiyama"],
    "venue": "In NIPS,",
    "year": 2014
  }, {
    "title": "Convex formulation for learning from positive and unlabeled data",
    "authors": ["M.C. du Plessis", "G. Niu", "M. Sugiyama"],
    "venue": "In ICML,",
    "year": 2015
  }, {
    "title": "Learning classifiers from only positive and unlabeled data",
    "authors": ["C. Elkan", "K. Noto"],
    "venue": "In SIGKDD, pp",
    "year": 2008
  }, {
    "title": "Semi-supervised learning by entropy minimization",
    "authors": ["Y. Grandvalet", "Y. Bengio"],
    "venue": "In NIPS, pp",
    "year": 2004
  }, {
    "title": "Estimating the class prior and posterior from noisy positives and unlabeled data",
    "authors": ["S. Jain", "M. White", "P. Radivojac"],
    "year": 2016
  }, {
    "title": "Computationally efficient class-prior estimation under class balance change using energy distance",
    "authors": ["H. Kawakubo", "M.C. du Plessis", "M. Sugiyama"],
    "venue": "IEICE Transactions on Information and Systems,",
    "year": 2016
  }, {
    "title": "Positive-unlabeled learning with non-negative risk estimator",
    "authors": ["R. Kiryo", "G. Niu", "M.C. du Plessis", "M. Sugiyama"],
    "venue": "arXiv preprint arXiv:1703.00593,",
    "year": 2017
  }, {
    "title": "Robust semi-supervised least squares classification by implicit constraints",
    "authors": ["J.H. Krijthe", "M. Loog"],
    "venue": "Pattern Recognition,",
    "year": 2017
  }, {
    "title": "Probability in Banach Spaces: Isoperimetry and Processes",
    "authors": ["M. Ledoux", "M. Talagrand"],
    "year": 1991
  }, {
    "title": "Towards making unlabeled data never hurt",
    "authors": ["Li", "Y.-F", "Zhou", "Z.-H"],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
    "year": 2015
  }, {
    "title": "Convex and scalable weakly labeled SVMs",
    "authors": ["Li", "Y.-F", "I.W. Tsang", "J.T. Kwok", "Zhou", "Z.-H"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2013
  }, {
    "title": "Laplacian support vector machines trained in the primal",
    "authors": ["S. Melacci", "M. Belkin"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2011
  }, {
    "title": "Lower bounds for the empirical minimization algorithm",
    "authors": ["S. Mendelson"],
    "venue": "IEEE Transactions on Information Theory,",
    "year": 2008
  }, {
    "title": "Foundations of Machine Learning",
    "authors": ["M. Mohri", "A. Rostamizadeh", "A. Talwalkar"],
    "year": 2012
  }, {
    "title": "Squared-loss mutual information regularization: A novel information-theoretic approach to semisupervised learning",
    "authors": ["G. Niu", "W. Jitkrittum", "B. Dai", "H. Hachiya", "M. Sugiyama"],
    "venue": "In ICML,",
    "year": 2013
  }, {
    "title": "Theoretical comparisons of positive-unlabeled learning against positive-negative learning",
    "authors": ["G. Niu", "M.C. du Plessis", "T. Sakai", "Y. Ma", "M. Sugiyama"],
    "year": 2016
  }, {
    "title": "Mixture proportion estimation via kernel embedding of distributions",
    "authors": ["H.G. Ramaswamy", "C. Scott", "A. Tewari"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "The asymptotics of semi-supervised learning in discriminative probabilistic models",
    "authors": ["N. Sokolovska", "O. Cappé", "F. Yvon"],
    "venue": "In ICML, pp",
    "year": 2008
  }, {
    "title": "Statistical Learning Theory",
    "authors": ["V.N. Vapnik"],
    "year": 1998
  }, {
    "title": "The Nature of Statistical Learning Theory",
    "authors": ["V.N. Vapnik"],
    "year": 1995
  }, {
    "title": "The concave-convex procedure (CCCP)",
    "authors": ["A.L. Yuille", "A. Rangarajan"],
    "venue": "In NIPS, pp. 1033–1040,",
    "year": 2002
  }, {
    "title": "Learning deep features for scene recognition using places database",
    "authors": ["B. Zhou", "A. Lapedriza", "J. Xiao", "A. Torralba", "A. Oliva"],
    "venue": "In NIPS, pp",
    "year": 2014
  }],
  "id": "SP:1a11031f4c89e909b3e68835d3a66827eb5e9b65",
  "authors": [{
    "name": "Tomoya Sakai",
    "affiliations": []
  }, {
    "name": "Marthinus Christoffel du Plessis",
    "affiliations": []
  }, {
    "name": "Gang Niu",
    "affiliations": []
  }, {
    "name": "Masashi Sugiyama",
    "affiliations": []
  }],
  "abstractText": "Most of the semi-supervised classification methods developed so far use unlabeled data for regularization purposes under particular distributional assumptions such as the cluster assumption. In contrast, recently developed methods of classification from positive and unlabeled data (PU classification) use unlabeled data for risk evaluation, i.e., label information is directly extracted from unlabeled data. In this paper, we extend PU classification to also incorporate negative data and propose a novel semi-supervised classification approach. We establish generalization error bounds for our novel methods and show that the bounds decrease with respect to the number of unlabeled data without the distributional assumptions that are required in existing semi-supervised classification methods. Through experiments, we demonstrate the usefulness of the proposed methods.",
  "title": "Semi-Supervised Classification Based on Classification from Positive and Unlabeled Data"
}