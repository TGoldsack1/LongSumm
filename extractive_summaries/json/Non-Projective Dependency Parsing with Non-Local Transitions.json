{
  "sections": [{
    "text": "Proceedings of NAACL-HLT 2018, pages 693–700 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Greedy transition-based parsers are popular in NLP, as they provide competitive accuracy with high efficiency. They syntactically analyze a sentence by greedily applying transitions, which read it from left to right and produce a dependency tree.\nHowever, this greedy process is prone to error propagation: one wrong choice of transition can lead the parser to an erroneous state, causing more incorrect decisions. This is especially crucial for long attachments requiring a larger number of transitions. In addition, transition-based parsers traditionally focus on only two words of the sentence and their local context to choose the next transition. The lack of a global perspective favors the presence of errors when creating arcs involving multiple transitions. As expected, transition-based parsers build short arcs more accurately than long ones (McDonald and Nivre, 2007).\nPrevious research such as (Fernández-González and Gómez-Rodrı́guez, 2012) and (Qi and Manning, 2017) proves that the widely-used projective arc-eager transition-based parser of Nivre (2003) benefits from shortening the length of transition\nsequences by creating non-local attachments. In particular, they augmented the original transition system with new actions whose behavior entails more than one arc-eager transition and involves a context beyond the traditional two focus words. Attardi (2006) and Sartorio et al. (2013) also extended the arc-standard transition-based algorithm (Nivre, 2004) with the same success.\nIn the same vein, we present a novel unrestricted non-projective transition system based on the well-known algorithm by Covington (2001) that shortens the transition sequence necessary to parse a given sentence by the original algorithm, which becomes linear instead of quadratic with respect to sentence length. To achieve that, we propose new transitions that affect non-local words and are equivalent to one or more Covington actions, in a similar way to the transitions defined by Qi and Manning (2017) based on the arc-eager parser. Experiments show that this novel variant significantly outperforms the original one in all datasets tested, and achieves the best reported accuracy for a greedy dependency parser on the Stanford Dependencies conversion of the WSJ Penn Treebank."
  }, {
    "heading": "2 Non-Projective Covington Parser",
    "text": "The original non-projective parser defined by Covington (2001) was modelled under the transitionbased parsing framework by Nivre (2008). We only sketch this transition system briefly for space reasons, and refer to (Nivre, 2008) for details.\nParser configurations have the form c = 〈λ1, λ2, B,A〉, where λ1 and λ2 are lists of partially processed words, B a list (called buffer) of unprocessed words, and A the set of dependency arcs built so far. Given an input string w1 · · ·wn, the parser starts at the initial configuration cs(w1 . . . wn) = 〈[], [], [1 . . . n], ∅〉 and runs transitions until a terminal configuration of the\n693\nform 〈λ1, λ2, [], A〉 is reached: at that point, A contains the dependency graph for the input.1\nThe set of transitions is shown in the top half of Figure 1. Their logic can be summarized as follows: when in a configuration of the form 〈λ1|i, λ2, j|B,A〉, the parser has the chance to create a dependency involving words i and j, which we will call left and right focus words of that configuration. The Left-Arc and Right-Arc transitions are used to create a leftward (i ← j) or rightward arc (i → j), respectively, between these words, and also move i from λ1 to the first position of λ2, effectively moving the focus to i − 1 and j. If no dependency is desired between the focus words, the No-Arc transition makes the same modification of λ1 and λ2, but without building any arc. Finally, the Shift transition moves the whole content of the list λ2 plus j to λ1 when no more attachments are pending between j and the words of λ1, thus reading a new input word and placing the focus on j and j + 1. Transitions that create arcs are disallowed in configurations where this would violate the single-head or acyclicity constraints (cycles and nodes with multiple heads are not allowed in the dependency graph). Figure 3 shows the transition sequence in the Covington transition system which derives the dependency graph in Figure 2.\nThe resulting parser can generate arbitrary nonprojective trees, and its complexity is O(n2)."
  }, {
    "heading": "3 Non-Projective NL-Covington Parser",
    "text": "The original logic described by Covington (2001) parses a sentence by systematically traversing\n1Note that, in general, A is a forest, but it can be converted to a tree by linking headless nodes as dependents of an artificial root node at position 0.\nevery pair of words. The Shift transition, introduced by Nivre (2008) in the transition-based version, is an optimization that avoids the need to apply a sequence of No-Arc transitions to empty the list λ1 before reading a new input word.\nHowever, there are still situations where sequences of No-Arc transitions are needed. For example, if we are in a configuration C with focus words i and j and the next arc we need to create\ngoes from j to i − k (k > 1), then we will need k − 1 consecutive No-Arc transitions to move the left focus word to i and then apply Left-Arc. This could be avoided if a non-local Left-Arc transition could be undertaken directly at C, creating the required arc and moving k words to λ2 at once. The advantage of such approach would be twofold: (1) less risk of making a mistake at C due to considering a limited local context, and (2) shorter transition sequence, alleviating error propagation.\nWe present a novel transition system called NLCovington (for “non-local Covington”), described in the bottom half of Figure 1. It consists in a modification of the non-projective Covington algorithm where: (1) the Left-Arc and Right-Arc transitions are parameterized with k, allowing the immediate creation of any attachment between j and the kth leftmost word in λ1 and moving k words to λ2 at once, and (2) the No-Arc transition is removed since it is no longer necessary.\nThis new transition system can use some restricted global information to build non-local dependencies and, consequently, reduce the number of transitions needed to parse the input. For instance, as presented in Figure 4, the NL-Covington parser will need 9 transitions, instead of 12 traditional Covington actions, to analyze the sentence in Figure 2.\nIn fact, while in the standard Covington algorithm a transition sequence for a sentence of length n has length O(n2) in the worst case (if all nodes are connected to the first node, then we need to traverse every node to the left of each right focus word); for NL-Covington the sequence length is alwaysO(n): one Shift transition for each of the n words, plus one arc-building transition for each of the n − 1 arcs in the dependency tree. Note, however, that this does not affect the parser’s time complexity, which is still quadratic as in the original Covington parser. This is because the algorithm hasO(n) possible transitions to be scored at each configuration, while the original Covington has O(1) transitions due to being limited to creating local leftward/rightward arcs between the focus words.\nThe completeness and soundness of NLCovington can easily be proved as there is a mapping between transition sequences of both parsers, where a sequence of k − 1 No-Arc and one arc transition in Covington is equivalent to a Left-Arck or Right-Arck in NL-Covington."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Data and Evaluation",
    "text": "We use 9 datasets2 from the CoNLL-X (Buchholz and Marsi, 2006) and all datasets from the CoNLL-XI shared task (Nivre et al., 2007). To compare our system to the current state-of-theart transition-based parsers, we also evaluate it on the Stanford Dependencies (de Marneffe and Manning, 2008) conversion (using the Stanford parser v3.3.0)3 of the WSJ Penn Treebank (Marcus et al., 1993), hereinafter PT-SD, with standard splits. Labelled and Unlabelled Attachment Scores (LAS and UAS) are computed excluding punctuation only on the PT-SD, for comparability. We repeat each experiment with three independent random initializations and report the average accuracy. Statistical significance is assessed by a paired test with 10,000 bootstrap samples."
  }, {
    "heading": "4.2 Model",
    "text": "To implement our approach we take advantage of the model architecture described in Qi and Manning (2017) for the arc-swift parser, which extends the architecture of Kiperwasser and Goldberg (2016) by applying a biaffine combination during the featurization process. We implement both the Covington and NL-Covington parsers under this architecture, adapt the featurization process with biaffine combination of Qi and Manning (2017) to these parsers, and use their same training\n2We excluded the languages from CoNLL-X that also appeared in CoNLL-XI, i.e., if a language was present in both shared tasks, we used the latest version.\n3https://nlp.stanford.edu/software/ lex-parser.shtml\nsetup. More details about these model parameters are provided in Appendix A.\nSince this architecture uses batch training, we train with a static oracle. The NL-Covington algorithm has no spurious ambiguity at all, so there is only one possible static oracle: canonical transition sequences are generated by choosing the transition that builds the shortest pending gold arc involving the current right focus word j, or Shift if there are no unbuilt gold arcs involving j.\nWe note that a dynamic oracle can be obtained for the NL-Covington parser by adapting the one for standard Covington of Gómez-Rodrı́guez and Fernández-González (2015). As NL-Covington transitions are concatenations of Covington ones, their loss calculation algorithm is compatible with NL-Covington. Apart from error exploration, this also opens the way to incorporating nonmonotonicity (Fernández-González and GómezRodrı́guez, 2017). While these approaches have shown to improve accuracy under online training settings, here we prioritize homogeneous comparability to (Qi and Manning, 2017), so we use batch training and a static oracle, and still obtain stateof-the-art accuracy for a greedy parser."
  }, {
    "heading": "4.3 Results",
    "text": "Table 1 presents a comparison between the Covington parser and the novel variant developed here. The NL-Covington parser outperforms the original version in all datasets tested, with all improvements statistically significant (α = .05).\nTable 2 compares our novel system with other state-of-the-art transition-based dependency parsers on the PT-SD. Greedy parsers are in the first block, beam-search and dynamic programming parsers in the second block. The third block shows the best result on this benchmark, obtained with constituent parsing with generative re-ranking and conversion to dependencies. Despite being the only non-projective parser tested on a practically projective dataset,4 our parser achieves the highest score among greedy transition-based models (even above those trained with a dynamic oracle).\nWe even slightly outperform the arc-swift system of Qi and Manning (2017), with the same model architecture, implementation and training setup, but based on the projective arc-eager transition-based parser instead. This may be because our system takes into consideration any permissible attachment between the focus word j and any word in λ1 at each configuration, while their approach is limited by the arc-eager logic: it al-\n4Only 41 out of 39,832 sentences of the PT-SD training dataset present some kind of non-projectivity.\nlows all possible rightward arcs (possibly fewer than our approach as the arc-eager stack usually contains a small number of words), but only one leftward arc is permitted per parser state. It is also worth noting that the arc-swift and NL-Covington parsers have the same worst-case time complexity, (O(n2)), as adding non-local arc transitions to the arc-eager parser increases its complexity from linear to quadratic, but it does not affect the complexity of the Covington algorithm. Thus, it can be argued that this technique is better suited to Covington than to arc-eager parsing.\nWe also compare NL-Covington to the arcswift parser on the CoNLL datasets (Table 3). For fairness of comparison, we projectivize (via maltparser5) all training datasets, instead of filtering non-projective sentences, as some of the languages are significantly non-projective. Even doing that, the NL-Covington parser improves over the arc-swift system in terms of UAS in 14 out of 19 datasets, obtaining statistically significant improvements in accuracy on 7 of them, and statistically significant decreases in just one.\nFinally, we analyze how our approach reduces the length of the transition sequence consumed by\n5http://www.maltparser.org/\nthe original Covington parser. In Table 4 we report the transition sequence length per sentence used by the Covington and the NL-Covington algorithms to analyze each dataset from the same benchmark used for evaluating parsing accuracy. As seen in the table, NL-Covington produces notably shorter transition sequences than Covington, with a reduction close to 50% on average."
  }, {
    "heading": "5 Conclusion",
    "text": "We present a novel variant of the non-projective Covington transition-based parser by incorporating non-local transitions, reducing the length of transition sequences from O(n2) to O(n). This system clearly outperforms the original Covington parser and achieves the highest accuracy on the WSJ Penn Treebank (Stanford Dependencies) obtained to date with greedy dependency parsing."
  }, {
    "heading": "Acknowledgments",
    "text": "This work has received funding from the European Research Council (ERC), under the European Union’s Horizon 2020 research and innovation programme (FASTPARSE, grant agreement No 714150), from the TELEPARES-UDC (FFI201451978-C2-2-R) and ANSWER-ASAP (TIN201785160-C2-1-R) projects from MINECO, and from Xunta de Galicia (ED431B 2017/01)."
  }, {
    "heading": "A Model Details",
    "text": "We provide more details of the neural network architecture used in this paper, which is taken from Qi and Manning (2017).\nThe model consists of two blocks of 2-layered bidirectional long short-term memory (BiLSTM) networks (Graves and Schmidhuber, 2005) with 400 hidden units in each direction. The first block is used for POS tagging and the second one, for parsing. As the input of the tagging block, we use words represented as word embeddings, and BiLSTMs are employed to perform feature extraction. The resulting output is fed into a multi-layer perceptron (MLP), with a hidden layer of 100 rectified linear units (ReLU), that provides a POS tag for each input token in a 32-dimensional representation. Word embeddings concatenated to these POS tag embeddings serve as input of the second block of BiLSTMs to undertake the parsing stage. Then, the output of the parsing block is fed into a MLP with two separate ReLU hidden layers (one for deriving the representation of the head, and the other for the dependency label) that, after being merged and by means of a softmax function, score all the feasible transitions, allowing to greedily choose and apply the highest-scoring one.\nMoreover, we adapt the featurization process with biaffine combination described in Qi and Manning (2017) for the arc-swift system to be used on the original Covington and NL-Covington parsers. In particular, arc transitions are featurized by the concatenation of the representation of the head and dependent words of the arc to be created, the No-Arc transition is featurized by the rightmost word in λ1 and the leftmost word in the buffer B and, finally, for the Shift transition only the leftmost word in B is used. Unlike Qi and Manning (2017) do for baseline parsers, we do not use the featurization method detailed in Kiperwasser and Goldberg (2016)6 for the original Covington parser, as we observed that this results in lower\n6For instance, Kiperwasser and Goldberg (2016) featurize all transitions of the arc-eager parser in the same way by concatenating the representations of the top 3 words on the stack and the leftmost word in the buffer.\nscores and then the comparison would be unfair in our case. We implement both systems under the same framework, with the original Covington parser represented as the NL-Covington system plus the No-Arc transition and with k limited to 1. A thorough description of the model architecture and featurization mechanism can be found in Qi and Manning (2017).\nOur training setup is exactly the same used by Qi and Manning (2017), training the models during 10 epochs for large datasets and 30 for small ones. In addition, we initialize word embeddings with 100-dimensional GloVe vectors (Pennington et al., 2014) for English and use 300-dimensional Facebook vectors (Bojanowski et al., 2016) for other languages. The other parameters of the neural network keep the same values.\nThe parser’s source code is freely available at https://github.com/danifg/ Non-Local-Covington."
  }],
  "year": 2018,
  "references": [{
    "title": "Improved transition-based parsing and tagging with neural networks",
    "authors": ["Chris Alberti", "David Weiss", "Greg Coppola", "Slav Petrov."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon,",
    "year": 2015
  }, {
    "title": "Globally normalized transition-based neural networks",
    "authors": ["Daniel Andor", "Chris Alberti", "David Weiss", "Aliaksei Severyn", "Alessandro Presta", "Kuzman Ganchev", "Slav Petrov", "Michael Collins."],
    "venue": "Proceedings of the 54th Annual Meeting of the Associ-",
    "year": 2016
  }, {
    "title": "Experiments with a multilanguage non-projective dependency parser",
    "authors": ["Giuseppe Attardi."],
    "venue": "Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL). pages 166– 170.",
    "year": 2006
  }, {
    "title": "Training with exploration improves a greedy stack-lstm parser",
    "authors": ["Miguel Ballesteros", "Yoav Goldberg", "Chris Dyer", "Noah A. Smith."],
    "venue": "CoRR abs/1603.03793. http://arxiv.org/abs/1603.03793.",
    "year": 2016
  }, {
    "title": "Enriching word vectors with subword information",
    "authors": ["Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov."],
    "venue": "arXiv preprint arXiv:1607.04606 .",
    "year": 2016
  }, {
    "title": "CoNLL-X shared task on multilingual dependency parsing",
    "authors": ["Sabine Buchholz", "Erwin Marsi."],
    "venue": "Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL). pages 149–164. http://www.aclweb.org/anthology/W06-",
    "year": 2006
  }, {
    "title": "A fast and accurate dependency parser using neural networks",
    "authors": ["Danqi Chen", "Christopher Manning."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Doha, Qatar, pages 740–750.",
    "year": 2014
  }, {
    "title": "A fundamental algorithm for dependency parsing",
    "authors": ["Michael A. Covington."],
    "venue": "Proceedings of the 39th Annual ACM Southeast Conference. ACM, New York, NY, USA, pages 95–102.",
    "year": 2001
  }, {
    "title": "The stanford typed dependencies representation",
    "authors": ["Marie-Catherine de Marneffe", "Christopher D. Manning."],
    "venue": "Coling 2008: Proceedings of the Workshop on Cross-Framework and Cross-Domain Parser Evaluation. Associ-",
    "year": 2008
  }, {
    "title": "Transitionbased dependency parsing with stack long shortterm memory",
    "authors": ["Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computa-",
    "year": 2015
  }, {
    "title": "Improving transition-based dependency parsing with buffer transitions",
    "authors": ["Daniel Fernández-González", "Carlos GómezRodrı́guez"],
    "venue": "In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Com-",
    "year": 2012
  }, {
    "title": "A full non-monotonic transition system for unrestricted non-projective parsing",
    "authors": ["Daniel Fernández-González", "Carlos GómezRodrı́guez"],
    "venue": "In Proceedings of the 55th Annual Meeting of the Association",
    "year": 2017
  }, {
    "title": "An efficient dynamic oracle for unrestricted non-projective parsing",
    "authors": ["Carlos Gómez-Rodrı́guez", "Daniel FernándezGonzález"],
    "venue": "In Proceedings of the 53rd Annual Meeting of the Association",
    "year": 2015
  }, {
    "title": "Framewise phoneme classification with bidirectional lstm and other neural network architectures",
    "authors": ["Alex Graves", "Jürgen Schmidhuber."],
    "venue": "Neural Networks pages 5–6.",
    "year": 2005
  }, {
    "title": "Simple and accurate dependency parsing using bidirectional LSTM feature representations",
    "authors": ["Eliyahu Kiperwasser", "Yoav Goldberg."],
    "venue": "TACL 4:313–327. https://transacl.org/ojs/index.php/tacl/article/view/885.",
    "year": 2016
  }, {
    "title": "What do recurrent neural network grammars learn about syntax",
    "authors": ["Adhiguna Kuncoro", "Miguel Ballesteros", "Lingpeng Kong", "Chris Dyer", "Graham Neubig", "Noah A. Smith"],
    "venue": "In Proceedings of the 15th Conference",
    "year": 2017
  }, {
    "title": "Building a large annotated",
    "authors": ["Mitchell P. Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz"],
    "year": 1993
  }, {
    "title": "Characterizing the errors of data-driven dependency parsing models",
    "authors": ["Ryan McDonald", "Joakim Nivre."],
    "venue": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language",
    "year": 2007
  }, {
    "title": "An efficient algorithm for projective dependency parsing",
    "authors": ["Joakim Nivre."],
    "venue": "Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03). ACL/SIGPARSE, pages 149–160.",
    "year": 2003
  }, {
    "title": "Incrementality in deterministic dependency parsing",
    "authors": ["Joakim Nivre."],
    "venue": "Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together (ACL). pages 50–57.",
    "year": 2004
  }, {
    "title": "Algorithms for Deterministic Incremental Dependency Parsing",
    "authors": ["Joakim Nivre."],
    "venue": "Computational Linguistics 34(4):513–553. https://doi.org/10.1162/coli.07-056-R1-07-027.",
    "year": 2008
  }, {
    "title": "The CoNLL 2007 shared task on dependency parsing",
    "authors": ["Joakim Nivre", "Johan Hall", "Sandra Kübler", "Ryan McDonald", "Jens Nilsson", "Sebastian Riedel", "Deniz Yuret."],
    "venue": "Proceedings of the CoNLL Shared Task Session",
    "year": 2007
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."],
    "venue": "Empirical Methods in Natural Language Processing (EMNLP). pages 1532– 1543. http://www.aclweb.org/anthology/D14-1162.",
    "year": 2014
  }, {
    "title": "Arcswift: A novel transition system for dependency parsing",
    "authors": ["Peng Qi", "Christopher D. Manning."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - Au-",
    "year": 2017
  }, {
    "title": "A transition-based dependency parser using a dynamic parsing strategy",
    "authors": ["Francesco Sartorio", "Giorgio Satta", "Joakim Nivre."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
    "year": 2013
  }, {
    "title": "Fast(er) exact decoding and global training for transition-based dependency parsing via a minimal feature set",
    "authors": ["Tianze Shi", "Liang Huang", "Lillian Lee."],
    "venue": "CoRR abs/1708.09403. http://arxiv.org/abs/1708.09403.",
    "year": 2017
  }, {
    "title": "Structured training for neural network transition-based parsing",
    "authors": ["David Weiss", "Chris Alberti", "Michael Collins", "Slav Petrov."],
    "venue": "Proceedings of",
    "year": 2015
  }, {
    "title": "2016) featurize all transitions of the arc-eager parser in the same way by concatenating the representations of the top 3 words on the stack and the leftmost word in the buffer",
    "authors": ["Kiperwasser", "Goldberg"],
    "year": 2016
  }, {
    "title": "2017), training the models dur",
    "authors": ["Qi", "Manning"],
    "year": 2017
  }],
  "id": "SP:1e2918073821de7fe05c5d066e5fc0a0f9733b6c",
  "authors": [{
    "name": "Daniel Fernández-González",
    "affiliations": []
  }, {
    "name": "Carlos Gómez-Rodrı́guez",
    "affiliations": []
  }],
  "abstractText": "We present a novel transition system, based on the Covington non-projective parser, introducing non-local transitions that can directly create arcs involving nodes to the left of the current focus positions. This avoids the need for long sequences of No-Arc transitions to create long-distance arcs, thus alleviating error propagation. The resulting parser outperforms the original version and achieves the best accuracy on the Stanford Dependencies conversion of the Penn Treebank among greedy transition-based parsers.",
  "title": "Non-Projective Dependency Parsing with Non-Local Transitions"
}