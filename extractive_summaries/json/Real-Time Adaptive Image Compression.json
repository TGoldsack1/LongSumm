{
  "sections": [{
    "text": "important function used in modern digital video cameras to improve visual quality of color images suffered from low dynamic range and poor contrast defects. This study addresses real-time implementation of an adaptive dynamic range compression algorithm for color image/video enhancement. To achieve this purpose, we first propose a new image-dependent nonlinear intensity-transfer function to produce a satisfactory dynamic range compression result with less color artifacts. The proposed algorithm is then derived by combining the new adaptive nonlinear intensitytransfer function with an efficient local contrast enhancement algorithm. Moreover, an algorithmic acceleration method is also presented to accelerate the processing speed of the proposed color image enhancementmethod, achieving real-time performance in processing high-definition video signals. Experimental results validate the performance of the developed method in terms of quantitative evaluation, visual quality, computational efficiency, and power consumption.\nKeywords Adaptive dynamic range compression Color image enhancement Local contrast enhancement Real-time implementation Algorithmic acceleration"
  }, {
    "heading": "1 Introduction",
    "text": "Recent advances in visual sensing technology have made vision sensors more attractive to be used in modern\nintelligent systems. Such systems usually require use of sophisticated computer vision algorithms, in which image enhancement plays an important preliminary processing role in a variety of vision-based technical applications (i.e., contour detection in object extraction, local contrast enhancement in object recognition, etc.). The study of image enhancement to improve visual quality of images is an active research area in image and video processing. Numerous methods have been reported in the literature for gray-image enhancement during the past two decades; however, they often cannot directly apply on natural color images. As color is an important cue in many computer vision applications, color image enhancement has now become a significant task for the development of intelligent vision systems. Nature color images taken from a commercial digital video camera usually suffer from certain defects caused by image sensor limitations on dynamic range, pixel resolution, and light sensitivity, etc. Although several image enhancement methods have been proposed to deal with color image defects (i.e., low dynamic range, poor contrast, and color distortion, etc.), there is always room for improvement, especially in computational efficiency for real-time applications.\nThis paper addresses real-time implementation of an adaptive color image enhancement scheme to deal with low dynamic range and poor contrast defects. Current digital video cameras can only capture images with a limited dynamic range, and the captured image may result in poor visibility due to overexposure in bright regions and underexposure in dark regions. This problem motivates the development of an image enhancement process, commonly known as dynamic range compression, to handle high dynamic range scenes by compressing the dynamic range of captured images. Various dynamic range compression techniques have been proposed based on Retinex theory, a lightness and color perception model of human vision [1]. C.-Y. Tsai (&) C.-H. Huang Department of Electrical Engineering, Tamkang University, 151 Ying-zhuan Road, Tamsui District, New Taipei City 25137, Taiwan R.O.C e-mail: chiyi_tsai@mail.tku.edu.tw; 600460140@s00.tku.edu.tw\nRetinex-based techniques, such as multi-scale Retinex [2], perceptual color enhancement [3–5], and automatic natural enhancement [6, 7], are general-purpose methods simultaneously achieving dynamic range compression, local contrast enhancement, and color consistency; however, these algorithms are usually computationally expensive, requiring algorithmic simplification and hardware acceleration to achieve real-time performance [8–10]. On the other hand, tone-mapping techniques are widely used to reproduce an undistorted high dynamic range (HDR) still image on a low dynamic range (LDR) displays device [11–15]. For this purpose, Reinhard et al. [11] proposed a local tone-mapping operator based on an automatic dodging-and-burning technique to select the best local illumination value for each pixel from a Gaussian pyramid of the image, accomplishing dynamic range compression with finedetails preservation. The authors in Ref. [12] further investigated the Reinhard’s operator for real-time embedded implementation. Fattal et al. [13] proposed a gradient domain dynamic range compression algorithm that manipulates the HDR image in an attenuated gradient domain to produce a new LDR image via an inverse gradient transform, which is equivalent to solving the Poisson equation and is the most computationally intensive step of the Fattal’s operator. To reduce the computational complexity of this step, the authors in Ref. [14] developed a local Fattal’s operator to solve the Poisson equation locally and repeatedly. By doing so, the local Fattal’s operator becomes highly parallelizable and is able to achieve realtime performance through hardware acceleration [15]. The tone-mapping techniques usually produce satisfactory results for rendering HDR images encoded in radianceRGBE format [16], but these methods may not process conventional color images stored in RGB format.\nTo improve visual quality of the conventional color images, some dynamic range compression methods are combined with a local contrast enhancement algorithm. For instance, Tao et al. [17] proposed an Adaptive and Integrated Neighborhood-Dependent Approach for Nonlinear Enhancement (AINDANE) algorithm which involves two separate processes: adaptive luminance enhancement and adaptive contrast enhancement. The former process compresses dynamic range of the input image, and the latter process restores local contrast after range compression. The authors also extended their work to color image enhancement using an illuminance-perception-based adaptive dynamic range compression process [18]. Monobe et al. [19] proposed a spatially variant dynamic range compression algorithm with local contrast preservation based on the concept of local contrast range transform. Although these methods perform well in color image enhancement, the image enhancement procedure usually requires high computational costs with a large memory, leading to an\ninefficient algorithm. To improve computational efficiency, Unaldi et al. [20] proposed a fast and robust Wavelet-based Dynamic Range Compression (WDRC) algorithm with local contrast enhancement. The processing time of WDRC algorithm is notably reduced since it fully operates in wavelet domain. Recently, the authors in Ref. [21] proposed a Simultaneous Dynamic Range Compression and Local Contrast Enhancement (SDRCLCE) algorithm, which improves computational efficiency via parallel processing. However, this method requires computing the derivative function of a given intensity-transfer function and thus may lead to an inefficient algorithm when employing a complicated intensity-transfer function.\nThis paper presents an adaptive dynamic range compression format with a local contrast enhancement algorithm to efficiently resolve color image enhancement problem. The proposed algorithm is derived from the existing AINDANE and SDRCLCE algorithms, but producing results with less color artifacts. Moreover, an algorithmic acceleration method is presented to improve the computational efficiency of the proposed algorithm in order to meet the requirement of real-time applications without hardware acceleration. This helps leading to an efficient and low-cost algorithm achieving real-time performance in practical applications such as real-time video enhancement processing, which will be validated in the experiments by testing with high-definition (HD) video signals.\nThe rest of this paper is organized as follows. Section 2 introduces two existing methods related to the development of the proposed algorithm. Section 3 presents a new adaptive dynamic range compression algorithm with the property of enhancing local image contrast. Section 4 presents our algorithmic acceleration method for the proposed algorithm to achieve real-time performance without hardware acceleration. Experimental results are reported in Sect. 5 to evaluate the effectiveness and efficiency of the developed real-time color image enhancement method. Section 6 concludes the contributions of this paper."
  }, {
    "heading": "2 The existing methods",
    "text": "This section briefly describes two existing methods that efficiently achieve dynamic range compression while enhancing local contrast of color images.\n2.1 The AINDANE algorithm\nThe AINDANE algorithm [17] is a well-known method in color image enhancement. This algorithm consists of two processes: adaptive luminance enhancement and adaptive contrast enhancement. Let Lin2 ½0; 1 be the normalized luminance component of an input color image. The\nadaptive luminance enhancement process first compresses the dynamic range of an input luminance image using the following nonlinear transfer function:\nT1½Linðx; yÞ ¼ 1\n2\nn L ð0:75zþ0:25Þ in ðx; yÞ þ L ð2 zÞ in ðx; yÞ\nþ0:4ð1 zÞ½1 Linðx; yÞ o ; ð1Þ\nwhere the parameter z is determined by an intensity level L related to the darkness of the input luminance image such that\nz ¼ 0; for L 50 L 50 100\n; for 50\\L 150 1; for L[ 150 :\n8< :\nThe adaptive contrast enhancement process next enhances the contrast of the range-compressed luminance image using a center-surround contrast enhancement technique as follows:\nLAINDANEout ðx; yÞ ¼ T1½Linðx; yÞ Linðx;yÞ Linðx;yÞ P ð2Þ\nwhere Linðx; yÞ is the value of local average luminance of the pixels in a neighborhood of specified size, and the parameter P is related to the global standard deviation rg of the input luminance image such that\nP ¼ 3; for rg 3 27 2rg\n7 ; for 3\\rg\\10\n1; for rg 10\n8< : :\nBecause the AINDANE algorithm only processes the luminance component of the input image, it requires combining with a linear color restoration process to deal with color image enhancement. The existing linear color restoration process usually works in RGB color space. Let PRGBin ¼ Rin Gin Bin½ T\nand PRGBout ¼ Rout Gout Bout½ T ; respectively, denote the input and output color value of each pixel in RGB color space. Then, the linear color restoration process for each input RGB color pixel can be expressed as\nPRGBout ðx; yÞ ¼ qðx; yÞPRGBin ðx; yÞ; ð3Þ\nwhere q(x,y) is a nonnegative color-mapping ratio given by\nqðx; yÞ ¼ L AINDANE out ðx; yÞ þ e Linðx; yÞ þ e ; ð4Þ\nwhere e is a small positive value to avoid dividing by zero. Expression (3) is able to preserve color information of the original image for minimal color shifts appeared in the enhanced result.\nRemark 1 To compute the input luminance image, several existing methods can be employed for extracting the luminance value of a RGB color pixel based on NTSC standard\n[17], sRGB standard [22], or the definition of HSV intensity value [23]. However, according to Ref. [18], adopting HSV intensity value is suggested as it achieves color consistency in the RGB color image enhancement without color space conversion. In this study,we therefore use theHSVintensity value as the input luminance Lin(x, y) for color image enhancement, but using NTSC intensity value for video enhancement due to the consideration of computational efficiency.\n2.2 The SDRCLCE algorithm\nThe SDRCLCE algorithm [21] provides an efficient way to simultaneously achieve dynamic range compression and local contrast enhancement for color images. Let T½ 2 C1 denotes an arbitrary monotonically increasing and continuously differentiable intensity-transfer function, and T 0½Linðx; yÞ ¼ dT ½X =dXjX¼Linðx;yÞ the corresponding derivative function of T. Then, the general form of SDRCLCE algorithm is given by LSDRCLCEout ðx; yÞ ¼ n f 1n ðx; yÞ cðx; yÞLTðx; yÞ\nþ½1 cðx; yÞ Llceðx; yÞ o1\n0 ;\nð5aÞ\nfnðx; yÞ ¼ cMaxðx; yÞTðLMaxin Þ þ ½1 cMaxðx; yÞ\n½aT 0ðLMaxin ÞLMaxin 1 e ; ð5bÞ\nLlceðx; yÞ ¼ aT 0½Linðx; yÞ Linðx; yÞ; ð5cÞ\nwhere a is a two-valued parameter (its value can be-1 or 1), and LTðx; yÞ ¼ T ½Linðx; yÞ is the luminance output obtained from the function T. In (5a), the operator xf gba means that the value of x is bounded to the range [a, b], and c(x, y) is a weighting coefficient defined as cðx; yÞ ¼ Linðx; yÞ þ e Linðx; yÞ þ e ; ð6Þ\nwhere, again, e is a small positive value to avoid dividing by zero, and Linðx; yÞ is the local average value previously defined in (2). In (5b), fn 2 ½e; 1 is a normalization factor depending on a weighting coefficient given by\ncMaxðx; yÞ ¼ LMaxin þ e\nLinðx; yÞ þ e ; ð7Þ\nwhere LMaxin is the maximum input luminance value. We take the nonlinear transfer function T1, previously defined in (1), as an example to explain how the SDRCLCE algorithm works. As the function T1 satisfies monotonically increasing and continuously differentiable conditions, the derivative function of T1 can be found such that\nT 01 ½Linðx; yÞ ¼ 1\n2\nn 0:25ð3zþ 1Þ½Linðx; yÞ þ e 0:75ðz 1Þ\nþ ð2 zÞLð1 zÞin ðx; yÞ 0:4ð1 zÞ o ; ð8Þ\nwhere the small nonzero parameter e is employed to avoid dividing by zero. Substituting (1) and (8) into (5a–5c) yields the SDRCLCE output with respect to T1 such that LSDRCLCEout T1 ðx; yÞ ¼ n ½f T1n ðx; yÞ 1 cðx; yÞLT1ðx; yÞf\nþ ½1 cðx; yÞ LT1lceðx; yÞ o1 0 ; ð9Þ\nwhere f T1n ðx; yÞ ¼ cMaxðx; yÞT1ðLMaxin Þ þ ½1 cMaxðx; yÞ ½aT 01ðLMaxin ÞLMaxin g 1 e ; LT1ðx; yÞ ¼ T1½Linðx; yÞ ; and L T1 lceðx; yÞ ¼ aT 01 ½Linðx; yÞ Linðx; yÞ: The contrast enhancement property of the SDRCLCE algorithm can be determined by the two-valued parameter a. That is, setting a = 1 in (9) leads to preserve local contrast of output luminance during range compression (Fig. 1c), and a = -1 leading to enhance local contrast (Fig. 1d). From Fig. 1, visually comparing the SDRCLCE output (9) with the AINDANE output (2) observes that the SDRCLCE algorithm is able to enhance local contrast of the image without employing the adaptive contrast enhancement process. This advantage makes the SDRCLCE algorithm more suitable to meet the requirements of real-time applications, which will be highlighted in Sect. 4."
  }, {
    "heading": "3 The proposed algorithm",
    "text": "Recalling the SDRCLCE formula (5a–5c), the enhanced output is characterized by a specific intensity-transfer function. Hence, selecting a suitable intensity-transfer function is an important task when employing the SDRCLCE algorithm. This section first presents a new intensity-transfer function that achieves adaptive range compression with satisfactory enhancement on visual quality. The proposed algorithm is then derived by applying the SDRCLCE formula on the new intensity-transfer function.\n3.1 A new intensity-transfer function\nThe AINDANE method usually performs well in color image enhancement; however, it may over-enhance dark regions of the image. Figure 2a shows the intensity mapping curve processed by the nonlinear transfer function (1) and explains how this problem occurred by the AINDANE method. From Fig. 2a, one can see that when z\\ 1, the nonlinear transfer function (1) remaps a zero-value input to a nonzero-value output. According to (4), this feature leads to a large color-mapping ratio for a dark pixel and thus usually produces color artifacts in the dark region of the image. This problem highlights the importance to design a new intensity-transfer function that achieves satisfactory dynamic range compression while preventing over enhancement in the dark region of the image.\nObserving the nonlinear intensity-transfer function (1) finds that the over enhancement problem mentioned above is caused by the third term in the braces. Based on this observation, a modification on this term to guarantee that the output equals to zero when Lin = 0 is proposed as follows:\nT2½Linðx; yÞ ¼ 1\n2\nn L ½ð1 uÞzþu in ðx; yÞ þ L ð2 zÞ in ðx; yÞ\nþSð1 zÞLðuþ1Þin ðx; yÞ½1 Linðx; yÞ o ; ð10Þ\nwhere S 2 ð0; 2 is a nonzero positive constant related to the variability range of parameter u (see Appendix), and u 2 ½0;Minð1; SÞ controls the capability of dynamic range compression. That is, a smaller (larger) value of u provides more (less) dynamic range compression for dark pixels. It is clear from expressions (1) and (10) that when u = 0.25, the first and second terms of (1) and (10) are the same. Moreover, for S = 0.4, the scale factor used in the third terms of (1) and (10) are also the same. Thus, we choose u = 0.25 and S = 0.4 as the default settings for the new intensitytransfer function (10) in order to provide a fair comparison with the AINDANE method. Note that expression (10) cannot be seen as a generalization of expression (1) as (1) cannot be derived from (10). Figure 2b illustrates the intensity mapping curve processed by the modified nonlinear transfer function (10) with S = 0.4 and u = 0.25. From Fig. 2b, it is clear that the proposed intensity-transfer function (10) satisfies a zero-input, zero-output condition for all z 2 ½0; 1 . This property helps achieving an acceptable dynamic range compression result with less color artifacts and will be validated in the experiment section. Another observation is that expression (10) equals expression (1) when u = 0.25 and z = 1, i.e., for intensity level L greater than 150, as can be seen in Fig. 2.\n3.2 Application of SDRCLCE formula into the new\nintensity-transfer function\nAs the modified nonlinear transfer function (10) also satisfies the monotonically increasing and continuously differentiable conditions, the proposed algorithm is derived by applying the SDRCLCE expressions (5a–5c) to this function such that LSDRCLCEout T2 ðx; yÞ ¼ n ½f T2n ðx; yÞ 1 cðx; yÞLT2ðx; yÞf\nþ½1 cðx; yÞ LT2lceðx; yÞ o1\n0 ;\nð11Þ\nwhere f T2n ðx; yÞ ¼ cMaxf ðx; yÞT2ðLMaxin Þ þ½1 cMaxðx; yÞ ½aT 02ðLMaxin ÞLMaxin g 1 e ;LT2ðx; yÞ ¼ T2½Linðx; yÞ and L T2 lceðx; yÞ ¼ aT 02 ½Linðx; yÞ Linðx; yÞ with T 02 ½Linðx; yÞ ¼ 12 ½ð1 uÞz þu ½Linðx; yÞ þ e ½ð1 uÞzþu 1 þð2 zÞLð1 zÞin ðx; yÞþSð1 zÞ\nL u inðx; yÞfðuþ 1Þ ½1 Linðx; yÞ Linðx; yÞgg: For the enhancement of color images, the linear color restoration process (3) is employed, but using LSDRCLCEout T2 instead of LAINDANEout in (4). According to [17], the value of z depends on an intensity level L related to the cumulative distribution function of the input intensity image. This implies that the range compression property of the expression (11) used in the proposed algorithm is adaptively changed according to the intensity histogram of the input image. This feature improves the range compression property of the proposed method in dealing with a variety of low dynamic range images."
  }, {
    "heading": "4 Algorithmic acceleration of the proposed algorithm",
    "text": "This section presents an algorithmic acceleration method for the proposed algorithm to achieve real-time performance without any hardware acceleration. Recalling expression (11), one can observe that the output of the\nproposed algorithm depends on four terms: the luminance remapping output LT2 , the local contrast enhancement component LT2lce, the weighting coefficient c, and the normalization factor f T2n . Suppose that the range compression parameter u is determined a priori and is constant during the process. Then, according to (10), the luminance remapping output LT2 can be simply represented by LT2 ¼ T2½Lin ¼ g1ðLin; zÞ; ð12Þ\nwhere g1ðLin; zÞ is a two-variable function of the input luminance value Lin and image-dependent parameter z. Similarly, the other three terms in (11) can also be represented by\nLT2lce ¼ aT 02 ½Lin Lin ¼ g2ðLin; zÞ; c ¼ Lin þ e Lin þ e\n¼ g3ðLin; LinÞ; and f T2n ðx; yÞ ¼ g4ð Lin; zÞ; ð13Þ\nwhere g2, g3, and g4 are three two-variable functions. In particular, g2 depends on the input luminance value Lin and on the image-dependent parameter z, g3 depends on Lin and\non the local average value Lin, while g4 depends on Lin and on z. Substituting (12) and (13) into (11), expression (11) can then be rewritten as LSDRCLCEout T2 ¼ n ½g4ð Lin; zÞ 1 g3ðLin; LinÞg1ðLin; zÞ\nþ½1 g3ðLin; LinÞ g2ðLin; zÞ o1\n0\ngðLin; Lin; zÞ; ð14Þ\nwhere gðLin; Lin; zÞ is a three-variable function of Lin, Lin, and z. Expression (14) provides an important clue for speeding up the proposed algorithm significantly. For instance, the luminance value in digital video standards\ngenerally is an eight-bit digital signal, and the values of Lin, Lin and the intensity level L in (1) thus range from 0 to 255. Based on this observation, the output luminance LSDRCLCEout T2 can be pre-computed for each value of Lin, Lin and z using (14) when the parameter u is decided a priori. More specifically, the expression (14) can be used to pre-construct a 256-by-256-by-256 three-dimensional luminance look-uptable (3D LLUT) that simplifies the process of the proposed algorithm to a local average computation, a parameter z computation, and a 3D LLUT-indexing operation, as shown in Fig. 3. This design can drastically speed up the entire process of the proposed method; however, it requires\na 3D LUT with a large memory size (16 M bytes). This requirement greatly restricts the applicability of the proposed method. To reduce the memory usage of the implementation, Fig. 4 shows another possible way to realize the proposed algorithm with real-time performance. This implementation uses a 256-by-256 2D LLUT efficiently reducing the memory usage from 16 M bytes to 65 K bytes, but it needs to update the LUT when the value of z is changed. As the parameter z is image dependent, the implementation shown in Fig. 4 may not be suitable for real-time video signal processing. These problems, therefore, highlight the importance to develop an efficient acceleration method for real-time video color enhancement with less memory usage. In the following, a new acceleration method will be proposed to achieve this purpose.\n4.1 Acceleration by 2D LUT indexing and linear\ninterpolation\nSince the value of z is image dependent and ranges from 0 to 1, we first rewrite the function gðLin; Lin; zÞ in (14) as a\ntwo-variable function with respect to two positive-integer parameters, denoted by i and N, such that\ngiðLin; LinÞ g Lin; Lin; i=N 1 ; ð15Þ\nwhere N 2 and i ¼ 0 N 1. Expression (15) means that if N ! 1, then the function giðLin; LinÞ is equivalent to gðLin; Lin; zÞ z2½0;1\n. By contrast, if N is a finite positive integer, then (15) is a discrete version of (14) with N samples. This observation is useful to develop an efficient approximation method to speed up the proposed algorithm with less memory usage. Suppose that i ¼ zðN 1Þb c, where Xb c means the largest integer less than or equal to X. Then the output formula (14) can be approximated by linear interpolation of the discrete function (15) such that\nL̂SDRCLCEout T2\n¼ giðLin; LinÞ; if w ¼ 0 ð1 wÞ giðLin; LinÞ þ w giþ1ðLin; LinÞ; otherwise\nð16Þ\nwhere w ¼ zðN 1Þ i. Figure 5 shows the concept of linear approximation via expression (16). In Fig. 5, the value of i is supposed to be 0, and the output (14) is thus approximated by a linear interpolation operation between the outputs of g0ðLin; LinÞ and g1ðLin; LinÞ. As each output of the functions giðLin; LinÞ, for i ¼ 0 N 1, can be precomputed in a N-by-256-by-256 3D LUT, the computation of (16) is simplified to a local average computation, a parameter z computation, two 2D LLUT-indexing operations, and a linear interpolation operation (Fig. 6a). By doing so, the memory usage of the proposed linear approximation method is dependent on the layer-number N. To find the minimum layer-number N with an acceptable approximation, we define an approximation error metric between LSDRCLCEout T2 and L̂ SDRCLCE out T2 such that"
  }, {
    "heading": "MSE ¼ 1",
    "text": "UV XU x¼1 XV y¼1 LSDRCLCEout T2 ðx; yÞ L̂ SDRCLCE out T2 ðx; yÞ h i2 ;\nð17Þ\nwhere U and V are, respectively, the total column and row number of the image. Twelve nature color images selected from Kodak PhotoCD, which are widely used in the literature (such as color interpolation [24], color conversion [25], and color image enhancement [26], etc.), are then employed to compute the MSE measures of the proposed linear approximation method (16) with different layernumber settings. Figure 6b shows the evolution of the approximation error results. In Fig. 6b, one can see that when N 5, the approximation error converges to a small MSE measure. Therefore, the minimum layer-number N for the proposed linear approximation method can be set as five layers that greatly reduces the memory usage from 16 M to 327 K bytes when compared to the 3D-LUT acceleration method. Hence, N ¼ 5 is used as the default setting for the proposed linear approximation method.\nRemark 2 The proposed linear approximation method also can be applied on the AINDANE algorithm. However, recalling the AINDANE formula (2), the AINDANE output can be rewritten as LAINDANEout ¼ hðLin; Lin; z;PÞ, where hðLin; Lin; z;PÞ is a four-variable function of Lin, Lin, z, and P. This means that the AINDANE method requires preconstructing a 4D LLUT with a very large memory size (about 4G bytes) to improve the processing speed. When applying the linear approximation method (16) on the function hðLin; Lin; z;PÞ, it still requires multiple 3D LLUTs with large memory usage. This is therefore the main advantage of the proposed formula (11) over the existent AINDANE formula (2).\n4.2 Local average luminance computation\nAs mentioned in the previous subsection, the proposed acceleration method requires calculating the local average luminance of the image to perform the LUT-indexing operation. A conventional method to achieve this requirement is to convolute the luminance image with a spatial low-pass\nfilter such that Lin ¼ Lin FL, where the operator denotes the 2D convolution operation, and FL denotes a spatial lowpass filter kernel function satisfying the conditionP x P y FLðx; yÞ ¼ 1. The kernel function FL can be considered as a blurring filter (i.e., Gaussian filter or combinedscale Gaussian filter [20]) or an edge-preserving filter (i.e., bilateral filter [27], trilateral filter [28], or nonlocal mean\nLayer 0\nLayer 1\nLayer N-1\nLin\ninL\n256-by-256 2D LLUT\n⎣ ⎦)1( −= Nzi i+1\nSDRCLCE ToutL 2_ ˆ\n),( inini LLg\n),(1 inini LLg +\n1-w\niNzw −−= )1(x(1-w)\nx w\nFig. 5 Concept of the proposed approximation method based on linear interpolation of the discrete function (15)\nfilter [29]); however, selectingFL as a simple blurring filter is better to meet the requirements of real-time applications. This study hence employs a Gaussian blur filter as the kernel function given by FLðx; yÞ ¼ Ke ðx 2þy2Þ=r2 ; where K is the scalar of the filter to normalize the sumof filter coefficients to 1, and r denotes the standard deviation of the Gaussian kernel. The size of the filter kernel is determined by ð2rþ 3Þ ð2rþ 3Þb c: That is, according to Ref. [21], increasing the value of r will increment not only the level of local contrast enhancement but also the processing time of the proposed method. To obtain better computing performance when using a larger value of r, an efficient method is first down-sampling the input luminance image such that\nL # d ¼ downsampleðLin; 2dÞ; ð18Þ\nwhere d 1 is a positive integer, and downsampleðI;DÞ denotes a 2D down-sampling operation on an image I with a desired down-scaling ratio D. The local average luminance image is then obtained by resizing the convolution result between L # d and FL so that Lin ¼ resizeðL#d FL;W ;HÞ; ð19Þ\nwhere W and H denote, respectively, the input image width and height, and resizeðI;Wd;HdÞ denotes a 2D resizing operation on a single-channel image I with a desired width Wd and a desired height Hd. Here, the image resizing algorithm can be simply realized by a real-time bilinear interpolation method [30].\n4.3 Extension to video signal processing\nWe now extend the proposed method to video signals. Many video enhancement methods process in YCbCr color space as YCbCr is the most commonly used color space in video rendering based on digital video standard. However, these methods usually result in less saturated colors, as they only enhancing the Y component while leaving Cb, Cr components unchanged. To overcome this problem, an YCbCr linear color remapping was proposed in Ref. [21] to preserve the color information of the input image during the enhancement process in YCbCr color space. Let\nYin C b in C r in and Yout C b out C r out denote the input and output color pixel in YCbCr color space, respectively. According to Ref. [21], the remapping of luminance and chrominance components of each YCbCr color pixel are, respectively, given by Youtðx; yÞ ¼ qðx; yÞ Yinðx; yÞ þ 16½1 qðx; yÞ ; and ð20Þ\nCioutðx; yÞ ¼ qðx; yÞCiinðx; yÞ þ 128½1 qðx; yÞ ; ð21Þ\nwhere qðx; yÞ is the color-mapping ratio defined in (4), and Cij (i = b, r, and j = in, out) denotes one of the chrominance components. Combining the proposed algorithm\nwith the YCbCr linear color remapping formulas (20) and (21) allows directly enhancing video signals without color space conversion, greatly reducing the processing time of video enhancement process. The interested reader is referred to Ref. [21] for more technical details."
  }, {
    "heading": "5 Experimental results",
    "text": "The following experiments focus on four issues, including an examination of the properties of the proposed linear approximation method, the quantitative and visual comparisons with AINDANE approach, computational speed evaluation, and power consumption comparison. Note that in order to quantitatively evaluate the performance of the proposed and compared methods, the quantitative method proposed in Ref. [31] is employed in the experiments. This quantitative method evaluates image quality by two criteria, called detail variance (DV) and background variance (BV). The DV and BV measures, respectively, indicate the average variance of all the pixels located in the detail and background regions, which are classified by thresholding the image according to the variance value of each pixel in a neighborhood of specified size. Here, the threshold value was set as 5 and the window size of neighborhood was 7-by-7. Note that the desired result after applying image enhancement is increase in DV but no change in BV. Please refer to Ref. [31] for more technical details.\n5.1 Properties of the proposed linear approximation\nmethod\nTo evaluate the properties of the proposed linear-approximated SDRCLCE method (16), the parameters a, d, and e are set to -1 (for local contrast enhancement), 1 (for 2:1 down-sampling ratio), and 1/255, respectively. The level of image enhancement of the proposed linear approximation method then depends on four parameters (r, u, S, N). To understand about the dependency of the image enhancement performance on the value of each parameter, the following experiments consist of four parameter-tweaking tests listed below:\n1. tweaking r with fixed u, S, and N; 2. tweaking u with fixed r, S, and N; 3. tweaking S with fixed r, u, and N; and 4. tweaking N with fixed r, u, and S.\nFigures 7, 8, 9, and 10 present the results of the experiments (1), (2), (3), and (4), respectively. In these figures, the lightness and contrast of the image are, respectively, measured by the global mean (GM) and DV, BV measures, which are listed above each image. In Fig. 7, it is clear that the parameter r has significant influence on\nthe image contrast after enhancement processing. Tuning parameter r to a large value will increase overall contrast and lightness, but may loss fine details as the value of r greater than 4. Thus, the parameter r should range between 2 and 4 to provide better image enhancement performance with fine-details preservation. Next, Fig. 8 illustrates the influence of parameter u on the enhanced result, showing that the parameter u has great influence on the image lightness after enhancement processing. A smaller (larger) value of u leads to a larger (smaller) enhancement on overall lightness. In contrast to the influence of u on image lightness, a smaller (larger) value of S leads to a smaller (larger) enhancement on overall lightness (Fig. 9).\nTherefore, the parameters r, u, and S are useful for the proposed method to control overall lightness and contrast of the enhanced result.\nFigure 10a–d represents the influence of parameter N on the enhanced result as its value increasing from 2 to 5 with fixed parameters r = 2, u = 0.25, and S = 0.4. Figure 10e shows the corresponding result obtained by the 2D LUT-accelerated SDRCLCE method (14). In Fig. 10, one can see that the parameter N influences the similarity between the SDRCLCE and linearapproximated results. That is, a larger value of N leads to a better similarity between them. Hence, the parameter N is useful to control the performance of the proposed\nlinear approximation method similar to the SDRCLCE output.\nSummarizing the parameter-tweaking experiment, we\nhave the following observations:\n1. In the proposed linear approximation method, the\nparameters u and S control overall lightness of the enhanced result. 2. The parameter r controls overall lightness and contrast of the enhanced result. 3. Setting r 2 ½2; 4 is able to provide contrast enhancement with fine-details preservation.\n4. The parameter N controls the performance of the\nproposed linear approximation method similar to the SDRCLCE output.\n5.2 Quantitative and visual comparisons\nTable 1 tabulates the parameter setting for the compared and proposed methods used in the experiments. To provide a fair comparison, all methods use the same local average computation defined in (19) with a fixed down-sampling ratio d = 1 and a single-scale Gaussian filter kernel r = 2.\nMoreover, the YCbCr color remapping method given by (20) and (21) is also used in the competing method for processing video signals. For both proposed methods, the values S = 0.4, u = 0.25, and N = 5 are used as the default setting. The small positive value e is set as 1/255 for all methods.\nTo evaluate the performance of the proposed methods on a large dataset, three image databases were used in the experiments. Each database was generated by randomly capturing 500 images (all stored in RGB full-color format) in a HD video stream with different image resolutions. The compared and proposed methods were then applied to these databases for performance evaluation. Table 2 records average quantitative measure of image quality before and after enhancement processing. It is clear from Table 2 that the AINDANE method produces better BV measures than the proposed methods; however, the proposed methods produce better DV measures. This implies that the AINDANE method preserves contrast of background region well, but it only produces weak contrast enhancement on detail region and could not efficiently enhance image details. By contrast, both proposed methods produce better contrast enhancement on detail region than the AINDANE method does. This advantage improves visual quality of the image as human vision is very sensitive to image details, which are measured by the DV criteria. Note that observing Table 1 finds that both proposed methods produce similar DV and BV measures for all image databases. This also validates the performance of the proposed linear approximation method.\nFigures 11, 12, and 13 present the enhanced results of three color images recorded in the database No. 1. A visual comparison shows that the AINDANE method produces\nhigh-range compression results, but with notable color artifacts in dark regions. Both proposed methods, however, produce satisfactory results in range compression and contrast enhancement with slight color artifacts. They also produce a significant improvement on the visual quality and detail enhancement of a typical color image captured from a video stream (see Fig. 11c, d). In Figs. 12 and 13, one can see that the AINDANE method produces an unnatural image with unwanted artifacts, caused by overenhancing the dark regions of the image (as mentioned in Sect. 3.1). By contrast, both proposed methods produce significant improvement in the resulting image by enhancing fine details in dark regions with fewer artifacts. Therefore, these experimental results validate the proposed methods in terms of dynamic range compression, local contrast enhancement, and color artifacts.\n5.3 Computational speed\nThe proposed color image enhancement approaches were implemented in C?? running on a Windows 7 machine with 2.5 GHz Intel Core 2 processor and 4 GB of memory. It used non-optimized parallel programming with OpenMP to improve the computational efficiency of the entire process. Table 3 records average processing time of each stage required for the competing and proposed methods to process two 4:2:0 YCbCr [32] HD video streams with different image resolutions (720 and 1080p). The total number of frames in 720 and 1080p video streams, respectively, contains 3482 and 2969 frames, which were entirely processed in the experiments. As can be seen in Table 3, the processing time of the proposed 2D LUT-accelerated SDRCLCE method (14) takes an average of 13.434 and\nDatabase no. Number of images Image resolution Measures Original image AINDANE (2) 2D LUT-accelerated SDRCLCE (14)\nLinear-approximated SDRCLCE (16)\n1 500 pictures 480p (848 9 448) DV 17.6045 17.9725 24.9992 24.9938\nBV 2.3037 2.6373 2.9509 2.9511\n2 500 pictures 720p (1280 9 608) DV 16.3281 18.4071 20.3208 20.3195\nBV 2.218 2.7771 3.0878 3.0879\n3 500 pictures 1080p (1920 9 1080) DV 19.4471 20.2437 22.3407 22.3379\nBV 1.5307 2.0016 2.2671 2.2632\nTable 1 Parameter setting for each compared method used in the experiments\n32.152 ms per frame for 720 and 1080p HD video streams, respectively. This achieves 30 frames per second, the target frame rate, in real-time HD video processing. On the other hand, the proposed linear-approximated SDRCLCE method (16) accelerates the enhancement process and reduces the processing time compared with the 2D LUT-accelerated SDRCLCE method noticeably due to skipping the 2D LUT updating operation. In previous subsection, we have\nobserved that the proposed linear approximation method is able to produce very similar results to the original method. Therefore, the proposed linear approximation method provides an efficient solution to enhance visual quality of color images with real-time performance. Note that one can see from Table 3 that the main processing time of AINDANE method is spent on the adaptive contrast enhancement process, which requires computing the P value defined in\n(2) and enhancing pixel contrast after range compression. In Remark 2, we have explained that this process is difficult to speed up due to the large memory requirement. By contrast, the proposed method simultaneously achieves range compression and contrast enhancement via a 2D LUT-indexing operation. This is one of the main advantages of the proposed method over the AINDANE method, from the implementation point of view.\nRemark 3 Observing Table 3 finds that the critical operations of both proposed algorithms are the local average computation and YCbCr color remapping. This implies that the computational efficiency of both proposed algorithms can be further improved by speeding up these two critical operations via hardware acceleration or GPU computing [33]. Taking the local average computation as an example, its operation is equivalent to a 2D convolution operation. According to a recently published report [34], the CPU implementation of 2D convolution operation was only able to provide real-time performance for a kernel size smaller than 10 10 (the kernel size used in the experiments is 7 7 by the default setting). By contrast, the FPGA implementation can maintain frame rates over 30 for 1080p images with a maximum kernel size of 25 25, depending on the hardware limitations. The GPU implementation usingNVIDIA’s CUFFT library [35] also achieves real-time performance for 1080p images, even operating with a kernel size greater than 25 25. Therefore, employing one of these acceleration techniques can allow both proposed algorithms to maintain real-time performance when operating with a large kernel size and without down-sampling process.\n5.4 Power consumption\nTo measure the power consumption of the platform (a laptop) used in the experiments, we use the DeviceIoControl function [36] to query the current status of the battery that records the current rate of battery discharge in milliwatts [37]. The platform was configured as follows: (1) All peripherals were turned-on. (2) Power supply was removed; only the battery was used during the testing. (3) The battery manager was set in normal mode without energy saving options.\nTable 4 lists the average power consumption of the competing and proposed methods measured during the video enhancement process. In Table 4, the pass-through method is a simple memory-to-memory copy operation without any enhancement process. This method indicates the basic power consumption of the testing platform to perform video decoding, data transmission, video rendering, and other background operations. The power consumption of each video enhancement method can then be coarsely estimated by the increment in the overall battery\ndischarge rate, as indicated in the last row ‘‘add-up in average’’ of Table 4 that shows the difference between the battery discharge rate value for each algorithm and the same value for the pass through. From Table 4, it is clear that the proposed 2D LUT-accelerated SDRCLCE method (14) increases average power consumption about 5.41 and 11.24 W for 720 and 1080p video enhancement, respectively. By contrast, the proposed linear-approximated\nSDRCLCE method (16) reduces the increment of average power consumption to about 4.74 and 10.17 W in the cases of processing 720p and 1080p videos, respectively. Therefore, the above experimental observations validate that the proposed linear approximation method is able to achieve real-time performance with higher computational\nand energy efficiency compared with the AINDANE and 2D LUT-accelerated SDRCLCE methods.\nRemark 4 According to Ref. [34], the FPGA was the most energy-efficient device, compared with CPU and GPU devices, for 2D convolution implementations with a kernel\nCompeting method AINDANE (2)\nVideo format 4:2:0 YCbCr Image resolution 720p (1280 9 608) 1080p (1920 9 1080)\nsize greater than 10 10. This observation inspires us to implement the proposed linear approximation method in a FPGA-based embedded system [38] in order to further reduce overall power consumption and maintain real-time performance. However, some operations of the proposed method, such as the z value computation and 2D LUT building, may not be suitable for hardware implementation. In other words, the FPGA implementation of the proposed method should be divided into hardware and software parts. The former handles the operations of intensity extraction, local average computation, 2D LUT indexing, linear interpolation, and YCbCr color remapping, and the latter addresses the tasks of z value computation and 2D LUT building. This implementation issue hence becomes a hardware/software co-design problem and will be left in our future work.\n5.5 Conclusions and future work\nThis paper proposes an adaptive dynamic range compression with local contrast enhancement algorithm for real-time color image enhancement. The proposed algorithm consists of a new image-dependent nonlinear intensity-transfer function, inspired by the AINDANE method, to produce a satisfactory dynamic range compression result with less color artifacts. By combining the existing SDRCLCE algorithmwith the proposed adaptive nonlinear intensity-transfer function, the proposed method is able to simultaneously enhance image lightness and local contrast with less color artifacts. To improve the computational efficiency, an algorithmic accelerationwith linear approximation approach is also proposed to accelerate the entire process of the proposed method in processing video signals. Experimental results validate that the proposed color image enhancement method not only produces satisfactory color enhancement results but also achieves real-time performance in processing 1080p HD video streams. This greatly increases the applicability of the proposed method in practical application. In the future, implementation with hardware/software codesign for the proposed method will be further investigated.\nAcknowledgments This study was supported by the National Science Council of Taiwan, ROC under Grant NSC 101-2221-E-032-022."
  }, {
    "heading": "Appendix",
    "text": "In this Appendix, we prove that the variability range of the parameter u is [0, U], where U is the solution of the equation uð1þ eÞðu 1Þ S ¼ 0 with S 2 ð0; 2 . Moreover, we justify the choice u 2 ½0;Minð1; SÞ ½0;U made in our algorithm. Let us compute the variability range of u.\nFirst of all, we note that the normalization factor fn(x,y) defined in (5b) must be a nonzero positive value for each pixel. Hence, when applying the SDRCLCE algorithm to the intensity-transfer function (10), it has to satisfy a necessary condition such that\ncMaxðx; yÞT2ðLMaxin Þ þ ½1 cMaxðx; yÞ ½aT 02ðLMaxin ÞLMaxin [ 0; ð22Þ\nwhich guarantees that the normalization factor f T2n ðx; yÞ defined in (11) is always nonzero positive. Suppose that LMaxin ¼ 1 (i.e., normalizing the input luminance value to range [0,1]), then we have T2ðLMaxin Þ ¼ 1;\ncMaxðx; yÞ ¼ LMaxin þ e Linðx; yÞ þ e ¼ 1þ e Linðx; yÞ þ e ; and ð23Þ\nT 02 ðLMaxin Þ ¼ 1\n2\nn ½ð1 uÞzþ u ð1þ eÞ½ð1 uÞzþu 1\nþð2 zÞ Sð1 zÞ o ;\nð24Þ\nwhere T 02 ðLMaxin Þ 0 for every u 0 under the conditions of z 2 ½0; 1 and S 2 ð0; 2 : Consequently, the necessary condition (22) becomes\n1þ e Linðx; yÞ þ e þ a 1 1þ e Linðx; yÞ þ e T 02 ðLMaxin Þ\n¼ 1þ e Linðx; yÞ þ e þ a½ Linðx; yÞ 1 T 02 ðLMaxin Þ Linðx; yÞ þ e\n[ 0: ð25Þ\nThe above expression can further be simplified as\n1þ eþ a½ Linðx; yÞ 1 T 02 ðLMaxin Þ[ 0; ð26Þ\nwhere the value of a can be -1 or 1. For the case of a = -1, the expression (26) becomes\n1þ e ½ Linðx; yÞ 1 T 02 ðLMaxin Þ ¼ 1þ eþ ½1 Linðx; yÞ T 02 ðLMaxin Þ: ð27Þ\nAs T 02 ðLMaxin Þ 0 and Linðx; yÞ 2 ½0; 1 due to the condition LMaxin ¼ 1, it is clear that the condition (26) is always satisfied for every u 0 when a = -1.\nOn the other hand, for the case of a = 1, the expression (26) becomes\n1þ eþ ½ Linðx; yÞ 1 T 02 ðLMaxin Þ 1þ e T 02 ðLMaxin Þ: ð28Þ\nThis implies that the condition (26) can be satisfied if we\nhave\n1þ e[ T 02 ðLMaxin Þ: ð29Þ\nSubstituting (24) into (29) yields\n2ð1þ eÞ[ ½ð1 uÞzþ u ð1þ eÞ½ð1 uÞzþu 1 þ ð2 zÞ Sð1 zÞ; or equivalently,\n2ð1þ eÞ ð2 zÞ þ Sð1 zÞ ¼ Sþ 2eþ zð1 SÞ[ ½ð1 uÞzþ u ð1\nþ eÞ½ð1 uÞzþu 1 : ð30Þ\nNow, we have to compute the upper bound of the parameter u. Let g ¼ 1þ e and x ¼ ð1 uÞzþ u ¼ zþ ð1 zÞu with z 2 ½0; 1 and u 0. We note that the function f ðxÞ :¼ xgðx 1Þ is strictly convex since its second derivative f 00ðxÞ ¼ gðx 1Þð2þ x ln gÞ ln g is positive for all x 0. Then, from the definition of strictly convex functions, the right-hand side of the inequality (30) also satisfies the following inequality\nf ðzþ ð1 zÞuÞjg¼1þe\\zf ð1Þjg¼1þeþð1 zÞf ðuÞjg¼1þe ¼ zþ ð1 zÞuð1þ eÞðu 1Þ:\nð31Þ\nNext, the left-hand side of (30) can be rewritten as\nSþ 2eþ zð1 SÞ ¼ zþ ð1 zÞSþ 2e: ð32Þ\nObserving (30), (31) and (32) finds that if the positive\nconstant S satisfies the condition\nS uð1þ eÞðu 1Þ; ð33Þ\nthen the following relationship is guaranteed\nzþ ð1 zÞSþ 2e[ zþ ð1 zÞuð1þ eÞðu 1Þ\n[ f ðzþ ð1 zÞuÞjg¼1þe:\nExpression (33) shows that the upper bound of u is the root of the equation\nuð1þ eÞðu 1Þ S ¼ 0: ð34Þ\nFor instance, if S ¼ 2 and e ¼ 1=255, then the root of (34) is 1.9922 (searched by using ‘‘fzero’’ command in Matlab), and the range of u can be determined as u 2 ½0; 1:9922 . However, this method is too complicated to use in practice as it requires employing a onedimensional minimization method [39] in the proposed algorithm, increasing the complexity of the implementation of the algorithm. Instead, a simpler way is that if we set u 1, then we have 1 u uð1þ eÞðu 1Þ. Let U denote the root of the Eq. (34). In fact, we have S U for all S 2 ð0; 1Þ, and U S for all S 2 ½1; 2 . Based on the above observations, the upper bound of u thus can be assigned as S for the case of S\\1 and assigned as 1 for the case of S 1. This means that the range ½0;Minð1; SÞ is guaranteed to be a subset of range ½0;U under the condition of u 1 and S 2 ð0; 2 . By doing so, the process of one-dimensional minimization can be omitted while the necessary condition (22) is always satisfied. This concludes the choice of variability range u 2 ½0;Minð1; SÞ ½0;U used in our method."
  }, {
    "heading": "Author Biographies",
    "text": "Chi-Yi Tsai was born in Kaohsiung, Taiwan, Republic of China in 1978. He received the B.S. and M.S. degree in electrical engineering from National Yunlin University of Science and Technology, Yunlin, Taiwan, in 2000 and 2002, respectively. He received the Ph.D. degree in electrical and control engineering, at the National Chiao Tung University, Taiwan, in 2008. From Sep 2007 to Aug 2009, he was a software engineer in software R&D depart-\nment of software R&D division, ASUSTek Computer Incorporation. From Sep 2009 to Jan 2010, he was an assistant researcher in ChungShan Institute of Science & Technology, Armaments Bureau, Ministry of National Defense, Taiwan. He is currently an assistant professor in department of electrical engineering, Tamkang University, Taiwan. His research interests include image processing, color image enhancement processing, visual tracking control for mobile robots, visual servoing, and computer vision.\nChih-Hung Huang was born in Taipei, Taiwan, Republic of China in 1987. He received the B.S. degree in electrical engineering from Tamkang University, Taiwan, in 2011. He is currently pursuing the M.S. degree in electrical engineering at the Tamkang University, Taiwan. His research interests include image processing and computer vision."
  }],
  "year": 2015,
  "references": [{
    "title": "Recent advances in Retinex theory",
    "authors": ["E. Land"],
    "venue": "Vis. Res. 26(1), 7–21",
    "year": 1986
  }, {
    "title": "A multiscale Retinex for bridging the gap between color images and human observation of scenes",
    "authors": ["D. Jobson", "Z. Rahman", "G. Woodell"],
    "venue": "IEEE Trans. Image Process. 6(7), 965–976",
    "year": 1997
  }, {
    "title": "Perceptual color correction through variational techniques",
    "authors": ["M. Bertalmı́o", "V. Caselles", "E. Provenzi", "A. Rizzi"],
    "venue": "IEEE Trans. Image Process. 16(4), 1058–1072",
    "year": 2007
  }, {
    "title": "Perceptually motivated automatic color contrast enhancement based on color constancy estimation",
    "authors": ["A. Choudhury", "G. Medioni"],
    "venue": "EURASIP J. Image Video Process. 2010(837237), 1–22",
    "year": 2010
  }, {
    "title": "An analysis of visual adaptation and contrast perception for tone mapping",
    "authors": ["S. Ferradans", "M. Bertalmı́o", "E. Provenzi", "V. Caselles"],
    "venue": "IEEE Trans. Pattern Anal. Mach. Intell. 33(10), 2002–2012",
    "year": 2011
  }, {
    "title": "Natural enhancement of color image",
    "authors": ["Chen", "S.-H.", "A. Beghdadi"],
    "venue": "EURASIP J. Image Video Process. 2010(175203), 1–19",
    "year": 2010
  }, {
    "title": "Natural HDR image tonemapping based on retinex",
    "authors": ["K. Kim", "J. Bae", "J. Kim"],
    "venue": "IEEE Trans. Consum. Electron. 57(4), 1807–1814",
    "year": 2011
  }, {
    "title": "Algorithmic and architectural design for real-time and power-efficient retinex image/video processing",
    "authors": ["S. Saponara", "L. Fanucci", "S. Marsi", "G. Ramponi"],
    "venue": "J. Real-Time Image Proc. 1(4), 267–283",
    "year": 2007
  }, {
    "title": "Application-specific instruction-set processor for retinex-like image and video processing",
    "authors": ["S. Saponara", "L. Fanucci", "S. Marsi", "G. Ramponi", "D. Kammler", "E.M. Witte"],
    "venue": "IEEE Transact. Circuits Syst.-II: Exp. Briefs 54(7), 596–600",
    "year": 2007
  }, {
    "title": "Integrated video motion estimator with Retinex-like pre-processing for robust motion analysis in automotive scenarios: algorithmic and real-time architecture design",
    "authors": ["S. Marsi", "S. Saponara"],
    "venue": "J. Real-Time Image Proc. 5(4), 275–289",
    "year": 2010
  }, {
    "title": "Photographic tone reproduction for digital images",
    "authors": ["E. Reinhard", "M. Stark", "P. Shirley", "J. Ferwerda"],
    "venue": "Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques, pp. 267–276",
    "year": 2002
  }, {
    "title": "An FPGA-based architecture for a local tone-mapping operator",
    "authors": ["F. Hassan", "J.E. Carletta"],
    "venue": "J. Real-Time Image Proc. 2(4), 293–308",
    "year": 2007
  }, {
    "title": "Gradient domain high dynamic range compression",
    "authors": ["R. Fattal", "D. Lischinski", "M. Werman"],
    "venue": "ACM Trans. Graph. 21(3), 249–256",
    "year": 2002
  }, {
    "title": "Exploiting redundancy to solve the Poisson equation using local information",
    "authors": ["F. Hassan", "L. Vytla", "J.E. Carletta"],
    "venue": "Proceedings of IEEE International Conference on Image Processing, pp. 2689–2692",
    "year": 2009
  }, {
    "title": "A real-time implementation of gradient domain high dynamic range compression using a local Poisson solver",
    "authors": ["L. Vytla", "F. Hassan", "J.E. Carletta"],
    "venue": "J. Real-Time Image Process, pp. 1–15",
    "year": 2011
  }, {
    "title": "Adaptive and integrated neighborhooddependent approach for nonlinear enhancement of color images",
    "authors": ["L. Tao", "V.K. Asari"],
    "venue": "J. Electron. Imaging. 14(4), 043006-1–043006-14",
    "year": 2005
  }, {
    "title": "An illuminance-reflectance model for nonlinear enhancement of color images",
    "authors": ["L. Tao", "R. Tompkins", "V.K. Asari"],
    "venue": "Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 159–166",
    "year": 2005
  }, {
    "title": "Dynamic range compression preserving local image contrast for digital video camera",
    "authors": ["Y. Monobe", "H. Yamashita", "T. Kurosawa", "H. Kotera"],
    "venue": "IEEE Trans. Consum. Electron. 51(1), 1–10",
    "year": 2005
  }, {
    "title": "Fast and robust wavelet-based dynamic range compression with local contrast enhancement",
    "authors": ["N. Unaldi", "V.K. Asari", "Z. Rahman"],
    "venue": "Proceedings of SPIE 6978, pp. 697805-1–697805-12 (2008)  J Real-Time Image Proc",
    "year": 2015
  }, {
    "title": "A novel simultaneous dynamic range compression and local contrast enhancement algorithm for digital video cameras",
    "authors": ["Tsai", "C.-Y.", "Chou", "C.-H."],
    "venue": "EURASIP J. Image Video Process. 2011(6), 1–19",
    "year": 2011
  }, {
    "title": "Image display algorithms for high and low dynamic range display devices",
    "authors": ["E. Reinhard", "T. Kunkel", "Y. Marion", "J. Brouillat", "R. Cozot", "K. Bouatouch"],
    "venue": "J. Soc. Inform. Disp. 15(12), 997–1014",
    "year": 2007
  }, {
    "title": "Video enhancement and dynamic range control of HDR sequences for automotive applications",
    "authors": ["S. Marsi", "G. Impoco", "A. Ukovich", "S. Carrato", "G. Ramponi"],
    "venue": "EURASIP J. Adv. Signal Process. 2007(080971), 1–9",
    "year": 2007
  }, {
    "title": "Heterogeneity-projection hard-decision color interpolation using spectral-spatial correlation",
    "authors": ["Tsai", "C.-Y.", "Song", "K.-T."],
    "venue": "IEEE Trans. Image Process. 16(1), 78–91",
    "year": 2007
  }, {
    "title": "Color conversion technology of fourprimary color images developed on wide color gamut red, green, blue monitor",
    "authors": ["Chen", "H.-S.", "Chang", "T.-T."],
    "venue": "J. Imaging Sci. Technol. 53(6), 1–10",
    "year": 2009
  }, {
    "title": "An approach to color image enhancement using minimum mean brightness error dynamic histogram equalization",
    "authors": ["M.F. Hossain", "M.R. Alsharif", "K. Yamashita"],
    "venue": "Int. J. Innov. Comput. Inf. Control. 7(2), 827–840",
    "year": 2011
  }, {
    "title": "Bilateral filtering for gray and color images",
    "authors": ["C. Tomasi", "R. Manduchi"],
    "venue": "Proceedings of the IEEE International Conference on Computer Vision, pp. 839–846",
    "year": 1998
  }, {
    "title": "A universal noise removal algorithm with an impulse detector",
    "authors": ["R. Garnett", "T. Huegerich", "C. Chui", "W. He"],
    "venue": "IEEE Trans. Image Process. 14(11), 1747–1754",
    "year": 2005
  }, {
    "title": "Nonlocal image and movie denoising",
    "authors": ["A. Buades", "B. Coll", "Morel", "J.-M."],
    "venue": "Int. J. Comput. Vis. 76(2), 123–139",
    "year": 2008
  }, {
    "title": "Adaptive interpolation algorithm for real-time image resizing",
    "authors": ["Xiao", "J.-P.", "Zou", "X.-C.", "Liu", "Z.-L.", "X. Guo"],
    "venue": "Proceedings of the First International Conference on Innovative Computing, Information and Control, pp. 221–224",
    "year": 2006
  }, {
    "title": "Nonlinear unsharp masking methods for image contrast enhancement",
    "authors": ["G. Ramponi", "N.K. Strobel", "S.K. Mitra", "Yu", "T.-H."],
    "venue": "J. Electron. Imaging 5(3), 353–366",
    "year": 1996
  }, {
    "title": "Chrominance subsampling in digital images",
    "authors": ["D.A. Kerr"],
    "venue": "The Pumpkin 2012(3), 1–15",
    "year": 2012
  }, {
    "title": "GPU computing",
    "authors": ["J.D. Owens", "M. Houston", "D. Luebke", "S. Green", "J.E. Stone", "J.C. Phillips"],
    "venue": "Proceedings of the IEEE 96(5), pp. 879–899",
    "year": 2008
  }, {
    "title": "A performance and energy comparison of FPGAs, GPUs, and multicores for slidingwindow applications",
    "authors": ["J. Fowers", "G. Brown", "P. Cooke", "G. Stitt"],
    "venue": "Proceedings of the ACM/SIGDA 20th International Symposium on Field Programmable Gate Arrays, pp. 47–56",
    "year": 2012
  }],
  "id": "SP:a7ce66909a970ea1ba1e26519dd5a2d95f9054bd",
  "authors": [{
    "name": "Chi-Yi Tsai",
    "affiliations": []
  }, {
    "name": "Chih-Hung Huang",
    "affiliations": []
  }],
  "abstractText": "Dynamic range compression has become an important function used in modern digital video cameras to improve visual quality of color images suffered from low dynamic range and poor contrast defects. This study addresses real-time implementation of an adaptive dynamic range compression algorithm for color image/video enhancement. To achieve this purpose, we first propose a new image-dependent nonlinear intensity-transfer function to produce a satisfactory dynamic range compression result with less color artifacts. The proposed algorithm is then derived by combining the new adaptive nonlinear intensitytransfer function with an efficient local contrast enhancement algorithm. Moreover, an algorithmic acceleration method is also presented to accelerate the processing speed of the proposed color image enhancementmethod, achieving real-time performance in processing high-definition video signals. Experimental results validate the performance of the developed method in terms of quantitative evaluation, visual quality, computational efficiency, and power consumption.",
  "title": "An adaptive dynamic range compression with local contrast enhancement algorithm for real-time color image enhancement"
}