{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1132‚Äì1142, Lisbon, Portugal, 17-21 September 2015. c¬©2015 Association for Computational Linguistics.\nand reasoning approach to automatically solving math word problems. A new meaning representation language is designed to bridge natural language text and math expressions. A CFG parser is implemented based on 9,600 semi-automatically created grammar rules. We conduct experiments on a test set of over 1,500 number word problems (i.e., verbally expressed number problems) and yield 95.4% precision and 60.2% recall."
  }, {
    "heading": "1 Introduction",
    "text": "Computers, since their creation, have exceeded human beings in (speed and accuracy of) mathematical calculation. However, it is still a big challenge nowadays to design algorithms to automatically solve even primary-school-level math word problems (i.e., math problems described in natural language).\nEfforts to automatically solve math word problems date back to the 1960s (Bobrow, 1964a, b). Previous work on this topic falls into two categories: symbolic approaches and statistical learning methods. In symbolic approaches (Bobrow, 1964a, b; Charniak, 1968; Bakman, 2007; Liguda & Pfeiffer, 2012), math problem sentences are transformed to certain structures by pattern matching or verb categorization. Equations are then derived from the structures. Statistical learning methods are employed in two recent papers (Kushman et al., 2014; Hosseini et al., 2014).\nsuffer from two major shortcomings. First, natural language (NL) sentences are processed by simply applying pattern matching and/or transformation rules in an ad-hoc manner (refer to the related work section for more details). Second, surprisingly, they seldom report evaluation results about the effectiveness of the methods (except for some examples for demonstration purposes). For the small percentage of work with evaluation results available, it is unclear whether the patterns and rules are specially designed for specific sentences in a test set.\nIn this paper, we present a computer system called SigmaDolphin which automatically solves math word problems by semantic parsing and reasoning. We design a meaning representation language called DOL (abbreviation of dolphin language) as the structured semantic representation of NL text. A semantic parser is implemented to transform math problem text into DOL trees. A reasoning module is included to derive math expressions from DOL trees and to calculate final answers. Our approach falls into the symbolic category, but makes improvements over previous symbolic methods in the following ways, ______________________________________ * Work done while this author was an intern at Microsoft Research\n1132\n1) We introduce a systematic way of parsing\nNL text, based on context-free grammar (CFG).\n2) Evaluation is enhanced in terms of both data set construction and evaluation mechanisms. We split the problem set into a development set (called dev set) and a test set. Only the dev set is accessible during our algorithm design (especially in designing CFG rules and in implementing the parsing algorithm), which avoids over-tuning towards the test set. Three metrics (precision, recall, and F1) are employed to measure system performance from multiple perspectives, in contrast to all previous work (including the statistical ones) which only measures accuracy.\nWe target, in experiments, a subtype of word problems: number word problems (i.e., verbally expressed number problems, as shown in Figure 1). We hope to extend our techniques to handle general math word problems in the future.\nWe build a test set of over 1,500 problems and make a quantitative comparison with state-of-theart statistical methods. Evaluation results show that our approach significantly outperforms baseline methods on our test set. Our system yields an extremely high precision of 95.4% and a reasonable recall of 60.2%, which shows promising application of our system in precision-critical situations."
  }, {
    "heading": "2 Related Work",
    "text": ""
  }, {
    "heading": "2.1 Math word problem solving",
    "text": "Most previous work on automatic word problem solving is symbolic. STUDENT (Bobrow, 1964a, b) handles algebraic problems by first transforming NL sentences into kernel sentences using a small set of transformation patterns. The kernel sentences are then transformed to math expressions by recursive use of pattern matching. CARPS (Charniak, 1968, 1969) uses a similar approach to solve English rate problems. The major difference is the introduction of a tree structure as the internal representation of the information gathered for one object. Liguda & Pfeiffer (2012) propose modeling math word problems with augmented semantic networks. Addition/subtraction problems are studied most in early research (Briars & Larkin, 1984; Fletcher, 1985; Dellarosa, 1986; Bakman, 2007; Ma et al., 2010). Please refer to Mukherjee & Garain (2008) for a review of symbolic approaches before 2008.\n1 http://www.wolframalpha.com\nNo empirical evaluation results are reported in most of the above work. Almost all of these approaches parse NL text by simply applying pattern matching rules in an ad-hoc manner. For example, as mentioned in Bobrow (1964b), due to the pattern ‚Äú($, AND $)‚Äù, the system would incorrectly divide ‚ÄúTom has 2 apples, 3 bananas, and 4 pears.‚Äù into two ‚Äúsentences‚Äù: ‚ÄúTom has 2 apples, 3 bananas.‚Äù and ‚Äú4 pears.‚Äù\nWolframAlpha1 shows some examples2 of automatically solving elementary math word problems, with technique details unknown to the general public. Other examples on the web site demonstrate a large coverage of short phrase queries on math and other domains. By randomly selecting problems from our dataset and manually testing on their web site, we find that it fails to handle most problems in our problem collection.\nStatistical learning methods have been proposed recently in two papers: Hosseini et al. (2014) solve single step or multi-step homogenous addition and subtraction problems by learning verb categories from the training data. Kushman et al. (2014) can solve a wide range of word problems, given that the equation systems and solutions are attached to problems in the training set. The method of the latter paper (referred to as KAZB henceforth) is used as one of our baselines."
  }, {
    "heading": "2.2 Semantic parsing",
    "text": "There has been much work on analyzing the semantic structure of NL strings. In semantic role labeling and frame-semantic parsing (Gildea & Jurafsky, 2002; Carreras & Marquez, 2004; Marquez et al., 2008; Baker et al., 2007; Das et al., 2014), predicate-argument structures are discovered from text as their shallow semantic representation. In math problem solving, we need a deeper and richer semantic representation from which to facilitate the deriving of math expressions.\nAnother type of semantic parsing work (Zelle & Mooney, 1996; Zettlemoyer & Collins, 2005; Zettlemoyer & Collins, 2007; Wong & Mooney, 2007; Cai & Yates, 2013; Berant et al., 2013; Kwiatkowski et al., 2013; Berant & Liang, 2014) maps NL text into logical forms by supervised or semi-supervised learning. Some of them are based on or related to combinatory categorial grammar (CCG) (Steedman, 2000). Abstract Meaning Representation (AMR) (Banarescu et al., 2013) keeps richer semantic information than CCG and logical\n2 https://www.wolframalpha.com/examples/ElementaryMath.html (bottom-right part)\nforms. In Section 3.1.4, we discuss the differences between DOL, AMR, and CCG, and explain why we choose DOL as the meaning representation language for math problem solving."
  }, {
    "heading": "3 Approach",
    "text": "Consider the first problem in Figure 1 (written below for convenience), One number is 16 more than another. If the smaller number is subtracted from 2/3 of the larger, the result is 1/4 of the sum of the two numbers. Find the numbers.\nTo automatically solve this problem, the computer system needs to figure out, somehow, that 1) two numbers x, y are demanded, and 2) they satisfy the equations below,\nx = 16 + y\n(2/3)x ‚Äì y = (x + y) / 4\n(1)\n(2)\nTo achieve this, reasoning must be performed based on common sense knowledge and the information provided by the source problem. Given the difficulty of performing reasoning directly on unstructured and ambiguous natural language text, it is reasonable to transform the source text into a structured, less ambiguous representation.\nOur approach contains three modules: 1) A meaning representation language called DOL newly designed by us as the semantic\nrepresentation of natural language text.\n2) A semantic parser which transforms natural language sentences of a math problem\ninto DOL representation.\n3) A reasoning module to derive math expressions from DOL representation."
  }, {
    "heading": "3.1 DOL: Meaning representation language",
    "text": "Every meaningful piece of NL text is represented in DOL as a semantic tree of various node types. Figure 2 shows the DOL representation of the second problem of Figure 1. It contains two semantic trees, corresponding to the two sentences."
  }, {
    "heading": "3.1.1 Node types",
    "text": "Node types of a DOL tree include constants, classes, and functions. Each interim node of a tree is always a function; and each leaf node can be a constant, a class, or a zero-argument function.\nConstants in DOL refer to specific objects in the world. A constant can be a number (e.g., 3.57), a lexical string (like ‚ÄúNew York‚Äù), or an entity.\nClasses: An entity class refers to a category of entities sharing common semantic properties. For example, all cities are represented by the class location.city; and math.number is a class for all numbers. It is clear that,\n3.14159 ‚àà math.number city.new_york ‚àà location.city\nA class C1 is a sub-class (denoted by ‚äÜ) of another class C2 if and only if every instance of C1 are in C2. The following holds according to common sense knowledge,\nmath.number ‚äÜ math.expression person.pianist ‚äÜ person.performer\nTemplate classes are classes with one or more parameters, just like template classes in C++. The most important template class in DOL is\nt.list<c,m,n>\nwhere c is a class; m and n are integers. Each instance of this class is a list containing at least m and at most n elements of type c. For example, each instance of t.list<math.number,2,+‚àû> is a list containing at least 2 numbers.\nFunctions are used in DOL as the major way to form larger language units from smaller ones. A function is comprised of a name, a list of core arguments, and a return type. DOL enables function overloading (again borrowing ideas from programming languages). That is, one function name can have multiple core-argument specifications. Below are two specifications for fn.math.sum (which appears in the example of Figure 2).\nnf.math.sum!1:\n$1: math.expression; $2: math.expression return type: math.expression return value: The sum of its arguments\nnf.math.sum!2:\n$1: t.list<math.expression,2,+‚àû> return type: math.expression return value: The sum of the elements in $1\nHere ‚Äú$1: math.expression‚Äù means the first ar-\ngument has type math.expression.\nDOL supports three kinds of functions: noun functions, verb functions, and modifier functions.\nNoun functions map entities to their properties or to other entities having specific relations with the argument(s). For example, nf.math.sum maps math expressions to their sum. Noun functions are used to represent noun phrases in natural language text. More noun functions are shown in Table 1.\nAmong all noun functions, nf.list has a special important position due to its high frequency in DOL trees. The function is specified below,\nnf.list\n$1: class; $2: math.number return type: t.list<$1> return value: An entity list with cardinality $2\nand element type $1\nFor example nf.list(math.number,5) returns a list containing 5 elements of type math.number. It is the semantic representation of ‚Äúfive numbers‚Äù.\nPronoun functions are special zero-argument noun functions. Examples are nf.it (representing an already-mentioned entity or event) and nf.what (denoting an unknown entity or entity list).\nVerb functions act as sentences or sub-sentences in DOL. As an example, vf.be.equ (in Figure 2) is a verb function that has two arguments of the quantity type.\nvf.be.equ\n$1: quantity.generic; $2: quantity.generic return type: t.vf Meaning: Two quantities $1 and $2 have the\nsame value\nIn addition to core arguments ($1, $2, etc.), many functions can take additional extended arguments as their modifiers. Our last function type called modifier functions often take the role of extended arguments, to modify noun functions, verb functions, or other modifier functions. Modifier functions are used in DOL as the semantic representation of adjectives, adverb phrases (including conjunctive adverb phrases), and prepositional phrases in natural languages. In the example of Figure 2, the function mf.number.even modifies the noun function nf.list as its extended argument."
  }, {
    "heading": "3.1.2 Entity variables",
    "text": "Variables are assigned to DOL sub-trees for indicating the co-reference of sub-trees to entities and for facilitating the construction of logical forms and math expressions from DOL. In Figure 2, the same variable v1 (meaning a variable with ID 1) is assigned to two sub-trees in the first sentence\nand one sub-tree in the second sentence. Thus the three sub-trees refer to the same entity."
  }, {
    "heading": "3.1.3 Key features of DOL",
    "text": "DOL has some nice characteristics that are critical to building a high-precision math problem solving system. That is why we invent DOL as our meaning representation language instead of employing an existing one.\nFirst, DOL is a strongly typed language. Every function has clearly defined argument types and a return type. A valid DOL tree must satisfy the type-compatibility property:\nType-compatibility: The type of each child of a function node should match the corresponding argument type of the function.\nFor example, in Figure 2, the return type of nf.math.power is math.expression, which matches the second argument of vf.be.equ. However, the following two trees (yielded from the corresponding pieces of text) are invalid because they do not satisfy type-compatibility.\nsum of 100 [unreasonable text] nf.math.sum!2(100) [invalid DOL tree] sum of 3 and Jordan [unreasonable text] nf.math.sum!2({3, ‚ÄúJordan‚Äù}) [invalid tree]\nSecond, we maintain in DOL an open-domain type system. The type system contains over 1000 manually verified classes and more automatically generated ones (refer to Section 3.2.1 for more details). Such a comprehensive type system makes it possible to define various kinds of functions and to perform type-compatibility checking. In contrast, most previous semantic languages have at most 100+ types at the grammar level. In addition, by introducing template classes, we avoid maintaining a lot of potentially duplicate types and reduce the type system management efforts. To the best of our knowledge, template classes are not\navailable in other semantic representation languages.\nThird, DOL has built-in data structures like t.list and nf.list which greatly facilitate both function declaration and text representation (especially math text representation). For example, the two variants of nf.math.sum (refer to Section 3.1.1 for their specifications) are enough to represent the following English phrases:\n3 plus 5  nf.math.sum!1(3, 5) sum of 3, 5, 7, and 9  nf.math.sum!2(nf.list(3, 5, 7, 9)) sum of ten thousand numbers  nf.math.sum!2(nf.list(math.number,10000))\nWithout t.list or nf.list, we would have to define a lot of overloaded functions for nf.math.sum to deal with different numbers of addends."
  }, {
    "heading": "3.1.4 Comparing with other languages",
    "text": "Among all meaning representation languages, AMR (Banarescu et al., 2013) is most similar to DOL. Their major differences are: First, they use very different mechanisms to represent noun phrases. In AMR, a sentence (e.g., ‚Äúthe boy destroyed the room‚Äù) and a noun phrase (e.g., ‚Äúthe boy‚Äôs destruction of the room‚Äù) can have the same representation. While in DOL, a sentence is always represented by a verb function; and a noun phrase is always a noun function or a constant. Second, DOL has a larger type system and is stricter in type compatibility checking. Third, DOL has template classes and built-in data structures like t.list and nf.list to facilitate the representation of math concepts.\nCCG (Steedman, 2000) provides a transparent interface between syntax and semantics. In CCG, semantic information is defined on words (e.g., ‚ÄúŒªx.odd(x)‚Äù for ‚Äúodd‚Äù and ‚ÄúŒªx.number(x)‚Äù for ‚Äúnumber‚Äù). In contrast, DOL explicitly connects NL text patterns to semantic elements. For example, as shown in Table 2 (Section 3.2.1), one CFG grammar rule connects pattern ‚Äú{$1} raised to the power of {$2}‚Äù to function nf.math.power.\nLogical forms are another way of meaning representation. We choose not to transform NL text directly to logical forms for two reasons: On one hand, state-of-the-art methods for mapping NL text into logical forms typically target short, onesentence queries in restricted domains. However, many math word problems are long and contain multiple sentences. On the other hand, variable-id assignment is a big issue in direct logical form construction for many math problems. Let‚Äôs use\nthe following problem (i.e., the first problem of Figure 1) to illustrate,\nOne number is 16 more than another. If the smaller number is subtracted from 2/3 of the larger, the result is 1/4 of the sum of the two numbers. Find the numbers.\nFor this problem, it is difficult to determine whether ‚Äúthe smaller number‚Äù refers to ‚Äúone number‚Äù or ‚Äúanother‚Äù in directly constructing logical forms. It is therefore a challenge to construct a correct logical form for such kinds of problems.\nOur solution to the above challenge is assigning a new variable ID (which is different from the IDs of ‚Äúone number‚Äù and ‚Äúanother‚Äù) and to delay the final variable-ID assignment to the reasoning stage. To enable this mechanism, the meaning representation language should support a lazy variable ID assignment and keep as much information (e.g., determiners, plurals, modifiers) from the noun phrases as possible. DOL is a language that always keeps the structure information of phrases, whether or not it has been assigned a variable ID.\nIn summary, compared with other languages, DOL has some unique features which make it more suitable for our math problem solving scenario."
  }, {
    "heading": "3.2 Semantic Parsing",
    "text": "Our parsing algorithm is based on context-free grammar (CFG) (Chomsky, 1956; Backus, 1959; Jurafsky & Martin, 2000), a commonly used mathematical system for modeling constituent structure in natural languages.\n3.2.1 CFG for connecting DOL and NL\nThe core part of a CFG is the set of grammar rules. Example English grammar rules for build-\ning syntactic parsers include ‚ÄúS ‚Üí NP VP‚Äù, ‚ÄúNP ‚Üí\nCD | DT NN | NP PP‚Äù, etc. Table 2 shows some example CFG rules in our system for mapping DOL nodes to natural language word sequences. The left side of each rule is a DOL element (a function, class, or constant); and the right side is a sequence of words and arguments. The grammar rules are consumed by our parser for building DOL trees from NL text.\nSo far there are 9,600 grammar rules in our system. For every DOL node type, the lexicon and grammar rules are constructed together in a semiautomatic way. Math-related classes, functions, and constants and their grammar rules are manually built by referring to text books and online tu-\ntorials. About 35 classes and 200 functions are obtained in this way. Additional instances of each element type are constructed in the ways below.\nClasses: Additional classes and grammar rules are obtained from two data sources: Freebase 3 types, and automatically extracted lexical semantic data. By treating Freebase types as DOL classes and the mapping from types to lexical names as grammar rules, we get the first version of grammar for classes. To improve coverage, we run a term peer similarity and hypernym extraction algorithm (Hearst, 1992; Shi et al., 2010; Zhang et al., 2011) on a web snapshot of 3 billion pages, and get a peer-similarity graph and a collection of is-a pairs. An is-a pair example is (Megan Fox, actress), where ‚ÄúMegan Fox‚Äù and ‚Äúactress‚Äù are instance and type names respectively. In our peer similarity graph, ‚ÄúMegan Fox‚Äù and ‚ÄúBritney Spears‚Äù have a high similarity score. The peer similarity graph is used to clean the is-a data collection (with the idea that peer terms often share some common type names). Given the cleaned isa data, we sort the type names by weight and manually create classes for top-1000 type names. For example, create a class person.actress and add a grammar rule ‚Äúperson.actress ‚Üí actress‚Äù. For the other 2000 type names in the top 3000, we create classes and rules automatically, in the form of ‚Äúclass.TN ‚Üí TN‚Äù, where TN is a type name. For example, create rule ‚Äúclass.succulent ‚Üí succulent‚Äù for name ‚Äúsucculent‚Äù.\n3 Freebase: http://www.freebase.com/\nFunctions: Additional noun functions are automatically created from Freebase properties and attribute extraction results (Pasca et al., 2006; Durme et al., 2008), using a similar procedure with creating classes from Freebase types and isa extraction results. We have over 50 manually defined math-related verb functions. Our future plan is automatically generating verb functions from databases like PropBank (Kingsbury & Palmer, 2002), FrameNet (Fillmore et al., 2003), and VerbNet4 (Schuler, 2005). Additional modifier functions are automatically created from an English adjective and adverb list, in the form of ‚Äúmf.adj.TN ‚Üí TN‚Äù and ‚Äúmf.adv.TN ‚Üí TN‚Äù where TN is the name of an adjective or adverb.\n3.2.2 Parsing\nParsing for CFG is a well-studied topic with lots of algorithms invented (Kasami, 1965; Earley, 1970). The core idea behind almost all the algorithms is exploiting dynamic programming to achieve efficient search through the space of possible parse trees. For syntactic parsing, a wellknown serious problem is ambiguity: the appearance of many syntactically correct but semantically unreasonable parse trees. Modern syntactic parsers reply on statistical information to reduce\n4 VerbNet: http://verbs.colorado.edu/~mpalmer/projects/verbnet.html\nambiguity. They are often based on probabilistic CFGs (PCFGs) or probabilistic lexicalized CFGs trained on hand-labeled TreeBanks.\nWith the new set of DOL-NL grammar rules (examples in Table 2) and the type-compatibility property (Section 3.1.3), ambiguity can hopefully be greatly reduced, because semantically unreasonable parsing often results in invalid DOL trees.\nWe implement a top-down parser for our new CFG of Section 3.2.1, following the Earley algorithm (Earley, 1970). No probabilistic information is attached in the grammar rules because no Treebanks are available for learning statistical probabilities for the new CFG. Figure 3 shows the parse tree returned by our parser when processing a simple sentence. The DOL tree can be obtained by removing the dotted lines (corresponding to the non-argument part in the right side of the grammar rules). A traditional syntactic parse tree is shown in Figure 4 for reference.\nDuring parsing, a score is calculated for each DOL node. The score of a tree T is the weighted average of the scores of its sub-trees,\nùë∫(ùëª) =\n‚àë ùë≥(ùëªùíä) ‚àô ùë∫(ùëªùíä) ùíå ùíä=ùüè\n‚àë ùë≥(ùëªùíä) ùíå ùíä=ùüè\n‚àô ùíë(ùëª) (3)\nwhere ùëáùëñ is a sub-tree, and ùêø(ùëáùëñ) is the number of words to which the sub-tree corresponds in the original text. If the type-compatibility property for T is satisfied, ùëù(ùëá)=1; otherwise ùëù(ùëá)=0. All leaf nodes are assigned a score of 1.0, except for pure lexical string nodes (which are used as named entity names). The score of a lexical string node is set to 1/(1+ùúán), where n is the number of words in the node, and ùúá (=0.2 in experiments) is a parameter whose value does not have much impact on parsing results. Such a score function encourages interpreting a word sequence with our grammar than treating it as an entity name.\nAmong all candidate DOL trees yielded during parsing, we return the one with the highest score as the final parsing result. A null tree is returned if the highest score is zero."
  }, {
    "heading": "3.3 Reasoning",
    "text": "The reasoning module is responsible for deriving math expressions from DOL trees and calculating problem answers by solving equation systems. Math expressions have different definitions in different contexts. In some definitions, equations and inequations are excluded from math expressions. In this paper, equations and inequations (like ‚Äúa=b‚Äù and ‚Äúax+b>0‚Äù) are called s-expressions because they represent mathematical sentences,\nwhile other math expressions (like ‚Äúx+5‚Äù) are named n-expressions since they are essentially noun phrases. Our definition of ‚Äúmath expressions‚Äù therefore includes both n-expressions and s-expressions.\nDifferent types of nodes may generate different types of math expressions. In most cases, s-expressions are derived from verb function nodes and modifier function nodes, while n-expressions are generated from constants and noun function nodes. For example, the s-expression ‚Äú9+x=314‚Äù can be derived from the DOL tree of Figure 3, if variable x represents the integer. In the same Figure, The n-expression ‚Äú9+x‚Äù is derived from the left sub-tree.\nThe pseudo-codes of our math expression derivation algorithm are shown in Figure 5. The algorithm generates the math expression for a DOL tree T by first calling the expression derivation procedure of sub-trees, and then applying the semantic interpretation of T. All the s-expressions derived so far are stored in an expression list named XL.\nThe semantic interpretation of DOL nodes plays a critical role in the algorithm. Table 3 shows some example interpretations of some representative DOL functions. In the table, $1, $2 etc. are function arguments, and $‚Üë for a modifier node denotes the node which the modifier modifies. So far the semantic interpretations are built manually. Please note that it is not necessary to make semantic interpretations for every DOL\nnode in solving number word problems. For example, most class nodes and many adverb nodes can have null interpretations at the moment."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Experimental setup",
    "text": "Datasets: Our problem collection5 contains 1,878 math number word problems, collected from two web sites: algebra.com6 (a web site for users to post math problems and get help from tutors) and answers.yahoo.com7. Problems on both sites are organized into categories. For algebra.com, problems are randomly sampled from the number word problems category; for answers.yahoo.com, we first randomly sample an initial set of problems from the math category and then ask human annotators to manually choose number word problems from them. Math equations 8 and answers to the problems are manually added by human annotators.\nWe randomly split the dataset into a dev set (for algorithm design and debugging) and a test set. More subsets are extracted to meet the requirements of the baseline methods (see below). Table 4 shows the statistics of the datasets.\nBaseline methods: We compare our approach with two baselines: KAZB (Kushman et al., 2014) and BasicSim.\nKAZB is a learning-based statistical method which solves a problem by mapping it to one of the equation templates determined by the annotated equations in the training data. We run the ALLEQ version of their algorithm since it performs much better than the other two (i.e., 5EQ and 5EQ+ANS). Their codes support only linear equations and require that there are at least two problems for each equation template (otherwise an exception will be thrown). By choosing problems from the collection that meet these requirements, we build a sub-dataset called LinearT2. In the dataset of KAZB, each equation template corresponds to at least 6 problems. So we form another sub-dataset called LinearT6 by removing from the test set the problems for which the associated equation template appears less than 6 times.\nBasicSim is a simple statistical method which works by computing the similarities between a testing problem and those in the training set, and then applying the equations of the most similar problem. This method has similar performance\n5 Available from http://research.microsoft.com/en-us/projects/dolphin/ 6 http://www.algebra.com\nwith KAZB on their dataset, but does not have the two limitations mentioned above. Therefore we adopt it as the second baseline.\nFor both baselines, experiments are conducted using 5-fold cross-validation with the dev set always included in the training data. In other words, we always use the dev set and 4/5 of the test set as training data for each fold.\nEvaluation metrics: Evaluation is performed in the setting that a system can choose NOT to answer all problems in the test set. In other words, one has the flexibility of generating answers only when she knows how to solve it or she is confident about her answer. In this setting, the following three metrics are adopted in reporting evaluation results (assuming, in a test set of size n, a system generates answers for m problems, where k of them are correct):\nPrecision: k/m Recall (or coverage): k/n F1: 2PR/(P+R) = 2k/(m+n)"
  }, {
    "heading": "4.2 Experimental results",
    "text": "The Overall evaluation results are summarized in Table 5, where ‚ÄúDolphin‚Äù represents our approach. The results show that our approach significantly outperforms (with p<<0.01 according to two-tailed t-test) the two baselines on every test set, in terms of precision, recall, and F-measure. Our approach achieves a particularly high precision of 95%. That means once an answer is provided by our approach, it has a very high probability of being correct.\nPlease note that our grammar rules and parsing algorithm are NOT tuned for the evaluation data. Only the dev set is referred to in system building.\n7 https://answers.yahoo.com/ 8 Math equations are used in the baseline approaches as part of training data.\nSince the baselines generate results for all problems, the precision, recall, and F1 are all the same for each dataset.\nThe reason for such a high precision is that, by transforming NL text to DOL trees, the system ‚Äúunderstands‚Äù the problem (or has structured and accurate information about quantity relations). Therefore it is more likely to generate correct results than statistical methods who simply ‚Äúguess‚Äù according to features. By examining the problems in the dev set that we cannot generate answers, we find that most of them are due to empty parsing results.\nOn the other hand, statistical approaches have the advantage of generating answers without understanding the semantic meaning of problems (as long as there are similar problems in the training data). So they are able to handle (with probably low precision) problems that are complex in terms of language and logic.\nPlease pay attention that our experimental results reported here are on number word problems. General math word problems are much harder to our approach because the entity types, properties, relations, and actions contained in general word problems are much larger in quantity and more complex in quality. We are working on extending our approach to general math word problems. Now our DOL language and CFG grammar already have a good coverage on common entity types, but the coverage on properties, relations, and actions is quite limited. As a result, our parser fails to parse many sentences in general math word problems because they contain properties, relations or actions that are unknown to our system. We also observe that sometimes we are able to parse a problem successfully, but cannot derive math expressions in the reasoning stage. This is often because some relations or actions in the problem are not modeled appropriately. As future work, we plan to extend our DOL lexicon and\ngrammar to improve the coverage of properties, relations, and actions. We also plan to study the mechanism of modeling relations and actions."
  }, {
    "heading": "5 Conclusion",
    "text": "We proposed a semantic parsing and reasoning approach to automatically solve math number word problems. We have designed a new meaning representation language DOL to bridge NL text and math expressions. A CFG parser is implemented to parse NL text to DOL trees. A reasoning module is implemented to derive math expressions from DOL trees, by applying the semantic interpretation of DOL nodes. We achieve a high precision and a reasonable recall on our test set of over 1,500 problems. We hope to extend our techniques to handling general math word problems and to other domains (like physics and chemistry) in the future."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to thank the annotators for their efforts in assigning math equations and answers to the problems in our dataset. Thanks to the anonymous reviewers for their helpful comments and suggestions.\nReference\nJ.W. Backus. 1959. The syntax and semantics of the\nproposed international algebraic language of the Zurich ACM-GAMM conference. Proceedings of the International Conference on Information Processing, 1959.\nY. Bakman. 2007. Robust understanding of word prob-\nlems with extraneous information. http://arxiv.org/ abs/math/0701393. Accessed Feb. 2nd, 2015.\nC. Baker, M. Ellsworth, and K. Erk. 2007. SemEval-\n2007 Task 19: Frame semantic structure extraction. In Proceedings of SemEval.\nL. Banarescu, C. Bonial, S. Cai, M. Georgescu, K.\nGriffitt, U. Hermjakob, K. Knight, P. Koehn, M. Palmer, and N. Schneider. 2013. Abstract meaning representation for sembanking. In Proc. of the Linguistic Annotation Workshop and Interoperability with Discourse.\nJ. Berant, A. Chou, R. Frostig, and P. Liang. 2013. Se-\nmantic parsing on Freebase from question-answer pairs. In Empirical Methods in Natural Language Processing (EMNLP).\nJ. Berant and P. Liang. 2014. Semantic Parsing via Par-\naphrasing. In ACL'2014.\nD.G. Bobrow. 1964a. Natural language input for a\ncomputer problem solving system. Report MACTR-1, Project MAC, MIT, Cambridge, June\nD.G. Bobrow. 1964b. Natural language input for a\ncomputer problem solving system. Ph.D. Thesis, Department of Mathematics, MIT, Cambridge\nD.L. Briars, J.H. Larkin. 1984. An integrated model of\nskill in solving elementary word problems. Cognition and Instruction, 1984, 1 (3) 245-296.\nQ. Cai and A. Yates. 2013. Large-scale semantic pars-\ning via schema matching and lexicon extension. In Association for Computational Linguistics (ACL).\nX. Carreras. and L. Marquez. 2004. Introduction to the\nCoNLL-2004 shared task: Semantic role labeling. In Proceedings of CoNLL.\nE. Charniak. 1968. CARPS: a program which solves\ncalculus word problems. Report MAC-TR-51, Project MAC, MIT, Cambridge, July\nE. Charniak. 1969. Computer solution of calculus word\nproblems. In Proceedings of international joint conference on artificial intelligence. Washington, DC, pp 303‚Äì316\nN. Chomsky. 1956. Three models for the description of\nlanguage. Information Theory, IRE Transactions on, 2(3), 113-124.\nS. Clark, and J. Curran. 2007. Wide-coverage efficient\nstatistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493-552.\nD. Das, D. Chen, A.F.T. Martins, N. Schneider and\nN.A. Smith. 2014. Frame-Semantic Parsing. Computational Linguistics 40:1, pages 9-56\nD. Dellarosa. 1986. A computer simulation of chil-\ndren‚Äôs arithmetic word problem solving. Behavior Research Methods, Instruments, & Computers, 18:147‚Äì154\nV. Durme, T. Qian, and L. Schubert. 2008. Class-\ndriven attribute extraction. In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pp. 921-928. Association for Computational Linguistics, 2008.\nJ. Earley. 1970. An efficient context-free parsing algo-\nrithm. Communications of the ACM, 13(2), 94-102.\nC.J. Fillmore, C.R. Johnson, and M.R. Petruck. 2003.\nBackground to FrameNet. International Journal of Lexicography, 16(3).\nC.R. Fletcher. 1985. Understanding and solving arith-\nmetic word problems: a computer simulation. Behavior Research Methods, Instruments, & Computers, 17:565‚Äì571\nD. Gildea, and D. Jurafsky. 2002. Automatic labeling\nof semantic roles. Computational Linguistics, 28(3).\nM. Hearst. 1992. Automatic Acquisition of Hyponyms\nfrom Large Text Corpora. In Fourteenth International Conference on Computational Linguistics, Nantes, France.\nM.J. Hosseini, H. Hajishirzi, O. Etzioni, and N. Kush-\nman. 2014. Learning to Solve Arithmetic Word Problems with Verb Categorization. In EMNLP‚Äô2014.\nD. Jurafsky, and J.H. Martin. 2000. Speech & language\nprocessing. Pearson Education India.\nT. Kasami. 1965. An efficient recognition and syntax-\nanalysis algorithm for context-free languages (Technical report). AFCRL. 65-758.\nP. Kingsbury, and M. Palmer. 2002. From TreeBank to\nPropBank. In Proceedings of LREC.\nN. Kushman, Y. Artzi, L. Zettlemoyer, and R. Barzi-\nlay. 2014. Learning to automatically solve algebra word problems. In Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL).\nT. Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer.\n2013. Scaling semantic parsers with on-the-fly ontology matching. In Empirical Methods in Natural Language Processing (EMNLP).\nI. Lev, B. MacCartney, C. Manning, and R. Levy.\n2004. Solving logic puzzles: From robust processing to precise semantics. In Proceedings of the Workshop on Text Meaning and Interpretation. Association for Computational Linguistics.\nC. Liguda, T. Pfeiffer. 2012. Modeling Math Word\nProblems with Augmented Semantic Networks. NLDB‚Äô2012, pp. 247-252.\nY. Ma, Y. Zhou, G. Cui, R. Yun, R. Huang. 2010.\nFrame-based calculus of solving arithmetic multistep addition and subtraction word problems. In International Workshop on Education Technology and Computer Science, vol. 2, pp. 476‚Äì479.\nL. Marquez, X. Carreras, K.C. Litkowski, and S. Ste-\nvenson. 2008. Semantic role labeling: an introduction to the special issue. Computational Linguistics, 34(2).\nA. Mukherjee and U. Garain. 2008. A review of meth-\nods for automatic understanding of natural language mathematical problems. Artificial Intelligence Review, 29(2).\nM. Pasca, D. Lin, J. Bigham, A. Lifchits, and A. Jain.\n2006. Organizing and searching the world wide web of facts-step one: the one-million fact extraction challenge. In AAAI (Vol. 6, pp. 1400-1405).\nK.K. Schuler. 2005. VerbNet: A broad-coverage, com-\nprehensive verb lexicon. Dissertation. http://repository.upenn.edu/dissertations/AAI3179808\nS. Shi, H. Zhang, X. Yuan, and J.-R. Wen. 2010. Cor-\npus-based semantic class mining: distributional vs. pattern-based approaches. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 993‚Äì1001. Association for Computational Linguistics.\nM. Steedman. 2000. The Syntactic Process. The MIT\nPress.\nY. W. Wong and R. J. Mooney. 2007. Learning syn-\nchronous grammars for semantic parsing with lambda calculus. In Association for Computational Linguistics (ACL), pages 960‚Äì967.\nM. Zelle and R.J. Mooney. 1996. Learning to parse da-\ntabase queries using inductive logic proramming. In Association for the Advancement of Artificial Intelligence (AAAI), pages 1050‚Äì1055.\nL.S. Zettlemoyer and M. Collins. 2005. Learning to\nmap sentences to logical form: Structured classification with probabilistic categorial grammars. In Uncertainty in Artificial Intelligence (UAI), pages 658‚Äì666.\nL.S. Zettlemoyer and M. Collins. 2007. Online Learn-\ning of Relaxed CCG Grammars for Parsing to Logical Form. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).\nF. Zhang, S. Shi, J. Liu, S. Sun, and C.-Y. Lin. 2011.\nNonlinear evidence fusion and propagation for hyponymy relation mining. In ACL, volume 11, pages 1159‚Äì1168."
  }],
  "year": 2015,
  "references": [{
    "title": "The syntax and semantics of the proposed international algebraic language of the Zurich ACM-GAMM conference",
    "authors": ["J.W. Backus."],
    "venue": "Proceedings of the International Conference on Information Processing, 1959.",
    "year": 1959
  }, {
    "title": "Robust understanding of word problems with extraneous information",
    "authors": ["Y. Bakman."],
    "venue": "http://arxiv.org/ abs/math/0701393. Accessed Feb. 2, 2015.",
    "year": 2007
  }, {
    "title": "SemEval2007 Task 19: Frame semantic structure extraction",
    "authors": ["C. Baker", "M. Ellsworth", "K. Erk."],
    "venue": "Proceedings of SemEval.",
    "year": 2007
  }, {
    "title": "Abstract meaning representation for sembanking",
    "authors": ["L. Banarescu", "C. Bonial", "S. Cai", "M. Georgescu", "K. Griffitt", "U. Hermjakob", "K. Knight", "P. Koehn", "M. Palmer", "N. Schneider."],
    "venue": "Proc. of the Linguistic Annotation Workshop and Interoperability",
    "year": 2013
  }, {
    "title": "Semantic parsing on Freebase from question-answer pairs",
    "authors": ["J. Berant", "A. Chou", "R. Frostig", "P. Liang."],
    "venue": "Empirical Methods in Natural Language Processing (EMNLP).",
    "year": 2013
  }, {
    "title": "Semantic Parsing via Paraphrasing",
    "authors": ["J. Berant", "P. Liang."],
    "venue": "ACL'2014.",
    "year": 2014
  }, {
    "title": "Natural language input for a computer problem solving system",
    "authors": ["D.G. Bobrow."],
    "venue": "Report MACTR-1, Project MAC, MIT, Cambridge, June",
    "year": 1964
  }, {
    "title": "Natural language input for a computer problem solving system",
    "authors": ["D.G. Bobrow."],
    "venue": "Ph.D. Thesis, Department of Mathematics, MIT, Cambridge",
    "year": 1964
  }, {
    "title": "An integrated model of skill in solving elementary word problems",
    "authors": ["D.L. Briars", "J.H. Larkin."],
    "venue": "Cognition and Instruction, 1984, 1 (3) 245-296.",
    "year": 1984
  }, {
    "title": "Large-scale semantic parsing via schema matching and lexicon extension",
    "authors": ["Q. Cai", "A. Yates."],
    "venue": "Association for Computational Linguistics (ACL).",
    "year": 2013
  }, {
    "title": "Introduction to the CoNLL-2004 shared task: Semantic role labeling",
    "authors": ["X. Carreras.", "L. Marquez."],
    "venue": "Proceedings of CoNLL.",
    "year": 2004
  }, {
    "title": "CARPS: a program which solves calculus word problems",
    "authors": ["E. Charniak."],
    "venue": "Report MAC-TR-51, Project MAC, MIT, Cambridge, July",
    "year": 1968
  }, {
    "title": "Computer solution of calculus word problems",
    "authors": ["E. Charniak."],
    "venue": "Proceedings of international joint conference on artificial intelligence. Washington, DC, pp 303‚Äì316",
    "year": 1969
  }, {
    "title": "Three models for the description of language",
    "authors": ["N. Chomsky."],
    "venue": "Information Theory, IRE Transactions on, 2(3), 113-124.",
    "year": 1956
  }, {
    "title": "Wide-coverage efficient statistical parsing with CCG and log-linear models",
    "authors": ["S. Clark", "J. Curran."],
    "venue": "Computational Linguistics, 33(4):493-552.",
    "year": 2007
  }, {
    "title": "Frame-Semantic Parsing",
    "authors": ["D. Das", "D. Chen", "A.F.T. Martins", "N. Schneider", "N.A. Smith."],
    "venue": "Computational Linguistics 40:1, pages 9-56",
    "year": 2014
  }, {
    "title": "A computer simulation of children‚Äôs arithmetic word problem solving",
    "authors": ["D. Dellarosa."],
    "venue": "Behavior Research Methods, Instruments, & Computers, 18:147‚Äì154",
    "year": 1986
  }, {
    "title": "Classdriven attribute extraction",
    "authors": ["V. Durme", "T. Qian", "L. Schubert."],
    "venue": "Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pp. 921-928. Association for Computational Linguistics, 2008.",
    "year": 2008
  }, {
    "title": "An efficient context-free parsing algorithm",
    "authors": ["J. Earley."],
    "venue": "Communications of the ACM, 13(2), 94-102.",
    "year": 1970
  }, {
    "title": "Background to FrameNet",
    "authors": ["C.J. Fillmore", "C.R. Johnson", "M.R. Petruck."],
    "venue": "International Journal of Lexicography, 16(3).",
    "year": 2003
  }, {
    "title": "Understanding and solving arithmetic word problems: a computer simulation",
    "authors": ["C.R. Fletcher."],
    "venue": "Behavior Research Methods, Instruments, & Computers, 17:565‚Äì571",
    "year": 1985
  }, {
    "title": "Automatic labeling of semantic roles",
    "authors": ["D. Gildea", "D. Jurafsky."],
    "venue": "Computational Linguistics, 28(3).",
    "year": 2002
  }, {
    "title": "Automatic Acquisition of Hyponyms from Large Text Corpora",
    "authors": ["M. Hearst."],
    "venue": "Fourteenth International Conference on Computational Linguistics, Nantes, France.",
    "year": 1992
  }, {
    "title": "Learning to Solve Arithmetic Word Problems with Verb Categorization",
    "authors": ["M.J. Hosseini", "H. Hajishirzi", "O. Etzioni", "N. Kushman."],
    "venue": "EMNLP‚Äô2014.",
    "year": 2014
  }, {
    "title": "Speech & language processing",
    "authors": ["D. Jurafsky", "J.H. Martin."],
    "venue": "Pearson Education India.",
    "year": 2000
  }, {
    "title": "An efficient recognition and syntaxanalysis algorithm for context-free languages (Technical report)",
    "authors": ["T. Kasami."],
    "venue": "AFCRL. 65-758.",
    "year": 1965
  }, {
    "title": "From TreeBank to PropBank",
    "authors": ["P. Kingsbury", "M. Palmer."],
    "venue": "Proceedings of LREC.",
    "year": 2002
  }, {
    "title": "Learning to automatically solve algebra word problems",
    "authors": ["N. Kushman", "Y. Artzi", "L. Zettlemoyer", "R. Barzilay."],
    "venue": "Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL).",
    "year": 2014
  }, {
    "title": "Scaling semantic parsers with on-the-fly ontology matching",
    "authors": ["T. Kwiatkowski", "E. Choi", "Y. Artzi", "L. Zettlemoyer."],
    "venue": "Empirical Methods in Natural Language Processing (EMNLP).",
    "year": 2013
  }, {
    "title": "Solving logic puzzles: From robust processing to precise semantics",
    "authors": ["I. Lev", "B. MacCartney", "C. Manning", "R. Levy."],
    "venue": "Proceedings of the Workshop on Text Meaning and Interpretation. Association for Computational Linguistics.",
    "year": 2004
  }, {
    "title": "Modeling Math Word Problems with Augmented Semantic Networks",
    "authors": ["C. Liguda", "T. Pfeiffer."],
    "venue": "NLDB‚Äô2012, pp. 247-252.",
    "year": 2012
  }, {
    "title": "Frame-based calculus of solving arithmetic multistep addition and subtraction word problems",
    "authors": ["Y. Ma", "Y. Zhou", "G. Cui", "R. Yun", "R. Huang."],
    "venue": "International Workshop on Education Technology and Computer Science, vol. 2, pp. 476‚Äì479.",
    "year": 2010
  }, {
    "title": "Semantic role labeling: an introduction to the special issue",
    "authors": ["L. Marquez", "X. Carreras", "K.C. Litkowski", "S. Stevenson."],
    "venue": "Computational Linguistics, 34(2).",
    "year": 2008
  }, {
    "title": "A review of methods for automatic understanding of natural language mathematical problems",
    "authors": ["A. Mukherjee", "U. Garain."],
    "venue": "Artificial Intelligence Review, 29(2).",
    "year": 2008
  }, {
    "title": "Organizing and searching the world wide web of facts-step one: the one-million fact extraction challenge",
    "authors": ["M. Pasca", "D. Lin", "J. Bigham", "A. Lifchits", "A. Jain."],
    "venue": "AAAI (Vol. 6, pp. 1400-1405).",
    "year": 2006
  }, {
    "title": "VerbNet: A broad-coverage, comprehensive verb lexicon",
    "authors": ["K.K. Schuler."],
    "venue": "Dissertation. http://repository.upenn.edu/dissertations/AAI3179808",
    "year": 2005
  }, {
    "title": "Corpus-based semantic class mining: distributional vs",
    "authors": ["S. Shi", "H. Zhang", "X. Yuan", "J.-R. Wen."],
    "venue": "pattern-based approaches. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 993‚Äì1001. Association for Com-",
    "year": 2010
  }, {
    "title": "The Syntactic Process",
    "authors": ["M. Steedman."],
    "venue": "The MIT Press.",
    "year": 2000
  }, {
    "title": "Learning synchronous grammars for semantic parsing with lambda calculus",
    "authors": ["Y.W. Wong", "R.J. Mooney."],
    "venue": "Association for Computational Linguistics (ACL), pages 960‚Äì967.",
    "year": 2007
  }, {
    "title": "Learning to parse database queries using inductive logic proramming",
    "authors": ["M. Zelle", "R.J. Mooney."],
    "venue": "Association for the Advancement of Artificial Intelligence (AAAI), pages 1050‚Äì1055.",
    "year": 1996
  }, {
    "title": "Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars",
    "authors": ["L.S. Zettlemoyer", "M. Collins."],
    "venue": "Uncertainty in Artificial Intelligence (UAI), pages 658‚Äì666.",
    "year": 2005
  }, {
    "title": "Online Learning of Relaxed CCG Grammars for Parsing to Logical Form",
    "authors": ["L.S. Zettlemoyer", "M. Collins."],
    "venue": "Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language",
    "year": 2007
  }, {
    "title": "Nonlinear evidence fusion and propagation for hyponymy relation mining",
    "authors": ["F. Zhang", "S. Shi", "J. Liu", "S. Sun", "C.-Y. Lin."],
    "venue": "ACL, volume 11, pages 1159‚Äì1168.",
    "year": 2011
  }],
  "id": "SP:acfe603d8a90ee3d4187e426b26c4d7bf394b4c8",
  "authors": [{
    "name": "Shuming Shi",
    "affiliations": []
  }, {
    "name": "Yuehui Wang",
    "affiliations": []
  }, {
    "name": "Chin-Yew Lin",
    "affiliations": []
  }, {
    "name": "Xiaojiang Liu",
    "affiliations": []
  }, {
    "name": "Yong Rui",
    "affiliations": []
  }],
  "abstractText": "This paper presents a semantic parsing and reasoning approach to automatically solving math word problems. A new meaning representation language is designed to bridge natural language text and math expressions. A CFG parser is implemented based on 9,600 semi-automatically created grammar rules. We conduct experiments on a test set of over 1,500 number word problems (i.e., verbally expressed number problems) and yield 95.4% precision and 60.2% recall.",
  "title": "Automatically Solving Number Word Problems by Semantic Parsing and Reasoning"
}