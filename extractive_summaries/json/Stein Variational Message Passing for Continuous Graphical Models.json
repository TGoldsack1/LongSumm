{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Probabilistic graphical models, such as Markov random fields (MRFs) and Bayesian networks, provide a powerful framework for representing complex stochastic dependency structures between a large number of random effects (Pearl, 1988; Lauritzen, 1996). A key challenge, however, is to develop computationally efficient inference algorithms to approximate important integral quantities related to distributions of interest. Variational message passing methods, notably belief propagation (Pearl, 1988; Yedidia et al., 2003), provide one of the most powerful frameworks for approximate inference in graphical models (Wainwright & Jordan, 2008). In addition to accurate approximation, message passing algorithms perform inference in a distributed fashion by passing messages between variable nodes to\n*Equal contribution 1Department of Computer Science, The University of Texas at Austin 2School of Mathematical Sciences, Zhejiang University. Correspondence to: Dilin Wang <dilin@cs.utexas.edu>, Qiang Liu <lqiang@cs.utexas.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\npropagate uncertainty, well suited for decentralized inference tasks such as sensor network localization (e.g., Ihler et al., 2005).\nUnfortunately, standard belief propagation (BP) is best applicable only to discrete or Gaussian variable models. Significant additional challenges arise when applying BP to continuous, non-Gaussian graphical models, because the exact BP updates involve intractable integration. As a result, the existing continuous variants of BP require additional particles or non-parametric approximation (e.g., Ihler et al., 2005; Ihler & McAllester, 2009; Sudderth et al., 2010; Song et al., 2011), which deteriorates the accuracy and stability. Another key aspect that was not well discussed in the literature is that the traditional continuous BP methods are gradient-free, in that they do not use the gradient of the density function. Although this makes the methods widely applicable, their performance can be significantly improved by incorporating the gradient information whenever available.\nStein variational gradient descent (SVGD) (Liu & Wang, 2016) is a recent particle-based variational inference algorithm that combines the advantages of variational inference and particle-based methods, and efficiently leverages the gradient information for continuous inference. Unlike traditional variational inference that constructs parametric approximation of the target distribution by minimizing KL divergence, SVGD directly approximates the target distribution with a set of particles, which is iteratively updated following a velocity field that decreases the KL divergence with the fastest speed among all possible velocity fields in a reproducing kernel Hilbert space (RKHS) of a positive definite kernel. This makes SVGD inherit the theoretical consistency of particle methods (Liu, 2017), while obtaining the fast practical convergence thanks to its deterministic updates. The goal of this work is to adapt SVGD for distributed inference of continuous graphical models.\nIn principle, one can directly apply SVGD to continuous graphical models. However, standard SVGD does not yield a distributed message passing like BP, because its update involves a kernel function, which is defined on all the variable dimensions, introducing additional dependency beyond the Markov blanket of the graphical model of interest. In addition, the use of the global kernel function on all the\nvariables also deteriorates the performance in high dimensions; our empirical findings show that although SVGD tends to perform exceptionally well in estimating the mean parameters, it becomes less sample efficient in terms of estimating the variances as the dimension increases.\nIn this paper, we improve SVGD to take advantage of the inherent dependency structure of graphical models for better distributed inference. Instead of using a global kernel function, we associate each node with a local kernel function that only depends on the Markov blanket of each node. This simple modification allows us to turn SVGD into a distributed message passing algorithm, and simultaneously alleviates the curse of dimensionality.\nTheoretically, our method extends the original SVGD in two significant ways: i) it uses different kernel functions for different coordinates (or variable nodes), justified with a theoretical analysis that extends the results of Liu et al. (2016); Liu & Wang (2016); ii) it uses a local kernel over the Markov blanket for each node, which, compared with the typical global kernel function, can be viewed as introducing a type of deterministic approximation to trade for better sample efficiency. Our empirical results show that our method outperforms a variety of baseline methods, including the typical SVGD and Monte Carlo, and particle message passing (PMP). We note that a similar idea is independently and concurrently proposed by Zhuo et al. (2018) in the same conference proceeding."
  }, {
    "heading": "2. Background",
    "text": "We introduce the background of Stein variational gradient descent (SVGD) and kernelized Stein discrepancy (KSD), which forms the foundation of our work. For notation, we denote by x = [x1, . . . , xd] a vector in Rd and {x`}n`=1 a set of n vectors.\nStein Variational Gradient Descent (SVGD) Let p(x) be a positive differentiable density function on Rd. Our goal is to find a set of points (or particles) {x`}n`=1 to approximate p so that ∑n `=1 f(x\n`)/n ≈ Ep[f ] for general test functions f . SVGD achieves this by iteratively updating the particles with deterministic transforms of form\nx` ← x` + φ(x`), ∀` = 1, . . . , n,\nwhere is a small step size and φ is a velocity field that decides the update directions of the particles. The key problem is to choose an optimal velocity field φ to decrease the KL divergence between the distribution of particles and the target p(x) as fast as possible. This can be solved by the following basic observation shown in Liu & Wang (2016): assume x ∼ q and q[ φ] is the distribution of x′ = x+ φ(x), then\nKL(q[ φ] ‖ p) = KL(q ‖ p)− Ex∼q[P>x φ(x)] +O( 2),\nwhere Px is a linear operator, called Stein operator, that acts on function φ via\nP>x φ(x) def = ∇x log p(x)>φ(x) +∇>x φ(x). (1)\nThis result suggests that the decreasing rate of KL divergence when applying transform x′ = x + φ(x) is dominated by Ex∼q[P>x φ(x)] when the step size is small. In a special case when q = p, Stein operator draws connection to Stein’s identity, which shows\nEx∼q[P>x φ(x)] = 0 when p = q.\nThis is expected because as q = p, the decreasing rate of KL divergence must be zero for all velocity fields φ.\nGiven a candidate set F of velocity fields φ, we should choose the best φ to maximize the decreasing rate,\nD(q || p) def= max φ∈F\n{ Ex∼q[P>x φ(x)] } , (2)\nwhere the maximum decreasing rate D(q || p) is called the Stein discrepancy between q and p. AssumeF includes±φ for ∀φ ∈ F , then (2) is equivalent to maximizing the absolute value of Eq[P>x φ] and D(q || p) must be non-negative for any q and p. In addition, IfF is taken to be rich enough, D(q || p) = 0 only if there exists no velocity field φ that can decrease the KL divergence between p and q, which must imply p = q.\nTo make F computationally tractable, Liu & Wang (2016) further assumed that F is the unit ball of a vector-valued RKHS H = H0 × · · · × H0, where each H0 is a scalarvalued RKHS associated with a positive definite kernel k(x, x′). In this case, Liu et al. (2016) showed that the optimal solution of (2) is φ∗/||φ∗||, where\nφ∗(·) = Ex∼q[Pxk(x, ·)] = Ex∼q[∇x log p(x)k(x, ·) +∇xk(x, ·)]. (3)\nThis gives the optimal update direction within RKHS H. By starting with a set of initial particles and then repeatedly applying this update with q replaced by the empirical distributions of the particles, we obtain the SVGD algorithm:\nx` ← x` + φ∗(x`), ∀` = 1, . . . , n, (4)\nφ∗(·) = 1 n n∑ `=1 [∇x` log p(x`)k(x`, ·) +∇x`k(x`, ·)].\nThe two terms in φ∗(x) play different roles: the first term with the gradient ∇x log p(x) drives the particles toward the high probability regions of p(x), while the second term with ∇x`k(x, x`) serves as a repulsive force to encourage diversity as shown in Liu & Wang (2016). It is easy to see from (4) that SVGD reduces to standard gradient ascent for maximizing log p(x) (i.e., maximum a posteriori (MAP)) when there is only a single particle (n = 1).\nDiscriminative Stein Discrepancy One key requirement when selecting the function spaceH is that it should be rich enough to make Stein discrepancy discriminative, that is,\nD(q || p) = 0 implies q = p. (5)\nThis problem has been studied in various recent works, including Liu et al. (2016); Chwialkowski et al. (2016); Oates et al. (2016); Gorham & Mackey (2017), all of which require H to be an universal approximator in certain sense. In particular, the condition required in Liu et al. (2016) is that the kernel k(x, x′) should be strictly integrally positive definite in the sense that∫\ng(x)k(x, x′)g(x′)dxdx′ > 0, (6)\nfor any nonzero function g with 0 < ||g||22 < ∞. Many widely used kernels, including Gaussian RBF kernels of form k(x, x′) = exp(− 1h ||x− x\n′||22), are strictly integrally positive definite."
  }, {
    "heading": "3. SVGD for Graphical Models",
    "text": "The goal of our work is to extend SVGD to approximate high dimensional probabilistic graphical models of form\np(x) ∝ exp [∑ s∈S ψ(xs) ] , (7)\nwhere S is a family of index sets s ⊆ {1, . . . , d}, and xs = [xi]i∈s represents the sub-vector of x over index set s. Here the clique set S specifies the Markov structure of the graphical model: for each variable (or node) i, its Markov blanket (or neighborhood) Ni is the set of nodes that co-appears in at least one clique s ∈ S , that is, Ni := ∪{s : s ∈ S, s 3 i} \\ {i}. Related, we define the closed neighborhood (or clique) of node i to be Ci := Ni ∪{i}. The local Markov property guarantees that a variable xi is conditionally independent of all other nodes given its Markov blanket Ni.\nThe Markov structure is also reflected in gradient∇ log p:\n∂xi log p(x) = ∑ s3i ∂xiψ(xs),\nwhere ∂xi denotes the partial derivative with respect to xi, the i-th component of x. This suggests that the gradient evaluation of node i only requires information from its closed neighborhood set Ci; this property makes gradientbased distributed inference methods a possibility.\nUnfortunately, when directly applying SVGD to graphical models, the Markov structure is not inherited in the SVGD update (4), because typical kernel functions do not have the same (additive) factorization structure as ∂xi log p(x).\nTake the commonly used Gaussian RBF kernel k(x, x′) = exp(− 1h ||x − x\n′||22) as an example. Because k(x, x′) involves all the coordinates of x, the i-th coordinate of the Stein variational gradient φ∗(x) in (4) depends on all the other nodes, including those out of the Markov blanket of node i. This makes it infeasible to apply vanilla SVGD in distributed settings because the update of node i requires information from all the other nodes.\nMore importantly, this global dependency introduced by kernel functions may also lead to poor performance in high dimensional models. To illustrate this, we consider a simple example when the distribution p(x) of interest is fully factorized, that is, p(x) = ∏d i=1 pi(xi), where each node xi is independent of all the other nodes. In this case, we find that SVGD with the standard Gaussian RBF kernel (see SVGD (global kernel) in Figure 1) requires increasingly more particles in order to estimate the variance accurately as the dimension d increases; this is caused by the additional (and unnecessary) dependencies introduced by the use of the global RBF kernel.\nIn this particular case, an obviously better approach is to apply SVGD with RBF kernel on each of the onedimensional marginal pi(xi) individually (see SVGD (independent) in Figure 1)); this naturally leverages the fully factorized structure of p(x), and makes the algorithm immune to the curse of dimensionality because the RBF kernel is applied on an individual variable each time. Therefore, exploiting the sparse dependency structure can significantly improve the performance in high dimensions. The key question, however, is how we can extend the idea beyond the fully factorized case. This motivates our graphical SVGD algorithm as we show in the sequel."
  }, {
    "heading": "3.1. Graphical SVGD",
    "text": "In order to extend the above example, we observe that running SVGD on each marginal distribution pi(xi) independently can be viewed as a special SVGD applied on the joint distribution p(x) = ∏ i pi(xi), but updating each co-\nordinate xi using its own kernel ki(x, x′) that only depends on the i-th coordinate, that is, ki(x, x′) := ki(xi, x′i). An intuitive way to extend this to p(x) with more general Markov structures is to update each xi with a local kernel function ki(x, x′) := ki(xCi , x ′ Ci) that depends only on the closed neighborhood Ci of node i, that is,\nx`i ← x`i + φ∗i (x`), ∀i ∈ [d], ` ∈ [n] (8)\nφ∗i (x) := 1\nn n∑ `=1 [si(x `)ki(x ` Ci , xCi) + ∂x`iki(x ` Ci , xCi)],\nwhere si(x) = ∂xi log p(x). This procedure, which we call graphical SVGD (see also Algorithm 1), provides a simple way to efficiently integrate the graphical structure of p(x) into SVGD. As we demonstrate in our experiments, it significantly improves the performance in high dimensional, sparse graphical models. In addition, it yields a communication-efficient distributed message passing form, since the update of xi only requires to access the neighborhood variables in Ci.\nIs this graphical SVGD update theoretically sound? The key difference between (8) and the original SVGD (4) includes: i) graphical SVGD uses a different kernel ki(x, x′) for each coordinate xi; and ii) each kernel ki(x, x′) = ki(xCi , x ′ Ci) only depends on the closed neighborhood Ci = {i} ∪ Ni of node i. We justify these two choices theoretically in Section 3.2 and Section 3.3, respectively."
  }, {
    "heading": "3.2. Stein Discrepancy with Coordinate-wise Kernels",
    "text": "Using coordinate-wise kernel ki(x, x′) can be simply viewed as taking the spaceH in the functional optimization (2) to be a more general product spaceH = H1×· · ·×Hd, where each individual RKHS Hi is related to a different kernel ki(x, x′); the original SVGD can be viewed as a special case of this when all the kernels ki(x, x′), ∀i ∈ [d] equal. The following result extends Lemma 3.2 and Theorem 3.3 of Liu & Wang (2016) to take into account coordinate-wise kernels.\nTheorem 1. Let Hi be the (scalar-valued) RKHS related to kernel ki(x, x′), and H = H1 × · · · × Hd their product RKHS consisting of φ = [φ1, . . . , φd]> with norm ||φ||2H = ∑ i ||φi||2Hi , ∀φi ∈ Hi. Taking F = {φ ∈ H : ||φ||H ≤ 1} in the optimization problem in (2), then the optimal solution is\nφ∗(·) = Ex∼q[Px ◦ k(x, ·)], (9)\nwith Px ◦ k(x, ·) def = [Px1k1(x, ·), · · · ,Pxdkd(x, ·)]>,\nwhere ◦ denotes the entrywise product betweenPx and k = [k1, . . . , kd]. Further, the related Stein discrepancy in (2) equals D(q || p) = ||φ∗||H.\nAlgorithm 1 Graphical Stein Variational Gradient Descent Input: A graphical model p(x) with Markov blanket Ni for node i; Ci = Ni ∪ {i}; a set of local kernels ki(xCi , x ′ Ci), and initial particles {x\n`,0}n`=1; step size . Goal: A set of particles {x`}n`=1 that approximates p(x) for iteration t do\nfor node i do\nx`,t+1i ← x `,t i + φ ∗ i (x `,t) where φ∗i (x) is defined in (8) (with x ` = x`,t).\nend for end for\nThis result suggests that updates of form x′i ← x′i + Ex∼q[Pxiki(x, x′)] yields the fastest descent direction of KL divergence within H, justifying the graphical SVGD update in (8).\nThe following result studies the properties of the Stein discrepancy related to coordinate-wise kernels k = [k1, . . . , kd], showing that D(q || p) is discriminative if all the kernels ki(x, x′) are strictly integrally positive definite, a result that generalizes Proposition 3.3 of Liu et al. (2016). Theorem 2. Following Theorem 1, the Stein discrepancy D(q || p) with kernels k = [k1, . . . , kd] satisfies\nD(q || p)2 = d∑ i=1 Ex,x′∼q[PxiPx′iki(x, x ′)].\nFurther, Assume both p(x) and q(x) are positive and differentiable densities. Denote by Qx the Stein operator of distribution q. If Stein’s identity Ex∼q[Qxiki(x, x′)] = 0, ∀x′ ∈ X holds for all the kernels ki, ∀i ∈ [d], we have\nD(q || p)2 = d∑ i=1 Ex,x′∼q[δi(x)ki(x, x′)δi(x′)], (10)\nwhere δi(x) = ∇xi log p(xi|x¬i)−∇xi log q(xi|x¬i), with ¬i = {1, . . . , n} \\ {i}.\nAssume ||qδi||22 < ∞, ∀i ∈ [d]. If all the kernels ki(x, x′) are strictly integrally positive definite in the sense of (6), then D(q || p) = 0 implies q = p."
  }, {
    "heading": "3.3. Stein Discrepancy with Local Kernels",
    "text": "Theorem 2 requires every kernel ki(x, x′) to be strictly integral positive definite to make Stein discrepancy discriminative. However, in our graphical SVGD, each kernel function ki(x, x′) := ki(xCi , x ′ Ci) only depends on a subset of the variables and can be easily seen to be not strictly integrally positive definite in the sense of (6). As a result, the related Stein discrepancy is no longer discriminative in general.\nFortunately, as we show in the following, once each ki(xCi , x ′ Ci) is strictly integrally positive definite w.r.t. its own local variable domain xCi , that is,∫ g(xCi)ki(xCi , x ′ Ci)g(x ′ Ci)dxCidx ′ Ci > 0 (11)\nfor any function g(xCi) with 0 < ||g||22 < ∞, then a zero Stein discrepancy D(q || p) = 0 guarantees to match the conditional distributions:\nq(xi | xNi) = p(xi | xNi) for any i ∈ [d].\nAlthough this in general does not necessarily imply that the joint distribution equals (q = p) (unless q is guaranteed a priori to have the same Markov structure as p), it suggests that graphical SVGD captures important perspectives of the target distribution, especially in terms of the quantities related to the local dependency structures.\nTheorem 3. Assuming that p(x) is a graphical model in which the Markov neighborhood of node i is Ni and Ci = Ni ∪ {i}, and that ki(x, x′) = ki(xCi , x′Ci), ∀i ∈ [d], then (10) reduces to\nD(q || p)2 = d∑ i=1 Ex,x′∼q[δi(xCi)ki(xCi , x′Ci)δi(x ′ Ci)],\nwhere δi(xCi) = ∇xi log p(xi|xNi) − ∇xi log q(xi|xNi). Further, assume g(xCi) := q(xCi)δi(xCi) and ||g||22 < ∞. If each kernel ki(xCi , xCi) is integrally strictly positive definite w.r.t. variable xCi as defined in (11), we have\nD(q || p) = 0 iff q(xi|xNi) = p(xi|xNi), ∀i ∈ [d].\nGenerally speaking, matching the condition distributions shown in Theorem 3 does not guarantee to match the joint distributions (p = q). A simple counter example is when p(x) is fully factorized, p(x) = ∏ i pi(xi) and Ni = ∅, in which case matching the singleton marginals p(xi) = q(xi), i ∈ [d] does not imply p(x) = q(x) jointly since one can construct infinite many distributions with the same singleton marginals using the Copula method (Nelsen, 2007).\nTherefore, graphical SVGD can be viewed as a partial reconstruction of the target distribution p, which retains the local dependency structures while ignoring the long-range relations which are inherently difficult to infer due to the curse of high dimensionality. Focusing on the local dependency structures makes the problem easier and tractable, and also of practical interest since local marginals are often what we care in practice. Therefore, graphical SVGD can be viewed as an interesting hybrid of deterministic approximation (via the use of local kernels) and particle approximation (by approximating q with the empirical distributions of the particles)."
  }, {
    "heading": "4. Experimental Evaluation",
    "text": "We compare our method with a number of baselines, including the vanilla SVGD, particle message passing (PMP), and Langevin dynamics. Note that Langevin dynamics (without the Metropolis-Hasting (MH) rejection) can also be used in decentralized settings thanks to the factorization form of the gradient ∇x log p. However, algorithms with MH-rejection, including Metropolis-adjusted Langevin algorithm (MALA) and NUTS (Hoffman & Gelman, 2014), can not be easily performed distributedly because the MH-rejection step requires calculating a global probability ratio.\nWe evaluate the results on three sets of experiments, including a Gaussian MRFs toy example, a sensor localization example, and a crowdsourcing application with realworld datasets. We find our method significantly outperforms the baseline methods on high dimensional, sparse graphical models.\nFor all our experiments, we use Gaussian RBF kernel for both the vanilla and graphical SVGD and choose the bandwidth using the standard median trick. Specifically, for graphical SVGD, the kernel we use is ki(x, x′) := exp(−||xCi − x′Ci || 2 2/hi) with bandwidth hi = med 2 i where medi is the median of pairwise distances between {x`Ci} n `=1 for each node xi. We use AdaGrad (Duchi et al., 2011) for step size unless otherwise specified."
  }, {
    "heading": "4.1. Toy example on Gaussian MRFs",
    "text": "We set our target distribution to be the following pairwise Gaussian MRF: p(x) ∝ exp[ ∑n i=1(bixi− 1 2Aiix 2 i )−∑\n(i,j)∈E 1 2xiAijxj ], where E is the edge set of a Markov graph. The model parameters (A, b) are generated first with bi ∼ N (0, 1), and Aij ∼ uniform([−0.1, 0.1]), followed with A← (A+A>)/2 and Aii ← 0.1 + ∑ j 6=i |Aij |.\nFigure 2(a)-(c) shows the results when we take E to be a 4-neighborhood 2D grid of size 10 × 10, so that the overall variable dimension d equals 100. We compare our graphical SVGD (denoted by SVGD (graphical)) with a number of baselines, including the typical SVGD (denoted by SVGD (vanilla)), exact Monte Carlo sampling, and Langevin dynamics. The results are evaluated in three different metrics:\ni) Figure 2(a) shows the MSE for estimating the mean E[xi] of each node i, averaged across the dimensions. We see both the graphical and vanilla SVGD perform exceptionally well in estimating the means, which does not seem to suffer from the curse of dimensionality. Graphical SVGD does not show an advantage over vanilla SVGD for the mean estimation.\nii) Figure 2(b) shows the MSE for estimating the second\norder moment E[x2i ] of each node i, again averaged across the dimensions. In this case, graphical SVGD significantly outperforms vanilla SVGD.\niii) Figure 2(c) shows the maximum mean discrepancy (MMD) (Gretton et al., 2012) between the particles {x`} returned by different algorithms and the true distribution p, approximated by drawing a large sample from p. The kernel in MMD is taken to be the RBF kernel, with the bandwidth picked using the median trick. We find that vanilla SVGD does poorly in terms of MMD, while graphical SVGD gives the best MMD among all the methods. This is surprisingly interesting because graphical SVGD does not guarantee to match the joint distribution in theory.\nEffects of Graph Sparsity Figure 2(d) shows the results of graphical and vanilla SVGD as we add more edges into the graph. The graphs are constructed by putting 10 × 10 points uniformly on a 2D grid, and connecting all the points with distance no larger than r, with r varying in [1, . . . , 14]. The figure shows that the advantage of graphical SVGD compared to vanilla SVGD increases as the sparsity of the graph increases.\nWhat if we apply local kernels on dense graphs? Although our method requires that the local kernels are strictly positive definite on the Markov blanket of each node, an interesting question is what would happen if the\nlocal kernels are defined only on a subset of the Markov blanket, that is, when ki(x, x′) = ki(xDi , x ′ Di) where Di is a strict subset of Ci of p. To test this, we take p to be a fully connected Gaussian MRF with (A, b) generated in the same way as above, and test a variant of graphical SVGD, called SVGD (graphical+random), which uses local kernels ki(xDi , x ′ Di) where the domain Di is a neighborhood of size five, consisting of node xi and four neighbors randomly selected at each iteration. The results are shown in Figure 3, where we find that SVGD (graphical+random) still bring significant improvement over the vanilla SVGD in this case (see Figure 3(b)-(c)).\nIn Figure 3, we also tested SVGD (combine) whose kernel is ki(x, x′) = αki(xDi , x ′ Di) + (1− α)k(x, x\n′), which combines the local kernel ki(xDi , x ′ Di) with a global RBF kernel k(x, x′) (we take α = 0.5). Compared with SVGD (graphical+random), SVGD (combine) has the theoretical advantage that ki(x, x′) is strictly integrally positive definite and hence exactly matches the joint distribution p asymptotically. Empirically, we find that the performance of SVGD (combine) lies in between SVGD (graphical+random) and SVGD (vanilla) as shown in Figure 3."
  }, {
    "heading": "4.2. Sensor Network Localization",
    "text": "An important task in wireless sensor networks is to determine the location of each sensor given noisy measurements of pairwise distances (see, e.g., Ihler et al., 2005). We\nconsider a 2D sensor network with nodes consisting of a set S of d sensors placed on unknown locations {xi}i∈S , and a set A of m anchors with known locations {xi}i∈A where xi ∈ R2. For our experiments, we randomly generate the true sensor locations {x∗i }i∈S uniformly from interval [−1, 1]2. Assume the sensor-sensor(anchor) distances are measured with a Gaussian noise of variance σ: rij = ||xi − xj ||2 + σ ij where ij ∼ N (0, 1) and we set σ = 0.05. Assume only the pairwise distances smaller than 0.5 are measured, and denote the set of measured pairs by E . The posterior of the unknown sensor locations is\np(xS |xA, r) ∝ ∏\n(ij)∈E\nexp [ − 1 2σ2 (||xi − xj ||2 − rij)2 ] .\nParticle message passing (PMP) algorithms have been widely used for approximate inference of continuous graphical models, especially for sensor network location\n(Ihler et al., 2005; Ihler & McAllester, 2009). We compare with two recent versions of PMP methods, including T-PMP (Besse et al., 2014) and D-PMP (Pacheco et al., 2014). We use the settings suggested in Pacheco & Sudderth (2015), utilizing a combination of proposals with 75% neighbor-based proposals and 25% Gaussian random walk proposals in the augmentation step. The variance of Gaussian proposals is chosen to be 0.05, which is the best setting we found on a separate validation dataset simulated with the generative model that we assumed. We also select the best learning rate for Langevin, SVGD (vanilla) and SVGD(graphical) in the aforementioned validation dataset.\nFigure 4 reports the contours of 50 particles returned by different approaches on a small sensor network of size d = 9,m = 3, which includes three anchor points put on the corners. We observe that SVGD and Monte Carlo-type methods tend to capture multiple modes when the location information is ambiguous, while D-PMP and T-PMP obtain\nmore concentrated posteriors. For example, the locations of the sensors on A and B are far away from all the three anchor points with known locations and can not be accurately estimated. As a result, the posterior includes two modes A, A′ and B, B′, respectively. This is correctly identified by both SVGD (graphical), SVGD (vanilla), NUTS and Langevin, but not by D-PMP and T-PMP.\nWe then demonstrate the effectiveness of our approach on a larger sensor network of size d = 100. We place four anchor sensors at the four corners (±1,±1) (m = 4), In order to evaluate the methods quantitatively, Figure 5(a) shows the mean square error between true locations and the posterior mean estimated by the average of particles. (We find the posterior is essentially unimodal in this case, so posterior mean severs a reasonable estimation). Figure 5(b)(c) shows the approximate quantity of the posterior distribution, using a set of ground truth samples generated by NUTS (Hoffman & Gelman, 2014) with the true sensor positions as the initialization. We can see that graphical SVGD tends to outperform all the other baselines. It is interesting to see that Langevin dynamics performs significantly worse because it finds difficulty in converging well in this case (even if we searched the best step size extensively)."
  }, {
    "heading": "4.3. Application to Crowdsourcing",
    "text": "Crowdsourcing has been widely used in data-driven applications for collecting large amounts of labeled data. We apply our method to infer unknown continuous quantities from estimations given by the crowd workers.\nFollowing the setting in Liu et al. (2013) and Wang et al. (2016), we assume that there is a set of questions {i}, each of which is associated with an unknown continuous quantity xi that we want to estimate. We assume xi is generated from a Gaussian prior xi ∼ N (0, σ2x). Let {j} be a set of crowd workers that we hire to estimate {xi}, and rij the estimate of xi given by worker j. We assume the label rij is generated by a bias-variance Gaussian model:\nrij = xi + bj + √ νj ij , ij ∼ N (0, 1), (12)\nwhere bj and νj are the bias and variance of worker j, respectively, both of which are unknown with a prior of bj ∼ N (0, σ2b ) and an inverse Gamma prior p(νj) = Inv-Gamma(α, β) on νj . We are interested in evaluating the posterior estimation of {xi}, which can be done by sampling from the joint distribution p(x, b, ν | r). This is a non-Gaussian, highly skewed distribution because it involves the variance parameters vj .\nWe evaluate our approach on the PriceUCI dataset (Liu et al., 2013), which consists of 80 household items collected from the Internet, whose prices are estimated by 155 UCI undergraduate students. To construct an assignment graph for our experiments, we randomly assign 1-5 works to each question, and also ensure each worker is assigned to at least 3 questions. Because the bias bj would not be identifiable without any ground truth, we randomly select 10 questions as control questions with known answers, and infer the labels of the remaining 70 questions. The hyper-parameters in the priors are set to be σx = σb = 5, α = 3, β = 1. Results are averaged over 50 random trials.\nWe select the best learning rate for Langenvin, SVGD (vanilla) and our approach on a separate validation dataset generated with model (12). The inference is applied on model p(θ) with θ = [x, b, log(ν)], we clip the value of log(ν) to [−3, 3] to stablize the training. For evaluation, we generate a large set of samples for ground truth by running NUTS for a large number steps with the true task labels as initialization. As shown in figure 6, our graphical SVGD again outperforms both the typical SVGD and Langevin dynamics."
  }, {
    "heading": "5. Conclusion",
    "text": "In this paper, we propose a particle-based distributed inference algorithm for approximate inference on continuous graphical models based on Stein variational gradient descent (SVGD). Our approach leverages the inherent graphical structures to improve the performance in high dimensions, and also incorporates the key advantages of gradient optimization compared to traditional PMP methods."
  }, {
    "heading": "Acknowledgements",
    "text": "This work is supported in part by NSF CRII 1565796."
  }],
  "year": 2018,
  "references": [{
    "title": "PMBP: Patchmatch belief propagation for correspondence field estimation",
    "authors": ["F. Besse", "C. Rother", "A. Fitzgibbon", "J. Kautz"],
    "venue": "International Journal of Computer Vision,",
    "year": 2014
  }, {
    "title": "A kernel test of goodness of fit",
    "authors": ["K. Chwialkowski", "H. Strathmann", "A. Gretton"],
    "venue": "In Proceedings of the International Conference on Machine Learning (ICML),",
    "year": 2016
  }, {
    "title": "Adaptive subgradient methods for online learning and stochastic optimization",
    "authors": ["J. Duchi", "E. Hazan", "Y. Singer"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2011
  }, {
    "title": "Measuring sample quality with kernels",
    "authors": ["J. Gorham", "L. Mackey"],
    "venue": "Proceedings of the International Conference on Machine Learning (ICML),",
    "year": 2017
  }, {
    "title": "A kernel two-sample test",
    "authors": ["A. Gretton", "K.M. Borgwardt", "M.J. Rasch", "B. Schölkopf", "A. Smola"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "The no-U-turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo",
    "authors": ["M.D. Hoffman", "A. Gelman"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Particle belief propagation",
    "authors": ["A. Ihler", "D. McAllester"],
    "venue": "In Artificial Intelligence and Statistics,",
    "year": 2009
  }, {
    "title": "Nonparametric belief propagation for self-localization of sensor networks",
    "authors": ["A.T. Ihler", "J.W. Fisher", "R.L. Moses", "A.S. Willsky"],
    "venue": "IEEE Journal on Selected Areas in Communications,",
    "year": 2005
  }, {
    "title": "Stein variational gradient descent as gradient flow",
    "authors": ["Q. Liu"],
    "venue": "In Advances in neural information processing systems (NIPS),",
    "year": 2017
  }, {
    "title": "Stein variational gradient descent: A general purpose Bayesian inference algorithm",
    "authors": ["Q. Liu", "D. Wang"],
    "venue": "In Advances In Neural Information Processing Systems (NIPS),",
    "year": 2016
  }, {
    "title": "Scoring workers in crowdsourcing: How many control questions are enough",
    "authors": ["Q. Liu", "A.T. Ihler", "M. Steyvers"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS),",
    "year": 1914
  }, {
    "title": "A kernelized Stein discrepancy for goodness-of-fit tests",
    "authors": ["Q. Liu", "J.D. Lee", "M.I. Jordan"],
    "venue": "In Proceedings of the International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "An introduction to copulas",
    "authors": ["R.B. Nelsen"],
    "venue": "Springer Science & Business Media,",
    "year": 2007
  }, {
    "title": "Convergence rates for a class of estimators based on Stein’s identity",
    "authors": ["C.J. Oates", "J. Cockayne", "Briol", "F.-X", "M. Girolami"],
    "venue": "arXiv preprint arXiv:1603.03220,",
    "year": 2016
  }, {
    "title": "Proteins, particles, and pseudo-max-marginals: A submodular approach",
    "authors": ["J. Pacheco", "E. Sudderth"],
    "venue": "In International Conference on Machine Learning (ICML),",
    "year": 2015
  }, {
    "title": "Preserving modes and messages via diverse particle selection",
    "authors": ["J. Pacheco", "S. Zuffi", "M. Black", "E. Sudderth"],
    "venue": "In Proceedings of the 31st International Conference on Machine Learning (ICML),",
    "year": 2014
  }, {
    "title": "Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference",
    "authors": ["J. Pearl"],
    "year": 1988
  }, {
    "title": "Kernel belief propagation",
    "authors": ["L. Song", "A. Gretton", "D. Bickson", "Y. Low", "C. Guestrin"],
    "venue": "In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2011
  }, {
    "title": "Nonparametric belief propagation",
    "authors": ["E.B. Sudderth", "A.T. Ihler", "M. Isard", "W.T. Freeman", "A.S. Willsky"],
    "venue": "Communications of the ACM,",
    "year": 2010
  }, {
    "title": "Graphical models, exponential families, and variational inference",
    "authors": ["M. Wainwright", "M. Jordan"],
    "venue": "Found. Trends Mach. Learn.,",
    "year": 2008
  }, {
    "title": "Efficient observation selection in probabilistic graphical models using Bayesian lower bounds",
    "authors": ["D. Wang", "J.W. Fisher III", "Q. Liu"],
    "venue": "In Proceedings of the Conference on Uncertainty in Artificial Intelligence,",
    "year": 2016
  }, {
    "title": "Understanding belief propagation and its generalizations",
    "authors": ["J.S. Yedidia", "W.T. Freeman", "Y. Weiss"],
    "venue": "Exploring artificial intelligence in the new millennium,",
    "year": 2003
  }, {
    "title": "Message passing Stein variational gradient descent",
    "authors": ["J. Zhuo", "C. Liu", "J. Shi", "J. Zhu", "N. Chen", "B. Zhang"],
    "venue": "arXiv preprint arXiv:1711.04425v2,",
    "year": 2018
  }],
  "id": "SP:9e5a34449da2e0312d95008f006e9ab6fb83c761",
  "authors": [{
    "name": "Dilin Wang",
    "affiliations": []
  }, {
    "name": "Zhe Zeng",
    "affiliations": []
  }, {
    "name": "Qiang Liu",
    "affiliations": []
  }],
  "abstractText": "We propose a novel distributed inference algorithm for continuous graphical models, by extending Stein variational gradient descent (SVGD) (Liu & Wang, 2016) to leverage the Markov dependency structure of the distribution of interest. Our approach combines SVGD with a set of structured local kernel functions defined on the Markov blanket of each node, which alleviates the curse of high dimensionality and simultaneously yields a distributed algorithm for decentralized inference tasks. We justify our method with theoretical analysis and show that the use of local kernels can be viewed as a new type of localized approximation that matches the target distribution on the conditional distributions of each node over its Markov blanket. Our empirical results show that our method outperforms a variety of baselines including standard MCMC and particle message passing methods.",
  "title": "Stein Variational Message Passing for Continuous Graphical Models"
}