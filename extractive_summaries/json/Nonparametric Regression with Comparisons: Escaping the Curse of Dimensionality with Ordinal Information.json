{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Classical nonparametric regression is centered around the development and analysis of methods that use labeled observations, {(X1, y1), . . . , (Xn, yn)}, where (Xi, yi) ∈\n1Machine Learning Department, Carnegie Mellon University, Pittsburgh, USA 2Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, USA 3Auton Lab, Carnegie Mellon University, Pittsburgh, USA. Correspondence to: Yichong Xu <yichongx@cs.cmu.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nRd × R, in various tasks of estimation and inference. Nonparametric methods are appealing in practice owing to their flexibility, and the relatively weak a-priori structural assumptions that they impose on the unknown regression function. However, the price we pay is that nonparametric methods typically require a large amount of labeled data, scaling exponentially with the dimension, to estimate complex target functions – the so-called curse of dimensionality. This has motivated research on structural constraints – for instance, sparsity or manifold constraints – as well as research on active learning and semi-supervised learning where labeled samples are used judiciously. We consider a complementary approach, motivated by applications in material science, crowdsourcing, and healthcare, where we are able to supplement a small labeled dataset with a potentially larger dataset of ordinal information. Such ordinal information is obtained either in the form of a (noisy) ranking of unlabeled points or in the form of (noisy) pairwise comparisons between function values at unlabeled points.\nIn crowdsourcing we rely on human labeling effort, and in many cases humans are able to provide more accurate ordinal feedback with substantially less effort (see for instance (Tsukida & Gupta, 2011; Shah et al., 2015)). We investigate a task of this flavor in Section 6. In material synthesis the broad goal is to design complex new materials and machine learning approaches are gaining popularity (Xue et al., 2016; Faber et al., 2016). Typically given a setting of input parameters (temperature, pressure etc.) we are able to perform a synthesis experiment and measure the quality of resulting synthesized material. Understanding this quality landscape is essentially a task of high-dimensional function estimation. Synthesis experiments can be costly and material scientists when presented with pairs of input parameters are often able to cheaply provide noisy comparative assessments of synthesis quality. Similarly, in clinical settings, precise assessment of an individual patient’s health readings can be difficult, expensive and/or risky, but comparing the relative status of two patients may be relatively easy and accurate. In each of these settings, it is important to develop methods for function estimation that combine standard supervision with (potentially) cheaper and abundant ordinal or comparative supervision.\nRelated Work: There is considerable work in supervised and unsupervised learning on incorporating additional types of feedback beyond labels. For instance, the papers (Zou et al., 2015) and (Poulis & Dasgupta, 2017) study the benefits of different types “feature feedback” in clustering and supervised learning respectively. There is also a vast literature on models and methods for analyzing pairwise comparison data, like the classical Bradley-Terry (Bradley & Terry, 1952) and Thurstone (Thurstone, 1927) models. In this literature, the typical focus is on ranking or quality estimation for a fixed set of objects. In contrast, we focus on function estimation and the resulting models and methods are quite different. We build on work on “noisy sorting” (Braverman & Mossel, 2009) to extract a consensus ranking from noisy pairwise comparisons. Most close in spirit to our own work are the two recent papers (Kane et al., 2017; Xu et al., 2017), which consider binary classification with ordinal information. These works differ from ours in their focus on classification, emphasis on active querying strategies and use of quite different ordinal feedback models. Finally, given ordinal information of sufficient fidelity, the problem of nonparametric regression is related to the problem of regression with shape constraints, or more specifically isotonic regression (Barlow, 1972; Zhang, 2002). Accordingly, we leverage algorithms from this literature in our work and we comment further on the connections in Section 3. Some salient differences between this literature and our work are that we design methods that work in a semisupervised setting, and further that our target is an unknown d-dimensional (smooth) regression function as opposed to a univariate shape-constrained function.\nOur Contributions: We develop the Ranking-Regression (R2) algorithm for nonparametric regression that can leverage ordinal information, in addition to direct labels. Theoretical analysis and practical experiments show the strength of our algorithm.\n• To establish the usefulness of ordinal information in nonparametric regression, in Section 3 we consider the idealized setting where we obtain a perfect ordering of the unlabeled set. We show that the Mean Squared Error (MSE) of R2 can be bounded by Õ(m−2/3 + n−2/d)1, where m denotes the number of labeled samples and n the number of ranked samples. To achieve an MSE of ε, the number of labeled samples required by R2 is independent of dimension. This result establishes that sufficient ordinal information of high quality can allow us to effectively circumvent the curse of dimensionality.\n• In Section 4 we analyze R2 when using a noisy ranking. We show that the MSE is bounded as Õ(m−2/3 + √ ν+\n1We use the standard big-O notation throughout this paper, and use Õ when we suppress log-factors.\nn−2/d), where ν is the Kendall-Tau distance between the true and noisy ranking.\n• As a corollary, we develop results for R2 using pairwise comparisons. If the comparison noise is bounded, the R2 algorithm can be combined with algorithms for ranking from pairwise comparisons (Braverman & Mossel, 2009) to obtain an MSE of Õ(m−2/3 +n−2/d) when d ≥ 4. • We give information-theoretic lower bounds to char-\nacterize the fundamental limits of combining ordinal and standard supervision. These lower bounds show that our algorithms are almost optimal. In particular, the R2 algorithm under perfect ranking, as well as under bounded noise comparisons, is optimal up to log factors.\n• In our experiments, we test R2 on simulated data, on UCI datasets and on various age-estimation tasks. Our experimental results show the advantage of R2 over algorithms that only use labeled data when this labeled data is scarce. Our experiments with the age-estimation data also show the practicality of R2."
  }, {
    "heading": "2. Background and Problem Setup",
    "text": "We consider a non-parametric regression model with random design, i.e. we suppose first that we are given access to an unlabeled set U = {X1, . . . , Xn}, where Xi ∈ X ⊂ [0, 1]d, and Xi are drawn i.i.d. from a distribution PX . We assume that PX has a density p(x) which is upper and lower bounded as 0 < pmin ≤ p(x) ≤ pmax for x ∈ [0, 1]d. Our goal is to estimate a function f : X 7→ R, where following classical work (Györfi et al., 2006; Tsybakov, 2009) we assume that f is bounded in [−M,M ] and belongs to a Hölder ball Fs,L, with 0 < s ≤ 1 where:\nFs,L = {f : |f(x)− f(y)| ≤ L‖x− y‖s2,∀ x, y ∈ X} .\nFor s = 1 this is the class of Lipschitz functions. We discuss the estimation of smoother functions (i.e. the case when s > 1) in Section 7. We obtain two forms of supervision:\n1. Classical supervision: For a (uniformly) randomly chosen subset L ⊆ U of sizem (we assume throughout that m ≤ n and focus on settings where m n) we make noisy observations of the form:\nyi = f(Xi) + i, i ∈ L,\nwhere i are i.i.d. E[ i] = 0,Var[ i] = σ2. We denote the indices of the labeled samples as {t1, . . . , tm} ⊂ {1, . . . , n}.\n2. Ordinal supervision: For the given dataset {X1, . . . , Xn} we let π denote the true ordering, i.e. π is a permutation of {1, . . . , n} such that for i, j ∈ {1, . . . , n}, with π(i) ≤ π(j) we have that f(Xi) ≤ f(Xj). We assume access to one of the following types of ordinal supervision:\n(1) We are given access to a noisy ranking π̂, i.e. for a parameter ν ∈ [0, 1] we assume that the KendallTau distance between π̂ and the true-ordering is upperbounded as:∑ i,j∈[n] I[(π(i)− π(j))(π̂(i)− π̂(j)) < 0] ≤ νn2.\n(1)\n(2) For each pair of samples (Xi, Xj), with i < j we obtain a comparison Zij where for some constant λ > 0:\nP(Zij = I(f(Xi) > f(Xj))) ≥ 1\n2 + λ. (2)\nAs we discuss in Section 5 it is straightforward to extend our results to a setting where only a randomly chosen subset of all pairwise comparisons are observed.\nAlthough classical supervised learning estimates a regression function with labels only and without ordinal supervision, we note that we cannot consistently estimate the underlying function with only ordinal supervision and without direct observations. In the case when no direct measurements are available the underlying function is only identifiable up to certain monotonic transformations.\nOur goal is to estimate f , and the quality of an estimate f̂ is assessed using the mean squared error E(f̂(X)− f(X))2, where the expectation is taken over the labeled and unlabeled training samples, as well as the new test point X . We also study the fundamental information-theoretic limits of estimation with classical and ordinal supervision by establishing lower (and upper) bounds on the minimax risk. Letting η denote various problem dependent parameters (the Hölder parameters s, L and various noise parameters), the minimax risk:\nM(m,n; η) = inf f̂ sup f∈Fs,L\nE(f̂(X)− f(X))2, (3)\nprovides an information-theoretic benchmark to assess the performance of an estimator. We conclude this section recalling a well-known fact: given access to only classical supervision the minimax risk M(m; η) = Θ(m− 2s 2s+d ), suffers from an exponential curse of dimensionality."
  }, {
    "heading": "3. Nonparametric Regression with Perfect",
    "text": "Ranking\nTo establish the value of ordinal information we first consider an idealized setting, where we are given a perfect ranking π of the unlabeled samples in U . We present our Ranking-Regression (R2) algorithm with performance guarantees in Section 3.1, and a lower bound in Section 3.2 which shows that R2 is optimal up to log factors.\nAlgorithm 1 R2: Ranking-Regression Input: Unlabeled data U = {X1, ..., Xn}, a labeled set\nof size m and corresponding labels, i.e. samples {(Xt1 , yt1), . . . , (Xtm , ytm)}, and a ranking π̂. 1: Order elements in U as (Xπ̂(1), ..., Xπ̂(n)). 2: Run isotonic regression (see (4)) on {yt1 , . . . , ytm}. De-\nnote the estimated values by {ŷt1 , . . . , ŷtm}. 3: For i = 1, 2, ..., n, let ĩ = tk, where π̂(tk) is the largest\nvalue such that π̂(tk) ≤ π̂(i), k = 0, 1, ...,m, and ĩ = ? if no such tk exists. Set\nŷi = { ŷ̃i if ĩ 6= ? 0 otherwise.\nOutput: Function f̂ = NearestNeighbor({(Xi, ŷi)}ni=1)."
  }, {
    "heading": "3.1. Upper bounds for the R2 Algorithm",
    "text": "Our non-parametric regression estimator is described in Algorithm 1 and Figure 1. We first rank all the samples in U according to the (given or estimated) permutation π̂. We then run isotonic regression (Barlow, 1972) on the labeled samples in L to de-noise them and borrow statistical strength. In more detail, we solve the following program to de-noise the labeled samples:\nmin {ŷπ̂(t1),...,ŷπ̂(tm)} m∑ k=1 (ŷπ̂(tk) − yπ̂(tk)) 2\ns.t. ŷtk ≤ ŷtl ∀ (k, l) such that π̂(tk) < π̂(tl) −M ≤ {yπ̂(t1), . . . , yπ̂(tm)} ≤M.\n(4)\nWe introduce the bounds {M,−M} in the above program to ease our analysis. In our experiments, we simply set M to be a large positive value so that it has no influence on our estimator. We then leverage the ordinal information in π̂ to impute regression estimates for the unlabeled samples in U , by assigning each unlabeled sample the value of the nearest (de-noised) labeled sample which has a smaller function value according to π̂. Finally, for a new test point, we use the imputed (or estimated) function value of the nearest neighbor in U .\nIn the setting where we use a perfect ranking the following theorem characterizes the performance of R2:\nTheorem 1. For constants C1, C2 > 0 the MSE of f̂ is bounded by\nE(f̂(X)− f(X))2 ≤ C1m−2/3 log2 n logm+ C2n−2s/d.\nBefore we turn our attention to the proof of this result, we examine some consequences. Remarks: (1) Theorem 1 shows a surprising dependency on the sizes of the labeled and unlabeled sets (m and n).\nThe MSE of nonparametric regression using only the labeled samples is Θ(m− 2s 2s+d ) which is exponential in d and makes non-parametric regression impractical in highdimensions. Focusing on the dependence on m, Theorem 1 improves the rate to m−2/3polylog(m,n), which is no longer exponential in d. By using enough ordinal information we can avoid the curse of dimensionality. (2) On the other hand, the dependence on n (which dictates the amount of ordinal information needed) is still exponential. This illustrates that ordinal information is most beneficial when it is copious. We show in Section 3.2 that this is unimprovable in an information-theoretic sense. (3) Somewhat surprisingly, we also observe that the dependence on n is faster than the n− 2s 2s+d rate that would be obtained if all the samples were labeled. (4) In the case where all points are labeled (i.e., m = n), the MSE is of order n−2/3 + n−2s/d, again improving slightly on the rate when no ordinal information is available. The improvement is largest when m n. (5) Finally, we also note in passing that the above theorem provides an upper bound on the minimax risk in (3).\nProof Sketch. We provide a brief outline and defer technical details to the Supplementary Material. For a randomly drawn point X ∈ X , we denote by Xα the nearest neighbor of X in U . We decompose the MSE as\nE [ (f̂(X)− f(X))2 ] ≤2E [ (f̂(X)− f(Xα))2 ] +\n2E [ (f(Xα)− f(X))2 ] . (5)\nThe second term corresponds roughly to the finite-sample bias induced by the discrepancy between the function value at X and the closest labeled sample. We use standard sample-spacing arguments (see (Györfi et al., 2006)) to\nbound this term. This term contributes the n−2s/d rate to the final result. For the first term, we show a technical result in the Appendix (Lemma 9). Without loss of generality suppose f ( Xt1 ) ≤ · · · f ( Xtm ) . By conditioning on a probable configuration of the points and enumerating over choices of the nearest neighbor we find that roughly (see Lemma 9 for a precise statement):\nE [ (f̂(X)− f(Xα))2 ] ≤ ( log2 n logm\nm\n) ×\nE ( m∑ k=1 (( f̂(Xtk)− f(Xtk) )2 + ( f ( Xtk+1 ) − f ( Xtk ))2)) .\n(6)\nIntuitively, these terms are related to the estimation error arising in isotonic regression (first term) and a term that captures the variance of the function values (second term). When the function f is bounded, we show that the dominant term is the isotonic estimation error which is on the order of m−2/3. Putting these pieces together we obtain the theorem."
  }, {
    "heading": "3.2. Lower bounds with Ordinal Data",
    "text": "To understand the fundamental limits on the usefulness of ordinal information, as well as to study the optimality of the R2 algorithm we now turn our attention to establishing lower bounds on the minimax risk. In our lower bounds we choose PX to be uniform on [0, 1]d. Our estimators f̂ are functions of the labeled samples: {(Xt1 , yt1), . . . , (Xtm , ytm)}, the set U = {X1, . . . , Xn} and the true ranking π. We have the following result:\nTheorem 2. For any estimator f̂ we have that for a universal constant C > 0,\ninf f̂ sup f∈Fs,L\nE [ (f(X)− f̂(X))2 ] ≥ C(m−2/3 + n−2s/d).\nComparing with the result in Theorem 1 we conclude that the R2 algorithm is optimal up to log factors, when the ranking is noiseless.\nProof Sketch. We establish each term in the lower bound separately. Intuitively, for the n−2s/d lower bound we consider the case when all the n points are labeled perfectly (in which case the ranking is redundant) and show that even in this setting the MSE of any estimator is at least n−2s/d due to the finite resolution of the sample.\nTo prove the m−2/3 lower bound we construct a novel packing set of functions in the class Fs,L, and use informationtheoretic techniques (Fano’s inequality) to establish the lower bound. The functions we construct are all increasing functions, and as a result the ranking π provides no additional information for these functions easing the analysis. Figure 2 contrasts the classical construction for lower\nbounds in non-parametric regression (where tiny bumps are introduced to a reference function) with our construction where we additionally ensure the perturbed functions are all increasing. To complete the proof, we provide bounds on the cardinality of the packing set we create, as well as bounds on the Kullback-Leibler divergence between the induced distributions on the labeled samples. We provide the technical details in the Appendix."
  }, {
    "heading": "4. Nonparametric Regression using Noisy",
    "text": "Ranking\nIn this section, we study the setting where the ordinal information is noisy. We focus here on the setting where as in Equation (1) we obtain a ranking π̂ whose Kendall-Tau distance from the true ranking π is at most νn2. We show that the R2 algorithm is quite robust to ranking errors and achieves an MSE of Õ(m−2/3+ √ ν+n−2s/d). We establish a complementary lower bound of Õ(m−2/3 + ν2 +n−2s/d) in Section 4.2."
  }, {
    "heading": "4.1. Upper Bounds for the R2 Algorithm",
    "text": "We characterize the robustness of R2 to ranking errors, i.e. when π̂ satisfies the condition in (1), in the following theorem:\nTheorem 3. For constants C1, C2 > 0, the MSE of the R2 estimate f̂ is bounded by\nE[(f̂(X)− f(X))2] ≤ C1 ( log2 n logm ( m−2/3 + √ ν )) + C2n −2s/d.\nRemarks: (1) Once again we observe that in the regime where sufficient ordinal information is available, i.e. n is large, the rate no longer has an exponential dependence on the dimension d.\n(2) This result also shows that the R2 algorithm is inherently robust to noise in the ranking, and the mean squared error degrades gracefully as a function of the noise parameter ν. We investigate the optimality of the √ ν-dependence in the next section. (3) Finally, in settings where ν is large R2 can be led astray by the ordinal information, and a standard non-parametric regressor can achieve the (possibly faster) O ( m− 2s 2s+d ) rate by ignoring the ordinal information. As we show in Appendix E a simple cross-validation procedure can combine the benefits of the two estimators to achieve a rate of Õ ( m−2/3 + min{ √ ν,m− 2s 2s+d } + n−2s/d ) . This rate can converge to 0 if we have sufficiently many labels, even if the comparisons are very noisy. The cross validation process is standard and computationally efficient: we estimate the regression function twice, once using R2 and once using k-nearest neighbors, and choose the regression function that performs better on a held-out validation set.\nWe now turn our attention to the proof of this result.\nProof Sketch. When using an estimated permutation π̂ the true function of interest f is no longer an increasing (isotonic) function with respect to π̂, and this results in a modelmisspecification bias. The core technical novelty of our proof is in relating the upper bound on the error in π̂ to an upper bound on this bias. Concretely, in the Appendix we show the following lemma:\nLemma 4. For any permutation π̂ satisfying the condition in (1)\nn∑ i=1 (f(Xπ−1(i))− f(Xπ̂−1(i)))2 ≤ 8M2 √ 2νn.\nUsing this result we bound the minimal error of approximating an increasing sequence according to π by an increasing sequence according to the estimated ranking π̂. We denote this error by ∆, and using Lemma 4 we show that in expectation (over the random choice of the labeled set)\nE[∆] ≤ 8M2 √ 2νm.\nWith this technical result in place we follow the same decomposition and subsequent steps before we arrive at the expression in Equation (6). In this case, the first term for some constant C > 0 is bounded as:\nE ( m∑ k=1 ( f̂(Xtk)− f(Xtk) )2) ≤ 2E[∆] + Cm1/3, where the first term corresponds to the modelmisspecification bias and the second corresponds to the usual isotonic regression rate. Putting these terms together in the decomposition in Equation (6) we obtain the theorem."
  }, {
    "heading": "4.2. Lower bounds with Noisy Ordinal Data",
    "text": "In this section we turn our attention to lower bounds in the setting with noisy ordinal information. In particular, we construct a permutation π̂ such that for a pair (Xi, Xj) of points randomly chosen from PX :\nP[(π(i)− π(j))(π̂(i)− π̂(j)) < 0] ≤ ν.\nWe analyze the minimax risk of an estimator which has access to this noisy permutation π̂, in addition to the labeled and unlabeled sets (as in Section 3.2). Theorem 5. There is a constant C > 0 such that for any estimator f̂ taking input X1, ..., Xn, y1, ..., ym and π̂,\ninf f̂ sup f∈Fs,L\nE ( f(X)− f̂(X) )2 ≥ C(m− 2 3 + min{ν2,m− 2 d+2 }+ n−2s/d).\nComparing this result with our result in Remark 3 following Theorem 3, our upper and lower bounds differ by the gap between √ ν and ν2, in the case of Lipschitz functions (s = 1).\nProof Sketch. We focus on the dependence on ν, as the other parts are identical to Theorem 2. We construct a packing set of Lipschitz functions, and we subsequently construct a noisy comparison oracle π̂ which provides no additional information beyond the labeled samples. The construction of our packing set is inspired by the construction of standard lower bounds in non-parametric regression (see Figure 2), but we modify this construction to ensure that π̂ is uninformative. In the classical construction we divide [0, 1]d into ud grid points, with u = m1/(d+2) and add a “bump” at a carefully chosen subset of the grid points. Here we instead divide [0, t]d into a grid with ud points, and add an increasing function along the first dimension, where t is a parameter we choose in the sequel.\nWe now describe the ranking oracle which generates the permutation π̂: we simply rank sample points according to their first coordinate. This comparison oracle only makes an error when both x, x′ lies in [0, t]d, and both x1, x′1 lie in the same grid segment [tk/u, t(k + 1)/u] for some k ∈ [u]. So the Kendall-Tau error of the comparison oracle is (td)2 × ((1/u)2 × u) = ut2d. We choose t such that this value is less than ν. Once again we complete the proof by lower bounding the cardinality of the packing-set for our stated choice of t, upper bounding the Kullback-Leibler divergence between the induced distributions and appealing to Fano’s inequality."
  }, {
    "heading": "5. Regression with Noisy Pairwise Comparisons",
    "text": "In this section we focus on the setting where the ordinal information is obtained in the form of noisy pairwise com-\nparisons, following Equation (2). We investigate a natural strategy of aggregating the pairwise comparisons to form a consensus ranking π̂ and then applying the R2 algorithm with this estimated ranking. We build on results from theoretical computer science, where such aggregation algorithms are studied for their connections to sorting with noisy comparators. In particular, Braverman & Mossel (2009) study noisy sorting algorithms under the noise model described in (2) and establish the following result:\nTheorem 6 ((Braverman & Mossel, 2009)). Let α > 0. There exists a polynomial-time algorithm using noisy pairwise comparisons between n samples, that with probability 1 − n−α, returns a ranking π̂ such that for a constant c(α, λ) > 0 we have that:∑ i,j∈[n] I[(π(i)− π(j))(π̂(i)− π̂(j)) < 0] ≤ c(α, λ)n.\nFurthermore, if allowed a sequential (active) choice of comparisons, the algorithm queries at most O(n log n) pairs of samples.\nCombining this result with our result on the robustness of R2 we obtain an algorithm for nonparametric regression with access to noisy pairwise comparisons with the following guarantee on its performance:\nCorollary 7. For constants C1, C2 > 0, R2 with π̂ estimated as described above produces an estimator f̂ with MSE\nE ( f̂(X)− f(X) )2 ≤ C1m−2/3 log2 n logm+ C2 max{n−2s/d, n−1/2 log2 n logm}.\nRemarks: (1) From a technical standpoint this result is an immediate corollary of Theorems 3 and 6, but the extension is important from a practical standpoint. The ranking error of O(1/n) from the noisy sorting algorithm leads to an additional Õ(1/ √ n) term in the MSE. This error is dominated by the n−2s/d term if d ≥ 4s, and in this setting the result in Theorem 7 is also optimal up to log factors (following the lower bound in Section 3.2).\n(2) We also note that the analysis in (Braverman & Mossel, 2009) extends in a straightforward way to a setting where only a randomly chosen subset of the pairwise comparisons are obtained."
  }, {
    "heading": "6. Experiments & Simulations",
    "text": "To verify our theoretical results and test R2 in practice, we perform three sets of experiments. First, we conduct experiments on simulated data, where the noise in the labels and ranking can be controlled separately. Second, we test R2 on UCI datasets, where the rankings are simulated using labels. We present these results in Appendix A. Finally, we\nconsider a practical application of predicting people’s age from portraits and we test R2 on two realistic estimation tasks.\nWe compare R2 with k-NN algorithms in all experiments. We choose k-NN methods because they are near-optimal theoretically, and are widely used in practice. Theoretical guidelines suggest using the tuning parameter km = m 2 d+2 when we have access to m labeled samples; however for all m, d values we considered, m 2 d+2 is very small (< 5). Instead we choose a range of different constant values of k (that do not change with m) in our experiments. We repeat each experiment 20 times and report the average MSE2."
  }, {
    "heading": "6.1. Simulated Data",
    "text": "Data Generation. We generate simulated data following Härdle et al. (2012). Let d = 8, and sample X uniformly random from [0, 1]d. Our target function is f(x) = ∑d i=1 f\n(d mod 4)(xd), where xd is x’s d-th dimension, and\nf (1)(x) = px− 1/2, f (2)(x) = px3 − 1/3, f (3)(x) = −2 sin(−px), f (4)(x) = e−px + e−1 − 1\nwith p sampled uniformly random in [0, 10]. We rescale f(x) so that it has 0 mean and unit variance. The labels are generated as y = f(x)+εwhere ε ∼ N (0, 0.52). We generate a training and a test set of n = 1000 samples respectively. At test time, we compute the MSE 1n ∑n i=1(f(X test i ) − f̂(X testi )) 2 for all test data X test1 , ..., X test n .\nVariants of R2. We consider two variants of R2. The first variant is exactly Algorithm 1 using 1-NN as the final estimator; the second variant uses 5-NN as the final estimator. Using 5-NN does not change the asymptotic behavior of our bounds. However, we find that using 5-NN improves our estimator empirically.\nBaselines. We compare R2 with the following baselines: i) 1-NN and 5-NN using noisy labels (x, y). Since R2 uses\n2Our plots are best viewed in color.\nordinal data in addition to labels, it should have lower MSE than 1-NN and 5-NN. ii) 1-NN and 5-NN using perfect labels (x, f(x)). Since these algorithms use perfect labels, when m = n they serve as a benchmark for our algorithms.\nR2 with perfect rankings. In our first experiment, R2 had access to the ranking over all 1000 training samples, while the k-NN baseline algorithms only had access to labeled samples. We varied the number of labeled samples for all algorithms from m = 5 to m = 1000. The results are depicted in Figure 3(a). R2 1-NN and R2 5-NN exhibited better performance than their counterparts using only labels, whether using noisy or perfect labels; in fact, R2 1-NN and R2 5-NN performed nearly the same as 1-NN or 5-NN using all 1000 perfect labels, while only requiring around 50 labeled samples.\nR2 with noisy rankings. We then consider noisy rankings; particularly in Figure 3(b), the input ranking of R2 is obtained from noisy labels. This eliminates the need for isotonic regression in Algorithm 1, but we find that the ranking still provides useful information for the unlabeled samples. In this setting R2 outperformed the 1-NN and 5-NN counterparts using noisy labels. However, R2 was outperformed by algorithms using perfect labels when n = m. As expected, R2 and k-NN with noisy labels achieved identical MSE when n = m.\nEffect of ranking noise. We also consider the effect of ranking noise in Figure 3(c). We fixed the number of labeled/ranked samples to 100/1000, and varied the noise level of ranking. For noise level σ, the ranking is generated from\ny′ = f(x) + ε′\nwhere ε′ ∼ N (0, σ2). We varied σ from 0 to 5 and plotted the MSE. As σ goes up, the error of both variants of the R2 algorithm increases as expected."
  }, {
    "heading": "6.2. Predicting Ages from Portraits",
    "text": "To further validate R2 in practice, we consider the task of estimating people’s age from portraits. We use the APPA-\nREAL dataset (E Agustsson, 2017), which contains 7,591 images, where each image is associated a biological age and an apparent age. The biological age is the person’s actual age, whereas the apparent ages are collected by crowdsourcing. Estimates from (on average 38 different) labelers are averaged to obtain the apparent age. APPA-REAL also provides the standard deviation of the apparent age estimates. The images are divided into 4113 train, 1500 validation and 1978 test samples, and we only use the train and validation samples for our experiments.\nFeatures and Models. We extract the 128-dim feature for each image using the last layer of FaceNet (Schroff et al., 2015). We rescale the features so that everyX ∈ [0, 1]d. We use 5-NN and 10-NN in this experiment. To further show the effectiveness of R2, we also compare to kernelized support vector regression (SVR). We used the standard parameter configuration in scikit-learn (Pedregosa et al., 2011), using penalty parameter C = 1, RBF kernel, and tolerance of 0.1.\nTasks. We considered two tasks, motivated by real-world applications.\n1. In the first task, the goal is to predict biological age. The labels were biological age, whereas the ranking came from apparent ages. This is motivated by the collection process of most modern datasets where typically, an aggregated (de-noised) label is obtained through majority vote. For example, we may have the truthful biological age for a fraction of samples, but wish to collect more through crowdsourcing. In crowdsourcing, people give comparisons based on appar-\nent age instead of biological age. So we assume additional access to a ranking that comes from apparent ages.\n2. In the second task, the goal is to predict the apparent age. Both labels and ranking were generated using the standard deviation provided in APPA-REAL. Labels were generated according to a Gaussian distribution with mean equal to the apparent age, and standard deviation provided in the dataset. The ranking was generated by first generating a sample of all labels using the same distribution, and ranking according to the sample. This resembles the case where we ask one single labeler for each label and comparison, to collect data for more samples. Such policy is also used in e.g., (Bi et al., 2014; Khetan et al., 2017). Note that in real applications, the ranking will have less noise than in our experiment; (Shah et al., 2015) considered exactly the same task, and showed that comparisons are more reliable than labels.\nResults are depicted in Figure 4. The 10-NN version of R2 gave the best overall performance in both tasks. R2 5-NN and R2 10-NN both outperformed other algorithms when the number of labeled samples was less than 500. The performance of SVR was between 5-NN and 10-NN in our experiments. Interestingly, we observe that there is a gap between R2 and its nearest neighbor counterparts even when n = m, i.e. the ordinal information continues to be useful even when all samples are labeled, indicating the high reliability of the ordinal information for this task."
  }, {
    "heading": "7. Discussion and Conclusion",
    "text": "We design minimax-optimal algorithms for nonparametric regression using additional ordinal information. In settings where large amounts of ordinal information are available, we find that limited direct supervision suffices to obtain accurate estimates. We provide complementary minimax lower bounds, and illustrate our proposed algorithm on real and simulated datasets. Since ordinal information is typically easier to obtain than direct labels, one might expect in these favorable settings the R2 algorithm to have lower effective cost than an algorithm based purely on direct supervision.\nIn future work motivated by practical applications in crowdsourcing, we hope to address the setting where both direct and ordinal supervision are actively acquired. Another possible direction is to consider partial orders, where we have several subsets of unlabeled data ranked, but the relation between these subsets is unknown. It would also be interesting to consider other models for ordinal information and to more broadly understand settings where indirect feedback is beneficial. Also, several recent papers (Bellec & Tsybakov, 2015; Bellec, 2018; Han et al., 2017) demonstrate the adaptivity (to complexity of the unknown parameter) of the MLE in shape-constrained problems. Understanding precise assumptions on the underlying smooth function which would induce a low-complexity isotonic regression problem is an interesting avenue for future work."
  }, {
    "heading": "Acknowledgements",
    "text": "This work is supported by AFRL grant FA8750-17-2-0212, NSF CCF-1763734, NSF DMS-1713003 and DARPA award FA8750-17-2-0130."
  }],
  "year": 2018,
  "references": [{
    "title": "Statistical inference under order restrictions: The theory and application of isotonic regression",
    "authors": ["R.E. Barlow"],
    "venue": "Technical report,",
    "year": 1972
  }, {
    "title": "Sharp oracle inequalities for least squares estimators in shape restricted regression",
    "authors": ["P.C. Bellec"],
    "venue": "The Annals of Statistics,",
    "year": 2018
  }, {
    "title": "Sharp oracle bounds for monotone and convex regression through aggregation",
    "authors": ["P.C. Bellec", "A.B. Tsybakov"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2015
  }, {
    "title": "Learning to predict from crowdsourced data",
    "authors": ["W. Bi", "L. Wang", "J.T. Kwok", "Z. Tu"],
    "venue": "In Uncertainty in Artificial Intelligence,",
    "year": 2014
  }, {
    "title": "Rank analysis of incomplete block designs: I. the method of paired comparisons",
    "authors": ["R.A. Bradley", "M.E. Terry"],
    "year": 1952
  }, {
    "title": "Sorting from noisy information",
    "authors": ["M. Braverman", "E. Mossel"],
    "venue": "arXiv preprint arXiv:0910.1191,",
    "year": 2009
  }, {
    "title": "Rates of convergence for the cluster tree",
    "authors": ["K. Chaudhuri", "S. Dasgupta"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2010
  }, {
    "title": "On the tchebychef inequality of bernstein",
    "authors": ["C.C. Craig"],
    "venue": "The Annals of Mathematical Statistics,",
    "year": 1933
  }, {
    "title": "Spearman’s footrule as a measure of disarray",
    "authors": ["P. Diaconis", "R.L. Graham"],
    "venue": "Journal of the Royal Statistical Society. Series B (Methodological),",
    "year": 1977
  }, {
    "title": "Apparent and real age estimation in still images with deep residual regressors on appa-real database",
    "authors": ["E Agustsson", "R Timofte", "S.E.X.B.I.G.R. R"],
    "venue": "IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG),",
    "year": 2017
  }, {
    "title": "Machine learning energies of 2 million Elpasolite(ABC2D6)crystals",
    "authors": ["F.A. Faber", "A. Lindmaa", "O.A. von Lilienfeld", "R. Armiento"],
    "venue": "Physical Review Letters,",
    "year": 2016
  }, {
    "title": "A distribution-free theory of nonparametric regression",
    "authors": ["L. Györfi", "M. Kohler", "A. Krzyzak", "H. Walk"],
    "venue": "Springer Science & Business Media,",
    "year": 2006
  }, {
    "title": "Isotonic regression in general dimensions",
    "authors": ["Q. Han", "T. Wang", "S. Chatterjee", "R.J. Samworth"],
    "venue": "arXiv preprint arXiv:1708.09468,",
    "year": 2017
  }, {
    "title": "Nonparametric and semiparametric models",
    "authors": ["W.K. Härdle", "M. Müller", "S. Sperlich", "A. Werwatz"],
    "venue": "Springer Science & Business Media,",
    "year": 2012
  }, {
    "title": "Active classification with comparison queries",
    "authors": ["D.M. Kane", "S. Lovett", "S. Moran", "J. Zhang"],
    "venue": "arXiv preprint arXiv:1704.03564,",
    "year": 2017
  }, {
    "title": "Learning from noisy singly-labeled data",
    "authors": ["A. Khetan", "Z.C. Lipton", "A. Anandkumar"],
    "venue": "arXiv preprint arXiv:1712.04577,",
    "year": 2017
  }, {
    "title": "Learning with feature feedback: From theory to practice",
    "authors": ["S. Poulis", "S. Dasgupta"],
    "venue": "In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,",
    "year": 2017
  }, {
    "title": "Facenet: A unified embedding for face recognition and clustering",
    "authors": ["F. Schroff", "D. Kalenichenko", "J. Philbin"],
    "venue": "In Proceedings of the IEEE conference on computer vision and pattern recognition,",
    "year": 2015
  }, {
    "title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence",
    "authors": ["N. Shah", "S. Balakrishnan", "J. Bradley", "A. Parekh", "K. Ramchandran", "M. Wainwright"],
    "venue": "In Artificial Intelligence and Statistics,",
    "year": 2015
  }, {
    "title": "Stochastically transitive models for pairwise comparisons: Statistical and computational issues",
    "authors": ["N. Shah", "S. Balakrishnan", "A. Guntuboyina", "M. Wainwright"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "A law of comparative judgment",
    "authors": ["L.L. Thurstone"],
    "venue": "Psychological review,",
    "year": 1927
  }, {
    "title": "How to analyze paired comparison data",
    "authors": ["K. Tsukida", "M.R. Gupta"],
    "venue": "Technical report, DTIC Document,",
    "year": 2011
  }, {
    "title": "Optimal aggregation of classifiers in statistical learning",
    "authors": ["A.B. Tsybakov"],
    "venue": "The Annals of Statistics,",
    "year": 2004
  }, {
    "title": "Introduction to nonparametric estimation. revised and extended from the 2004 french original. translated by vladimir zaiats",
    "authors": ["A.B. Tsybakov"],
    "year": 2009
  }, {
    "title": "Noise-tolerant interactive learning from pairwise comparisons with near-minimal label complexity",
    "authors": ["Y. Xu", "H. Zhang", "K. Miller", "A. Singh", "A. Dubrawski"],
    "venue": "arXiv preprint arXiv:1704.05820,",
    "year": 2017
  }, {
    "title": "Accelerated search for materials with targeted properties by adaptive design",
    "authors": ["D. Xue", "P.V. Balachandran", "J. Hogden", "J. Theiler", "T. Lookman"],
    "venue": "Nature Communications,",
    "year": 2016
  }, {
    "title": "Risk bounds in isotonic regression",
    "authors": ["Zhang", "C.-H"],
    "venue": "The Annals of Statistics,",
    "year": 2002
  }, {
    "title": "Crowdsourcing feature discovery via adaptively chosen comparisons",
    "authors": ["J.Y. Zou", "K. Chaudhuri", "A.T. Kalai"],
    "venue": "In Proceedings of the Third AAAI Conference on Human Computation and Crowdsourcing,",
    "year": 2015
  }],
  "id": "SP:038a69d1497986794fede3b02b6b3c485663c96d",
  "authors": [{
    "name": "Yichong Xu",
    "affiliations": []
  }, {
    "name": "Hariank Muthakana",
    "affiliations": []
  }, {
    "name": "Sivaraman Balakrishnan",
    "affiliations": []
  }, {
    "name": "Artur Dubrawski",
    "affiliations": []
  }, {
    "name": "Aarti Singh",
    "affiliations": []
  }],
  "abstractText": "In supervised learning, we leverage a labeled dataset to design methods for function estimation. In many practical situations, we are able to obtain alternative feedback, possibly at a low cost. A broad goal is to understand the usefulness of, and to design algorithms to exploit, this alternative feedback. We focus on a semi-supervised setting where we obtain additional ordinal (or comparison) information for potentially unlabeled samples. We consider ordinal feedback of varying qualities where we have either a perfect ordering of the samples, a noisy ordering of the samples or noisy pairwise comparisons between the samples. We provide a precise quantification of the usefulness of these types of ordinal feedback in nonparametric regression, showing that in many cases it is possible to accurately estimate an underlying function with a very small labeled set, effectively escaping the curse of dimensionality. We develop an algorithm called Ranking-Regression (R) and analyze its accuracy as a function of size of the labeled and unlabeled datasets and various noise parameters. We also present lower bounds, that establish fundamental limits for the task and show that R is optimal in a variety of settings. Finally, we present experiments that show the efficacy of R and investigate its robustness to various sources of noise and model-misspecification.",
  "title": "Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information"
}