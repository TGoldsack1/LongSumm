{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Generalized bipartite matching or bipartite b-matching is one of the fundamental problems in computer science. Canonical applications include resource allocation problems such as ad allocation in online advertising, job/server allocation in cloud computing, organ/donor matching, and product recommendation under resource constraints. It has also been utilized as an algorithmic tool in a variety of do-\n*Equal contribution 1Columbia University, New York, NY 2Google Research. Correspondence to: Shipra Agrawal <sa3305@columbia.edu>, Vahab Mirrokni <mirrokni@google.com>, Morteza Zadimoghaddam <zadim@google.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nmains, including computer vision (Belongie et al., 2002), estimating text similarity (Pang et al., 2016), string matching for protein structure alignment (Krissinel & Henrick, 2004), document clustering (Dhillon, 2001); and as a subroutine in several machine learning tasks (Huang & Jebara, 2007; Jebara & Shchogolev, 2006).\nThe focus of this paper is on large-scale matching problems such as those arising in online advertising. In online advertising settings, a set of advertisers A provide their targeting domains to determine what subset of impressions I they are interested in. This can be modeled as a bipartite graph G(A, I,E). The advertisers also set capacity/targeting constraints on the number of impressions they want their ads to be shown to, referred to as capacity (or budget) constraints. It is assumed that each advertiser a has a capacity constraint Ca. The matching task is to assign each impression to at most one eligible advertiser based on the targeting information while respecting the capacity constraints. Typically, the goal is to maximize either the number of matched impressions, or the sum of values of the assignments if we are awarded different values for the assignment of every pair of impressions and advertisers.\nThe rapid growth in Internet advertising has introduced many large scale matching problems for assigning billions of impressions to advertisers on a daily basis. Classic centralized approaches to solve these problems may be irrelevant due to their computational and memory limitations. In online advertising, the number of impressions are usually much higher than the number of advertisers. Such bipartite graphs are called lopsided bipartite graphs. The number of impressions is often so large that these matching instances do not fit in the memory of a single machine, and there is a dire need of designing simple and scalable matching algorithms. This is true even if we treat similar impressions as identical copies because each impression type is “the Cartesian product of several features (such as geographic location, time of day/week), domains of which have sizes typically ranging from thousands to millions” (Bateni et al., 2017). Similar lopsided bipartite matching problems arise in many other domains, for example in product recommendation, where the number of users is typically much higher than the number of products, or document-word clustering, where\nthe number of words is typically much larger compared to the number of documents (Dhillon, 2001).\nAll the above motivate the problem of designing simple and scalable algorithms for lopsided bipartite matching in practice. One such natural algorithm that has been used in practice is the proportional allocation algorithm: consider the bipartite matching problem on graph G(A, I,E) with given capacity constraints Ca for a ∈ A. Proportional allocation algorithm is as follows: Maintain a priority score βa for each a ∈ A, initialized as βa = 1. Iteratively allocate each node i ∈ I to an eligible node a ∈ A in proportion of its score βa. After each round, increase or decrease βa based on over- or under- allocation of node a, for each a ∈ A. Repeat until this algorithm converges to a stable solution. This is a natural and easy to implement algorithm, used in practice to compute b-matching in a distributed fashion for large-scale problems. This is especially useful when the graph is lop-sided, so that the number of advertisers, and hence, the number of priority scores to be maintained and communicated are relatively small.\nOur first result is that this simple iterative algorithm converges to a (1 − )-approximate fractional b-matching solution in O( logn 2 ) rounds. To this end, we first present a combinatorial proof of our result for the unweighted case. Then, we present a primal-dual interpretation via convex programing duality. We formulate a convex program for the problem of maximizing the cardinality/weight of matching in a bipartite graph, with the entropy of the matching as a regularizer in the objective. Interestingly, it turns out that the priority scores in the proportional allocation algorithm correspond to the dual variables of this convex program. And, the proportional allocation rule corresponds to the complimentary primal solution, for any given values of the dual variables. This formulation helps us extend the proportional allocation algorithm and convergence results to edge-weighted graphs.\nMore importantly, an implication of this formulation is that the proportional allocation algorithm naturally produces high entropy matchings. In fact, we formally demonstrate that we can set certain parameters of the algorithm to ensure convergence to an almost optimal matching with high entropy. High entropy, in turn, implies additional desirable properties of this matching. First of all, by maximizing entropy, the allocation achieves higher diversity both from the advertisers’ point of view and from the users’ perspective. From advertisers’ perspective, they see a more diverse set of impressions which translates to reaching out to a more diverse demographics. From impressions’ perspective, each user will also see a more diverse set of ads. The connection between entropy and various diversity measures has been confirmed by several papers (Qin & Zhu, 2013; Ahmed et al., 2017; Noia et al., 2017). Besides achieving higher di-\nversity, high entropy allocations are also believed to be more fair (e.g., (Venkatasubramanian, 2010) and (Lan et al., 2010) propose high entropy as an important fairness criteria).\nFurthermore, one can argue that the proportional allocation algorithm achieves better fairness due to its symmetry and anonymity properties (Lan et al., 2010). It is also likely to be more robust to changes in demand patterns (due to its increased randomized allocation criteria). Below, we further discuss the merits of proportional allocation in comparison to other related online and distributed algorithms for bipartite matching."
  }, {
    "heading": "1.1. Related work",
    "text": "Graph matching and assignment problems are some of the most well studied problems in combinatorial optimization. There is considerable work on fast exact algorithms, as well as faster approximate algorithms, for matching problems. Notable examples include (1− ) approximation in O(m log(1/ )) time by (Duan & Pettie, 2014) for weighted graphs, where m is the number of edges in the graph. For maximum cardinality matching, many classic algorithms (e.g., (Hopcroft & Karp, 1971) ) can achieve this.\nMotivated by the large-scale applications of matching in advertising and other e-commerce applications, recently there has been a focus on distributed algorithms. In these applications, it is desirable to have algorithms which run in potentially logarithmic rounds or phases, with each phase involving simple computations that can be distributed1 and/or parallelized. Some recent literature includes the work by (Bahmani et al., 2014) in the MapReduce framework, which improves upon previous work of (Ahn & Guha, 2013) and (Bahmani et al., 2012). The proportional allocation algorithm provides a much simpler alternative approach for such distributed large-scale settings, especially in case of large lop-sided bipartite graphs. Arguably, this heuristic is comparable in its simplicity and ease of implementation to the greedy heuristic, which only allows a 2-factor approximation. In contrast, as proven in this paper, the proportional allocation converges to optimal solution in logarithmic number of rounds.\nAnother closely related work is by Charles et al. (2010) on fast streaming algorithms for bipartite matching in lopsided graphs. Proportional allocation has several significant benefits over the method proposed there, including high entropy matching, amenability to distributed implementation, and simple concise representation through priority scores of advertisers (i.e., one score for each node on the smaller side in the lop sided graphs) only.\nWe also note that iterative approximation algorithms have been developed for the more general problem class of pack-\n1i.e., allow the graph to be stored in a distributed manner\ning and covering (Plotkin et al., 1995; Awerbuch & Khandekar, 2009; Garg & Konemann, 2007). In fact, many of these algorithms belong to the class of multiplicative weight update (MWU) methods(Arora et al., 2012). The MWU methods operate by maintaining weights wa for each advertiser, similar to our priority scores. These weights are updated in a multiplicative manner based on the amount of over-allocation or under-allocation in every round. The weights are then used as Lagrangian dual variables to combine the packing (capacity) constraints, so that the packing problem reduces to a knapsack problem. The impression allocation then roughly reduces to greedily selecting impression-advertiser mappings with highest ratio ri,a/wa. Besides having a simpler score update rule (constant factor updates) and a simpler, distributed assignment rule (proportional allocation), the proportional allocation algorithm is naturally designed to yield higher entropy solutions compared to these methods. Intuitively, this is because proportional allocation rule essentially does a softmax over (ri,a − βa): imagine the case when weights ri,a are distinct but infinitesimally close to each other, then the abovementioned greedy approach will select the top Ca impressions for every advertiser, where as the softmax will give almost uniform distribution. In fact, we formally show that softmax is the optimal form of primal decision for maximizing entropy along with weight of the matching.\nExtensions of such primal-dual approaches have also been proposed for online packing problems motivated by the Display Ads Allocation (DA) problem (Gupta & Molinaro, 2016; Agrawal & Devanur, 2015; Devanur et al., 2011; Agrawal et al., 2009; Feldman et al., 2009; 2010; Vee et al., 2010), and the Budgeted Allocation (AdWords) problem (Mehta et al., 2007; Devanur & Hayes, 2009). In the online setting, the impressions arrive one by one in sequential time steps, and should either be immediately assigned to one of the advertisers with remaining budget, or discarded. In these algorithms, the dual variables or advertiser weights are updated periodically over time either by solving an LP (Agrawal et al., 2009; Feldman et al., 2009; 2010; Devanur & Hayes, 2009), or by multiplicative weight updates (Gupta & Molinaro, 2016; Agrawal & Devanur, 2015; Devanur et al., 2011). These weights are then used as thresholds for making assignments of impressions arriving online. Besides the concerns mentioned above for MWU methods, the weight updates in these online algorithms must be performed sequentially, and therefore are not amenable to parallel implementations."
  }, {
    "heading": "1.2. Organization of the paper.",
    "text": "In Section 2, we formulate the generalized bipartite matching problems considered in this paper. In Section 3, we present the proportional allocation algorithm for the maximum cardinality case, as well as its simple extension to the problem of finding maximum weighted matching with high-\nentropy. In Section 4, we prove our main results (Theorem 1 and Theorem 2) regarding efficient convergence of both these versions of the proportional allocation algorithm. The proof of Theorem 2 also provides an interesting primal-dual interpretation of the proportional allocation algorithm."
  }, {
    "heading": "2. Problem Formulation",
    "text": "Here, we formulate the generalized bipartite matching problems, aka bipartite b-matching problems, considered in this paper. Throughout the paper, we use the terminology from online advertising, with the two sides of the bipartite graph being ‘impressions’ and ‘advertisers’.\nMaximum cardinality matching. A set A of advertisers and a set I of impressions are given. For each advertiser a ∈ A, there is a set of impressions Na ⊆ I that can be potentially assigned to a. Similarly for any i ∈ I, we define Ni ⊆ A to be the set of advertisers that impression i can be matched to. These connections can be represented with a bipartite graph G of edge set E = {(i, a) : i ∈ I, a ∈ Ni} = {(i, a) : a ∈ A, i ∈ Na}. Each advertiser a has capacity Ca denoting maximum number of impressions she is interested to be matched to.\nThe goal is to find a subset of edges M ⊆ E such that: • Each impression is incident to at most one edge in M .\nThis property ensures that each impression is assigned to at most one advertiser. • Each advertiser a is incident to at most Ca edges in M respecting its capacity.\nwhile maximizing the cardinality of M . Such an edge set M is referred to as a maximum cardinality matching.\nA maximum cardinality fractional matching is defined as an assignment {xi,a} ∈ [0, 1]E that maximizes ∑ (i,a)∈E xi,a while satisfying capacity constraints, i.e.,∑ i∈I\nxi,a ≤ Ca, ∀a ∈ A, (1)∑ a∈A xi,a ≤ 1, ∀i ∈ I (2)\nMaximum weighted matching. We also consider the more general problem of maximum weighted matching. Here, for each edge e = (i, a) ∈ E, a weight ri,a has been specified. The goal is to find a subset of edges M ⊆ E such that the capacity constraints for each advertiser and impression are satisfied, while maximizing total weight ∑ (i,a)∈M ri,a of the matching. For fractional matching {xi,a}(i,a)∈E, similarly the goal is to maximize∑ (i,a)∈E xi,ari,a, while satisfying constraints in (1) and (2).\nHigh entropy matching. The proportional allocation algorithm proposed in this paper naturally gives a high en-\nAlgorithm 1 PropAlloc : A proportional allocation algorithm for maximum cardinality matching Input: G = (A, I,E), {Ca}a∈A; parameter ∈ (0, 1),\nnumber of rounds R. Initialization: Set βa = 1, for all a ∈ A.\nfor rounds ` = 1, 2, . . . , R do Step 1: For each impression i, set assignment\nxi,a = βa∑\na′∈Ni βa′ ,∀a ∈ Ni\nStep 2: For each advertiser a, update βa as follows:\nAlloca ≤ Ca\n(1 + ) =⇒ βa := (1 + )βa\nAlloca ≥ (1 + )Ca =⇒ βa := βa\n(1 + ) where Alloca := ∑ i∈Na xi,a.\nend for for each a with Alloca > Ca do\nSet xi,a := CaAlloca xi,a,∀i ∈ Na end for\ntropy fractional matching, while also maximizing cardinality/weight of the matching. To formally study this property of the algorithm, we consider an alternate objective of maximizing a combination of weight and entropy of the matching. Specifically, given a parameter λ ≥ 0, the goal here is to find a fractional matching {xi,a}(i,a)∈E that maximizes∑\n(i,a)∈E\nri,axi,a + λ ∑\n(i,a)∈E\nxi,a log(1/xi,a) (3)\nwhile satisfying capacity constraints in (1) and (2). The second term in the above is the entropy of assignment {xi,a}."
  }, {
    "heading": "3. Proportional allocation algorithm",
    "text": "We propose the multi round distributed algorithm PropAlloc that finds an almost optimum fractional matching, and then prove how the fractional matching can be transformed into an (integral) matching without much loss if the capacities of advertisers are large.\nAlgorithm PropAlloc intends to find priority score βa for each advertiser a ∈ A such that if the impressions are assigned proportional to these priorities, we achieve an almost optimum allocation. Formally, impression i will be assigned to advertiser a ∈ Ni with probability βa∑\na′∈Ni βa′\n. Algorithm\nPropAlloc then computes the expected number of impressions each advertiser a receives as follows.\nAlloca = ∑ i∈Na βa∑ a′∈Ni βa′\n(4)\nAlgorithm 2 PropAlloc + : A proportional allocation algorithm for high-entropy maximum weight matching Input: G = (A, I,E), {Ca}a∈A, weights {ri,a}(i,a)∈E, pa-\nrameter λ; parameter ∈ (0, 1), number of rounds R. Initialization: Set βa = (1 + )−R, for all a ∈ A.\nfor rounds ` = 1, 2, . . . , R do Step 1: For each impression i, set assignment\nxi,a =\n{ βaDi,a,λ if ∑ a′∈Ni βa′Di,a′,λ ≤ 1\nβaDi,a,λ∑ a′∈Ni βa′Di,a′,λ otherwise\nwhereDi,a,λ = e ri,a λ −1 Step 2: For each advertiser a, update βa as follows:\nAlloca ≤ Ca\n(1 + ) =⇒ βa := (1 + )βa\nAlloca ≥ (1 + )Ca =⇒ βa := βa\n(1 + ) where Alloca := ∑ i∈Na xi,a.\nend for for each a with Alloca > Ca do\nReduce xi,a for impressions i ∈ Na with xi,a ≥ Ca|Na| , until ∑ i∈Na xi,a ≤ Ca.\nend for\nIntuitively, if the expected allocation Alloca exceeds the capacity Ca, it means advertiser a has been over-allocated, so the overflow of impressions Alloca − Ca are going to be discarded without contributing anything to the objective function. On the other hand, if the expected allocation Alloca does not reach the capacity Ca, it means advertiser a has been under-allocated, so the there is a Ca−Alloca extra capacity left to be potentially exploited. Both of the above situations introduce some room for improving the priority variables. Algorithm PropAlloc initializes all βa variables to the same value (for instance 1), and then updates βa for each a ∈ A in each round as follows.\n• If Alloca ≤ Ca(1+ ) =⇒ βa := (1 + )βa. In other words increase priority of a by a multiplicative factor of 1 + . • If Alloca ≥ (1 + )Ca =⇒ βa := βa 1+ .\nIn other words decrease priority of a by a multiplicative factor of 1 + .\n• Otherwise, do not change the priority of a.\nAlgorithm PropAlloc consists of R rounds of computing Alloc variables based on the priorities, {βa}a∈A, and then updating the priorities with above rules. After all these rounds, PropAlloc computes the fractional matching respecting all capacity constraints as follows. For every impression i ∈ I and each advertiser a ∈ Ni, we set the\nassignment xi,a to be the probability that i is assigned to a based on the current priority values. That is,\nxi,a = βa∑\na′∈Ni βa′\nThese assignments always respect the constraints (1) on impressions, since the total assignment of each impression i ∈ I, given by ∑ a∈Ni xi,a, is equal to 1. But, there might be advertisers that receive more total assignment than their capacities. To adjust for these over-allocations, at the end of R rounds, the assignments to these advertisers can be reduced in any manner. For each advertiser, a ∈ A with Alloca > Ca, we can scale down the assignments of all edges incident on a by a factor of AllocaCa to make sure that the capacity constraints are all respected. Therefore, the total weight of the fractional matching is equal to MatchWeight = ∑ a∈A min{Alloca,Ca}.\nThe proportional allocation algorithm is summarized in Algorithm 1. We show that a logarithmic number of rounds suffices to converge to an almost optimum fractional allocation, and then find an integral assignment based on that. Further, among the maximum cardinality matching, the proportional allocation algorithm naturally finds matchings with high entropy. To formalize this observation, below we give a simple extension of the algorithm for the joint objective of maximizing entropy and weight of the matching, combined with a parameter λ. In fact Algorithm 1 will be a special case of the new algorithm for λ ≈ 0, ri,a = 1,∀i, a.\nAlgorithm for high-entropy weighted matching. Given weights {ri,a}(i,a)∈E, and a parameter λ > 0, a simple extension of the proportional allocation algorithm computes maximum weight matching with high entropy. This algorithm maintains and updates priority scores {βa} in a similar manner to Algorithm 1. However, to account for weights and entropy parameter λ, given the priority scores, the assignments xi,a are now computed as follows: let Di,a,λ := e ri,a λ −1, then,\nxi,a =\n{ βaDi,a,λ if ∑ a′∈Ni βa′Di,a′,λ ≤ 1\nβaDi,a,λ∑ a′∈Ni βa′Di,a′,λ otherwise\nThe new algorithm is summarized in Algorithm 2. Note that the main change is in Step 2. Further, at the end of R rounds, earlier in Algorithm 1 we could allow any kind of adjustment to assignments of over-allocated advertisers. But, since entropy is of consideration here, in Algorithm 2 we make a slightly more careful adjustment: we only remove impressions with large assignment value, i.e., impressions i ∈ Na with xi,a ≥ Ca|Na| .\nNote that these modifications keeps the simple distributed structure of the algorithm intact: given priority scores of\nadvertisers, the impressions can be allocated in a distributed manner in proprtion of these scores."
  }, {
    "heading": "4. Analysis",
    "text": ""
  }, {
    "heading": "4.1. Main results",
    "text": "First, we show that after enough number of rounds, the fractional matching achieved by PropAlloc (refer to Algorithm 1 is almost optimal.\nTheorem 1. For any δ ∈ (0, 1], there exists2 an > 0 such that algorithm PropAlloc with parameter returns a (1−δ)approximate fractional matching after R = O( log(n/δ)δ2 ) rounds. Here, n is the number of advertisers.\nFurther, we provide a primal-dual interpretation of the proportional allocation algorithm to show that PropAlloc + (refer to Algorithm 2) can achieve any desired tradeoff between weight of the matching and entropy of the matching.\nTheorem 2. For any δ ∈ (0, 1], λ > 0, there exists an > 0 such that algorithm PropAlloc + with parameter returns a fractional matching that achieves (1 − δ)approximation for the weight-entropy objective in (3), after R = O ( rmax rmin (1+λ log N̄))2 λδ ) rounds.\nHere, rmax = max(i,a)∈E ri,a, rmin = min(i,a)∈E ri,a, N̄ = maxa∈A\n|Na| Ca .\nRemark 1. Any feasible fractional allocation can be adapted as a randomized allocation algorithm since the sum of edge weights per impression does not exceed 1 and they can be interpreted as allocation probabilities. In expectation, this gives a feasible integral allocation. Further, using concentration bounds (e.g., Lemma 13 of (Bansal & Sviridenko, 2006)), with high probability, the capacity constraints will not be violated by more than a factor of Õ(1 + 1√Ca\n) for any advertiser a. Therefore, if advertisers have large enough capacities, the fractional matching can be rounded to an integral solution with negligible loss.\n4.2. A combinatorial analysis of PropAlloc (Proof of Theorem 1)\nWe focus on the β variables when the algorithm terminates (after the end of round R). The minimum value the priority variables can take after R rounds is βmin = 1 (1+ )R\n, and any a ∈ A can take one of the following 2R + 1 potential priority values:\nβa ∈ {βmin, (1 + )βmin, · · · , (1 + )2Rβmin}\nFor each 0 ≤ k ≤ 2R, let Lk be the set of advertisers with priority value (1 + )kβmin, i.e. Lk := {a|βa = (1 + )kβmin}. Since these sets form a hierarchy of priority\n2It suffices to set = δ/5.\nvalues, we call them level sets. We note that some of these sets may be empty. There are two main sources of possible suboptimality in the fractional matching that PropAlloc finds:\n• Over-allocation: If Alloca is greater than Ca, Alloca− Ca matched impressions will not be counted towards the objective. • Under-allocation: If Alloca is less than Ca, an extra capacity of Ca − Alloca is left to be exploited for advertiser a.\nIn the following, we show that for advertisers in most of the level sets, both of the above over-allocation and underallocation losses are negligible.\nLemma 1. For any a ∈ ∪2R−1k=0 Lk, the under-allocation Ca−Alloca is at most 3 Ca. Similarly for any a ∈ ∪2Rk=1Lk, the over-allocation Alloca − Ca is at most 3 Ca.\nProof. Due to the symmetry of the two claims, we only prove the former. Since a is not in level set L2R, there was a time that we did not increase βa. Let t be the last round that βa was not increased. At this point, Alloca Ca was at least 1 (1+ ) . For t = R, this completes the proof. Otherwise, we focus on round t+ 1 ≤ R. Recall, Alloca = ∑ i∈Na βa∑ a′∈Ni βa′ .\nIf βa is unchanged at round t, the numerator of each term also remains unchanged. The denominator terms are increased at most by a factor of (1 + ). So in total, Alloca is not decreased by more than a factor of (1 + ) yielding the lower bound AllocaCa ≥ 1 (1+ )2 at round t+ 1. In the other case, βa is decreased at round t, so the numerator of each term is also reduced by a factor of (1 + ). In total, the ratio Alloca\nCa is decreased by a factor of at most 1 (1+ )2 at round t + 1. Note that the reduction of βa at round t means the ratio AllocaCa was at least 1 + , and therefore at least 1 1+ at round t+ 1. So independent of whether βa was reduced or not, AllocaCa will be at least 1 (1+ )2 at round t+ 1.\nBy definition of t, βa is increased in all rounds after t. With a similar argument, we know that AllocaCa does not decrease at any of these rounds. So the ratio AllocaCa remains at least\n1 (1+ )2 ≥ 1 + 3 for ≤ 1 till the last round.\nLemma 1 shows that every advertiser is either changed in one direction (reducing or increasing β) in all rounds, or its fractional allocation will be almost equal to its capacity. The latter helps us prove optimality, and the former only contains advertisers in level sets L0 and L2R. Next, we prove two main claims: on lower bounding the weight of the fractional matching, MatchWeight = ∑ a∈A min{Alloca,Ca}, and on upper bounding the optimum value in terms of the level sets. These are stated as Claim 1.\nClaim 1. For any two indices 1 ≤ ` and `+ log(n/ )/ ≤ `′ ≤ 2R, we have:\n• MatchWeight, is at least:\n(1− 4 ) (∑`\nk=0 ∑ a∈Lk Ca + |N(∪ 2R k′=`′+1Lk′)| ) (5)\nwhere N(S) for any subset S of advertisers is the union of their neighborhoods ∪a∈SNa. • The weight of the optimum fractional matching does not exceed:(∑`′\nk=0 ∑ a∈Lk Ca + |N(∪ 2R k′=`′+1Lk′)| ) (6)\nProof. The proof of the second statement is very similar to folklore graph theoretic results like Konig’s Theorem (Ahmadi & Hall). The number of matched impressions in the optimum allocation consists of two main classes: those matched to advertisers in ∪`′k=0Lk, and those assigned to advertisers in ∪2Rk=`′+1Lk. The former cannot be more than the sum of capacities of the associated advertisers which is the first term in the upper bound. The latter is a subset of all neighbors of advertisers in ∪2Rk=`′+1Lk and therefore at most |N(∪2Rk′=`′+1Lk′)|.\nTo prove the first statement of the Claim, we categorize assigned impressions in MatchWeight into two categories. Using Lemma 1, the impressions assigned to advertisers in L0, L1, · · · , L` almost fill up their capacities and therefore sum up to at least (1−3 ) ∑` k=0 ∑ a∈Lk Ca which is larger than the first term of the lower bound.\nThe second term represents all neighbors of advertisers in L`′+1, · · · , L2R. To avoid double counting, we show that any impression that has a neighbor in ∪2Rk′=`′+1Lk′ will not be assigned to any advertiser in ∪`k=0Lk w.h.p. (≥ 1− ).\nConsider impression i that is a neighbor of a′ ∈ Lk′ for some k′ ≥ `′ + 1. Because `′ is at least `+ log(n/ )/ , we have βa′ ≥ n βa for any a ∈ Lk with k ≤ `. Therefore the probability of i being assigned to a is at most /n times the probability it being assigned to a′. Since there could be potentially at most n candidates like a, the probability of i being assigned to any advertiser in ∪`k=0Lk is at most . So every impression in N(∪2Rk=`′+1Lk) will be assigned to some advertiser in∪2Rk=`+1Lk with probability at least 1− . Using Lemma 1, at least 1− 3 fraction of every such impression will be counted towards MatchWeight. So in total, we get at least 1−4 for each impression in N(∪2Rk′=`′+1Lk′) which concludes the proof of the Claim.\nProof of Theorem 1. Given Claim 1, there are two main gaps between the lower bound of (5) and the upper bound of (6): the 1 − 4 factor and the sum ∑`′ k=`+1 ∑ a∈Lk Ca. We show that the latter gap is small for some value of ` and `′ = `+ log(n/ )/ .\nSumming this gap over different values of ` yields∑2R−log(n/ )/ `=0 ∑`+log(n/ )/ k=`+1 ∑ a∈Lk Ca\n≤ (log(n/ )/ ) ∑2R k=1 ∑ a∈Lk Ca\nTherefore there exists an 0 ≤ ` ≤ 2R − log(n/ )/ such that its associated gap ∑`+log(n/ )/ k=`+1 ∑ a∈Lk Ca is at most\nlog(n/ )/ 2R−log(n/ )/ +1 ∑2R k=1 ∑ a∈Lk Ca ≤ ∑2R k=1 ∑ a∈Lk Ca where the last inequality holds when R is at least log(n/ )/ 2.\nUsing Lemma 1, for every a ∈ ∪2Rk=1Lk, the over-allocation Alloca − Ca is at most 3 Ca. Therefore MatchWeight is at least (1 − 3 ) ∑2R k=1 ∑ a∈Lk Ca. This means the gap associated for some ` is at most MatchWeight/(1 − 3 ). Using Claim 1, we have MatchWeight ≥ (1− 4 )(OPT − MatchWeight/(1 − 3 )) yielding a final approximation factor of at least 1 − 5 . Then, the theorem statement can be obtained by setting δ = /5, R = log(n/ )/ 2 = O(log(n/δ)/δ2)."
  }, {
    "heading": "4.3. Primal-dual interpretation: Proof of Theorem 2",
    "text": "Consider the matching problem with weights {ri,a}(i,a)∈E. Given any λ > 0, let OPTλ denote the optimal value of the following convex optimization problem that maximizes a combination of weight of matching and entropy:\nmaximize ∑ (i,a)∈E ri,axi,a+ λ ∑ i,a xi,a log(1/xi,a)\nsubject to ∑ a∈Ni xi,a ≤ 1, i ∈ I∑ i∈Na xi,a ≤ Ca, a ∈ A\nxi,a ≥ 0 ∀(i, a) ∈ E (7)\nWe show that in R = rmaxrmin (1+λ log(N̄))2 δλ iterations, where N̄ = maxa |Na| Ca , the proportional allocation algorithm with\n≤ rmin rmax\n1\n8(2 + λ log(N̄)) δ,\nfinds an assignment {xi,a}i,a satisfying: OPTλ ≤ (1 + δ) ∑ i,a ri,axi,a + λ ∑ i,a xi,a log(1/xi,a)\nFollowing upper bound on OPTλ can be obtained using Lagrangian duality for the convex program (7). This also provides a dual-based interpretation of the decision xi,a with priority scores {βa} emerging as an exponential function of the corresponding dual variables for the advertisers’ capacity constraints.\nLemma 2. Given any {γa ≥ 0}a, let\nx∗i,a =  e −γa λ Di,a,λ∑ a′∈Ni e −γ a′ λ Di,a′,λ , ∑ a′∈Ni e −γ a′ λ Di,a′,λ ≥ 1\ne −γa λ Di,a,λ otherwise.\n(8)\n(recallDi,a,λ = e ri,a λ −1). Then,\nOPTλ ≤ ∑\n(i,a)∈E\nri,ax∗i,a − λx∗i,a log(x∗i,a)\n+ ∑ a∈A γa(Ca − ∑ i∈Na x∗i,a) (9)\nProof. Using Lagrangian duality for (7)\nOPTλ = min γ≥0,z≥0 max x≥0 L(x, γ, z)\nwhere\nL(x, γ, z) :=  ∑i,a ri,axi,a − λxi,a log(xi,a)+∑i zi(1−∑a∈Ni xi,a) + ∑ a γa(Ca − ∑ i∈Na xi,a)  Also, for any {γa ≥ 0, zi ≥ 0}\nOPTλ ≤ maxx≥0 L(x, γ, z)\nNow, ∂\n∂xi,a L(x, γ, z) = ri,a − λ− λ log(xi,a)− zi − γa\nso for any zi ≥ 0, γa ≥ 0,\nx∗i,a = e −γa/λ−zi/λe\nri,a λ −1\nsatisfies x∗i,a ≥ 0, ∂∂xi,aL(x, γ, z) = 0, and therefore it is a maximizer of L(x, γ, z), and from above we have OPTλ ≤ L(x∗, γ, z). Now, set zi as follows: IF∑ a∈Ni e −γa/λDi,a,λ ≥ 1, set e zi λ = ∑ a∈Ni e −γa λ Di,a,λ where Di,a,λ = e ri,a λ −1. Otherwise, set zi = 0. Then, substituting zi, x∗i,a is as given in (8). Further, for all i, zi( ∑ a∈Ni x ∗ i,a − 1) = 0, substituting which we get\nL(x∗, γ, z) = ∑ i,a rax∗i,a − λx∗i,a log(x∗i,a)\n+ ∑ a γa(Ca − ∑ i∈Na x∗i,a)\nand therefore, using OPTλ ≤ L(x∗, γ, z) we obtain the upper bound in (9).\nCorollary 1. Let {xRi,a}(i,a)∈E be the assignments and {βRa }a∈A be the priority scores at the end of R iterations of Algorithm 2, then\nOPTλ ≤ ∑\n(i,a)∈E\nri,axRi,a − λxRi,a log(xRi,a)\n− ∑ a∈A λ log(βRa )(Ca − ∑ i∈Na xRi,a) (10)\nProof. We can observe this using Lemma 2, by substituting γa = λ log(1/β R a ). Since initial value of βa is (1 + )\n−R, and there is a increase of at most (1 + )R factor, we have that βa ≤ 1, so that γa = λ log(1/β R a ) ≥ λ log(1) = 0. Therefore, it is a valid assignment of γa.\nPrimal-dual interpretation of PropAlloc + . From the above discussion, observe that there is a one-to-one mapping between the priority scores βa and dual variables γa. On setting βa = e −γa λ , we obtained that the assignments made by our algorithm are same as complimentary solution {x∗i,a} given by (8). This provides a primal dual interpretation of the proportional allocation algorithm. The proportional allocation algorithm is essentially updating the dual variables based on the feasibility (over-allocation/under-allocation) of the primal complimentary solution.\nNow, using observations similar to those made in Lemma 1 in the previous section, it is easy to see that algorithm PropAlloc + satisfies the following property.\nLemma 3. For any a ∈ A, unless βa was increased in all iterations or decreased in all iterations, at the end of R iterations of Algorithm 2, Alloca := ∑ i∈Na xi,a ∈ [(1 +\n)−2Ca, (1 + )2Ca].\nWe are now ready to prove Theorem 2. Here we provide an outline, with detailed proof in the supplementary material.\nProof of Theorem 2 (Sketch). Without loss of generality, let’s assume that rmax is 1. This can be obtained by dividing all ri,a by rmin. rmin in the processed instance is then in fact the ratio of rmin and rmax of the original instance. Let xRi,a and β R a denote the value of assignments and priority scores at the end of R iterations of Algorithm 2 (before the processing in the last step was done to handle over-allocated advertisers). And, let xMi,a denote the feasible assignments obtained after the processing in the last step of the algorithm. Let weight(M) := ∑ i,a∈E ri,ax M i,a denote the weight of this feasible fractional matching M .\nInitially, βa = (1 + ) −R. From Lemma 3, for every a, either ∑ i∈Na x R i,a ∈ [(1 + )−2Ca, (1 + )2Ca], i.e., the advertiser budget constraint is approximately satisfied; or, we will have that βa was continuously increased/decreased by (1+ ) factor for allR iterations, so that βRa is either 1 or (1 + )−2R. Let us call the first set of advertisers where the budget constraint is approximately satisfied as E . For these advertisers, |Ca− ∑ i∈Na xi,a| ≤ 3 Ca for any ≤ 1. Also, βRa ≥ (1 + )−2R. Among the second set, let O be the set of advertisers a ∈ A with βRa = (1 + )−2R. Here, βa was continuously decreased in order to decrease the allocation, and these advertisers will be over-allocated in the end. For the remaining a /∈ E , a /∈ O, we have βRa = 1.\nUsing the upper bound from (10), and substituting the value of βRa ,\nOPTλ ≤ ∑ i,a ri,axRi,a + ∑ a∈O 2R λ(Ca − ∑ i∈Na xRi,a)\n+ ∑ a∈E 2R λ(3 Ca)− λ ∑ i,a xRi,a log(x R i,a)\nThe terms for a /∈ O, a /∈ E do not appear in above because log(1/βRa ) = log(1) = 0 for those a. Next, we relate the above upper bound to the weight and entropy of the feasible fractional matching M . First, we substitute R as:\nR = 12 λ ( 1 + λ log(N̄) ) , (11)\n(where N̄ = maxa Ca|Na| ) to decompose the above upper bound on OPTλ as:\nOPTλ ≤ ∑ i,a ri,axRi,a + ∑ a∈O (Ca − ∑ i∈Na xRi,a) (12)\n+λ log(N̄) ∑ a∈O (Ca − ∑ i∈Na xRi,a)− λ ∑ i,a xRi,a log x R i,a(13)\n+ ∑ a∈E 3 ( 1 + λ log(N̄) ) Ca (14)\nNow, matching M was created by removing ∑ i∈Na x R i,a − Ca edges from {xRi,a} for every over-allocated advertiser a ∈ O. Therefore, the second term in (12) accounts for the weight (since rmax = 1) of all edges removed, except for those in a ∈ E . Since a ∈ E can be over-allocated by at most 3 Ca, we can show that for small , almost all the decrease in the weight is accounted for, and (12) is close to weight(M):\n(12) ≤ (1 + δ2 )weight(M), when\n= rmin\n8(2 + λ log(N̄)) δ, (15)\nSimilarly, we show that the first term in (13) accounts for any increase in entropy due to removal of edges from xRi,a, so that\n(13) ≤ λEntropy(xMi,a) := λ ∑ i,a x R i,a log(1/xRi,a)\nHere, we utilize the fact that in Algorithm 2 does not decrease very small assignments: it only decreases assignment of edges while xRi,a ≥ Ca/|Na|. Finally, for small , the last part (14) is negligible compared to weight(M). Specifically, for the choice of in (15),\n(14) ≤ δ2 weight(M).\nCombining these observations,\nOPTλ ≤ (1 + δ)weight(M) + λEntropy(M)\nFinally, from (11), substituting value of from (15), we have the number of iterations\nR = 1\n2 λ\n( 1 + λ log(N̄) ) ≤ 8\nrmin (1 + λ log(N̄))2 λδ\nThen, the theorem statement is obtained on substituting back rmin/rmax for rmin."
  }],
  "year": 2018,
  "references": [{
    "title": "Fast algorithms for online stochastic convex programming",
    "authors": ["S. Agrawal", "N.R. Devanur"],
    "venue": "In Proceedings of the Twenty-Sixth Annual ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2015
  }, {
    "title": "A dynamic near-optimal algorithm for online linear programming",
    "authors": ["S. Agrawal", "Z. Wang", "Y. Ye"],
    "venue": "Computing Research Repository,",
    "year": 2009
  }, {
    "title": "Bipartite matching and vertex covers. http://www.princeton.edu/ ̃amirali/ Public/Teaching/ORF523/S16/ORF523_ S16_Lec6_gh.pdf",
    "authors": ["A. Ahmadi", "G. Hall"],
    "year": 2018
  }, {
    "title": "Diverse weighted bipartite b-matching",
    "authors": ["F. Ahmed", "J.P. Dickerson", "M. Fuge"],
    "venue": "In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence,",
    "year": 2017
  }, {
    "title": "Linear programming in the semistreaming model with application to the maximum matching problem",
    "authors": ["K.J. Ahn", "S. Guha"],
    "venue": "Inf. Comput.,",
    "year": 2013
  }, {
    "title": "The multiplicative weights update method: a meta-algorithm and applications",
    "authors": ["S. Arora", "E. Hazan", "S. Kale"],
    "venue": "Theory of Computing,",
    "year": 2012
  }, {
    "title": "Stateless distributed gradient descent for positive linear programs",
    "authors": ["B. Awerbuch", "R. Khandekar"],
    "venue": "SIAM J. Comput.,",
    "year": 2009
  }, {
    "title": "Densest subgraph in streaming and mapreduce",
    "authors": ["B. Bahmani", "R. Kumar", "S. Vassilvitskii"],
    "venue": "Proc. VLDB Endow.,",
    "year": 2012
  }, {
    "title": "Efficient primaldual graph algorithms for mapreduce",
    "authors": ["B. Bahmani", "A. Goel", "K. Munagala"],
    "venue": "In International Workshop on Algorithms and Models for the Web-Graph,",
    "year": 2014
  }, {
    "title": "The santa claus problem",
    "authors": ["N. Bansal", "M. Sviridenko"],
    "venue": "In Proceedings of the Thirty-eighth Annual ACM Symposium on Theory of Computing,",
    "year": 2006
  }, {
    "title": "A study of compact reserve pricing languages",
    "authors": ["M. Bateni", "H. Esfandiari", "V.S. Mirrokni", "S. Seddighin"],
    "year": 2017
  }, {
    "title": "Shape matching and object recognition using shape contexts",
    "authors": ["S. Belongie", "J. Malik", "J. Puzicha"],
    "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
    "year": 2002
  }, {
    "title": "Fast algorithms for finding matchings in lopsided bipartite graphs with applications to display ads",
    "authors": ["D. Charles", "M. Chickering", "N.R. Devanur", "K. Jain", "M. Sanghi"],
    "venue": "In Proceedings of the 11th ACM conference on Electronic commerce,",
    "year": 2010
  }, {
    "title": "The adwords problem: Online keyword matching with budgeted bidders under random permutations",
    "authors": ["N. Devanur", "T. Hayes"],
    "venue": "In EC, pp",
    "year": 2009
  }, {
    "title": "Near optimal online algorithms and fast approximation algorithms for resource allocation problems",
    "authors": ["N.R. Devanur", "K. Jain", "B. Sivan", "C.A. Wilkens"],
    "venue": "In Proceedings of the 12th ACM Conference on Electronic Commerce, EC",
    "year": 2011
  }, {
    "title": "Co-clustering documents and words using bipartite spectral graph partitioning",
    "authors": ["I.S. Dhillon"],
    "venue": "In Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2001
  }, {
    "title": "Linear-time approximation for maximum weight matching",
    "authors": ["R. Duan", "S. Pettie"],
    "venue": "J. ACM,",
    "year": 2014
  }, {
    "title": "Online ad assignment with free disposal",
    "authors": ["J. Feldman", "N. Korula", "V. Mirrokni", "S. Muthukrishnan", "M. Pal"],
    "venue": "In WINE,",
    "year": 2009
  }, {
    "title": "Online stochastic packing applied to display ad allocation",
    "authors": ["J. Feldman", "M. Henzinger", "N. Korula", "V.S. Mirrokni", "C. Stein"],
    "venue": "In ESA,",
    "year": 2010
  }, {
    "title": "Faster and simpler algorithms for multicommodity flow and other fractional packing problems",
    "authors": ["N. Garg", "J. Konemann"],
    "venue": "SIAM Journal on Computing,",
    "year": 2007
  }, {
    "title": "How the experts algorithm can help solve lps online",
    "authors": ["A. Gupta", "M. Molinaro"],
    "venue": "Math. Oper. Res.,",
    "year": 2016
  }, {
    "title": "A n5/2 algorithm for maximum matchings in bipartite",
    "authors": ["J.E. Hopcroft", "R.M. Karp"],
    "venue": "In Proceedings of the 12th Annual Symposium on Switching and Automata Theory (Swat 1971),",
    "year": 1971
  }, {
    "title": "Loopy belief propagation for bipartite maximum weight b-matching",
    "authors": ["B. Huang", "T. Jebara"],
    "venue": "In Artificial Intelligence and Statistics, pp",
    "year": 2007
  }, {
    "title": "B-matching for spectral clustering",
    "authors": ["T. Jebara", "V. Shchogolev"],
    "venue": "Machine Learning: ECML",
    "year": 2006
  }, {
    "title": "Secondary-structure matching (SSM), a new tool for fast protein structure alignment in three dimensions",
    "authors": ["E. Krissinel", "K. Henrick"],
    "venue": "Acta Crystallographica Section D,",
    "year": 2004
  }, {
    "title": "An axiomatic theory of fairness in network resource allocation",
    "authors": ["T. Lan", "D.T.H. Kao", "M. Chiang", "A. Sabharwal"],
    "venue": "In INFOCOM 2010. 29th IEEE International Conference on Computer Communications,",
    "year": 2010
  }, {
    "title": "Adwords and generalized online matching",
    "authors": ["A. Mehta", "A. Saberi", "U. Vazirani", "V. Vazirani"],
    "venue": "J. ACM,",
    "year": 2007
  }, {
    "title": "Adaptive multi-attribute diversity for recommender systems",
    "authors": ["T.D. Noia", "J. Rosati", "P. Tomeo", "E.D. Sciascio"],
    "venue": "Inf. Sci.,",
    "year": 2017
  }, {
    "title": "Text matching as image recognition",
    "authors": ["L. Pang", "Y. Lan", "J. Guo", "J. Xu", "S. Wan", "X. Cheng"],
    "venue": "In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,",
    "year": 2016
  }, {
    "title": "Fast approximation algorithms for fractional packing and covering problems",
    "authors": ["S.A. Plotkin", "D.B. Shmoys", "É. Tardos"],
    "venue": "Math. Oper. Res.,",
    "year": 1995
  }, {
    "title": "Promoting diversity in recommendation by entropy regularizer",
    "authors": ["L. Qin", "X. Zhu"],
    "venue": "IJCAI",
    "year": 2013
  }, {
    "title": "Optimal online assignment with forecasts",
    "authors": ["E. Vee", "S. Vassilvitskii", "J. Shanmugasundaram"],
    "venue": "In EC, pp",
    "year": 2010
  }, {
    "title": "Fairness is an emergent selforganized property of the free market for labor",
    "authors": ["V. Venkatasubramanian"],
    "year": 2010
  }],
  "id": "SP:3a24c07e1c4e9d811a819835f04e965fd653231b",
  "authors": [{
    "name": "Shipra Agrawal",
    "affiliations": []
  }, {
    "name": "Vahab Mirrokni",
    "affiliations": []
  }, {
    "name": "Morteza Zadimoghaddam",
    "affiliations": []
  }],
  "abstractText": "Inspired by many applications of bipartite matching in online advertising and machine learning, we study a simple and natural iterative proportional allocation algorithm: Maintain a priority score βa for each node a ∈ A on one side of the bipartition, initialized as βa = 1. Iteratively allocate the nodes i ∈ I on the other side to eligible nodes in A in proportion of their priority scores. After each round, for each node a ∈ A, decrease or increase the score βa based on whether it is overor underallocated. Our first result is that this simple, distributed algorithm converges to a (1 − )-approximate fractional b-matching solution in O( logn 2 ) rounds. We also extend the proportional allocation algorithm and convergence results to the maximum weighted matching problem, and show that the algorithm can be naturally tuned to produce maximum matching with high entropy. High entropy, in turn, implies additional desirable properties of this matching, e.g., it satisfies certain diversity and fairness (aka anonymity) properties that are desirable in a variety of applications in online advertising and machine learning.",
  "title": "Proportional Allocation:  Simple, Distributed, and Diverse Matching with High Entropy "
}