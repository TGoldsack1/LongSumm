{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Semidefinite relaxation is the technique of replacing a broad range of non-convex optimization problems involving a vector of (possibly discrete) variables with convex problems involving matrices. The relaxed convex problem is then solved to global optimality, and the solution is used to extract a global minimizer of the original non-convex problem. Unfortunately, convexity comes at a steep cost: semidefinite relaxation squares the dimensionality of the problem, resulting in formulations that are convex but computationally intractable in many situations. In fact, the increase in dimensionality, which is called lifting, often prevents the use of this technique in machine learning and computer vision applications involving thousands to millions of variables.\nThis article studies convex relaxation for phase retrieval, a canonical non-convex problem that can be solved via semidefinite relaxation. We present a relaxation approach that convexifies the problem without lifting, i.e., it solves the problem in its original, low-dimensional space.\n*Equal contribution 1University of Maryland 2Cornell University. Correspondence to: Tom Goldstein <tomg at cs.umd.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s)."
  }, {
    "heading": "2. Phase Retrieval Problems",
    "text": "Phase retrieval deals with the recovery of an n-dimensional signal x0 ∈ Hn, with H either R or C, from m ≥ n magnitude measurements of the form (Candès et al., 2013)\nbi = |〈ai,x0〉|, i = 1, 2, . . . ,m, (1)\nwhere ai ∈ Hn, and i = 1, 2, . . . ,m are the (known) measurement vectors. Because of the nonlinearity caused by measuring the magnitude of the linear terms in (1), the phase retrieval problem is non-convex.\nA variety of algorithms exist for finding x0 in (1). Classical methods, such as the Gerchberg-Saxton and Feinup algorithms, search for a solution via alternating least-squares steps that are efficient when the measurement ensemble {ai} forms a tight frame (e.g., a collection of Fourier matrices).\nMore recently, there has been significant interest in convex methods for phase retrieval that provably find global solutions without the danger of getting trapped in local minima. These methods, including PhaseLift (Candès et al., 2013) and its dual formulation PhaseCut (Waldspurger et al., 2015), rely on semidefinite relaxation and replace the unknown n-dimensional vector x with a (much larger) n× n matrix of unknowns that is recovered using semi-definite programming. While such methods come with strong theoretical guarantees and do not get trapped in local minima, they require lifting (semidefinite relaxation squares the number of unknowns), which makes this approach intractable for real-world image processing applications involving thousands or millions of variables. As a result, there has been a flurry of interest in global convergence properties of nonconvex solvers that operate in the original feature space, such as the methods in (Netrapalli et al., 2013; Schniter & Rangan, 2015; Candès et al., 2015; Chen & Candès, 2015; Wang et al., 2016). While these methods come with theoretical guarantees, non-convexity makes it difficult to combine them with commonly used regularizers, and typically precludes the use of sophisticated optimization methods that can handle constraints, non-differentiable terms, etc.\nWe note that the PhaseMax formulation has also been proposed by (Bahmani & Romberg, 2016) and was recently analyzed by (Hand & Voroninski, 2016). We discuss and compare these results in Section 8.2."
  }, {
    "heading": "3. A Word on Notation",
    "text": "Scalars are lower-case letters, and vector quantities are boldface, lower-case letters. Matrices are boldface uppercase letters, and sets are written using upper-case script font. We denote the inner product between the vectors x,y ∈ Hn as 〈x,y〉 = xTy, and xT is the transpose in the real case or the Hermitian transpose in the complex case. We denote the real part of the inner product as 〈x,y〉< = <(xTy) and the imaginary part as 〈x,y〉= so that 〈x,y〉 = 〈x,y〉< + j〈x,y〉= with j2 = −1. The non-negative reals are denoted R+0 . We denote the unit sphere embedded in Rn as Sn−1R , and use Sn−1C for the sphere in complex space. To address both of these cases at once, we will often write\nSn−1H = {x ∈ Hn | ‖x‖2 = 1},\nwhereH ∈ {R,C} is either the real or complex numbers."
  }, {
    "heading": "4. Proposed Relaxation",
    "text": "We propose PhaseMax, a formulation of the phase retrieval problem that avoids lifting. Put simply, PhaseMax relaxes the non-convex equality constraints |〈ai,x〉| = bi into convex inequality constraints of the form |〈ai,x〉| ≤ bi. The resulting convex problem can then be solved using linear programming in the real case or using second-order cone programming in the complex case.\nAt first glance, the proposed relaxation seems too simplistic to recover x0. Indeed, the relaxed system of inequalities has a trivial solution: the all-zeros vector. To obtain a meaningful solution, we need to force the solution vector to lie on the boundary of the constraint set, where the inequality constraints hold with equality. To force the solution to lie on the boundary, we rely on some intelligent “guess” x̂ ∈ Hn of the solution to (1); we will discuss methods for producing such guesses in Section 8.1. We then find the feasible point that lies as far in the direction of x̂ ∈ Hn as possible. This results in the convex optimization problem\n(PhaseMax)\n{ maximize\nx∈Hn 〈x, x̂〉<\nsubject to |〈ai,x〉| ≤ bi, i = 1, . . . ,m.\nThe key idea behind PhaseMax is that the objective forces the solution vector to lie along the boundary of the constraint set, where the constraints are active. Evidently, if all of the constraints are active at this solution, then we have recovered a solution to the original non-convex problem (1).\nQuite surprisingly, the PhaseMax relaxation provably recovers the true solution to (1) in many situations. In particular, we have the following main result: Theorem 1. Consider the case of recovering a signal x ∈ Hn fromm measurements of the form (1) with measure-\nment vectors ai, i = 1, 2, . . . ,m, sampled independently and uniformly from the unit sphere. Let\nangle(x0, x̂) = arccos ( 〈x0, x̂〉< ‖x0‖2‖x̂‖2 ) be the angle between the true vector x0 and the “guess” x̂, and define the constant\nα = 1− 2 π angle(x0, x̂)\nthat measures the accuracy of our guess. If H = C, then whenever αm > 4n − 1, the probability that PhaseMax recovers the true signal x0 is at least\n1− exp ( − (αm−4n) 2\n4m\n) . (2)\nSimilar results for the real case are derived below."
  }, {
    "heading": "5. Formulation using Geometric Probability",
    "text": "Conditions for which PhaseMax enables exact recovery can be formulated as a classical problem from geometric probability involving random hemispheres, or “caps.” We begin with a few simple definitions. Recall that we use Sn−1H to denote the unit sphere embedded in Hn. Given a vector a ∈ Sn−1H , the hemisphere cap centered at a is CH(a) = {δ ∈ Sn−1H | 〈a, δ〉< ≥ 0}. (3) This cap contains all vectors that form an acute angle with a.\nWe also need the concept of aligned vectors. A complex vector a ∈ Sn−1H is said to be aligned with x ∈ Sn−1H if 〈x,a〉 ∈ R+0 . In words, two vectors are aligned if their inner product is real valued and non-negative. Given a vector x and a measurement vector a, we have |〈ai,x〉| = |〈ωai,x0〉| for any unit-magnitude ω ∈ C. For this reason, we will often consider the set {ãi} = {sign ( 〈ai,x0〉 ) ai} of measurement vectors aligned with x0 without loss of generality. Note that replacing {ai} with {ãi} in PhaseMax does not change the feasible set, and thus does not impact the recovered solution. Finally, observe that a solution x? to (PM) must be aligned with x̂. This is because 〈ωx?, x̂〉 = |〈x?, x̂〉|when ω = sign(〈x?, x̂〉) . It follows that x? cannot be optimal unless sign(〈x?, x̂〉) = 1. We are now ready to formulate the following exact recovery condition for PhaseMax. Theorem 2. Consider the recovery of a vector x0 using PhaseMax with guess x̂. Assume, without loss of generality, that x̂ and the measurement ensemble {ai} are aligned with x0. Let D = { δ |〈δ, x̂〉 ∈ R+0 } be the set of unit vectors aligned with x̂. Then, x0 is the unique solution of PhaseMax if\nD ⊂ m⋃ i=1 CH(ai). (4)\nProof. Suppose the conditions of this theorem hold, and let x? be a solution to (PM). Since x0 is in the feasible set, x? must produce an objective value at least as large as x0, and so 〈x?, x̂〉 ≥ 〈x0, x̂〉. We know that x? is aligned with x̂. Since x0 is assumed to be aligned with x̂, the vector ∆ = x? − x0 is also aligned with x̂, and satisfies\n〈∆, x̂〉 = 〈x?, x̂〉 − 〈x0, x̂〉 ≥ 0. Since x? is a feasible solution for (PM), we have\n|〈ai,x0 + ∆〉|2 = |〈ai,x0〉|2+ 2[〈ai,x0〉∗〈ai,∆〉]< + |〈ai,∆〉|2 ≤ b2i , ∀i. (5)\nNow, recall that |〈ai,x0〉|2 = b2i , and ai is aligned with x0. Hence, we get\n〈ai,∆〉< ≤ − 1\n2 |〈ai,∆〉|2 ≤ 0, ∀i. (6)\nIf ‖∆‖2 > 0, then we see from (6) that the unit-length vector δ = ∆/‖∆‖2 satisfies δ 6∈ C(ai),∀i, which contradicts the covering condition (4). It follows that ‖∆‖2 = 0 and x? = x0."
  }, {
    "heading": "6. Sphere Covering Results",
    "text": "Theorem 2 states that exact recovery of x0 occurs when the measurement ensemble {ai} is aligned with x0, and the set D is covered by the caps {CH(ai)}. We now study the probability that this condition holds. To do so, we need a few elementary sphere covering results. Our proof builds on the following simple result. Lemma 1. Suppose we slice the sphere Sn−1R ⊂ Rn using k planes through the origin. Then we divide the sphere into as most\nr(n, k) = 2 n−1∑ i=0 ( k − 1 i ) (7)\nregions.\nProof. The proof is by induction. As a base case, we have r(n, 1) = 2 and r(2, k) = 2k for k ≥ 1. Now suppose we have a sphere Sn−1R in n dimensions sliced by k − 1 planes into r(n, k − 1) “original” regions. Consider the effect of adding a kth plane, pk. The number of new regions created is equal to the number of original regions that are intersected by pk. To count the number of new regions, we project the k − 1 original normal vectors into pk, and count the minimal number of regions formed inside pk by the resulting projected planes, which is at most r(n− 1, k− 1). Adding this to the number of original regions yields\nr(n, k) = r(n, k − 1) + r(n− 1, k − 1). We leave it to the reader to verify that (7) satisfies this recurrence relation.\nLemma 1 appears to have been first proved by (Schläfli, 1953), and simple induction arguments can be found in (Wendel, 1962; Gilbert, 1965; Füredi, 1986).\nBefore we attack the problem of when (4) holds, we begin with a simpler question: “how often is a sphere covered by caps with centers chosen at random from the sphere?” This question has been studied in detail by Gilbert (Gilbert, 1965) in the case n = 3. For our purposes, we need to study the covering probability in the more general case when caps are only chosen from a subset of the sphere, and the sphere can have arbitrarily high dimension. We show below that calculating this probability is easy when the caps are chosen from a symmetric subset of the sphere. We say that the set A is symmetric if, for all x ∈ A, we also have −x ∈ A. A probability measure defined over A is symmetric if the measure of a is the same as −a for every a ⊂ A. Lemma 2. Consider some non-empty symmetric set A ⊂ Sn−1R . Choose some set of mA measurements {ai}mAi=1 at random from A using a symmetric measure. Then, the caps {CR(ai)} cover the sphere Sn−1R with probability\npcover(mA, n) ≥ 1− 1\n2mA−1 n−1∑ k=0 ( mA − 1 k ) .\nThis is the probability of getting n or more heads when flipping mA − 1 fair coins.\nProof. Let {a′i} be a collection of m i.i.d. vectors sampled from A using a symmetric measure. Define ai = cia′i, where {ci} are i.i.d. Bernoulli variables that take value +1 or −1 with probability 12 . Clearly, the random vectors {ai} are i.i.d. with the same distribution as {a′i}. Consider the set⋂\ni CR(−ai) = ⋂ i CR(−cia′i), (8)\nwhich contains all points not covered by the caps {CR(ai)}. The caps {CR(ai)} cover the sphere whenever the intersection (8) is empty. There are 2mA such intersections that can be formed, one for each choice of the sequence {ci}. Now, from Lemma 1, we know that the mA random planes{ {x | 〈ai,x〉 = 0} } divide the sphere into at most r(n,mA) non-empty regions. Each of these regions corresponds to the intersection (8) for one possible choice of {ci}. Therefore, of the 2mA possible intersections, at most r(n,mA) of them are non-empty. Since each intersection is equally likely, the probability of covering the sphere is at least\npcover(mA, n) ≥ 1− r(n,mA)\n2mA .\nRemark: It can be shown that the bound in Lemma 1 is tight/exact when the slicing planes are chosen from a continuous probability distribution. Similarly, the bound in Lemma 2 is exact when the set {ai} is sampled from a continuous distribution over A. We are now ready to present our main result. Exact recovery theorems for PhaseMax will follow immediately from the following geometric theorem. The result considers the case where the measurement vectors are drawn from only one hemisphere. Lemma 3. Consider two vectors x,y ⊂ Sn−1R , and the caps CR(x) and CR(y). Let α = 1 − 2π angle(x,y) be a measure of the similarity between the vectors x and y.Draw some collection {ai ∈ CR(x)}mi=1 of m vectors uniformly from CR(x) so that α(m− 1) > 2n. Then,\nCR(y) ⊂ ⋃ i CR(ai)\nholds with probability at least pcover(m,n;x,y) ≥ 1− exp ( − (αm− α− 2n) 2\n2m− 2\n) .\nProof. To simplify notation, we assume y = [1, 0, . . . , 0]T . Because of rotational symmetries this does not change the generality of our proof. Consider the reflection of x over y given by x̃ = [x1,−x2, . . . ,−xn]T . Suppose we have some collection {ai} independently and uniformly distributed on the entire sphere. Consider the collection of vectors\na′i =  ai, if 〈ai,x〉 ≥ 0 (9) ai − 2〈ai,y〉y, if 〈ai,x〉 < 0, 〈ai, x̃〉 < 0 (10) −ai, if 〈ai,x〉 < 0, 〈ai, x̃〉 ≥ 0. (11)\nThe mapping ai → a′i maps the half sphere {a | 〈a,x〉 < 0} onto the half sphere {a | 〈a,x〉 > 0} using a combination of reflections and translations (see Figure 1). This makes the mapping ai → a′i onto and (piecewise) isometric, and so {a′i} will be uniformly distributed over the half sphere {a | 〈a,x0〉 > 0} whenever {ai} is independently and uniformly distributed over the entire sphere.\nConsider the “hourglass” shaped, symmetric set\nA = {a | 〈a,x〉 ≥ 0, 〈a, x̃〉 ≥ 0} ∪ {a | 〈a,x〉 ≤ 0, 〈a, x̃〉 ≤ 0}.\nWe claim that CR(y) ⊂ ⋃ i CR(a′i) whenever\nSn−1R ⊂ ⋃\nai∈A CR(ai). (12)\nIn words, if the caps defined by the subset of {ai} in A cover the entire sphere, then the caps {CR(a′i)} (which have\ncenters in CR(x)) not only cover CR(x), but also cover the nearby cap CR(y). To justify this claim, suppose that (12) holds. Choose some δ ∈ CR(y). This point is covered by some cap CR(ai) with ai ∈ A. If 〈ai,x〉 ≥ 0, then ai = a′i and δ is covered by CR(a′i). If 〈ai,x〉 < 0, then\n〈δ,a′i〉 = 〈δ,ai − 2〈ai,y〉y〉 = 〈δ,ai〉 − 2〈ai,y〉〈δ,y〉 ≥ 〈δ,ai〉 ≥ 0.\nNote we have used the fact that 〈δ,y〉 is real-valued and nonnegative because δ ∈ CR(y). We have also used 〈ai,y〉 = [ai]1 = 1 2 (〈ai,x〉 + 〈ai, x̃〉) < 0, which follows from the definition of x̃ and the definition of A. Since 〈δ,a′i〉 ≥ 0, we have δ ∈ CR(a′i), which proves our claim. We can now see that the probability that CR(y) ⊂ ⋃ i CR(a′i) is at least as high as the probability that (12) holds. Let pcover(m,n;x,y |mA) denote the probability of covering C(y) conditioned on the number mA of points lying in A. From Lemma 2, we know that pcover(m,n;x,y |mA) ≥ pcover(mA, n). As noted in Lemma 2, this is the chance of turning up n or more heads when flippingmA−1 fair coins, which is one coin for every measurement ai in A. This probability pcover(m,n;x,y) is\npcover(m,n;x,y) = EmA [pcover(m,n;x,y |mA)] ≥ EmA [pcover(mA, n)].\nLet’s evaluate this expectation. The region A is defined by two planes that intersect at an angle of β = angle(x, x̃) = 2 angle(x,y). The probability of a random point ai lying in A is given by α = 2π−2β2π = 1− 2β π , which is the fraction of the unit sphere that lies either above or below both planes. The probability of a measurement ai contributing to the heads count is half the probability of it lying in A, or 12α.\nThe probability of turning up n or more heads is therefore given by\npcover(m,n;x,y) = (13)\n1− n−1∑ k=0 ( 1 2 α )k ( 1− 1 2 α )m−k−1( m− 1 k ) .\nOur final result is obtained by applying Hoeffding’s inequality to (13)."
  }, {
    "heading": "7. Recovery Guarantees for PhaseMax",
    "text": "Using the covering result of Lemma 3, together with the covering formulation of the exact recovery condition (4), proving exact recovery of PhaseMax is now rather straightforward. We begin with the real-valued case.\nTheorem 3. Consider the case of recovering a real-valued signal x0 ∈ Rn from m measurements of the form (1) with i.i.d. and uniform vectors {ai ∈ Sn−1R }. PhaseMax recovers the true signal x0, with probability at least\npR(m,n) ≥ 1− exp (−(αm− α− 2n)2\n2m− 2\n) ,\nwhere α = 1− 2π angle(x0, x̂) and α(m− 1) > 2n.\nProof. Consider the set of m independent and uniformly sampled measurements {ai ∈ Sn−1R }mi=1. The aligned vectors {ãi = phase(〈ai,x0〉)ai} are uniformly distributed over the half sphere CR(x0). Exact reconstruction happens when the condition in Lemma 2 holds. To bound this probability, we invoke Lemma 3 with x = x0 and y = x̂.\nWe have an analogous result in the complex case.\nTheorem 4. Consider the case of recovering a complexvalued signal x0 ∈ Rn from m measurements of the form (1) with i.i.d. and uniform vectors {ai ∈ Sn−1R }. PhaseMax recovers the true signal x0, with probability at least\npC(m,n) ≥ 1− exp (−(αm− 4n)2\n4m\n) ,\nwhere α = 1− 2π angle(x0, x̂) and αm > 4n+ 1.\nProof. Let {ãi} = {phase(〈ai,x0〉)ai} be aligned measurement vectors. Define the half sphere of aligned ascent directions\nDC = {δ ∈ Sn−1C | 〈δ, x̂〉 ∈ R+0 }.\nBy Lemma 2, PhaseMax recovers x0 if\nDC ⊂ ⋃ i CC(ãi). (14)\nLet us bound the probability of this event. Consider the set A = {δ | 〈δ,x0〉= = 0}. We now claim that (14) holds whenever\nCC(x̂) ∩ A ⊂ ⋃ i CC(ãi). (15)\nTo prove this claim, consider some δ ∈ DC. To keep notation light, we will assume without loss of generality that ‖x0‖2 = 1. Form the vector δ′ = δ + j〈δ,x0〉= x0, which is the projection of δ onto A. Suppose now that (15) holds. Since δ′ ∈ CC(x̂) ∩ A, there is some i with δ′ ∈ CC(ãi). But then\n0 ≤ 〈δ′, ãi〉< = 〈δ, ãi〉< + 〈j〈δ,x0〉= x0, ãi〉< (16) = 〈δ, ãi〉<. (17)\nWe have used the fact that 〈j〈δ,x0〉= x0, ãi〉 = j〈δ,x0〉=〈ãi,x0〉, which is imaginary valued and thus has no real component. We see that δ ∈ CC(ãi), and the claim is proved.\nWe now know that exact reconstruction happens whenever condition (15) holds. Note that the sphere Sn−1C is isomorphic to S2n−1R , and the set A is isomorphic to the sphere S2n−2R . The aligned vectors {ãi} are uniformly distributed over a half sphere in CC(x0) ∩ A, which is isomorphic to the upper half sphere in S2n−2R . The probability of these vectors covering the cap CC(x̂) ∩ A is thus given by pcover(m, 2n− 1;x0, x̂) from Lemma 3, which is at least\n1− exp (−(αm− α− 4n+ 2)2\n4m− 4\n) .\nWe can simplify this by using the fact that α < 1. We also throw away the small constants in the numerator and denominator, which weakens the bound very slightly but tidies up the result."
  }, {
    "heading": "8. Experiments and Discussion",
    "text": ""
  }, {
    "heading": "8.1. Initialization Methods",
    "text": "A variety of methods exist for generating the initial guess x0. The simplest approach is to use a random vector; see (Goldstein & Studer, 2016) for a corresponding analysis and exact recovery proof in this case. A more powerful method is the truncated spectral initializer (Chen & Candès, 2015), which is a refinement of the method put forward in (Netrapalli et al., 2013). A detailed analysis of such initializers is provided in (Lu & Li, 2017). As proved in Prop. 8 of (Chen & Candès, 2015), for any δ < √ 2, there is a constant c0 such that, with probability exceeding 1 − exp(−c0m), a unit-length version of the approximation vector x̂ computed by the truncated spectral initializer satisfies 1 − δ22 ≤ |〈x0, x̂〉|, provided that m > c1n for\nsome constant c1 > 0. This implies that the approximation accuracy satisfies\nα =1− 2 π angle(x0, x̂)\n≥ 1− 2 π arccos\n( 1− δ 2\n2\n) > 0 (18)\nwith high probability.\nThis motivates the following process that recovers x0 using a number of measurements that grows linearly with n. First, choose some δ < √ 2 and calculate α from (18). Next, generate a spectral initializer x̂ using c1 random Gaussian measurements. This initializer has accuracy α with high probability. Finally, using 5n/α (the constant in this expression must be larger than 4 to guarantee recovery with high probability) additional random Gaussian measurements, recover the vector x0 using PhaseMax. This recovery step succeeds with high probability when n is large. This process recovers x0 using (5/α+c1)nmeasurements, which is linear in n. For a more detailed analysis with no unspecified constants, see (Goldstein & Studer, 2016).\nA simpler recovery approach only samples max{5/α, c1}n measurements, and then uses the same set of measurements for both the initialization and recovery. This process works well in practice, and is used in the experiments below. Technically, our results assume the measurements {ai} are independent of x̂, and so our theory does not formally guarantee convergence in this case. For an analysis that considers the case where {ai} and x̂ are dependent, we refer to the analysis in (Bahmani & Romberg, 2016)."
  }, {
    "heading": "8.2. Comparison to Other Phase Retrieval Methods",
    "text": "We compare PhaseMax with other recovery methods, including lifted convex methods and non-convex approaches. Table 1 lists the sample complexity (measurements needed to achieve exact recovery with 0.5 probability) of various phase retrieval methods as a function of the number of un-\nknowns n. We also list the probability of reconstruction from m measurements. We see that PhaseMax requires the same sample complexity (O(n)) as compared to PhaseLift, TWF, and TAW, when used together with the truncated spectral initializer proposed in (Candès & Li, 2014).\nThe recovery bounds for all other methods require unspecified constants (ci in Table 1) that are generally extremely large and require a lower bound on the initialization accuracy. In contrast, the bounds for PhaseMax contain no unspecified constants, explicitly depend on the approximation factor α, and our new analytical approach yields extremely sharp bounds (see below for the details).\nWe also compare in Table 1 to a different analysis of the PhaseMax formulation by (Bahmani & Romberg, 2016) that appeared shortly before our own, and to a later analysis by (Hand & Voroninski, 2016). By using methods from machine learning theory, (Bahmani & Romberg, 2016) produce exact reconstruction bounds that, for a specified value of α, are uniform with respect to the initialization x̂, and thus guarantee exact signal recovery in the case that x̂ is dependent on the measurement vectors. The analysis presented here is weaker in the sense that is does not have this uniformity property, but stronger in the sense that it produces tighter bounds without unspecified constants. The bounds by (Hand & Voroninski, 2016) require unspecified constants, but the authors show that PhaseMax can be analyzed using standard concentration of measure arguments."
  }, {
    "heading": "8.3. Tightness of Guarantees",
    "text": "By using strong concentration bounds for the unit sphere, our analysis produces sharp recovery guarantees that lie close to behavior observed in practice. In Figure 2, we use random Gaussian test problems and the accelerated gradientbased solver described in (Goldstein et al., 2014) to plot the empirical and theoretical probabilities of exact signal recovery for n = 100 and n = 500 measurements while varying the accuracy β = angle(x̂,x0) of the initial guess.\nWe declared exact recovery when the relative error of the recovered signal fell below 10−5.\nOur theoretical bounds tend to agree fairly closely with observations, and generally require fewer than 50% more measurements than is needed in practice. We also observe a sharp phase transition between inaccurate and accurate recovery, as predicted by our theory."
  }, {
    "heading": "8.4. Performance Limits of PhaseMax",
    "text": "To compare PhaseMax to other phase retrieval methods, we observe the accuracy of signal reconstruction as a function of the number of measurements. We emphasize that this comparison is only done in the random Gaussian problem setting, and results may differ with different types of signal, measurement, and noise models. The sole purpose of this experiment is to explore the efficacy and limits of PhaseMax, and to test the tightness of the predicted recovery guarantees. For an extensive comparison between existing methods, see (Waldspurger et al., 2015; Jaganathan et al., 2015)). We compare the Gerchberg-Saxton algorithm (Gerchberg & Saxton, 1972), the Fienup algorithm (Fienup, 1982), the truncated Wirtinger flow (Chen & Candès, 2015), and PhaseMax. All methods were initialized using the truncated spectral initializer (Chen & Candès, 2015).\nWe also run simulations using the semidefinite relaxation method PhaseLift (Candès et al., 2013) implemented using a proximal gradient solver. PhaseLift, and its equivalent dual formulation PhaseCut (Waldspurger et al., 2015), is the only convex alternative to PhaseMax. However, unlike PhaseMax, PhaseLift/PhaseCut “lifts” the problem to a higher\ndimension and squares the number of unknowns.\nFigure 3 reveals that PhaseMax requires larger oversampling ratios m/n to enable faithful signal recovery compared to non-convex phase-retrieval algorithms that operate in the original signal dimension. This is because the truncated spectral initializer requires oversampling ratios of about six or higher to yield sufficiently accurate approximation vectors x̂ that enable PhaseMax to succeed. While PhaseMax does not achieve exact reconstruction with the lowest number of measurements, it is convex, operates in the original signal dimension, can be implemented via solvers for Basis Pursuit, and comes with sharp performance guarantees that do not sweep constants under the rug (cf. Figure 2).\nThe convexity of PhaseMax enables a natural extension to sparse phase retrieval (Jaganathan et al., 2013; Shechtman et al., 2014) or other signal priors (e.g., total variation, group sparsity, or bounded infinity norm) that can be formulated with convex functions. Such non-differentiable priors cannot be efficiently minimized using simple gradient descent methods (which form the basis of Wirtinger or amplitude flow, and many other methods), but can potentially be solved using standard convex solvers when combined with the PhaseMax formulation."
  }, {
    "heading": "9. Conclusions",
    "text": "We have proposed a convex relaxation for phase retrieval problems called PhaseMax that does not require lifting. Using methods from geometric probability, we have provided tight bounds on the probability of correct signal recovery.\nThe proposed problem and its analysis also represents a radical departure, both in theory and algorithms, from conventional methods for convex or semidefinite relaxation. By providing a convex relaxation for phase retrieval in the native parameter space, our approach opens the door for using a broad range of convex optimization routines, regularizers, and priors to solve phase retrieval or related problems in machine learning, computer vision, or signal processing.\nFinally, the new analytical methods used in this paper have recently been used to prove tight reconstruction bounds for bi-convex problems outside the field of phase retrieval (Aghasi et al., 2017), and may be broadly applicable to a wide range of signal processing problems."
  }, {
    "heading": "Acknowledgments",
    "text": "The work of T. Goldstein was supported in part by the US National Science Foundation (NSF) under grant CCF1535902, by the US Office of Naval Research under grant N00014-17-1-2078, and by the Sloan Foundation. The work of C. Studer was supported in part by Xilinx, Inc. and by the US NSF under grants ECCS-1408006, CCF-1535897, and CAREER CCF-1652065."
  }],
  "year": 2017,
  "references": [{
    "title": "Branchhull: Convex bilinear inversion from the entrywise product of signals with known signs",
    "authors": ["A. Aghasi", "A. Ahmed", "P. Hand"],
    "venue": "arXiv preprint :1702.04342,",
    "year": 2017
  }, {
    "title": "Phase retrieval meets statistical learning theory: A flexible convex relaxation",
    "authors": ["S. Bahmani", "J. Romberg"],
    "venue": "arXiv preprint:",
    "year": 2016
  }, {
    "title": "Solving quadratic equations via PhaseLift when there are about as many equations as unknowns",
    "authors": ["E.J. Candès", "X. Li"],
    "venue": "Found. Comput. Math.,",
    "year": 2014
  }, {
    "title": "PhaseLift: Exact and stable signal recovery from magnitude measurements via convex programming",
    "authors": ["E.J. Candès", "T. Strohmer", "V. Voroninski"],
    "venue": "Commun. Pure Appl. Math.,",
    "year": 2013
  }, {
    "title": "Phase retrieval via Wirtinger flow: Theory and algorithms",
    "authors": ["J.E. Candès", "X. Li", "M. Soltanolkotabi"],
    "venue": "IEEE Trans. Inf. Theory,",
    "year": 2015
  }, {
    "title": "Solving random quadratic systems of equations is nearly as easy as solving linear systems",
    "authors": ["Y. Chen", "E. Candès"],
    "venue": "In Adv. Neural Inf. Process. Syst.,",
    "year": 2015
  }, {
    "title": "Phase retrieval algorithms: a comparison",
    "authors": ["J.R. Fienup"],
    "venue": "Appl. Opt.,",
    "year": 1982
  }, {
    "title": "Random polytopes in the d-dimensional cube",
    "authors": ["Z. Füredi"],
    "venue": "Disc. Comput. Geom.,",
    "year": 1986
  }, {
    "title": "A practical algorithm for the determination of phase from image and diffraction plane pictures",
    "authors": ["R.W. Gerchberg", "W.O. Saxton"],
    "venue": "Optik,",
    "year": 1972
  }, {
    "title": "The probability of covering a sphere with n circular caps",
    "authors": ["E.N. Gilbert"],
    "year": 1965
  }, {
    "title": "PhaseMax: convex phase retrieval via basis pursuit",
    "authors": ["T. Goldstein", "C. Studer"],
    "venue": "arXiv preprint:",
    "year": 2016
  }, {
    "title": "A field guide to forward-backward splitting with a FASTA implementation",
    "authors": ["T. Goldstein", "C. Studer", "R. Baraniuk"],
    "venue": "arXiv preprint:",
    "year": 2014
  }, {
    "title": "Adaptive primal-dual splitting methods for statistical learning and image processing",
    "authors": ["T. Goldstein", "M. Li", "X. Yuan"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "An elementary proof of convex phase retrieval in the natural parameter space via the linear program PhaseMax",
    "authors": ["P. Hand", "V. Voroninski"],
    "venue": "arXiv preprint: 1611.03935,",
    "year": 2016
  }, {
    "title": "Sparse phase retrieval: Convex algorithms and limitations",
    "authors": ["K. Jaganathan", "S. Oymak", "B. Hassibi"],
    "venue": "In Proc. IEEE Int. Symp. Inf. Theory (ISIT),",
    "year": 2013
  }, {
    "title": "Phase transitions of spectral initialization for high-dimensional nonconvex estimation",
    "authors": ["Y.M. Lu", "G. Li"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Phase retrieval using alternating minimization",
    "authors": ["P. Netrapalli", "P. Jain", "S. Sanghavi"],
    "venue": "In Adv. Neural Inf. Process. Syst., pp",
    "year": 2013
  }, {
    "title": "Compressive phase retrieval via generalized approximate message passing",
    "authors": ["P. Schniter", "S. Rangan"],
    "venue": "IEEE Trans. Sig. Process.,",
    "year": 2015
  }, {
    "title": "GESPAR: efficient phase retrieval of sparse signals",
    "authors": ["Y. Shechtman", "A. Beck", "Y.C. Eldar"],
    "venue": "IEEE Trans. Sig. Process.,",
    "year": 2014
  }, {
    "title": "Phase recovery, maxcut and complex semidefinite programming",
    "authors": ["I. Waldspurger", "A. d’Aspremont", "S. Mallat"],
    "venue": "Math. Prog.,",
    "year": 2015
  }, {
    "title": "Solving systems of random quadratic equations via truncated amplitude flow",
    "authors": ["G. Wang", "G.B. Giannakis", "Y.C. Eldar"],
    "venue": "J. G. A problem in geometric probability. Math. Scand.,",
    "year": 1962
  }],
  "id": "SP:22049e9730e726333d1c487bd908c208666befaf",
  "authors": [{
    "name": "Tom Goldstein",
    "affiliations": []
  }, {
    "name": "Christoph Studer",
    "affiliations": []
  }],
  "abstractText": "Semidefinite relaxation methods transform a variety of non-convex optimization problems into convex problems, but square the number of variables. We study a new type of convex relaxation for phase retrieval problems, called PhaseMax, that convexifies the underlying problem without lifting. The resulting problem formulation can be solved using standard convex optimization routines, while still working in the original, lowdimensional variable space. We prove, using a random spherical distribution measurement model, that PhaseMax succeeds with high probability for a sufficiently large number of measurements. We compare our approach to other phase retrieval methods and demonstrate that our theory accurately predicts the success of PhaseMax.",
  "title": "Convex Phase Retrieval without Lifting via PhaseMax"
}