{
  "sections": [{
    "text": "Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1569–1575, Denver, Colorado, May 31 – June 5, 2015. c©2015 Association for Computational Linguistics\nUser-generated passwords tend to be memorable, but not secure. A random, computergenerated 60-bit string is much more secure. However, users cannot memorize random 60- bit strings. In this paper, we investigate methods for converting arbitrary bit strings into English word sequences (both prose and poetry), and we study their memorability and other properties."
  }, {
    "heading": "1 Introduction",
    "text": "Passwords chosen by users (e.g., “Scarlet%2”) are easy to remember, but not secure (Florencio and Herley, 2007). A more secure method is to use a system-assigned 60-bit random password, such as 0010100010100...00101001. However, this string is hard to memorize. In this paper, we convert such strings into English phrases, in order to improve their memorability, using natural language processing to select fluent passphrases.\nOur methods are inspired by an XKCD cartoon1 that proposes to convert a randomly-chosen 44-bit password into a short, nonsensical sequence of English words. The proposed system divides the 44-bit password into four 11-bit chunks, and each chunk provides an index into a 2048-word English dictionary. XKCD’s example passphrase is correct horse battery staple:\n1http://xkcd.com/936\n44-bit password English phrase --------------- -------------- 10101101010 -> correct 10010110101 -> horse 01010101010 -> battery 10110101101 -> staple\nThe four-word sequence is nonsense, but it is easier to memorize than the 44-bit string, and XKCD hypothesizes that users can improve memorability by building an image or story around the four words.\nIn this paper, we investigate other methods for converting a system-generated bit string into a memorable sequence of English words. Our methods produce whole sentences, e.g.\nFox news networks are seeking views from downtown streets.\nas well as short poems, e.g.\nDiversity inside replied, Soprano finally reside.\nWe also move to 60-bit passwords, for better security. One source claims:\nAs of 2011, available commercial products claim the ability to test up to 2,800,000,000 passwords a second on a standard desktop computer using a highend graphics processor.2\nIf this is correct, a 44-bit password would take one hour to crack, while a 60-bit password would take 11.3 years.\nOur concrete task is as follows: 2http://en.wikipedia.org/wiki/Password cracking\n1569\n• Input: A random, system-generated 60-bit password.\n• Output: An English word sequence with two properties:\n– It is memorable. – We can deterministically recover the orig-\ninal input 60-bit string from it.\nThis implies that we map 260 distinct bit strings into 260 distinct English sequences. If a user memorizes the English word sequence supplied to them, then they have effectively memorized the 60-bit string."
  }, {
    "heading": "2 Password Generation Methods",
    "text": "We now describe our baseline password generation method, followed by four novel methods. In Section 3 we experimentally test their memorability."
  }, {
    "heading": "2.1 XKCD Baseline",
    "text": "Our baseline is a version of XKCD. Instead of a 2048-word dictionary, we use a 32,7868-word dictionary. We assign each word a distinct 15-bit code.\nAt runtime, we take a system-assigned 60-bit code and split it into four 15-bit sequences. We then substitute each 15-bit segment with its corresponding word. By doing this, we convert a random 60-bit code into a 4-word password.\nThe first row of Table 1 shows three sample XKCD passwords, along with other information, such as the average number of characters (including spaces)."
  }, {
    "heading": "2.2 First Letter Mnemonic",
    "text": "XKCD passwords are short but nonsensical, so we now look into methods that instead create longer but fluent English sentences. We might think to guarantee fluency by selecting sentences from an alreadyexisting text corpus, but no corpus is large enough to contain 260 (∼ 1018) distinct sentences. Therefore, we must be able to synthesize new English strings.\nIn our first sentence generation method (First Letter Mnemonic), we store our input 60-bit code in the first letters of each word. We divide the 60-bit code into 4-bit sections, e.g., ‘0100-1101-1101-...’. Every 4-bit sequence type corresponds to an English letter\nor two, per Table 2. We build a word-confusion network (or “sausage lattice”) by replacing each 4-bit code with all English words that start with a corresponding letter, e.g.: 0100 1101 1111 ... 0011 ---- ---- ---- ---- income my frog ... octopus is miner feast ... of inner priest gratuitous ... oregon ... ... ... ...\nThis yields about 1074 paths, some good (is my frog. . . ) and some bad (income miner feast. . . ). To select the most fluent path, we train a 5-gram language model with the SRILM toolkit (Stolcke, 2002) on the English Gigaword corpus.3 SRILM also includes functionality for extracting the best path from a confusion network.\nTable 1 shows sample sentences generated by the method. Perhaps surprisingly, even though the sentences are much longer than XKCD (15 words versus 4 words), the n-gram language model (LM) score is a bit better. The sentences are locally fluent, but not perfectly grammatical.\nWe can easily reconstruct the original 60-bit code by extracting the first letter of each word and applying the Table 2 mapping in reverse."
  }, {
    "heading": "2.3 All Letter Method",
    "text": "Most of the characters in the previous methods seem “wasted”, as only the word-initial letters bear information relevant to reconstructing the original 60-\n3https://catalog.ldc.upenn.edu/LDC2011T07\nbit string. Our next technique (All Letter Method) non-deterministically translates every bit into an English letter, per Table 3. Additionally, we nondeterministically introduce a space (or not) between each pair of letters.\nThis yields 4 · 1084 possible output strings per input, 3 ·1056 of which consist of legal English words. From those 3 · 1056 strings, we choose the one that yields the best word 5-gram score.\nIt is not immediately clear how to process a letterbased lattice with a word-based language model. We solve this search problem by casting it as one of machine translation from bit-strings to English. We create a phrase translation table by pairing each English word with a corresponding “bit phrase”, using Table 3 in reverse. Sample entries include:\ndin ||| 1 0 1 through ||| 1 0 0 0 0 0 0 yields ||| 1 0 0 1 1 1\nWe then use the Moses machine translation toolkit (Koehn et al., 2007) to search for the 1-best translation of our input 60-bit string, using the phrase table and a 5-gram English LM, disallowing re-ordering.\nTable 1 shows that these sentences are shorter than the mnemonic method (11.8 words versus 15 words), without losing fluency.\nGiven a generated English sequence, we can deterministically reconstruct the original 60-bit input string, using the above phrase table in reverse."
  }, {
    "heading": "2.4 Frequency Method",
    "text": "Sentence passwords from the previous method contain 70.8 characters on average (including spaces). Classic studies by Shannon (1951) and others estimate that printed English may ultimately be compressible to about one bit per character. This implies we might be able to produce shorter output (60 characters, including space) while maintaining normal English fluency.\nOur next technique (Frequency Method) modifies the phrase table by assigning short bit codes to frequent words, and long bit codes to infrequent words. For example:\ndin ||| 0 1 1 0 1 0 1 0 0 through ||| 1 1 1 1 yields ||| 0 1 0 1 1 1 0 1\nNote that the word din is now mapped to a 9-bit sequence rather than a 3-bit sequence. More precisely, we map each word to a random bit sequence of length bmax(1,−α × log P(word) + β)c. By changing variables α and β we can vary between smooth but long sentences (α = 1 and β = 0) to XKCD-style phrases (α = 0 and β = 15).\nTable 1 shows example sentences we obtain with α = 2.5 and β = −2.5, yielding sentences of 9.7 words on average."
  }, {
    "heading": "2.5 Poetry",
    "text": "In ancient times, people recorded long, historical epics using poetry, to enhance memorability. We follow this idea by turning each system-assigned 60-bit string into a short, distinct English poem. Our format is the rhyming iambic tetrameter couplet:\n• The poem contains two lines of eight syllables each.\n• Lines are in iambic meter, i.e., their syllables have the stress pattern 01010101, where 0 represents an unstressed syllable, and 1 represents a stressed syllable. We also allow 01010100, to allow a line to end in a word like Angela.\n• The two lines end in a pair of rhyming words. Words rhyme if their phoneme sequences match from the final stressed vowel onwards. We obtain stress patterns and phoneme sequences from the CMU pronunciation dictionary.4\nMonosyllabic words cause trouble, because their stress often depends on context (Greene et al., 2010). For example, eighth is stressed in eighth street, but not in eighth avenue. This makes it hard to guarantee that automatically-generated lines will scan as intended. We therefore eject all monosyllabic words\n4http://www.speech.cs.cmu.edu/cgi-bin/cmudict\nfrom the vocabulary, except for six unstressed ones (a, an, and, the, of, or).\nHere is a sample poem password:\nThe le-gen-da-ry Ja-pan-ese ↓ ↑ ↓ ↑ ↓ ↑ ↓ ↑ Sub-si-di-ar-ies ov-er-seas ↓ ↑ ↓ ↑ ↓ ↑ ↓ ↑\nMeter and rhyme constraints make it difficult to use the Moses machine translation toolkit to search for fluent output, as we did above; the decoder state must be augmented with additional short- and longdistance information (Genzel et al., 2010).\nInstead, we build a large finite-state acceptor (FSA) with a path for each legal poem. In each path, the second line of the poem is reversed, so that we can enforce rhyming locally.\nThe details of our FSA construction are as follows. First, we create a finite-state transducer (FST) that maps each input English word onto four sequences that capture its essential properties, e.g.:\ncreate -> 0 1 create -> 0 1 EY-T create -> 1r 0r create -> EY-T 1r 0r\nHere, EY-T represents the rhyme-class of words like create and debate. The r indicates a stress pattern in the right-to-left direction.\nWe then compose this FST with an FSA that only accepts sequences of the form: 0 1 0 1 0 1 0 1 X X 1r 0r 1r 0r 1r 0r 1r 0r where X and X are identical rhyme classes (e.g., EYT and EY-T).\nIt remains to map an arbitrary 60-bit string onto a path in the FSA. Let k be the integer representation of the 60-bit string. If the FSA contains exactly 260 paths, we can easily select the kth path using the following method. At each node N of the FSA, we store the total number of paths from N to the final state—this takes linear time if we visit states in reverse topological order. We then traverse the FSA deterministically from the start state, using k to guide the path selection.\nOur FSA actually contains 279 paths, far more than the required 260. We can say that the information capacity of the English rhyming iambic tetrameter couplet is 79 bits! Some are very good:\nSophisticated potentates misrepresenting Emirates.\nThe supervisor notified the transportation nationwide.\nAfghanistan, Afghanistan, Afghanistan, and Pakistan.\nwhile others are very bad: The shirley emmy plebiscite complete suppressed unlike invite\nThe shirley emmy plebiscite complaints suppressed unlike invite\nThe shirley emmy plebiscite complaint suppressed unlike invite\nFortunately, because our FSA contains over a million times the required 260 paths, we can avoid these bad outputs. For any particular 60-bit string, we have a million poems to choose from, and we output only the best one.\nMore precisely, given a 60-bit input string k, we extract not only the kth FSA path, but also the k + i · 260 paths, with i ranging from 1 to 999,999. We explicitly list out these paths, reversing the second half of each, and score them with our 5-gram LM. We output the poem with the 1-best LM score. Table 1 shows sample outputs.\nTo reconstruct the original 60-bit string k, we first find the FSA path corresponding to the user-recalled English string (with second half reversed). We use depth-first search to find this path. Once we have the path, it is easy to determine which numbered path it is, lexicographically speaking, using the nodelabeling scheme above to recover k."
  }, {
    "heading": "3 Experiments",
    "text": "We designed two experiments to compare our methods.\nThe first experiment tests the memorability of passwords. We asked participants to memorize a password from a randomly selected method5 and recall it two days later. To give more options to users,\n5In all experiments, we omit the First Letter Mnemonic, due to its low performance in early tests.\nwe let them select from the 10-best passwords according to the LM score for a given 60-bit code. Note that this flexibility is not available for XKCD, which produces only one password per code.\n62 users participated in this experiment, 44 returned to recall the password, and 22 successfully recalled the complete password. Table 4 shows that the Poetry and XKCD methods yield passwords that are easiest to remember.\nIn the second experiment, we present a separate set of users with passwords from each of the four methods. We ask which they would prefer to use, without requiring any memorization. Table 5 shows that users prefer sentences over poetry, and poetry over XKCD."
  }, {
    "heading": "4 Analysis",
    "text": "Table 4 shows that the Poetry and XKCD methods yield passwords that are easiest to memorize. Complete sentences generated by the All Letter and Frequency Methods are harder to memorize. At the same time Table 5 shows that people like the sentences better than XKCD, so it seems that they overestimate their ability to memorize a sentence of 10- 12 words. Here are typical mistakes (S = system-\ngenerated, R = as recalled by user):\n(S) Still looking for ruben sierra could be in central michigan (R) I am still looking for ruben sierra in central michigan\n(S) That we were required to go to college more than action movies (R) We are required to go to college more than action movies\n(S) No dressing allowed under canon law in the youth group (R) No dresses allowed under canon law for youth groups\nUsers remember the gist of a sentence very well, but have trouble reproducing the exact wording. Post-experiment interview reveal this to be partly an effect of overconfidence. Users put little mental work into memorizing sentences, beyond choosing among the 10-best alternatives presented to them. By contrast, they put much more work into memorizing an XKCD phrase, actively building a mental image or story to connect the four otherwise unrelated words."
  }, {
    "heading": "5 Future Directions",
    "text": "Actually, we can often automatically determine that a user-recalled sequence is wrong. For example, when we go to reconstruct the 60-bit input string from a user-recalled sequence, we may find that we get a 62-bit string instead. We can then automatically prod the user into trying again, but we find that this is not effective in practice. An intriguing direction is to do automatic error-correction, i.e., take the user-recalled sequence and find the closest match among the 260 English sequences producible by the method. Of course, it is a challenge to do this with 1-best outputs of an MT system that uses heuristic beam search, and we must also ensure that security is maintained.\nWe may also investigate new ways to re-rank nbest lists. Language model scoring is a good start, but we may prefer vivid, concrete, or other types of words, or we may use text data associated with the user (papers, emails) for secure yet personalized password generation."
  }, {
    "heading": "6 Related Work",
    "text": "Gasser (1975), Crawford and Aycock (2008), and Shay et al. (2012) describe systems that produce meaningless but pronounceable passwords, such as “tufritvi” . However, their systems can only assign ∼ 230 distinct passwords.\nJeyaraman and Topkara (2005) suggest generating a random sequence of characters, and finding a mnemonic for it in a text corpus. A limited corpus means they again have a small space of systemassigned passwords. We propose a similar method in Section 2.2, but we automatically synthesize a new mnemonic word sequence.\nKurzban (1985) and Shay et al. (2012) use a method similar to XKCD with small dictionaries. This leads to longer nonsense sequences that can be difficult to remember."
  }, {
    "heading": "7 Conclusion",
    "text": "We introduced several methods for generating secure passwords in the form of English word sequences. We learned that long sentences are seemingly easy to remember, but actually hard to reproduce, and we also learned that our poetry method produced relatively short, memorable passwords that are liked by users."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to thank James Bedell, Aliya Deri, Tomer Levinboim, Jonathan May, Nima Pourdamghani and the anonymous reviewers for their very helpful comments. This work was supported in part by DARPA contract FA-8750-13-2-0045."
  }],
  "year": 2015,
  "references": [{
    "title": "Kwyjibo: automatic domain name generation",
    "authors": ["Heather Crawford", "John Aycock."],
    "venue": "Software: Practice and Experience, 38(14):1561–1567.",
    "year": 2008
  }, {
    "title": "A largescale study of web password habits",
    "authors": ["Dinei Florencio", "Cormac Herley."],
    "venue": "Proceedings of the 16th international conference on World Wide Web, pages 657–666. ACM.",
    "year": 2007
  }, {
    "title": "A random word generator for pronounceable passwords",
    "authors": ["Morrie Gasser."],
    "venue": "Technical report, Electronic Systems Division, Air Force Systems Command, USAF.",
    "year": 1975
  }, {
    "title": "Poetic statistical machine translation: rhyme and meter",
    "authors": ["Dmitriy Genzel", "Jakob Uszkoreit", "Franz Och."],
    "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 158–166. Association for Computational Linguistics.",
    "year": 2010
  }, {
    "title": "Automatic analysis of rhythmic poetry with applications to generation and translation",
    "authors": ["Erica Greene", "Tugba Bodrumlu", "Kevin Knight."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 524–533. Association for",
    "year": 2010
  }, {
    "title": "Have your cake and eat it too–infusing usability into text-password based authentication systems",
    "authors": ["Sundararaman Jeyaraman", "Umut Topkara."],
    "venue": "Proceedings of ACSAC.",
    "year": 2005
  }, {
    "title": "Moses: Open source toolkit for statistical machine translation",
    "authors": ["Philipp Koehn", "Hieu Hoang", "Alexandra Birch", "Chris Callison-Burch", "Marcello Federico", "Nicola Bertoldi", "Brooke Cowan", "Wade Shen", "Christine Moran", "Richard Zens"],
    "year": 2007
  }, {
    "title": "Easily remembered passphrases: a better approach",
    "authors": ["Stanley A Kurzban."],
    "venue": "ACM SIGSAC Review, 3(2-4):10–21.",
    "year": 1985
  }, {
    "title": "Prediction and entropy of printed English",
    "authors": ["Claude E. Shannon."],
    "venue": "Bell System Technical Journal, 30(1):50–64.",
    "year": 1951
  }, {
    "title": "Correct horse battery staple: Exploring the usability of system-assigned passphrases",
    "authors": ["Richard Shay", "Patrick Gage Kelley", "Saranga Komanduri", "Michelle L Mazurek", "Blase Ur", "Timothy Vidas", "Lujo Bauer", "Nicolas Christin", "Lorrie Faith Cranor."],
    "venue": "Proceed-",
    "year": 2012
  }, {
    "title": "SRILM-an extensible language modeling toolkit",
    "authors": ["Andreas Stolcke."],
    "venue": "INTERSPEECH, pages 901–904.",
    "year": 2002
  }],
  "id": "SP:c73921c0c99a51c47ebcd3a7b1dd800c492893e3",
  "authors": [{
    "name": "Marjan Ghazvininejad",
    "affiliations": []
  }, {
    "name": "Kevin Knight",
    "affiliations": []
  }],
  "abstractText": "User-generated passwords tend to be memorable, but not secure. A random, computergenerated 60-bit string is much more secure. However, users cannot memorize random 60bit strings. In this paper, we investigate methods for converting arbitrary bit strings into English word sequences (both prose and poetry), and we study their memorability and other properties.",
  "title": "How to Memorize a Random 60-Bit String"
}