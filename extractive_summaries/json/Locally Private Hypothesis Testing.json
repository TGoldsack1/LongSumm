{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Differential privacy is a mathematically rigorous notion of privacy that has become the de-facto gold-standard of privacy preserving data analysis. Informally, -differential privacy bounds the affect of a single datapoint on any result of the computation by . In recent years the subject of private hypothesis testing has been receiving increasing attention (see Related Work below). However, by and large, the focus of private hypothesis testing is in the centralized model (or the curated model), where a single trusted entity holds the sensitive details of n users and runs the private hypothesis tester on the actual data.\n1Dept. of Computing Science, University of Alberta.. Correspondence to: Or Sheffet <osheffet@ualberta.ca>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nIn contrast, the subject of this work is private hypothesis testing in the local-model (or the distributed model), where a -differentially private mechanism is applied independently to each datum. This model, which alleviates trust (each user can run the mechanism independently on her own and release the noisy signal from the mechanism), has gained much popularity in recent years, especially since it was adopted by Google’s Rappor (Erlingsson et al., 2014) and Apple (Apple, 2017). And yet, despite its popularity, and the fact that recent works (Bassily & Smith, 2015; Bassily et al., 2017) have shown the space of possible locally-private mechanism is richer than what was originally thought, little is known about private hypothesis testing in the local-model."
  }, {
    "heading": "1.1. Background: Local Differential Privacy",
    "text": "We view the local differentially private model as a signaling scheme. Each datum / user has a type x taken from a predefined and publicly known set of possible types X whose size is T = |X |. The differentially private mechanism is merely a randomized function M : ([n],X ) → S, mapping each possible type X of the i-th datum to some set of possible signals S, which we assume to be -differentially private: for any index i, any pair of types x, x′ ∈ X and any signal s ∈ S it holds that Pr[M(i, x) = s] ≤ e Pr[M(i, x′) = s].1 In our most general results (Theorems 1 and 9), we ignore the fact thatM is -differentially private, and just refer to any signaling scheme that transforms one domain (namely, X ) into another (S). For example, a surveyer might unify rarely occurring types under the category of “other”, or perhaps users report their types over noisy channels, etc.\nWe differentiate between two types of signaling schemes: the symmetric (or index-oblivious) variety, and the nonsymmetric (index-aware) type. A local signaling mechanism is called symmetric if it is independent of the index of the datum. Namely, if for any i 6= j we have that M(i, x) = M(j, x) def= M(x). A classic exam-\n1For simplicity, we assume S, the set of possible signals, is discrete. Note that this doesn’t exclude mechanisms such as adding Gaussian/Gamma noise to a point in Rd — such mechanisms require X to be some bounded subset of Rd and use the bound to set the noise appropriately. Therefore, the standard approach of discretizing X and projecting the noisy point to the closest point in the grid yields a finite set of signals S.\nple of such a mechanism is randomized-response — that actually dates back to before differential privacy was defined (Warner, 1965) and was first put to use in differential privacy in (Kasiviswanathan et al., 2008) — where each user / datum x draws her own signal from the set S = X skewing the probability ever-so-slightly in favor of the original type. I.e. if the user’s type is x then\nM(x) =\n{ x, w.p. e\nT−1+e\nx′, for any other x′ w.p. 1T−1+e .\nThe utility of the above-mentioned symmetric mechanism scales polynomially with T (or rather, with |S|), which motivated the question of designing local mechanisms with error scaling logarithmically in T . This question was recently answered in the affirmative by the works of Bassily and Smith (2015) and Bassily et al (2017), whose mechanisms are not symmetric. In fact, both of them work by presenting each user i with a mapping fi : X → S (the mapping itself is chosen randomly, but it is public, so we treat it as a given), and the user then runs the standard randomized response mechanism on the signals using fi(x) as the more-likely signal. (In fact, in both schemes, S = {1,−1}: in (Bassily & Smith, 2015) fi is merely the j-th coordinate of a hashing of the types where j and the hashing function are publicly known, and in (Bassily et al., 2017) fi maps a u.a.r chosen subset of X to 1 and its complementary to −1.2) So given fi, the user then tosses her own private random coins to determine what signal she broadcasts. Therefore, each user’s mechanism can be summarized in a |S| × |X |-matrix, where Mi(s, x) is the probability a user of type x sends the signal s. For example, using the mechanism of (Bassily et al., 2017), each user whose type maps to 1 sends “signal 1” with probability e\n1+e and “signal −1” with probability 1 1+e . Namely, Mi(fi(x), x) = e 1+e andMi(−fi(x), x) = 1\n1+e , where fi is the mapping X → {1,−1} set for user i."
  }, {
    "heading": "1.2. Our Contribution and Organization",
    "text": "This work initiates (to the best of our knowledge) the theory of differentially private hypothesis testing in the local model. First we survey related work and preliminaries. Then, in Section 3, we examine the symmetric case and show that any mechanism (not necessarily a differentially private one) yields a distribution on the signals for which finding a maximum-likelihood hypothesis is feasible, assuming the set of possible hypotheses is convex. Then, focusing on the classic randomized-response mechanism, we show that the problem of maximizing the likelihood of the observed signals is strongly-convex and thus simpler than the original problem. More importantly, in essence\n2In both works, much effort is put to first reducing T to the most frequent √ n types, and then run the counting algorithm. Regardless, the end-counts / collection of users’ signals are the ones we care for the sake of hypothesis testing.\nwe give a characterization of hypothesis testing under randomized response: the symmetric locally-private mechanism translates the original null hypothesis H0 (and the alternative H1) by a known affine translation into a different set ϕ(H0) (and resp. ϕ(H1)). Hence, hypothesis testing under randomized-response boils to discerning between two different (and considerably closer in total-variation distance) sets, but in the exact same model as in standard hypothesis testing as all signals were drawn from the same hypothesis in ϕ(H0). As an immediate corollary we give bounds on identity-testing (Corollary 5) and independencetesting (Theorem 6) under randomized-response. (The latter requires some manipulations and far less straightforward than the former.) The sample complexity (under certain simplifying assumptions) of both problems is proportional to T 2.5.\nIn Section 4 we move to the non-symmetric local-model. Again, we start with a general result showing that in this case too, finding an hypothesis that maximizes the likelihood of the observed signals is feasible when the hypothesis-set is convex. We then focus on the mechanism of Bassily et al (2017) and show that it also makes the problem of finding a maximum-likelihood hypothesis strongly-convex. We then give a simple identity tester under this scheme whose sample complexity is proportional to T 2, and is thus more efficient than any tester under standard randomized-response. Similarly, we also give an independence-tester with a similar sample complexity. In Section 4.2 we empirically investigate alternative identitytesting and independence-testing based on Pearson’s χ2test in this non-symmetric scheme, and identify a couple of open problems in this regime."
  }, {
    "heading": "1.3. Related Work",
    "text": "Several works have looked at the intersection of differential privacy and statistics (Dwork & Lei, 2009; Smith, 2011; Chaudhuri & Hsu, 2012; Duchi et al., 2013a; Dwork et al., 2015) mostly focusing on robust statistics; but only a handful of works study rigorously the significance and power of hypotheses testing under differential privacy. Vu and Slavkovic (2009) looked at the sample size for privately testing the bias of a coin. Johnson and Shmatikov (2013), Uhler et al (2013) and Yu et al (2014) focused on the Pearson χ2-test (the simplest goodness of fit test), showing that the noise added by differential privacy vanishes asymptotically as the number of datapoints goes to infinity, and propose a private χ2-based test which they study empirically. Wang et al (2015) and Gaboardi et al (2016) who have noticed the issues with both of these approaches, have revised the statistical tests themselves to incorporate also the added noise in the private computation. Cai et al (2017) give a private identity tester based on noisy χ2-test over large bins, Sheffet (2017) studies private Ordinary Least Squares using the JL transform, and Karwa and Vadhan (2018) give\nmatching upper- and lower-bounds on the confidence intervals for the mean of a population. All of these works however deal with the centralized-model of differential privacy.\nPerhaps the closest to our work are the works of Duchi et al (2013a; 2013b) who give matching upper- and lowerbound on robust estimators in the local model. And while their lower bounds do inform as to the sample complexity’s dependency on −2, they do not ascertain the sample complexity dependency on the size of the domain (T ) we get in Section 3. Moreover, these works disregard independence testing (and in fact (Duchi et al., 2013b) focus on mean estimation so they apply randomized-response to each feature independently generating a product-distribution even when the input isn’t sampled from a product-distribution). And so, to the best of our knowledge, no work has focused on hypothesis testing in the local model, let alone in the (relatively new) non-symmetric local model. Lastly, developed concurrently to our work, Gaboardi and Rogers (2018) study the asymptotic power of a variety chi-squared based hypothesis testing in the local model."
  }, {
    "heading": "2. Preliminaries, Notation and Background",
    "text": "Notation. We user lower-case letters to denote scalars, bold characters to denote vectors and CAPITAL letters to denote matrices. So 1 denotes the number, 1 denotes the all-1 vector, and 1X×X denotes the all-1 matrix over a domain X . We use ex to denote the standard basis vector with a single 1 in coordinate corresponding to x. To denote the x-coordinate of a vector v we use v(x), and to denote the (x, x′)-coordinate of a matrix M we use M(x, x′). For a given vector v , we use diag(v) to denote the matrix whose diagonal entries are the coordinates of v . For any natural n, we use [n] to denote the set {1, 2, ..., n}.\nDistances and norms. Unless specified otherwise ‖v‖ refers to the L2-norm of v , whereas ‖v‖1 refers to the L1-\nnorm. We also denote ‖v‖ 2 3\n= (∑\ni |vi| 2 3\n) 3 2\n. For a matrix, ‖M‖1 denotes (as usual) the maximum absolute column sum. We identify a distribution p over a domain X as a T -dimensional vector with non-negative entries that sum to 1. This defines the total variation distance between two distributions: dTV(p,q) = 12‖p − q‖1. (On occasion, we will apply dTV to vectors that aren’t distributions, but rather nearby estimations; in those cases we use the same definition: the half of the L1-norm.) It is known that the TV-distance is a metric overs distributions. We also use the χ2-divergence to measure difference between two distributions: dχ2(p,q) = ∑ x (p(x)−q(x))2 p(x) = (∑ x (q(x))2 p(x) ) − 1. The χ2-divergence is not symmetric and can be infinite, however it is non-negative and zeros only when p = q . We refer the reader to (Sason & Verdú, 2016) for more properties of the total-variance distance the χ2-divergence.\nDifferential Privacy. An algorithm A is called - differentially private, if for any two datasets D and D′ that differ only on the details of a single user and any set of outputsO, we have that Pr[A(D) ∈ O] ≤ e Pr[A(D′) ∈ O]. The unacquainted reader is referred to the Dwork-Roth monograph (Dwork & Roth, 2014) as an introduction to the rapidly-growing field of differential privacy.\nHypothesis testing. The problem of hypothesis testing is to test whether a given set of samples was drawn from a distribution satisfying the null-hypothesis or the alternativehypothesis. Thus, the null-hypothesis is merely a set of possible distributions H0 and the alternative is disjoint set H1. Hypothesis tests boils down to estimating a teststatistic θ whose distribution has been estimated under the null-hypothesis. We can thus reject the null-hypothesis if the value of θ is highly unlikely, or accept the nullhypothesis otherwise. We call an algorithm a tester if the acceptance (in the completeness case) or rejection (in the soundness case) happen with probability ≥ 2/3. Standard amplification techniques (return the median of independent tests) reduce the error probability from 1/3 to any β > 0 at the expense of increasing the sample complexity by a factor of O(log(1/β)); hence we focus on achieving a constant error probability. One of the most prevalent and basic tests is the identity-testing, where the null-hypothesis is composed of a single distribution H0 = {p} and our goal is to accept if the samples are drawn from p and reject if they were drawn from any other α-far (in dTV) distribution. Another extremely common tester is for independence when X is composed of several features (i.e., X = X 1 ×X 2 × ...×X d) and the null-hypothesis is composed of all product distributions H0 = {p1 × ... × pd} where each pj is a distribution on the jth feature X j .\nMiscellaneous. We use M 0 to denote that M is a positive semi-definite (PSD) matrix, and M N to denote that (M − N) 0. We use M† to denote M ’s pseudoinverse. We emphasize that we made no effort to minimize constants in our proofs, and only strived to obtain asymptotic bounds (O(·),Ω(·))."
  }, {
    "heading": "3. Symmetric Signaling Scheme",
    "text": "Recall, in the symmetric signaling scheme, each user’s type is mapped through a random functionM into a set of signals S. This mapping is index-oblivious — each user of type x ∈ X , sends the signal s with the same probability Pr[M(x) = s]. We denote the matrixG as the (|S|×|X |)- matrix whose entries are Pr[M(x) = s], and its sth-row by gs. Note that all entries of G are non negative and that for each x we have ‖Gex‖1 = 1. By garbling each datum i.i.d, we observe the new dataset (y1, y2, ..., yn) ∈ Sn.\nTheorem 1. For any convex setH of hypotheses, the problem of finding the max-likelihood p ∈ H generating the observed signals (y1, .., yn) is poly-time solvable.\nProof. Since G(s, x) describes the probability that a user of type x sends the signal s, any distribution p ∈ H over the types in X yields a distribution on S where Pr[user sends s] = ∑ x∈X G(s, x) · p(x) = gTsp. Therefore, given signals (y1, ..., yn) summarized as a signalshistogram 〈ns〉s∈S , the likelihood of these signals is given by: L(p; y1, ..., yn) = ∏ i g T yip = ∏ s∈S(g T s p) ns =\nexp (∑ s ns log(g T sp) ) . Thus, the gradient of the negative\nlog-loss function is∇f = − 1n ∑ s∈S ns gTsp ·gs, and its Hes-\nsian is given by the matrix 1n ∑ s∈S ns (gTsp) 2gsg T s . Clearly, as a non-negative sum of rank-1 matrices, the Hessian is a PSD matrix.so our loss-function is convex. Known polytime algorithms for minimizing a convex function over a convex set (e.g. (Zinkevich, 2003)) conclude the proof.\nUnfortunately, in general the solution to this problem has no closed form (to the best of our knowledge). However, we can find a close-form solution under the assumption that G isn’t just any linear transformation but rather one that induces probability distribution over S, the assumption that |S| ≤ |X | (in all applications we are aware of use fewer signals than user-types) and one extra-condition.\nCorollary 2. Let q∗ be the |S|-dimensional vector given by 〈nsn 〉. Given that |S| ≤ |X |, that G is a full-rank matrix satisfying ‖G‖1 = 1 and assuming that ( G†q∗+ker(G) ) ∩ H 6= ∅, then any vector inH of the form p∗+u where p∗ = G†q∗ and u ∈ ker(G) is an hypothesis that maximizes the likelihood of the given signals (y1, ..., yn). Proof deferred to the supplementary material, Section B."
  }, {
    "heading": "3.1. Hypothesis Testing under Randomized-Response",
    "text": "We now aim to check the affect of a particular G, the one given by the randomized-response mechanism. In this case S = X and we denote G as the matrix whose entries are\nG(x, x′) = { ρ+ γ , if x′ = x ρ , otherwise where ρ def= 1T−1+e\nand γ def= e −1\nT−1+e . We get that G = ρ · 1X×X + γI (where 1X×X is the all-1 matrix). In particular, all vectors gs = gx, which correspond to the rows of G, are of the form: gx = ρ1 + γex. It follows that for any probability distribution p ∈ H we have that Pr[seeing signal x] = gTxp = ρ+ γp(x). We have therefore translated any p ∈ H (over X ) to an hypothesis q over S (which in this case S = X ), using the affine transformation ϕ(p) = ρ1 +γp = TρuX +γp when uX denotes the uniform distribution over X . (Indeed, γ = 1 − Tρ, an identity we will often apply.) At the risk of overburdening notation, we use ϕ to denote the same transformation over scalars, vectors and even sets (applying ϕ to each vector in the set). Since ϕ is injective, we have therefore discovered the following theorem.\nTheorem 3. Under the classic randomized response mechanism, testing for any hypothesis H0 (or for comparing H0 against the alternative H1) of the original distribution,\ntranslates into testing for hypothesis ϕ(H0) (or ϕ(H0) against ϕ(H1)) for generating the signals y1, ..., yn. Theorem 3 seems very natural and simple, and yet (to the best of our knowledge) it was never put to words.\nMoreover, it is simple to see that under standardrandomized response, our log-loss function is in fact strongly-convex, and therefore finding p∗ becomes drastically more efficient (see, for example (Hazan et al., 2006)).\nClaim 4. Given signals y1, ..., yn generated using standard randomized response with parameter < 1, we have that our log-loss function is Θ( 2 · minx{nx}n )-strongly convex. Note that in expectation nx ≥ ρn, hence with overwhelming probability we have minx nx ≥ n/(2T ). The proof is fairly straight-forward and is deferred to the supplementary material, Section B.\nA variety of corollaries follow from Theorem 3. In particular, a variety of detailing matching sample complexity upper- and lower-bounds translate automatically into the realm of making such hypothesis-tests over the outcomes of the randomized-response mechanism. We focus here on two of the most prevalent tests: identity testing and independence testing.\nIdentity Testing. Perhaps the simplest of the all hypothesis testing is to test whether a given sample was generated according to a given distribution or not. Namely, the null hypothesis is a single hypothesis H0 = {p}, and the alternative is H1 = {q : dTV(p,q) ≥ α} for a given parameter α. The seminal work of Valiant and Valiant (2014) discerns that (roughly) Θ(‖p‖ 2\n3 /α2) samples are sufficient\nand are necessary for correctly rejecting or accepting the null-hypothesis w.p.≥ 2/3.3\nHere, the problem of identity testing under standard randomized response reduces to the problem of hypothesis testing between ϕ(H0) = {ρ1 + γp : p ∈ H0} and ϕ(H1) = {ϕ(q) : q satisfying dTV(p,q) ≥ α}. Corollary 5. In order to do identity testing under standard randomized response with confidence and power ≥ 2/3, it is necessary and sufficient that we get Θ( T 2.5\n2α2 ) samples. The proof uses the results of (Valiant & Valiant, 2014) as a black-box and is mainly composed of calculations, so it is deferred to supplementary material, Section B.\nIndependence Testing. Another prevalent hypothesis testing over a domain X where each type is composed of multiple feature is independence testing. Denoting X = X 1 × X 2 × ... × X d as a domain with d possible features (hence T = |X | = ∏ j |X j | def = ∏ j T\nj), our goal is to discern whether an observed sample is drawn from a product distribution or a distribution α-far from any product distri-\n3For the sake of brevity, we ignore pathological examples where by removing α probability mass from p we obtain a vector of significantly smaller 2\n3 -norm.\nbution. In particular, the null-hypothesis in this case is a complex one: H0 = {p̄ = p1×p2× ...×pd} and the alternative is H1 = {q : minp̄∈H0 dTV(q, p̄) ≥ α}. To the best of our knowledge, the (current) tester with smallest sample complexity is of Acharya et al (2015), which requires Ω ( ( √ T + ∑ j T j)/α2 ) iid samples.\nWe now consider the problem of testing for independence under standard randomized response. Our goal is to prove the following theorem. Theorem 6. There exists an algorithm that takes n =\nΩ̃( T 2\nα2 2\n( d2(max\nj {T j})2 +\n√ T ) ) signals generated by\napplying standard randomized response (with < 1) on n samples drawn from a distribution p and with probability ≥ 2/3 accepts if p ∈ H0, or rejects if p ∈ H1. Moreover, no algorithm can achieve such guarantee using n = o(T 5/2/(α2 2)) signals. Note there are at least two types per feature, so d ≤ log2(T ). Should all T\njs be equal we have (T j)2 ≤ T 2d , making T 2.5/(α2 2) the leading term in the above bound.\nProof. Theorem 3 implies we are comparing ϕ(H0) = {ρ1X+γ(p1×...×pd)} to ϕ(H1) = {ρ1X+γq : q ∈ H1}. Note that ϕ(H0) is not a subset of product-distributions over X but rather a convex combination (with publicly known weights) of the uniform distribution and H0; so we cannot run the independence tester of Acharya et al on the signals as a black-box. Luckily it holds that ϕ(H1) is far from all distributions in ϕ(H0): for each q ∈ H1 and p̄ ∈ H0 we have dTV(ϕ(q), ϕ(p̄)) ≥ γdTV(q, p̄) ≥ γα. And so we leverage on the main result of Acharya et al ((2015), Theorem 2): we first find a distribution ρ1 + γz̄ ∈ ϕ(H0) such that if the signals were generated by some ρ1X + γp̄ ∈ ϕ(H0) then dχ2(ϕ(z̄), ϕ(p̄)) ≤ γ2α2/500, and then test if indeed the signals are likely to be generated by a distribution close to ϕ(z̄) using Acharya et al’s algorithm. We now give our procedure for finding the product-distribution z̄ .\nPer feature j, given the jth feature of the signals yj1, ..., y j n where each xj ∈ X j appears nxj times, our procedure for finding zj is as follows.\n0. (Preprocessing:) Denote τ = α/(10d · T j). We call any type xj where nxjn ≤ 1−γ T j + γτ as small and\notherwise we say type xj is large. Ignore all small types, and learn zj only over large types. (For brevity, we refer to n as the number of signals on large types and T j as the number of large types.)\n1. Set the distribution z̃j as the “add-1” estimator of Kamath et al (2015) for the signals: z̃j(xj) = 1+nxjT j+n .\n2. Compute zj = 1γ ( I − 1−γT j 1X j ) z̃j .\nOnce zj is found for each feature j, set z̄ = z1 × ... × zd run the test of Acharya et al (2015) (Theorem 2) with ϕ(z̄) looking only at the large types from each feature, setting\nthe distance parameter to αγ2 and confidence 1 9 , to decide whether to accept or reject.\nIn order to successfully apply the Acharya et al’s test, a few conditions need to hold. First, the provided distribution ϕ(z̄) should be close to ϕ(H0). This however hold trivially, as z̄ is a product-distribution. Secondly, we need that ϕ(z̄) and ϕ(p̄) to be close in χ2-divergence, as we argue next.\nLemma 7. Suppose that n, the number of signals, is at least Ω( d 2\nα2γ2 maxj{T j}). Then the above procedure cre-\nates distributions zj such that the product distribution z̄ = z1×z2× ...×zd satisfies the following property. If the signals y1, ..., yn were generated by ϕ(p̄) for some productdistribution p̄ = p1 × ... × pd, then w.p. ≥ 8/9 we have that dχ2(ϕ(z̄), ϕ(p̄)) ≤ γ2α2/1000. We table the proof of Lemma 7 to Section B in the supplementary material. Next, either completeness or soundness must happen: either the signals were taken from randomized-response on a product distribution, or they were generated by a distribution γα/2-far from ϕ(H0). If no type of any feature was deemed as “small”, this condition clearly holds; but we need to argue this continues to hold even when we run our tester on a strict subset of X composed only of large types in each feature. Completeness is straight-forward: since we remove types feature by feature, the types now come from a product distribution p̄large = p 1 large × ... × pdlarge where each pjlarge is a restriction of p j to the large types of feature j. Soundness however is more intricate. We partition X into two subsets: AllLarge = {(x1, x2, ..., xd) ∈ X : ∀j, xj is large} and Rest = X \\AllLarge; and break q into q = ηqRest + (1− η)qAllLarge, with η = Prq [Rest]. Claim 8 (proof deferred to the supplementary material) argues that η < α2 . Therefore, dTV(q, qAllLarge) ≤ α 2 , implying that dTV(ϕ(qAllLarge), ϕ(H0)) > α · γ− αγ2 = αγ 2 . Claim 8. Assume the underlying distribution of the samples is q and that the number of signals is at least n = Ω( d2(maxj T j)2\nα2γ2 log(dmaxj T j)). Then w.p. ≥ 8/9 our\npreprocessing step marks certain types each feature as “small” such that the probability (under q) of sampling a type (x1, x2, ..., xd) such that ∃j, xj is small is ≤ α/2. So, given that both Lemma 7 and Claim 8 hold, we can use the test of Acharya et al, which requires a sample of size n = Ω( √ T/(αγ)2). Recall that < 1 so γ = Θ( /T ), and we get that the sample size required for the last test is n = Ω( T 2.5\nα2 2 ). Moreover, for this last part, the lower bound in Acharya et al (2015) still holds (for the same reason it holds in the identity-testing case): the lower bound is derived from the counter example of testing whether the signals were generated from the uniform distribution (which clearly lies in ϕ(H0)) or any distribution from a collection of perturbations which all belong to ϕ(H1) (See (Paninski, 2008) for more details). Each of distribution is thus γα-far from ϕ(H0) and so any tester for this particular construc-\ntion requires √ T/(αγ)2-many samples. This proves both the upper- and lower-bounds of Theorem 6."
  }, {
    "heading": "4. Non-Symmetric Signaling Schemes",
    "text": "Let us recall the non-symmetric signaling schemes in (Bassily & Smith, 2015; Bassily et al., 2017). Each user, with true type x ∈ X , is assigned her own mapping (the mapping is broadcast and publicly known) fi : X → S . This sets her inherent signal to fi(x), and then she runs standard (symmetric) randomized response on the signals, making the probability of sending her true signal fi(x) to be e -times greater than any other signal s 6= fi(x).\nIn fact, let us allow an even broader look. Each user is given a mapping fi : X → S, and denoting (like before) T = |X | and S = |S|, we identify this mapping with a (S × T )-matrix Gi. The column gxi = Giex is the probability distribution that a user of type x is going to use to pick which signal she broadcasts. (And so the guarantee of differential privacy is that for any signal s ∈ S and any two types x 6= x′ we have that gxi (s) ≤ e gx ′\ni (s).) Therefore, all entries in Gi are non-negative and ‖Gi‖1 = 1 for all is.\nSimilarly to the symmetric case, we first exhibit the feasibility of finding a maximum-likelihood hypothesis given the signals from the non-symmetric scheme. Since we view which signal in S was sent, our likelihood mainly depends on the row vectors gsi . We prove the following theorem, proof deferred to Section C in the supplementary material.\nTheorem 9. For any convex set H , the problem of finding the max-likelihood p ∈ H generating the observed nonsymmetric signals (y1, .., yn) is poly-time solvable."
  }, {
    "heading": "4.1. Hypothesis Testing under Non-Symmetric Locally-Private Mechanisms",
    "text": "Let us recap the differentially private scheme of Bassily et al (2017). It this scheme, the mechanism uses solely two signals S = {1,−1} (so S = 2). For every i the mechanism sets Gi by picking u.a.r for each x ∈ X which of the two signals in S is more likely; the chosen signal gets a probability mass of e\n1+e and the other get probability mass of 11+e . We denote η as the constant such that 1 2 + η = e\n1+e and 1 2 − η = 1 1+e ; namely η = e −1 2(e +1) =\nΘ( ) when < 1. Thus, for every s ∈ {1,−1} the row vector gsi is chosen such that each coordinate is chosen iid and uniformly from { 12 + η, 1 2 − η}. (Obviously, there’s dependence between g1i and g −1 i , as g 1 i + g −1 i = 1, but the distribution of g1i is identical to the one of g −1 i .)\nFirst we argue that for any distribution p, if n is sufficiently large then w.h.p over the generation of theGis and over the signals we view from each user, then finding p̂ which maximizes the likelihood of the observed signals yields a good approximation to p. To that end, it suffices to argue that the function we optimize is Lipfshitz and strongly-convex.\nLemma 10. Fix δ > 0 and assume that the number of signals we observe is n = Ω(T 3 log(1/δ)). Then w.p.≥ 1− δ it holds that the function f(p) we optimize (as given in\nEquation (1)) is ( 3 √ T ) -Lipfshitz and ( η2\n2\n) -strongly con-\nvex over the subspace {x : xT1 = 0} (all vectors orthogonal to the all-1 vector). The proof of Lemma 10 — which (in part) is hairy due to the dependency between the matrix Gi and the signal yi — is deferred to Section C in the supplementary material.\nIdentity Testing. Designing an Identity Test based solely on the maximum-likelihood is feasible, due to results like Cesa-Binachi et al (2002) which allow us to compare between the risk of the result p̃ of a online gradient descent algorithm to the original distribution p which generated the signals. Through some manipulations one can (eventually) infer that |f(p) − f(p̃)| = O(1/ √ n). However, since strong-convexity refers to the L2-norm squared of ‖p − p̃‖, we derive the resulting bound is ‖p − p̃‖21 ≤ T‖p − p̃‖22 = O( 1η2√n ), which leads to a sample complexity bound proportional to T 3/(αη)4. This bound is worse than the bounds in Section 3.\nWe therefore design a different, simple, identity tester in the local non-symmetric scheme, based on the estimator given in (Bassily et al., 2017). The tester itself — which takes as input a given distribution p, a distance parameter α > 0 and the n signals — is quite simple.\n1. Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator θ = 1n ∑ i 1 η ( gyii − 121 ) .\n2. If dTV( 12ηθ,p) ≤ α 2 then accept, else reject. Theorem 11. Assume < 1. If we observe n = Ω( ( T α )2 ) signals generated by a distribution q then w.p. ≥ 2/3 over the matrices Gi we generate and the signals we observe, it holds that dTV( 12ηθ,q) ≤ α/2. The correctness of the tester now follows from checking for the two cases where either p = q or dTV(p,q) > α.\nProof. In the first part of the proof we assume the types of the n users were already drawn and are now fixed. We denote xi as the type of user i. We denote the frequency vector f = 〈nxn 〉x∈X , generated by counting the number of users of type x and normalizing it by n.\nGiven f , we examine the estimator θ. For each user i we have that 1η (g yi i − 121) ∈ {−1, 1}\nT . Because xi, the type of user i, is fixed, then for each coordinate x′ 6= xi, the signal yi is independent of the x′-column in Gi (yi depends solely on the entries in the xi-column). We thus have that gyii (x\n′) is distributed uniformly among { 12 ± η} and so E[ 1 η (g yi i (x\n′) − 12 )] = 0. In contrast, Pr[ 1η (g yi i (xi) − 12 ) = 1 ]\n= ∑ s∈{−1,1} Pr[ 1 η (g s i (xi) − 12 ) = 1 and yi = s] = 2 · 12 · ( 1 2 + η) = 1 2 +η. Therefore, E[ 1 η (g yi i (xi)− 12 )] =\n( 12 + η)− ( 1 2 − η) = 2η. It follows that E[ 1 η (g yi i − 121)] = 2ηexi and so E[θ] = 2ηf .\nNext we examine the variance of θ , and argue the following (proof deferred to supplementary material).\nProposition 12. E[(θ − 2ηf )(θ − 2ηf )T] 1nI So as a result, the expectedL2-difference E[‖θ − 2ηf ‖2] = E[trace((θ − 2ηf )(θ − 2ηf )T)] = trace(E[(θ − 2ηf )(θ − 2ηf )T]) ≤ Tn . Chesbyshev’s inequality assures us that therefore Pr[ 12η‖θ − 2ηf ‖ > √ 6T 2η √ n ] ≤ T/n6T/n = 1 6 .\nSo far we have assumed f is fixed, and only looked at the event that the coin-tosses of the mechanism yielded an estimator far from its expected value. We now turn to bounding the distance between f and its expected value q (the distribution that generated the types). Indeed, it is clear to see that the expected value of f = 1n ∑ i exi is E[f ] = q . Moreover, it isn’t hard (and has been computed before many times, e.g. Agresti (2003)) to see that E[(f − q)(f − q)T] = 1n ( diag(q)− qqT ) . Thus\nE[‖f −q‖2] = trace( 1n ( diag(q)− qqT ) ) = 1n (1−‖q‖\n2). Therefore, applying Chebyshev again, we get that w.p. at most 1/6 over the choice of types by q , we have that Pr[‖f − q‖ > √ 6/n] ≤ 1/n6/n = 1 6 .\nCombining both results we get that w.p. ≥ 2/3 we have that ‖ 12ηθ − q‖1 ≤ √ T‖ 12ηθ − q‖ ≤√\nT ( ‖ 12ηθ − f ‖+ ‖f − q‖ ) ≤ √ 6T 2 4η2n+ √ 6T n ≤ α since\nwe have n = Ω( T 2\nη2α2 ). Recall that η = Θ( ) and that dTV(x,y) = 1 2‖x−y‖1, and the bound of α 2 is proven.\nIndependence Testing. Similarly to the identity tester, we propose a similar tester for independence. Recall that in this case, X is composed of d features, hence X = X 1 × X 2 × ... × X d, with our notation of T j = |X j | for each j. Our tester should accept when the underlying distribution over the types is some product distribution p, and should reject when the underlying distribution over the types is α-far from any product distribution. The tester, whose input is the n signals and a distance parameter α > 0, is as follows.\n1. Given the n matrices G1, ..., Gn and the n observed signals y1, ..., yn, compute the estimator θ = 1n ∑ i 1 η ( gyii − 121 ) .\n2. For each feature j compute θj — the jth marginal of 1 2ηθ (namely, for each x\nj ∈ X j sum all types whose jth feature is xj). Denote θ̄ = θ1 × ...× θd.\n3. If dTV( 12ηθ, θ̄) ≤ α 2 then accept, else reject.\nTheorem 13. Assume < 1. Given n = Ω( Tα2 2 ( T + d2 ∑ j T j )\n) iid drawn signals from the nonsymmetric locally-private mechanism under a dataset whose types were drawn iid from some distribution q , then\nw.p. ≥ 2/3 over the matrices Gi we generate and the types in the dataset we have the following guarantee. If q is a product distribution, then dTV( 12ηθ, θ̄) ≤ α 2 , and if q is αfar from any product distribution then dTV( 12ηθ, θ̄) > α 2 . (Proof deferred to the supplementary material, Section C.)\nOpen Problems. (1) Is there a tester with a better sample complexity? The experiment in Section 4.2 leads us to conjecture that there exists a tester with sample complexity of T 1.5/(ηα)2. There could exist better testers, of smaller sample complexity, which leads to the second question. (2) Can one derive lower bounds for identity/independence testing in this model, where each sample has its own distribution, related to the original distribution over types? In Section D in the supplementary material we give more details as to possible venues to tackle both problems, relating them to the problem of learning a mixture-model of product distributions."
  }, {
    "heading": "4.2. Experiment: Proposed χ2-Based Testers",
    "text": "Following the derivations in the proof of Theorem 11, we can see that Var(θ) = 1n ( I − 4η2diag(f 2) ) . As ever, we assume is a small constant and as a result the variance in 2ηf (which is approximately 4η 2\nn diag(p)) is significantly smaller than the variance of θ. This allows us to use the handwavey approximation f ≈ p, and argue that we have the approximation Var(θ) ≈ 1 n ( I − 4η2diag(p2) ) def = 1nM . Central Limit Theorem thus give that √ nM−1/2(θ − 2ηp) n→∞→ N (0, I). Therefore, it stands to reason that the norm of the LHS is distributed like a χ2-distribution, namely,\nP (θ) def = n ∑ x∈X (θ(x)− 2η · p(x))2 1− 4η2p(x)2 n→∞→ χ2T\nOur experiment is aimed at determining whether P (θ) can serve as a test statistic and assessing its sample complexity.\nSetting and Default Values. We set a true ground distribution on T possible types, p. We then pick a distribution q which is α-far from p using the counter example of Paninski (2008): we pair the types and randomly move 2αT probability mess between each pair of matched types. We then generate n samples according to q , and apply the nonsymmetric -differentially private mechanism of (Bassily et al., 2017). Finally, we aggregate the suitable vectors to obtain our estimator θ and compute P (θ). If we decide to accept/reject we do so based on comparison of P to the 23 -quantile of the χ 2 T -distribution, so that in the limit we reject only w.p. 1/3 under the null-hypothesis. We repeat this entire process t times. We have set the default values T = 10, p = uT (uniform on [T ]), α = 0.2, n = 1000, = 0.25 and therefore η = 12 e −1 e +1 , and t = 10000.\nExperiment 1: Convergence to the χ2-distribution in the null case. First we ask ourself whether our approximation, denoting P (θ) ≈ χ2T is correct when indeed p is\nthe distribution generating the signals. To that end, we set α = 0 (so the types are distributed according to p) and plot the t empirical values of P we in our experiment, varying both the sample size n ∈ {10, 100, 1000, 10000} and the domain size T ∈ {10, 25, 50, 100}. The results are consistent — P is distributed like a χ2T - distribution. Indeed, the mean of the t sample points is≈ T (the mean of a χ2T -distribution). The results themselves appear in Figure 2 in the supplementary material, Section D.\nExperiment 2: Divergence from the χ2-distribution in the alternate case. Secondly, we asked whether P can serve as a good way to differentiate between the null hypothesis (the distribution over the types is derived from p) and the alternative hypothesis (the distribution over the types if ≥ α-far from p). We therefore ran our experiment while varying α (between 0.25 and 0.05) and increasing n. Again, the results show that the distribution does shift towards higher values as n increases. The results are given in\nFigure 3 in the supplementary material, Section D.\nExperiment 3: Sample Complexity. Next, we set to find the required sample complexity for rejection. We fix the α-far distribution from p, and first do binary search to hone on an interval [nL, nU ] where the empirical rejection probability is between 30% − 35%; then we equipartition this interval and return the n for which the empirical rejection probability is the closest to 33%. We repeat this experiment multiple times, each time varying just one of the 3 most important parameters, T , α and . We maintain two parameters at default values, and vary just one parameter: T ∈ {5, 10, 15, .., 100}, α ∈ {0.05, 0.1, 0.15, ..., 0.5}, ∈ {0.05, 0.1, 0.15, ..., 0.5}. The results are shown in Figure 1, where next to each curve we plot the curve of our conjecture in a dotted line.4 We conjecture initially that n ∝ T cT · αcα · c . And so, for any parameter ξ ∈ {T, α, }, if we compare two experiments i, j that differ only on the value of this parameter and resulted in two empirical estimations Ni, Nj of the sample complexity, then we get that cξ ≈ log(Ni/Nj)log(ξi/ξj) . And so for any ξ ∈ {T, α, } we take the median over of all pairs of i and j and we get the empirical estimations of c = −1.900793, cα = −1.930947 and cT = 1.486957. This leads us to the conjecture that the actual sample complexity according to this test is T 1.5\nα2 2 .\nOpen Problem. Perhaps even more interesting, is the experiment we wish we could have run: a χ2-based independence testing. Assuming the distribution of the type is a product distribution p̄ = p1 × ... × pd, the proof of Theorem 13 shows that for each feature j we have Var(θj − pj) ≈ 14η2n T T j IX j . Thus 4η 2nT j T ‖θ j − pj‖2 n→∞→ χ2T j . However, the d estimators θj are not independent, so it is\n4We plot the dependency on α and on the same plot, as both took the same empirical values.\nnot true that ∑ j 4η 2nT j T ‖θ j − pj‖2 n→∞→ χ2∑ j T j . Moreover, even if the estimators of the marginals were independent,5 we are still unable to determine the asymptotic distribution of ‖θ̄−p̄‖2 (only a bound, scaled byO(maxj Tj), using Proposition 17 in the supplementary material), let alone the asymptotic distribution of ‖ 12ηθ − θ̄‖ 2.\nNonetheless, we did empirically measure the quantity\nQ(θ) def = n ∑ x ( 1 2η θ(x)−θ̄(x)) 2 θ̄(x) under the null (α = 0) and the alternative (α = 0.25) hypothesis with n = 25, 000 samples in each experiment. The results (given in Figure 4 in the supplementary material) show that the distribution of Q — albeit not resembling a χ2-distribution — is different under the null- and the alternative-hypothesis, so we suspect that there’s merit to using this quantity as a tester. We thus leave the design of a χ2-based statistics for independence in this model as an open problem.\n5E.g. by assigning each example i to one of the d estimators, costing only d = log(T ) factor in sample complexity"
  }, {
    "heading": "Acknowledgments",
    "text": "This work was supported by the Natural Sciences and Engineering Council of Canada, Grant #2017-06701. The author is also an unpaid collaborator on NSF grant 1565387. The authors thanks the anonymous reviewers for many helpful suggestions and ideas, as well as Marco Gaboardi and Ryan Rogers for helpful discussions illustrating the similarities and differences between our two papers."
  }],
  "year": 2018,
  "references": [{
    "title": "Optimal testing for properties of distributions",
    "authors": ["J. Acharya", "C. Daskalakis", "G. Kamath"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Categorical Data Analysis. Wiley Series in Probability and Statistics",
    "authors": ["A. Agresti"],
    "year": 2003
  }, {
    "title": "Learning with privacy at scale",
    "authors": ["D.P.T. Apple"],
    "venue": "Apple Machine Learning Journal,",
    "year": 2017
  }, {
    "title": "Local, private, efficient protocols for succinct histograms",
    "authors": ["R. Bassily", "A.D. Smith"],
    "venue": "In STOC, pp",
    "year": 2015
  }, {
    "title": "Practical locally private heavy hitters",
    "authors": ["R. Bassily", "K. Nissim", "U. Stemmer", "A.G. Thakurta"],
    "venue": "In NIPS,",
    "year": 2017
  }, {
    "title": "Priv’it: Private and sample efficient identity testing",
    "authors": ["B. Cai", "C. Daskalakis", "G. Kamath"],
    "venue": "In ICML,",
    "year": 2017
  }, {
    "title": "On the generalization ability of on-line learning algorithms",
    "authors": ["N. Cesa-bianchi", "A. Conconi", "C. Gentile"],
    "venue": "In NIPS, pp",
    "year": 2002
  }, {
    "title": "Convergence rates for differentially private statistical estimation",
    "authors": ["K. Chaudhuri", "D. Hsu"],
    "venue": "In ICML,",
    "year": 2012
  }, {
    "title": "Local privacy and statistical minimax rates",
    "authors": ["J. Duchi", "M. Jordan", "M. Wainwright"],
    "venue": "In FOCS,",
    "year": 2013
  }, {
    "title": "Local privacy and minimax bounds: Sharp rates for probability estimation",
    "authors": ["J.C. Duchi", "M.I. Jordan", "M.J. Wainwright"],
    "venue": "In NIPS,",
    "year": 2013
  }, {
    "title": "Differential privacy and robust statistics",
    "authors": ["C. Dwork", "J. Lei"],
    "venue": "In STOC,",
    "year": 2009
  }, {
    "title": "The Algorithmic Foundations of Differential Privacy",
    "authors": ["C. Dwork", "A. Roth"],
    "venue": "Foundations and Trends in Theoretical Computer Science, NOW Publishers,",
    "year": 2014
  }, {
    "title": "Private false discovery rate control",
    "authors": ["C. Dwork", "W. Su", "L. Zhang"],
    "venue": "CoRR, abs/1511.03803,",
    "year": 2015
  }, {
    "title": "Rappor: Randomized aggregatable privacy-preserving ordinal response",
    "authors": ["Ú. Erlingsson", "V. Pihur", "A. Korolova"],
    "venue": "In CCS,",
    "year": 2014
  }, {
    "title": "Local private hypothesis testing: Chi-square tests",
    "authors": ["M. Gaboardi", "R.M. Rogers"],
    "venue": "In ICML (to appear),",
    "year": 2018
  }, {
    "title": "Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing",
    "authors": ["M. Gaboardi", "H.W. Lim", "R. Rogers", "S.P. Vadhan"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "Logarithmic regret algorithms for online convex optimization",
    "authors": ["E. Hazan", "A. Kalai", "S. Kale", "A. Agarwal"],
    "venue": "In COLT, pp",
    "year": 2006
  }, {
    "title": "Privacy-preserving data exploration in genome-wide association studies",
    "authors": ["A. Johnson", "V. Shmatikov"],
    "venue": "In KDD, pp",
    "year": 2013
  }, {
    "title": "On learning distributions from their samples",
    "authors": ["S. Kamath", "A. Orlitsky", "D. Pichapati", "A.T. Suresh"],
    "venue": "In COLT, pp",
    "year": 2015
  }, {
    "title": "Finite sample differentially private confidence intervals, 2018",
    "authors": ["V. Karwa", "S. Vadhan"],
    "year": 2018
  }, {
    "title": "What can we learn privately",
    "authors": ["S.P. Kasiviswanathan", "H.K. Lee", "K. Nissim", "S. Raskhodnikova", "A. Smith"],
    "venue": "In FOCS,",
    "year": 2008
  }, {
    "title": "A coincidence-based test for uniformity given very sparsely sampled discrete data",
    "authors": ["L. Paninski"],
    "venue": "IEEE Trans. Information Theory,",
    "year": 2008
  }, {
    "title": "Approximate distributions of order statistics: with applications to nonparametric statistics. Springer series in statistics",
    "authors": ["R. Reiss"],
    "year": 1989
  }, {
    "title": "f-divergence inequalities",
    "authors": ["I. Sason", "S. Verdú"],
    "venue": "IEEE Trans. Information Theory,",
    "year": 2016
  }, {
    "title": "Differentially private ordinary least squares",
    "authors": ["O. Sheffet"],
    "venue": "In ICML,",
    "year": 2017
  }, {
    "title": "Privacy-preserving statistical estimation with optimal convergence rates",
    "authors": ["A. Smith"],
    "venue": "In STOC,",
    "year": 2011
  }, {
    "title": "Privacypreserving data sharing for genome-wide association studies",
    "authors": ["C. Uhler", "A.B. Slavkovic", "S.E. Fienberg"],
    "venue": "Journal of Privacy and Confidentiality,",
    "year": 2013
  }, {
    "title": "An automatic inequality prover and instance optimal identity testing",
    "authors": ["G. Valiant", "P. Valiant"],
    "venue": "In FOCS, pp. 51–",
    "year": 2014
  }, {
    "title": "URL http://arxiv",
    "authors": ["Vershynin", "R. Introduction to the non-asymptotic analysis of random matrices."],
    "venue": "org/abs/1011.3027.",
    "year": 2010
  }, {
    "title": "Differential privacy for clinical trial data: Preliminary evaluations",
    "authors": ["D. Vu", "A. Slavkovic"],
    "venue": "In ICDM,",
    "year": 2009
  }, {
    "title": "Differentially private hypothesis testing, revisited",
    "authors": ["Y. Wang", "J. Lee", "D. Kifer"],
    "venue": "CoRR, abs/1511.03376,",
    "year": 2015
  }, {
    "title": "Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias",
    "authors": ["S. Warner"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1965
  }, {
    "title": "Scalable privacy-preserving data sharing methodology for genome-wide association studies",
    "authors": ["F. Yu", "S. Fienberg", "A. Slavkovic", "C. Uhler"],
    "venue": "Journal of Biomedical Informatics,",
    "year": 2014
  }, {
    "title": "Online convex programming and generalized infinitesimal gradient ascent",
    "authors": ["M. Zinkevich"],
    "venue": "In ICML,",
    "year": 2003
  }],
  "id": "SP:897cfd9b46c65d95147f94d26d3626fe098d9b3c",
  "authors": [{
    "name": "Or Sheffet",
    "affiliations": []
  }],
  "abstractText": "We initiate the study of differentially private hypothesis testing in the local-model, under both the standard (symmetric) randomized-response mechanism (Warner, 1965; Kasiviswanathan et al., 2008) and the newer (non-symmetric) mechanisms (Bassily & Smith, 2015; Bassily et al., 2017). First, we study the general framework of mapping each user’s type into a signal and show that the problem of finding the maximum-likelihood distribution over the signals is feasible. Then we discuss the randomizedresponse mechanism and show that, in essence, it maps the nulland alternative-hypotheses onto new sets, an affine translation of the original sets. We then give sample complexity bounds for identity and independence testing under randomizedresponse. We then move to the newer nonsymmetric mechanisms and show that there too the problem of finding the maximum-likelihood distribution is feasible. Under the mechanism of Bassily et al (2017) we give identity and independence testers with better sample complexity than the testers in the symmetric case, and we also propose a χ-based identity tester which we investigate empirically.",
  "title": "Locally Private Hypothesis Testing"
}