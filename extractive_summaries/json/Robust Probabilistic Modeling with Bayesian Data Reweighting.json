{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Probabilistic modeling is a powerful approach to discovering hidden patterns in data. We begin by expressing assumptions about the class of patterns we expect to discover; this is how we design a probability model. We follow by inferring the posterior of the model; this is how we discover the specific patterns manifest in an observed data set. Advances in automated inference (Hoffman & Gelman, 2014; Mansinghka et al., 2014; Kucukelbir et al., 2017) enable easy development of new models for machine learning and artificial intelligence (Ghahramani, 2015).\nIn this paper, we present a recipe to robustify probabilistic models. What do we mean by “robustify”? Departure from a model’s assumptions can undermine its inference and prediction performance. This can arise due to corrupted\n1Columbia University, New York City, USA. Correspondence to: Yixin Wang <yixin.wang@columbia.edu>.\nProceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nobservations, or in general, measurements that do not belong to the process we are modeling. Robust models should perform well in spite of such mismatch with reality.\nConsider a movie recommendation system. We gather data of people watching movies via the account they use to log in. Imagine a situation where a few observations are corrupted For example, a child logs in to her account and regularly watches popular animated films. One day, her parents use the same account to watch a horror movie. Recommendation models, like Poisson factorization (PF), struggle with this kind of corrupted data (see Section 4): it begins to recommend horror movies.\nWhat can be done to detect and mitigate this effect? One strategy is to design new models that are less sensitive to corrupted data, such as by replacing a Gaussian likelihood with a heavier-tailed t distribution (Huber, 2011; Insua & Ruggeri, 2012). Most probabilistic models we use have more sophisticated structures; these template solutions for specific distributions are not readily applicable. Other classical robust techniques act mostly on distances between observations (Huber, 1973); these approaches struggle with high-dimensional data. How can we still make use of our favorite probabilistic models while making them less sensitive to the messy nature of reality?\nMain idea. We propose reweighted probabilistic models (RPM). The idea is simple. First, posit a probabilistic model. Then adjust the contribution of each observation by raising each likelihood term to its own (latent) weight. Finally, infer these weights along with the latent variables of the original probability model. The posterior of this adjusted model identifies observations that match its assumptions; it downweights observations that disagree with its assumptions.\n0 1 2\nFigure 1 depicts this tradeoff. The dataset includes cor-\nrupted measurements that undermine the original model; Bayesian data reweighting automatically trades off the low likelihood of the corrupted data near 1.5 to focus on the uncorrupted data near zero. The RPM (green curve) detects this mismatch and mitigates its effect compared to the poor fit of the original model (red curve).\nFormally, consider a dataset of N independent observations y D .y1; : : : ; yN /. The likelihood factorizes as a productQN\nnD1 `.yn j ˇ/, where ˇ is a set of latent variables. Posit a prior distribution pˇ .ˇ/.\nBayesian data reweighting follows three steps:\n1. Define a probabilistic model pˇ .ˇ/ QN\nnD1 `.yn j ˇ/. 2. Raise each likelihood to a positive latent weight wn.\nThen choose a prior on the weights pw.w/, where w D .w1; : : : ; wN /. This gives a reweighted probabilistic model (RPM)\np.y; ˇ; w/ D 1 Z pˇ .ˇ/pw.w/ NY nD1 `.yn j ˇ/wn ;\nwhere Z is the normalizing factor.\n3. Infer the posterior of both the latent variables ˇ and the weights w, p.ˇ; w j y/.\nThe latent weights w allow an RPM to automatically explore which observations match its assumptions and which do not. Writing out the logarithm of the RPM gives some intuition; it is equal (up to an additive constant) to\nlog pˇ .ˇ/ C log pw.w/ C X\nn\nwn log `.yn j ˇ/: (1)\nPosterior inference, loosely speaking, seeks to maximize the above with respect to ˇ and w. The prior on the weights pw.w/ plays a critical role: it trades off extremely low likelihood terms, caused by corrupted measurements, while encouraging the weights to be close to one. We study three options for this prior in Section 2.\nHow does Bayesian data reweighting induce robustness? First, consider how the weights w affect Equation (1). The logarithm of our priors are dominated by the log wn term: this is the price of moving wn from one towards zero. By shrinking wn, we gain an increase in wn log `.yn j ˇ/ while paying a price in a log wn. The gain outweighs the price we pay if log `.yn j ˇ/ is very negative. Our priors are set to prefer wn to stay close to one; an RPM only shrinks wn for very unlikely (e.g., corrupted) measurements.\nNow consider how the latent variables ˇ affect Equation (1). As the weights of unlikely measurements shrink, the likelihood term can afford to assign low mass to those corrupted measurements and focus on the rest of the dataset.\nJointly, the weights and latent variables work together to automatically identify unlikely measurements and focus on observations that match the original model’s assumptions.\nSection 2 presents these intuitions in full detail, along with theoretical corroboration. In Section 3, we study four models under various forms of mismatch with reality, including missing modeling assumptions, misspecified nonlinearities, and skewed data. RPMs provide better parameter inference and improved predictive accuracy across these models. Section 4 presents a recommendation system example, where we improve on predictive performance and identify atypical film enthusiasts in the Movielens 1M dataset.\nRelated work. Jerzy Neyman elegantly motivates the main idea behind robust probabilistic modeling, a field that has attracted much research attention in the past century.\nEvery attempt to use mathematics to study some real phenomena must begin with building a mathematical model of these phenomena. Of necessity, the model simplifies matters to a greater or lesser extent and a number of details are ignored. [...] The solution of the mathematical problem may be correct and yet it may be in violent conflict with realities simply because the original assumptions of the mathematical model diverge essentially from the conditions of the practical problem considered. (Neyman, 1949, p.22).\nOur work draws on three themes around robust modeling.\nThe first is a body of work on robust statistics and machine learning (Provost & Fawcett, 2001; Song et al., 2002; Yu et al., 2012; McWilliams et al., 2014; Feng et al., 2014; Shafieezadeh-Abadeh et al., 2015). These developments focus on making specific models more robust to imprecise measurements.\nOne strategy is popular: localization. To localize a probabilistic model, allow each likelihood to depend on its own “copy” of the latent variable ˇn. This transforms the model into\np.y; ˇ; ˛/ D p˛.˛/ NY\nnD1 `.yn j ˇn/pˇ .ˇn j ˛/; (2)\nwhere a top-level latent variable ˛ ties together all the ˇn variables (de Finetti, 1961; Wang & Blei, 2015).1 Localization decreases the effect of imprecise measurements. RPMs present a broader approach to mitigating mismatch, with improved performance over localization (Sections 3 and 4).\nThe second theme is robust Bayesian analysis, which studies sensitivity with respect to the prior (Berger et al., 1994).\n1 Localization also relates to James-Stein shrinkage; Efron (2010) connects these dots.\nRecent advances directly focus on sensitivity of the posterior (Minsker et al., 2014; Miller & Dunson, 2015) or the posterior predictive distribution (Kucukelbir & Blei, 2015). We draw connections to these ideas throughout this paper.\nThe third theme is data reweighting. This involves designing individual reweighting schemes for specific tasks and models. Consider robust methods that toss away “outliers.” This strategy involves manually assigning binary weights to datapoints (Huber, 2011). Another example is covariate shift adaptation/importance sampling where reweighting transforms data to match another target distribution (Veach & Guibas, 1995; Sugiyama et al., 2007; Shimodaira, 2000; Wen et al., 2014). In contrast, RPMs treat weights as latent variables. The weights are automatically inferred; no custom design is required. RPMs also connect to ideas around ensemble learning and boosting (Schapire & Freund, 2012). Boosting procedures reweight datapoints to build an ensemble of predictors for supervised learning, whereas RPMs apply to Bayesian models in general."
  }, {
    "heading": "2. Reweighted Probabilistic Models",
    "text": "Reweighted probabilistic models (RPM) offer a new approach to robust modeling. The idea is to automatically identify observations that match the assumptions of the model and to base posterior inference on these observations."
  }, {
    "heading": "2.1. Definitions",
    "text": "An RPM scaffolds over a probabilistic model, pˇ .ˇ/ QN nD1 `.yn j ˇ/. Raise each likelihood to a latent weight and posit a prior on the weights. This gives the reweighted joint density\np.y; ˇ; w/ D 1 Z pˇ .ˇ/pw.w/ NY nD1 `.yn j ˇ/wn ; (3) where Z D R pˇ .ˇ/pw.w/QNnD1 `.yn j ˇ/wn dy dˇ dw is the normalizing factor.\nThe reweighted density integrates to one when the normalizing factor Z is finite. This is always true when the likelihood `. j ˇ/ is an exponential family distribution with Lesbegue base measure (Bernardo & Smith, 2009); this is the class of models we study in this paper.2\nRPMs apply to likelihoods that factorize over the observations. (We discuss non-exchangeable models in Section 5.) Figure 2 depicts an RPM as a graphical model. Specific models may have additional structure, such as a separation of local and global latent variables (Hoffman et al., 2013), or fixed parameters; we omit these in this figure.\n2Heavy-tailed likelihoods and Bayesian nonparametric priors may violate this condition; we leave these for future analysis.\nˇ ynpˇ\nN\n(a) Original probabilistic model\nThe reweighted model introduces a set of weights; these are latent variables, each with support wn 2 R>0. To gain intuition, consider how these weights affect the posterior, which is proportional to the product of the likelihood of every measurement. A weight wn that is close to zero flattens out its corresponding likelihood `.yn j ˇ/wn ; a weight that is larger than one makes its likelihood more peaked. This, in turn, enables the posterior to focus on some measurements more than others. The prior pw.w/ ensures that not too many likelihood terms get flattened; in this sense, it plays an important regularization role.\nWe study three options for this prior on weights: a bank of Beta distributions, a scaled Dirichlet distribution, and a bank of Gamma distributions.\nBank of Beta priors. This option constrains each weight as wn 2 .0; 1/. We posit an independent prior for each weight\npw.w/ D NY\nnD1 Beta.wn I a; b/ (4)\nand use the same parameters a and b for all weights. This is the most conservative option for the RPM; it ensures that none of the likelihoods ever becomes more peaked than it was in the original model.\nThe parameters a, b offer an expressive language to describe different attitudes towards the weights. For example, setting both parameters less than one makes the Beta act like a “two spikes and a slab” prior, encouraging weights to be close to zero or one, but not in between. As another example, setting a greater than b encourages weights to lean towards one.\nScaled Dirichlet prior. This option ensures the sum of the weights equals N . We posit a symmetric Dirichlet prior on all the weights\nw D Nv pv.v/ D Dirichlet.a1/ (5)\nwhere a is a scalar parameter and 1 is a .N ⇥ 1/ vector of ones. In the original model, where all the weights are one, then the sum of the weights is N . The Dirichlet option maintains this balance; while certain likelihoods may become more peaked, others will flatten to compensate.\nThe concentration parameter a gives an intuitive way to configure the Dirichlet. Small values for a allow the model to easily up- or down-weight many data observations; larger values for a prefer a smoother distribution of weights. The Dirichlet option connects to the bootstrap approaches in Rubin et al. (1981); Kucukelbir & Blei (2015), which also preserves the sum of weights as N .\nBank of Gamma priors. Here we posit an independent Gamma prior for each weight\npw.w/ D NY\nnD1 Gamma.wn I a; b/ (6)\nand use the same parameters a and b for all weights. We do not recommend this option, because observations can be arbitrarily up- or down-weighted. In this paper, we only consider Equation (6) for our theoretical analysis in Section 2.2.\nThe bank of Beta and Dirichlet options perform similarly. We prefer the Beta option as it is more conservative, yet find the Dirichlet to be less sensitive to its parameters. We explore these options in the empirical study (Section 3)."
  }, {
    "heading": "2.2. Theory and intuition",
    "text": "How can theory justify Bayesian data reweighting? Here we investigate its robustness properties. These analyses intend to confirm our intuition from Section 1. Appendices B and C present proofs in full technical detail.\nIntuition. Recall the logarithm of the RPM joint density from Equation (1).Now compute the maximum-a-posterior (MAP) estimate of the weights w. The partial derivative is\n@ log p.y; ˇ; w/ @wn D d log pw.wn/ dwn C log `.yn j ˇ/ (7)\nfor all n D 1; : : : ; N . Plug the Gamma prior from Equation (6) into the partial derivative in Equation (7) and set it equal to zero. This gives the MAP estimate of wn,\nbwn D a 1 b log `.yn j ˇ/ : (8)\nThe MAP estimate bwn is an increasing function of the log likelihood of yn when a > 1. This reveals that bwn shrinks the contribution of observations that are unlikely under the log likelihood; in turn, this encourages the MAP estimate for b̌ to describe the majority of the observations. This is how an RPM makes a probabilistic model more robust.\nA similar argument holds for other exponential family priors on w with log wn as a sufficient statistic. We formalize this intuition and generalize it in the following theorem, which establishes sufficient conditions where a RPM improves the inference of its latent variables ˇ.\nTheorem 1 Denote the true value of ˇ as ˇ⇤. Let the posterior mean of ˇ under the weighted and unweighted model be Ňw and Ňu respectively. Assume mild conditions on pw , ` and the corruption level, and that j`.yn j Ňw/ `.yn j ˇ⇤/j < ✏ holds 8n with high probability. Then, there exists an N ⇤ such that for N > N ⇤, we have j Ňu ˇ⇤j ⌫2 j Ňw ˇ⇤j, where ⌫2 denotes second order stochastic dominance. (Details in Appendix B.)\nThe likelihood bounding assumption is common in robust statistics theory; it is satisfied for both likely and unlikely (corrupted) measurements. How much of an improvement does it give? We can quantify this through the influence function (IF) of Ňw . Consider a distribution G and a statistic T .G/ to be a function of data that comes iid from G. Take a fixed distribution, e.g., the population distribution, F . Then, IF.zI T; F / measures how much an additional observation at z affects the statistic T .F /. Define\nIF.zI T; F / D lim t!0C T .tız C .1 t /F / T .F / t\nfor z where this limit exists. Roughly, the IF measures the asymptotic bias on T .F / caused by a specific observation z that does not come from F . We consider a statistic T to be robust if its IF is a bounded function of z, i.e., if outliers can only exert a limited influence (Huber, 2011). Here, we study the IF of the posterior mean T D Ňw under the true data generating distribution F D `. j ˇ⇤/. Say a value z has likelihood `.z j ˇ⇤/ that is nearly zero; we think of this z as corrupted. Now consider the weight function induced by the prior pw.w/. Rewrite it as a function of the log likelihood, like w.log `. j ˇ⇤// as in Equation (8). Theorem 2 If lima! 1 w.a/ D 0 and lima! 1 a w.a/ < 1, then IF.zI Ňw ; `. j ˇ⇤// ! 0 as `.z j ˇ⇤/ ! 0:\nThis result shows that an RPM is robust in that its IF goes to zero for unlikely measurements. This is true for all three priors. (Details in Appendix C.)"
  }, {
    "heading": "2.3. Inference and computation",
    "text": "We now turn to inferring the posterior of an RPM, p.ˇ; w j y/. The posterior lacks an analytic closed-form expression for all but the simplest of models; even if the original model admits such a posterior for ˇ, the reweighted posterior may take a different form.\nTo approximate the posterior, we appeal to probabilistic programming. A probabilistic programming system enables a user to write a probability model as a computer program and then compile that program into an inference executable. Automated inference is the backbone of such systems: it takes in a probability model, expressed as a program, and outputs an efficient algorithm for inference. We use automated inference in Stan, a probabilistic programming system (Carpenter et al., 2015).\nIn the empirical study that follows, we highlight how RPMs detect and mitigate various forms of model mismatch. As a common metric, we compare the predictive accuracy on held out data for the original, localized, and reweighted model.\nThe posterior predictive likelihood of a new datapoint yé is poriginal.yé j y/ D R `.yé j ˇ/p.ˇ j y/ dˇ: Localization couples each observation with its own copy of the latent variable; this gives plocalized.yé j y/ D’\n`.yé j ˇé/p.ˇé j ˛/p.˛ j y/ d˛ dˇé where ˇé is the localized latent variable for the new datapoint. The prior p.ˇé j ˛/ has the same form as pˇ in Equation (2). Bayesian data reweighting gives the following posterior predictive likelihood pRPM.yé j y/ D “ p.yé j ˇ; wé/pRPM.ˇ j y/p.wé/ dwé dˇ;\nwhere pRPM.ˇ j y/ is the marginal posterior, integrating out the inferred weights of the training dataset, and the prior p.wé/ has the same form as pw in Equation (3)."
  }, {
    "heading": "3. Empirical Study",
    "text": "We study RPMs under four types of mismatch with reality. This section involves simulations of realistic scenarios; the next section presents a recommendation system example using real data. We default to No-U-Turn sampler (NUTS) (Hoffman & Gelman, 2014) for inference in all experiments, except for Sections 3.5 and 4 where we leverage variational inference (Kucukelbir et al., 2017). The additional computational cost of inferring the weights is unnoticeable relative to inference in the original model."
  }, {
    "heading": "3.1. Outliers: a network wait-time example",
    "text": "A router receives packets over a network and measures the time it waits for each packet. Suppose we typically observe wait-times that follow a Poisson distribution with rate ˇ D 5. We model each measurement using a Poisson likelihood `.yn j ˇ/ D Poisson.ˇ/ and posit a Gamma prior on the rate pˇ .ˇ/ D Gam.a D 2; b D 0:5/. Imagine that F % percent of the time, the network fails. During these failures, the wait-times come from a Poisson with much higher rate ˇ D 50. Thus, the data actually contains a mixture of two Poisson distributions; yet, our model only assumes one. (Details in Appendix D.1.)\nHow do we expect an RPM to behave in this situation? Suppose the network failed 25% of the time. Figure 3a shows the posterior distribution on the rate ˇ. The original posterior is centered at 18; this is troubling, not only because the rate is wrong but also because of how confident the posterior fit is. Localization introduces greater uncertainty, yet still estimates a rate around 15. The RPM correctly identifies that the majority of the observations come from ˇ D 5. Observations from when the network failed are down-weighted. It gives a confident posterior centered at five.\nFigure 3b shows posterior 95% credible intervals of ˇ under failure rates up to F D 45%. The RPM is robust to corrupted measurements; instead it focuses on data that it can\nexplain within its assumptions. When there is no corruption, the RPM performs just as well as the original model.\nVisualizing the weights elucidates this point. Figure 4 shows the posterior mean estimates of w for F D 25%. The weights are sorted into two groups, for ease of viewing. The weights of the corrupted observations are essentially zero; this downweighting is what allows the RPM to shift its posterior on ˇ towards five.\nDespite this downweighting, the RPM posteriors on ˇ are not overdispersed, as in the localized case. This is due to the interplay we described in the introduction. Downweighting observations should lead to a smaller effective sample size, which would increase posterior uncertainty. But the downweighted datapoints are corrupted observations; including them also increases posterior uncertainty.\nThe RPM is insensitive to the prior on the weights; both Beta and Dirichlet options perform similarly. From here on, we focus on the Beta option. We let the shape parameter a scale with the data size N such that N=a ⇡ 103; this encodes a mild attitude towards unit weights. We now move on to other forms of mismatch with reality."
  }, {
    "heading": "3.2. Missing latent groups: predicting color blindness",
    "text": "Color blindness is unevenly hereditary: it is much higher for men than for women (Boron & Boulpaep, 2012). Suppose we are not aware of this fact. We have a dataset of both genders with each individual’s color blindness status and his/her relevant family history. No gender information is available. Consider analyzing this data using logistic regression. It can only capture one hereditary group. Thus, logistic regression misrepresents both groups, even though men exhibit strong heredity. In contrast, an RPM can detect and mitigate the missing group effect by focusing on the dominant hereditary trait. Here we consider men as the dominant group.\nWe simulate this scenario by drawing binary indicators of color blindness yn ⇠ Bernoulli.1=1 C exp. pn// where the pn’s come from two latent groups: men exhibit a stronger dependency on family history (pn D 0:5xn) than women (pn D 0:01xn). We simulate family history as\nxn ⇠ Unif. 10; 10/. Consider a Bayesian logistic regression model without intercept. Posit a prior on the slope as pˇ .ˇ/ D N .0; 10/ and assume a Beta.0:1; 0:01/ prior on the weights. (Details in Appendix D.2.)\nFigure 5 shows the posterior 95% credible intervals of ˇ as we vary the percentage of females from F D 0% to 40%. A horizontal line indicates the correct slope for the dominant group, ˇmen D 0:5. As the size of the missing latent group (women) increases, the original model quickly shifts its credible interval away from 0:5. The reweighted and localized posteriors both contain ˇmen D 0:5 for all percentages, but the localized model exhibits much higher variance in its estimates.\nThis analysis shows how RPMs can mitigate the effect of missing latent groups. While the original logistic regression model would perform equally poorly on both groups, an RPM is able to automatically focus on the dominant group.\n0 1\nEp.wjy/Œwç\nD en\nsi ty Corrupted (F D 25%)\nClean (F D 0%)\nFigure 6. Kernel density estimate of the distribution of weights across all measurements in the missing latent groups study. The percentage of females is denoted by F . A hypothetical clean dataset receives weights that concentrate around one; the actual corrupted dataset exhibits a two-hump distribution of weights.\nAn RPM also functions as a diagnostic tool to detect mismatch with reality. The distribution of the inferred weights indicates the presence of datapoints that defy the assumptions of the original model. Figure 6 shows a kernel density estimate of the inferred posterior weights. A hypothetical dataset with no corrupted measurements receives weights close to one. In contrast, the actual dataset with measurements from a missing latent group exhibit a bimodal distribution of weights. Testing for bimodality of the inferred weights is one way in which an RPM can be used to diagnose mismatch with reality."
  }, {
    "heading": "3.3. Covariate dependence misspecification: a lung cancer risk study",
    "text": "Consider a study of lung cancer risk. While tobacco usage exhibits a clear connection, other factors may also contribute. For instance, obesity and tobacco usage appear to interact, with evidence towards a quadratic dependence on obesity (Odegaard et al., 2010).\nDenote tobacco usage as x1 and obesity as x2. We study three models of lung cancer risk dependency on these covariates. We are primarily interested in understanding the effect of tobacco usage; thus we focus on ˇ1, the regression coefficient for tobacco. In each model, some form of covariance misspecification discriminates the true structure from the assumed structure.\nFor each model, we simulate a dataset of size N D 100 with random covariates x1 ⇠ N .10; 52/ and x2 ⇠ N .0; 102/ and regression coefficients ˇ0;1;2;3 ⇠ Unif. 10; 10/. Consider a Bayesian linear regression model with prior pˇ .ˇ/ D N .0; 10/. (Details in Appendix D.3.) Table 1 summarizes the misspecification and shows absolute differences on the estimated ˇ1 regression coefficient. The RPM yields better estimates of ˇ1 in the first two models. These highlight how the RPM leverages datapoints useful for estimating ˇ1. The third model is particularly challenging because obesity is ignored in the misspecified model. Here, the RPM gives similar results to the original model; this highlights that RPMs can only use available information. Since the original model lacks dependence on x2, the RPM cannot compensate for this."
  }, {
    "heading": "3.4. Predictive likelihood results",
    "text": "Table 2 shows how RPMs also improve predictive accuracy. In all the above examples, we simulate test data with and without their respective types of corruption. RPMs improve prediction for both clean and corrupted data, as they focus on data that match the assumptions of the original model."
  }, {
    "heading": "3.5. Skewed data: cluster selection in a mixture model",
    "text": "Finally, we show how RPMs handle skewed data. The Dirichlet process mixture model (DPMM) is a versatile model for density estimation and clustering (Bishop, 2006;\nMurphy, 2012). While real data may indeed come from a finite mixture of clusters, there is no reason to assume each cluster is distributed as a Gaussian. Inspired by the experiments in Miller & Dunson (2015), we show how a reweighted DPMM reliably recovers the correct number of components in a mixture of skewnormals dataset.\nA standard Gaussian mixture model (GMM) with large K and a sparse Dirichlet prior on the mixture proportions is an approximation to a DPMM (Ishwaran & James, 2012). We simulate three clusters from two-dimensional skewnormal distributions and fit a GMM with maximum K D 30. Here we use automatic differentiation variational inference (ADVI), as NUTS struggles with inference of mixture models (Kucukelbir et al., 2017). (Details in Appendix D.4.)\nFigure 7 shows posterior mean estimates from the original GMM; it incorrectly finds six clusters. In contrast, the RPM identifies the correct three clusters. Datapoints in the tails of each cluster get down-weighted; these are datapoints that do not match the Gaussianity assumption of the model."
  }, {
    "heading": "4. Case Study: Poisson factorization for recommendation",
    "text": "We now turn to a study of real data: a recommendation system. Consider a video streaming service; data comes as a binary matrix of users and the movies they choose to watch. How can we identify patterns from such data? Poisson factorization (PF) offers a flexible solution (Cemgil, 2009; Gopalan et al., 2015). The idea is to infer a K-dimensional\nlatent space of user preferences ✓ and movie attributes ˇ. The inner product ✓>ˇ determines the rate of a Poisson likelihood for each binary measurement; Gamma priors on ✓ and ˇ promote sparse patterns. As a result, PF finds interpretable groupings of movies, often clustered according to popularity or genre. (Full model in Appendix E.)\nHow does classical PF compare to its reweighted counterpart? As input, we use the MovieLens 1M dataset, which contains one million movie ratings from 6 000 users on 4 000 movies. We place iid Gamma.1; 0:001/ priors on the preferences and attributes. Here, we have the option of reweighting users or items. We focus on users and place a Beta.100; 1/ prior on their weights. For this model, we use MAP estimation. (Localization is computationally challenging for PF; it requires a separate “copy” of ✓ for each movie, along with a separate ˇ for each user. This dramatically increases computational cost.)\nWe begin by analyzing the original (clean) dataset. Reweighting improves the average held-out log likelihood from 1:68 of the original model to 1:53 of the corre-\nsponding RPM. The boxplot in Figure 8a shows the inferred weights. The majority of users receive weight one, but a few users are down-weighted. These are film enthusiasts who appear to indiscriminately watch many movies from many genres. (Appendix F shows an example.) These users do not contribute towards identifying movies that go together; this explains why the RPM down-weights them.\nRecall the example from our introduction. A child typically watches popular animated films, but her parents occasionally use her account to watch horror films. We simulate this by corrupting a small percentage of users. We replace a ratio R D .0:1; 0:5; 1/ of these users’ movies with randomly selected movies.\nThe boxplot in Figure 8b shows the weights we infer for these corrupted users, based on how many of their movies we randomly replace. The weights decrease as we corrupt more movies. Table 3 shows how this leads to higher heldout predictive accuracy; down-weighting these corrupted users leads to better prediction."
  }, {
    "heading": "5. Discussion",
    "text": "Reweighted probabilistic models (RPM) offer a systematic approach to mitigating various forms of mismatch with reality. The idea is to raise each data likelihood to a weight and to infer the weights along with the hidden patterns. We demonstrate how this strategy introduces robustness and improves prediction accuracy across four types of mismatch.\nRPMs also offer a way to detect mismatch with reality. The distribution of the inferred weights sheds light onto datapoints that fail to match the original model’s assumptions. RPMs can thus lead to new model development and deeper insights about our data.\nRPMs can also work with non-exchangeable data, such as time series. Some time series models admit exchangeable likelihood approximations (Guinness & Stein, 2013). For other models, a non-overlapping windowing approach would also work. The idea of reweighting could also extend to structured likelihoods, such as Hawkes process models."
  }, {
    "heading": "Acknowledgements",
    "text": "We thank Adji Dieng, Yuanjun Gao, Inchi Hu, Christian Naesseth, Rajesh Ranganath, Francisco Ruiz, and Dustin Tran for their insightful comments. This work is supported by NSF IIS-1247664, ONR N00014-11-1-0651, DARPA PPAML FA8750-14-2-0009, DARPA SIMPLEX N6600115-C-4032, and the Alfred P. Sloan Foundation."
  }],
  "year": 2017,
  "references": [{
    "title": "An overview of robust Bayesian analysis",
    "authors": ["Berger", "James O", "Moreno", "Elías", "Pericchi", "Luis Raul", "Bayarri", "M Jesús", "Bernardo", "José M", "Cano", "Juan A", "De la Horra", "Julián", "Martín", "Jacinto", "Ríos-Insúa", "David", "Betrò", "Bruno"],
    "year": 1994
  }, {
    "title": "Pattern Recognition and Machine Learning",
    "authors": ["Bishop", "Christopher M"],
    "year": 2006
  }, {
    "title": "Stan: a probabilistic programming language",
    "authors": ["Carpenter", "Bob", "Gelman", "Andrew", "Hoffman", "Matt", "Lee", "Daniel", "Goodrich", "Ben", "Betancourt", "Michael", "Brubaker", "Marcus A", "Guo", "Jiqiang", "Li", "Peter", "Riddell", "Allen"],
    "venue": "Journal of Statistical Software,",
    "year": 2015
  }, {
    "title": "Bayesian inference for nonnegative matrix factorisation models",
    "authors": ["Cemgil", "Ali Taylan"],
    "venue": "Computational Intelligence and Neuroscience,",
    "year": 2009
  }, {
    "title": "The Bayesian approach to the rejection of outliers",
    "authors": ["de Finetti", "Bruno"],
    "venue": "In Proceedings of the Fourth Berkeley Symposium on Probability and Statistics,",
    "year": 1961
  }, {
    "title": "Large-Scale Inference",
    "authors": ["Efron", "Bradley"],
    "year": 2010
  }, {
    "title": "Robust logistic regression and classification",
    "authors": ["Feng", "Jiashi", "Xu", "Huan", "Mannor", "Shie", "Yan", "Shuicheng"],
    "venue": "In NIPS",
    "year": 2014
  }, {
    "title": "Probabilistic machine learning and artificial intelligence",
    "authors": ["Ghahramani", "Zoubin"],
    "venue": "Nature, 521(7553):452–459,",
    "year": 2015
  }, {
    "title": "Scalable recommendation with hierarchical Poisson factorization",
    "authors": ["Gopalan", "Prem", "Hofman", "Jake M", "Blei", "David M"],
    "year": 2015
  }, {
    "title": "Transformation to approximate independence for locally stationary Gaussian processes",
    "authors": ["Guinness", "Joseph", "Stein", "Michael L"],
    "venue": "Journal of Time Series Analysis,",
    "year": 2013
  }, {
    "title": "The No-U-Turn sampler",
    "authors": ["Hoffman", "Matthew D", "Gelman", "Andrew"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2014
  }, {
    "title": "Stochastic variational inference",
    "authors": ["Hoffman", "Matthew D", "Blei", "David M", "Wang", "Chong", "Paisley", "John"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2013
  }, {
    "title": "Robust regression: asymptotics, conjectures and Monte Carlo",
    "authors": ["Huber", "Peter J"],
    "venue": "The Annals of Statistics,",
    "year": 1973
  }, {
    "title": "Robust Bayesian Analysis",
    "authors": ["Insua", "David Ríos", "Ruggeri", "Fabrizio"],
    "venue": "Springer Science & Business Media,",
    "year": 2012
  }, {
    "title": "Approximate Dirichlet process computing in finite normal mixtures",
    "authors": ["Ishwaran", "Hemant", "James", "Lancelot F"],
    "venue": "Journal of Computational and Graphical Statistics,",
    "year": 2012
  }, {
    "title": "Population empirical Bayes",
    "authors": ["Kucukelbir", "Alp", "Blei", "David M"],
    "venue": "In UAI,",
    "year": 2015
  }, {
    "title": "Automatic differentiation variational inference",
    "authors": ["Kucukelbir", "Alp", "Tran", "Dustin", "Ranganath", "Rajesh", "Gelman", "Andrew", "Blei", "David M"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2017
  }, {
    "title": "Venture: a higher-order probabilistic programming platform with programmable inference",
    "authors": ["Mansinghka", "Vikash", "Selsam", "Daniel", "Perov", "Yura"],
    "year": 2014
  }, {
    "title": "Fast and robust least squares estimation in corrupted linear models",
    "authors": ["McWilliams", "Brian", "Krummenacher", "Gabriel", "Lucic", "Mario", "Buhmann", "Joachim M"],
    "venue": "In NIPS",
    "year": 2014
  }, {
    "title": "Robust Bayesian inference via coarsening",
    "authors": ["Miller", "Jeffrey W", "Dunson", "David B"],
    "venue": "arXiv preprint arXiv:1506.06101,",
    "year": 2015
  }, {
    "title": "Robust and scalable Bayes via a median of subset posterior measures",
    "authors": ["Minsker", "Stanislav", "Srivastava", "Sanvesh", "Lin", "Lizhen", "Dunson", "David B"],
    "venue": "arXiv preprint arXiv:1403.2660,",
    "year": 2014
  }, {
    "title": "Machine Learning: a Probabilistic Perspective",
    "authors": ["Murphy", "Kevin P"],
    "year": 2012
  }, {
    "title": "On the problem of estimating the number of schools of fish",
    "authors": ["Neyman", "Jerzy"],
    "venue": "University of California Publications in Statistics,",
    "year": 1949
  }, {
    "title": "Robust classification for imprecise environments",
    "authors": ["Provost", "Foster", "Fawcett", "Tom"],
    "venue": "Machine Learning,",
    "year": 2001
  }, {
    "title": "The Bayesian bootstrap",
    "authors": ["Rubin", "Donald B"],
    "venue": "The annals of statistics,",
    "year": 1981
  }, {
    "title": "Boosting: Foundations and Algorithms",
    "authors": ["R.E. Schapire", "Y. Freund"],
    "year": 2012
  }, {
    "title": "Distributionally robust logistic regression",
    "authors": ["Shafieezadeh-Abadeh", "Soroosh", "Esfahani", "Peyman Mohajerin", "Kuhn", "Daniel"],
    "venue": "In NIPS",
    "year": 2015
  }, {
    "title": "Improving predictive inference under covariate shift by weighting the log-likelihood function",
    "authors": ["Shimodaira", "Hidetoshi"],
    "venue": "Journal of Statistical Planning and Inference,",
    "year": 2000
  }, {
    "title": "Robust support vector machine with bullet hole image classification. Systems, Man, and Cybernetics, Part C: Applications and Reviews",
    "authors": ["Song", "Qing", "Hu", "Wenjie", "Xie", "Wenfang"],
    "venue": "IEEE Transactions on,",
    "year": 2002
  }, {
    "title": "Covariate shift adaptation by importance weighted cross validation",
    "authors": ["Sugiyama", "Masashi", "Krauledat", "Matthias", "Müller", "Klaus-Robert"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2007
  }, {
    "title": "Optimally combining sampling techniques for Monte Carlo rendering",
    "authors": ["Veach", "Eric", "Guibas", "Leonidas J"],
    "venue": "In Proceedings of the 22nd annual conference on Computer graphics and interactive techniques,",
    "year": 1995
  }, {
    "title": "A general method for robust Bayesian modeling",
    "authors": ["Wang", "Chong", "Blei", "David M"],
    "venue": "arXiv preprint arXiv:1510.05078,",
    "year": 2015
  }, {
    "title": "Robust learning under uncertain test distributions: Relating covariate shift to model misspecification",
    "authors": ["Wen", "Junfeng", "Yu", "Chun-nam", "Greiner", "Russell"],
    "venue": "In ICML,",
    "year": 2014
  }, {
    "title": "A polynomial-time form of robust regression",
    "authors": ["Yu", "Yaoliang", "Aslan", "Özlem", "Schuurmans", "Dale"],
    "venue": "In NIPS",
    "year": 2012
  }],
  "id": "SP:6d43d343c8f46f84858062e5efa13753d4e668bd",
  "authors": [{
    "name": "Yixin Wang",
    "affiliations": []
  }, {
    "name": "Alp Kucukelbir",
    "affiliations": []
  }, {
    "name": "David M. Blei",
    "affiliations": []
  }],
  "abstractText": "Probabilistic models analyze data by relying on a set of assumptions. Data that exhibit deviations from these assumptions can undermine inference and prediction quality. Robust models offer protection against mismatch between a model’s assumptions and reality. We propose a way to systematically detect and mitigate mismatch of a large class of probabilistic models. The idea is to raise the likelihood of each observation to a weight and then to infer both the latent variables and the weights from data. Inferring the weights allows a model to identify observations that match its assumptions and down-weight others. This enables robust inference and improves predictive accuracy. We study four different forms of mismatch with reality, ranging from missing latent groups to structure misspecification. A Poisson factorization analysis of the Movielens 1M dataset shows the benefits of this approach in a practical scenario.",
  "title": "Robust Probabilistic Modeling with Bayesian Data Reweighting"
}