{
  "sections": [{
    "text": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 860–865, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics\n___________________ *Corresponding author\nion analysis to make use of available language resources for other resource scarce languages. However, the cumulative class noise in transfer learning adversely affects performance when more training data is used. In this paper, we propose a novel method in transductive transfer learning to identify noises through the detection of negative transfers. Evaluation on NLP&CC 2013 cross-lingual opinion analysis dataset shows that our approach outperforms the state-of-the-art systems. More significantly, our system shows a monotonic increase trend in performance improvement when more training data are used."
  }, {
    "heading": "1 Introduction",
    "text": "Mining opinions from text by identifying their positive and negative polarities is an important task and supervised learning methods have been quite successful. However, supervised methods require labeled samples for modeling and the lack of sufficient training data is the performance bottle-neck in opinion analysis especially for resource scarce languages. To solve this problem, the transfer leaning method (Arnold et al., 2007) have been used to make use of samples from a resource rich source language to a resource scarce target language, also known as cross language opinion analysis (CLOA).\nIn transductive transfer learning (TTL) where the source language has labeled data and the target language has only unlabeled data, an algorithm needs to select samples from the unlabeled target language as the training data and assign them with class labels using some estimated confidence. These labeled samples in the target language, referred to as the transferred samples, also have a probability of being misclassified. During\nes class noise which accumulates, resulting in a so called negative transfer that affects the classification performance.\nIn this paper, we propose a novel method aimed at reducing class noise for TTL in CLOA. The basic idea is to utilize transferred samples with high quality to identify those negative transfers and remove them as class noise to reduce noise accumulation in future training iterations. Evaluations on NLP&CC 2013 CLOA evaluation data set show that our algorithm achieves the best result, outperforming the current state-ofthe-art systems. More significantly, our system shows a monotonic increasing trend in performance when more training data are used beating the performance degradation curse of most transfer learning methods when training data reaches certain size.\nThe rest of the paper is organized as follows. Section 2 introduces related works in transfer learning, cross lingual opinion analysis, and class noise detection technology. Section 3 presents our algorithm. Section 4 gives performance evaluation. Section 5 concludes this paper."
  }, {
    "heading": "2 Related works",
    "text": "TTL has been widely used before the formal concept and definition of TTL was given in (Arnold, 2007). Wan introduced the co-training method into cross-lingual opinion analysis (Wan, 2009; Zhou et al., 2011), and Aue et al. introduced transfer learning into cross domain analysis (Aue, 2005) which solves similar problems. In this paper, we will use the terms source language and target language to refer to all cross lingual/domain analysis.\nTraditionally, transfer learning methods focus on how to estimate the confidence score of transferred samples in the target language or domain (Blitzer et al, 2006, Huang et al., 2007; Sugiyama et al., 2008, Chen et al, 2011, Lu et al., 2011). In some tasks, researchers utilize NLP tools such as alignment to reduce the bias towards that of\n860\nthe source language in transfer learning (Meng et al., 2012). However, detecting misclassification in transferred samples (referred to as class noise) and reducing negative transfers are still an unresolved problem.\nThere are two basic methods for class noise detection in machine learning. The first is the classification based method (Brodley and Friedl, 1999; Zhu et al, 2003; Zhu 2004; Sluban et al., 2010) and the second is the graph based method (Zighed et al, 2002; Muhlenbach et al, 2004; Jiang and Zhou, 2004). Class noise detection can also be applied to semi-supervised learning because noise can accumulate in iterations too. Li employed Zighed’s cut edge weight statistic method in self-training (Li and Zhou, 2005) and co-training (Li and Zhou, 2011). Chao used Li’s method in tri-training (Chao et al, 2008). (Fukumoto et al, 2013) used the support vectors to detect class noise in semi-supervised learning.\nIn TTL, however, training and testing samples\ncannot be assumed to have the same distributions. Thus, noise detection methods used in semisupervised learning are not directly suited in TTL. Y. Cheng has tried to use semi-supervised method (Jiang and Zhou, 2004) in transfer learning (Cheng and Li, 2009). His experiment showed that their approach would work when the source domain and the target domain share similar distributions. How to reduce negative transfers is still a problem in transfer learning."
  }, {
    "heading": "3 Our Approach",
    "text": "In order to reduce negative transfers, we propose to incorporate class noise detection into TTL. The basic idea is to first select high quality labeled samples after certain iterations as indicator to detect class noise in transferred samples. We then remove noisy samples that cause negative transfers from the current accumulated training set to retain an improved set of training data for the remainder of the training phase. This negative sample reduction process can be repeated several times during transfer learning. Two questions must be answered in this approach: (1) how to measure the quality of transferred samples, and (2) how to utilize high quality labeled samples to detect class noise in training data."
  }, {
    "heading": "3.1 Estimating Testing Error",
    "text": "To determine the quality of the transferred samples that are added iteratively in the learning process, we cannot use training error to estimate true error because the training data and the test-\ning data have different distributions. In this work, we employ the Probably Approximately Correct (PAC) learning theory to estimate the error boundary. According to the PAC learning theory, the least error boundary ε is determined by the size of the training set m and the class noise rate η, bound by the following relation:\n√ ( ) ( ) In TTL, m increases linearly, yet η is multiplied in each iteration. This means the significance of m to performance is higher at the beginning of transfer learning and gradually slows down in later iterations. On the contrary, the influence of class noise increases. That is why performance improves initially and gradually falls to negative transfer when noise accumulation outperforms the learned information as shown in Fig.1. In TTL, transferred samples in both the training data and test data have the same distribution. This implies that we can apply the PAC theory to analyze the error boundary of the machine learning model using transferred data.\nAccording to PAC theorem with an assumed fixed probability δ (Angluin and Laird, 1988), the least error boundary ε is given by:\n√ ( ⁄ ) ( ( ) ) ( ) where N is a constant decided by the hypothesis space. In any iteration during TTL, the hypothesis space is the same and the probability δ is fixed. Thus the least error boundary is determined by the size of the transferred sample m and the class noise of transferred samples η. According to (2), we apply a manifold assumption based method to estimate η. Let T be the number of iterations to serve as one period. We then estimate the least error boundary before and after each T to measure the quality of transferred samples during each T. If the least error boundary is reduced, it means that transferred samples used in this period are of high quality and can improve the performance. Otherwise, the transfer learning algorithm should stop."
  }, {
    "heading": "3.2 Estimating Class Noise",
    "text": "For formula (2) to work, we need to know the class noise rate η to calculate the error boundary. Obviously, we cannot use conditional probabilities from the training data in the source language to estimate the noise rate η of the transferred samples because the distribution of source language is different from that of target language.\nConsider a KNN graph on the transferred samples using any similarity metric, for example, cosine similarity, for any two connected vertex ( )and ( ) in the graph from samples to classes, the edge weight is given by:\n( ) ( )\nFurthermore, a sign function for the two vertices ( )and ( ), is defined as:\n{\n( )\nAccording to the manifold assumption, the conditional probability ( | ) can be approximated by the frequency of ( ) which is\nequal to ( ). In opinion annotations, the\nagreement of two annotators is often no larger than 0.8. This means that for the best cases\n( )=0.2. Hence follows a Bernoulli\ndistribution with p=0.2 for the best cases in manual annotations.\nLet ( ) be the vertices that are\nconnected to the vertex, the statistical magnitude of the vertex can be defined as:\n∑ ( )\nwhere j refers to the vertex that is connected to the vertex.\nFrom the theory of cut edge statics, we know that the expectation of is: ( ) ∑ ( )\nAnd the variance of is:\n( ) ( ) ∑\n( )\nBy the Center Limit Theorem (CLT), follows the normal distribution:\n( )\n( ) ( )\nTo detect the noise rate of a sample ( ) , we can use (8) as the null hypothesis to test the significant level. Let denotes probability of the correct classification for a transferred sample.\nshould follow a normal distribution,\n√ ∫\n( )\n( )\nNote that experiments (Li and Zhou, 2011; Cheng and Li, 2009; Brodley and Friedl, 1999) have shown that is related to the error rate of\nthe example ( ), but it does not reflect the ground-truth probability in statistics. Hence we assume the class noise rate of example ( ) is: ( )\nWe take the general significant level of 0.05 to reject the null hypothesis. It means that if of ( ) is larger than 0.95, the sample will be considered as a class noisy sample. Furthermore,\ncan be used to estimate the average class noise rate of a transferred samples in (2).\nIn our proposed approach, we establish the quality estimate period T to conduct class noise detection to estimate the class noise rate of transferred samples. Based on the average class noise we can get the least error boundary so as to tell if an added sample is of high quality. If the newly added samples are of high quality, they can be used to detect class noise in transferred training data. Otherwise, transfer learning should stop. The flow chart for negative transfer is in Fig.2.\nIn the above flow chart, SLS and TLS refer to the source and target language samples, respectively. TS refers to the transferred samples. Let T denote quality estimate period T in terms of iteration numbers. The transfer process select k samples in each iteration. When one period of transfer process finishes, the negative transfer detection will estimate the quality by comparing and either select the new transferred samples or remove class noise accumulated up to this iteration."
  }, {
    "heading": "4 Experiment",
    "text": ""
  }, {
    "heading": "4.1 Experiment Setting",
    "text": "The proposed approach is evaluated on the NLP&CC 2013 cross-lingual opinion analysis (in\nshort, NLP&CC) dataset 1 . In the training set, there are 12,000 labeled English Amazon.com products reviews, denoted by Train_ENG, and 120 labeled Chinese product reviews, denoted as Train_CHN, from three categories, DVD, BOOK, MUSIC. 94,651 unlabeled Chinese products reviews from corresponding categories are used as the development set, denoted as Dev_CHN. In the testing set, there are 12,000 Chinese product reviews (shown in Table.1). This dataset is designed to evaluate the CLOA algorithm which uses Train_CHN, Train_ENG and Dev_CHN to train a classifier for Test_CHN. The performance is evaluated by the correct classification accuracy for each category in Test_CHN 2 :\nwhere c is either DVD, BOOK or MUSIC.\nTeam DVD Book Music\nTrain_CHN 40 40 40 Train_ENG 4000 4000 4000 Dev_CHN 17814 47071 29677 Test_CHN 4000 4000 4000\nTable.1 The NLP&CC 2013 CLOA dataset\nIn the experiment, the basic transfer learning algorithm is co-training. The Chinese word segmentation tool is ICTCLAS (Zhang et al, 2003) and Google Translator 3 is the MT for the source language. The monolingual opinion classifier is SVM light4 , word unigram/bigram features are employed."
  }, {
    "heading": "4.2 CLOA Experiment Results",
    "text": "Firstly, we evaluate the baseline systems which use the same monolingual opinion classifier with three training dataset including Train_CHN, translated Train_ENG and their union, respectively.\nDVD Book Music Accuracy\nTrain_CHN 0.552 0.513 0.500 0.522 Train_ENG 0.729 0.733 0.722 0.728 Train_CHN\n+Train_ENG 0.737 0.722 0.742 0.734\nTable.2 Baseline performances\nIt can be seen that using the same method, the classifier trained by Train_CHN are on avergage 20% worse than the English counter parts.The combined use of Train_CHN and translated Train_ENG, however, obtained similar\n1http://tcci.ccf.org.cn/conference/2013/dldoc/evdata03.zip 2http://tcci.ccf.org.cn/conference/2013/dldoc/evres03.pdf 3https://translate.google.com 4http://svmlight.joachims.org/\nperformance to the English counter parts. This means the predominant training comes from the English training data.\nIn the second set of experiment, we compare our proposed approach to the official results in NLP&CC 2013 CLOA evaluation and the result is given in Table 3. Note that in Table 3, the top performer of NLP&CC 2013 CLOA evaluation is the HLT-HITSZ system(underscored in the table), which used the co-training method in transfer learning (Gui et al, 2013), proving that co-training is quite effective for cross-lingual analysis. With the additional negative transfer detection, our proposed approach achieves the best performance on this dataset outperformed the top system (by HLT-HITSZ) by a 2.97% which translate to 13.1% error reduction improvement to this state-of-the-art system as shown in the last row of Table 3.\nTeam DVD Book Music Accuracy\nBUAA 0.481 0.498 0.503 0.494 BISTU 0.647 0.598 0.661 0.635 HLT-HITSZ 0.777 0.785 0.751 0.771\nTHUIR 0.739 0.742 0.733 0.738\nSJTU 0.772 0.724 0.745 0.747 WHU 0.783 0.770 0.760 0.771 Our approach 0.816 0.801 0.786 0.801\nError\nReduction 0.152 0.072 0.110 0.131\nTable.3 Performance compares with NLP&CC\n2013 CLOA evaluation results\nTo further investigate the effectiveness of our method, the third set of experiments evaluate the negative transfer detection (NTD) compared to co-training (CO) without negative transfer detection as shown in Table.4 and Fig.3 Here, we use the union of Train_CHN and Train_ENG as labeled data and Dev_CHN as unlabeled data to be transferred in the learning algorithms.\nDVD Book Music Mean\nNTD\nBest case 0.816 0.801 0.786 0.801 Best period 0.809 0.798 0.782 0.796 Mean 0.805 0.795 0.781 0.794\nCO\nBest case 0.804 0.796 0.783 0.794 Best period 0.803 0.794 0.781 0.792 Mean 0.797 0.790 0.775 0.787\nTable.4 CLOA performances\nTaking all categories of data, our proposed method improves the overall average precision (the best cases) from 79.4% to 80.1% when compared to the state of the art system which translates to error reduction of 3.40% (pvalue≤0.01 in Wilcoxon signed rank test). Although the improvement does not seem large, our\nalgorithm shows a different behavior in that it can continue to make use of available training data to improve the system performance. In other words, we do not need to identify the tipping point where the performance degradation can occur when more training samples are used. Our approach has also shown the advantage of stable improvement.\nIn the most practical tasks, co-training based approach has the difficulty to determine when to stop the training process because of the negative transfer. And thus, there is no sure way to obtain the above best average precision. On the contrary, the performance of our proposed approach keeps stable improvement with more iterations, i.e. our approach has a much better chance to ensure the best performance. Another experiment is conducted to compare the performance of our proposed transfer learning based approach with supervised learning. Here, the achieved performance of 3-folder cross validation are given in\nThe accuracy of our approach is only 1.0% lower than the supervised learning using 2/3 of Test_CHN. In the BOOK subset, our approach achieves match result. Note that the performance gap in different subsets shows positive correlation to the size of Dev_CHN. The more samples are given in Dev_CHN, a higher precision is achieved even though these samples are unlabeled. According to the theorem of PAC, we know that the accuracy of a classifier training from a large enough training set with confined class noise rate will approximate the accuracy of classifier training from a non-class noise training set. This experiment shows that our proposed negative transfer detection controls the class noise rate in a very limited boundary. Theoreti-\ncally speaking, it can catch up with the performance of supervised learning if enough unlabeled samples are available. In fact, such an advantage is the essence of our proposed approach."
  }, {
    "heading": "5 Conclusion",
    "text": "In this paper, we propose a negative transfer detection approach for transfer learning method in order to handle cumulative class noise and reduce negative transfer in the process of transfer learning. The basic idea is to utilize high quality samples after transfer learning to detect class noise in transferred samples. We take cross lingual opinion analysis as the data set to evaluate our method. Experiments show that our proposed approach obtains a more stable performance improvement by reducing negative transfers. Our approach reduced 13.1% errors than the top system on the NLP&CC 2013 CLOA evaluation dataset. In BOOK category it even achieves better result than the supervised learning. Experimental results also show that our approach can obtain better performance when the transferred samples are added incrementally, which in previous works would decrease the system performance. In future work, we plan to extend this method into other language/domain resources to identify more transferred samples.\nAcknowledgement\nThis research is supported by NSFC 61203378, 61300112, 61370165, Natural Science Foundation of GuangDong S2013010014475, MOE Specialized Research Fund for the Doctoral Program of Higher Education 20122302120070, Open Projects Program of National Laboratory\nof Pattern Recognition，Shenzhen Foundational Research Funding JCYJ20120613152557576, JC201005260118A, Shenzhen International Cooperation Research Funding GJHZ20120613110641217 and Hong Kong Polytechnic University Project code Z0EP.\nReference\nAngluin, D., Laird, P. 1988. Learning from Noisy\nExamples. Machine Learning, 2(4): 343-370.\nArnold, A., Nallapati, R., Cohen, W. W. 2007. A\nComparative Study of Methods for Transductive Transfer Learning. In Proc. 7 th IEEE ICDM Workshops, pages 77-82.\nAue, A., Gamon, M. 2005. Customizing Sentiment\nClassifiers to New Domains: a Case Study, In Proc. of t RANLP.\nBlitzer, J., McDonald, R., Pereira, F. 2006. Domain\nAdaptation with Structural Correspondence Learning. In Proc. EMNLP, 120-128.\nBrodley, C. E., Friedl, M. A. 1999. Identifying and\nEliminating Mislabeled Training Instances. Journal of Artificial Intelligence Research, 11:131-167.\nChao, D., Guo, M. Z., Liu, Y., Li, H. F. 2008. Partic-\nipatory Learning based Semi-supervised Classification. In Proc. of 4 th ICNC, pages 207-216.\nCheng, Y., Li, Q. Y. 2009. Transfer Learning with\nData Edit. LNAI, pages 427–434.\nChen, M., Weinberger, K. Q., Blitzer, J. C. 2011.\nCo-Training for Domain Adaptation. In Proc. of 23 th NIPS.\nFukumoto, F., Suzuki, Y., Matsuyoshi, S. 2013. Text\nClassification from Positive and Unlabeled Data using Misclassified Data Correction. In Proc. of 51st ACL, pages 474-478.\nGui, L., Xu, R., Xu, J., et al. 2013. A Mixed Model\nfor Cross Lingual Opinion Analysis. In CCIS, 400, pages 93-104.\nHuang, J., Smola, A., Gretton, A., Borgwardt, K.M.,\nScholkopf, B. 2007. Correcting Sample Selection Bias by Unlabeled Data. In Proc. of 19 th NIPS, pages 601-608.\nJiang, Y., Zhou, Z. H. 2004. Editing Training Data for\nkNN Classifiers with Neural Network Ensemble. In LNCS, 3173, pages 356-361.\nLi, M., Zhou, Z. H. 2005. SETRED: Self-Training\nwith Editing. In Proc. of PAKDD, pages 611-621.\nLi, M., Zhou, Z. H. 2011. COTRADE: Confident Co-\nTraining With Data Editing. IEEE Transactions on Systems, Man, and Cybernetics—Part B: Cybernetics, 41(6):1612-1627.\nLu, B., Tang, C. H., Cardie, C., Tsou, B. K. 2011.\nJoint Bilingual Sentiment Classification with Unlabeled Parallel Corpora. In Proc. of 49 th ACL, pages 320-330.\nMeng, X. F., Wei, F. R., Liu, X. H., et al. 2012.\nCross-Lingual Mixture Model for Sentiment Classification. In Proc. of 50 th ACL, pages 572-581.\nMuhlenbach, F., Lallich, S., Zighed, D. A. 2004.\nIdentifying and Handling Mislabeled Instances. Journal of Intelligent Information System, 22(1): 89-109.\nPan, S. J., Yang, Q. 2010. A Survey on Transfer\nLearning, IEEE Transactions on Knowledge and Data Engineering, 22(10):1345-1360.\nSindhwani, V., Rosenberg, D. S. 2008. An RKHS for\nMulti-view Learning and Manifold CoRegularization. In Proc. of 25 th ICML, pages 976– 983.\nSluban, B., Gamberger, D., Lavra, N. 2010. Advanc-\nes in Class Noise Detection. In Proc.19 th ECAI, pages 1105-1106.\nSugiyama, M., Nakajima, S., Kashima, H., Buenau,\nP.V., Kawanabe, M. 2008. Direct Importance Estimation with Model Selection and its Application to Covariate Shift Adaptation. In Proc. 20 th NIPS.\nWan, X. 2009. Co-Training for Cross-Lingual Senti-\nment Classification, In Proc. of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, 235–243.\nZhang, H. P., Yu, H. K., Xiong, D. Y., and Liu., Q.\n2003. HHMM-based Chinese Lexical Analyzer ICTCLAS. In 2 nd SIGHAN workshop affiliated with 41 th ACL, pages 184-187.\nZhou, X., Wan X., Xiao, J. 2011. Cross-Language\nOpinion Target Extraction in Review Texts. In Proc. of IEEE 12th ICDM, pages 1200-1205.\nZhu, X. Q., Wu, X. D., Chen, Q. J. 2003. Eliminating\nClass Noise in Large Datasets. In Proc. of 12 th ICML, pages 920-927.\nZhu, X. Q. 2004. Cost-guided Class Noise Handling\nfor Effective Cost-sensitive Learning In Proc. of 4 th IEEE ICDM, pages 297-304.\nZighed, D. A., Lallich, S., Muhlenbach, F. 2002.\nSeparability Index in Supervised Learning. In Proc. of PKDD, pages 475-487."
  }],
  "year": 2014,
  "references": [{
    "title": "Learning from Noisy Examples",
    "authors": ["D. Angluin", "P. Laird"],
    "venue": "Machine Learning, 2(4): 343-370.",
    "year": 1988
  }, {
    "title": "A Comparative Study of Methods for Transductive Transfer Learning",
    "authors": ["A. Arnold", "R. Nallapati", "W.W. Cohen"],
    "venue": "Proc. 7",
    "year": 2007
  }, {
    "title": "Customizing Sentiment Classifiers to New Domains: a Case Study, In Proc",
    "authors": ["A. Aue", "M. Gamon"],
    "venue": "of t RANLP.",
    "year": 2005
  }, {
    "title": "Domain Adaptation with Structural Correspondence Learning",
    "authors": ["J. Blitzer", "R. McDonald", "F. Pereira"],
    "venue": "Proc. EMNLP, 120-128.",
    "year": 2006
  }, {
    "title": "Identifying and Eliminating Mislabeled Training Instances",
    "authors": ["C.E. Brodley", "M.A. Friedl"],
    "venue": "Journal of Artificial Intelligence Research, 11:131-167.",
    "year": 1999
  }, {
    "title": "Participatory Learning based Semi-supervised Classification",
    "authors": ["D. Chao", "M.Z. Guo", "Y. Liu", "H.F. Li"],
    "venue": "Proc. of 4",
    "year": 2008
  }, {
    "title": "Transfer Learning with Data Edit",
    "authors": ["Y. Cheng", "Q.Y. Li"],
    "venue": "LNAI, pages 427–434.",
    "year": 2009
  }, {
    "title": "Co-Training for Domain Adaptation",
    "authors": ["M. Chen", "K.Q. Weinberger", "J.C. Blitzer"],
    "venue": "Proc. of 23",
    "year": 2011
  }, {
    "title": "Text Classification from Positive and Unlabeled Data using Misclassified Data Correction",
    "authors": ["F. Fukumoto", "Y. Suzuki", "S. Matsuyoshi"],
    "venue": "Proc. of 51st ACL, pages 474-478.",
    "year": 2013
  }, {
    "title": "A Mixed Model for Cross Lingual Opinion Analysis",
    "authors": ["L. Gui", "R. Xu", "J Xu"],
    "venue": "In CCIS,",
    "year": 2013
  }, {
    "title": "Correcting Sample Selection Bias by Unlabeled Data",
    "authors": ["J. Huang", "A. Smola", "A. Gretton", "K.M. Borgwardt", "B. Scholkopf"],
    "venue": "Proc. of 19",
    "year": 2007
  }, {
    "title": "Editing Training Data for kNN Classifiers with Neural Network Ensemble",
    "authors": ["Y. Jiang", "Z.H. Zhou"],
    "venue": "LNCS, 3173, pages 356-361.",
    "year": 2004
  }, {
    "title": "SETRED: Self-Training with Editing",
    "authors": ["M. Li", "Z.H. Zhou"],
    "venue": "Proc. of PAKDD, pages 611-621.",
    "year": 2005
  }, {
    "title": "COTRADE: Confident CoTraining With Data Editing",
    "authors": ["M. Li", "Z.H. Zhou"],
    "venue": "IEEE Transactions on Systems, Man, and Cybernetics—Part B: Cybernetics, 41(6):1612-1627.",
    "year": 2011
  }, {
    "title": "Joint Bilingual Sentiment Classification with Unlabeled Parallel Corpora",
    "authors": ["B. Lu", "C.H. Tang", "C. Cardie", "B.K. Tsou"],
    "venue": "Proc. of 49",
    "year": 2011
  }, {
    "title": "Cross-Lingual Mixture Model for Sentiment Clas",
    "authors": ["X.F. Meng", "F.R. Wei", "Liu", "X. H"],
    "year": 2012
  }, {
    "title": "Identifying and Handling Mislabeled Instances",
    "authors": ["F. Muhlenbach", "S. Lallich", "D.A. Zighed"],
    "venue": "Journal of Intelligent Information System, 22(1): 89-109.",
    "year": 2004
  }, {
    "title": "A Survey on Transfer Learning",
    "authors": ["S.J. Pan", "Q. Yang"],
    "venue": "IEEE Transactions on Knowledge and Data Engineering,",
    "year": 2010
  }, {
    "title": "An RKHS for Multi-view Learning and Manifold CoRegularization",
    "authors": ["V. Sindhwani", "D.S. Rosenberg"],
    "venue": "Proc. of 25",
    "year": 2008
  }, {
    "title": "Advances in Class Noise Detection",
    "authors": ["B. Sluban", "D. Gamberger", "N. Lavra"],
    "venue": "th ICML,",
    "year": 2010
  }, {
    "title": "Co-Training for Cross-Lingual Sentiment Classification, In Proc",
    "authors": ["X. Wan"],
    "venue": "of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, 235–243.",
    "year": 2009
  }, {
    "title": "HHMM-based Chinese Lexical Analyzer ICTCLAS",
    "authors": ["H.P. Zhang", "H.K. Yu", "D.Y. Xiong", "Q. Liu."],
    "venue": "2",
    "year": 2003
  }, {
    "title": "Cross-Language Opinion Target Extraction in Review Texts",
    "authors": ["X. Zhou", "Wan X.", "J. Xiao"],
    "venue": "Proc. of IEEE 12th ICDM, pages 1200-1205.",
    "year": 2011
  }, {
    "title": "Eliminating Class Noise in Large Datasets",
    "authors": ["X.Q. Zhu", "X.D. Wu", "Q.J. Chen"],
    "venue": "Proc. of 12",
    "year": 2003
  }, {
    "title": "Cost-guided Class Noise Handling for Effective Cost-sensitive Learning In Proc",
    "authors": ["X.Q. Zhu"],
    "venue": "of 4",
    "year": 2004
  }, {
    "title": "Separability Index in Supervised Learning",
    "authors": ["D.A. Zighed", "S. Lallich", "F. Muhlenbach"],
    "venue": "IEEE ICDM,",
    "year": 2002
  }],
  "id": "SP:f2a68cbe8efd4bd4c3cdef672b3414138082a612",
  "authors": [{
    "name": "Lin Gui",
    "affiliations": []
  }, {
    "name": "Ruifeng Xu",
    "affiliations": []
  }, {
    "name": "Qin Lu",
    "affiliations": []
  }, {
    "name": "Jun Xu",
    "affiliations": []
  }, {
    "name": "Jian Xu",
    "affiliations": []
  }, {
    "name": "Bin Liu",
    "affiliations": []
  }, {
    "name": "Xiaolong Wang",
    "affiliations": []
  }],
  "abstractText": "Transfer learning has been used in opinion analysis to make use of available language resources for other resource scarce languages. However, the cumulative class noise in transfer learning adversely affects performance when more training data is used. In this paper, we propose a novel method in transductive transfer learning to identify noises through the detection of negative transfers. Evaluation on NLP&CC 2013 cross-lingual opinion analysis dataset shows that our approach outperforms the state-of-the-art systems. More significantly, our system shows a monotonic increase trend in performance improvement when more training data are used.",
  "title": "Cross-lingual Opinion Analysis via Negative Transfer Detection"
}