{
  "sections": [{
    "text": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 97–102 Vancouver, Canada, July 30 - August 4, 2017. c©2017 Association for Computational Linguistics\nhttps://doi.org/10.18653/v1/P17-2016"
  }, {
    "heading": "1 Introduction",
    "text": "Automated text simplification (ATS) tries to automatically transform (syntactically, lexically and/or semantically) complex sentences into their simpler variants without significantly altering the original meaning. It has attracted much attention recently as it could make texts more accessible to wider audiences (Aluı́sio and Gasperin, 2010; Saggion et al., 2015), and used as a pre-processing step, improve performances of various NLP tasks and systems (Vickrey and Koller, 2008; Evans, 2011; Štajner and Popović, 2016).\nHowever, the state-of-the-art ATS systems still do not reach satisfying performances and require some human post-editing (Štajner and Popović, 2016). While the best supervised approaches generally lead to grammatical output with preserved original meaning, they are overcautious, making almost no changes to the input sentences (Specia, 2010; Štajner et al., 2015), probably due to the limited size or bad quality of parallel TS corpora used for training. The largest existing sentence-aligned TS dataset for English is the English Wikipedia – Simple English Wikipedia\n(EW–SEW) dataset, which contains 160-280,000 sentence pairs, depending on whether we want to model only traditional sentence rewritings or also to model content reduction and stronger paraphrasing (Hwang et al., 2015). For Spanish, the largest existing parallel TS corpus contains only 1,000 sentence pairs thus impeding the use of fully supervised approaches. The best unsupervised lexical simplification (LS) systems for English which leverage word-embeddings (Glavaš and Štajner, 2015; Paetzold and Specia, 2016) seem to perform more lexical substitutions but at the cost of having less grammatical output and more often changed meaning. However, there have been no direct comparisons of supervised and unsupervised state-of-the-art approaches so far.\nThe Newsela corpora1 offers over 2,000 original news articles in English and around 250 in Spanish, manually simplified to 3–4 different complexity levels following strict guidelines (Xu et al., 2015). Although it was suggested that it has better quality than the EW–SEW corpus (Xu et al., 2015), Newsela has not yet been used for training end-to-end ATS systems, due to the lack of its sentence (and paragraph) alignments. Such alignments, between various text complexity levels, would offer large training datasets for modelling different levels of simplification, i.e. ‘mild’ simplifications (using the alignments from the neighbouring levels) and ‘heavy’ simplifications (using the alignments of level pairs: 0–3, 0–4, 1–4).\nContributions. We: (1) provide several methods for paragraph- and sentence alignment of parallel texts, and for assessing similarity level between pairs of text snippets, as freely avail-\n1Freely available: https://newsela.com/data/\n97\nable software;2 (2) compare the performances of lexically- and semantically-based alignment methods across various text complexity levels; (3) test the hypothesis that the original order of information is preserved during manual simplification (Bott and Saggion, 2011) by offering customized MST-LIS alignment strategy (Section 3.1); and (4) show that the new sentence-alignments lead to the state-of-the-art ATS systems even in a basic phrase-based statistical machine translation (PBSMT) approach to text simplifications."
  }, {
    "heading": "2 Related Work",
    "text": "The current state-of-the-art systems for automatic sentence-alignment of original and manually simplified texts are the GSWN method (Hwang et al., 2015) used for sentence-alignment of original and simple English Wikipedia, and the HMMbased method (Bott and Saggion, 2011) used for sentence-alignment of the Spanish Simplext corpus (Saggion et al., 2015).\nThe HMM-based method can be applied to any language as it does not require any languagespecific resources. It is based on two hypotheses: (H1) that the original order of information is preserved, and (H2) that every ‘simple’ sentence has at least one corresponding ‘original’ sentence (it can have more than one in the case of ‘n-1’ or ‘nm’ alignments).\nAs Simple Wikipedia does not represent direct simplification of the ‘original’ Wikipedia articles (‘simple’ articles were written independently of the ‘original’ ones), GSWN method does not assume H1 or H2. The main limitations of this method are that it only allows for ‘1-1’ sentence alignments – which is very restricting for TS as it does not allow for sentence splitting (‘1-n’), and summarisation and compression (‘n-1’ and ‘n-m’) alignments – and it is language-dependent as it requires English Wiktionary.\nUnlike the GSWN method, all the methods we apply are language-independent, resource-light and allow for ‘1-n’, ‘n-1’, and ‘n-m’ alignments. Similar to the HMM-method, our methods assume the hypothesis H2. We provide them in both variants, using the hypothesis H1 and without it (Section 3.1).\n2https://github.com/neosyon/ SimpTextAlign"
  }, {
    "heading": "3 Approach",
    "text": "Having a set of ‘simple’ text snippets S and a set of ‘complex’ text snippets C, we offer two strategies (Section 3.1) to obtain the alignments (si, cj), where si ∈ S, cj ∈ C. Each alignment strategy, in turn, can use one of the three methods (Section 3.2) to calculate similarity scores between text snippets (either paragraphs or sentences)."
  }, {
    "heading": "3.1 Alignment strategies",
    "text": "Most Similar Text (MST): Given one of the similarity methods (Section 3.2), MST compares similarity scores of all possible pairs (si, cj), and aligns each si ∈ S with the closest one in C. MST with Longest Increasing Sequence (MSTLIS): MST-LIS uses the hypothesis H1. It first uses the MST strategy, and then postprocess the output by extracting – from all obtained alignments – only those alignments li ∈ L, which contain the longest increasing sequence of offsets jk in C. In order to allow for ‘1–n’ alignments (i.e. sentence splitting), we allow for repeated offsets of C (‘complex’ text snippets) in L. The ‘simple’ text snippets not contained in L are included in the set U of unaligned snippets. Finally, we align each um ∈ U by restricting the search space in C to those offsets of ‘complex’ text snippets that correspond to the previous and the next aligned ‘simple’ snippets. For instance, if L = {(s1, c4), (s3, c7)} and U = {s2}, then the search space for the alignments of s2 is reduced to {c4...c7}. We denote this strategy with an ‘*’ in the results (Table 2), e.g. C3G*."
  }, {
    "heading": "3.2 Similarity Methods",
    "text": "C3G: We employ the Character N -Gram (CNG) (Mcnamee and Mayfield, 2004) similarity model (for n = 3) with log TF-IDF weighting (Salton and McGill, 1986) and compare vectors using the cosine similarity. WAVG: We use the continuous skip-gram model (Mikolov et al., 2013b) of the TensorFlow toolkit3 to process the whole English Wikipedia and generate continuous representations of its words.4 For each text snippet, we average its word vectors to obtain a single representation of its content as this setting has shown good results\n3https://www.tensorflow.org/ 4We use 300-dimensional vectors, context windows of size 10, and 20 negative words for each sample, in all our continuous word-based models.\nin other NLP tasks (e.g. for selecting out-of-thelist words (Mikolov et al., 2013a)). Finally, the similarity between text snippets is estimated using the cosine similarity. CWASA: We employ the Continuous Word Alignment-based Similarity Analysis (CWASA) model (Franco-Salvador et al., 2016), which finds the optimal word alignment by computing cosine similarity between continuous representations of all words (instead of averaging word vectors as in the case of WAVG). It was originally proposed for plagiarism detection with excellent results, especially for longer text snippets."
  }, {
    "heading": "4 Manual Evaluation",
    "text": "To compare the performances of different alignment methods, we randomly selected 10 original texts (Level 0) and their corresponding simpler versions at Levels 1, 3 and 4. Instead of creating a ‘gold standard’ and then automatically evaluating the performances, we asked two annotators to rate each pair of automatically aligned paragraphs and sentences – by each of the possible six alignment methods and the HMM-based method (Bott and Saggion, 2011) – for three pairs of text complexity levels (0–1, 0–4, and 3–4) on a 0–2 scale, where: 0 – no semantic overlap in the content; 1 – partial semantic overlap (partial matches); 2 – same semantic content (good matches). This resulted in a total of 1526 paragraph- and 1086 sentence-alignments for the 0–1 pairs, and 1218 paragraph- and 1266 sentence-alignments for the 0–4 and 3–4 pairs. In the context of TS, both good- and partial matches\nare important. While full semantic overlap models full paraphrases (‘1-1’ alignments), partial overlap models sentence splitting (“1-n” alignments), deleting irrelevant sentence parts, adding explanations, or summarizing (‘n-m’ alignments). Several examples of full and partial matches from the EW–SEW dataset (Hwang et al., 2015) are given in Table 1.\nWe expect that the automatic-alignment task is the easiest between the 0–1 text complexity levels, and much more difficult between the 0-4 levels (Level 4 is obtained after four stages of simplification and thus contains stronger paraphrases and less lexical overlap with Level 0 than Level 1 has). We also explore whether the task is equally difficult whenever we align two neighbouring levels, or the difficulty of the task depends on the level complexity (0–1 vs. 3–4). The obtained interannotator agreement, weighted Cohen’s κ (on 400 double-annotated instances) was between 0.71 and 0.74 depending on the task and levels.\nThe results of the manual analysis (Table 2) showed that: (1) all applied methods significantly (p < 0.001) outperformed the HMM method on both paragraph- and sentence-alignment tasks;5 (2) the methods which do not assume hypothesis H1 (C3G, CWASA, and WAVG) led to (not significantly) higher percentage of correct alignments than their counterparts which do assume\n5Although some of our methods share the same percentage of good+partial matches with the HMM method on the paragraph-alignment 0–1 task, there is still significant difference in the obtained scores (in some cases, our methods led to good matches whereas the HMM only led to partial matches).\nH1 (C3G*, CWASA*, WAVG*); (3) the difference in the performances of the lexical approach (C3G) and semantic approaches (CWASA and WAVG) was significant only in the 0–4 sentencealignment task, where CWASA performed significantly worse (p < 0.001) than the other two methods, and in the 0–4 paragraph-alignment task, where WAVG performed significantly worse than C3G; (4) the 2-step C3G alignment-method (C3G-2s), which first aligns paragraphs using the best paragraph-alignment method (C3G) and then within each paragraph align sentences with the best sentence-alignment method (C3G), led to more good+partial alignments than the ‘direct’ sentence-alignment C3G method."
  }, {
    "heading": "5 Extrinsic Evaluation",
    "text": "Finally, we test our new English Newsela (C3G2s) sentence-alignments (both for the neighbouring levels – neighb. and for all levels – all) and Newsela sentence-alignments for neighboring levels obtained with HMM-method6 (Bott and Saggion, 2011) in the ATS task using standard PBSMT models7 in the Moses toolkit (Koehn et al., 2007). We vary the training dataset and the corpus used to build language models (LMs), while keeping always the same 2,000 sentence pairs for tuning (Xu et al., 2016) and the first 70 sentence\n6Given that the performance of the HMM-method was poor for non-neighboring levels (Table 2).\n7GIZA++ implementation of the IBM word alignment model 4 (Och and Ney, 2003), refinement and phraseextraction heuristics (Koehn et al., 2003), the minimum error rate training (Och, 2003) for tuning, and 5-gram LMs with Kneser-Ney smoothing trained with SRILM (Stolcke, 2002).\npairs of their test set8 for our human evaluation. Using that particular test set allow us to compare our (PBSMT) systems with the output of the stateof-the-art syntax-based MT (SBMT) system for TS (Xu et al., 2016) which is not freely available. We compare: (1) the performance of the standard PBSMT model which uses only the already available EW–SEW dataset (Hwang et al., 2015) with the performances of the same PBSMT models but this time using the combination of the EW–SEW dataset and our newly-created Newsela datasets; (2) the latter PBSMT models (which use both EW–SEW and new Newsela datasets) against the state-of-the-art supervised ATS system (Xu et al., 2016), and one of the recently proposed unsupervised lexical simplification systems, the LightLS system (Glavaš and Štajner, 2015).9\nWe perform three types of human evaluation on the outputs of all systems. First, we count the total number of changes made by each system (Total), counting the change of a whole phrase (e.g. “become defunct” → “was dissolved”) as one change. We mark as Correct those changes that preserve the original meaning and grammaticality of the sentence (assessed by two native English speakers) and, at the same time, make the sentence easier to understand (assessed by two non-native fluent English speakers).10 Second, three native English speakers rate the grammaticality (G) and meaning preservation (M) of each sentence with at least one change on a 1–5 Likert scale (1 – very bad; 5 – very good). Third, the three nonnative fluent English speakers were shown original (reference) sentences and target (output) sentences (one pair at the time) and asked whether the target sentence is: +2 – much simpler; +1 – somewhat simpler; 0 – equally difficult; -1 – somewhat more difficult; -2 – much more difficult, than the reference sentence. While the correctness of changes takes into account the influence of each individual change on grammaticality, meaning and simplicity of a sentence, the Scores (G and M) and Rank (S) take into account the mutual influence of all changes within a sentence.\nAdding our sentence-aligned Newsela corpus\n8Both freely available from: https://github.com/ cocoxu/simplification/\n9We use the output of the original SBMT (Xu et al., 2016) and LightLS (Glavaš and Štajner, 2015) systems, obtained from the authors.\n10Those cases in which the two annotators did not agree are additionally evaluated by a third annotator to obtain majority.\n(either neighb. C3G-2l or all C3G-2l) to the currently best sentence-aligned Wiki corpus (Hwang et al., 2015) in a standard PBSMT setup significantly11 improves grammaticality (G) and meaning preservation (M), and increases the percentage of correct changes (Table 3). It also significantly outperforms the state-of-the-art ATS systems by simplicity rankings (S), meaning preservation (M), and number of correct changes (Correct), while achieving almost equally good grammaticality (G).\nThe level of simplification applied in the training dataset (Newsela neighb. C3G-2s vs. Newsela all C3G-2s) significantly influences G and M scores.\nThe use of the HMM-method for aligning Newsela (instead of ours) lead to significantly worse simplifications by all five criteria.\n11Wilcoxon’s signed rank test, p < 0.001.\nAn example of the outputs of different ATS systems is presented in Table 4."
  }, {
    "heading": "6 Conclusions",
    "text": "We provided several methods for paragraphand sentence-alignment from parallel TS corpora, made the software publicly available, and showed that the use of the new sentence-aligned (freely available) Newsela dataset leads to state-of-the-art ATS systems even in a basic PBSMT setup. We also showed that lexically-based C3G method is superior to semantically-based methods (CWASA and WAVG) in aligning paraphraphs and sentences with ‘heavy’ simplifications (0–4 alignments), and that 2-step sentence alignment (aligning first paragraphs and then sentences within the paragraphs) lead to more correct alignments than the ‘direct’ sentence alignment."
  }, {
    "heading": "Acknowledgments",
    "text": "This work has been partially supported by the SFB 884 on the Political Economy of Reforms at the University of Mannheim (project C4), funded by the German Research Foundation (DFG), and also by the SomEMBED TIN2015-71147-C2-1-P MINECO research project."
  }],
  "year": 2017,
  "references": [{
    "title": "Fostering Digital Inclusion and Accessibility: The PorSimples project for Simplification of Portuguese Texts",
    "authors": ["Sandra Maria Aluı́sio", "Caroline Gasperin"],
    "venue": "In Proceedings of YIWCALA Workshop at NAACL-HLT",
    "year": 2010
  }, {
    "title": "An Unsupervised Alignment Algorithm for Text Simplification Corpus Construction",
    "authors": ["Stefan Bott", "Horacio Saggion."],
    "venue": "Proceedings of the Workshop on Monolingual Text-To-Text Generation. ACL, pages 20–26.",
    "year": 2011
  }, {
    "title": "Comparing methods for the syntactic simplification of sentences in information extraction",
    "authors": ["Richard J. Evans."],
    "venue": "Literary and Linguistic Computing 26(4):371–388.",
    "year": 2011
  }, {
    "title": "Cross-language plagiarism detection over continuous-space- and knowledge graph-based representations of language",
    "authors": ["Marc Franco-Salvador", "Parth Gupta", "Paolo Rosso", "Rafael E. Banchs."],
    "venue": "Knowledge-Based Systems 111:87 – 99.",
    "year": 2016
  }, {
    "title": "Simplifying Lexical Simplification: Do We Need Simplified Corpora? In Proceedings of the ACL&IJCNLP 2015 (Volume 2: Short Papers)",
    "authors": ["Goran Glavaš", "Sanja Štajner."],
    "venue": "pages 63–68.",
    "year": 2015
  }, {
    "title": "Aligning Sentences from Standard Wikipedia to Simple Wikipedia",
    "authors": ["William Hwang", "Hannaneh Hajishirzi", "Mari Ostendorf", "Wei Wu."],
    "venue": "Proceedings of NAACL&HLT . pages 211–217.",
    "year": 2015
  }, {
    "title": "Statistical phrase-based translation",
    "authors": ["Philipp Koehn", "Franz Josef Och", "Daniel Marcu."],
    "venue": "Proceedings of the NAACL&HLT, Vol. 1. pages 48–54.",
    "year": 2003
  }, {
    "title": "Character n-gram tokenization for European language text retrieval",
    "authors": ["Paul Mcnamee", "James Mayfield."],
    "venue": "Information Retrieval 7(1):73–97.",
    "year": 2004
  }, {
    "title": "Efficient estimation of word representations in vector space",
    "authors": ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean."],
    "venue": "Proceedings of Workshop",
    "year": 2013
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "Advances in Neural Information Processing Systems 26. pages 3111–3119.",
    "year": 2013
  }, {
    "title": "Minimum Error Rate Training in Statistical Machine Translation",
    "authors": ["Franz Och."],
    "venue": "Proceedings of the ACL. pages 160–167.",
    "year": 2003
  }, {
    "title": "A systematic comparison of various statistical alignment models",
    "authors": ["Franz Josef Och", "Hermann Ney."],
    "venue": "Computational Linguistics 29(1):19–51.",
    "year": 2003
  }, {
    "title": "Unsupervised lexical simplification for non-native speakers",
    "authors": ["Gustavo Henrique Paetzold", "Lucia Specia."],
    "venue": "Proceedings of the 30th AAAI.",
    "year": 2016
  }, {
    "title": "Making It Simplext: Implementation and Evaluation of a Text Simplification System for Spanish",
    "authors": ["Horacio Saggion", "Sanja Štajner", "Stefan Bott", "Simon Mille", "Luz Rello", "Biljana Drndarevic."],
    "venue": "ACM Transactions on Accessible Computing 6(4):14:1–",
    "year": 2015
  }, {
    "title": "Introduction to Modern Information Retrieval",
    "authors": ["Gerard Salton", "Michael J. McGill."],
    "venue": "McGrawHill, Inc.",
    "year": 1986
  }, {
    "title": "Translating from complex to simplified sentences",
    "authors": ["Lucia Specia."],
    "venue": "Proceedings of the 9th PROPOR. Springer Berlin Heidelberg, volume 6001 of Lecture Notes in Computer Science, pages 30–39.",
    "year": 2010
  }, {
    "title": "SRILM - an Extensible Language Modeling Toolkit",
    "authors": ["Andreas Stolcke."],
    "venue": "Proceedings of the International Conference on Spoken Language Processing (ICSLP). pages 901–904.",
    "year": 2002
  }, {
    "title": "Sentence simplification for semantic role labeling",
    "authors": ["David Vickrey", "Daphne Koller."],
    "venue": "Proceedings of ACL&HLT . volume 344–352.",
    "year": 2008
  }, {
    "title": "A Deeper Exploration of the Standard PBSMT Approach to Text Simplification and its Evaluation",
    "authors": ["Sanja Štajner", "Hannah Bechara", "Horacio Saggion."],
    "venue": "Proceedings of ACL&IJCNLP (Volume 2: Short Papers). pages 823–828.",
    "year": 2015
  }, {
    "title": "Can Text Simplification Help Machine Translation",
    "authors": ["Sanja Štajner", "Maja Popović"],
    "venue": "Baltic Journal of Modern Computing",
    "year": 2016
  }, {
    "title": "Problems in Current Text Simplification Research: New Data Can Help",
    "authors": ["Wei Xu", "Chris Callison-Burch", "Courtney Napoles."],
    "venue": "Transactions of the Association for Computational Linguistics (TACL) 3:283–297.",
    "year": 2015
  }, {
    "title": "Optimizing statistical machine translation for text simplification",
    "authors": ["Wei Xu", "Courtney Napoles", "Ellie Pavlick", "Quanze Chen", "Chris Callison-Burch."],
    "venue": "Transactions of the Association for Computational Linguistics 4:401–415.",
    "year": 2016
  }],
  "id": "SP:791e94ca29a964c3972bb777508e398e3c1c0c7b",
  "authors": [{
    "name": "Sanja Štajner",
    "affiliations": []
  }, {
    "name": "Marc Franco-Salvador",
    "affiliations": []
  }, {
    "name": "Simone Paolo Ponzetto",
    "affiliations": []
  }, {
    "name": "Paolo Rosso",
    "affiliations": []
  }, {
    "name": "Heiner Stuckenschmidt",
    "affiliations": []
  }],
  "abstractText": "We provide several methods for sentencealignment of texts with different complexity levels. Using the best of them, we sentence-align the Newsela corpora, thus providing large training materials for automatic text simplification (ATS) systems. We show that using this dataset, even the standard phrase-based statistical machine translation models for ATS can outperform the state-of-the-art ATS systems.",
  "title": "Sentence Alignment Methods for Improving Text Simplification Systems"
}