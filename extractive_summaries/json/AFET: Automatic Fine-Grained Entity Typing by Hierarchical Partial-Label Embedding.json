{
  "sections": [{
    "text": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1369–1378, Austin, Texas, November 1-5, 2016. c©2016 Association for Computational Linguistics\nDistant supervision has been widely used in current systems of fine-grained entity typing to automatically assign categories (entity types) to entity mentions. However, the types so obtained from knowledge bases are often incorrect for the entity mention’s local context. This paper proposes a novel embedding method to separately model “clean” and “noisy” mentions, and incorporates the given type hierarchy to induce loss functions. We formulate a joint optimization problem to learn embeddings for mentions and typepaths, and develop an iterative algorithm to solve the problem. Experiments on three public datasets demonstrate the effectiveness and robustness of the proposed method, with an average 15% improvement in accuracy over the next best compared method1."
  }, {
    "heading": "1 Introduction",
    "text": "Assigning types (e.g., person, organization) to mentions of entities in context is an important task in natural language processing (NLP). The extracted entity type information can serve as primitives for relation extraction (Mintz et al., 2009) and event extraction (Ji and Grishman, 2008), and assists a wide range of downstream applications including knowledge base (KB) completion (Dong et al., 2014), question answering (Lin et al., 2012) and entity recommendation (Yu et al., 2014). While\n∗Equal contribution. 1Codes and datasets used in this paper can be down-\nloaded at https://github.com/shanzhenren/AFET.\ntraditional named entity recognition systems (Ratinov and Roth, 2009; Nadeau and Sekine, 2007) focus on a small set of coarse types (typically fewer than 10), recent studies (Ling and Weld, 2012; Yosef et al., 2012) work on a much larger set of fine-grained types (usually over 100) which form a tree-structured hierarchy (see the blue region of Fig. 1). Fine-grained typing allows one mention to have multiple types, which together constitute a type-path (not necessarily ending in a leaf node) in the given type hierarchy, depending on the local context (e.g., sentence). Consider the example in Fig. 1, “Arnold Schwarzenegger” could be labeled as {person, businessman} in S3 (investment). But he could also be labeled as {person, politician} in S1 or {person, artist, actor} in S2. Such fine-grained type representation provides more informative features for other NLP tasks. For exam-\n1369\nple, since relation and event extraction pipelines rely on entity recognizer to identify possible arguments in a sentence, fine-grained argument types help distinguish hundreds or thousands of different relations and events (Ling and Weld, 2012).\nTraditional named entity recognition systems adopt manually annotated corpora as training data (Nadeau and Sekine, 2007). But the process of manually labeling a training set with large numbers of fine-grained types is too expensive and errorprone (hard for annotators to distinguish over 100 types consistently). Current fine-grained typing systems annotate training corpora automatically using knowledge bases (i.e., distant supervision) (Ling and Weld, 2012; Ren et al., 2016a). A typical workflow of distant supervision is as follows (see Fig. 1): (1) identify entity mentions in the documents; (2) link mentions to entities in KB; and (3) assign, to the candidate type set of each mention, all KB types of its KB-linked entity. However, existing distant supervision methods encounter the following limitations when doing automatic fine-grained typing. • Noisy Training Labels. Current practice of distant supervision may introduce label noise to training data since it fails to take a mention’s local contexts into account when assigning type labels (e.g., see Fig. 1). Many previous studies ignore the label noises which appear in a majority of training mentions (see Table. 1, row (1)), and assume all types obtained by distant supervision are “correct” (Yogatama et al., 2015; Ling and Weld, 2012). The noisy labels may mislead the trained models and cause negative effect. A few systems try to denoise the training corpora using simple pruning heuristics such as deleting mentions with conflicting types (Gillick et al., 2014). However, such strategies significantly reduce the size of training set (Table 1, rows (2a-c)) and lead to performance degradation (later shown in our experiments). The larger the target type set, the more severe the loss. • Type Correlation. Most existing methods (Yogatama et al., 2015; Ling and Weld, 2012) treat every type label in a training mention’s candidate type set equally and independently when learning the classifiers but ignore the fact that types in the given hierarchy are semantically correlated (e.g., actor is more relevant to singer than to politician). As a consequence, the learned classifiers may bias\ntoward popular types but perform poorly on infrequent types since training data on infrequent types is scarce. Intuitively, one should pose smaller penalty on types which are semantically more relevant to the true types. For example, in Fig. 1 singer should receive a smaller penalty than politician does, by knowing that actor is a true type for “Arnold Schwarzenegger” in S2. This provides classifiers with additional information to distinguish between two types, especially those infrequent ones.\nIn this paper, we approach the problem of automatic fine-grained entity typing as follows: (1) Use different objectives to model training mentions with correct type labels and mentions with noisy labels, respectively. (2) Design a novel partial-label loss to model true types within the noisy candidate type set which requires only the “best” candidate type to be relevant to the training mention, and progressively estimate the best type by leveraging various text features extracted for the mention. (3) Derive type correlation based on two signals: (i) the given type hierarchy, and (ii) the shared entities between two types in KB, and incorporate the correlation so induced by enforcing adaptive margins between different types for mentions in the training set. To integrate these ideas, we develop a novel embedding-based framework called AFET. First, it uses distant supervision to obtain candidate types for each mention, and extract a variety of text features from the mentions themselves and their local contexts. Mentions are partitioned into a “clean” set and a “noisy” set based on the given type hierarchy. Second, we embed mentions and types jointly into a low-dimensional space, where, in that space, objects (i.e., features and types) that are semantically close to each other also have similar representations. In the proposed objective, an adaptive margin-based rank loss is pro-\nposed to model the set of clean mentions to capture type correlation, and a partial-label rank loss is formulated to model the “best” candidate type for each noisy mention. Finally, with the learned embeddings (i.e., mapping matrices), one can predict the typepath for each mention in the test set in a top-down manner, using its text features. The major contributions of this paper are as follows:\n1. We propose an automatic fine-grained entity typing framework, which reduces label noise introduced by distant supervision and incorporates type correlation in a principle way.\n2. A novel optimization problem is formulated to jointly embed entity mentions and types to the same space. It models noisy type set with a partial-label rank loss and type correlation with adaptive-margin rank loss.\n3. We develop an iterative algorithm for solving the joint optimization problem efficiently.\n4. Experiments with three public datasets demonstrate that AFET achieves significant improvement over the state of the art."
  }, {
    "heading": "2 Automatic Fine-Grained Entity Typing",
    "text": "Our task is to automatically uncover the type information for entity mentions (i.e., token spans representing entities) in natural language sentences. The task takes a document collection D (automatically labeled using a KB Ψ in conjunction with a target type hierarchy Y) as input and predicts a type-path in Y for each mention from the test set Dt. Type Hierarchy and Knowledge Base. Two key factors in distant supervision are the target type hierarchy and the KB. A type hierarchy, Y , is a tree where nodes represent types of interests from Ψ. Previous studies manually create several clean type hierarchies using types from Freebase (Ling and Weld, 2012) or WordNet (Yosef et al., 2012). In this study, we adopt the existing hierarchies constructed using Freebase types2. To obtain types for entities EΨ in Ψ, we use the human-curated entity-type facts in Freebase, denoted as FΨ = { (e, y) } ⊂ EΨ × Y .\n2We use the Freebase dump as of 2015-06-30.\nAutomatically Labeled Training Corpora. There exist publicly available labeled corpora such as Wikilinks (Singh et al., 2012) and ClueWeb (Gabrilovich et al., 2013). In these corpora, entity mentions are identified and mapped to KB entities using anchor links. In specific domains (e.g., product reviews) where such public corpora are unavailable, one can utilize distant supervision to automatically label the corpus (Ling and Weld, 2012). Specifically, an entity linker will detect mentions mi and map them to one or more entity ei in EΨ. Types of ei in KB are then associated with mi to form its type set Yi, i.e., Yi = { y | (ei, y) ∈ FΨ, y ∈ Y } . Formally, a training corpus D consists of a set of extracted entity mentionsM = {mi}Ni=1, the context (e.g., sentence, paragraph) of each mention {ci}Ni=1, and the candidate type sets {Yi}Ni=1 for each mention. We represent D using a set of triples D = { (mi, ci,Yi) }N i=1 .\nProblem Description. For each test mention, we aim to predict the correct type-path in Y based on the mention’s context. More specifically, the test set T is defined as a set of mention-context pairs (m, c), where mentions in T (denoted asMt) are extracted from their sentences using existing extractors such as named entity recognizer (Finkel et al., 2005). We denote the gold type-path for a test mention m as Y∗. This work focuses on learning a typing model from the noisy training corpus D, and estimating Y∗ from Y for each test mention m (in set Mt), based on mention m, its context c, and the learned model.\nFramework Overview. At a high level, the AFET framework (see also Fig. 2) learns low-dimensional representations for entity types and text features, and\ninfers type-paths for test mentions using the learned embeddings. It consists of the following steps:\n1. Extract text features for entity mentions in training set M and test set Mt using their surface names as well as the contexts. (Sec. 3.1).\n2. Partition training mentions M into a clean set (denoted asMc) and a noisy set (denoted asMn) based on their candidate type sets (Sec. 3.2).\n3. Perform joint embedding of entity mentions M and type hierarchy Y into the same lowdimensional space where, in that space, close objects also share similar types (Secs. 3.3-3.6).\n4. For each test mention m, estimate its type-path Y∗ (on the hierarchy Y) in a top-down manner using the learned embeddings (Sec. 3.6)."
  }, {
    "heading": "3 The AFET Framework",
    "text": "This section introduces the proposed framework and formulates an optimization problem for learning embeddings of text features and entity types jointly."
  }, {
    "heading": "3.1 Text Feature Generation",
    "text": "We start with a representation of entity mentions. To capture the shallow syntax and distributional semantics of a mention mi ∈ M, we extract various features from both mi itself and its context ci. Table 2 lists the set of text features used in this work, which is similar to those used in (Yogatama et al., 2015; Ling and Weld, 2012). We denote the set of M unique features extracted from D as F = {fj}Mj=1."
  }, {
    "heading": "3.2 Training Set Partition",
    "text": "A training mention mi (in setM) is considered as a “clean” mention if its candidate type set obtained by distant supervision (i.e., Yi) is not ambiguous, i.e., candidate types in Yi can form a single path in tree Y . Otherwise, a mention is considered as “noisy” mention if its candidate types form multiple typepaths in Y . Following the above hypothesis, we judge each mention mi (in set M) and place it in either the “clean” set Mc, or the “noisy” set Mn. Finally, we haveM =Mc ∪Mn."
  }, {
    "heading": "3.3 The Joint Mention-Type Model",
    "text": "We propose to learn mappings into low-dimensional vector space, where, both entity mentions and type\nlabels (in the training set) are represented, and in that space, two objects are embedded close to each other if and only if they share similar types. In doing so, we later can derive the representation of a test mention based on its text features and the learned mappings. Mapping functions for entity mentions and entity type labels are different as they have different representations in the raw feature space, but are jointly learned by optimizing a global objective of interests to handle the aforementioned challenges.\nEach entity mention mi ∈ M can be represented by aM -dimensional feature vector mi ∈ RM , where mi,j is the number of occurrences of feature fj (in set F) formi. Each type label yk ∈ Y is represented by a K-dimensional binary indicator vector yk ∈ {0, 1}K , where yk,k = 1, and 0 otherwise.\nSpecifically, we aim to learn a mapping function from the mention’s feature space to a lowdimensional vector space, i.e., ΦM(mi) : RM 7→ Rd and a mapping function from type label space to the same low-dimensional space, i.e., ΦY(yk) : RK 7→ Rd. In this work, we adopt linear maps, as similar to the mapping functions used in (Weston et al., 2011).\nΦM(mi) = Umi; ΦY(yk) = Vyk, (1)\nwhere U ∈ Rd×M and V ∈ Rd×K are the projection matrices for mentions and type labels, respectively."
  }, {
    "heading": "3.4 Modeling Type Correlation",
    "text": "In type hierarchy (tree) Y , types closer to each other (i.e., shorter path) tend to be more related (e.g., actor is more related to artist than to person in the right column of Fig. 2). In KB Ψ, types assigned to similar sets of entities should be more related to each other than those assigned to quite different entities (Jiang et al., 2015) (e.g., actor is\nmore related to director than to author in the left column of Fig. 3). Thus, type correlation between yk and yk′ (denoted as wkk′) can be measured either using the one over the length of shortest path in Y , or using the normalized number of shared entities in KB, which is defined as follows.\nwkk′ = (∣∣Ek ∩ Ek′ ∣∣/ ∣∣Ek ∣∣+ ∣∣Ek ∩ Ek′ ∣∣/ ∣∣Ek′ ∣∣ ) /2. (2)\nAlthough a shortest path is efficient to compute, its accuracy is limited—It is not always true that a type (e.g., athlete) is more related to its parent type (i.e., person) than to its sibling types (e.g., coach), or that all sibling types are equally related to each other (e.g., actor is more related to director than to author). We later compare these two methods in our experiments.\nWith the type correlation computed, we propose to apply adaptive penalties on different negative type labels (for a training mention), instead of treating all of the labels equally as in most existing work (Weston et al., 2011). The hypothesis is intuitive: given the positive type labels for a mention, we force the negative type labels which are related to the positive type labels to receive smaller penalty. For example, in the right column of Fig. 3, negative label businessman receives a smaller penalty (i.e., margin) than athele does, since businessman is more related to politician.\nHypothesis 1 (Adaptive Margin) For a mention, if a negative type is correlated to a positive type, the margin between them should be smaller.\nWe propose an adaptive-margin rank loss to model the set of “clean” mentions (i.e., Mc), based on the above hypothesis. The intuition is simple: for each mention, rank all the positive types ahead of negative types, where the ranking score is measured by similarity between mention and type. We denote\nfk(mi) as the similarity between (mi, yk) and is defined as the inner product of ΦM(mi) and ΦY(yk). `c(mi,Yi,Yi) = ∑\nyk∈Yi\n∑\nyk̄∈Yi\nL ⌊ rankyk ( f(mi) )⌋ Θi,k,k̄;\nΘi,k,k̄ = max { 0, γk,k̄ − fk(mi) + fk̄(mi) } ;\nrankyk ( f(mi) ) = ∑\nyk̄∈Yi\n1 ( γk,k̄ + fk̄(mi) > fk(mi) ) .\nHere, γk,k̄ is the adaptive margin between positive type k and negative type k̄, which is defined as γk,k̄ = 1 + 1/(wk,k̄ +α) with a smooth parameter α. L(x) =∑x\ni=1 1 i transforms rank to a weight, which is then multiplied to the max-margin loss Θi,k,k̄ to optimize precision at x (Weston et al., 2011)."
  }, {
    "heading": "3.5 Modeling Noisy Type Labels",
    "text": "True type labels for noisy entity mentionsMn (i.e., mentions with ambiguous candidate types in the given type hierarchy) in each sentence are not available in knowledge bases. To effectively model the set of noisy mentions, we propose not to treat all\ncandidate types (i.e., {Yi} as true labels. Instead, we model the “true” label among the candidate set as latent value, and try to infer that using text features.\nHypothesis 2 (Partial-Label Loss) For a noisy mention, the maximum score associated with its candidate types should be greater than the scores associated with any other non-candidate types\nWe extend the partial-label loss in (Nguyen and Caruana, 2008) (used to learn linear classifiers) to enforce Hypothesis 2, and integrate with the adaptive margin to define the loss for mi (in setMn). `n(mi,Yi,Yi) = ∑\nk̄∈Yi\nL ⌊ rankyk∗ ( f(mi) )⌋ Ωi,k̄;\nΩi,k = max { 0, γk∗,k̄ − fk∗(mi) + fk̄(mi) } ;\nrankyk∗ ( f(mi) ) = ∑\nyk̄∈Yi\n1 ( γk∗,k̄ + fk̄(mi) > fk∗(mi) )\nwhere we define . yk∗ = argmaxyk∈Yi fk(mi) and yk̄∗ = argmaxyk∈Yi fk(mi).\nMinimizing `n encourages a large margin between the maximum scores maxyk∈Yi fyk(mi) and maxyk̄∈Yi fyk(mi). This forces mi to be embedded closer to the most “relevant” type in the noisy candidate type set, i.e., y∗ = argmaxyk∈Yi fyk(mi), than to any other non-candidate types (i.e., Hypothesis 2). This constrasts sharply with multi-label learning (Yosef et al., 2012), where a large margin is enforced between all candidate types and noncandidate types without considering noisy types."
  }, {
    "heading": "3.6 Hierarchical Partial-Label Embedding",
    "text": "Our goal is to embed the heterogeneous graphG into a d-dimensional vector space, following the three proposed hypotheses in the section. Intuitively, one can collectively minimize the objectives of the two kinds of loss functions `c and `n, across all the training mentions. To achieve the goal, we formulate a joint optimization problem as follows.\nmin U, V\nO = ∑\nmi∈Mc `c(mi,Yi,Yi) +\n∑\nmi∈Mn `n(mi,Yi,Yi).\nWe use an alternative minimization algorithm based on block-wise coordinate descent (Tseng, 2001) to jointly optimize the objective O. One can also apply stochastic gradient descent to do online update.\nType Inference. With the learned mention embeddings {ui} and type embeddings {vk}, we perform\ntop-down search in the given type hierarchy Y to estimate the correct type-path Y∗i . Starting from the tree’s root, we recursively find the best type among the children types by measuring the dot product of the corresponding mention and type embeddings, i.e., sim(ui,vk). The search process stops when we reach a leaf type, or the similarity score is below a pre-defined threshold η > 0."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Data Preparation",
    "text": "Datasets. Our experiments use three public datasets. (1) Wiki (Ling and Weld, 2012): consists of 1.5M sentences sampled from Wikipedia articles; (2) OntoNotes (Weischedel et al., 2011): consists of 13,109 news documents where 77 test documents are manually annotated (Gillick et al., 2014); (3) BBN (Weischedel and Brunstein, 2005): consists of 2,311 Wall Street Journal articles which are manually annotated using 93 types. Statistics of the datasets are shown in Table 3.\nTraining Data. We followed the process in (Ling and Weld, 2012) to generate training data for the Wiki dataset. For the BBN and OntoNotes datasets, we used DBpedia Spotlight3 for entity linking. We discarded types which cannot be mapped to Freebase types in the BBN dataset (47 of 93).\nTable 2 lists the set of features used in our experiments, which are similar to those used in (Yogatama et al., 2015; Ling and Weld, 2012) except for topics and ReVerb patterns. We discarded the features which occur only once in the corpus."
  }, {
    "heading": "4.2 Evaluation Settings",
    "text": "For the Wiki and OntoNotes datasets, we used the provided test set. Since BBN corpus is fully annotated, we followed a 80/20 ratio to partition it into\n3http://spotlight.dbpedia.org/\ntraining/test sets. We report Accuracy (Strict-F1), Micro-averaged F1 (Mi-F1) and Macro-averaged F1 (Ma-F1) scores commonly used in the fine-grained type problem (Ling and Weld, 2012; Yogatama et al., 2015). Since we use the gold mention set for testing, the Accuracy (Acc) we reported is the same as the Strict F1.\nBaselines. We compared the proposed method (AFET) and its variant with state-of-the-art typing methods, embedding methods and partial-label learning methods 4: (1) FIGER (Ling and Weld, 2012); (2) HYENA (Yosef et al., 2012); (3) FIGER/HYENA-Min (Gillick et al., 2014): removes types appearing only once in the document; (4) ClusType (Ren et al., 2015): predicts types based on co-occurring relation phrases; (5) HNM (Dong et al., 2015): proposes a hybrid neural model without hand-crafted features; (6) DeepWalk (Perozzi et al., 2014): applies Deep Walk to a feature-mention-type graph by treating all nodes as the same type; (7) LINE (Tang et al., 2015b): uses a second-order LINE model on feature-type bipartite graph; (8) PTE (Tang et al., 2015a): applies the PTE joint training algorithm on featuremention and type-mention bipartite graphs. (9) WSABIE (Yogatama et al., 2015): adopts WARP loss to learn embeddings of features and types; (10) PLSVM (Nguyen and Caruana, 2008): uses a marginbased loss to handle label noise. (11) CLPL (Cour et al., 2011): uses a linear model to encourage large average scores for candidate types.\nWe compare AFET and its variant: (1) AFET: complete model with KB-induced type correlation; (2) AFET-CoH: with hierarchy-induced correlation (i.e., shortest path distance); (3) AFET-NoCo: without type correlation (i.e., all margin are “1”) in the objective O; and (4) AFET-NoPa: without label partial loss in the objective O."
  }, {
    "heading": "4.3 Performance Comparison and Analyses",
    "text": "Table 4 shows the results of AFET and its variants. Comparison with the other typing methods. AFET outperforms both FIGER and HYENA systems, demonstrating the predictive power of the\n4We used the published code for FIGER, ClusType, HNM, LINE, PTE, and DeepWalk, and implemented other baselines which have no public code. Our implementations yield comparable performance as those reported in the original papers.\nlearned embeddings, and the effectiveness of modeling type correlation information and noisy candidate types. We also observe that pruning methods do not always improve the performance, since they aggressively filter out rare types in the corpus, which may lead to low Recall. ClusType is not as good as FIGER and HYENA because it is intended for coarse types and only utilizes relation phrases.\nComparison with the other embedding methods. AFET performs better than all other embedding methods. HNM does not use any linguistic features. None of the other embedding methods consider the label noise issue and treat the candidate type sets as clean. Although AFET adopts the WARP loss in WSABIE, it uses an adaptive margin in the objective to capture the type correlation information.\nComparison with partial-label learning methods. Compared with PL-SVM and CLPL, AFET obtains superior performance. PL-SVM assumes that only one candidate type is correct and does not consider type correlation. CLPL simply averages the model output for all candidate types, and thus may generate results biased to frequent false types. Superior performance of AFET mainly comes from modeling type correlation derived from KB.\nComparison with its variants. AFET always outperforms its variant on all three datasets. It gains performance from capturing type correlation, as well as handling type noise in the embedding process."
  }, {
    "heading": "4.4 Case Analyses",
    "text": "Example output on news articles. Table 5 shows the types predicted by AFET, FIGER, PTE and WSABIE on two news sentences from OntoNotes dataset: AFET predicts fine-grained types with better accuracy (e.g., person title) and avoids overly-specific predictions (e.g., news company). Figure 5 shows the types estimated by AFET, PTE and WSABIE on a training sentence from OntoNotes dataset. We found AFET could discover the best type from noisy candidate types.\nTesting the effect of training set size and dimension. Experimenting with the same settings for model learning, Fig. 6(a) shows the performance trend on the Wiki dataset when varying the sampling ratio (subset of mentions randomly sampled from the training set D). Fig. 6(b) analyzes the performance sensitivity of AFET with respect to d—the embedding dimension on the BBN dataset. Accuracy of AFET improves as d becomes large but the gain decreases when d is large enough. Testing sensitivity of the tuning parameter. Fig. 7(b) analyzes the sensitivity of AFET with respect to α on the BBN dataset. Performance increases as α becomes large. When α is large than 0.5, the performance becomes stable. Testing at different type levels. Fig. 7(a) reports the Ma-F1 of AFET, FIGER, PTE and WSABIE at different levels of the target type hierarchy (e.g., per-\nson and location on level-1, politician and artist on level-2, author and actor on level-3). The results show that it is more difficult to distinguish among more fine-grained types. AFET always outperforms the other two method, and achieves a 22.36% improvement in Ma-F1, compared to FIGER on level-3 types. The gain mainly comes from explicitly modeling the noisy candidate types.\nTesting for frequent/infrequent types. We also\nevaluate the performance on frequent and rare types (Table 6). Note that we use a different evaluation metric, which is introduced in (Yosef et al., 2012) to calculate the F1 score for a type. We find AFET can always perform better than other baselines and it works for both frequent and rare types."
  }, {
    "heading": "5 Related Work",
    "text": "There has been considerable work on named entity recognition (NER) (Manning et al., 2014), which focuses on three types (e.g., person, location) and cast the problem as multi-class classification following the type mutual exclusion assumption (i.e., one type per mention) (Nadeau and Sekine, 2007).\nRecent work has focused on a much larger set of fine-grained types (Yosef et al., 2012; Ling and Weld, 2012). As the type mutual exclusion assumption no longer holds, they cast the problem as multilabel multi-class (hierarchical) classification problems (Gillick et al., 2014; Yosef et al., 2012; Ling and Weld, 2012). Embedding techniques are also recently applied to jointly learn feature and type representations (Yogatama et al., 2015; Dong et al., 2015). Del Corro et al. (2015) proposed an unsupervised method to generate context-aware candidates types, and subsequently select the most appropriate type. Gillick et al. (2014) discuss the label noise issue in fine-grained typing and propose three pruning heuristics. However, these heuristics aggressively delete training examples and may suffer from low recall (see Table. 4).\nIn the context of distant supervision, label noise issue has been studied for other information extraction tasks such as relation extraction (Takamatsu et al., 2012). In relation extraction, label noise is introduced by the false positive textual matches of entity pairs. In entity typing, however, label noise comes from the assignment of types to entity mentions without considering their contexts. The forms\nof distant supervision are different in these two problems. Recently, (Ren et al., 2016b) has tackled the problem of label noise in fine-grained entity typing, but focused on how to generate a clean training set instead of doing entity typing.\nPartial label learning (PLL) (Zhang, 2014; Nguyen and Caruana, 2008; Cour et al., 2011) deals with the problem where each training example is associated with a set of candidate labels, where only one is correct. Unlike existing PLL methods, our method considers type hierarchy and correlation."
  }, {
    "heading": "6 Conclusion and Future Work",
    "text": "In this paper, we study automatic fine-grained entity typing and propose a hierarchical partial-label embedding method, AFET, that models “clean” and “noisy” mentions separately and incorporates a given type hierarchy to induce loss functions. AFET builds on a joint optimization framework, learns embeddings for mentions and type-paths, and iteratively refines the model. Experiments on three public datasets show that AFET is effective, robust, and outperforms other comparing methods.\nAs future work, it would be interesting to study topical features as the context cues of the entity mentions, to leverage multi-sensing embedding to represent linguistic features with multiple senses, and to exploits other effective modeling methods to inject type hierarchy information. The proposed objective function is general and can be considered to incorporate various language features, to conduct integrated modeling of multiple sources, and to be extended to distantly-supervised relation extraction."
  }, {
    "heading": "7 Acknowledgments",
    "text": "Research was sponsored in part by the U.S. Army Research Lab. under Cooperative Agreement No. W911NF-09-2-0053 (NSCTA), DARPA DEFT No. FA8750-13-2-0041, National Science Foundation IIS-1017362, IIS-1320617, IIS-1354329, and IIS-1523198, HDTRA1-10-1-0120, and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans-NIH Big Data to Knowledge (BD2K) initiative (www.bd2k.nih.gov). The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies."
  }],
  "year": 2016,
  "references": [{
    "title": "Learning from partial labels",
    "authors": ["Timothee Cour", "Ben Sapp", "Ben Taskar."],
    "venue": "JMLR, 12:1501–1536.",
    "year": 2011
  }, {
    "title": "Finet: Context-aware fine-grained named entity typing",
    "authors": ["Luciano Del Corro", "Abdalghani Abujabal", "Rainer Gemulla", "Gerhard Weikum."],
    "venue": "EMNLP.",
    "year": 2015
  }, {
    "title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion",
    "authors": ["Xin Luna Dong", "Thomas Strohmann", "Shaohua Sun", "Wei Zhang."],
    "venue": "KDD.",
    "year": 2014
  }, {
    "title": "A hybrid neural model for type classification of entity mentions",
    "authors": ["Li Dong", "Furu Wei", "Hong Sun", "Ming Zhou", "Ke Xu."],
    "venue": "IJCAI.",
    "year": 2015
  }, {
    "title": "A new entity salience task with millions of training examples",
    "authors": ["Jesse Dunietz", "Dan Gillick."],
    "venue": "EACL.",
    "year": 2014
  }, {
    "title": "Incorporating non-local information into information extraction systems by gibbs sampling",
    "authors": ["Jenny Rose Finkel", "Trond Grenager", "Christopher Manning."],
    "venue": "ACL.",
    "year": 2005
  }, {
    "title": "Facc1: Freebase annotation of clueweb corpora",
    "authors": ["Evgeniy Gabrilovich", "Michael Ringgaard", "Amarnag Subramanya"],
    "year": 2013
  }, {
    "title": "Contextdependent fine-grained entity type tagging",
    "authors": ["Dan Gillick", "Nevena Lazic", "Kuzman Ganchev", "Jesse Kirchner", "David Huynh."],
    "venue": "arXiv preprint arXiv:1412.1820.",
    "year": 2014
  }, {
    "title": "Refining event extraction through cross-document inference",
    "authors": ["Heng Ji", "Ralph Grishman."],
    "venue": "ACL.",
    "year": 2008
  }, {
    "title": "Entity-driven type hierarchy construction for freebase",
    "authors": ["Jyun-Yu Jiang", "Chin-Yew Lin", "Pu-Jen Cheng."],
    "venue": "WWW.",
    "year": 2015
  }, {
    "title": "No noun phrase left behind: detecting and typing unlinkable entities",
    "authors": ["Thomas Lin", "Oren Etzioni"],
    "year": 2012
  }, {
    "title": "Fine-grained entity recognition",
    "authors": ["Xiao Ling", "Daniel S Weld."],
    "venue": "AAAI.",
    "year": 2012
  }, {
    "title": "The stanford corenlp natural language processing toolkit",
    "authors": ["Christopher D Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J Bethard", "David McClosky."],
    "venue": "ACL.",
    "year": 2014
  }, {
    "title": "Distant supervision for relation extraction without labeled data",
    "authors": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."],
    "venue": "ACL.",
    "year": 2009
  }, {
    "title": "A survey of named entity recognition and classification",
    "authors": ["David Nadeau", "Satoshi Sekine."],
    "venue": "Lingvisticae Investigationes, 30:3–26.",
    "year": 2007
  }, {
    "title": "Classification with partial labels",
    "authors": ["Nam Nguyen", "Rich Caruana."],
    "venue": "KDD.",
    "year": 2008
  }, {
    "title": "Deepwalk: Online learning of social representations",
    "authors": ["Bryan Perozzi", "Rami Al-Rfou", "Steven Skiena."],
    "venue": "KDD.",
    "year": 2014
  }, {
    "title": "Design challenges and misconceptions in named entity recognition",
    "authors": ["Lev Ratinov", "Dan Roth."],
    "venue": "ACL.",
    "year": 2009
  }, {
    "title": "Clustype: Effective entity recognition and typing by relation phrase-based clustering",
    "authors": ["Xiang Ren", "Ahmed El-Kishky", "Chi Wang", "Fangbo Tao", "Clare R Voss", "Heng Ji", "Jiawei Han."],
    "venue": "KDD.",
    "year": 2015
  }, {
    "title": "Automatic entity recognition and typing in massive text corpora",
    "authors": ["Xiang Ren", "Ahmed El-Kishky", "Chi Wang", "Jiawei Han."],
    "venue": "WWW.",
    "year": 2016
  }, {
    "title": "Label noise reduction in entity typing by heterogeneous partial-label embedding",
    "authors": ["Xiang Ren", "Wenqi He", "Meng Qu", "Clare R Voss", "Heng Ji", "Jiawei Han."],
    "venue": "KDD.",
    "year": 2016
  }, {
    "title": "Wikilinks: A largescale cross-document coreference corpus labeled via links to wikipedia",
    "authors": ["Sameer Singh", "Amarnag Subramanya", "Fernando Pereira", "Andrew McCallum."],
    "venue": "UM-CS-2012-015.",
    "year": 2012
  }, {
    "title": "Reducing wrong labels in distant supervision for relation extraction",
    "authors": ["Shingo Takamatsu", "Issei Sato", "Hiroshi Nakagawa."],
    "venue": "ACL.",
    "year": 2012
  }, {
    "title": "Pte: Predictive text embedding through large-scale heterogeneous text networks",
    "authors": ["Jian Tang", "Meng Qu", "Qiaozhu Mei."],
    "venue": "KDD.",
    "year": 2015
  }, {
    "title": "Line: Large-scale information network embedding",
    "authors": ["Jian Tang", "Meng Qu", "Mingzhe Wang", "Ming Zhang", "Jun Yan", "Qiaozhu Mei."],
    "venue": "WWW.",
    "year": 2015
  }, {
    "title": "Convergence of a block coordinate descent method for nondifferentiable minimization",
    "authors": ["Paul Tseng."],
    "venue": "JOTA, 109(3):475–494.",
    "year": 2001
  }, {
    "title": "Bbn pronoun coreference and entity type corpus",
    "authors": ["Ralph Weischedel", "Ada Brunstein."],
    "venue": "Linguistic Data Consortium, 112.",
    "year": 2005
  }, {
    "title": "Ontonotes: A large training corpus for enhanced processing",
    "authors": ["Ralph Weischedel", "Eduard Hovy", "Mitchell Marcus", "Martha Palmer", "Robert Belvin", "Sameer Pradhan", "Lance Ramshaw", "Nianwen Xue"],
    "year": 2011
  }, {
    "title": "Wsabie: Scaling up to large vocabulary image annotation",
    "authors": ["Jason Weston", "Samy Bengio", "Nicolas Usunier."],
    "venue": "IJCAI.",
    "year": 2011
  }, {
    "title": "Embedding methods for fine grained entity type classification",
    "authors": ["Dani Yogatama", "Dan Gillick", "Nevena Lazic."],
    "venue": "ACL.",
    "year": 2015
  }, {
    "title": "Hyena: Hierarchical type classification for entity names",
    "authors": ["Mohamed Amir Yosef", "Sandro Bauer", "Johannes Hoffart", "Marc Spaniol", "Gerhard Weikum."],
    "venue": "COLING.",
    "year": 2012
  }, {
    "title": "Personalized entity recommendation: A heterogeneous information network approach",
    "authors": ["Xiao Yu", "Xiang Ren", "Yizhou Sun", "Quanquan Gu", "Bradley Sturt", "Urvashi Khandelwal", "Brandon Norick", "Jiawei Han."],
    "venue": "WSDM.",
    "year": 2014
  }, {
    "title": "Disambiguation-free partial label learning",
    "authors": ["Min-Ling Zhang."],
    "venue": "SDM. 1378",
    "year": 2014
  }],
  "id": "SP:a931cc972da051f5c6c12634ae226a3cf3582cd3",
  "authors": [{
    "name": "Xiang Ren",
    "affiliations": []
  }, {
    "name": "Wenqi He",
    "affiliations": []
  }, {
    "name": "Meng Qu",
    "affiliations": []
  }, {
    "name": "Lifu Huang",
    "affiliations": []
  }, {
    "name": "Heng Ji",
    "affiliations": []
  }, {
    "name": "Jiawei Han",
    "affiliations": []
  }],
  "abstractText": "Distant supervision has been widely used in current systems of fine-grained entity typing to automatically assign categories (entity types) to entity mentions. However, the types so obtained from knowledge bases are often incorrect for the entity mention’s local context. This paper proposes a novel embedding method to separately model “clean” and “noisy” mentions, and incorporates the given type hierarchy to induce loss functions. We formulate a joint optimization problem to learn embeddings for mentions and typepaths, and develop an iterative algorithm to solve the problem. Experiments on three public datasets demonstrate the effectiveness and robustness of the proposed method, with an average 15% improvement in accuracy over the next best compared method1.",
  "title": "AFET: Automatic Fine-Grained Entity Typing by Hierarchical Partial-Label Embedding"
}