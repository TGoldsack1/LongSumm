{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2288–2297 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n2288\nlaborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so. Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated. In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways: First, we trained a words-asclassifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog. We then used these semantic models to learn the general referring ability of each word, which is independent of referent features. These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data."
  }, {
    "heading": "1 Introduction",
    "text": "A crucial part of dialog situated in a physical environment is exophoric references, i.e. language used by the participants to make entities in the shared environment salient to each other for the purposes of communication (Poesio and Vieira, 1998). Several studies in exophoric reference resolution have investigated how referential semantics can be learned automatically via the relationship of a referent’s features to the language referring to it (cf. Kennington et al., 2015; Shore and Skantze, 2017) or the state of the interaction a dialog is situated in (cf. Prasov and Chai, 2008; Iida\n† Deceased 2 July 2018.\net al., 2010), inferring a relationship between e.g. the word red and the individual features it refers to, e.g. a particular range of hue values.\nMost works in exophoric reference resolution have assumed the identification of certain subsets of language known as referring expressions (REs) that have been either manually or automatically annotated (cf. Schutte et al., 2011; Meena et al., 2012; Zarrieß et al., 2016; Shore and Skantze, 2017). However, discerning REs from non-referring language in dialog is not trivial. For example, Figure 1 illustrates an interaction between two participants in a reference communication task like that of Krauss and Weinheimer (1964), whereby speaker A describes a particular\nreferent which must be resolved by speaker B. 1.\nWhile REs are idealized as contiguous, single noun phrases (NPs) such as the pinkish one, reference in unrestricted, natural dialog is in fact a collaborative process to which both partners in a dyad contribute (Clark and Wilkes-Gibbs, 1986), and not all referring language (RL) is nominal, e.g. big in Figure 1. Both participants contribute RL in a cumulative fashion, but often no complete nominal RE is produced, e.g. the big pinkish asteroid to the left. Due to this, it is difficult to infer from syntax alone the referring ability (RA) of language, i.e. the overall ability of a subset of language to unambiguously refer to entities in discourse (Ariel, 1988; Reboul, 1997). In context (e.g. given the set of possible abstract shapes to choose from), it is easy to infer which words have the greatest RA, but without context this is more difficult. This makes recognizing “non-ideal” cases of RL difficult, as the boundary between RL and non-RL is often fuzzy.\nMoreover, participants in dialog tend to develop so-called conceptual pacts, which means that they converge on commonly-used RL for unique referents in dialog (Brennan and Clark, 1996). As an example, they may repeatedly refer to a given entity as e.g. the asteroid even though asteroid may only rarely be used to refer to similar entities in the general population. Thus, RL varies less within a given dialog than across dialogs, and variation of RL has an inverse relationship with the length of the time two participants interact due to alignment of dialog participants’ use of language (Clark and Wilkes-Gibbs, 1986; Garrod and Anderson, 1987; Brennan, 1996).\nIn this paper, we present two contributions to the automatic learning of referential semantics for reference resolution in situated dialog that address these problems: Firstly, we show the benefits of adapting models of RL semantics to a specific dialog as it progresses to accommodate the dyad’s idiosyncratic use of RL. Secondly, we present a method for deriving a gradient (non-binary) measure of RA in situated dialog. Thus, instead of first identifying REs and then resolving which entity they refer to, we treat all language in the dialog as being more or less referential, and use this gradual measure together with the referential semantics to derive which entity is being talked about. Our assumption is that while the exact\n1Examples are from the dataset of Shore et al. (2018)\nreferential semantics of words vary greatly across dyads, the general ability of a given word to successfully refer to entities varies little across dyads. Thus, it should be possible to statistically measure the ability of a set of language to refer to entities in general, irrespective of the language’s semantic content (e.g. the exact hue understood as pink by a dyad). This knowledge, combined with dialogic adaptation, facilitates accurate automatic reference resolution in situated dialog without annotation of REs, even with little background data."
  }, {
    "heading": "2 Background",
    "text": "Both behavioral studies on reference resolution and RL and computational models thereof have illustrated the context-sensitive nature of reference resolution and RL and the gradient nature of RA."
  }, {
    "heading": "2.1 Collaboration in Reference Resolution",
    "text": "Traditionally, reference resolution in dialog was analyzed using a literary model of reference, whereby individual REs are seen as unique identifiers of a referent as in written discourse, i.e. each RE is assumed to be “atomic” in its reference to a particular entity (Clark and WilkesGibbs, 1986, 3). However, shortcomings in this approach have long since been identified (cf. Olson, 1970): REs often do not unambiguously identify their referent when initiated but rather comprise a larger process of collaborative reference resolution, whereby multiple dialog participants iteratively extend, repair and even replace REs initiated by themselves or others (Clark and WilkesGibbs, 1986; Heeman and Hirst, 1995).\nIn Figure 1, speaker A initiates the RE the one to the left and immediately expands it in an episodic manner (Clark and Wilkes-Gibbs, 1986, 4, 17). Given a literary model of reference, they should have supplied exactly enough information to identify the referent and no more (the big pinkish asteroid to the left), adhering to Grice’s (1975) maxim of quantity. However, RL can undergo not only expansion but also replacement: For color, speaker B proposes both purple and pinkish, but only pinkish is then accepted by A.\nIn contrast to a literary model of reference, a collaborative model represents reference resolution as a process of iteratively presenting RL to the other participant(s) in a dialog, which is then either accepted as being sufficient to identify a referent or rejected as insufficient (Clark and Wilkes-\nGibbs, 1986, 9). This more accurately models reference observed in spoken dialog."
  }, {
    "heading": "2.2 Referring Language Syntax",
    "text": "Literary reference models fail to account not only for the collaborative nature of reference resolution but also for the syntactic structure of RL itself: Ideally, a reference is expressed linguistically as an NP, but this ideal does not hold in unrestricted dialog (Clark and Wilkes-Gibbs, 1986).\nSince an RE cannot be defined as an atomic referring unit, a model of RL should ideally be able to measure the RA of any given set of language rather than simply classifying language as (part of) an RE in a binary decision, such as by using handcrafted rules (cf. Shore and Skantze, 2017) or expert annotation (cf. Spanger et al., 2009; Kennington et al., 2015)."
  }, {
    "heading": "2.3 Modeling Referring Language",
    "text": "There have already been some efforts in automatic annotation of REs: For example, Schutte et al. (2011) algorithmically extracted RL as utterance(s) preceding a discrete event in a shared environment within a certain timeframe. However, one drawback to this method is that “the references must be contained in instructions that cause events involving the referents” and “it must be possible to automatically detect these events” (Schutte et al., 2011, 189). Thus, REs not referring to a detectable event cannot be detected in this manner. Moreover, not all language extracted is that of REs: For example, in the instruction go through that door, only half of the tokens constitute RL (that door). This means that this method must either be supplemented with additional methods to extract RL or tolerate a high noise-to-signal ratio.\nOther approaches use language structure to infer RL, namely in parsing said language using a combination of statistical or rule-based methods. However, both entail that a solution be specialized for language specific to a given domain, such as for route-following instructions (Meena et al., 2012) or for a specific instructor-manipulator pair task (Shore and Skantze, 2017): Meena et al. (2012) used the highly-structured nature of routefollowing instructions to great effect, while Shore and Skantze (2017) used a phrase-structure parser pre-trained on out-of-domain data and supplemented it with hand-crafted rules to extract NPs according to the literary ideal of RL.\nFinally, many works simply ignore the distinction between RL and non-RL and focus solely on learning reference resolution as a function of language and extra-linguistic knowledge such as entity features (cf. Kennington et al., 2015; Shore and Skantze, 2017), discourse and action history (cf. Iida et al., 2010), perception (cf. Matuszek et al., 2012) or gesture (cf. Matuszek et al., 2014). Although these methods improve the resolution of what RL refers to, they do not resolve what language is RL. Moreover, none of these works address the strong dyadic and dialogic entrainment effects on RL which include the formation of CPs, reinforcing the use of RL specific to a given dialog even if it diverges from population RL use."
  }, {
    "heading": "3 Data Description",
    "text": "The data used is that of Shore et al. (2018), a set of |D| = 42 task-oriented dialogs (mean duration µ = 15:25 minutes, standard deviation SD = 1:13, total 647:35) in which one participant is an instructor referring to specific pieces on a shared game board which the other participant, the manipulator, must then attempt to resolve by selecting without the aid of extra-linguistic cues (see Figures 1–2): They sit at different locations and communicate solely through an audio channel. Upon successful selection, the piece moves to a random free place on the board and the participants alternate roles. This dataset is somewhat larger than that for similar tasks (cf. Iida et al., 2010; Matuszek et al., 2012; Malinowski and Fritz, 2014; Kennington et al., 2015). However, unlike in many other works, participants\nwere allowed to refer to pieces in any way they wish and both were allowed to speak freely.\nEach dialog d ∈ D has |R| = 20 randomlygenerated game pieces and is divided into individual game rounds d , 〈d′1 . . . d ′ n〉, in each of which d′ , (R, r̂, T ) a single entity is pre-selected by the game as the entity r̂ ∈ R which must be successfully resolved for that round. Each dialog presents the same 20 referents aside from their changing position, so participants must also refer to pieces which have already been referenced before: After 40 rounds, all pieces are guaranteed to have been referred to and so every reference thereafter is a coreference (see Figure 2).\nEach entity r ∈ R has features representing shape, size, color and position during the given round. A sequence of tokens T was transcribed from the speech of both participants using Penn Treebank tokenization rules (Marcus et al., 1993). See the Supplementary Material for further information on the dataset."
  }, {
    "heading": "4 Baseline",
    "text": "The reference resolution method used as a baseline was a words-as-classifiers (WaC) regression model (cf. Kennington et al., 2015). In this framework, an individual logistic regression model pt(r) , σ(w T t r + bt) is trained for each token type t, predicting the probability of a given entity r being the token’s TRUE referent r̂, given the feature vector r representing shape, size, color and position (see the Supplementary Material for details). For example, if trained successfully, the model for the token ”red” should be sensitive to the entity’s hue, but not to its size. Common nondescriptive words such as ”the” should not be sensitive to any of the entity’s properties, yielding an output of 0.5 for all entities. The score of a given entity r being the referent r = r̂ of a set of RL tokens T is defined as the normalized linear combination of the tokens’ corresponding classifiers pt(r):\np′(r = r̂, T ) , 1\nn\nn∑\nt∈T\npt(r) (1)\nFor training, language in each round (R, r̂, T ) is defined as a bag of words T referring to the referent r̂. For each token t ∈ T , a training example is defined for the referent r̂ (with a target score of 1) as well as for each non-referent entity r ∈ R \\ r̂ (with a target score of 0). To address model bias,\nthe training example for r̂ is weighted by its complement set size, |R \\ r̂| = 19.\nInitial experiments showed that lemmatization did not affect the performance on our dataset. Thus, each inflected lexical form is considered a unique word (i.e., vocabulary item). Unlike Kennington et al. (2015), no smoothing was used, instead ignoring words of fewer than α , 3 occurrences. The motivation for this is that a general out-of-vocabulary model is not expected to increase the performance, since it basically learns to ignore entity properties, similar to the models for common words such as ”the”. This was also confirmed in our initial experiments.\nNote that all language from both the instructor and the manipulator in each round is used. This is unlike Kennington et al. (2015), who only used language from (manually annotated) REs. As argued above, REs cannot easily be identified in the type of dialog data we are addressing. This of course makes the task much more challenging, and the baseline performance can be expected to be lower than that reported in Kennington et al. (2015).\nWe did 42-fold cross-validation, in each fold using 40 dialogs for training as background data, one for testing and one for use as random data to compare the effects of dialog-specific data to (see Section 5 below). Each round in the test dialog is evaluated by the reciprocal rank (RR) of the referent r̂ in the set of entities R ordered by their combined score for all word classifiers in the round ∑\nt∈T pt(r), and its mean (MRR) is then calculated.\nThe cross-validation results for the baseline WaC model are shown in Table 1. As expected, this is indeed worse than e.g. Kennington et al. (2015)’s reported mean rank of 2.16 when only using speech features. The WaC model is nevertheless a simple and effective representation of referential semantics in domains where features for each individual referent can be easily represented (cf. Kennington and Schlangen, 2015). Still, it has two shortcomings: Firstly, it infers a static model of referential semantics which is good across di-\nalogs but is suboptimal for language within dialogs due to effects of language alignment (Garrod and Anderson, 1987; Brennan, 1996; Brennan and Clark, 1996). Secondly, it encodes RA only indirectly: Given a large enough dataset, logistic regression for non-RL such as okay now I’m ready should have an even distribution between TRUE and FALSE classes, i.e. these classifiers should decide nothing. Conversely, strong RL such as red should entail strong relationships between certain features and decisions. However, due to the effects of idiosyncrasy and alignment on dialogic language, understanding low-frequency words is crucial despite that they cannot be conditioned for as well as can be done for high-frequency ones."
  }, {
    "heading": "5 Dialogic Model Adaptation",
    "text": "We evaluated the benefits of adapting reference resolution parameters to the language of individual dialogs by initially conditioning WaC models on the training set as background data and then adapting the model during evaluation by retraining using data from previous states in the dialog being evaluated: The RR for the ith round (R, r̂, T )i is calculated using a model trained on both background data and interaction data defined as the rounds observed thus far in the given dialog (R, r̂, T )i′<i. The parameters for the logistic regression models representing individual words are optimized using quasi-Newton hybrid conjugate gradient descent from Weka v3.8.0 (Dai and Yuan, 2001; Frank et al., 2016). A ridge λ = 100 was used to avoid over-fitting of models for low-frequency words, tuned using crossvalidation over the dataset (le Cessie and van Houwelingen, 1992). The same cross-validation method determined an optimal interaction data weight of 3 relative to background data, i.e. an observation in a given dialog is three times as relevant as one from the background data2.\nFigure 3 compares the improvement of RR from adapting model parameters using dialog interaction data (Adt) to the Baseline as well as effects of adding data from a randomly-chosen round from another unseen dialog (RndAdt): The condition RndAdt is used to rule out the possibility that model fit improves simply due to more training data in general. We fit a linear mixed model with conditions Adt, RndAdt, Wgt and scaled Tokens as linear fixed effects and game\n2Interaction data weight values tested were 1, 3, 5, 7, 10.\nround ordinality (ROUND) as a quadratic fixed effect: Wgt denotes weighting word classifiers by RA, which will be discussed in Section 6. Tokens denotes the number of word tokens produced by both speakers in the given round3. DYAD (the pair of participants in a given dialog) was included as a random intercept with a random slope for Adt and Wgt. We selected the bestfitting model using backwards selection with loglikelihood ratio tests: Starting from the maximally complex model (Barr et al., 2013), we first simplified the random structure and then removed fixed effects not contributing to fit. This showed that including RndAdt does not significantly improve fit (χ2 = 0.00003, p = 0.99599), meaning model fit improves from data specific to the given dialog and not merely from more training data.\nWe refit the final model using maximumlikelihood estimation with Satterthwaite approximation to degrees of freedom (see the Supplementary Material for details). Despite that RR correlates with ROUND i even for the baseline method due to dialogic lexical alignment (cf. Shore and Skantze, 2017; Shore et al., 2018), there is a significant improvement in RR from Adt (B = 0.04882, t(40) = 7.65, p < 0.001).\nSince adding a small amount of data from a dialog significantly improves reference resolution for that dialog, dialogic reference resolution can be seen as a model adaptation problem, where indomain data (that from the dialog being evaluated)\n3Adding the count of coreferences to a given referent as a fixed effect prevented model convergence when included with Tokens. Regardless, adding it in lieu of Tokens did not significantly improve fit (χ2 = 3.7329,, p = 0.05335).\nis relatively sparse compared to out-of-domain data (that from other dialogs). This suggests that the effect of dyadic alignment on reference resolution is amplified: As ROUND i increases, not only is more data specific to the given dialog available, but the data observed becomes more homogeneous. Thus, the benefit of this method increases with time, as the ratio of interaction to background data increases."
  }, {
    "heading": "6 Weighting by Referring Ability",
    "text": "While the method above facilitates the adaption of referential semantics models to dyad-specific language, not all language which is rare and/or observed in only one dyad has great RA: For example, in the dataset used, there were 19 observations of the word awesome but 15 of those were in a single dialog. Even when evaluating on that dialog, a classifier would be inferred from the 19− 15 > α remaining observations, and even adapting the word models with interaction data as done in Section 5 will only add noise since it only occurs as non-RL (e.g. awesome good work). Conversely, a word such as piece is semantically heavy in general English but is by itself a poor signifier of referents given the task at hand. So, we evaluated the benefit of weighting word classifiers by their RA in order to mitigate the effects of such spurious observations. To do this, we define the RA of a word t as the mean difference between the probability of the actual referent r̂ being TRUE pt(r̂) and the mean probability for all other entities R \\ r̂ for every occurrence of the word in the training data:\nwt , 1\nn\nn∑\nd∈D (R,r̂,T )∈d\np′′t (R, r̂, T )\np′′t (R, r̂, T ) , p ′ t(r̂, T )−\n1\nm\nm∑\nr∈R\\r̂\np′t(r, T )\np′t(r, T ) , pt(r)\n|T |∑\ni=1\n[Ti = t]\n(2)\nOne alternative to this metric that we considered was the area under the receiver operating characteristic (ROC) curve (AUC). However, the metric above is more conservative in cases of word models with few observations by penalizing their score due to the logistic ridge used, thus putting more “trust” in word models with more observations; The AUC does not account for this directly.\nAlthough this metric is derived from referential semantics learned for a specific domain, the WaC logistic regression model(s) encoding referential semantics are simple and thus can easily be re-trained for other domains. It can also be derived from other models of referential semantics.\nFigure 4 compares the improvement of RR from weighting each classifier pt(r) by its RA wt (Wgt) to the Baseline and finally to that from combining adaptation from Section 5 with weighting (Adt,Wgt); Using the same linear mixed model described in Section 5, a significant improvement in RR was found for Wgt over the baseline (B = 0.1314, t(39) = 11.79, p < 0.001) although the effect weakens over time. However, this is likely not a weakness of the method but rather an effect of repeated reference on participants’ RL use: With repeated reference, the length of RL reduces (Clark and Wilkes-Gibbs, 1986), meaning that the mean RA of each word increases due to fewer tokens of weak RA being uttered. Indeed, a significant interaction between Round and Tokens was found in their effects on RA (see Supplementary Material). Figure 5 shows a significant correlation of ROUND i and mean RA of all tokens for that round 1 n ∑n t∈Ti wt. Additionally, Figure 6 shows a significant inverse relationship with token count |Ti|. Since the referent r̂ is chosen at random by the game, the amount of references to an entity increases with round ordinality, and so this corresponds with Clark and WilkesGibbs (1986).\nA qualitative assessment shows that vocabulary items with the great RA are typically nouns\nstrongly associated with the task at hand: The 31 words with greatest RA are all nouns referring to shapes. Despite this, however, great RA is not exclusive to nouns: In Table 2, inside, a preposition, is considered semantically lighter in general English than nouns are (Froud, 2001), but has RA greater than the mean (µ = 0.2424, SD = 0.1266). On the other hand, the noun color has relatively little RA given the task at hand.\nMoreover, including Adt and Wgt using dialog interaction data (Adt,Wgt) shows significant improvements over either alone: During model selection, including Wgt significantly improved fit\n(χ2 = 61.425, p < 0.001). This means that both methods can be used together and complement each other: Weighting is particularly beneficial for shorter interactions, where little in-domain interaction data is present, while adaptation provides greater benefit for longer interactions (cf. Figure 3). In fact, Figure 7 shows that Wgt has better MRR using only 12 randomly-chosen dialogs as background data than the Baseline does with 40, and adaptation and weighting together (Adt,Wgt) has better MRR with only 7. Figure 8 illustrates the effects of the two conditions on reference resolution in the task used for evaluation: The baseline classifier has a rank of 10 for the referent r̂ out of |R| = 20 possible referents. In the baseline (A), the classifier for e.g. color has as much weight as e.g. rectangle although the former is not a useful signifier for the given task. When weighting by RA (B), however, the less-useful words contribute less to the total∑ t∈T (pt(r̂) · wt), improving rank to 5. Finally, when adapting the model with interaction data (C), models for semantically-heavy words like violet better fit the dyad’s RL use, bringing rank to 1.\nWhen both incrementally adapting semantic models with in-domain dialog data and weighting by RA, MRR for reference resolution was improved by 32.5% over the baseline (see Table 3)."
  }, {
    "heading": "7 Conclusion and Discussion",
    "text": "We have shown that it is possible to improve reference resolution for situated dialog by incrementally adapting word semantic model parameters to\na given dialog in order to accommodate idiosyncratic language use by dyad partners, and the effect of the partners’ own alignment makes this method even more beneficial over time. Additionally, we have defined a metric of word referring ability which is derived from a word’s referential semantics in situated dialog but holds across individual dialogs despite dyadic variation in RL use. We showed that this metric can be used to automatically determine the usefulness of a given word for reference resolution, meaning that RE annotation is not necessary. Both of these aspects are beneficial to natural language understanding (NLU) for situated dialog due to the difficulty of acquiring data domain-appropriate data.\nModel adaption using dialogic knowledge can be effective for improving NLU (cf. Riccardi and Gorin, 2000) despite that little work has been done in this regard specifically for reference resolution. Our experiments with model adaptation in Section 5 suggest that it may be beneficial to treat reference resolution in situated dialog as a model adaptation task, where a given dialog being evalu-\nated is considered “in-domain” data and all other dialogs considered “out-of-domain” data. Moreover, due to the fact that dialog participants’ use of RL converges over time (Garrod and Anderson, 1987; Brennan, 1996; Brennan and Clark, 1996), the task should adapt a pre-trained reference resolution model not only for a given dialog but also to the given state of that dialog; On the other hand, Iida et al. (2010) incorporate intra-dialogic knowledge but do not adapt to inter-dialogic effects.\nLastly, weighting by RA wt as derived from logistic word classifier scores pt(r) in Section 6 was shown to be effective and can be easily inferred from data. However, this inaccurately assumes inter-word independence, since it does not encode a word’s context: For example, the RA of not was 0.0638, which is relatively low. While it is a poor signifier in itself, it reverses the polarity of the predicate it modifies. For example, in it’s the baby blue K the light one not the dark one, the NP the dark one should in fact have negative RA: Entities with a low semantic score ∑\nt∈〈the,dark,one〉 pt(r) should in fact be preferred over those those with a high score. This could be addressed via structural prediction (e.g. conditional random fields or neural networks) or even higher-order n-grams, but these methods cannot be easily utilized given the typically small size of situated dialog datasets."
  }, {
    "heading": "Acknowledgments",
    "text": "This work is supported by the SSF (Swedish Foundation for Strategic Research) project COIN. Plots were made with ggplot2 v2.2.1 (Wickham, 2009). The authors are grateful for Zofia Malisz’s help with model selection."
  }],
  "year": 2018,
  "references": [{
    "title": "Referring and accessibility",
    "authors": ["Mira Ariel."],
    "venue": "Journal of Linguistics, 24(1):65–87.",
    "year": 1988
  }, {
    "title": "Random effects structure for confirmatory hypothesis testing: Keep it maximal",
    "authors": ["Dale J. Barr", "Roger Levy", "Christoph Scheepers", "Harry J. Tily."],
    "venue": "Journal of Memory and Language, 68(3):255–278.",
    "year": 2013
  }, {
    "title": "Lexical entrainment in spontaneous dialog",
    "authors": ["Susan E. Brennan."],
    "venue": "Proceedings of the International Symposium on Spoken Dialogue (ISSD ’96), pages 41–44, Philadelpha, PA, USA. Acoustical Society of Japan.",
    "year": 1996
  }, {
    "title": "Conceptual pacts and lexical choice in conversation",
    "authors": ["Susan E. Brennan", "Herbert H. Clark."],
    "venue": "Journal of Experimental Psychology: Learning, Memory, and Cognition, 22(6):1482–1493.",
    "year": 1996
  }, {
    "title": "Ridge estimators in logistic regression",
    "authors": ["S. le Cessie", "J.C. van Houwelingen."],
    "venue": "Applied Statistics, 41(1):191–201.",
    "year": 1992
  }, {
    "title": "Referring as a collaborative process",
    "authors": ["Herbert H. Clark", "Deanna Wilkes-Gibbs."],
    "venue": "Cognition, 22(1):1–39.",
    "year": 1986
  }, {
    "title": "An efficient hybrid conjugate gradient method for unconstrained optimization",
    "authors": ["Yu-Hong Dai", "Ya-xiang Yuan."],
    "venue": "Annals of Operations Research, 103(1):33–47.",
    "year": 2001
  }, {
    "title": "The WEKA workbench",
    "authors": ["Eibe Frank", "Mark A. Hall", "Ian H. Witten."],
    "venue": "Online appendix for “Data mining: Practical machine learning tools and techniques”, Morgan Kaufmann, fourth edition, 2016. Last accessed 21 February 2018.",
    "year": 2016
  }, {
    "title": "Prepositions and the lexical/ functional divide: Aphasic evidence",
    "authors": ["Karen Froud."],
    "venue": "Lingua, 111(1):1–28.",
    "year": 2001
  }, {
    "title": "Saying what you mean in dialogue: A study in conceptual and semantic co-ordination",
    "authors": ["Simon Garrod", "Anthony Anderson."],
    "venue": "Cognition, 27(2):181– 218.",
    "year": 1987
  }, {
    "title": "Logic and conversation",
    "authors": ["Herbert Paul Grice."],
    "venue": "Syntax and Semantics, Volume 3: Speech Acts, pages 41–58. Academic Press, New York, NY, USA.",
    "year": 1975
  }, {
    "title": "Collaborating on referring expressions",
    "authors": ["Peter A. Heeman", "Graeme Hirst."],
    "venue": "Computational Linguistics, 21(3).",
    "year": 1995
  }, {
    "title": "Incorporating extra-linguistic information into reference resolution in collaborative task dialogue",
    "authors": ["Ryu Iida", "Syumpei Kobayashi", "Takenobu Tokunaga."],
    "venue": "Proceedings of the 48 Annual Meeting of the Association for Computational Linguis-",
    "year": 2010
  }, {
    "title": "A discriminative model for perceptuallygrounded incremental reference resolution",
    "authors": ["Casey Kennington", "Livia Dia", "David Schlangen."],
    "venue": "Proceedings of the 11 International Conference on Computational Semantics, pages 195–205, London,",
    "year": 2015
  }, {
    "title": "Simple learning and compositional application of perceptually grounded word meanings for incremental reference resolution",
    "authors": ["Casey Kennington", "David Schlangen."],
    "venue": "Proceedings of the 53 Annual Meeting of the Association for Computational",
    "year": 2015
  }, {
    "title": "Changes in reference phrases as a function of frequency of usage in social interaction: a preliminary study",
    "authors": ["Robert M. Krauss", "Sidney Weinheimer."],
    "venue": "Psychonomic Science, 1(1):113–114.",
    "year": 1964
  }, {
    "title": "A multiworld approach to question answering about realworld scenes based on uncertain input",
    "authors": ["Mateusz Malinowski", "Mario Fritz."],
    "venue": "Zoubin Ghahramani, Max Welling, Corinna Cortes, Neil D. Lawrence, and Kilian Q. Weinberger, editors, Ad-",
    "year": 2014
  }, {
    "title": "Building a large annotated corpus of English: The Penn treebank",
    "authors": ["Mitchell P. Marcus", "Mary Ann Marcinkiewicz", "Beatrice Santorini."],
    "venue": "Computational Linguistics, 19(2).",
    "year": 1993
  }, {
    "title": "Learning from unscripted deictic gesture and language for human-robot interactions",
    "authors": ["Cynthia Matuszek", "Liefeng Bo", "Luke Zettlemoyer", "Dieter Fox."],
    "venue": "Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence, pages 2556–",
    "year": 2014
  }, {
    "title": "A joint model of language and perception for grounded attribute learning",
    "authors": ["Cynthia Matuszek", "Nicholas FitzGerald", "Luke Zettlemoyer", "Liefeng Bo", "Dieter Fox."],
    "venue": "Proceedings of the 29 International Conference on Machine Learning (ICML-12),",
    "year": 2012
  }, {
    "title": "A data-driven approach to understanding spoken route directions in human-robot dialogue",
    "authors": ["Raveesh Meena", "Gabriel Skantze", "Joakim Gustafson."],
    "venue": "INTERSPEECH 2012, 13 Annual Conference of the International Speech Commu-",
    "year": 2012
  }, {
    "title": "Language and thought: Aspects of a cognitive theory of semantics",
    "authors": ["David Richard Olson."],
    "venue": "Psychological Review, 77(4):257–273.",
    "year": 1970
  }, {
    "title": "A corpusbased investigation of definite description use",
    "authors": ["Massimo Poesio", "Renata Vieira."],
    "venue": "Computational Linguistics, 24(2):183–216.",
    "year": 1998
  }, {
    "title": "What’s in a gaze?: The role of eye-gaze in reference resolution in multimodal conversational interfaces",
    "authors": ["Zahar Prasov", "Joyce Y. Chai."],
    "venue": "Proceedings of the 13 International Conference on Intelligent User Interfaces, IUI ’08, pages 20–29, New",
    "year": 2008
  }, {
    "title": "What (if anything) is accessibility? a relevance-oriented criticism of Ariel’s accessibility theory of referring expressions",
    "authors": ["Anne Reboul."],
    "venue": "John H. Connolly, Roel M. Vismans, Christopher S. Butler, and Richard A. Gatward, editors, Discourse and",
    "year": 1997
  }, {
    "title": "Stochastic language adaptation over time and state in natural spoken dialog systems",
    "authors": ["Giuseppe Riccardi", "Allen L. Gorin."],
    "venue": "IEEE Transactions on Speech and Audio Processing, 8(1):3–10.",
    "year": 2000
  }, {
    "title": "Automatic annotation of referring expression in situated dialogues",
    "authors": ["Niels Schutte", "John D. Kelleher", "Brian Mac Namee."],
    "venue": "International Journal of Computational Linguistics and Applications, 2(12):175–190.",
    "year": 2011
  }, {
    "title": "KTH Tangrams: A dataset for research on alignment and conceptual pacts in taskoriented dialogue",
    "authors": ["Todd Shore", "Theofronia Androulakaki", "Gabriel Skantze."],
    "venue": "Proceedings of the Eleventh International Conference on Language Resources",
    "year": 2018
  }, {
    "title": "Enhancing reference resolution in dialogue using participant feedback",
    "authors": ["Todd Shore", "Gabriel Skantze."],
    "venue": "Proceedings, GLU 2017 International Workshop on Grounding Language Understanding, pages 78–82, Stockholm, Sweden.",
    "year": 2017
  }, {
    "title": "Using extra linguistic information for generating demonstrative pronouns in a situated collaboration task",
    "authors": ["Philipp Spanger", "Yasuhara Masaaki", "Iida Ryu", "Tokunaga Tokenobu."],
    "venue": "Proceedings of the Workshop on the Production of Referring Ex-",
    "year": 2009
  }, {
    "title": "ggplot2: Elegant Graphics for Data Analysis",
    "authors": ["Hadley Wickham."],
    "venue": "Springer-Verlag New York, New York, NY, USA.",
    "year": 2009
  }, {
    "title": "PentoRef: A corpus of spoken references in task-oriented dialogues",
    "authors": ["Sina Zarrieß", "Julian Hough", "Casey Kennington", "Ramesh Manuvinakurike", "David DeVault", "Raquel Fernández", "David Schlangen."],
    "venue": "Proceedings of the Tenth International",
    "year": 2016
  }],
  "id": "SP:a5cf78337329d11a3ddc269d94264b10795e6956",
  "authors": [{
    "name": "Todd Shore",
    "affiliations": []
  }],
  "abstractText": "Referring to entities in situated dialog is a collaborative process, whereby interlocutors often expand, repair and/or replace referring expressions in an iterative process, converging on conceptual pacts of referring language use in doing so. Nevertheless, much work on exophoric reference resolution (i.e. resolution of references to entities outside of a given text) follows a literary model, whereby individual referring expressions are interpreted as unique identifiers of their referents given the state of the dialog the referring expression is initiated. In this paper, we address this collaborative nature to improve dialogic reference resolution in two ways: First, we trained a words-asclassifiers logistic regression model of word semantics and incrementally adapt the model to idiosyncratic language between dyad partners during evaluation of the dialog. We then used these semantic models to learn the general referring ability of each word, which is independent of referent features. These methods facilitate accurate automatic reference resolution in situated dialog without annotation of referring expressions, even with little background data.",
  "title": "Using Lexical Alignment and Referring Ability to Address Data Sparsity in Situated Dialog Reference Resolution"
}