{
  "sections": [{
    "heading": "1. Introduction",
    "text": "We study a novel approach to collaborative ranking—the personalized ranking of items for users based on their observed preferences—through the use of listwise losses, which are dependent only on the observed rankings of items by users. We propose the SQL-Rank algorithm, which can handle ties and missingness, incorporate both explicit ratings and more implicit feedback, provides personalized rankings, and is\n1Department of Statistics, University of California, Davis, CA, USA 2Department of Computer Science, University of California, Davis, CA, USA. Correspondence to: Liwei Wu <liwu@ucdavis.com>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nbased on the relative rankings of items. To better understand the proposed contributions, let us begin with a brief history of the topic."
  }, {
    "heading": "1.1. A brief history of collaborative ranking",
    "text": "Recommendation systems, found in many modern web applications, movie streaming services, and social media, rank new items for users and are judged based on user engagement (implicit feedback) and ratings (explicit feedback) of the recommended items. A high-quality recommendation system must understand the popularity of an item and infer a user’s specific preferences with limited data. Collaborative filtering, introduced in (Hill et al., 1995), refers to the use of an entire community’s preferences to better predict the preferences of an individual (see (Schafer et al., 2007) for an overview). In systems where users provide ratings of items, collaborative filtering can be approached as a pointwise prediction task, in which we attempt to predict the unobserved ratings (Pan et al., 2017). Low rank methods, in which the rating distribution is parametrized by a low rank matrix (meaning that there are a few latent factors) provides a powerful framework for estimating ratings (Mnih & Salakhutdinov, 2008; Koren, 2008). There are several issues with this approach. One issue is that the feedback may not be representative of the unobserved entries due to a sampling bias, an effect that is prevalent when the items are only ‘liked’ or the feedback is implicit because it is inferred from user engagement. Augmenting techniques like weighting were introduced to the matrix factorization objective to overcome this problem (Hsieh et al., 2015; Hu et al., 2008). Many other techniques are also introduced (Kabbur et al., 2013; Wang et al., 2017; Wu et al., 2016). Another methodology worth noting is the CofiRank algorithm of (Weimer et al., 2008) which minimizes a convex surrogate of the normalized discounted cumulative gain (NDCG). The pointwise framework has other flaws, chief among them is that in recommendation systems we are not interested in predicting ratings or engagement, but rather we must rank the items.\nRanking is an inherently relative exercise. Because users have different standards for ratings, it is often desirable for ranking algorithms to rely only on relative rankings and not absolute ratings. A ranking loss is one that only considers a user’s relative preferences between items, and ignores the\nabsolute value of the ratings entirely, thus deviating from the pointwise framework. Ranking losses can be characterized as pairwise and listwise. A pairwise method decomposes the objective into pairs of items j, k for a user i, and effectively asks ‘did we successfully predict the comparison between j and k for user i?’. The comparison is a binary response—user i liked j more than or less than k—with possible missing values in the event of ties or unobserved preferences. Because the pairwise model has cast the problem in the classification framework, then tools like support vector machines were used to learn rankings; (Joachims, 2002) introduces rankSVM and efficient solvers can be found in (Chapelle & Keerthi, 2010). Much of the existing literature focuses on learning a single ranking for all users, which we will call simple ranking (Freund et al., 2003; Agarwal, 2006; Pahikkala et al., 2009). This work will focus on the personalized ranking setting, in which the ranking is dependent on the user.\nPairwise methods for personalized ranking have seen great advances in recent years, with the AltSVM algorithm of (Park et al., 2015), Bayesian personalized ranking (BPR) of (Rendle et al., 2009), and the near linear-time algorithm of (Wu et al., 2017). Nevertheless, pairwise algorithms implicitly assume that the item comparisons are independent, because the objective can be decomposed where each comparison has equal weight. Listwise losses instead assign a loss, via a generative model, to the entire observed ranking, which can be thought of as a permutation of the m items, instead of each comparison independently. The listwise permutation model, introduced in (Cao et al., 2007), can be thought of as a weighted urn model, where items correspond to balls in an urn and they are sequentially plucked from the urn with probability proportional to (X\nij ) where X\nij is the latent score for user i and item j and is some non-negative function. They proposed to learn rankings by optimizing a cross entropy between the probability of k items being at the top of the ranking and the observed ranking, which they combine with a neural network, resulting in the ListNet algorithm. (Shi et al., 2010) applies this idea to collaborative ranking, but uses only the top-1 probability because of the computational complexity of using top-k in this setting. This was extended in (Huang et al., 2015) to incorporate neighborhood information. (Xia et al., 2008) instead proposes a maximum likelihood framework that uses the permutation probability directly, which enjoyed some empirical success.\nVery little is understood about the theoretical performance of listwise methods. (Cao et al., 2007) demonstrates that the listwise loss has some basic desirable properties such as monotonicity, i.e. increasing the score of an item will tend to make it more highly ranked. (Lan et al., 2009) studies the generalizability of several listwise losses, using the local Rademacher complexity, and found that the excess\nrisk could be bounded by a 1/ p n term (recall, n is the number of users). Two main issues with this work are that no dependence on the number of items is given—it seems these results do not hold when m is increasing—and the scores are not personalized to specific users, meaning that they assume that each user is an independent and identically distributed observation. A simple open problem is: can we consistently learn preferences from a single user’s data if we are given item features and we assume a simple parametric model? (n = 1,m ! 1.)"
  }, {
    "heading": "1.2. Contributions of this work",
    "text": "We can summarize the shortcomings of the existing work: current listwise methods for collaborative ranking rely on the top-1 loss, algorithms involving the full permutation probability are computationally expensive, little is known about the theoretical performance of listwise methods, and few frameworks are flexible enough to handle explicit and implicit data with ties and missingness. This paper addresses each of these in turn by proposing and analyzing the SQLrank algorithm.\n• We propose the SQL-Rank method, which is motivated by the permutation probability, and has advantages over the previous listwise method using cross entropy loss. • We provide an O(iter · (|⌦|r)) linear algorithm based on stochastic gradient descent, where ⌦ is the set of observed ratings and r is the rank. • The methodology can incorporate both implicit and explicit feedback, and can gracefully handle ties and missing data. • We provide a theoretical framework for analyzing listwise methods, and apply this to the simple ranking and personalized ranking settings, highlighting the dependence on the number of users and items."
  }, {
    "heading": "2. Methodology",
    "text": ""
  }, {
    "heading": "2.1. Permutation probability",
    "text": "The permutation probability, (Cao et al., 2007), is a generative model for the ranking parametrized by latent scores. First assume there exists a ranking function that assigns scores to all the items. Let’s say we have m items, then the scores assigned can be represented as a vector s = (s1, s2, ..., sm). Denote a particular permutation (or ordering) of the m items as ⇡, which is a random variable and takes values from the set of all possible permutations S\nm\n(the symmetric group on m elements). ⇡1 denotes the index of highest ranked item and ⇡\nm\nis the lowest ranked. The\nprobability of obtaining ⇡ is defined to be\nP s\n(⇡) := mY\nj=1\n(s ⇡j )P\nm l=j (s⇡l) , (1)\nwhere (.) is an increasing and strictly positive function. An interpretation of this model is that each item is drawn without replacement with probability proportional to (s\ni\n)\nfor item i in each step. One can easily show that P s (⇡) is a valid probability distribution, i.e.\nP ⇡2Sm Ps(⇡) =\n1, P s (⇡) > 0, 8⇡. Furthermore, this definition of permutation probability enjoys several favorable properties (see (Cao et al., 2007)). For any permutation ⇡ if you swap two elements ranked at i < j generating the permutation ⇡0 (⇡0\ni\n= ⇡ j , ⇡0 j = ⇡ i , ⇡ k = ⇡0 k , k 6= i, j), if s ⇡i > s⇡j\nthen P s (⇡) > P s (⇡0). Also, if permutation ⇡ satisfies s ⇡i > s⇡i+1 , 8i, then we have ⇡ = argmax⇡02Sm Ps(⇡0). Both of these properties can be summarized: larger scores will tend to be ranked more highly than lower scores. These properties are required for the negative log-likelihood to be considered sound for ranking (Xia et al., 2008).\nIn recommendation systems, the top ranked items can be more impactful for the performance. In order to focus on the top k ranked items, we can compute the partial-ranking marginal probability,\nP (k,m̄) s (⇡) =\nmin{k,m̄}Y\nj=1\n(s ⇡j )P\nm̄ l=j (s⇡l) . (2)\nIt is a common occurrence that only a proportion of the m items are ranked, and in that case we will allow m̄  m to be the number of observed rankings (we assume that ⇡1, . . . ,⇡m̄ are the complete list of ranked items). When k = 1, the first summation vanishes and top-1 probability can be calculated straightforwardly, which is why k = 1 is widely used in previous listwise approaches for collaborative ranking. Counter-intuitively, we demonstrate that using a larger k tends to improve the ranking performance.\nWe see that computing the likelihood loss is linear in the number of ranked items, which is in contrast to the crossentropy loss used in (Cao et al., 2007), which takes exponential time in k. The cross-entropy loss is also not sound, i.e. it can rank worse scoring permutations more highly, but the negative log-likelihood is sound. We will discuss how we can deal with ties in the following subsection, namely, when the ranking is derived from ratings and multiple items receive the same rating, then there is ambiguity as to the order of the tied items. This is a common occurrence when the data is implicit, namely the output is whether the user engaged with the item or not, yet did not provide explicit feedback. Because the output is binary, the cross-entropy loss (which is based on top-k probability with k very small) will perform very poorly because there will be many ties\nfor the top ranked items. To this end, we propose a collaborative ranking algorithm using the listwise likelihood that can accommodate ties and missingness, which we call Stochastic Queuing Listwise Ranking, or SQL-Rank."
  }, {
    "heading": "2.2. Deriving objective function for SQL-Rank",
    "text": "The goal of collaborative ranking is to predict a personalized score X\nij that reflects the preference level of user i towards item j, where 1  i  n and 1  j  m. It is reasonable to assume the matrix X 2 Rn⇥m to be low rank because there are only a small number of latent factors contributing to users’ preferences. The input data is given in the form of “user i gives item j a relevance score R\nij ”. Note that for simplicity we assume all the users have the same number m̄ of ratings, but this can be easily generalized to the nonuniform case by replacing m̄ with m\ni (number of ratings for user i).\nWith our scores X and our ratings R, we can specify our collaborative ranking model using the permutation probability (2). Let ⇧\ni be a ranking permutation of items for user i (extracted from R), we can stack ⇧1, . . .⇧n, row by row, to get the permutation matrix ⇧ 2 Rn⇥m. Assuming users are independent with each other, the probability of observing a particular ⇧ given the scoring matrix X can be written as\nP (k,m̄) X (⇧) =\nnY\ni=1\nP (k,m̄) Xi (⇧ i ). (3)\nWe will assume that log (x) = 1/(1 + exp( x)) is the sigmoid function. This has the advantage of bounding the resulting weights, (X\nij ), and maintaining their positivity without adding additional constraints.\nTypical rating data will contain many ties within each row. In such cases, the permutation ⇧ is no longer unique and there is a set of permutations that coincides with rating because with any candidate ⇧ we can arbitrarily shuffle the ordering of items with the same relevance scores to generate a new candidate matrix ⇧0 which is still valid (see Figure 1). We denote the set of valid permutations as S(R,⌦), where ⌦ is the set of all pairs (i, j) such that R\ni,j is observed. We call this shuffling process the Stochastic Queuing Process, since one can imagine that by permuting ties we are stochastically queuing new ⇧’s for future use in the algorithm.\nThe probability of observing R therefore should be defined as P (k,m̄)\nX\n(R) = P\n⇧2S(R,⌦) PX(⇧). To learn the scoring matrix X , we can naturally solve the following maximum likelihood estimator with low-rank constraint:\nmin X2X log\nX\n⇧2S(R,⌦)\nP (k,m̄) X (⇧), (4)\nwhere X is the structural constraint of the scoring matrix. To enforce low-rankness, we use the nuclear norm regularization X = {X : kXk⇤  r}.\nEq (4) is hard to optimize since there is a summation inside the log. But by Jensen’s inequality and convexity of log function, we can move the summation outside log and obtain an upper bound of the original negative log-likelihood, leading to the following optimization problem:\nmin X2X\nX\n⇧2S(R,⌦)\nlogP (k,m̄) X (⇧) (5)\nThis upper bound is much easier to optimize and can be solved using Stochastic Gradient Descent (SGD).\nNext we discuss how to apply our model for explicit and implicit feedback settings. In the explicit feedback setting, it is assumed that the matrix R is partially observed and the observed entries are explicit ratings in a range (e.g., 1 to 5). We will show in the experiments that k = m̄ (using the full list) leads to the best results. (Huang et al., 2015) also observed that increasing k is useful for their cross-entropy loss, but they were not able to increase k since their model has time complexity exponential to k.\nIn the implicit feedback setting each element of R ij is either 1 or 0, where 1 means positive actions (e.g., click or like) and 0 means no action is observed. Directly solving (5) will be expensive since m̄ = m and the computation will involve all the mn elements at each iteration. Moreover, the 0’s in the matrix could mean either a lower relevance score or missing, thus should contribute less to the objective function. Therefore, we adopt the idea of negative sampling (Mikolov et al., 2013) in our list-wise formulation. For each user (row of R), assume there are m̃ 1’s, we then sample ⇢m̃ unobserved entries uniformly from the same row and append\nAlgorithm 1 SQL-Rank: General Framework Input: ⌦, {R\nij : (i, j) 2 ⌦}, 2 R+, ss, rate, ⇢ Output: U 2 Rr⇥n and V 2 Rr⇥m Randomly initialize U, V from Gaussian Distribution repeat\nGenerate a new permutation matrix ⇧ {see alg 2} Apply gradient update to U while fixing V Apply gradient update to V while fixing U {see alg 4}\nuntil performance for validation set is good return U, V {recover score matrix X}\nAlgorithm 2 Stochastic Queuing Process Input: ⌦, {R\nij : (i, j) 2 ⌦}, ⇢ Output: ⇧ 2 Rn⇥m for i = 1 to n do\nSort items based on observed relevance levels R i Form ⇧ i\nbased on indices of items in the sorted list Shuffle ⇧\ni for items within the same relevance level if Dataset is implicit feedback then\nUniformly sample ⇢m̃ items from unobserved items Append sampled indices to the back of ⇧\ni\nend if end for Stack ⇧\ni as rows to form matrix ⇧ Return ⇧ {Used later to compute gradient}\nto the back of the list. This then becomes the problem with m̄ = (1 + ⇢)m̃ and then we use the same algorithm in explicit feedback setting to conduct updates. We then repeat the sampling process at the end of each iteration, so the update will be based on different set of 0’s at each time."
  }, {
    "heading": "2.3. Non-convex implementation",
    "text": "Despite the advantage of the objective function in equation (5) being convex, it is still not feasible for large-scale problems since the scoring matrix X 2 Rn⇥m leads to high computational and memory cost. We follow a common trick to transform (5) to the non-convex form by replacing X = UTV : with U 2 Rr⇥n, V 2 Rr⇥m so that the objective is,\nX\n⇧2S(R,⌦)\nnX\ni=1\nm̄X\nj=1\nlog\n(uT i v⇧ij )P m̄\nl=j (u T i v⇧il) | {z }\nf(U,V )\n+\n2\n(kUk2 F +kV k2 F ),\nwhere u i , v j are columns of U, V respectively. We apply stochastic gradient descent to solve this problem. At each step, we choose a permutation matrix ⇧ 2 S(R,⌦) using the stochastic queuing process (Algorithm 2) and then update U, V by rf(U, V ). For example, the gradient with\nrespect to V is (g = log is the sigmoid function),\n@f\n@v j\n=\nX\ni2⌦j\nm̄X\nt=1\n⇢ g0(uT\ni\nv t )u i\n+\n(rank i (j) t) (uT i v j )\nP m̄\nl=t (u T i v⇧il) g0(uT i v j )u i\nwhere ⌦ j denotes the set of users that have rated the item j and rank\ni (j) is a function gives the rank of the item j for that user i. Because g is the sigmoid function, g0 = g · (1 g). The gradient with respect to U can be derived similarly.\nAs one can see, a naive way to compute the gradient of f requires O(nm̄2r) time, which is very slow even for one iteration. However, we show in Algorithm 3 (in the appendix) that there is a smart way to re-arranging the computation so that r\nV f(U, V ) can be computed in O(nm̄r) time, which makes our SQL-Rank a linear-time algorithm (with the same per-iteration complexity as classical matrix factorization)."
  }, {
    "heading": "3. Theory",
    "text": "Throughout this section, we will establish a theoretical framework for understanding listwise ranking algorithms. We do not consider ties and missing data and reserve this extension of the theory developed here for future work. These tools can be employed to analyze any problem of the constrained form\nˆX := argmin logP X\n(⇧) such that X 2 X . (6)\nWe will consider two main settings of listwise ranking, the simple ranking setting where for each X 2 X ,\nX ij = >z ij , 2 Rs, k k  c b , (7)\nwhere the feature vectors z ij 2 Rs are known, and the personalized setting,\nX ij = u> i v j , u i , v j 2 Rr, kUk F  c u , kV k F  c v . (8)\nThe simple ranking setting, among other listwise programs was considered in (Lan et al., 2009), and it was determined that the excess risk is bounded by a 1/ p n term. Critically, these results assumed that the number of items m is bounded, severely limiting their relevance to realistic recommendation systems. It seems that we should be able to learn something about a user’s preferences by having them rank more items, yet the existing theory does not reflect this.\nThe main engine of our theoretical analysis is a generative mechanism for listwise ranking, which demonstrates that the permutation probability model, (1), is also the probability of a row-wise ordering of an exponential ensemble matrix. We demonstrate that the excess risk in the parametric setting scales like p m lnm/n, achieving parametric rates in n and\nsub-linear excess risk in m when the feature dimension s is fixed. In the personalized setting, (8), we bound the excess risk by p m/n lnm when the rank r is fixed, which matches comparable results for matrix factorization up to log factors."
  }, {
    "heading": "3.1. Generative mechanism for listwise ranking",
    "text": "We give an alternative generative mechanism which will prove useful for understanding the listwise ranking objective. Theorem 1. Consider a matrix, Y , with independent entries, Y\nij that are drawn from an exponential distribution with rate (X\nij ). Let ⇧ i be the ordering of the entries of Y i from smallest to largest, then the probability of ⇧ i |X i\nis exactly P\nXi(⇧i).\nThe proof is in the appendix. A key aspect of this generative mechanism is that the listwise likelihood can be written as a function of the exponential ensemble. This allows us to establish concentration of measure results for the listwise loss via bounded differences."
  }, {
    "heading": "3.2. Statistical guarantees",
    "text": "As a first step to controlling the excess risk, we establish a basic inequality. This bounds the excess risk by an empirical process term, which is a random function of ˆX and for a fixed ˆX it has mean zero. The excess risk (the difference in expected loss between the estimate and the truth) can also be written as the KL divergence between the estimated model and the true model. Lemma 1. Consider the minimizer, ˆX , to the constrained optimization, (6). Suppose that there exists a X? 2 X such that ⇧\ni ⇠ P X\n? i independently for all i = 1, . . . , n. The KLdivergence between the estimate and the truth is bounded\nD(X?, ˆX) := 1\nn\nnX\ni=1\nE log P X ? i (⇧ i )\nP X̂i (⇧ i )\n(basic)\n 1 n\nnX\ni=1\nlog\nP X\n? i (⇧ i )\nP X̂i (⇧ i )\nE log P X ? i (⇧ i )\nP X̂i (⇧ i )\n! .\nBecause the RHS of (basic), the empirical process term, has mean zero and is a function of the random permutation, we can use Theorem 1 to bound it with high probability for a fixed ˆX . Because ˆX is random, we need to control the empirical process term uniformly over the selection of ˆX 2 X . To this end, we employ Dudley’s chaining, which gives us the following theorem (see the Supplement for the complete proof). Theorem 2. Assume the conditions of Lemma 1. Define the matrix norm, for the n⇥m matrix Z,\nkZk1,2 :=\nvuut nX\ni=1\nkZ i k21\nand define Z = {log (X) : X 2 X} where log is applied elementwise. Also, let N (✏,Z, k.k1,2) be the ✏- covering number of Z in the 1, 2 norm (the fewest number of ✏ radius balls in the 1, 2 norm required to cover Z). Then, if sup\nZ2Z kZk1  C (where k.k1 is the elementwise absolute maximum), then\nD(X?, ˆX) = OP\n✓p m ln(m)\nn · g(Z)\n◆ ,\nwhere\ng(Z) := Z 1\n0\nq lnN (u,Z, k.k1,2)du,\nand C is bounded by a constant in n,m.\nTheorem 2 bounds the KL-divergence by the geometric quantity g(Z). For the derived corollaries, we will assume that log is 1-Lipschitz, which is true when log is the sigmoid function. The results do not significantly change by increasing the Lipschitz constant, so for simplicity of presentation we set it to be 1.\nCorollary 1. Assume the conditions to Lemma 1, the simple ranking setting (7), that log is 1-Lipschitz, and kZ\nij k2 is bounded uniformly, then\nD(X?, ˆX) = OP\n✓p sm\nn lnm\n◆ .\nNotably when n = 1 this bound is on the order of p m lnm. In the event that P X\n? is concentrated primarily on a single permutation for this user, and we resort to random guessing (i.e. ˆX1j = 0) then the KL divergence will be close to lnm! ⇡ m lnm. So, a reduction of the KL-divergence from order m lnm to p m lnm is a large improvement, and the above result should be understood to mean that we can achieve consistency even when n = 1 (where consistency is measured relative to random guessing).\nCorollary 2. Assume the conditions to Lemma 1, the personalized ranking setting, (8), and that log is 1-Lipschitz,\nD(X?, ˆX) = OP\n✓r rm\nn lnm\n◆ .\nNotably, even in the personalized setting, where each user has their own preferences, we can achieve 1/ p n rates for fixed m, r. Throughout these results the OP notation only hides the constants c\nb , c u , c v , and any dependence on s, r,m, n is explicitly given. While Theorem 2 gives us a generic result that can be applied to a large range of constraint sets, we believe that the parametric simple ranking and the low-rank personalized setting are the two most important listwise ranking problems."
  }, {
    "heading": "4. Experiments",
    "text": "In this section, we compare our proposed algorithm (SQLRank) with other state-of-the-art algorithms on real world datasets. Note that our algorithm works for both implicit feedback and explicit feedback settings. In the implicit feedback setting, all the ratings are 0 or 1; in the explicit feedback setting, explicit ratings (e.g., 1 to 5) are given but only to a subset of user-item pairs. Since many real world recommendation systems follow the implicit feedback setting (e.g., purchases, clicks, or checkins), we will first compare SQL-Rank on implicit feedback datasets and show it outperforms state-of-the-art algorithms. Then we will verify that our algorithm also performs well on explicit feedback problems. All experiments are conducted on a server with an Intel Xeon E5-2640 2.40GHz CPU and 64G RAM."
  }, {
    "heading": "4.1. Implicit Feedback",
    "text": "In the implicit feedback setting we compare the following methods:\n• SQL-Rank: our proposed algorithm implemented in Julia 1. • Weighted-MF: the weighted matrix factorization algorithm by putting different weights on 0 and 1’s (Hu et al., 2008; Hsieh et al., 2015). • BPR: the Bayesian personalized ranking method motivated by MLE (Rendle et al., 2009). For both WeightedMF and BPR, we use the C++ code by Quora 2.\nNote that other collaborative ranking methods such as Pirmal-CR++ (Wu et al., 2017) and List-MF (Shi et al., 2010) do not work for implicit feedback data, and we will compare with them later in the explicit feedback experiments. For the performance metric, we use precision@k for k = 1, 5, 10 defined by\nprecision@k = P n\ni=1 |{1  l  k : Ri⇧il = 1}| n · k , (9)\nwhere R is the rating matrix and ⇧ il gives the index of the l-th ranked item for user i among all the items not rated by user i in the training set.\nWe use rank r = 100 and tune regularization parameters for all three algorithms using a random sampled validation set. For Weighted-MF, we also tune the confidence weights on unobserved data. For BPR and SQL-Rank, we fix the ratio of subsampled unobserved 0’s versus observed 1’s to be 3 : 1, which gives the best performance for both BPR and SQL-rank in practice.\nWe experiment on the following four datasets. Note that the 1 https://github.com/wuliwei9278/SQL-Rank\n2 https://github.com/quora/qmf\noriginal data of Movielens1m, Amazon and Yahoo-music are ratings from 1 to 5, so we follow the procedure in (Rendle et al., 2009; Yu et al., 2017) to preprocess the data. We transform ratings of 4, 5 into 1’s and the rest entries (with rating 1, 2, 3 and unknown) as 0’s. Also, we remove users with very few 1’s in the corresponding row to make sure there are enough 1’s for both training and testing. For Amazon, Yahoo-music and Foursquare, we discard users with less than 20 ratings and randomly select 10 1’s as training and use the rest as testing. Movielens1m has more ratings than others, so we keep users with more than 60 ratings, and randomly sample 50 of them as training.\n• Movielens1m: a popular movie recommendation data with 6, 040 users and 3, 952 items. • Amazon: the Amazon purchase rating data for musical instruments 3 with 339, 232 users and 83, 047 items. • Yahoo-music: the Yahoo music rating data set 4 which contains 15, 400 users and 1, 000 items. • Foursquare: a location check-in data5. The data set contains 3, 112 users and 3, 298 venues with 27, 149 check-ins. The data set is already in the form of “0/1” so we do not need to do any transformation.\nThe experimental results are shown in Table 1. We find that SQL-Rank outperforms both Weighted-MF and BPR in most cases."
  }, {
    "heading": "4.2. Explicit Feedback",
    "text": "Next we compare the following methods in the explicit feedback setting:\n• SQL-Rank: our proposed algorithm implemented in Julia. Note that in the explicit feedback setting our\n3 http://jmcauley.ucsd.edu/data/amazon/ 4 https://webscope.sandbox.yahoo.com/\ncatalog.php?datatype=r&did=3\n5 https://sites.google.com/site/\nyangdingqi/home/foursquare-dataset\nalgorithm only considers pairs with explicit ratings. • List-MF: the listwise algorithm using the cross entropy\nloss between observed rating and top 1 probability (Shi et al., 2010). We use the C++ implementation on github6. • MF: the classical matrix factorization algorithm in (Koren, 2008) utilizing a pointwise loss solved by SGD. We implemented SGD in Julia. • Primal-CR++: the recently proposed pairwise algorithm in (Wu et al., 2017). We use the Julia implementation released by the authors7.\nExperiments are conducted on Movielens1m and Yahoomusic datasets. We perform the same procedure as in implicit feedback setting except that we do not need to mask the ratings into “0/1”.\nWe measure the performance in the following two ways:\n• NDCG@k: defined as:\nNDCG@k = 1\nn\nnX\ni=1\nDCG@k(i,⇧ i ) DCG@k(i,⇧⇤ i ) ,\nwhere i represents i-th user and\nDCG@k(i,⇧ i ) =\nkX\nl=1\n2 Ri⇧il 1 log2(l + 1) .\nIn the DCG definition, ⇧ il represents the index of the l-th ranked item for user i in test data based on the learned score matrix X . R is the rating matrix and R\nij is the rating given to item j by user i. ⇧⇤ i is the ordering provided by the ground truth rating. • Precision@k: defined as a fraction of relevant items among the top k recommended items:\nprecision@k = P n\ni=1 |{1  l  k : 4  Ri⇧il  5}| n · k ,\nhere we consider items with ratings assigned as 4 or 5 as relevant. R\nij follows the same definitions above but unlike before ⇧\nil gives the index of the l-th ranked item for user i among all the items that are not rated by user i in the training set (including both rated test items and unobserved items).\nAs shown in Table 2, our proposed listwise algorithm SQLRank outperforms previous listwise method List-MF in both NDCG@10 and precision@1, 5, 10. It verifies the claim that log-likelihood loss outperforms the cross entropy loss if we use it correctly. When listwise algorithm SQL-Rank is compared with pairwise algorithm Primal-CR++, the performances between SQL-Rank and Primal-CR++ are quite similar, slightly lower for NDCG@10 but higher for\n6 https://github.com/gpoesia/listrankmf 7 https://github.com/wuliwei9278/ml-1m\nprecision@1, 5, 10. Pointwise method MF is doing okay in NDCG but really bad in terms of precision. Despite having comparable NDCG, the predicted top k items given by MF are quite different from those given by other algorithms utilizing a ranking loss. The ordered lists based on SQL-Rank, Primal-CR++ and List-MF, on the other hand, share a lot of similarity and only have minor difference in ranking of some items. It is an interesting phenomenon that we think is worth exploring further in the future."
  }, {
    "heading": "4.3. Training speed",
    "text": "To illustrate the training speed of our algorithm, we plot precision@1 versus training time for the Movielen1m dataset and the Foursquare dataset. Figure 2 and Figure 3 (in the appendix) show that our algorithm SQL-Rank is faster than BPR and Weighted-MF. Note that our algorithm is implemented in Julia while BPR and Weighted-MF are highly-optimized C++ codes (usually at least 2 times faster than Julia) released by Quora. This speed difference makes sense as our algorithm takes O(nm̄r) time, which is linearly to the observed ratings. In comparison, pair-wise model such as BPR has O(nm̄2) pairs, so will take O(nm̄2r) time for each epoch."
  }, {
    "heading": "4.4. Effectiveness of Stochastic Queuing (SQ)",
    "text": "One important innovation in our SQL-Rank algorithm is the Stochastic Queuing (SQ) Process for handling ties. To illustrate the effectiveness of the SQ process, we compare our algorithm with and without SQ. Recall that without SQ\nmeans we fix a certain permutation matrix ⇧ and optimize with respect to it throughout all iterations without generating new ⇧, while SQ allows us to update using a new permutation at each time. As shown Table 3 and Figure 4 (in the appendix), the performance gain from SQ in terms of precision is substantial (more than 10%) on Movielen1m dataset. It verifies the claim that our way of handling ties and missing data is very effective and improves the ranking results by a lot."
  }, {
    "heading": "4.5. Effectiveness of using the Full List",
    "text": "Another benefit of our algorithm is that we are able to minimize top k probability with much larger k and without much overhead. Previous approaches (Huang et al., 2015) already pointed out increasing k leads to better ranking results, but their complexity is exponential to k so they were not able to have k > 1. To show the effectiveness of using permutation probability for full lists rather than using the top k probability for top k partial lists in the likelihood loss, we fix everything else to be the same and only vary k in Equation (5). We obtain the results in Table 4 and Figure 5 (in the appendix). It shows that the larger k we use, the better the results we can get. Therefore, in the final model, we set k to be the maximum number (length of the observed list.)"
  }, {
    "heading": "5. Conclusions",
    "text": "In this paper, we propose a listwise approach for collaborative ranking and provide an efficient algorithm to solve it. Our methodology can incorporate both implicit and explicit feedback, and can gracefully handle ties and missing data. In experiments, we demonstrate our algorithm outperforms existing state-of-the art methods in terms of top k recommendation precision. We also provide a theoretical framework for analyzing listwise methods highlighting the dependence on the number of users and items."
  }, {
    "heading": "Acknowledgements",
    "text": "JS is partially supported by NSF DMS-1712996. CJH acknowledge the support by NSF IIS-1719097, Google Cloud and Nvidia.\nSide Note by Liwei Wu: SQL in SQL-Rank is not only the abbreviation for Stochastically Queuing Listwise, but also name initials of Liwei’s girlfriend ShuQing Li. Special thanks for her support."
  }],
  "year": 2018,
  "references": [{
    "title": "Ranking on graph data",
    "authors": ["S. Agarwal"],
    "venue": "In Proceedings of the 23rd international conference on Machine learning,",
    "year": 2006
  }, {
    "title": "Learning to rank: from pairwise approach to listwise approach",
    "authors": ["Z. Cao", "T. Qin", "Liu", "T.-Y", "Tsai", "M.-F", "H. Li"],
    "venue": "In Proceedings of the 24th international conference on Machine learning,",
    "year": 2007
  }, {
    "title": "Efficient algorithms for ranking with svms",
    "authors": ["O. Chapelle", "S.S. Keerthi"],
    "venue": "Information Retrieval,",
    "year": 2010
  }, {
    "title": "An efficient boosting algorithm for combining preferences",
    "authors": ["Y. Freund", "R. Iyer", "R.E. Schapire", "Y. Singer"],
    "venue": "Journal of machine learning research,",
    "year": 2003
  }, {
    "title": "Recommending and evaluating choices in a virtual community of use",
    "authors": ["W. Hill", "L. Stead", "M. Rosenstein", "G. Furnas"],
    "venue": "In Proceedings of the SIGCHI conference on Human factors in computing systems,",
    "year": 1995
  }, {
    "title": "Pu learning for matrix completion",
    "authors": ["Hsieh", "C.-J", "N. Natarajan", "I. Dhillon"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2015
  }, {
    "title": "Collaborative filtering for implicit feedback datasets",
    "authors": ["Y. Hu", "Y. Koren", "C. Volinsky"],
    "venue": "In Data Mining,",
    "year": 2008
  }, {
    "title": "Listwise collaborative filtering",
    "authors": ["S. Huang", "S. Wang", "Liu", "T.-Y", "J. Ma", "Z. Chen", "J. Veijalainen"],
    "venue": "In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,",
    "year": 2015
  }, {
    "title": "Optimizing search engines using clickthrough data",
    "authors": ["T. Joachims"],
    "venue": "In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2002
  }, {
    "title": "Fism: factored item similarity models for top-n recommender systems",
    "authors": ["S. Kabbur", "X. Ning", "G. Karypis"],
    "venue": "In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2013
  }, {
    "title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
    "authors": ["Y. Koren"],
    "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2008
  }, {
    "title": "Generalization analysis of listwise learning-to-rank algorithms",
    "authors": ["Y. Lan", "Liu", "T.-Y", "Z. Ma", "H. Li"],
    "venue": "In Proceedings of the 26th Annual International Conference on Machine Learning,",
    "year": 2009
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["T. Mikolov", "I. Sutskever", "K. Chen", "G.S. Corrado", "J. Dean"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2013
  }, {
    "title": "Probabilistic matrix factorization",
    "authors": ["A. Mnih", "R.R. Salakhutdinov"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2008
  }, {
    "title": "An efficient algorithm for learning to rank from preference graphs",
    "authors": ["T. Pahikkala", "E. Tsivtsivadze", "A. Airola", "J. Järvinen", "J. Boberg"],
    "venue": "Machine Learning,",
    "year": 2009
  }, {
    "title": "Transfer learning for behavior ranking",
    "authors": ["W. Pan", "Q. Yang", "Y. Duan", "B. Tan", "Z. Ming"],
    "venue": "ACM Transactions on Intelligent Systems and Technology (TIST),",
    "year": 2017
  }, {
    "title": "Preference completion: Large-scale collaborative ranking from pairwise comparisons",
    "authors": ["D. Park", "J. Neeman", "J. Zhang", "S. Sanghavi", "I. Dhillon"],
    "venue": "In International Conference on Machine Learning,",
    "year": 1907
  }, {
    "title": "Bpr: Bayesian personalized ranking from implicit feedback",
    "authors": ["S. Rendle", "C. Freudenthaler", "Z. Gantner", "L. SchmidtThieme"],
    "venue": "In Proceedings of the twenty-fifth conference on uncertainty in artificial intelligence,",
    "year": 2009
  }, {
    "title": "Collaborative filtering recommender systems",
    "authors": ["J.B. Schafer", "D. Frankowski", "J. Herlocker", "S. Sen"],
    "venue": "In The adaptive web,",
    "year": 2007
  }, {
    "title": "List-wise learning to rank with matrix factorization for collaborative filtering",
    "authors": ["Y. Shi", "M. Larson", "A. Hanjalic"],
    "venue": "In Proceedings of the fourth ACM conference on Recommender systems,",
    "year": 2010
  }, {
    "title": "The generic chaining: upper and lower bounds of stochastic processes",
    "authors": ["M. Talagrand"],
    "venue": "Springer Science & Business Media,",
    "year": 2006
  }, {
    "title": "Cofi rank-maximum margin matrix factorization for collaborative ranking",
    "authors": ["M. Weimer", "A. Karatzoglou", "Q.V. Le", "A.J. Smola"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2008
  }, {
    "title": "Large-scale collaborative ranking in near-linear time",
    "authors": ["L. Wu", "Hsieh", "C.-J", "J. Sharpnack"],
    "venue": "In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,",
    "year": 2017
  }, {
    "title": "Collaborative denoising auto-encoders for top-n recommender systems",
    "authors": ["Y. Wu", "C. DuBois", "A.X. Zheng", "M. Ester"],
    "venue": "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,",
    "year": 2016
  }, {
    "title": "Listwise approach to learning to rank: theory and algorithm",
    "authors": ["F. Xia", "Liu", "T.-Y", "J. Wang", "W. Zhang", "H. Li"],
    "venue": "In Proceedings of the 25th international conference on Machine learning,",
    "year": 2008
  }, {
    "title": "Selection of negative samples for one-class matrix factorization",
    "authors": ["Yu", "H.-F", "M. Bilenko", "Lin", "C.-J"],
    "venue": "In Proceedings of the 2017 SIAM International Conference on Data Mining,",
    "year": 2017
  }],
  "id": "SP:37abd043be6045b27468b524c72b79e4d56ca047",
  "authors": [{
    "name": "Liwei Wu",
    "affiliations": []
  }, {
    "name": "Cho-Jui Hsieh",
    "affiliations": []
  }, {
    "name": "James Sharpnack",
    "affiliations": []
  }],
  "abstractText": "In this paper, we propose a listwise approach for constructing user-specific rankings in recommendation systems in a collaborative fashion. We contrast the listwise approach to previous pointwise and pairwise approaches, which are based on treating either each rating or each pairwise comparison as an independent instance respectively. By extending the work of (Cao et al., 2007), we cast listwise collaborative ranking as maximum likelihood under a permutation model which applies probability mass to permutations based on a low rank latent score matrix. We present a novel algorithm called SQL-Rank, which can accommodate ties and missing data and can run in linear time. We develop a theoretical framework for analyzing listwise ranking methods based on a novel representation theory for the permutation model. Applying this framework to collaborative ranking, we derive asymptotic statistical rates as the number of users and items grow together. We conclude by demonstrating that our SQL-Rank method often outperforms current state-of-the-art algorithms for implicit feedback such as WeightedMF and BPR and achieve favorable results when compared to explicit feedback algorithms such as matrix factorization and collaborative ranking.",
  "title": "SQL-Rank: A Listwise Approach to Collaborative Ranking"
}