{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 86–96, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "Brand preference analysis is an important topic in marketing. To induce a desired brand choice, a marketer must understand the main factors that influence a consumer’s brand preferences. This task is not easy since many factors may play a role in determining one’s brand preferences such as a consumer’s individual characteristics and preferences as well as the properties of a brand (e.g., its perceived quality). Among consumer related factors, demographics such as age, gender and income have been studied extensively in marketing research (Evans, 1959; Elliott, 1994; Lin, 2002). In this study, we focus on analyzing a set of consumer characteristics, which have received less attention but with these features, potentially we can build more precise and more accurate brand preference prediction models. Especially, we focus on three types of personal traits: personality,\npersonal values, and individual needs. Personality is a combination of characteristics or qualities that form an individual’s distinctive character; Personal values reflect what are important to different individuals and what motivate them in their decision making. Moreover, all people have certain needs that they want to satisfy. Thus, analyzing a comprehensive set of personal traits may help us understand the way we react to a particular brand.\nPreviously, the relationship between personal traits and brand preference/purchase decisions has drawn limited interest in marketing research due to the difficulty in obtaining consumer traits on a large scale. Among these efforts, Westfall found that differences exist between the personalities of the owners of convertible cars and those of standard & compact cars (Westfall, 1962). Similarly, the congruence of personal and brand personality was suggested to be a predictor of consumers’ brand preferences (Jamal and Goode, 2001; Dikcius et al., 2013). However, Shank & Langmeyer found personal traits less useful in building a strategic marketing tool (Shank and Langmeyer, 1994).\nGiven limited and sometimes conflicting results in previous research, in this study, we want to systematically investigate the relationship between a comprehensive set of personal traits and brand preferences. Specifically, we want to shed some light on (1) whether it is possible to use personal traits to predict consumer’s brand preferences? (2) whether it is feasible to use automatically inferred personal traits to build brand preference prediction systems that are scalable?\nOur study offers several significant contributions to the field of brand preference analysis:\n1. It is the first study that includes a comprehensive set of personal traits in brand preference analysis. Our current investigation includes personality (5 general categories and 30 sub-\n86\nfacets), personal values (5 dimensions) and individual needs (12 dimensions). In contrast, previous work typically only included a small number of personal traits (e.g., just 5 personality traits in (Hirsh et al., 2012)).\n2. It is the first study that uses personal traits obtained from both psychometric evaluation and social media analytics. The traits scores derived from psychometric tests are more accurate, which allow us to focus on the relationship between personal traits and brand preferences without the distractions from the mistakes introduced by an automated trait inference system. However, since psychometric tests require users to answer a large number of survey questions, without sufficient incentives, it is difficult to perform psychometric evaluation for a large number of people. In contrast, automatically derived trait features based on social media analytics require no user effort, and can be applied to millions of social media users.\n3. Our study involves diverse brand categories such as luxury car brands, retail brands, fast food brands, and household product brands (e.g., shampoo brands). With this data, we can investigate whether the relationship between personal traits and brand preferences varies across multiple product categories.\nSince the current study focuses on a comprehensive set of consumer characteristics and preferences which does not include many important brand properties such as perceived quality, risk, price and market presence, the main goal of our investigation is not to build a highly accurate brand preference prediction system. Instead, we want to first establish the feasibility of using derived trait features in building large-scale brand preference prediction systems. In the following, we first summarize some prior work, then describe the details of our experiments."
  }, {
    "heading": "2 Related Work",
    "text": "Predicting brand preference is a hard problem. A large number of factors may influence customers’ choices. Table 1 summarizes the factors that have been explored in previous research. Due to the scope, so far, there isn’t any prior investigation that is capable of incorporating all the factors in\na single model. Our study is one of the most comprehensive analyses so far. We not only investigate the influence of a large number of personal traits but also combine them with other known consumer-related features such as demographics and personal interests. We however have not included any brand-related properties such as perceived quality, risk and market presence because we do not have access to these data.\nIn recent social media studies, Wang et al. utilized customer reviews to predict coffee brand satisfaction (Wang et al., 2013). Also, there is a large-body of work trying to predict brand preferences based on one’s social media posts. Most of these work, however is performed in the context of sentiment analysis. In sentiment analysis, the main focus was to infer the sentiment associated with a post that mentions a particular brand/product. For example, Kim et al. collected 600,000 tweets that contain smartphone-related keywords and then performed sentiment analysis to infer whether a user’s attitude toward a particular mobile phone is positive or negative (Kim et al., 2012). Similarly, Mostafa analyzed the sentiment associated with 3,500+ tweets, which showed a generally positive consumer sentiment towards several famous brands (Mostafa, 2013). In contrast, our trait-based analysis is more general since it does not require users to explicitly express their opinions about a specific brand. For example, to infer whether an individual likes BMW or not, with sentiment analysis, a user has to ex-\nplicitly express his opinion towards BMW (e.g. Driving BMW is exciting!). In contrast, with our system, if we know that he likes to seek excitement (excitement, a needs dimension) and enjoys luxury products (Hedonism, a values dimension), we can guess he may like BMW although he has never explicitly mentioned BMW in his social media posts before. This difference is important since among the millions of products on social media, only a small number of products have been explicitly rated/mentioned by a particular user.\nIn summary, brand preferences may be influenced by many consumer and brand-related factors. Previous research has not paid sufficient attention to the influence of personal traits. In addition, most previous studies used psychometric surveys which are impractical in mass marketing since it is unlikely that a large number of customers would take the time to answer lengthy survey questions. In this study, we focus on investigating the feasibility of using automatically inferred personal traits in large-scale brand preference prediction. Next, we describe the dataset we collected to support this study."
  }, {
    "heading": "3 Data Collection",
    "text": "To investigate how personal traits are related to an individual’s brand preferences, we collected two datasets. In the first dataset, in addition to brand preferences, we also used standard psychometric tests to obtain clean and accurate personal trait measures. With this dataset, we can build and evaluate brand preference prediction models that use accurate personal traits. In contrast, the second dataset is used to build and evaluate brand preference prediction models that use trait features automatically inferred from social media. By comparing the models built from both datasets, we can answer questions such as: (1) whether personal traits are useful in predicting brand preferences (2) whether the traits automatically inferred from social media are useful in predicting brand preferences.\nTo collect these datasets, we designed two Amazon Mechanical Turk (MTurk) 1 tasks. All the MTurk participants are from the US since people outside the US may be unfamiliar with some of the brands. In the following, we describe the details of each MTurk task.\n1http://mturk.com/"
  }, {
    "heading": "3.1 Task 1: PTBP Survey",
    "text": "To collect the first dataset, we conducted a Personal Traits & Brand Preferences (PTBP) survey. Our trait survey includes five parts designed to measure three types of personal traits: personality, values and needs plus demographics and personal interests. Specifically, since the Big-Five model of personality is the most popular model of personality traits among personality psychologists, we adopted a standard survey for Big 5 personality. Here to limit the time MTurkers need to spend on the survey, instead of the full 300-item personality test, we used the shorter 50-item IPIP survey (Goldberg, 1993) which will score a user along 5 general personality dimensions: openness, conscientiousness, extraversion, agreeableness and neuroticism. However, with the shorter survey, we can not obtain the scores for 30 additional personality facets. Similarly, we used the standard 21-item PVQ survey to obtain the values defined in Schwartz’s theory of basic values (Schwartz, 2003). We also used the 35-item BNS survey to obtain the needs defined in Ford’s needs model (Ford, 2005; Yang and Li, 2013). In addition, we also included survey questions about a user’s demographics (e.g., gender, age, marital status, education and income) and personal interests (e.g,, automobile, sports, movies, travel) since they were used in some previous studies on brand preference (Pennacchiotti and Gurumurthy, 2011; Lin, 2002). Finally for each user, we collected her preferences for 22 brands in six categories. We have chosen well-known brands from diverse groups ranging from mobile phones to retail stores and fast food restaurants. The brands within each category are often competitors. For each brand in each category, we asked users to rate their preferences using a 5-point scale: Love, Like, Neutral, Dislike and Hate. A user can choose “n/a” if she has no knowledge of a particular brand. In total, we have collected the data from 1,207 MTurkers. To ensure the quality of the data collected from MTurk, we also included several validation ques-\ntions. The validation questions are pairs of questions that are paraphrases of each other. If the answers to a pair of validation questions are significantly different, the user data are excluded from our analysis. Our final dataset has 1,017 valid responses. Table 2 lists all the brands used in our study. All the measures used in our PTBP survey are listed in Table 3."
  }, {
    "heading": "3.2 Task 2: TAE Survey",
    "text": "The data collected in the Text Analytics Evaluation (TAE) survey are used to study the correlation between the trait features inferred from a person’s social media posts (e.g., tweets) and his brand preferences. Before the TAE survey, the participants were first asked to verify whether they had a Twitter account, if so, provide us their Twitter IDs. The users also agreed that we could access their tweets after the survey. Since our automated trait inference system relies on linguistic cues derived from a person’s Twitter posts, to ensure we can have a stable and reliable reading of one’s personal traits from his tweets, only active Twitter users with over 50 tweets (excluding retweets) can participate this survey. Since the majority of MTurkers are not active Twitter users, to increase the size of our data, in addition to MTurk, we also directly invited random Twitter users to participate in our TAE survey.\nIn addition to Twitter IDs, we also asked participants to provide their preferences for the same 22 brands as those used in the PTBP survey. Similarly, to filter out data by people who do not follow instructions, we also added two validation questions. In total, in the TAE survey, we have collected data from 659 participants, out of which 608 are valid. (550 valid ones are from MTurk,\nand 109 are from direct Twitter invitation)."
  }, {
    "heading": "3.3 Data Preparation",
    "text": "To obtain the trait scores for each user based on his answers in the PTBP survey, we first computed the raw trait scores based on the original survey guidelines. Since different surveys used different scales, we normalized the trait scores by using their rank percentile (e.g., top 1%, top 5%). As a result, all the normalized personal trait scores are between 0 and 1.\nMoreover, for each of the 20 topics of interest, we created a binary variable, indicating whether a participant is interested in a specific topic. In addition, each demographics feature such as age, education, income, was first mapped to an integer and then normalized into a number between 0 and 1.\nTo derive the trait scores for a user in the TAE survey, we crawled all the tweets in his Twitter account. Since personal traits are inferred from the text authored by a user, we discarded all the retweets. Due to the restrictions of the Twitter API, we can only crawl a maximum of 3,200 tweets for each user2.\nRecent research in psycholinguistics has shown it is possible to automatically infer personal traits from one’s linguistic footprints such as tweets and blogs (Yarkoni, 2010; Chen et al., 2014; Yang and Li, 2013). Here, we used a similar approach. Specifically, given input text authored by a user (e.g., tweets), our system computed the word counts of different psychologically-meaningful word categories defined in the Linguistic Inquiry and Word Count (LIWC) dictionary (Pennebaker et al., 2001). The LIWC counts were then used to build prediction models to correlate one’s word usage with his ground truth personal traits obtained via a prior psychometric survey. Then the built models were used to automatically infer a user’s personal traits. Based on a preliminary evaluation with 250 participants, more than 80 percent of them, scores for traits that were inferred for all three models correlated significantly with survey-based scores (p<0.05 and correlation coefficient between 0.05 and 0.8). Specifically, scores that were derived by our system correlated with survey-based scores for 80.8% of participants’ Big Five scores (p<0.05 and correlation coefficients between 0.05 and 0.75), for 86.6% of participants’\n2https://dev.twitter.com\nNeeds scores (p<0.05 and correlation coefficient between 0.05 and 0.8), and for 98.21% of participants’ Values scores (p<0.05 and correlation coefficients between 0.05 and 0.55). Moreover, the participants also rated on a five-point scale how well each derived characteristic matched their perceptions of themselves, and their ratings suggest that the inferred characteristics largely matched their self-perceptions. Specifically, means of all ratings were above 3 (“somewhat”) out of 5 (“perfect”): 3.4 (with a std. of 1.14) for Big Five, 3.39 (with a std. of 1.34) for Needs, and 3.13 (with a std. of 1.17) for Values.\nIn addition to personal traits, we also included topics of interest in the TAE dataset. They were automatically inferred from tweets using Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Since we need a large Twitter dataset to mine a list of general topics of interest, our current tweet collection is not sufficient. Therefore, we use a separate and much larger Twitter dataset from 10,000 randomly selected Twitter users. For each user, we crawled his tweets and then aggregated them into a big document, one for each Twitter user. As a result, we have 10,000 documents in our dataset. We then built an LDA topic model using this dataset. From the LDA inference results, we can infer a user’s topics of interest. Basically, for a given user u, LDA outputs a per user topic distribution Θu, which is a T -dimensional vector where T is the number of topics. The value θu,i is an indication of how likely Topic i is mentioned in user u’s tweets. The higher θu,i is, the more likely that user u is interested in topic i. Table 4 shows some of the topics automatically learned by LDA.\nAs a summary, table 5 shows all the features from the TAE survey, including those automatically inferred from tweets. For personality, following the same procedure defined in (Yarkoni, 2010), in addition to the Big five personality dimensions, our system is able to automatically extract 30 additional personality facets for the TAE\ndataset.\nIn the following section, we explain two analyses we performed on these datasets."
  }, {
    "heading": "4 Experiment 1",
    "text": "The main objective of this analysis is twofold: (1) to understand why people like or dislike a brand. (2) to build a computational model that automatically differentiates people who have positive, negative, or neutral opinions about a brand."
  }, {
    "heading": "4.1 Definition and Statistics",
    "text": "For each brand in this study, we define people who have positive opinions as those who gave a love or like rating in their brand preference surveys. Similarly, people who have negative opinions are those who gave a hate or dislike rating. People who gave a neutral rating are in the neutral category. Table 6 shows the number of instances in each of the three categories for each brand."
  }, {
    "heading": "4.2 Classification",
    "text": "In this experiment, we want to investigate whether it is possible to differentiate people who have (Positive, Negative, or Neutral) opinions towards different brands. For each brand, we built threeway classifiers using different classification algorithms including AdaBoost (Freund and Schapire, 1996), Decision Tree (C4.5) (Quinlan, 1993), Logistic Regression, Naive Bayes, Random Forest (Breiman, 2001), and SVM (Platt, 1999). In addition, for SVM, we have tested different kernels including polynomial kernel, pearson VII functionbased universal kernel (Üstün et al., 2006), and the radial basis function kernel. They are all implemented in the Weka machine learning toolkit (Hall\net al., 2009). Since our current goal is not to build the best brand preference prediction system, but to show the feasibility of building brand preference prediction systems that are scalable to millions of users, we ran all our classifiers using the default parameter settings from Weka (E.g. for Random Forest, we used 10 trees. The umber of features was set to log2(number of all features)+1.). We expect in the future, by optimizing model parameters, we can further improve the prediction power of each model.\nThe baseline classifiers classify every data instance into the majority class. Among all the classifiers we tested, we found that overall Naive Bayes has the best performance on both the PTBP and the TAE datasets. In the following, we report the average F-scores and AUC across 22 different brands using Naive Bayes with 10-fold cross validations. We created models that use all the user features and also those that use only trait features. Table 7 shows the results.\nOverall, all the classifiers performed significantly better than the baselines (p<0.05). Moreover, the models using all the features performed similarly to those using only trait features. The differences are not statistically significant. In addition, comparing the models trained on the PTBP\ndata with those on the TAE dataset, their performances are very similar, although the exact numbers are not directly comparable since they are from two different datasets.\nTo break down the results by product category, in Table 8, we list the per-brand classification results using only the trait features. The numbers in the parentheses show the F-score percentage increase from the baselines. In general, models with trait features did much better than the baselines on both datasets. But their effectiveness varied from one brand to another. For example, the trait features were very effective in predicting user preferences for Cadillac (50.8% increase on the PTBP dataset and 68.5% increase on the TAE dataset). In contrast, there was barely any improvement for Target. After inspecting the data, it seems this may be caused by the distribution of the data. For instance, the Target TAE data was very skewed. There were 430 people who had positive opinions about Target versus 18 people who had negative opinions. Since the baseline predicts “all people like Target”, which resulted in a pretty high Fscore (0.781), any further improvement over this baseline became more difficult.\nIn summary, for the task of differentiating people who have positive, negative, or neutral opinions towards different brands, automatically inferred traits can be a good proxy for the clean data derived from psychometric surveys. Models based on the trait features inferred from social media can perform similarly to those using a much larger set of clean features. This result is encouraging since\nit implies that it is possible to build large-scale brand preference prediction systems that do not require costly psychometric surveys."
  }, {
    "heading": "4.3 Top Features",
    "text": "In this study, we want to find out what are the most significant features that can be used to differentiate a brand’s likers from dislikers. The feature selection was conducted using logistic regression in SPSS3. Due to the page limit, we cannot list all the significant features for all the 22 brands. Here we only show the most important features in predicting people who like and dislike luxury car brands based on the PTBP dataset (Table 9). Based on the regression analysis, all the features are significantly associated with brand preferences ( p< 0.05). In this table, personal trait features are highlighted and followed by their types: P (Personalities), V (Values), and N (Needs). “+” or “-” means the features contribute positively or negatively to the model. As shown in the table, more than half of all the top features are trait features. For example, the No. one trait feature to differentiate BMW likers from dislikers is ideal, a trait associated with people who have a desire for perfection. For Cadillac, the top trait is hedonism, which is often associated with people who pursue pleasure and sensuous gratification in life. For Lexus, the most useful feature is self-expression, a trait often associated with people who have a desire to assert their own identifies. Other interesting findings include that females are less likely to be a fan of a luxury car brand than males. This is true across all three luxury car brands."
  }, {
    "heading": "5 Experiment 2",
    "text": "In the previous section, we demonstrated that given a particular brand such as Pepsi, it is possible to automatically differentiate the people who have positive, negative or neutral opinions. In\n3http://www-01.ibm.com/software/analytics/spss/\nthis section, we try to answer a different question: given a list of competing brands in the same product category, can we automatically rank a user’s preferences of these brands? For example, given popular beverage brands such as Pepsi and CocaCola, can we automatically predict whether a person will like Pepsi or Coca-Cola more?"
  }, {
    "heading": "5.1 Average Rank for Each Brand",
    "text": "For each user, we rank all the brands in each product category based on his preferences in the survey (e.g., 1 means most preferred brand). We aggregate the ranks from all the users and show the overall brand preference ranks for both datasets. As shown in table 10, the overall brand preference ranks for the PTBP and TAE surveys are highly correlated. Half of the product categories have exact the same preference ranks for all the products; The other half has only one slightly mis-matched rank in each product category. This suggests that the population participated in the PTBP and TAE survey has very similar brand preference distributions. In the future, it maybe interesting to investigate how this rank is related to different brands’ market share."
  }, {
    "heading": "5.2 Rank Correlation",
    "text": "To predict the rank of a product in each category, we trained a multi-class classifier to estimate how likely a user will like a brand. For example, for smart phone brands, since we have four competing brands, we train a 4-way classifier to estimate the likelihood a person likes iPhone, HTC, Nokia and Sony. We then output the preference rank based on the estimated likelihood. Higher likelihood means a stronger preference. We also built\ntwo types of models, one used all the user features, the other used traits only. We applied them to both the PTBP and the TAE datasets.\nSince our model and the ground truth both produce a ranked list for each product category, here we used rank correlation analysis to evaluate the quality of the predicted ranks. For each user and each product category, we computed the Spearman’s rank correlation coefficient ρ. If the coefficient ρ is 1, there is a perfect positive correlation between the predict rank and the ground truth (i.e. both produce identical ranks). If ρ is -1, there is a perfect negative correlation between the predicted rank and the ground truth (i.e., the rank predicted by the system is exactly the opposite of the ground truth). If ρ is 0 , then the predicted rank and the ground truth are randomly related. For each product category, we report the average ρ across all the users.\nWe use the overall rank data in Table 10 as our baseline. Specifically, for each product category, the baseline always ranks all its brands based on the average ranks defined in Table 10. For each user and each product category, we compute the ρ between the user’s ground truth rank in the survey and the rank produced by the baseline. We compute the average ρ across all the users and all the product categories to represent the baseline performance. For the PTBP data, the average ρ for the baseline is 0.193. For the TAE data, the average ρ is 0.060.\nThere are several main findings from these results. First, for all the product categories, the predicted ranks are all significantly and positively correlated with the ground truth (p < 0.05). Also, our models perform significantly better than the non-personalized ranks produced by the baseline. This result is important because it shows that there is a stable and statistically significant agreement between the predicted ranks and the ground truth and the personalized models with additional trait features perform significantly better than the non-\npersonalized baseline system (on PTBP, the average ρ of the model with personal traits is 0.305 versus 0.193 of the baseline. It is 0.403 versus 0.060 on the TAE dataset). Second, the performance on the TAE dataset is better than that on the PTBP dataset (e.g., the average ρ is 0.403 on TAE versus 0.305 on PTBP when only trait features were used). This may be due to the fact that in the TAE dataset, in addition to the Big 5 personality features, we also automatically extracted 30 personality sub-facets from tweets using the procedure described in (Yarkoni, 2010). These finergrained personality features are not available in the PTBP dataset. This result is encouraging since it suggests that using automatically inferred traits can predict brand preferences as well as if not better than the clean trait features that can be obtained only through costly psychometric evaluations. Finally, for our models, since the overall correlation coefficients ρ are between 0.3 and 0.4, the strength of these correlations is moderate. Thus, it may not be sufficient to build an accurate brand preference prediction system with only user features. Other features especially brand-related features as well as features that capture the compatibility of a brand and a user are needed."
  }, {
    "heading": "5.3 Top Features",
    "text": "We used multinomial logistic regression to find the most significant predicting features for each brand category. We show the feature ranks by significance for survey data in Table 12 and 13. Almost all of the top 10 features for each brand are significantly correlated with the ranks. Again, the personal traits features are highlighted and followed by their types: P (Personalities), V (Values), and N (Needs)."
  }, {
    "heading": "6 Conclusion and Future Direction",
    "text": "In this paper, we present a comprehensive analysis of the relationship between personal traits and brand preferences. Our study includes a large number of personal traits including personality, personal values and individual needs. We collect two datasets: one contains clean user features obtained from psychometric surveys; The other includes noisy users features derived automatically from social media posts. We investigate the influence of personal traits in two scenarios: (1) in differentiating people who have positive, negative, or neutral opinion about a brand, (2) in ranking\na user’s preference of competing brands within a product category. Our findings demonstrated that it is possible to use personal traits in predicting a user’s brand preferences. Moreover, we have also shown that automatically inferred user features are good proxies for the clean trait features that can be acquired only from costly psychometric surveys. This work may have significant impact on the field of brand preference analysis since this suggests that it is possible for businesses to build scalable marketing tools to identify and target potential customers on social media.\nBrand preference prediction is a hard problem. So far, we have focused primarily on user features. To further improve the prediction accuracy, in the future, we will extend our current study by incorporating new features such as the properties of a brand as well social influence from people in one’s social network."
  }],
  "year": 2015,
  "references": [{
    "title": "Dimensions of brand personality",
    "authors": ["Jennifer L Aaker."],
    "venue": "Journal of Marketing Research, pages 347– 356.",
    "year": 1997
  }, {
    "title": "An attitude model for the study of brand preference",
    "authors": ["Frank M Bass", "W Wayne Talarzyk."],
    "venue": "Journal of Marketing Research, pages 93–96.",
    "year": 1972
  }, {
    "title": "Latent dirichlet allocation",
    "authors": ["David M Blei", "Andrew Y Ng", "Michael I Jordan."],
    "venue": "the Journal of machine Learning research, 3:993–1022.",
    "year": 2003
  }, {
    "title": "Random forests",
    "authors": ["Leo Breiman."],
    "venue": "Machine Learning, 45(1):5–32.",
    "year": 2001
  }, {
    "title": "Crossing the threshold",
    "authors": ["Barbara Everitt Bryant", "Jaesung Cha."],
    "venue": "Marketing Research, 8(4):20–28.",
    "year": 1996
  }, {
    "title": "The moderating effect of perceived risk on consumers evaluations of product incongruity: Preference for the norm",
    "authors": ["Margaret C Campbell", "Ronald C Goodstein."],
    "venue": "Journal of Consumer Research, 28(3):439–449.",
    "year": 2001
  }, {
    "title": "Consumer preference formation and pioneering advantage",
    "authors": ["Gregory S Carpenter", "Kent Nakamoto."],
    "venue": "Journal of Marketing Research, pages 285– 298.",
    "year": 1989
  }, {
    "title": "The role of involvement in attention and comprehension processes",
    "authors": ["Richard L Celsi", "Jerry C Olson."],
    "venue": "Journal of Consumer Research, pages 210– 224.",
    "year": 1988
  }, {
    "title": "The chain of effects from brand trust and brand affect to brand performance: the role of brand loyalty",
    "authors": ["Arjun Chaudhuri", "Morris B Holbrook."],
    "venue": "Journal of Marketing, 65(2):81–93.",
    "year": 2001
  }, {
    "title": "Understanding individuals’ personal values from social media word use",
    "authors": ["Jilin Chen", "Gary Hsieh", "Jalal U Mahmud", "Jeffrey Nichols."],
    "venue": "Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing, pages 405–",
    "year": 2014
  }, {
    "title": "Selective recall and information use in consumer preferences",
    "authors": ["Carolyn L Costley", "Merrie Brucks."],
    "venue": "Journal of Consumer Research, pages 464–474.",
    "year": 1992
  }, {
    "title": "Imported versus usproduced apparel: Consumer views and buying patterns",
    "authors": ["Kitty G Dickerson."],
    "venue": "Home Economics Research Journal, 10(3):241–252.",
    "year": 1982
  }, {
    "title": "Congruence between brand and consumer personalities",
    "authors": ["Vytautas Dikcius", "Eleonora Seimiene", "Ermita Zaliene."],
    "venue": "Economic and Management, 18(3):526–536.",
    "year": 2013
  }, {
    "title": "Modeling a households choice among food store types",
    "authors": ["Diansheng Dong", "Hayden Stewart."],
    "venue": "American Journal of Agricultural Economics, 94(3):702–717.",
    "year": 2012
  }, {
    "title": "Exploring the symbolic meaning of brands",
    "authors": ["Richard Elliott."],
    "venue": "British Journal of Management, 5(s1):S13–S19.",
    "year": 1994
  }, {
    "title": "Psychological and objective factors in the prediction of brand choice ford versus chevrolet",
    "authors": ["Franklin B Evans."],
    "venue": "The Journal of Business, 32(4):340–369.",
    "year": 1959
  }, {
    "title": "Brands Laid Bare: Using Market Research for Evidence-based Brand Management",
    "authors": ["J Kevin Ford."],
    "venue": "John Wiley & Sons.",
    "year": 2005
  }, {
    "title": "Experiments with a new boosting algorithm",
    "authors": ["Yoav Freund", "Robert E Schapire."],
    "venue": "Thirteenth International Conference on Machine Learning, volume 96, pages 148–156.",
    "year": 1996
  }, {
    "title": "The structure of phenotypic personality traits",
    "authors": ["Lewis R Goldberg."],
    "venue": "American Psychologist, 48(1):26.",
    "year": 1993
  }, {
    "title": "Using promotional messages to manage the effects of brand and self-image on brand evaluations",
    "authors": ["Timothy R Graeff."],
    "venue": "Journal of Consumer Marketing, 13(3):4–18.",
    "year": 1996
  }, {
    "title": "Testing thirteen attitude scales for agreement and brand discrimination",
    "authors": ["Russell I Haley", "Peter B Case."],
    "venue": "The Journal of Marketing, pages 20–32.",
    "year": 1979
  }, {
    "title": "The weka data mining software: an update",
    "authors": ["Mark Hall", "Eibe Frank", "Geoffrey Holmes", "Bernhard Pfahringer", "Peter Reutemann", "Ian H Witten."],
    "venue": "ACM SIGKDD explorations newsletter, 11(1):10–",
    "year": 2009
  }, {
    "title": "Country-oforigin effects for uni-national and bi-national products",
    "authors": ["C Min Han", "Vern Terpstra."],
    "venue": "Journal of International Business Studies, pages 235–255.",
    "year": 1988
  }, {
    "title": "Customer repurchase intention: a general structural equation model",
    "authors": ["Phillip K Hellier", "Gus M Geursen", "Rodney A Carr", "John A Rickard."],
    "venue": "European Journal of Marketing, 37(11/12):1762–1800.",
    "year": 2003
  }, {
    "title": "Personalized persuasion tailoring persuasive appeals to recipients personality traits",
    "authors": ["Jacob B Hirsh", "Sonia K Kang", "Galen V Bodenhausen."],
    "venue": "Psychological Science, 23(6):578–581.",
    "year": 2012
  }, {
    "title": "Finding choice alternatives in memory: Probability models of brand name recall",
    "authors": ["J Wesley Hutchinson", "Kalyan Raman", "Murali K Mantrala."],
    "venue": "Journal of Marketing Research, pages 441–461.",
    "year": 1994
  }, {
    "title": "Consumers and brands: a study of the impact of self-image congruence on brand preference and satisfaction",
    "authors": ["Ahmad Jamal", "Mark MH Goode."],
    "venue": "Marketing Intelligence & Planning, 19(7):482–492.",
    "year": 2001
  }, {
    "title": "Customer preference analysis based on sns data",
    "authors": ["Jong Soo Kim", "Ming Hao Yang", "Young Jin Hwang", "Sang Hoon Jeon", "KY Kim", "IS Jung", "Chi-Hawn Choi", "Wan-Sup Cho", "JH Na."],
    "venue": "Cloud and Green Computing (CGC), 2012 Second International Con-",
    "year": 2012
  }, {
    "title": "Creating meaningful new brand names: A study of semantics and sound symbolism",
    "authors": ["Richard R Klink."],
    "venue": "Journal of Marketing Theory and Practice, pages 27–34.",
    "year": 2001
  }, {
    "title": "Personality characteristics of purchasers",
    "authors": ["Arthur Koponen."],
    "venue": "Journal of Advertising Research.",
    "year": 1960
  }, {
    "title": "Segmenting customer brand preference: demographic or psychographic",
    "authors": ["Chin-Feng Lin."],
    "venue": "Journal of Product & Brand Management, 11(4):249–268.",
    "year": 2002
  }, {
    "title": "Large-scale behavioral targeting with a social twist",
    "authors": ["Kun Liu", "Lei Tang."],
    "venue": "Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1815–1824. ACM.",
    "year": 2011
  }, {
    "title": "Satisfaction, repurchase intent, and repurchase behavior: investigating the moderating effect of customer characteristics",
    "authors": ["Vikas Mittal", "Wagner A Kamakura."],
    "venue": "Journal of Marketing Research, 38(1):131–142.",
    "year": 2001
  }, {
    "title": "More than words: Social networks text mining for consumer brand sentiments",
    "authors": ["Mohamed M Mostafa."],
    "venue": "Expert Systems with Applications, 40(10):4241–4251.",
    "year": 2013
  }, {
    "title": "How personality traits predict design-driven consumer choices",
    "authors": ["Nils Myszkowski", "Martin Storme."],
    "venue": "Europes Journal of Psychology, 8(4):641– 650.",
    "year": 2012
  }, {
    "title": "Sports event sponsorship for brand promotion",
    "authors": ["JAF Nicholls", "Sydney Roslow", "Henry A Laskey."],
    "venue": "Journal of Applied Business Research (JABR), 10(4):35–40.",
    "year": 2011
  }, {
    "title": "Comparative evaluation and the relationship between quality, satisfaction, and repurchase loyalty",
    "authors": ["Svein Ottar Olsen."],
    "venue": "Journal of the Academy of Marketing Science, 30(3):240–249.",
    "year": 2002
  }, {
    "title": "A comparative image analysis of domestic versus imported products",
    "authors": ["Nicolas Papadopoulos", "Louise A Heslop", "Gary Bamossy."],
    "venue": "International Journal of Research in Marketing, 7(4):283–294.",
    "year": 1990
  }, {
    "title": "Investigating topic models for social media user recommendation",
    "authors": ["Marco Pennacchiotti", "Siva Gurumurthy."],
    "venue": "Proceedings of the 20th international conference companion on World wide web, pages 101–102. ACM.",
    "year": 2011
  }, {
    "title": "Linguistic inquiry and word count: Liwc 2001",
    "authors": ["James W Pennebaker", "Martha E Francis", "Roger J Booth."],
    "venue": "Mahway: Lawrence Erlbaum Associates, 71:2001.",
    "year": 2001
  }, {
    "title": "An investigation of perceived risk at the brand level",
    "authors": ["J Paul Peter", "Michael J Ryan."],
    "venue": "Journal of Marketing Research, pages 184–188.",
    "year": 1976
  }, {
    "title": "Fast training of support vector machines using sequential minimal optimization",
    "authors": ["John C Platt."],
    "venue": "Advances in kernel methods, pages 185–208. MIT press.",
    "year": 1999
  }, {
    "title": "C4",
    "authors": ["John Ross Quinlan."],
    "venue": "5: programs for machine learning, volume 1. Morgan kaufmann.",
    "year": 1993
  }, {
    "title": "A proposal for measuring value orientations across nations",
    "authors": ["Shalom H Schwartz."],
    "venue": "Questionnaire Package of the European Social Survey, pages 259– 290.",
    "year": 2003
  }, {
    "title": "Consumer evaluations of store brands: effects of store image and product attributes",
    "authors": ["Janjaap Semeijn", "Allard CR Van Riel", "A Beatriz Ambrosini."],
    "venue": "Journal of Retailing and Consumer Services, 11(4):247–258.",
    "year": 2004
  }, {
    "title": "Does personality influence brand image",
    "authors": ["Matthew D Shank", "Lynn Langmeyer"],
    "venue": "The Journal of Psychology,",
    "year": 1994
  }, {
    "title": "The effect of product visibility upon the relationship between price and quality",
    "authors": ["Robert J Sutton", "Peter C Riesz."],
    "venue": "Zeitschrift für Verbraucherpolitik, 3(2):145–150.",
    "year": 1979
  }, {
    "title": "Mental accounting and consumer choice",
    "authors": ["Richard Thaler."],
    "venue": "Marketing Science, 4(3):199–214.",
    "year": 1985
  }, {
    "title": "Uncovering the relationships between aspirations and luxury brand preference",
    "authors": ["Yann Truong", "Rod McColl", "Philip J Kitchen."],
    "venue": "Journal of Product & Brand Management, 19(5):346–355.",
    "year": 2010
  }, {
    "title": "An experiment on the salience of country-of-origin in the era of global brands",
    "authors": ["David K Tse", "Gerald J Gorn."],
    "venue": "Journal of International Marketing, pages 57–76.",
    "year": 1993
  }, {
    "title": "Facilitating the application of support vector regression by using a universal pearson vii function based kernel",
    "authors": ["Bülent Üstün", "Willem J Melssen", "Lutgarde MC Buydens."],
    "venue": "Chemometrics and Intelligent Laboratory Systems, 81(1):29–40.",
    "year": 2006
  }, {
    "title": "This text has the scent of starbucks: A laplacian structured sparsity model for computational branding analytics",
    "authors": ["William Yang Wang", "Edward Lin", "John Kominek."],
    "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language",
    "year": 2013
  }, {
    "title": "Psychological factors in predicting product choice",
    "authors": ["Ralph Westfall."],
    "venue": "The Journal of Marketing, pages 34–40.",
    "year": 1962
  }, {
    "title": "Group influence and brand choice congruence",
    "authors": ["Robert E Witt", "Grady D Bruce."],
    "venue": "Journal of Marketing Research, pages 440–443.",
    "year": 1972
  }, {
    "title": "Social influence on consumer decisions: Motives, modes, and consequences",
    "authors": ["Wendy Wood", "Timothy Hayes."],
    "venue": "Journal of Consumer Psychology, 22(3):324–328. Huahai Yang and Yunyao Li. 2013. Identifying user",
    "year": 2012
  }, {
    "title": "Personality in 100,000 words: A large-scale analysis of personality and word use among bloggers",
    "authors": ["Tal Yarkoni."],
    "venue": "Journal of Research in Personality, 44(3):363–373.",
    "year": 2010
  }, {
    "title": "New brand names and inferential beliefs: Some insights on naming new products",
    "authors": ["George M Zinkhan", "Claude R Martin Jr."],
    "venue": "Journal of Business Research, 15(2):157–172.",
    "year": 1987
  }],
  "id": "SP:58cf9d678103ad64b8b83573dc23280a7787d8fa",
  "authors": [{
    "name": "Chao Yang",
    "affiliations": []
  }, {
    "name": "Shimei Pan",
    "affiliations": []
  }, {
    "name": "Jalal Mahmud",
    "affiliations": []
  }, {
    "name": "Huahai Yang",
    "affiliations": []
  }, {
    "name": "Padmini Srinivasan",
    "affiliations": []
  }],
  "abstractText": "In this paper, we present a comprehensive study of the relationship between an individual’s personal traits and his/her brand preferences. In our analysis, we included a large number of character traits such as personality, personal values and individual needs. These trait features were obtained from both a psychometric survey and automated social media analytics. We also included an extensive set of brand names from diverse product categories. From this analysis, we want to shed some light on (1) whether it is possible to use personal traits to infer an individual’s brand preferences (2) whether the trait features automatically inferred from social media are good proxies for the ground truth character traits in brand preference prediction.",
  "title": "Using Personal Traits For Brand Preference Prediction"
}