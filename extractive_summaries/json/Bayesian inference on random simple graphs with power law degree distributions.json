{
  "sections": [{
    "heading": "1. Introduction",
    "text": "In statistical applications, random graphs serve as Bayesian models for network data, that is, data consisting of objects and the observed linkages between them. Here we will focus on models for random simple graphs (that is, graphs with edges that take binary values), which are appropriate for applications where we observe either the presence or\n1Pohang University of Science and Technology, Pohang, South Korea 2University of Cambridge, Cambridge, UK 3Uber AI Labs, San Francisco, CA, USA 4Hong Kong University of Science and Technology, Hong Kong. Correspondence to: Juho Lee <stonecold@postech.ac.kr>, Seungjin Choi <seungjin@postech.ac.kr>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nabsence of links between objects in the network. For example, in social networks, nodes may represent individuals and a link (i.e., a nonzero value of an edge) could represent friendship. In a protein-protein interaction network, nodes may represent proteins and links could represent an observed physical or chemical interaction between proteins. Many domains involving network data (including social and protein-protein interaction networks) have been shown to exhibit power law, i.e., heavy-tailed, degree distributions (Barabási & Albert, 1999). Models for random graphs with power law degree distributions, also called scale-free random graphs, have therefore become one of the most actively studied areas of graph theory and network science (Bollobás et al., 2001; Albert & Barabási, 2002; Dorogovtsev & Mendes, 2002). In this paper we present a model for simple, scale-free random graphs, which we apply as a probabilistic model for several network datasets.\nThe model we present in this paper is a special case of the generalized random graph defined by Britton et al. (2006), and studied further by van der Hofstad (2016, Ch. 6), which outlines a framework for defining scale-free random graphs, but does not provide practical constructions, much less algorithms for performing statistical inference on the model components given data. Here we provide one such practical construction, along with a variational inference routine (Jordan et al., 1999) for efficient posterior inference. What’s more, our construction readily generalizes to include the structure of latent factors/clusters, as captured by the popular stochastic blockmodels (Nowicki & Snijders, 2001; Airoldi et al., 2009), while maintaining power law behavior in the graph.\nApplying Bayesian inference algorithms on network datasets is a challenge because likelihood computations, in general, scale with the number of edges in the graph, which is O(n2) in a network with n nodes. To help overcome these difficulties, we follow Hoffman et al. (2013) and develop a stochastic variational inference algorithm in which we approximate many likelihood computations on only subsets of the data, called minibatches. In the case of a network dataset, the minibatches are comprised of subsets of edges in the graph.\nWe apply this inference procedure to several network\ndatasets that are commonly observed to possess power law structure. Our experiments show that accurately capturing this power law structure improves performance on tasks predicting missing edges in the networks."
  }, {
    "heading": "2. Bayesian models for simple graphs",
    "text": "We represent a simple graph with n nodes by an adjacency matrix X := (Xi,j)i,j≤n, where Xi,j = 1 if there is a link between nodes i and j and Xi,j = 0 otherwise. Here we will only consider undirected graphs, in which case X represents a symmetric matrix. Furthermore, we do not allow self links, so the diagonal entries in X are meaningless. Most probabilistic models for simple graphs take the entries in X to be conditionally independent Bernoulli random variables; in particular, for every i, j ≤ n, let pi,j be the (random) probability of a link between nodes i and j, and let Xi,j | pi,j ∼ Bernoulli(pi,j). For every simple graph x := (xi,j)i,j≤n, we may then write the likelihood for the parameters p := (pi,j)i,j≥1 given X as\nP (X = x | p) = ∏\ni<j≤n\np xi,j i,j (1− pi,j) 1−xi,j , (1)\nwhere in our case it should be clear that the product is only over i, j ≤ n such that i < j and i 6= j. Random simple graphs date back to the Erdös–Rényi model, which may be reviewed, along with the more general theory of random graphs, in the text by Bollobás (1998). A random graph is called scale-free when the fraction of nodes in the network having k connections to other nodes behaves like k−τ for large values of k and some exponent τ > 1. More precisely, let Dn,i := ∑ j 6=iXi,j denote the (random) degree of node i, for every i ≤ n. Then X is (asymptotically) scale-free when, for every node i ≤ n,\nP{Dn,i = k} ∼ ck−τ , as n→∞, (2)\nfor some constant c > 0, a power law exponent τ > 1, and k sufficiently large. Here the notation A ∼ B denotes that the ratio A/B → 1 in the specified limit.\nIn order to model scale-free random graphs, Britton et al. (2006) suggested reparameterizing the model in Eq. (1) by a sequence of odds ratios ri,j := pi,j/(1 − pi,j), for every i < j ≤ n, which factorize as ri,j = UiUj , for some U := (U1, . . . , Un). The node-specific factors Ui are then modeled as Ui := Wi/ √ L for some sequence of nonnegative random variables W := (W1, . . . ,Wn) and where L := ∑n i=1Wi. In a series of results, (Britton et al., 2006, Thms. 3.1 & 3.2) and (van der Hofstad, 2016, Cor. 6.11 & Thm. 6.13) assert conditions on the random variablesW so that the limiting distribution of the degrees Dn,i is a mixed Poisson distribution. We will further detail these previous results in Section 4.\nThe distribution of Wi is interpreted here as a prior distribution for the degree Dn,i of node i, and if its distribution has heavy tails, then so will the distribution of Dn,i. Conversely, if the distribution of Wi does not have heavy tails, then neither will the distribution of the degrees Dn,i. We explore this alternative in Section 7.\nPrevious authors did not suggest any particular choices for the distribution of Wi, and so we elect to model them with BFRY random variables (Bertoin et al., 2006; Devroye & James, 2014), which have a heavy-tailed distribution and have recently played a role in the construction of several power law models in Bayesian statistics. Other heavy tailed distributions, such as those exhibited by log normal random variables, may also be used to model the Wi, and these options may be explored. One benefit of the BFRY distribution is that the thickness of its tails, and thus the power law behavior of the resulting graph, may be straightforwardly controlled by the discount parameter α."
  }, {
    "heading": "3. A generalized random graph",
    "text": "Consider the model from the previous section, parameterized by the odds ratios r := (ri,j : i < j ≤ n). Define\nG(r) := ∏\ni<j≤n\n(1 + ri,j) = ∏\ni<j≤n\n(1 + UiUj), (3)\nand note that the conditional likelihood in Eq. (1) may be rewritten in terms of the degrees Dn,i as\nP (X = x | r) = G(r)−1 ∏\ni<j≤n\n(UiUj) xi,j (4)\n= G(r)−1 ∏ i≤n U Dn,i i . (5)\nThe random simple graphX is called a generalized random graph, and we will henceforth write X | r ∼ GRG(n, r).\nLet α ∈ (0, 1), which we call the discount parameter, and let C1, C2, . . . be a sequence of positive values satisfying\nlim n→∞ Cn =∞ and lim n→∞ Cαn/n = 0. (6)\nLet the weights W1, . . . ,Wn be i.i.d. with density\nfn(w) ∝ w−α−1(1− e−w)1{0≤w≤Cn}. (7)\n(These are truncated BFRY random variables and will be discussed, along with a method for simulation, in Section 3.1.) Then the corresponding generalized random graph has an (asymptotic) power law degree distribution with power law exponent τ = 1 + α. We summarize this construction in the following theorem:\nTheorem 3.1. For every n, let W1, . . . ,Wn be i.i.d. with density fn and let (Dn,i)i≤n be the degrees of the generalized random graph X | r ∼ GRG(n, r), where\nr := (ri,j)i<j≤n is the sequence of odds ratios\nri,j = WiWj/L, i < j ≤ n, (8)\nand L := ∑ iWi. Then the following hold:\n1. For y 1, P{Dn,i = y} ∼ cy−1−α, for every node i and for some constant c, as n→∞. 2. For any m, the collection Dn,1, . . . , Dn,m are asymptotically independent, as n→∞.\nThis construction is closely related to the model described by van der Hofstad (2016, Thm. 6.13), and the proof of Theorem 3.1, which is provided in the supplementary material, follows analogously to the results by Britton et al. (2006, Thms. 3.1 & 3.2). Note that the power law exponent τ = 1 + α of the graph (as described by Eq. (2)) is determined by the parameter α ∈ (0, 1), and takes values in (1, 2). While power law exponents in (2, 3) has often been suggested in the past, it has more recently been shown that exponents within the (1, 2) range of our model is more appropriate in many domains (van der Hofstad, 2016, Ch. 1); (Crane & Dempsey, 2015)."
  }, {
    "heading": "3.1. Truncated BFRY random variables",
    "text": "A random variable W with density function fn given by Eq. (7) is a ratio of gamma and beta random variables, upper truncated at Cn. In particular let\ng ∼ gamma(1− α, 1) and b ∼ beta(α, 1), (9)\nbe independent, then the ratio Z := g/b has density p(z) ∝ z−α−1(1 − e−z) on (0,∞) (by construction), which is known as the Bertoin-Fujita-Roynette-Yor (BFRY) distribution (Bertoin et al., 2006; Devroye & James, 2014) and has been used in the construction of power law models in some recent applications in machine learning (James et al., 2015; Lee et al., 2016). The random variable W is then\nobtained by upper truncating the random variable Z at Cn. By our requirements on the sequence Cn (c.f. Eq. (6)), the density function fn of W approaches the density function of the BFRY random variable Z as n→∞, that is,\nlim n→∞\nfn(w) = α\nΓ(1− α) w−α−1(1− e−w), (10)\nwhich is heavy-tailed with infinite moments. It is straightforward to simulate these truncated BFRY random variables by repeatedly simulating g and b as in Eq. (9), accepting W := g/b as a sample when W < Cn.\nThe truncation of W at Cn produces a random variable with finite mean (for n < ∞), which is essential when constructing the generalized random graph and motivates the construction by van der Hofstad (2016, Thm. 6.13) alluded to earlier; see Section 4. For simplicity, one could take Cn = n, but the flexibility to set this parameter allows us to control other properties of the model. For example, in the next section we show how to vary this truncation level to control the sparsity of the graph."
  }, {
    "heading": "3.2. Controlling power law and sparsity in the graph",
    "text": "The discount parameter α ∈ (0, 1) controls the power law behavior of the graph, where decreasing α results in heavier tails in the degree distribution of the nodes in the graph. We can visualize this behavior by simulating graphs at different values of α. In Section 3, we set Cn = n and show the number of nodes of varying degrees in two simulated graphs, one with α = 0.2 and one with α = 0.8.\nThe degree distribution of the nodes in a graph of course affects the sparsity of the graph; to characterize this relationship, we can upper bound the expected number of links in the graph as follows:\nTheorem 3.2. Let En be the number of positive edges in the graph. Then E[En] = O(nC1−αn ).\nThe derivation of this result is provided in the supplementary material. While varying α can thus control the sparsity of the graph in addition to the power law behavior, we often want to decouple these behaviors, in which case we could parameterize the truncation level as Cn = nβ , for some sparsity parameter β > 0. Note the restriction α < min{1, 1/β} must be enforced in order to ensure that the conditions in Eq. (6) are satisfied. In this case, the bound in Theorem 3.2 becomes E[En] = O(n1+β(1−α)). The interpretation here is that increasing the upper bound Cn increases the likelihood that any particular node will link to others, but does not affect the (asymptotic) power law characterized by Theorem 3.1. In Section 3.2, we display the average number of positive edges in graphs that were simulated with fixed α = 0.3 and varying values of the sparsity parameter β. We note that in simulations, we encountered numerical issues in β > 1.4 regimes."
  }, {
    "heading": "4. Related work",
    "text": "Referring to the construction for generalized random graphs in Section 2, Britton et al. (2006, Thm. 3.1) shows that when the weights Wi have finite first and second moments, then the limiting distribution of the degree Dn,i is a mixed Poisson distribution. Most such distributions are light-tailed, however, in which case the degrees will not exhibit power law behavior. Britton et al. (2006, Thm. 3.2) therefore provides an alternative construction in which Wi may have infinite moments (so that it may exhibit a heavy tail), which results in a graph with a power law exponent of τ = 2. Finally, van der Hofstad (2016, Thm. 6.13) suggests yet another construction where the Wi are upper truncated to be of order o(n), where n is the number of nodes in the graph. The resulting random variables therefore have finite moments, yet exhibit a heavy tail, and the resulting random graph has a heavy tailed degree distribution with an arbitrary power law exponent. None of these results suggest a particular choice for the distribution of Wi, however, and so we have elected to use BFRY random variables (which are heavy tailed) that are upper truncated (so that they have finite moments). We note that the requirements on our truncation level (c.f. Eq. (6)) is less strict than the o(n) criterion of the van der Hofstad (2016, Thm. 6.13) construction.\nThe reader may consult the surveys by Bollobás & Riordan (2003); Albert & Barabási (2002); Dorogovtsev & Mendes (2002) for a background on scale-free random graphs, which is too large to review here. While these models are numerous, the following recent pieces of work in the Bayesian statistics and machine learning communities may be of interest to the reader: Caron & Fox (2014); Veitch & Roy (2015); Crane & Dempsey (2016); Cai & Broderick (2015). This collection of work discusses power law degree distributions, albeit in some cases in multi-graphs\n(i.e., graphs with nonnegative integer-valued edges) and in some cases the power law behavior is not characterized, only numerically observed in simulations. Many of these models can be seen to invoke their power law properties from the Pitman–Yor process (Pitman & Yor, 1997) (or related stochastic processes), where the extent of this behavior is controlled by the discount parameter α ∈ (0, 1) of the Pitman–Yor model, which, like the BFRY distribution, is related to a stable subordinator of index α."
  }, {
    "heading": "5. Incorporating latent factors",
    "text": "Latent factor models for relational data assume that a set of latent clusters underlie the network. For example, in a social network, the latent factors could be the unobserved hobbies or interests of individuals, which determine the observed friendships in the network. Bayesian models for latent factors in relational data are widespread, with some of the most popular based on stochastic blockmodels, where models for unsupervised learning, or clustering, are used to infer the latent factors (Nowicki & Snijders, 2001; Kemp et al., 2006; Airoldi et al., 2009; Miller et al., 2009). In this section, we present extensions of the generalized random graph that incorporate latent factors by scaling the odds ratios, while maintaining their power law degree distribution.\nWe will first provide a general result showing how to incorporate random scaling variables into the model, followed by specific examples that model these scaling variables with latent clusters. Let the odds ratios in the generalized random graph be given by ri,j = Ai,jUiUj for some Ai,j ≥ 0. Note that pi,j → 1 as Ai,j → ∞ and pi,j → 0 as Ai,j → 0, and so the edge-specific weight Ai,j simply scales the link probability. The random graph X | r ∼ GRG(n, r) then has the likelihood\nP (X = x | r) = G(r)−1 ∏\ni<j≤n\nA xi,j i,j ∏ i≤n U Dn,i i , (11)\nwhere the normalization term G(r) in Eq. (3) is now\nG(r) := ∏\ni<j≤n\n(1 +Ai,jUiUj) (12)\n= ∑ x ∏ i<j≤n A xi,j i,j ∏ i≤n U Dn,i i , (13)\nwhere the final equality follows simply because∑ x P (X = x | r) = 1. So constructed, the odds ratios r will influence the link probabilities in the generalized random graph, but will not affect the power law behavior of the degree distributions (under some assumptions on the random variables Ai,j). We summarize this construction in the following theorem, the proof for which is provided in the supplementary material:\nTheorem 5.1. Let (Wi)i≤n be i.i.d. random variables with density function fn(w) (in Eq. (7)). Let (Ai,j)i<j≤n be a collection of uniformly bounded random variables, where, for every i ≤ n, the collection (Ai,j)j>i is exchangeable. Let (Dn,i)i≤n be the degrees of the random graph X | r ∼ GRG(n, r), where r := (ri,j)i<j≤n is the sequence of odds ratios\nri,j = Ai,jWiWj/L, i < j ≤ n, (14) and where L := ∑ iWi. Then the degrees (Dn,i)i≤n satisfy statements (1) and (2) in Theorem 3.1.\nFor example, we may construct stochastic blockmodels, such as those introduced by Nowicki & Snijders (2001), as follows: For every i ≤ n, let Zi be a random variable taking values in {1, . . . ,K}, indicating which one (and only one) of K different factors to associate with node i. We want the latent cluster assignments for two nodes i and j to influence their link probability, which we could capture with a set of parameters θk,`, for k, ` = 1, . . . ,K. Then the parameter θZi,Zj could represent, or influence, the probability of a link between nodes i and j. Taking a Bayesian approach, the indicator variables Zi may be modeled with a Dirichlet-categorical conjugate distribution and their values may be inferred via probabilistic inference. An example of such a model could be summarized as follows: Let\nZi ∼ categorical(π), i ≤ n, (15) π ∼ Dirichlet(c/K), where c > 0, (16)\nθ`,k ∼ gamma(aθ, bθ), `, k ≤ K, (17) Ai,j = θZi,Zj , i < j ≤ n, (18)\nand construct the random graph X as in Theorem 5.1. Kemp et al. (2006) developed a nonparametric extension of a similar model that in a sense takes the limit K → ∞, allowing an appropriate number of clusters to be automatically inferred from the data. In this case, the marginal law of the indicator variables Z1, . . . , Zn is given by a Chinese restaurant process (with concentration parameter c).\nSeveral generalizations of the stochastic blockmodel allow the clusters underlying the network to overlap, leading to mixed membership stochastic blockmodels (Airoldi et al., 2009) or the related latent feature relational models (Miller et al., 2009). To capture this structure, we may generalize the indicators Zi to now represent a binary K-vector with entry Zi,k = 1 indicating node i is associated with cluster k, now called a feature, and Zi,k = 0 otherwise. One example of such a model could be summarized as follows:\nZi,k ∼ Bernoulli(pk), i ≤ n, k ≤ K, (19) pk ∼ beta(c, cγ/K), k ≤ K, and c, γ > 0, (20) θ`,k ∼ gamma(aθ, bθ), `, k = 1, 2, . . . , (21)\nAi,j = ∑ k,` θk,`Zi,kZj,`, i < j ≤ n, (22)\nand construct the random graph X as in Theorem 5.1. Miller et al. (2009) derived a nonparametric extension of this model that in a sense takes the limit K →∞, in which case the marginal law of the vectors Z1, . . . , Zn is that of an Indian buffet process (with mass parameter γ and concentration parameter c) (Ghahramani et al., 2007)."
  }, {
    "heading": "6. Variational inference",
    "text": "We derive a variational Bayesian inference algorithm (Jordan et al., 1999) that approximates the (optimal state of the) posterior distribution of the model components, given a network dataset. We approximate the required gradients in this procedure with stochastic gradient ascent (Bottou, 2010; Hoffman et al., 2013), computed on minibatches (i.e., subsets) of edges in the graph."
  }, {
    "heading": "6.1. The variational lower bound",
    "text": "In variational inference, we approximate the posterior distribution on the latent variables W := (W1, . . . ,Wn) with a variational distribution q(W ; θ), the parameters θ of which are fit to maximize the following lower bound on the marginal likelihood\nlog p(X) ≥ Eq(W ;θ) [ log\np(X |W ;α)p(W ;α) q(W ; θ)\n] , (23)\nwhere p(X | W ) is the likelihood function computed as in Eq. (5), and p(W ;α) is the prior on W represented by the density function in Eq. (7). The (non random) discount parameter α is inferred by corresponding gradient ascent updates maximizing the likelihood of the model, which is described in Section 6.4. We specify a mean field variational distribution q(W ; θ) =∏n i=1 q(Wi; θi). We considered several approximations for the marginals q(Wi; θi) including truncated BFRY and truncated gamma distributions, however, in our experiments we found that the following rectified gamma distribution performed well:\nWi =q min{W ′i , Cn}, (24) W ′i ∼ gamma(θi,shp, θi,rte), (25)\nindependently for every i ≤ n, where θi,shp and θi,rte denote the shape and rate parameters of the gamma distribution, respectively, and the notation =q emphasizes that this formula holds under the variational distribution q."
  }, {
    "heading": "6.2. Stochastic gradient ascent",
    "text": "We maximize the lower bound on the right hand side of Eq. (23) by stochastic gradient ascent, where on the t-th step of the algorithm, we make the following updates to the\nparameters in parallel\nθ (t+1) i ← θ (t) i + ρt∇θiEq(W ;θ(t))[L(X,W ; θ (t))], (26)\nfor i ≤ n and some sequence (ρt)t≥1 of positive numbers satisfying the Robbins–Monro criterion (Robbins & Monro, 1951) ∑ t ρt =∞ and ∑ t ρ 2 t <∞, and where\nL(X,W ; θ) := log p(X,W ;α)− log q(W ; θ) (27)\n= ∑\n(i,j)∈E log p(Xi,j |W ) + n∑ i=1 log p(Wi;α)\n− n∑ i=1 log q(Wi; θi), (28)\nwhere E denotes the observed edges (both links and nonlinks) in the dataset. We cannot evaluate the expectation (with respect to the rectified gamma distributions q(W ; θ)) analytically, and so we elect to use a particular Monte Carlo approximation of this gradient detailed by Knowles (2015), which was developed for gamma variational distributions and easily applies to the rectified gamma case.\nBriefly, for every i ≤ n, create the collection of S Monte Carlo samples from the variational distribution as follows: Independently for s ≤ S, let z (s) i ∼ Uniform(0, 1), and set W (s) i = ψ(z (s) i ; θi), where ψ(z; θ) := min{F−1θ (z), Cn} and F −1 θ (x) is the inverse of the cumulative distribution function for a gamma random variable. For convenience, we recall that\nFa,b(x) = ∫ x 0 ba Γ(a) ta−1e−btdt. (29)\nFor every k ≤ n, the gradient with respect to the parameters θk is then approximated by\n∇θkEq(W ;θ)[L(X,W ; θ)]\n≈ 1 S ∑ s ∇WkL(X,W (s); θ)∇θkψ(z (s) k ; θk), (30)\nwhere W (s) := (W (s)1 , . . . ,W (s) n ). This estimator is unbiased and has low enough variance that often a single sample suffices for the approximation (Salimans & Knowles, 2013; Kingma & Welling, 2014). The gradient of ψ is nonzero only when {F−1θk (z (s) k ) < Cn}, in which case we may immediately obtain the partial derivative with respect to the rate parameter; in particular, we have\n∇θk,rteψ(z (s) k ; θk) =\n{ z (s) k\nθk,rte , if F−1θk (z (s) k ) < Cn,\n0, otherwise. (31)\nThe partial derivative with respect to the shape parameter ∇θk,shpψ(z (s) k ; θk) does not have a closed form solution and must be approximated. Different approximation routines are suggested by Knowles (2015) for different regimes of the shape parameter θk,shp, and we found these approximations to be accurate and efficient in our experiments."
  }, {
    "heading": "6.3. Minibatches of edges in the graph",
    "text": "Computing the n required gradients in Eq. (26) may be done in parallel, and this computation, whether performed analytically or with automatic differentiation methods, scales with the number of edges in the graph. This can be prohibitive for many network datasets, and we therefore introduce a further approximation where this gradient is evaluated on subsets (a.k.a. minibatches) of the dataset, a technique from stochastic gradient ascent (Bottou, 2010) adopted in the context of variational Bayesian inference by Hoffman et al. (2013). In the case of a network dataset, we may select minibatches that are subsets of the observed edges in the graph. In particular, write the gradient of Eq. (28) with respect to the variable Wk (which is required by Eq. (30)) as\n∇WkL(W (s); θ) = ∑\n(i,j)∈E\ng(i,j)(X,W (s); k), (32)\nwhere g(i,j)(X,W ; k) := ∇Wk [log p(Xi,j | W ) + |E|−1 log p(W ;α)− |E|−1 log q(W ; θ)] is the gradient that ignores all but one edge of the graph. We may therefore compute the unbiased estimate of this gradient\n∇WkL(W (s); θ) ≈ |E| |B| ∑ (i,j)∈B g(i,j)(X,W (s); k), (33)\non a minibatch B ⊆ E of the observed edges."
  }, {
    "heading": "6.4. Inference on the parameters α and β",
    "text": "Without good prior knowledge of how to set the discount parameter α and the sparsity parameter β controlling the power law and sparsity behaviors of the graph, respectively, we infer their values from the data. First consider the discount parameter, which we infer with gradient ascent. After every update to the latent variables W , we fix them to their mean under the distribution q, i.e., Ŵ := (Ŵ1, . . . , Ŵn) where Ŵi = Eq(Wi;θi)[Wi], and take a step in the direction of the gradient\n∇α log p(Ŵ ;α) = n∑ i=1 ∇α log p(Ŵi;α) (34)\n= n∑ i=1 [ −∇αZα,β Zα,β − log(Ŵi) ] , (35)\nwhich is straightforward to derive from the density function in Eq. (7), and where the normalization term\nZα,β := ∫ Cn 0 w−α−1(1− e−w) dw (36)\nis a function of α and β, if we let Cn = nβ as suggested in Section 3.2. We do not have a closed form solution for\nα = 0.3 BFRY -57323.19 ± 91.62 -57675.72 ± 31.71 Gamma -71341.90 ± 116.82 -71841.66 ± 47.38\nα = 0.5 BFRY -21077.62 ± 79.64 -21289.75 ± 34.23 Gamma -24430.38 ± 73.06 -24701.06 ± 11.31\nα = 0.7 BFRY -7894.67 ± 41.84 -8027.42 ± 51.08 Gamma -8511.48 ± 22.45 -8601.50 ± 15.42\nthis term when Cn < ∞, and, unfortunately, inference on model parameters where the likelihood is difficult to evaluate is a challenging problem; for example, see the approaches taken by Murray et al. (2006) on such problems, which those authors call doubly intractable distributions. Accurate inference for α is important in our model, because it controls the power law behavior of the graph. In our experiments, we approximate the gradient in Eq. (35) for (fixed β) by approximating Zα,β (via Eq. (36)) and ∇αZα,β = ∫ Cn 0 −w−α−1(1 − e−w) logw dw, with line integrals. In the Section 7, we demonstrate that this approximation works well in various regimes of α, with slight overestimation for moderate values.\nSimilar approaches to infer β may be derived with finite difference approximations; we did not find these approaches successful in our experiments, however, and so we instead select β by cross validation."
  }, {
    "heading": "7. Experiments",
    "text": "We first demonstrate how the inference procedure in Section 6.4 can correctly differentiate between various regimes\nof α. We ran an experiment where for each value α ∈ {0.1, 0.3, 0.5, 0.7}, we simulated 10 datasets from the model with n = 1, 000 nodes, while fixing β = 1.0. For each simulated dataset, we ran an instance of the inference routine with α randomly initialized. In Fig. 3, we show the trace plots of alpha during each instance of the inference routine. For comparison, the true values of α are also shown as horizontal dashed lines. We can see that the inference routine can correctly distinguish between these different regimes of α, with slight overestimation in the moderate α regime. Interestingly, despite random initializations of α ∈ (0, 1), the algorithm always immediately inflates α to around 0.9, and then slowly decreases this value during inference, regardless of what value of α generated the data.\nWe next demonstrate that accurately capturing power law structures in datasets will improve predictive performance. While fixing β = 1.0, we simulate three network datasets with 5,000 nodes from our model with discount parameters α = 0.3, 0.5, and 0.7, respectively, which therefore exhibit increasingly lighter-tailed degree distributions. The generated graphs have 117,300, 32,925, and 9,460 links, respectively. To establish a baseline model that does not exhibit power law degree distributions but is otherwise comparable to our model, we implement the generalized random graph where the node-specific weights are constructed from the gamma random variables Wi ∼ gamma(θ, 1), for some positive parameter θ, i.i.d. for every node i ≤ n. Note that the parameter θ controls the sparsity of the generated graph; larger values of θ imply denser graphs. It follows analogously to Theorem 5.1 that\nP{Dn,i = k} ∼ kθ−1\n2k+θ , (37)\nfor k 1, as n → ∞. This model therefore does not exhibit power law behavior, as desired. We refer to this model as “Gamma” and the power law graph model as “BFRY”.\nWe ran an experiment holding out 20% of the edges in the\nsimulated graphs as test sets, training the two models on the remaining 80% of the edges. We used a mini-batch size of 5,000 edges (note that the training dataset corresponds to almost 10 million observed edges). We ran each inference procedure for 20,000 steps of stochastic gradient ascent updates, using Adam (Kingma & Ba, 2015) to adjust the learning rates at each step. We repeated each experiment 5 times, each time holding out a different test set and using a different random initialization. Again, for this experiment we fixed β = 1. In Table 1 we report a mean loglikelihood metric for the test datasets, where the metric for each run is obtained by averaging the test log-likelihoods across the states for the last 4,000 steps of the inference procedure; the displayed intervals are at ±1 standard deviation about the metric, from across the 5 repeats. We also report a max log-likelihood metric, which simply records the maximum test log-likelihood across the last 4,000 steps of the inference procedure, instead of the average. The best performing method is highlighted in bold (which in each case was the BFRY model).\nIn each case, we see that the BFRY model achieves higher test log-likelihood metrics than the Gamma model, as expected, implying that accurately capturing a power law degree distribution improves predictive performance (when power law behavior is truly present in the network). In Table 3, we report the inferred values for α, which were reasonably accurate, though we see slight overestimation for some regimes, as seen in the demonstration earlier. For the baseline Gamma model, we optimized the hyperparameter θ using gradient ascent maximizing the evidence lower bound of the model (c.f. Eq. (23)), and the inferred values are also reported in Table 3.\nNext, we ran similar experiments on the following network datasets, each of which are expected to exhibit power law degree distributions:\n• ‘USTop500Airports’: 500 nodes, 2,980 links • ‘openflights’: 7,976 nodes, 15,243 links • ‘polblogs’: 1,490 nodes, 9,517 links • ‘Facebook107’: 1,034 nodes, 26,749 links\nWhere appropriate, we saved only the upper triangular parts of the adjacency matrices. The ‘USTop500Airports’ dataset contains the (undirected, unweighted) flight connections between the 500 busiest US airports. The similar,\nthough much larger, ‘openflights’ dataset contains the flight connections between non-US airports. Scale-free networks have been proposed for such traffic networks, detailed for these datasets by Colizza et al. (2007). The ‘polblogs’ dataset contains the links between political blogs (judged by hyperlinks between the front webpages of the blogs) in the period leading up to the 2004 US presidential election, which is observed to exhibit power law degree distributions by Adamic & Glance (2005). The ‘Facebook107’ dataset contains “friendships” between users of a Facebook app, collected by Leskovec & McAuley (2012); social networks are widely studied for their power law degree distributions.\nFor both the Gamma and BFRY models, we ran our variational inference procedure for 20,000 steps on each dataset. As before, we repeated the experiment 5 times for each network, each time holding out a different 20% of the edges in the network as a testing set. We selected the value of β from among the grid {0.6, 0.9, 1.0, 1.2, 1.4} with 5-fold cross validation on the training set. We set the minibatch size to be equal to the number of nodes in the graph; for example, we used minibatches of 1,490 edges for the polblog dataset. The evaluation metrics on the test datasets are summarized in Table 2, and the inferred hyperparameter values are reported in Table 3. We see that the BFRY model once again outperforms the Gamma baseline model, according to the test log-likelihood metrics.\nProbabilistic inference on α by the BFRY model provides some of the most interesting analyses here. With α ≈ 0.00 (underflowing our machine’s precision), the Facebook107 social network has the degree distribution with the heaviest tails, followed by the USTop500Airports traffic network with α ≈ 0.23, the polblog citation network with α ≈ 0.64, and the openflights network has the lightest tailed degree distribution with α ≈ 0.67."
  }, {
    "heading": "8. Future work",
    "text": "Future work could focus on implementing the latent factor modeling generalizations presented in Section 5, which are natural assumptions in many domains where networks are expected to exhibit power law degree distributions. Alternative approaches to inference on the sparsity parameter β should also be explored, since controlling the sparsity in the graph was important for good predictive performance."
  }, {
    "heading": "Acknowledgements",
    "text": "The authors thank Remco van der Hofstad for helpful advice and anonymous reviewers for helpful feedback. J. Lee and S. Choi were partly supported by an Institute for Information & Communications Technology Promotion (IITP) grant, funded by the Korean government (MSIP) (No.20140-00147, Basic Software Research in Human-level Lifelong Machine Learning (Machine Learning Center)) and Naver, Inc. C. Heaukulani undertook this work in part while a visiting researcher at the Hong Kong University of Science and Technology, who along with L. F. James was funded by grant rgc-hkust 601712 of the Hong Kong Special Administrative Region."
  }],
  "year": 2017,
  "references": [{
    "title": "The political blogosphere and the 2004 US election: divided they blog",
    "authors": ["L.A. Adamic", "N. Glance"],
    "venue": "In Proceedings of the 3rd international workshop on Link discovery,",
    "year": 2005
  }, {
    "title": "Mixed membership stochastic blockmodels",
    "authors": ["E.M. Airoldi", "D.M. Blei", "S.E. Fienberg", "E.P. Xing"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2009
  }, {
    "title": "Statistical mechanics of complex networks",
    "authors": ["R. Albert", "Barabási", "A-L"],
    "venue": "Reviews of modern physics,",
    "year": 2002
  }, {
    "title": "Emergence of scaling in random networks",
    "authors": ["A. Barabási", "R. Albert"],
    "venue": "Science, 286(5439):509–512,",
    "year": 1999
  }, {
    "title": "On a particular class of self-decomposable random variables: the durations of bessel excursions straddling independent exponential times",
    "authors": ["J. Bertoin", "T. Fujita", "B. Roynette", "M. Yor"],
    "venue": "Probability and Mathematical Statistics,",
    "year": 2006
  }, {
    "title": "Mathematical results on scale-free random graphs. Handbook of graphs and networks: from the genome to the internet",
    "authors": ["B. Bollobás", "O.M. Riordan"],
    "year": 2003
  }, {
    "title": "The degree sequence of a scale-free random graph process",
    "authors": ["B. Bollobás", "O. Riordan", "J. Spencer", "G. Tusnády"],
    "venue": "Random Structures & Algorithms,",
    "year": 2001
  }, {
    "title": "Large-scale machine learning with stochastic gradient descent",
    "authors": ["L. Bottou"],
    "venue": "In COMPSTAT,",
    "year": 2010
  }, {
    "title": "Generating simple random graphs with prescribed degree distribution",
    "authors": ["T. Britton", "M. Deijfen", "A. Martin-Löf"],
    "venue": "Journal of Statistical Physics,",
    "year": 2006
  }, {
    "title": "Completely random measures for modeling power laws in sparse graphs",
    "authors": ["D. Cai", "T. Broderick"],
    "venue": "In NIPS 2015 Workshop on Networks in the Social and Information Sciences,",
    "year": 2015
  }, {
    "title": "Sparse graphs using exchangeable random measures",
    "authors": ["F. Caron", "E.B. Fox"],
    "venue": "arXiv preprint arXiv:1401.1137,",
    "year": 2014
  }, {
    "title": "Reaction–diffusion processes and metapopulation models in heterogeneous networks",
    "authors": ["V. Colizza", "R. Pastor-Satorras", "A. Vespignani"],
    "venue": "Nature Physics,",
    "year": 2007
  }, {
    "title": "Atypical scaling behavior persists in real world interaction networks",
    "authors": ["H. Crane", "W. Dempsey"],
    "venue": "arXiv preprint arXiv:1509.08184,",
    "year": 2015
  }, {
    "title": "Edge exchangeable models for network data",
    "authors": ["H. Crane", "W. Dempsey"],
    "venue": "arXiv preprint arXiv:1603.04571,",
    "year": 2016
  }, {
    "title": "On simulation and properties of the stable law",
    "authors": ["L. Devroye", "L.F. James"],
    "venue": "Statistical methods & applications,",
    "year": 2014
  }, {
    "title": "Bayesian nonparametric latent feature models",
    "authors": ["Z. Ghahramani", "T.L. Griffiths", "P. Sollich"],
    "venue": "Bayesian Statistics,",
    "year": 2007
  }, {
    "title": "Stochastic variational inference",
    "authors": ["M.D. Hoffman", "D.M. Blei", "C. Wang", "J.W. Paisley"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2013
  }, {
    "title": "Scaled subordinators and generalizations of the Indian buffet process",
    "authors": ["L.F. James", "P. Orbanz", "Y.W. Teh"],
    "venue": "arXiv preprint arXiv:1510.07309,",
    "year": 2015
  }, {
    "title": "An introduction to variational methods for graphical models",
    "authors": ["M.I. Jordan", "Z. Ghahramani", "T.S. Jaakkola", "L.K. Saul"],
    "venue": "Machine learning,",
    "year": 1999
  }, {
    "title": "Learning systems of concepts with an infinite relational model",
    "authors": ["C. Kemp", "J.B. Tenenbaum", "T.L. Griffiths", "T. Yamada", "N. Ueda"],
    "venue": "In AAAI,",
    "year": 2006
  }, {
    "title": "Adam: a method for stochastic optimization",
    "authors": ["D.P. Kingma", "J. Ba"],
    "venue": "In ICLR,",
    "year": 2015
  }, {
    "title": "Auto-encoding variational Bayes",
    "authors": ["D.P. Kingma", "M. Welling"],
    "venue": "In ICLR,",
    "year": 2014
  }, {
    "title": "Stochastic gradient variational Bayes for gamma approximating distributions",
    "authors": ["D.A. Knowles"],
    "venue": "arXiv preprint arXiv:1509.01631,",
    "year": 2015
  }, {
    "title": "Finite-dimensional BFRY priors and variational Bayesian inference for power law models",
    "authors": ["J. Lee", "L.F. James", "S. Choi"],
    "venue": "In Advances In Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Learning to discover social circles in ego networks",
    "authors": ["J. Leskovec", "J.J. McAuley"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2012
  }, {
    "title": "Nonparametric latent feature models for link prediction",
    "authors": ["K. Miller", "M.I. Jordan", "T.L. Griffiths"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2009
  }, {
    "title": "Mcmc for doubly-intractable distributions",
    "authors": ["I. Murray", "Z. Ghahramani", "D.J.C. MacKay"],
    "venue": "In UAI,",
    "year": 2006
  }, {
    "title": "Estimation and prediction for stochastic blockstructures",
    "authors": ["K. Nowicki", "T.A.B. Snijders"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2001
  }, {
    "title": "The two-parameter Poisson– Dirichlet distribution derived from a stable subordinator",
    "authors": ["J. Pitman", "M. Yor"],
    "venue": "The Annals of Probability,",
    "year": 1997
  }, {
    "title": "A stochastic approximation method",
    "authors": ["H. Robbins", "S. Monro"],
    "venue": "The Annals of Mathematical Statistics,",
    "year": 1951
  }, {
    "title": "Fixed-form variational posterior approximation through stochastic linear regression",
    "authors": ["T. Salimans", "D.A. Knowles"],
    "venue": "Bayesian Analysis,",
    "year": 2013
  }, {
    "title": "Random graphs and complex networks: Volume 1. Cambridge Series in Statistical and Probabilistic Mathematics",
    "authors": ["R. van der Hofstad"],
    "year": 2016
  }, {
    "title": "The class of random graphs arising from exchangeable random measures",
    "authors": ["V. Veitch", "D.M. Roy"],
    "venue": "arXiv preprint arXiv:1512.03099,",
    "year": 2015
  }],
  "id": "SP:419c4685d6109c63789a269f5996946ea04623e5",
  "authors": [{
    "name": "Juho Lee",
    "affiliations": []
  }, {
    "name": "Creighton Heaukulani",
    "affiliations": []
  }, {
    "name": "Zoubin Ghahramani",
    "affiliations": []
  }, {
    "name": "Lancelot F. James",
    "affiliations": []
  }, {
    "name": "Seungjin Choi",
    "affiliations": []
  }],
  "abstractText": "We present a model for random simple graphs with power law (i.e., heavy-tailed) degree distributions. To attain this behavior, the edge probabilities in the graph are constructed from Bertoin–Fujita–Roynette–Yor (BFRY) random variables, which have been recently utilized in Bayesian statistics for the construction of power law models in several applications. Our construction readily extends to capture the structure of latent factors, similarly to stochastic blockmodels, while maintaining its power law degree distribution. The BFRY random variables are well approximated by gamma random variables in a variational Bayesian inference routine, which we apply to several network datasets for which power law degree distributions are a natural assumption. By learning the parameters of the BFRY distribution via probabilistic inference, we are able to automatically select the appropriate power law behavior from the data. In order to further scale our inference procedure, we adopt stochastic gradient ascent routines where the gradients are computed on minibatches (i.e., subsets) of the edges in the graph.",
  "title": "Bayesian inference on random simple graphs with power law degree distributions"
}