{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1277–1291 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n1277"
  }, {
    "heading": "1 Introduction",
    "text": "Many dependency parsers treat attachment decisions and syntactic relation labeling as two independent tasks, despite the fact that relation labels carry important subcategorization information. For example, the number and types of the syntactic arguments that a predicate may take is rather restricted for natural languages — it is not common for an English verb to have more than one syntactic subject or more than two objects.\nIn this work, we present a parsing approach that explicitly models subcategorization of (some) syntactic dependents as valency patterns (see\n1Our implementation is available at https:// github.com/tzshi/valency-parser-emnlp18\nFig. 1 for examples), and operationalize this notion as extracted supertags. An important distinction from prior work is that our definition of valency-pattern supertags is relativized to a userspecified subset of all possible syntactic relations (see §3). We train supertaggers that assign probabilities of potential valency patterns to each token, and leverages these probabilities during decoding to guide our parsers so that they favor more linguistically plausible output structures.\nWe mainly focus on two subsets of relations in our analysis, those involving core arguments and those that represent functional relations, and perform experiments over a collection of 53 treebanks in 41 languages from the Universal Dependencies dataset (UD; Nivre et al., 2017). Our valencyaware parsers improve upon strong baseline systems in terms of output linguistic validity, measured as the accuracy of the assigned valency patterns. They also have higher precision and F1 scores on the subsets of relations under analysis, suggesting a potentially controlled way to balance precision-recall trade-offs.\nWe further show that our approach is not limited to a particular treebank annotation style. We apply our method to parsing another grammar formalism, Tree Adjoining Grammar, where dependency and valency also play an important role in both theory and parser evaluation. Our parser reaches a new state-of-the-art LAS score of 92.59, with more than 0.6 core-argument F1-score improve-\nment over our strong baseline parser. Finally, we demonstrate the applicability of our valency analysis approach to other syntactic phenomena less associated with valency in its traditional linguistic sense. In a case study of PP attachment, we analyze the patterns of two syntactic relations commonly used in PP attachment, and include them in the joint decoding process. Precision of the parsers improves by an absolute 3.30% on these two relation types."
  }, {
    "heading": "2 Syntactic Dependencies and Valencies",
    "text": "According to Nivre (2005), the modern dependency grammar can be traced back to Tesnière (1959), with its roots reaching back several centuries before the Common Era. The theory is centered on the notion of dependency, an asymmetrical relation between words of a sentence. Tesnière distinguishes three node types when analyzing simple predicates: verb equivalents that describe actions and events, noun equivalents as the arguments of the events, and adverb equivalents for detailing the (temporal, spatial, etc.) circumstances. There are two types of relations: (1) verbs dominate nouns and adverbs through a dependency relation; (2) verbs and nouns are linked through a valency relation. Tesnière compares a verb to an atom: a verb can attract a certain number of arguments, just as the valency of an atom determines the number of bonds it can engage in (Ágel and Fischer, 2015). In many descriptive lexicographic works (Helbig and Schenkel, 1959; Herbst et al., 2004), valency is not limited to verbs, but also includes nouns and adjectives. For more on the linguistic theory, see Ágel et al. (2003, 2006).\nStrictly following the original notion of valency requires distinguishing between arguments and adjuncts, as well as obligatory and optional dependents. However, there is a lack of consensus as to how these categorizations may be distinguished (Tutunjian and Boland, 2008), and thus we adopt a more practical definition in this paper."
  }, {
    "heading": "3 Computational Representation",
    "text": "Formally, we fix a set of syntactic relations R, and define the valency pattern of a token wi with respect to R as the linearly-ordered2 sequence\n2Our approach, whose full description is in §5, can be adapted to cases where linear ordering is de-emphasized. The algorithm merely requires a distinction between left and right\na´j ¨ ¨ ¨ a´1 ˛ a1 ¨ ¨ ¨ ak: the ˛ symbol denotes the center word wi, and each al asserts the existence of a word w dominated by wi via relation al P R, wi\nalÝÑ w. For al and am, when l ă m, the syntactic dependent for al linearly precedes the syntactic dependent for am. As an example, consider the UD-annotated sentence in Fig. 1. The token says has a core-relation3 valency pattern nsubj ˛ ccomp, and like has the pattern nsubj ˛ xcomp. If we consider only functional relations, both like and swim have the pattern mark ˛.4 We sometimes employ the abbreviated notation αL ˛αR, where α indicates a sequence and the letters L and R distinguish left dependencies from right dependencies.\nWe make our definition of valency patterns dependent on choice of R not only because some dependency relations are more often obligatory and closer to the original theoretical definition of valency, but also because the utility of different types of syntactic relations can depend on the downstream task. For example, purely functional dependency labels are semantically vacuous, so they are often omitted in the semantic representations extracted from dependency trees for question answering (Reddy et al., 2016, 2017). There are also recent proposals for parser evaluation that downplay the importance of functional syntactic relations (Nivre and Fang, 2017).\ndependents. We choose to encode linearity since it appears that most languages empirically exhibit word order preferences even if they allow for relatively free word order.\n3UD core and functional relations are listed in Table 1. 4The (possibly counterintuitive) direction for that and to is a result of UD’s choice of a content-word-oriented design."
  }, {
    "heading": "4 Pilot Study: Sanity Checks",
    "text": "We consider two questions that need to be addressed at the outset:5\n1. How well do the extracted patterns generalize to unseen data?\n2. Do state-of-the-art parsers already capture the notion of valency implicitly, though they are not explicitly optimized for it?\nThe first question checks the feasibility of learning valency patterns from a limited amount of data; the second probes the potential for any valencyinformed parsing approach to improve over current state-of-the-art systems.\nTo answer these questions, we use the UD 2.0 dataset for the CoNLL 2017 shared task (Zeman et al., 2017) and the system outputs6 of the top five performing submissions (Dozat et al., 2017; Shi et al., 2017b; Björkelund et al., 2017; Che et al., 2017; Lim and Poibeau, 2017). Selection of treebanks is the same as in §6. We extract valency patterns relative to the set of 6 UD core arguments given in Table 1 because they are close to the original notion of valency and we hypothesize that these patterns should exhibit few variations. This is indeed the case: the average number of valency patterns we extract is 110.4 per training treebank, with Turkish (tr) having the fewest at 34, and Galician (gl) having the most at 298 patterns. We observe that in general, languages with higher degree of flexibility in word order tend to generate more patterns in the data, as our patterns encode linear word order information.\nNext, we extract valency patterns from the test set and compare them against those from the training set. On average, out of the 55.4 patterns observed in the gold-standard test sets, only 5.5, or 9.98%, are new and unseen with respect to training. In comparison, 36.2% of the word types appearing in the test sets are not seen during training. This suggests that the valency pattern space is relatively restricted, and the patterns extracted from training sets do generalize well to test sets.\nFinally, we consider the average number of valency patterns extracted from the top-performing\n5We actually performed these sanity checks after implementation and experiments of our approach, because we missed this idea and because it requires access to test sets that we abstained from looking at during model development.\n6Retrieved from https://lindat.mff.cuni.cz/ repository/xmlui/handle/11234/1-2424.\nsystem outputs and the number of those not observed in training.7 All 5 systems are remarkably “hallucinatory” in inventing valency relations, introducing 16.8 to 35.5 new valency patterns, significantly larger than the actual number of unseen patterns. Below we show an error committed by the state-of-the-art Dozat et al. (2017) parser (upper half) as compared to the gold-standard annotation (lower half), and we highlight the core argument valency relations of the verb bothers in bold. The system incorrectly predicts how come to be a clausal subject.\nHow come no one bothers to ask ...\nadvmod\ncsubj\nnsubj\nccomp\nadvmod\nfixed nsubj\nxcomp\nEach such non-existent new pattern implies at least some (potentially small) parsing error that can contribute to the degradation of downstream task performance."
  }, {
    "heading": "5 Valency-Aware Dependency Parsing",
    "text": ""
  }, {
    "heading": "5.1 Overview",
    "text": "Our model is based on the following probability factorization for a given sentence x “ w1, . . . , wn and parse tree y for x:\nP py|xq “ 1\nZx\nn ź i“1 P pvi|wiqP phi|wiqP pri|wi, hiq,\nwhere Zx is the normalization factor, vi is the valency pattern extracted for wi from y, hi is the index of the syntactic governor of wi, and ri is the syntactic relation label of the dependency relation between whi and wi. We first assume that we have a feature extractor that associates each token in the sentence wi with a contextualized feature vector wi, and explain how to calculate the factored probabilities (§5.2). Then we discuss decoding (§5.3) and training (§5.4). Our decoder can be viewed as a special-case implementation of headautomaton grammars (Alshawi, 1996; Eisner and Satta, 1999). Finally, we return to the issue of feature extraction (§5.5).\n7The CoNLL 2017 shared task is an end-to-end parsing task, so the participating systems do not have access to goldstandard tokenization, which is a potential explanation for the presented analysis. On the other hand, the conclusion still holds even if we restrict to system outputs with perfect or nearly perfect segmentations."
  }, {
    "heading": "5.2 Parameterization",
    "text": "We parameterize P pvi|wiq as a softmax distribution over all candidate valency patterns:\nP pvi|wiq 9 exppscoreVALvi pwiqq,\nwhere scoreVAL is a multi-layer perceptron (MLP). For each word wi, we generate a probability distribution over all potential syntactic heads in the sentence (Zhang et al., 2017). After we have selected the head of wi to be whi , we decide on the syntactic relation label based on another probability distribution. We use two softmax functions:\nP phi|wiq 9 exppscoreHEADpwhi ,wiqq, P pri|wi, hiq 9 exppscoreLABELri pwhi ,wiqq,\nwhere both scoreHEAD and scoreLABEL are parameterized by deep biaffine scoring functions (Dozat and Manning, 2017)."
  }, {
    "heading": "5.3 Decoding",
    "text": "For joint decoding, we adopt the Eisner’s (1996) algorithm annotated with valency patterns as the state information in Eisner and Satta (1999). The algorithm is depicted in Fig. 2. For each complete and incomplete span, visualized as triangles and trapezoids respectively, we annotate the head with its valency pattern. We adopt Earley’s (1970) notation of ‚ to outward-delimit the portion of a valency pattern, starting from the center word ˛, that has already been collected within the span. INIT generates a minimal complete span with hypothesized valency pattern; the ‚ is put adjacent to ˛.\nCOMB matches an incomplete span to a complete span with compatible valency pattern, yielding a complete analysis on the relevant side of ˛. LINK either advances the ‚ by attaching a syntactic dependent with the corresponding relation label, or attaches a dependent with a relation label irrelevant to the current valency analysis. This algorithm can be easily extended to cases where we analyze multiple subsets of valency relations simultaneously: we just need to annotate each head with multiple layers of valency patterns, one for each subset.8\nThe time complexity of a naïve dynamic programming implementation is Op|V |2|α|n3q, where |V | is the number of valency patterns and |α| is the maximum length of a valency pattern. In practice, |V | is usually larger than n, making the algorithm prohibitively slow. We thus turn to A* parsing for a more practical solution.\nA* parsing We take inspiration from A* CCG parsing (Lewis and Steedman, 2014; Lewis et al., 2016; Yoshikawa et al., 2017). The idea (see Alg. 1) is to estimate the best compatible full parse for every chart item (in our case, complete and incomplete spans), and expand the chart based on the estimated priority scores. Our factorization of probability scores allows the following admissible heuristic: for each span, we can optimistically estimate its best full parse score by assigning to\n8To allow our model to account for unseen patterns in new data, we create a special wildcard valency pattern that allows dependents with arbitrary relations in the decoding process, and during training, treat valency patterns occurring fewer than 5 times as examples of the wildcard pattern.\nAlgorithm 1 Agenda-based best-first parsing algorithm, adapted from Lewis et al. (2016), Alg. 1. Helper Functions: INITpsq returns the set of spans generated by INIT. C.RULESppq returns the set of spans that can be derived by combining p with existing entries in C through COMB or LINK.\n1: procedure PARSE(s) 2: // Empty priority queue A 3: A Ð H 4: // Initialize A with minimal complete spans 5: for p P INITpsq do 6: A.INSERTppq; 7: // Empty chart C 8: C Ð H 9: while A ‰ H do\n10: p Ð A.POPMAXpq 11: // Found the global optimal solution 12: if p is a full parse then return p 13: else if p R C then 14: C.ADDppq 15: // Extend the chart 16: for p1 P C.RULESppq do 17: A.INSERTpp1q\nevery token outside the span the best possible valency pattern, best possible attachment and best relation label."
  }, {
    "heading": "5.4 Training",
    "text": "We train all components jointly and optimize for the cross entropy between our model prediction and the gold standard, or, equivalently, the sum of the log-probabilities for the three distributions comprising our factorization from §5.1. This can be thought of as an instance of multi-task learning (MTL; Caruana, 1997), which has been shown to be useful in parsing (Kasai et al., 2018). To further reduce error propagation, instead of using part-of-speech tags as features, we train a tagger jointly with our main parser components (Zhang and Weiss, 2016)."
  }, {
    "heading": "5.5 Feature Extraction",
    "text": "We adopt bi-directional long short-term memory networks (bi-LSTMs; Hochreiter and Schmidhuber, 1997) as our feature extractors, since they have proven successful in a variety of syntactic parsing tasks (Kiperwasser and Goldberg, 2016; Cross and Huang, 2016; Stern et al., 2017; Shi et al., 2017a). As inputs to the bi-LSTMs,\nwe concatenate one pre-trained word embedding, one randomly-initialized word embedding, and the output of character-level LSTMs for capturing sub-token level information (Ballesteros et al., 2015). The bi-LSTM output vectors at each timestep are then assigned to each token as its contextualized representation wi."
  }, {
    "heading": "6 Experiments",
    "text": "Data and Evaluation Our main experiments are based on UD version 2.0, which was prepared for the CoNLL 2017 shared task (Zeman et al., 2017). We used 53 of the treebanks9 across 41 languages that have train and development splits given for the shared task. In contrast to the shared-task setting, where word and sentence segmentation are to be performed by the system, we directly use the testset gold segmentations in order to focus directly on parsing; but this does mean that the performance of our models cannot be directly compared to the officially-reported shared-task results. For evaluation, we report unlabeled and labeled attachment scores (UAS and LAS respectively). Further, we explicitly evaluate precision, recall and F1 scores (P/R/F) for the syntactic relations from Table 1, as well as valency pattern accuracies (VPA) involving those relations.\nImplementation Details We use three-layer biLSTMs with 500 hidden units (250 in each direction) for feature extraction. The valency analyzer uses a one-hidden-layer MLP with ReLU activation function (Nair and Hinton, 2010), while the head selector and labeler use 512- and 128- dimensional biaffine scoring functions respectively. Our models are randomly initialized (Glorot and Bengio, 2010) and optimized with AMSgrad (Reddi et al., 2018) with initial learning rate 0.002. We apply dropout (Srivastava et al., 2014) to our MLPs and variational dropout (Gal and Ghahramani, 2016) to our LSTMs with a keep rate of 0.67 during training.\nEfficiency Our A* parsers are generally reasonably efficient; for the rare (ă 1%) cases where the A* search does not finish within 500,000 chart expansion steps, we back off to a model without valency analysis. When analyzing three or more relation subsets, the initialization steps become pro-\n9We exclude the two large treebanks cs and ru_syntagrus due to experiment resource constraints. There are other Czech and Russian treebanks in our selected collection.\nhibitively slow due to the large number of valency pattern combinations. Thus, we limit the number of combinations for each token to the highestscoring 500.\nResults on UD We present our main experimental results on UD in Table 2. The baseline system does not leverage any valency information (we only train the head selectors and labelers, and use the original Eisner decoder). We compare the baseline to settings where we train the parsers jointly with our proposed valency analyzers, distinguishing the effect of using this information only at training (multi-task learning; MTL) vs. both at training and decoding.\nIncluding valency analysis into the training objective already provides a slight improvement in parsing performance, in line with the findings of Kasai et al. (2018). With our proposed joint decoding, there is a mild improvement to the overall UAS and LAS, and a higher boost to VPA. The output parse trees are now more precise in the analyzed valency relations: on core arguments, precision increases by as much as 4.56. As shown by Table 3, the performance gain of joint decoding varies across treebanks, ranging from an error reduction rate of over 30% (Dutch Lassy Small Treebank) on core argument relations to nearly 0% (Japanese). Overall, our approach exhibits a clearly positive impact on most of the treebanks in UD. We do not see performance correlating to language typology, although we do observe smaller error-reduction rates on treebanks with lower baseline performances, that is, on “harder” languages."
  }, {
    "heading": "7 Parsing Tree Adjoining Grammar",
    "text": "Dependency and valency relations also play an important role in formalisms other than dependency grammar. In this section, we apply our proposed valency analysis to Tree Adjoining Grammar (TAG; Joshi and Schabes, 1997), because TAG derivation trees, representing the process of inserting obligatory arguments and adjoining modifiers, can be treated as a dependency representation (Rambow and Joshi, 1997). We follow prior art and use Chen’s (2001) automatic conversion of the Penn Treebank (Marcus et al., 1993) into TAG derivation trees. The dataset annotation has labels 0, 1 and 2, corresponding to subject, direct object, and indirect object; we treat these as our core argument subset in valency anal-\nysis.10 Additionally, we also analyze CO (co-head for phrasal verbs) as a separate singleton subset. We leave out adj (adjuncts) in defining our valency patterns. We strictly follow the experiment protocol of previous work (Bangalore et al., 2009; Chung et al., 2016; Friedman et al., 2017; Kasai et al., 2017, 2018), and report the results in Table 4. The findings are consistent with our main experiments: MTL helps parsing performance, and joint decoding further improves on core argument F1 scores, reaching a new state-of-the-art result of 92.59 LAS. The precision recall trade-off is pronounced for the CO relation subset."
  }, {
    "heading": "8 Case Study on PP Attachment",
    "text": "Although valency information has traditionally been used to analyze complements or core arguments,11 in this section, we show the utility of our approach in analyzing other types of syntactic relations. We choose the long-standing problem of prepositional phrase (PP) attachment (Hindle and Rooth, 1993; Brill and Resnik, 1994; Collins and Brooks, 1995; de Kok et al., 2017), which is known to be a major source of parsing mistakes (Kummerfeld et al., 2012; Ng and Curran, 2015). In UD analysis, PPs usually have the labels obl or nmod with respect to their syntactic parents, whereas adpositions are attached via a case relation, which is included in the functional relation subset. Thus, we add another relation subset, obl and nmod, to our valency analysis.\nTable 5 presents the results for different combinations of valency relation subsets. We find that PP-attachment decisions are generally harder to make, compared with core and functional relations. Including them during training distracts other parsing objectives (compare Core + PP with only analyzing Core in §6). However, they do permit improvements on precision for PP attachment by 3.30, especially with our proposed joint decoding. This demonstrates the usage of our algorithm outside the traditional notions of valency — it can be a general method for training parsers to focus on specific subsets of syntactic relations.\n10We choose not to use the sparse labels 3 and 4, which encode additional complements.\n11There are also recent proposals to analyze valency without distinguishing complements and adjuncts (Čech et al., 2010)."
  }, {
    "heading": "9 Further Related Work",
    "text": "Supertagging Supertagging (Bangalore and Joshi, 2010) has been proposed for and used in parsing TAG (Bangalore and Joshi, 1999; Nasr and Rambow, 2004), CCG (Curran and Clark, 2003; Curran et al., 2006), and HPSG (Ninomiya et al., 2006; Blunsom and Baldwin, 2006). Within dependency parsing, supertags have also been explored in the literature, but prior work mostly treats them as additional features. Ambati et al. (2013, 2014) use CCG supertags to improve dependency parsing results, while Ouchi et al. (2014, 2016) leverage dependency-based supertags as features. Faleńska et al. (2015) compare supertagging to parser stacking, where they extract supertags from base parsers to provide additional features for stacked parsers, instead of having a supertagger as a separate component.\nConstrained Dependency Grammar Another line of research (Wang and Harper, 2004; Foth et al., 2006; Foth and Menzel, 2006; Bharati et al., 2002, 2009; Husain et al., 2011) utilizes supertags in dependency parsing within the framework of constraint dependency grammar (CDG; Maruyama, 1990; Heinecke et al., 1998). Constraints in CDG may be expressed in very general terms (and are usually hand-crafted for specific languages), so prior work in CDG involves a constraint solver that iteratively or greedily up-\ndate hypotheses without optimality guarantees. In contrast, our work focuses on a special form of constraints — the valency patterns of syntactic dependents within a subset of relations — and we provide an efficient A*-based exact decoding algorithm.\nValency in Parsing To the best of our knowledge, there have been few attempts to utilize lexical valency information or to improve specifically on core arguments in syntactic parsing apart from CDG. Øvrelid and Nivre (2007) target parsing core relations in Swedish with specificallydesigned features such as animacy and definiteness that are useful in argument realization. Jakubıček and Kovář (2013) leverage external lexicons of verb valency frames for reranking. Mirroshandel et al. (2012, 2013) and Mirroshandel and Nasr (2016) extract selectional constraints and subcategorization frames from large unannotated corpora, and enforce them through forest reranking. Our approach does not rely on external resources or lexicons, but directly extracts valency patterns from labeled dependency parse trees. Earlier works in this spirit include Collins (1997).\nSemantic Dependency Parsing and Semantic Role Labeling The notion of valency is also used to describe predicate-argument structures that are adopted in semantic dependency parsing and semantic role labeling (Surdeanu et al.,\n2008; Hajič et al., 2009; Oepen et al., 2014, 2015). While semantic frames clearly have patterns, previous work (Punyakanok et al., 2008; Flanigan et al., 2014; Täckström et al., 2015; Peng et al., 2017; He et al., 2017) incorporates several types of constraints, including uniqueness and determinism constraints that require that certain labels appear as arguments for a particular predicate only once. They perform inference through integer linear programming, which is usually solved approximately, and cannot easily encode linear ordering constraints for the arguments.\nA* parsing Best-first search uses a heuristic to expand the parsing chart instead of doing so exhaustively. It was first applied to PCFGs (Ratnaparkhi, 1997; Caraballo and Charniak, 1998; Sagae and Lavie, 2006), and then to dependency parsing (Sagae and Tsujii, 2007; Zhao et al., 2013; Vaswani and Sagae, 2016). Our probability factorization permits a simple yet effective A* heuristic. A* parsing was introduced for parsing PCFGs (Klein and Manning, 2003; Pauls and Klein, 2009), and has been widely used for grammar formalisms and parsers with large search spaces, for example CCG (Auli and Lopez, 2011) and TAG (Waszczuk et al., 2016, 2017). Our decoder is similar to the supertag and dependency factored A* CCG parser (Yoshikawa et al., 2017), which in turn builds upon the work of Lewis and Steedman (2014) and Lewis et al. (2016). Our model additionally adds syntactic relations into the probability factorizations."
  }, {
    "heading": "10 Conclusions",
    "text": "We have presented a probability factorization and decoding process that integrates valency patterns into the parsing process. The joint decoder favors syntactic analyses with higher valency-pattern supertagging probabilities. Experiments on a large set of languages from UD show that our parsers are more precise in the subset of syntactic relations chosen for valency analysis, in addition to enjoying the benefits gained from jointly training the parsers and supertaggers in a multi-task learning setting.\nOur method is not limited to a particular type of treebank annotation or a fixed subset of relations. We draw similar conclusions when we parse TAG derivation trees. Most interestingly, in a case study on PP attachment, we confirm the utility of our parsers in handling syntactic relations beyond the\ntraditional domain of valency. A key insight of this paper that departs from prior work on automatic extraction of supertags from dependency annotations is that our definition of valency patterns is relativized to a subset of syntactic relations. This definition is closer to the linguistic notion of valency and alleviates the data sparsity problems in that the number of extracted valency patterns is small. At the same time, the patterns generalize well, and empirically, they are effective in our proposed joint decoding process.\nOur findings point to a number of directions for future work. First, the choice of subsets of syntactic relations for valency analysis impacts the parsing performance in those categories. This may suggest a controllable way to address precisionrecall trade-offs targeting specific relation types. Second, we experimented with a few obvious subsets of relations; characterizing what subsets can be most improved with valency augmentation is an open question. Finally, our decoder builds upon projective dependency-tree decoding algorithms. In the future, we will explore the possibility of removing the projective constraint and the tree requirement, extending the applicability of valency patterns to other tasks such as semantic role labeling."
  }, {
    "heading": "Acknowledgments",
    "text": "We thank the three anonymous reviewers for their insightful comments, Jungo Kasai for assistance in setting up the TAG parsing experiments, and Xilun Chen, Jason Eisner, Jungo Kasai and Ana Smith for discussion and comments. We also thank CoNLL’17 shared task organizers and participants for publicizing system outputs. TS and LL were supported in part by a Google Focused Research Grant to Cornell University. LL was also supported in part by NSF grant SES-1741441. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation or other sponsors."
  }],
  "year": 2018,
  "references": [{
    "title": "Dependency grammar and valency theory",
    "authors": ["Vilmos Ágel", "Klaus Fischer."],
    "venue": "Bernd Heine and",
    "year": 2015
  }, {
    "title": "Head automata and bilingual tiling: Translation with minimal representations (invited talk)",
    "authors": ["Hiyan Alshawi."],
    "venue": "Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics, pages 167–176, Santa Cruz, California, USA.",
    "year": 1996
  }, {
    "title": "Using CCG categories to improve Hindi dependency parsing",
    "authors": ["Bharat Ram Ambati", "Tejaswini Deoskar", "Mark Steedman."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages",
    "year": 2013
  }, {
    "title": "Improving dependency parsers using Combinatory Categorial Grammar",
    "authors": ["Bharat Ram Ambati", "Tejaswini Deoskar", "Mark Steedman."],
    "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,",
    "year": 2014
  }, {
    "title": "Efficient CCG parsing: A* versus adaptive supertagging",
    "authors": ["Michael Auli", "Adam Lopez."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1577–1585, Portland,",
    "year": 2011
  }, {
    "title": "Improved transition-based parsing by modeling characters instead of words with LSTMs",
    "authors": ["Miguel Ballesteros", "Chris Dyer", "Noah A. Smith."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages",
    "year": 2015
  }, {
    "title": "MICA: A probabilistic dependency parser based on tree insertion grammars (application note)",
    "authors": ["Srinivas Bangalore", "Pierre Boullier", "Alexis Nasr", "Owen Rambow", "Benoît Sagot."],
    "venue": "Proceedings of Human Language Technologies: The 2009 Annual",
    "year": 2009
  }, {
    "title": "Supertagging: An approach to almost parsing",
    "authors": ["Srinivas Bangalore", "Aravind K. Joshi."],
    "venue": "Computational Linguistics., 25(2):237–265.",
    "year": 1999
  }, {
    "title": "Supertagging: Using Complex Lexical Descriptions in Natural Language Processing",
    "authors": ["Srinivas Bangalore", "Aravind K. Joshi."],
    "venue": "The MIT Press.",
    "year": 2010
  }, {
    "title": "Two stage constraint based hy",
    "authors": ["Akshar Bharati", "Samar Husain", "Dipti Misra", "Rajeev Sangal"],
    "year": 2009
  }, {
    "title": "A constraint based parser using integer programming",
    "authors": ["Akshar Bharati", "Rajeev Sangal", "T. Papi Reddy."],
    "venue": "Proceedings of the International Conference on Natural Language Processing.",
    "year": 2002
  }, {
    "title": "IMS at the CoNLL 2017 UD shared task: CRFs and perceptrons meet neural networks",
    "authors": ["Anders Björkelund", "Agnieszka Falenska", "Xiang Yu", "Jonas Kuhn."],
    "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to",
    "year": 2017
  }, {
    "title": "Multilingual deep lexical acquisition for HPSGs via supertagging",
    "authors": ["Phil Blunsom", "Timothy Baldwin."],
    "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 164–171, Sydney, Australia. Associ-",
    "year": 2006
  }, {
    "title": "A rule-based approach to prepositional phrase attachment disambiguation",
    "authors": ["Eric Brill", "Philip Resnik."],
    "venue": "Proceedings of the 15th Conference on Computational Linguistics – Volume 2, pages 1198– 1204, Kyoto, Japan. Association for Computational",
    "year": 1994
  }, {
    "title": "New figures of merit for best-first probabilistic chart parsing",
    "authors": ["Sharon A. Caraballo", "Eugene Charniak."],
    "venue": "Computational Linguistics, 24(2):275–298.",
    "year": 1998
  }, {
    "title": "Multitask learning",
    "authors": ["Rich Caruana."],
    "venue": "Machine Learning, 28(1):41–75.",
    "year": 1997
  }, {
    "title": "Full valency",
    "authors": ["Radek Čech", "Petr Pajas", "Ján Majčutek."],
    "venue": "Verb valency without distinguishing complements and adjuncts. Journal of Quantitative Linguistics, 17(4):291–302.",
    "year": 2010
  }, {
    "title": "The HIT-SCIR system for end-to-end parsing of Universal Dependencies",
    "authors": ["Wanxiang Che", "Jiang Guo", "Yuxuan Wang", "Bo Zheng", "Huaipeng Zhao", "Yang Liu", "Dechuan Teng", "Ting Liu."],
    "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Pars-",
    "year": 2017
  }, {
    "title": "Towards efficient statistical parsing using lexicalized grammatical information",
    "authors": ["John Chen."],
    "venue": "Ph.D. thesis, University of Delaware.",
    "year": 2001
  }, {
    "title": "Revisiting supertagging and parsing: How to use supertags in transition-based parsing",
    "authors": ["Wonchang Chung", "Suhas Siddhesh Mhatre", "Alexis Nasr", "Owen Rambow", "Srinivas Bangalore."],
    "venue": "Proceedings of the 12th International Workshop on Tree Adjoin-",
    "year": 2016
  }, {
    "title": "Three generative, lexicalised models for statistical parsing",
    "authors": ["Michael Collins."],
    "venue": "Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics, pages 16–23, Madrid, Spain. Association for Computational Linguistics.",
    "year": 1997
  }, {
    "title": "Prepositional phrase attachment through a backed-off model",
    "authors": ["Michael Collins", "James Brooks."],
    "venue": "Proceedings of the 3rd Workshop on Very Large Corpora, Cambridge, MA.",
    "year": 1995
  }, {
    "title": "Incremental parsing with minimal features using bi-directional LSTM",
    "authors": ["James Cross", "Liang Huang."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 32–37.",
    "year": 2016
  }, {
    "title": "Investigating GIS and smoothing for maximum entropy taggers",
    "authors": ["James R. Curran", "Stephen Clark."],
    "venue": "Proceedings of the Tenth Conference on European Chapter of the Association for Computational Linguistics – Volume 1, pages 91–98,",
    "year": 2003
  }, {
    "title": "Multi-tagging for lexicalized-grammar parsing",
    "authors": ["James R. Curran", "Stephen Clark", "David Vadas."],
    "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational",
    "year": 2006
  }, {
    "title": "Deep biaffine attention for neural dependency parsing",
    "authors": ["Timothy Dozat", "Christopher D. Manning."],
    "venue": "Proceedings of the 5th International Conference on Learning Representations.",
    "year": 2017
  }, {
    "title": "Stanford’s graph-based neural dependency parser at the CoNLL 2017 shared task",
    "authors": ["Timothy Dozat", "Peng Qi", "Christopher D. Manning."],
    "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies,",
    "year": 2017
  }, {
    "title": "An efficient context-free parsing algorithm",
    "authors": ["Jay Earley."],
    "venue": "Communations of the ACM, 13(2):94–102.",
    "year": 1970
  }, {
    "title": "Three new probabilistic models for dependency parsing: An exploration",
    "authors": ["Jason Eisner."],
    "venue": "Proceedings of the 16th International Conference on Computational Linguistics, pages 340–345.",
    "year": 1996
  }, {
    "title": "Efficient parsing for bilexical context-free grammars and head automaton grammars",
    "authors": ["Jason Eisner", "Giorgio Satta."],
    "venue": "Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 457–464, College Park, Mary-",
    "year": 1999
  }, {
    "title": "Stacking or supertagging for dependency parsing – what’s",
    "authors": ["Agnieszka Faleńska", "Anders Björkelund", "Özlem Çetinoğlu", "Wolfgang Seeker"],
    "year": 2015
  }, {
    "title": "A discriminative graph-based parser for the Abstract Meaning Representation",
    "authors": ["Jeffrey Flanigan", "Sam Thomson", "Jaime Carbonell", "Chris Dyer", "Noah A. Smith."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational",
    "year": 2014
  }, {
    "title": "Guiding a constraint dependency parser with supertags",
    "authors": ["Kilian A. Foth", "Tomas By", "Wolfgang Menzel."],
    "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computa-",
    "year": 2006
  }, {
    "title": "Hybrid parsing: Using probabilistic models as predictors for a symbolic parser",
    "authors": ["Kilian A. Foth", "Wolfgang Menzel."],
    "venue": "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for",
    "year": 2006
  }, {
    "title": "Linguistically rich vector representations of supertags for TAG parsing",
    "authors": ["Dan Friedman", "Jungo Kasai", "R. Thomas McCoy", "Robert Frank", "Forrest Davis", "Owen Rambow."],
    "venue": "Proceedings of the 13th International Workshop on Tree Adjoining",
    "year": 2017
  }, {
    "title": "A theoretically grounded application of dropout in recurrent neural networks",
    "authors": ["Yarin Gal", "Zoubin Ghahramani."],
    "venue": "Advances in Neural Information Processing Systems, pages 1019–1027.",
    "year": 2016
  }, {
    "title": "Understanding the difficulty of training deep feedforward neural networks",
    "authors": ["Xavier Glorot", "Yoshua Bengio."],
    "venue": "Proceedings of the 13th International Conference on Artificial Intelligence and Statistics, pages 249–256.",
    "year": 2010
  }, {
    "title": "Deep semantic role labeling",
    "authors": ["Luheng He", "Kenton Lee", "Mike Lewis", "Luke Zettlemoyer"],
    "year": 2017
  }, {
    "title": "Eliminative parsing with graded constraints",
    "authors": ["Johannes Heinecke", "Jürgen Kunze", "Wolfgang Menzel", "Ingo Schröder."],
    "venue": "Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on",
    "year": 1998
  }, {
    "title": "Wörterbuch zur Valenz und Distribution deutscher Verben",
    "authors": ["Gerhard Helbig", "Wolfgang Schenkel."],
    "venue": "Bibliographisches Institut, Leipzig.",
    "year": 1959
  }, {
    "title": "A Valency Dictionary of English: A Corpus-Based Analysis of the Complementation Patterns of English Verbs, Nouns and Adjectives, volume 40 of Topics in English Linguistics",
    "authors": ["Thomas Herbst", "David Heath", "Ian F. Roe", "Dieter Götz."],
    "venue": "De",
    "year": 2004
  }, {
    "title": "Structural ambiguity and lexical relations",
    "authors": ["Donald Hindle", "Mats Rooth."],
    "venue": "Computational Linguistics, 19(1):103–120.",
    "year": 1993
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural Computation, 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Linguistically rich graph based data driven parsing for Hindi",
    "authors": ["Samar Husain", "Raghu Pujitha Gade", "Rajeev Sangal."],
    "venue": "Proceedings of the Second Workshop on Statistical Parsing of Morphologically Rich Languages, pages 56–61, Dublin, Ireland.",
    "year": 2011
  }, {
    "title": "Enhancing Czech parsing with verb valency frames",
    "authors": ["Miloš Jakubıček", "Vojtěch Kovář."],
    "venue": "Proceedings of the 14th International Conference on Computational Linguistics and Intelligent Text Processing, pages 282–293, Samos, Greece. Springer.",
    "year": 2013
  }, {
    "title": "Treeadjoining grammars",
    "authors": ["Aravind K. Joshi", "Yves Schabes."],
    "venue": "Handbook of formal languages, Volume 3: Beyond Words, pages 69–124. Springer, New York.",
    "year": 1997
  }, {
    "title": "TAG parsing with neural networks and vector representations of supertags",
    "authors": ["Jungo Kasai", "Robert Frank", "R. Thomas McCoy", "Owen Rambow", "Alexis Nasr."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Process-",
    "year": 2017
  }, {
    "title": "End-to-end graphbased TAG parsing with neural networks",
    "authors": ["Jungo Kasai", "Robert Frank", "Pauli Xu", "William Merrill", "Owen Rambow."],
    "venue": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational",
    "year": 2018
  }, {
    "title": "Simple and accurate dependency parsing using bidirectional LSTM feature representations",
    "authors": ["Eliyahu Kiperwasser", "Yoav Goldberg."],
    "venue": "Transactions of the Association for Computational Linguistics, 4:313–327.",
    "year": 2016
  }, {
    "title": "A* parsing: Fast exact Viterbi parse selection",
    "authors": ["Dan Klein", "Christopher D. Manning."],
    "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology – Vol-",
    "year": 2003
  }, {
    "title": "2017. PP attachment: Where do we stand",
    "authors": ["Daniël de Kok", "Jianqiang Ma", "Corina Dima", "Erhard Hinrichs"],
    "venue": "In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume",
    "year": 2017
  }, {
    "title": "Parser showdown at the Wall Street Corral: An empirical investigation of error types in parser output",
    "authors": ["Jonathan K. Kummerfeld", "David Hall", "James R. Curran", "Dan Klein."],
    "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods",
    "year": 2012
  }, {
    "title": "LSTM CCG parsing",
    "authors": ["Mike Lewis", "Kenton Lee", "Luke Zettlemoyer."],
    "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 221–231, San Diego,",
    "year": 2016
  }, {
    "title": "A* CCG parsing with a supertag-factored model",
    "authors": ["Mike Lewis", "Mark Steedman."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 990– 1000, Doha, Qatar. Association for Computational",
    "year": 2014
  }, {
    "title": "A system for multilingual dependency parsing based on bidirectional LSTM feature representations",
    "authors": ["KyungTae Lim", "Thierry Poibeau."],
    "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependen-",
    "year": 2017
  }, {
    "title": "Building a large annotated corpus of English: The Penn Treebank",
    "authors": ["Mitchell Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz."],
    "venue": "Computational Linguistics, 19(2):313–330.",
    "year": 1993
  }, {
    "title": "Structural disambiguation with constraint propagation",
    "authors": ["Hiroshi Maruyama."],
    "venue": "Proceedings of the 28th Annual Meeting on Association for Computational Linguistics, pages 31–38, Pittsburgh, Pennsylvania. Association for Computational Linguistics.",
    "year": 1990
  }, {
    "title": "Integrating selectional constraints and subcategorization frames in a dependency parser",
    "authors": ["Seyed Abolghasem Mirroshandel", "Alexis Nasr."],
    "venue": "Computational Linguistics, 42(1):55–90.",
    "year": 2016
  }, {
    "title": "Semi-supervised dependency parsing using lexical affinities",
    "authors": ["Seyed Abolghasem Mirroshandel", "Alexis Nasr", "Joseph Le Roux."],
    "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
    "year": 2012
  }, {
    "title": "Enforcing subcategorization constraints in a parser using sub-parses recombining",
    "authors": ["Seyed Abolghasem Mirroshandel", "Alexis Nasr", "Benoît Sagot."],
    "venue": "Proceedings of the 2013 Conference of the North American Chapter of the Association for",
    "year": 2013
  }, {
    "title": "Rectified linear units improve restricted Boltzmann machines",
    "authors": ["Vinod Nair", "Geoffrey E. Hinton."],
    "venue": "Proceedings of the 27th International Conference on International Conference on Machine Learning, pages 807–814, Haifa, Israel.",
    "year": 2010
  }, {
    "title": "Supertagging and full parsing",
    "authors": ["Alexis Nasr", "Owen Rambow."],
    "venue": "Proceedings of the 7th International Workshop on Tree Adjoining Grammar and Related Formalisms, pages 56–63, Vancouver, Canada.",
    "year": 2004
  }, {
    "title": "Identifying cascading errors using constraints in dependency parsing",
    "authors": ["Dominick Ng", "James R. Curran."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natu-",
    "year": 2015
  }, {
    "title": "Extremely lexicalized models for accurate and fast HPSG parsing",
    "authors": ["Takashi Ninomiya", "Takuya Matsuzaki", "Yoshimasa Tsuruoka", "Yusuke Miyao", "Jun’ichi Tsujii"],
    "venue": "In Proceedings of the 2006 Conference on Empirical Methods in Natural Language",
    "year": 2006
  }, {
    "title": "Dependency grammar and dependency parsing",
    "authors": ["Joakim Nivre."],
    "venue": "Technical Report MSI 05133, Växjö University, School of Mathematics and Systems Engineering.",
    "year": 2005
  }, {
    "title": "Universal dependency evaluation",
    "authors": ["Joakim Nivre", "Chiao-Ting Fang."],
    "venue": "Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies, pages 86–95, Gothenburg, Sweden. Association for Computational Linguistics.",
    "year": 2017
  }, {
    "title": "SemEval 2015 task 18: Broad-coverage semantic dependency parsing",
    "authors": ["Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Silvie Cinkova", "Dan Flickinger", "Jan Hajic", "Zdenka Uresova."],
    "venue": "Proceedings of the 9th International Work-",
    "year": 2015
  }, {
    "title": "SemEval 2014 task 8: Broad-coverage semantic dependency parsing",
    "authors": ["Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Dan Flickinger", "Jan Hajic", "Angelina Ivanova", "Yi Zhang."],
    "venue": "Proceedings of the 8th International Workshop on",
    "year": 2014
  }, {
    "title": "Improving dependency parsers with supertags",
    "authors": ["Hiroki Ouchi", "Kevin Duh", "Yuji Matsumoto."],
    "venue": "Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, volume 2: Short Papers, pages 154–",
    "year": 2014
  }, {
    "title": "Transition-based dependency parsing exploiting supertags",
    "authors": ["Hiroki Ouchi", "Kevin Duh", "Hiroyuki Shindo", "Yuji Matsumoto."],
    "venue": "IEEE/ACM Transactions on Audio, Speech, and Language Processing, 24(11):2059–2068.",
    "year": 2016
  }, {
    "title": "When word order and part-of-speech tags are not enough – Swedish dependency parsing with rich linguistic features",
    "authors": ["Lilja Øvrelid", "Joakim Nivre."],
    "venue": "Proceedings of the International Conference on Recent Advances in Natural Language",
    "year": 2007
  }, {
    "title": "K-best A* parsing",
    "authors": ["Adam Pauls", "Dan Klein."],
    "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 958–966, Suntec, Singapore.",
    "year": 2009
  }, {
    "title": "Deep multitask learning for semantic dependency parsing",
    "authors": ["Hao Peng", "Sam Thomson", "Noah A. Smith."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2037–2048, Van-",
    "year": 2017
  }, {
    "title": "The importance of syntactic parsing and inference in semantic role labeling",
    "authors": ["Vasin Punyakanok", "Dan Roth", "Wen-tau Yih."],
    "venue": "Computational Linguistics, 34(2):257–287.",
    "year": 2008
  }, {
    "title": "A formal look at dependency grammars and phrase-structure grammars, with special consideration of word-order phenomena",
    "authors": ["Owen Rambow", "Aravind Joshi."],
    "venue": "volume 39, pages 167–190. John Benjamins, Amsterdam and Philadelphia.",
    "year": 1997
  }, {
    "title": "A linear observed time statistical parser based on maximum entropy models",
    "authors": ["Adwait Ratnaparkhi."],
    "venue": "Proceedings of the Second Conference on Empirical Methods in Natural Language Processing, pages 1–10, Providence, Rhode Island, USA.",
    "year": 1997
  }, {
    "title": "On the convergence of Adam and beyond",
    "authors": ["Sashank J. Reddi", "Satyen Kale", "Sanjiv Kumar."],
    "venue": "Proceedings of the 6th International Conference on Learning Representations.",
    "year": 2018
  }, {
    "title": "Transforming dependency structures to logical forms for semantic parsing",
    "authors": ["Siva Reddy", "Oscar Täckström", "Michael Collins", "Tom Kwiatkowski", "Dipanjan Das", "Mark Steedman", "Mirella Lapata."],
    "venue": "Transactions of the Association for Computational",
    "year": 2016
  }, {
    "title": "Universal semantic parsing",
    "authors": ["Siva Reddy", "Oscar Täckström", "Slav Petrov", "Mark Steedman", "Mirella Lapata."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 89–101, Copenhagen, Denmark.",
    "year": 2017
  }, {
    "title": "A best-first probabilistic shift-reduce parser",
    "authors": ["Kenji Sagae", "Alon Lavie."],
    "venue": "Proceedings of the COLING/ACL Main Conference Poster Sessions, pages 691–698, Sydney, Australia. Association for Computational Linguistics.",
    "year": 2006
  }, {
    "title": "Dependency parsing and domain adaptation with LR models and parser ensembles",
    "authors": ["Kenji Sagae", "Jun’ichi Tsujii"],
    "venue": "In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL",
    "year": 2007
  }, {
    "title": "Fast(er) exact decoding and global training for transition-based dependency parsing via a minimal feature set",
    "authors": ["Tianze Shi", "Liang Huang", "Lillian Lee."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Pro-",
    "year": 2017
  }, {
    "title": "Combining global models for parsing Universal Dependencies",
    "authors": ["Tianze Shi", "Felix G. Wu", "Xilun Chen", "Yao Cheng."],
    "venue": "Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies, pages 31–39, Van-",
    "year": 2017
  }, {
    "title": "Dropout: A simple way to prevent neural networks from overfitting",
    "authors": ["Nitish Srivastava", "Geoffrey E. Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."],
    "venue": "Journal of Machine Learning Research, 15:1929–1958.",
    "year": 2014
  }, {
    "title": "A minimal span-based neural constituency parser",
    "authors": ["Mitchell Stern", "Jacob Andreas", "Dan Klein."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 818–827, Vancouver, Canada.",
    "year": 2017
  }, {
    "title": "The CoNLL 2008 shared task on joint parsing of syntactic and semantic dependencies",
    "authors": ["Mihai Surdeanu", "Richard Johansson", "Adam Meyers", "Lluís Màrquez", "Joakim Nivre."],
    "venue": "CoNLL 2008:",
    "year": 2008
  }, {
    "title": "Efficient inference and structured learning for semantic role labeling",
    "authors": ["Oscar Täckström", "Kuzman Ganchev", "Dipanjan Das."],
    "venue": "Transactions of the Association for Computational Linguistics, 3:29–41.",
    "year": 2015
  }, {
    "title": "Éléments de Syntaxe Structurale",
    "authors": ["Lucien Tesnière."],
    "venue": "Librairie C. Klincksieck, Paris.",
    "year": 1959
  }, {
    "title": "Do we need a distinction between arguments and adjuncts? Evidence from psycholinguistic studies of comprehension",
    "authors": ["Damon Tutunjian", "Julie E. Boland."],
    "venue": "Language and Linguistics Compass, 2(4):631–646.",
    "year": 2008
  }, {
    "title": "Efficient structured inference for transition-based parsing with neural networks and error states",
    "authors": ["Ashish Vaswani", "Kenji Sagae."],
    "venue": "Transactions of the Association for Computational Linguistics, 4:183– 196.",
    "year": 2016
  }, {
    "title": "A statistical constraint dependency grammar (CDG) parser",
    "authors": ["Wen Wang", "Mary P. Harper."],
    "venue": "Proceedings of the Workshop on Incremental Parsing: Bringing Engineering and Cognition Together, pages 42–49, Barcelona, Spain. Association",
    "year": 2004
  }, {
    "title": "Promoting multiword expressions in A* TAG parsing",
    "authors": ["Jakub Waszczuk", "Agata Savary", "Yannick Parmentier."],
    "venue": "Proceedings of the 26th International Conference on Computational Linguistics: Technical Papers, pages 429–439, Osaka, Japan.",
    "year": 2016
  }, {
    "title": "Multiword expression-aware A* TAG parsing revisited",
    "authors": ["Jakub Waszczuk", "Agata Savary", "Yannick Parmentier."],
    "venue": "Proceedings of the 13th International Workshop on Tree Adjoining Grammars and Related Formalisms, pages 84–93, Umeå, Swe-",
    "year": 2017
  }, {
    "title": "A* CCG parsing with a supertag and dependency factored model",
    "authors": ["Masashi Yoshikawa", "Hiroshi Noji", "Yuji Matsumoto."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages",
    "year": 2017
  }, {
    "title": "Dependency parsing as head selection",
    "authors": ["Xingxing Zhang", "Jianpeng Cheng", "Mirella Lapata."],
    "venue": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 665–676,",
    "year": 2017
  }, {
    "title": "Stackpropagation: Improved representation learning for syntax",
    "authors": ["Yuan Zhang", "David Weiss."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1557–1566, Berlin,",
    "year": 2016
  }, {
    "title": "Optimal incremental parsing via best-first dynamic programming",
    "authors": ["Kai Zhao", "James Cross", "Liang Huang."],
    "venue": "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 758–768, Seattle, Washington, USA.",
    "year": 2013
  }],
  "id": "SP:17b3bbeacd8278d506fefd37f25a968ed4772918",
  "authors": [{
    "name": "Tianze Shi",
    "affiliations": []
  }, {
    "name": "Lillian Lee",
    "affiliations": []
  }],
  "abstractText": "We present a complete, automated, and efficient approach for utilizing valency analysis in making dependency parsing decisions. It includes extraction of valency patterns, a probabilistic model for tagging these patterns, and a joint decoding process that explicitly considers the number and types of each token’s syntactic dependents. On 53 treebanks representing 41 languages in the Universal Dependencies data, we find that incorporating valency information yields higher precision and F1 scores on the core arguments (subjects and complements) and functional relations (e.g., auxiliaries) that we employ for valency analysis. Precision on core arguments improves from 80.87 to 85.43. We further show that our approach can be applied to an ostensibly different formalism and dataset, Tree Adjoining Grammar as extracted from the Penn Treebank; there, we outperform the previous stateof-the-art labeled attachment score by 0.7. Finally, we explore the potential of extending valency patterns beyond their traditional domain by confirming their helpfulness in improving PP attachment decisions.1",
  "title": "Valency-Augmented Dependency Parsing"
}