{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Gaussian processes (GPs) are non-parametric models that can be used to address multi-class classification problems (Rasmussen & Williams, 2006). These models become more expressive as the number of data instances N grows. They are also very useful to introduce prior knowledge in the learning problem, as many properties of the model are specified by a covariance function. Moreover, GPs provide an estimate of the uncertainty in the predictions made which may be critical in some applications. Neverthe-\n*Equal contribution 1Universidad Autónoma de Madrid, Madrid, Spain. Correspondence to: Carlos Villacampa-Calvo <carlos.villacampa@uam.es>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nless, in spite of these advantages, GPs scale poorly to large datasets because their training cost is O(N3), where N is the number of instances. An additional challenge is that exact inference in these models is generally intractable and one has to resort to approximate methods in practice.\nTraditionally, GP classification has received more attention in the binary case than in the multi-class setting (Kuss & Rasmussen, 2005; Nickisch & Rasmussen, 2008). The reason is that approximate inference is more challenging in the multi-class case where there is one latent function per class. To this one has to add more complicated likelihood factors, which often have the form of softmax functions or intractable Gaussian integrals. In spite of these difficulties, there have been several works addressing multi-class GP classification (Williams & Barber, 1998; Kim & Ghahramani, 2006; Girolami & Rogers, 2006; Chai, 2012; Riihimäki et al., 2013). Nevertheless, most of the proposed methods do not scale well with the size of the training set.\nIn the literature there have been some efforts to scale up GPs. These techniques often introduce a set of M N inducing points whose location is learnt alongside with the other model hyper-parameters. The use of inducing points in the model can be understood as an approximate GP prior with a low-rank covariance structure (Quiñonero-Candela & Rasmussen, 2005). When inducing points are considered, the training cost can be reduced to O(NM2). This allows to address datasets with several thousands of instances, but not millions. The reason is the difficulty of estimating the model hyper-parameters, which is often done by maximizing an estimate of the log-marginal-likelihood. Because such an estimate does not involve a sum across the data instances, one cannot rely on efficient methods for optimization based on stochastic gradients and mini-batches.\nA notable exception is the work of (Hensman et al., 2015a) which uses variational inference to approximate the calculations. Such a method allows for stochastic optimization and can address datasets with millions of instances. In this work we propose an alternative based on expectation propagation (EP) (Minka, 2001) and recent advances on binary GP classification (Hernández-Lobato & HernándezLobato, 2016). The proposed approach also allows for efficient training using mini-batches. This leads to a training\ncost that is O(CM3), where C is the number of classes. An experimental comparison with the variational approach and related methods from the literature shows that the proposed approach has benefits both in terms of the training speed and the accuracy of the predictive distribution."
  }, {
    "heading": "2. Scalable Multi-class Classification",
    "text": "Here we describe multi-class Gaussian process classification and the proposed method. Such a method uses the expectation propagation algorithm whose original description is modified to be more efficient both in terms of memory and computational costs. For this, we consider stochastic gradients to update the hyper-parameters and an approximate likelihood that avoids one-dimensional quadratures."
  }, {
    "heading": "2.1. Multi-class Gaussian Process Classification",
    "text": "We consider a dataset of N instances in the form of a matrix of attributes X = (x1, . . . ,xN )T with labels y = (y1, . . . , yN )\nT, where yi ∈ {1, . . . , C} and C > 2 is the total number of different classes. The task of interest is to predict the class label of a new data instance x?.\nA typical approach in multi-class Gaussian process (GP) classification is to assume the following labeling rule for yi given xi: yi = arg maxk f\nk(xi), for k = 1, . . . , C, where each fk(·) is a non-linear latent function (Kim & Ghahramani, 2006). Define fk = (fk(x1), . . . , f k(xN )) T ∈ RN and fi = (f1(xi), . . . , f C(xi))\nT ∈ RC . The likelihood of f = (f1, . . . , fC)T ∈ RN×C , p(y|f) = ∏N i=1 p(yi|fi), is then a product of N factors of the form:\np(yi|fi) = ∏ k 6=yi Θ ( fyi(xi)− fk(xi) ) , (1)\nwhere Θ(·) is the Heaviside step function. This likelihood takes value one if f can explain the observed data and zero otherwise. Potential classification errors can be easily introduced in (1) by considering that each fk has been contaminated with Gaussian noise with variance σ2k. That is, fk(xi) = f̂ k(xi) + k i , where k i ∼ N (0, σ2k).\nIn multi-class GP classification a GP prior is assumed for each function fk(·) (Rasmussen & Williams, 2006). Namely, fk ∼ GP(0, c(·, ·; ξ)), where c(·, ·; ξk) is some covariance function with hyper-parameters ξk. Often these priors are assumed to be independent. That is, p(f) =∏C\nk=1 p(f k), where each p(fk) is a multivariate Gaussian distribution. The task of interest is to make inference about f and for that Bayes’ rule is used: p(f |y) = p(y|f)p(f)/p(y), where p(y) is a normalization constant (the marginal likelihood) which can be maximized to find good hyper-parameters ξk, for k = 1, . . . , C. However, because the likelihood in (1) is non-Gaussian, evaluating p(y)\nand p(f |y) is intractable. Thus, these computations must be approximated. Often, one computes a Gaussian approximation to p(f |y) (Kim & Ghahramani, 2006). This results in a non-parametric classifier with training cost O(N3), where N is the number of data instances.\nTo reduce the computational cost of the method described a typical approach is to consider a sparse representation for each GP. With this goal, one can introduce C datasets of M N inducting points Xk = (x1, . . . ,xkM )T, with associated values f k = (fk(xk1), . . . , f k(xkM )) T for k = 1, . . . , C (Snelson & Ghahramani, 2006; NaishGuzman & Holden, 2008). Given each X k the prior for\nfk is approximated as p(fk) = ∫ p(fk|fk)p(fk|Xk)dfk ≈∫\n[ ∏N\ni=1 p(f k i (xi)|f\nk )]p(f k|Xk)dfk = pFITC(fk|X k ), in\nwhich the conditional Gaussian distribution p(fk|fk) has been approximated by the factorizing distribution∏N\ni=1 p(f k i (xi)|f\nk ). This approximation is known as the\nfull independent training conditional (FITC) (QuiñoneroCandela & Rasmussen, 2005), and it leads to a Gaussian prior pFITC(fk|X k ) with a low-rank covariance matrix. This allows for approximate inference with costO(NM2). The inducing points {Xk}Ck=1 can be regarded as hyperparameters and can be learnt by maximizing the estimate of the marginal likelihood p(y)."
  }, {
    "heading": "2.2. Method Specification and Expectation Propagation",
    "text": "The formulation of the previous section is limited because the estimate of the log-marginal-likelihood log p(y) cannot be expressed as a sum across the data instances. This makes infeasible the use of efficient methods based on stochastic optimization for finding the model hyper-parameters.\nA recent work focusing on the binary case has shown that it is possible to obtain an estimate of log p(y) that involves a sum across the data instances if the values f k associated to the inducing points are not marginalized (HernándezLobato & Hernández-Lobato, 2016). We follow that work and consider the posterior approximation p(f |y) ≈∫ p(f |f)q(f)df , where f = (f1, . . . , fC)T, p(f |f) =∏C k=1 p(f k|fk), we have defined p(f) = ∏C k=1 p(f k|Xk), and q is a Gaussian approximation to p(f |y). This distribution q is obtained in three steps. First, we use on the exact posterior the FITC approximation:\np(f |y) = ∫ p(y|f)p(f |f)dfp(f)\np(y) ≈ ∫ p(y|f)pFITC(f |f)dfp(f)\np(y) = [ ∏N i=1 φi(f)]p(f)\np(y) , (2)\nwhere we have defined pFITC(f |f) = ∏N\ni=1 ∏C k=1 p(f k(xi)\n|fk) ≈ p(f |f) = ∏C\nk=1 p(f k|fk) and\nφi(f) = ∫ [ ∏ k 6=yi Θ ( fyi(xi)− fk(xi) ) ]\n× [ ∏C\nk=1 p(f k(xi)|f k )]dfi , (3)\nwith p(fk(xi)|f k ) = N (fk(xi)|mki , vki ), where\nmki = (k k\nxiX k) T(Kk X k X k) −1f k , (4)\nski = κ k xixi − (k k\nxiX k) T(Kk X k X k) −1kk xiX k . (5)\nIn the previous expressions N (·|µ, σ2) is the p.d.f. of a Gaussian with mean µ and variance σ2. Furthermore, kk\nxiX k\nis a vector with the covariances between fk(xi) and f k; Kk XkXk\nis a M ×M matrix with the cross covariances between fk; and, finally, κkxixi is the prior variance of f k(xi).\nA practical difficulty is that the integral in (3) is intractable. Although it can be evaluated using one-dimensional quadrature techniques (Hernández-Lobato et al., 2011), in this paper we follow a different approach. For that, we note that (3) is simply the probability that fyi(xi) > fk(xi) for k 6= yi, given f . Let fyii = fyi(xi) and fki = fk(xi). The second step consists in approximating (3) as follows:\np( ⋂ k 6=yi f yi > fk) =p(fyi > f1|S1)× p(fyi > f2|S2)×\n· · · × p(fyi > fyi−1|Syi−1)× p(f yi > fyi+1|Syi+1)× · · · ≈ ∏ k 6=yip(f yi > fk) = ∏ k 6=yi Φ(α k i ) , (6)\nwhere Sj = ⋂\nk/∈{1,...,j}∪{yi} f yi > fk, Φ(·) is the c.d.f. of a standard Gaussian and αki = (myii − m k i )/ √ syii + s k i , with myii , m k i , s yi i and s k i defined in (5). We have omitted in (6) the dependence on f to improve the readability. The quality of this approximation is supported by the good experimental results obtained in Section 4. When (6) is replaced in (2) we get an approximate posterior distribution in which we can evaluate all the likelihood factors:\np(f |y) ≈ [ ∏N i=1 ∏ k 6=yk φ k i (f)]p(f)\np(y) , (7)\nwhere we have defined φki (f) = Φ(α k i ).\nThe r.h.s. of (7) is intractable due to the non-Gaussian form of the likelihood factors. The third and last step uses expectation propagation (EP) (Minka, 2001) to get a Gaussian approximation q to (7). This approximation is obtained by replacing each φki with an approximate Gaussian factor φ̃ k i :\nφ̃ki (f) = s̃i,k exp { − 12 (f yi )TṼyii,kf yi + (f yi )Tm̃yii,k } ×\nexp { − 12 (f k )TṼi,kf k + (f k )Tm̃i,k } , (8)\nwhere Ṽyii,k = C 1,yi i,k υ yi i (υ yi i ) T, m̃yii,k = C 2,yi i,k υ yi i , Ṽi,k = C1i,kυ k i (υ k i ) T, m̃i,k = C2i,kυ k i , and we have defined υ k i = (kk xiX k ) T(Kk X k X k ) −1. In (8) C1,yii,k , C 2,yi i,k , C 1 i,k, C 2 i,k and s̃i,k are free parameters adjusted by EP. Because the precision matrices in (8) are one-rank (see the supplementary material for details), we only have to store in memory O(M) parameters for each φ̃ki . The posterior approximation q is obtained by replacing in (7) each exact factor φi,k by the corresponding approximate factor φ̃i,k. That is, q(f) = ∏N i=1 ∏ k 6=yi φ̃ k i (f)p(f)/Zq , where Zq is a normalization constant that approximates the marginal likelihood p(y). Because all the factors involved in the computation of q are Gaussian, and we assume independence among the latent functions of different classes in (8), q is a product of C multivariate Gaussians (on per class) on M dimensions.\nIn EP each φ̃ki is updated until convergence as follows: First, φki is removed from q by computing q\n\\i,k ∝ q/φ̃ki . Because the Gaussian family is closed under the product and division operations, q\\i,k is also Gaussian with parameters given by the equations in (Roweis, 1999). Then, the Kullback-Leibler divergence between Z−1i,k φ k i q \\i,k and q, i.e, KL[Z−1i,k φ k i q \\i,k|q], is minimized with respect to q, where Zi,k is the normalization constant of φki q \\i,k. This is done by matching the moments of Z−1i,k φ k i q \\i,k. These moments can be obtained from the derivatives of Zi,k with respect to the parameters of q\\i,k (Seeger, 2006). After updating q, the new approximate factor is φ̃i,k = Zi,kq/q\\i,k. We update all the approximate factors at the same time, and reconstruct q afterwards by computing the product of all the φ̃ki and the prior, as in (Hernández-Lobato et al., 2011).\nThe EP approximation to the marginal likelihood is the normalization constant of q, Zq . The log of its value is:\nlogZq = g(θ)− g(θprior) + ∑N\ni=1 ∑ k 6=yk log s̃i,k , (9)\nwhere log s̃i,k = logZi,k + g(θ\\i,k)− g(θ); θ, θ\\i,k, and θprior are the natural parameters of q, q\\i,k and the prior, respectively; and g(θ) is the log-normalizer of a multi-variate Gaussian distribution with natural parameters θ.\nIt is possible to show that if EP converges, the gradient of logZq w.r.t the parameters of each φ̃i,k is zero. Thus, the gradient of logZq w.r.t. a hyper-parameter ξkj of the k-th covariance function (including the inducing points) is:\n∂ logZq ∂ξkj = (ηT − ηTprior) ∂θprior ∂ξkj + N∑ i=1 ∑ k 6=yi logZi,k ∂ξkj , (10)\nwhere η and ηprior are the expected sufficient statistics under q and the prior, respectively. Importantly, only the direct dependency of logZi,k on ξkj has to be taken into account. See (Seeger, 2006). The dependency through θ\\i,k, i.e., the natural parameters of q\\i,k can be ignored.\nAfter obtaining q and finding the model hyper-parameters by maximizing logZq , one can get an approximate predictive distribution for the label y? of a new instance x?:\np(y?|x?,y) = ∫ p(y?|f?, f)q(f)dfdf? , (11)\nwhere we have defined f? = (f1(x?), . . . , fC(x?))T, and∫ p(y?|f?, f)df? has the same form as the likelihood factor in (3). The resulting integral in (11) is again intractable. However, it can be approximated using a one-dimensional quadrature. See the supplementary material.\nBecause some simplifications occur when computing the derivatives of logZq w.r.t the inducing points, the total training time of EP is O(NM2) while the total memory cost is O(NMC) (Snelson, 2007)."
  }, {
    "heading": "2.3. Scalable Expectation Propagation",
    "text": "Traditionally, for finding the model hyper-parameters with EP one re-runs EP until convergence (using the previous solution as the starting point), after each gradient ascent update of the hyper-parameters. The reason for this is that (10) is only true if EP has converged (i.e., the approximate factors do not change any more). This approach is particularly inefficient initially, when there are strong changes to the model hyper-parameters, and EP may require several iterations to converge. Recently, a more efficient method has been proposed in (Hernández-Lobato & HernándezLobato, 2016). In that work the authors suggest to update both the approximate factors and the model hyperparameters at the same time. Because we do not wait for EP to converge, one should ideally add to (10) extra terms to get the gradient. These terms account for the mismatch between the moments of Z−1i,k φ k i q \\i,k and q. However, according to (Hernández-Lobato & Hernández-Lobato, 2016) these extra terms can be ignored and one can simply use (10) for an inner update of the hyper-parameters.\nFigure 1 shows, for the Vehicle dataset from UCI repository (Lichman, 2013), the estimate of the marginal likelihood logZq with respect to the training time, for 250 updates of the hyper-parameters, and M = N/5. We compare three\nmethods: (i) re-running EP until convergence each time and using (10) to update the hyper-parameters (EP-outer); (ii) updating at the same time the approximate factors φ̃ki and the hyper-parameters with (10) (EP-inner-approx); and (iii) the same approach as the previous one, but using the exact gradient for the update instead of (10) (EP-inner-exact). All approaches successfully maximize logZq . However, the inner updates are more efficient as they do not wait until EP converges. Moreover, using the approximate gradient is faster (it is cheaper to compute), and it gives almost the same results as the exact gradient."
  }, {
    "heading": "2.3.1. STOCHASTIC EXPECTATION PROPAGATION",
    "text": "The memory cost of EP can be significantly reduced by a technique called stochastic EP (SEP) (Li et al., 2015). In SEP all the approximate factors φ̃ki are tied. This means that instead of storing their individual parameters, what is stored is their product, i.e., φ̃ = ∏N i=1 ∏ k 6=yk φ̃ k i . A consequence of this is that we no longer have direct access to their individual parameters. This only affects the computation of the cavity distribution q\\i,k which now is obtained in an approximate way q\\i,k ∝ q/φ̃ 1n , where n is the total number of factors and φ̃ 1 n approximates each individual factor. Thus, SEP reduces the memory costs of EP by a factor of n. All the other steps are carried out as in the original EP algorithm, including the computation of logZq and its gradients. Figure 2 shows the differences between EP and SEP on a toy example. When SEP is used in the proposed method, the memory cost is reduced to O(CM2)."
  }, {
    "heading": "2.3.2. TRAINING USING MINI-BATCHES",
    "text": "Both the estimate of the log-marginal-likelihood in (9) and its gradient in (10) contain a sum across the data instances. This allows to write an EP algorithm that processes mini-batches of data, as in (Hernández-Lobato & Hernández-Lobato, 2016). For this, the data are split in mini-batchesMj of size S N , where N is the number of instances. Given a mini-batch Mj , we process all the approximate factors corresponding to that mini-batch, i.e., {{φ̃ki }k 6=yi : (xi, yi) ∈ Mj}. Then, we update the model hyper-parameters using a stochastic approximation of (10): ∂ logZq ∂ξkj ≈ (ηT − ηTprior) ∂θprior ∂ξkj + ρ ∑ i∈Mj ∑ k 6=yi logZi,k ∂ξkj , (12)\nwhere ρ = N/|Mj |. We reconstruct q after each update of the approximate factors and each update of the hyper-\nparameters. When using mini-batches of data, we update more frequently q and the hyper-parameters. The consequence is that the training cost is O(CM3), assuming a constant number of updates until convergence. This training scheme can handle datasets with millions of instances."
  }, {
    "heading": "3. Related Work",
    "text": "The likelihood used in (1) was first considered for multiclass Gaussian process classification in (Kim & Ghahramani, 2006). That work considers full non-parametric GP priors, which lead to a training cost that is O(CN3). The consequence is that it can only address small classification problems. It is, however, straight forward to replace the non-parametric GP priors with the FITC approximate priors pFITC(fk|X k ) (Quiñonero-Candela & Rasmussen, 2005). These priors are obtained by marginalizing the latent variables f k associated to the inducing points X k , as indicated in Section 2.1. This allows to address datasets with a few thousand instances. This is precisely the approach followed in (Naish-Guzman & Holden, 2008) to address binary GP classification problems. We refer to such an approach as the generalized FITC approximation (GFITC). Nevertheless, such an approach cannot use stochastic optimization. The reason is that the estimate of the log-marginal-likelihood (needed for hyper-parameter estimation) does not contain a sum across the instances. Thus, GFITC cannot scale well to very large datasets. Nevertheless, unlike the proposed approach, it can run expectation propagation over the exact likelihood factors in (1). In GFITC we follow the traditional approach and run EP until convergence before updating the hyper-parameters.\nMulti-class GP classification for potentially huge datasets has also been considered in (Hensman et al., 2015b) using variational inference (VI). However, such an approach cannot use the likelihood in (1) since its logarithm is not well defined (note that it takes value zero for some values of fi). As an alternative, Hensman et al. (2015b) have considered the robust likelihood of (Hernández-Lobato et al., 2011):\np(yi|fi) = (1− ) ∏ k 6=yi Θ ( fyi(xi)− fk(xi) ) + C , (13)\nwhere is the probability of a labeling error (in that case, yi is chosen at random from the potential class labels). In (Hensman et al., 2015b) it is suggested to set = 10−3.\nWe now describe the VI approach in detail. Using (13) and the definitions of Section 2, we know that p(y|f) =∫ p(y|f)p(f |f)df . If we take the log and use Jensen’s inequality we get the bound log p(y|f) ≥ Ep(f |f)[log p(y|f)]. Consider now a Gaussian approximation q to p(f |y). Then,\nlog p(y) = ∫ q(f)p(y|f)p(f)/q(f)df ≥ Eq(f)[log p(y|f)]− KL[q(f)||p(f)] , (14)\nwhere we have used Jensen’s inequality and KL is the Kull-\nback Leibler divergence. If we use the first bound we get\nlog p(y) ≥ Eq(f)[Ep(f |f)[log p(y|f)]]KL[q(f)||p(f)]\n≥ Eq(f)[log p(y|f)]− KL[q(f)||p(f)] ≥ ∑N i=1Eq(fi)[log p(yi|fi)]− KL[q(f)||p(f)] , (15)\nwhere q(f) = ∫ p(f |f)q(f)df and the corresponding marginal over fi = (f1(xi), . . . , fC(xi))T is q(fi) =∏C k=1N (fk(xi)|m̂ki , ŝki ). Note that q(fi) is Gaussian because q(f) involves a Gaussian convolution. As in the proposed approach, q(f) is assumed to be a Gaussian factorizing over the latent functions f 1 , . . . , f C . However, its mean and covariance parameters, i.e., {mk}Ck=1 and {Sk}Ck=1 are found by maximizing (15). The parameters of q(fi) are:\nm̂ki = (k k\nxiX k ) T(Kk X k X k ) −1mk , (16)\nŝki = κ k xixi − (k k\nxiX k ) T(Kk X k X k ) −1kk xiX k\n+ (kk xiX k ) T(Kk X k X k ) −1Sk(Kk X k X k ) −1kk xiX k . (17)\nHensman et al. (2015b) consider Markov chain Monte Carlo (MCMC) to sample the hyper-parameters. Here we simply maximize (15) to find the hyper-parameters and the inducing points. The reason for this is that in very large datasets MCMC is not expected to give much better results. We refer to the described approach as VI. The objective in (15) contains a sum across the data instances. Thus, VI also allows for stochastic optimization and it results in the same cost as the proposed approach. However, the expectations in (15) must be approximated using one-dimensional quadratures. This is a drawback with respect to the proposed method which is free of any quadrature. Finally, there are some methods related to the VI approach just described. Dezfouli & Bonilla (2015) assume that q can be a mixture of Gaussians, and Chai (2012) uses a soft-max likelihood (but does not consider stochastic optimization). Both works need to introduce extra approximations.\nIn the literature there are other research works addressing multi-class Gaussian process classification. Some examples include (Williams & Barber, 1998; Girolami & Rogers, 2006; Hernández-Lobato et al., 2011; Henao & Winther, 2012; Riihimäki et al., 2013). These works employ expectation propagation, variational inference or the Laplace approximation to approximate the computations. Nevertheless, the corresponding estimate of the logmarginal-likelihood cannot be expressed as a sum across the data instances. This avoids using efficient techniques for optimization based on stochastic gradients. Thus, one cannot address very large datasets with these methods."
  }, {
    "heading": "4. Experiments",
    "text": "We evaluate the performance of the method proposed in Section 2.2. We consider two versions of it. A first\none, using expectation propagation (EP). A second, using the memory efficient stochastic EP (SEP). EP and SEP are compared with the methods described in Section 3. Namely, GFITC and VI. All methods are codified in the R language (the source code is in the supplementary material), and they consider the same initial values for the model hyper-parameters (including the inducing points, that are chosen at random from the training instances). The hyperparameters are optimized by maximizing the estimate of the marginal likelihood. A Gaussian covariance function with automatic relevance determination, an amplitude parameter and an additive noise parameter is employed."
  }, {
    "heading": "4.1. Performance on Datasets from the UCI Repository",
    "text": "We evaluate the performance of each method on 8 datasets from the UCI repository (Lichman, 2013). The characteristics of the datasets are displayed in Table 4.1. We use batch training in each method (i.e., we go through all the data to compute the gradients). Batch training does not scale to large datasets. However, it is preferred on small datasets like the ones considered here. We use 90% of the data for training and 10% for testing, expect for Satellite which is fairly big, where we use 20% for training and 80% for testing. In Waveform, which is synthetic, we generate 1000 instances and split them in 30% for training and 70% for testing. Finally, in Vowel we consider only the points that belong to the 6 first classes. All methods are trained for 250 iterations using gradient ascent (GFITC and VI use lBFGS, EP and SEP use an adaptive learning rate described in the supplementary material). We consider three values for M , the number of inducing points. Namely 5%, 10% and 20% of the number of training instances. We report averages over 20 repetitions of the experiments.\nTable 2 shows, for each value of M , the average negative test log-likelihood of each method with the corresponding error bars (test errors are shown in the supplementary material). The average training time of each method is also displayed. The best method (the lower the better) for each dataset is highlighted in bold face. We observe that the proposed approach, EP, obtains very similar results to those of GFITC, and sometimes it obtains the best results. The memory efficient version of EP, SEP, seems to provide similar results without reducing the performance. Regarding the computational cost, SEP is the\nfastest method (between 2 and 3 times faster than GFITC). VI is slower as a consequence of the quadratures required by this method. VI also gives much worse results in some datasets, e.g., Glass, Svmguide2 and Waveform. This is related to the optimization of Eq(fi)[log p(yi|fi)] in (15), instead of logEq(fi)[p(yi|fi)], which is closer to the data loglikelihood. In the EP objective in (9), ∑ k 6=yi logZi,k is probably more similar to logEq(fi)[p(yi|fi)]. This explains the much better results obtained by EP and SEP."
  }, {
    "heading": "4.2. Analysis of Inducing Point Learning",
    "text": "We generate a synthetic two dimensional problem with three classes by sampling the latent functions from the GP prior and applying the rule yi = arg maxk f\nk(xi). The distribution of xi is uniform in the box [−2.5, 2.5] × [−2.5, 2.5]. We consider 1000 training instances and a growing number of inducing points, i.e., M = 1 to M = 256. The initial location of the inducing points is chosen at random and it is the same for all the methods. We are interested in the location of the inducing points after training. Thus, we set the other hyper-parameters to their true values (specified before generating the data) and we keep them fixed. All methods but VI are trained using batch methods during 2000 iterations. VI is trained using stochastic gradients for 2000 epochs (the batch version often gets stuck in local optima). We use ADAM with the default settings (Kingma & Ba, 2015), and 100 as the mini-batch size.\nFigure 3 shows the location learnt by each method for the inducing points. Blue, red and green points represent the training data, black lines are decision boundaries and black border points are the inducing points. As we increase the number of inducing points the methods become more accurate. However, GFITC, EP and SEP identify decision boundaries that are better with a smaller number of inducing points. VI fails in this task. This is probably because VI updates the inducing-points with a bad estimate of q during the initial iterations. VI uses gradient steps to update q, which is less efficient than the EP updates (free of any learning rate). GFITC, EP and SEP overlap the inducing points, which can be seen as a pruning mechanism (if two inducing points are equal, it is like having only one). This has already been observed in regression problems (Bauer et al., 2016). By contrast, VI places the inducing points near the decision boundaries. This agrees with previous results on binary classification (Hensman et al., 2015a)."
  }, {
    "heading": "4.3. Performance as a Function of the Training Time",
    "text": "Figure 4 shows the negative test log-likelihood of each method as a function of the training time on the Satellite dataset (EP results are not shown since it performs equal to SEP). Training is done as in Section 4.1. We consider a growing number of inducing points M = 4, 20, 100 and report averages over 100 repetitions of the experiments. In all methods we use batch training. We observe that SEP is the method with the best performance at the lowest cost. Again, it is faster than GFITC because it optimizes q and the hyper-parameters at the same time, while GFITC waits until EP has converged to update the hyper-parameters. VI is not very efficient for small values of M , due to the quadratures. It also takes more time to get a good estimate of q, which is updated by gradient descent and is less ef-\nficient than the EP updates. Similar results are obtained in terms of the test error. See the supplementary material. However, in that case VI does not overfit the training data."
  }, {
    "heading": "4.4. Performance When Using Stochastic Gradients",
    "text": "In very large datasets batch training is infeasible, and one must use mini-batches to update q and to approximate the required gradients. We evaluate the performance of each method on the MNIST dataset (LeCun et al., 1998) with M = 200 inducing points and mini-batches with 200 instances. This dataset has 60, 000 instances for training and 10, 000 for testing. The learning rate of each method is set using ADAM with the default parameters (Kingma & Ba, 2015). GFITC does not allow for stochastic optimization. Thus, it is ignored in the comparison. The test error and the negative test log-likelihood of each method is displayed in Figure 5 (top) as a function of the training time. In this larger dataset all methods perform similarly. However, EP and SEP take less time to converge than VI. SEP obtains a test error that is 2.08% and average negative test log-likelihood that is 0.0725. The results of VI are 2.02% and 0.0686, respectively. These results are similar to the\nones reported in (Hensman et al., 2015a) using M = 500.\nA last experiment considers all flights within the USA between 01/2008 and 04/2008 (http://stat-computing. org/dataexpo/2009). The task is to classify the flights according to their delay using three classes: On time, more than 5 minutes of delay, or more than 5 minutes before time. We consider 8 attributes: age of the aircraft, distance covered, airtime, departure time, arrival time, day of the week, day of the month and month. After removing all instances with missing data 2, 127, 068 instances remain, from which 10, 000 are used for testing and the rest for training. We use the same settings as on the MNIST dataset and evaluate each method. The results obtained are shown in Figure 5 (bottom). We also report the performance of a logistic regression classifier. Again, all methods perform similarly in terms of test error. However, EP and SEP converge faster and quickly outperform the linear model. Importantly, the negative test log-likelihood of VI starts increasing at some point, which is again probably due to the optimization of Eq(fi)[log p(yi|fi)] in (15). The supplementary material has further evidence supporting this."
  }, {
    "heading": "5. Conclusions",
    "text": "We have proposed the first method for multi-class classification with Gaussian processes, based on expectation propagation (EP), that scales well to very large datasets. Such a method uses the FITC approximation to reduce the number of latent variables in the model from O(N) to O(M), whereM N , andN is the number of data instances. For this,M inducing points are introduced for each latent function in the model. Importantly, the proposed method allows for stochastic optimization as the estimate of the log-\nmarginal-likelihood involves a sum across the data. Moreover, we have also considered a stochastic version of EP (SEP) to reduce the memory usage. When mini-batches and stochastic gradients are used for training, the computational cost of the proposed approach is O(CM3), with C the number of classes. The memory cost is O(CM2).\nWe have compared the proposed method with other approaches from the literature based on variational inference (VI) (Hensman et al., 2015b), and with the model considered by Kim & Ghahramani (2006), which has been combined with FITC approximate priors (GFITC) (QuiñoneroCandela & Rasmussen, 2005). The proposed approach outperforms GFITC in large datasets as this method does not allow for stochastic optimization, and in small datasets it produces similar results. The proposed method, SEP, is slightly faster than VI which also allows for stochastic optimization. In particular, VI requires one-dimensional quadratures which in small datasets are expensive. We have also observed that SEP converges faster than VI. This is probably because the EP updates, free of any learning rate, are more efficient for finding a good posterior approximation than the gradient ascent updates employed by VI.\nAn important conclusion of this work is that VI sometimes gives bad predictive distributions in terms of the test loglikelihood. The EP and SEP methods do not seem to have this problem. Thus, if one cares about accurate predictive distributions, VI should be avoided in favor of the proposed methods. In our experiments we have also observed that the proposed approaches tend to place the inducing points one on top of each other, which can be seen as an inducing point pruning technique (Bauer et al., 2016). By contrast, VI tends to place them near the decision boundaries."
  }, {
    "heading": "Acknowledgements",
    "text": "The authors gratefully acknowledge the use of the facilities of Centro de Computación Cientı́fica (CCC) at Universidad Autónoma de Madrid. The authors also acknowledge financial support from Spanish Plan Nacional I+D+i, Grants TIN2013-42351-P, TIN2016-76406P, TIN2015-70308-REDT and TEC2016-81900-REDT (MINECO/FEDER EU), and from Comunidad de Madrid, Grant S2013/ICE-2845."
  }],
  "year": 2017,
  "references": [{
    "title": "Understanding probabilistic sparse Gaussian process approximations",
    "authors": ["M. Bauer", "M. van der Wilk", "C.E. Rasmussen"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2016
  }, {
    "title": "Variational multinomial logit Gaussian process",
    "authors": ["K.M.A. Chai"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2012
  }, {
    "title": "Scalable inference for Gaussian process models with black-box likelihoods",
    "authors": ["A. Dezfouli", "E.V. Bonilla"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "Variational Bayesian multinomial probit regression with Gaussian process priors",
    "authors": ["M. Girolami", "S. Rogers"],
    "venue": "Neural Computation,",
    "year": 2006
  }, {
    "title": "Predictive active set selection methods for Gaussian processes",
    "authors": ["R. Henao", "O. Winther"],
    "year": 2012
  }, {
    "title": "Scalable variational Gaussian process classification",
    "authors": ["J. Hensman", "A. Matthews", "Z. Ghahramani"],
    "venue": "In Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,",
    "year": 2015
  }, {
    "title": "MCMC for variationally sparse Gaussian processes",
    "authors": ["J. Hensman", "A.G. Matthews", "M. Filippone", "Z. Ghahramani"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "Scalable Gaussian process classification via expectation propagation",
    "authors": ["D. Hernández-Lobato", "J.M. Hernández-Lobato"],
    "venue": "In Proceedings of the 19th International Conference on Artificial Intelligence and Statistics,",
    "year": 2016
  }, {
    "title": "Robust multi-class Gaussian process classification",
    "authors": ["D. Hernández-Lobato", "J.M. ández Lobato", "P. Dupont"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2011
  }, {
    "title": "Bayesian Gaussian process classification with the EM-EP algorithm",
    "authors": ["Kim", "H.-C", "Z. Ghahramani"],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
    "year": 1948
  }, {
    "title": "ADAM: a method for stochastic optimization",
    "authors": ["D.P. Kingma", "J. Ba"],
    "venue": "In Inrernational Conference on Learning Representations,",
    "year": 2015
  }, {
    "title": "Assessing approximate inference for binary Gaussian process classification",
    "authors": ["M. Kuss", "C.E. Rasmussen"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2005
  }, {
    "title": "Gradient-based learning applied to document recognition",
    "authors": ["LeCun", "Yann", "Bottou", "Léon", "Bengio", "Yoshua", "Haffner", "Patrick"],
    "venue": "Proceedings of the IEEE,",
    "year": 1998
  }, {
    "title": "Stochastic expectation propagation",
    "authors": ["Y. Li", "J.M. Hernández-Lobato", "R.E. Turner"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "Expectation propagation for approximate Bayesian inference",
    "authors": ["T. Minka"],
    "venue": "In Proceedings of the 17th Annual Conference on Uncertainty in Artificial Intelligence,",
    "year": 2001
  }, {
    "title": "The generalized FITC approximation",
    "authors": ["A. Naish-Guzman", "S. Holden"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2008
  }, {
    "title": "Approximations for binary Gaussian process classification",
    "authors": ["H. Nickisch", "C.E. Rasmussen"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2008
  }, {
    "title": "A unifying view of sparse approximate Gaussian process regression",
    "authors": ["J. Quiñonero-Candela", "C.E. Rasmussen"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2005
  }, {
    "title": "Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)",
    "authors": ["C.E. Rasmussen", "C.K.I. Williams"],
    "year": 2006
  }, {
    "title": "Nested expectation propagation for Gaussian process classification with a multinomial probit likelihood",
    "authors": ["J. Riihimäki", "P. Jylänki", "A. Vehtari"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2013
  }, {
    "title": "Expectation propagation for exponential families",
    "authors": ["M. Seeger"],
    "venue": "Technical report, Department of EECS,",
    "year": 2006
  }, {
    "title": "Flexible and efficient Gaussian process models for machine learning",
    "authors": ["E. Snelson"],
    "venue": "PhD thesis,",
    "year": 2007
  }, {
    "title": "Sparse Gaussian processes using pseudo-inputs",
    "authors": ["E. Snelson", "Z. Ghahramani"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2006
  }, {
    "title": "Bayesian classification with Gaussian processes",
    "authors": ["C.K.I. Williams", "D. Barber"],
    "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence,",
    "year": 1998
  }],
  "id": "SP:d0b83adea3724310ba438adea020635300a0cf0f",
  "authors": [{
    "name": "Carlos Villacampa-Calvo",
    "affiliations": []
  }, {
    "name": "Daniel Hernández-Lobato",
    "affiliations": []
  }],
  "abstractText": "This paper describes an expectation propagation (EP) method for multi-class classification with Gaussian processes that scales well to very large datasets. In such a method the estimate of the log-marginal-likelihood involves a sum across the data instances. This enables efficient training using stochastic gradients and mini-batches. When this type of training is used, the computational cost does not depend on the number of data instances N . Furthermore, extra assumptions in the approximate inference process make the memory cost independent of N . The consequence is that the proposed EP method can be used on datasets with millions of instances. We compare empirically this method with alternative approaches that approximate the required computations using variational inference. The results show that it performs similar or even better than these techniques, which sometimes give significantly worse predictive distributions in terms of the test log-likelihood. Besides this, the training process of the proposed approach also seems to converge in a smaller number of iterations.",
  "title": "Scalable Multi-Class Gaussian Process Classification  using Expectation Propagation"
}