{
  "sections": [{
    "text": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1626–1637 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Offering a channel for customers to share opinions and give scores to products and services, review websites have become a highly influential information source that customers refer to for making purchase decisions. Popular examples include IMDB.com on the movie domain, Epinions.com on the product domain, and Yelp.com on the service domain. Figure 1 shows a screenshot of a restaurant review page on Yelp.com, which offers two main types of information. First, an overall rating score is given under the restaurant name; second, detailed user reviews are listed below the rating.\n∗This work has been done when the first author worked at SUTD.\nThough offering useful overview and details about a product or service, such information has several limitations for a user who has not used the product or service. First, the overall rating is general and not necessarily agreeable to the taste of an individual customer. Being a simple reflection of all customer scores, it serves an average customer well, but can be rather inaccurate for individuals. For example, the authors themselves often find highly rated movies being tedious. Second, there can be hundreds of reviews for a product or service, which makes it infeasible for exhaustive reading. It would be useful to have a brief summary of all reviews, which ideally should be customized to the reader.\nTo address the limitations above, we propose a new task called opinion recommendation, which is to generate a customized review score of the product that the user is likely to give, as well as a customized review that the user would have written for the target product, if the user had reviewed the product. The proposed opinion recommendation task is closely related to several existing lines of work in NLP. The first is sentiment analysis (Hu and Liu, 2004; Pang and Lee, 2008) and opinion summarization (Nishikawa et al., 2010; Wang and Ling, 2016), which is to give a rating score or summary based on existing customer reviews. Our\n1626\ntask is different in that we aim to generate user rating scores and review of a product unreviewed by the user. The second is recommendation (Su and Khoshgoftaar, 2009; Yang et al., 2014), which is to give a ranking score to a certain product or service based on the purchase history of the user and other customers who have purchased the target product. Our task is different in the source of input, which is textual customer reviews and ratings rather than numerical purchase history.\nThere are two types of inputs for our task, namely existing reviews of the target product, and the reviews of the user on other products, and two types of outputs, namely a customized rating score and a customized review. The ideal solution should consider the interaction between all given types of information, jointly predicting the two types of outputs. This poses significant challenges to statistical models, which require manually defined features to capture relevant patterns from training data. Deep learning is a relatively more feasible choice, offering viabilities of information fusion by fully connected hidden layers (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a). We leverage this advantage in building our model.\nIn particular, we use a sub RNN to model the semantic content of each review. A sub product model is used to consolidate existing reviews for the target product, and a user model is built by consolidating the reviews of the given user into a single vector form. To address potential sparsity of a user’s history reviews, neighbor users are identified by collaborative filtering (Ding et al., 2006), and a vector representation is learned by using a neural neighborhood model. Finally, a deep memory network is utilized to find the association between the user and target product, jointly yielding the rating score and customised review. Experiments on a Yelp dataset show that the model outperforms several pipelined baselines. We make our source code publicly available under GPL at https://github.com/ wangzq870305/opinion_recommend."
  }, {
    "heading": "2 Related Work",
    "text": "Sentiment Analysis. Our task is related to document-level sentiment classification (Pang and Lee, 2008) for various neural network models have been used, including convolutional neural networks (Kim, 2014), recursive neural net-\nwork (Socher et al., 2013) and recurrent neural network (Teng et al., 2016; Tai et al., 2015), Review rating prediction aims to predict the numeric rating of a given review. Pang and Lee (2005) pioneered this task by regarding it as a classification/regression problem. Most subsequent work focuses on designing effective textural features of reviews (Qu et al., 2010; Li et al., 2011; Wan, 2013).\nUser information has been widely investigated in sentiment analysis. Gao et al. (2013) developed user-specific features to capture user leniency, and Li et al. (2014) incorporated textual topic and userword factors through topic modeling. For integrating user information into neural network models, Tang et al. (2015) predicted the rating score given a review by using both lexical semantic information and a user embedding model. Chen et al. (2016b) proposed a neural network to incorporate global user and product information for sentiment classification via an attention mechanism.\nDifferent from the above research, which focuses on predicting the opinion on existing reviews, our task is to recommend the score that a user would give to a new product without knowing his review text. The difference originates from the objective. Previous research aims to predict opinions on reviewed products, while our task is to recommend opinion on new products, which the user has not reviewed.\nOpinion Summarization. Our work also overlaps with to the area of opinion summarization, which constructs natural language summaries for multiple product reviews (Hu and Liu, 2004). Most previous work extracts opinion words and aspect terms. Typical approaches include association mining of frequent candidate aspects (Hu and Liu, 2004; Qiu et al., 2011), sequence labeling based methods (Jakob and Gurevych, 2010; Yang and Cardie, 2013), as well as topic modeling techniques (Lin and He, 2009). Recently, word embeddings and recurrent neural networks are also used to extract aspect terms (Irsoy and Cardie, 2014; Liu et al., 2015). While all the methods above are extractive, Ganesan et al. (2010) presented a graph-based summarization framework to generate concise abstractive summaries of highly redundant opinions, and Wang and Ling (2016) used an attention-based neural network model to absorb information from multiple text units and generate summaries of movie reviews. We also\nperform abstractive summarization. However, different from the above research, which summarize existing reviews, we generate customized reviews for a unreviewed product.\nRecommendation. has been solved on mainly purchase history. There are two main approaches, which are content-based and collaborativefiltering (CF) based (Adomavicius and Tuzhilin, 2005; Yang et al., 2014), respectively. Most existing social recommendation systems are CF-based, and can be further grouped into model-based CF and neighborhood-based CF (Kantor et al., 2011; Su and Khoshgoftaar, 2009). Matrix Factorization (MF) is one of the most popular models for CF. In recent MF-based social recommendation works, user-user social trust information is integrated with user-item feedback history (e.g., ratings, clicks, purchases) to improve the accuracy of traditional recommendation systems, which only factorize user-item feedback data (Ding et al., 2006; Koren, 2008; He et al., 2016).\nThere has been work integrating sentiment analysis and recommendation systems, which use recommendation strategies such as matrix factorization to improve the performance of sentiment analysis (Leung et al., 2006; Singh et al., 2011). These methods typically use ensemble learning (Singh et al., 2011) or probabilistic graph models (Wu and Ester, 2015). For example, Zhang et al. (2014) proposed a factor graph model to recommend opinion rating scores by using explicit product features as hidden variables. Different from the above research, we recommend user opinions.\nNeural Network Models. Multi-task learning has been recognised as a strength of neural network models for natural language processing (Collobert et al., 2011; Henderson et al., 2013; Zhang and Weiss, 2016; Chen et al., 2016a), where hidden feature layers are shared between different tasks that have common basis. Our work can be regarded as an instance of such multi-tasks learning via shared parameters, which has been widely used in the research community recently.\nDynamic memory network models have been applied for NLP tasks such as question answering (Sukhbaatar et al., 2015; Kumar et al., 2016), language modeling (Tran et al., 2016) and machine translation (Wang et al., 2016). There are typically used to find abstract semantic representations of texts towards certain tasks, which are consistent with our main need, namely abstract-\ning the representation of a product that is biased towards the taste of a certain user. We use a variation of the memory network model for obtaining user-specific review representation."
  }, {
    "heading": "3 Model",
    "text": "Formally, the input to our model is a tuple 〈RT , RU , RN 〉, where RT = {rT1 , rT2 , ..., rTnt} is the set of existing reviews of a target product, RU = {rU1 , rU2 , ..., rUnu} is the set of user’s history reviews, and RN = {rN1 , rN2 , ..., rNnn} is the set of the user’s neighborhood reviews. All the reviews are sorted with temporal order. The output is a pair 〈YS , YR〉, where YS is a real number between 0 and 5 representing the customized rating score of the target product, and YR is a customised review. A characteristic of our model is that YS and YR are generated on a product that the user has not reviewed.\nFor capturing both general and personalized information, we first build a product model, a user model, and a neighborhood model, respectively, and using a memory network model to integrate these three types of information, constructing a customized product model. Finally, we predict a customized rating score and a review collectively using neural stacking framework. The overall architecture of the model is shown in Figure 2."
  }, {
    "heading": "3.1 Review Model",
    "text": "A review is the foundation of our model, based on which we derive representations of both a user and a target product. In particular, a user profile can be achieved by modeling all the reviews RU of the user, and a target product profile can be obtained by using all existing reviews RT of the product. We use the average of word embeddings to model a review. Formally, given a review r = {x1, x2, ..., xm}, where m is the length of\nthe review, each word xk is represented with a Kdimensional embedding ewk (Mikolov et al., 2013). We use the ∑ k(e w k )/m for the representation of the review ed(r)."
  }, {
    "heading": "3.2 User Model",
    "text": "A standard LSTM (Hochreiter and Schmidhuber, 1997) is used to learn the hidden states of an user’s reviews to build the user model. Denoting the recurrent function at step t as LSTM(xt, ht−1), we obtain a sequence of hidden state vectors {hU1 , hU2 , ..., hUnu} recurrently by feeding {ed(rU1), ed(rU2), ..., ed(rUnu )} as inputs, where hUi = LSTM(e\nd(rUi), hUi−1). The initial state and all standard LSTM parameters are randomly initialized and tuned during training.\nNot all reviews contribute equally to the representation of a user. We use the attention mechanism (Bahdanau et al., 2014; Yang et al., 2016) to extract the reviews that are relatively more important, aggregating the representation of reviews to form a vector. Taking the hidden state {hU1 , ...hU2 , ..., hUnu} of user model as input, the attention model outputs, a continuous vector vU ∈ Rd×1, which is computed as a weighted sum of each hidden state hUi , namely\nvU = nu∑ i αihUi (1)\nwhere nu is the hidden variable size, αi ∈ [0, 1] is the weight of hUi , and ∑ i αi = 1.\nFor each piece of hidden state hUi , the scoring function is calculated by\nui = tanh(WUhUi + bU ) (2)\nαi = exp(ui)∑ j exp(uj)\n(3)\nwhere WU and bU are model parameters. The attention vector vU is used to represent the user for the User Model."
  }, {
    "heading": "3.3 Neighborhood Model",
    "text": "We use neighborhood reviews to improve the user model, since a user may not have sufficient reviews to construct a reliable model. Here a neighbor refers to a user that has similar tastes to the target user (Koren, 2008; Desrosiers and Karypis, 2011). The same as the user model, we construct\nthe neighborhood model vN using the neighborhood reviews RN = {rN1 , rN2 , ..., rNnn} with an attention recurrent network.\nA key issue in building the neighborhood model is how to find neighbors of a certain user. In this study, we use matrix factorization (Koren, 2008) to detect neighbors, which is a standard approach for recommendation (Ding et al., 2006; Li et al., 2009; He et al., 2016). In particular, users’ rating scores of products are used to build a productusers matrix M ∈ Rnt×nu with nt products and nu users. We approximate it using three factors, specifying soft membership of products and users (Ding et al., 2006) by finding:\nmin F,S,T ||M − FST T || s.t.S ≥ 0, F ≥ 0, T ≥ 0\n(4)\nwhere F ∈ Rnt×K represents the posterior probability of K topic clusters for each product; S ∈ RK×K encodes the distribution of each topic k; and T ∈ RK×nu indicates the posterior probability of K topic clusters for each user.\nAs a result of matrix factorization, we directly obtain the probability of each user on each topic from the person-topic matrix T . To infer T , the optimization problem in Eq.4 can be solved using the following updating rule:\nTjk ← Tjk (M TFS)jk\n(TT TMTFS)jk (5)\nWith the user-topic matrix T , we measure the implicit connection between two users using:\nsim(i, j) = k∑\nk=1\nTikTjk (6)\nwhere sim(i, j) measure the implicit connection degree between users i and j. If sim(i, j) is higher than a threshold η, we consider user j as the neighbor of user i."
  }, {
    "heading": "3.4 Product Model",
    "text": "Given the representations of existing reviews {ed(rT1), ed(rT2), ..., ed(rTnt )} of the product, we use LSTM to model their temporal orders, obtaining a sequence of hidden vectors hT = {hT1 , hT2 , ..., hTnt} by recurrently feeding {ed(rT1), ed(rT2), ..., ed(rTnt} as inputs. The hidden state vectors hT are used to represent the product.\nCustomized Product Model. The product model represents salient information of existing reviews in their temporal order, yet do not reflect the taste of a particular user. We build the customised product model to integrate user information and product information (as reflected by the product model), resulting in a single vector that represents a customised product. From this vector we are able to synthesis both a customised review and a customised rating score. In particular, we use the user representation vU and the neighbour representation vN to transform the target product representation hT = {hT1 , hT2 , ..., hTnt} into a customised product representation vC , which is tailored to the taste of the user.\nA naive model of yielding vC could utilise the attention mechanism over ht, deriving a weighted sum according to user information. On the other hand, dynamic memory networks have been shown highly useful for deriving abstract semantic information compared with simple attention, and hence we follow Sukhbaatar et al. (2015) and Xiong et al. (2016), building a variation of DMN to iteratively find increasingly abstract representations of ht, by injecting vU and vN information.\nThe memory model consists of multiple dynamic computational layers (hops), each of which contains an attention layer and a linear layer. In the first computational layer (hop 1), we take the hidden variables hTi (0 ≤ i ≤ nt) of product model as input, adaptively selecting important evidences through one attention layer using vU and vN . The output of the attention layer gives a linear interpolation of hT , and the result is considered as input to the next layer (hop 2). In the same way, we stack multiple hops and run the steps multiple times, so that more abstract representations of the target product can be derived.\nThe attention model outputs a continuous vector vC ∈ Rd×1, which is computed as a weighted sum of hTi (0 ≤ i ≤ nt), namely\nvC = nt∑ i βihTi (7)\nwhere nt is the hidden variable size, βi ∈ [0, 1] is the weight of hTi , and ∑ i βi = 1. For each piece of hidden state hTi , we use a feed forward neural network to compute its semantic relatedness with the abstract representation vC . The scoring func-\ntion is calculated as follows at hop t:\nuti = tanh(WThTi +WCv t−1 C\n+WUvU +WNvN + b) (8)\nβti = exp(uti)∑ j exp(u t j)\n(9)\nThe vector vC is used to represent the customized product model. At the first hop, we define V 0C =∑\ni hTi/nt. The product model hTi (0 ≤ i ≤ nt) represents salient information of existing reviews in their temporal order, they do not reflect the taste of a particular user. We use the customised product model to integrate user information and product information (as reflected by the product model), resulting in a single vector that represents a customised product. From this vector we are able to synthesis both a customised review and a customised rating score."
  }, {
    "heading": "3.5 Customized Review Generation",
    "text": "The goal of customized review generation is to generate a review YR from the customized product representation vC , composed by a sequence of words yR1 , ..., yRnr . We use a standard LSTM decoder (Rush et al., 2015) to decompose the prediction of YR into a sequence of word-level predictions:\nlogP (YR|vC) =∑ j P (yRj |yR1 , ..., yRj−1 , vC) (10)\nwhere each word yRj is predicted conditional on the previously generated yR1 , ..., yRj−1 and the customized product vector vC . The probability is estimated by using standard word softmax:\nP (yRj |yR1 , ..., yRj−1 , vC) = softmax(hRj ) (11)\nwhere hRj is the hidden state variable at timestamp j, which is modeled as LSTM(uj−1, hRj). Here a LSTM is used to generate a new state hRj from the representation of the previous state hRj−1 and uj−1. uj−1 is the concatenation of previously generated word yRj−1 and the input representation of customized model vC ."
  }, {
    "heading": "3.6 Customized Rating Prediction",
    "text": "A straightforward approach to predicting the rating score of a product is to take the average of existing review scores. However, the drawback is that it cannot reflect the the variance in user tastes. In order to integrate user preferences into the rating, we instead take a user-based weighted average of existing rating scores, so that the scores of reviews that are closer to the user preference are given higher weights. However, existing ratings can be all different from a users personal rating, if the existing reviews do not come from the user’s neighbours. We thus use the customized product vector vc as a bias of the weighted average of existing rating scores.\nFormally, given the rating scores s1, s2, ..., sn of existing reviews, and the the customized product representation vC , we calculate:\nYS = n∑ i βi · si + µ tanh(WSvC + bS) (12)\nIn the left term ∑n\ni βi ·si, we use attention weights βi in Eq.9 to measure the important of each rating score si. The right term tanh(WSvC + bS) is a review-based shift, weighted by µ.\nSince the result of customized review generation can be helpful for rating score prediction, we use neural stacking additionally feeding the last hidden state hRn of review generation model as input for YS prediction, resulting in\nYS = n∑ i αi · si+\n+ µ tanh(WS(vC ⊕ hRn) + bS) (13)\nwhere ⊕ denotes vector concatenation."
  }, {
    "heading": "3.7 Training",
    "text": "For our task, there are two joint training objectives, for review scoring and review summarisation, respectively. For review scoring, the loss function is defined as:\nL(Θ) = N∑\ni=1\n(Y ∗Si − YSi)2 + λ\n2 ||Θ||2 (14)\nwhere Y ∗Si is the predicted rating score, YSi is the rating score in the training data, Θ is the set of model parameters and λ is a parameter for L2 regularization.\nFor customized review generation, loss is defined by maximizing the log probability of Eq.10 (Sutskever et al., 2014; Rush et al., 2015). The two loss functions for score and review prediction share the representation vectors under vC , hence forming multi-task learning.\nStandard back propagation is performed to optimize parameters, where gradients also propagate from the scoring objective to the review generation objective due to neural stacking (Eq.13). We apply online training, where model parameters are optimized by using AdaGrad (Duchi et al., 2011). Word embeddings are trained using the Skip-gram algorithm (Mikolov et al., 2013)1."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Experimental Settings",
    "text": "Our data are collected from the yelp academic dataset2, provided by Yelp.com, a popular restaurant review website. The data set contains three types of objects: business, user, and review, where business objects contain basic information about local businesses (i.e. restaurants), review objects contain review texts and star rating, and user objects contain aggregate information about a single user across all of Yelp. Table 1 illustrates the general statistics of the dataset.\nFor evaluating our model, we choose 4,755 user-product pairs from the dataset. The userproduct pairs are extracted by following criterions: for each selected user-product pair, the user should have written 10 reviews at least, and the product should contain 100 reviews at least. In addition, the gold-standard review that the user write for the corresponding product should contain 10 helpful hits at least. We did not try alternative data selection rules. We will give the detail in our draft.\nFor each pair, the existing reviews of the target service (restaurant) are used for the product model. The rating score given by each user to the target service is considered as the gold customized rating score, and the review of the target service given by\n1 https://code.google.com/p/word2vec/ 2https://www.yelp.com/academic dataset\neach user is used as the gold-standard customized review for the user. The remaining reviews of each user are used for training the user model. We use 3,000 user-product pairs to train the model, 1,000 pairs as testing data, and remaining data for development.\nWe use the ROUGE-1.5.5 (Lin, 2004) toolkit for evaluating the performance of customized review generation, and report unigram overlap (ROUGE-1) as a means of assessing informativeness. Mean Square Error (MSE) (Wan, 2013; Tang et al., 2015) is used as the evaluation metric for measuring the performance of customized rating score prediction. MSE penalizes more severe errors more heavily."
  }, {
    "heading": "4.2 Hyper-parameters",
    "text": "There are several important hyper-parameters in our models, and we tune their values using the development dataset. We set the regularization weight λ = 10−8 and the initial learning rate to 0.01. We set the size of word vectors to 128, the size of hidden vectors in LSTM to 128. In order to avoid over-fitting, dropout (Hinton et al., 2012) is used for word embedding with a ratio of 0.2. The neighbor similarity threshold η is set to 0.25."
  }, {
    "heading": "4.3 Development Experiments",
    "text": ""
  }, {
    "heading": "4.3.1 Ablation Test",
    "text": "Effects of various configurations of our model, are shown on Table 2, where Joint is the full model of this paper, -user ablates the user model, -neighbor ablates the neighbor model, -rating is a single-task model that generates a review without the rating score, and -generation yields only the rating.\nBy comparing “Joint” and “-user,-neighbor”, we can find that customized information have significant influence on both the rating and review generation results (p − value < 0.01 using ttest). In addition, comparison between “-Joint” and “-user”, and between “-user” and “-user, - neighbor” shows that both the user information and the neighbour user information of the user are effective for improving the results. A users neighbours can indeed alleviate scarcity of user reviews.\nFinally, comparison between “Joint” and “- generation”, and between “Joint” and “-rating” shows that multi-task learning by parameter sharing is highly useful."
  }, {
    "heading": "4.3.2 Influence of Hops",
    "text": "We show the influence of hops of memory network for customized review generation on Figure 3. When hop = 0, the model considers only the general product reviews (−user,−neighbor). When hop ≥ 1, customized product information is leveraged. From the figure we can find that, when hop = 3, the performance is the best. It indicates that multiple hops can capture more abstract evidences from external memory to improve the performance. However, too many hops leads to over-fitting, thereby harms the performance. As a result, we choose 3 as the number of hops in our final test."
  }, {
    "heading": "4.3.3 Influence of µ",
    "text": "We show the influence of the bias weight parameter µ for rating prediction in Figure 4. With µ being 0, the model uses the weighted sum of existing reviews to score the product. When µ is very large, the system tends to use only the customized product representation vc to score the product, hence ignoring existing review scores, which are a useful source of information. Our results show that when µ is 1, the performance is optimal, thus indicating both existing review scores and review contents are equally useful."
  }, {
    "heading": "4.4 Final Results",
    "text": "We show the final results for opinion recommendation, comparing our proposed model with the\nHOP Bais 0 1.342 0 1.102 1 1.102 1 0.904 2 1.046 2 1.067 3 0.904 3 1.136 4 0.987 4 1.206 5 1.102 5 1.227 6 1.045 7 1.126 8 1.172 9 1.152 10 1.167\n0.90\n0.95\n1.00\n1.05\n1.10\n1.15\n1.20\n1.25\n0 1 2 3 4 5\nM S\nE\nμ\n0.90\n0.95\n1.00\n1.05\n1.10\n1.15\n1.20\n1.25\n1.30\n1.35\n1.40\n0 1 2 3 4 5 6 7 8 9 10\nM S\nE\nhop\nFigure 4: Influence of bias score.\nfollowing state-of-the-art baseline systems:\n• RS-Average-Yelp is the widely-adopted baseline (e.g., by Yelp.com), using the averaged review scores as the final score.\n• RS-Linear estimates the rating score that a user would give by sui = sall + su + si (Ricci et al., 2011), where su and si are the the training deviations of rating score of the user u and the product i, respectively.\n• RS-Item applies kNN to estimate the rating score (Sarwar et al., 2001). We choose the cosine similarity between vc to measure the distance between product.\n• RS-MF is a state-of-the-art recommendation model, which uses matrix factorisation to predict rating score (Ding et al., 2006; Li et al., 2009; He et al., 2016).\n• Sum-Opinosis uses a graph-based framework to generate abstractive summarisation given redundant opinions (Ganesan et al., 2010).\n• Sum-LSTM-Att is a state-of-the-art neural abstractive summariser, which uses an attentional neural model to consolidate information from multiple text sources, generating summaries using LSTM decoding (Rush et al., 2015; Wang and Ling, 2016).\nBeing non-opinion recommendation methods, all the baselines are single-task models, without considering rating and summarisation prediction jointly. The results are shown in Table 3. Our model (“ Joint”) significantly outperforms both “RS-Average-Yelp” and “RS-Linear” (p − value < 0.01 using t-test). Note that, our proposed rating recommendation for the user are significantly closer individual real user rating compared with Yelp’s rating.\nOur proposed model also significantly outperforms state-of-the-art recommendation systems (RS-Item and RS-MF) (p− value < 0.01 using ttest), indicating that textual information are a useful addition to the rating scores themselves for recommending a product.\nFinally, comparison between our proposed model and state-of-the-art summarisation techniques (Sum-Opinosis and Sum-LSTM-Att) shows the advantage of leveraging user information to enhance customised review generation, and also the strength of joint learning."
  }, {
    "heading": "4.5 Example Output",
    "text": "Table 4 shows example outputs of rating scores and reviews. Ref. is the rating score and review written by user her/himself, and Base is the baseline model, that generates the rating score by RS-MF, and review by Sum-LSTM-Att. From these examples, we can find that, both rating score and review which generated by the proposed Joint model is closer to the real user. In particular, in the first example, the baseline system correctly identifies the main both price and quality information, which the target user wrote in the review, yet the baseline model did not yield comments about the price based on reviews of other users. Associating reviews and ratings closely, the joint model gives a rating score that is much closer to the real user score compared to the score given by the recommendation model MF. In addition, we can also find some habits of certain users from their customized reviews, for example, Mexican food, cheap and clean restaurant."
  }, {
    "heading": "5 Conclusion",
    "text": "We proposed a novel task called opinion recommendation, which is to generate the review and rating score that a certain user would give to an unreviewed product or service. In particular, a\ndeep memory network was utilized to find the association between the user and the product, jointly yielding the rating score and customised review. Results show that our methods are better results compared to several pipelines baselines using state-of-the-art sentiment rating and summarisation systems. Review scores given by the opinion recordation system are closer to real user review scores compared to the review scores which Yelp assigns to target products."
  }, {
    "heading": "Acknowledgments",
    "text": "The corresponding author is Yue Zhang. We are grateful for the help of Xuanyi Li for his initial exploration. We thank our anonymous reviewers for their constructive comments, which helped to improve the paper. This work is supported by the Temasek Lab grant IGDST1403012 at Singapore University of Technology and Design, and supported by the National Natural Science Foundation of China (No.61402314)."
  }],
  "year": 2017,
  "references": [{
    "title": "Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions",
    "authors": ["Gediminas Adomavicius", "Alexander Tuzhilin."],
    "venue": "IEEE transactions on knowledge and data engineering, 17(6):734–749.",
    "year": 2005
  }, {
    "title": "Neural machine translation by jointly learning to align and translate",
    "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."],
    "venue": "CoRR, abs/1409.0473.",
    "year": 2014
  }, {
    "title": "Neural network for heterogeneous annotations",
    "authors": ["Hongshen Chen", "Yue Zhang", "Qun Liu."],
    "venue": "Proceedings of the 2016 Conference on Empirical",
    "year": 2016
  }, {
    "title": "Neural sentiment classification with user and product attention",
    "authors": ["Huimin Chen", "Maosong Sun", "Cunchao Tu", "Yankai Lin", "Zhiyuan Liu."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016,",
    "year": 2016
  }, {
    "title": "Natural language processing (almost) from scratch",
    "authors": ["Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel P. Kuksa."],
    "venue": "Journal of Machine Learning Research, 12:2493–2537.",
    "year": 2011
  }, {
    "title": "A comprehensive survey of neighborhood-based recommendation methods",
    "authors": ["Christian Desrosiers", "George Karypis."],
    "venue": "Recommender Systems Handbook, pages 107–144.",
    "year": 2011
  }, {
    "title": "Orthogonal nonnegative matrix t-factorizations for clustering",
    "authors": ["Chris Ding", "Tao Li", "Wei Peng", "Haesun Park."],
    "venue": "Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 126–135. ACM.",
    "year": 2006
  }, {
    "title": "Adaptive subgradient methods for online learning and stochastic optimization",
    "authors": ["John C. Duchi", "Elad Hazan", "Yoram Singer."],
    "venue": "Journal of Machine Learning Research, 12:2121–2159.",
    "year": 2011
  }, {
    "title": "Opinosis: a graph-based approach to abstractive summarization of highly redundant opinions",
    "authors": ["Kavita Ganesan", "ChengXiang Zhai", "Jiawei Han."],
    "venue": "Proceedings of the 23rd international conference on computational linguistics, pages 340–348. Associa-",
    "year": 2010
  }, {
    "title": "Modeling user leniency and product popularity for sentiment classification",
    "authors": ["Wenliang Gao", "Naoki Yoshinaga", "Nobuhiro Kaji", "Masaru Kitsuregawa."],
    "venue": "IJCNLP, pages 1107–1111.",
    "year": 2013
  }, {
    "title": "Fast matrix factorization for online recommendation with implicit feedback",
    "authors": ["Xiangnan He", "Hanwang Zhang", "Min-Yen Kan", "Tat-Seng Chua."],
    "venue": "Proceedings of the 39th International ACM SIGIR conference on Research and Development in Infor-",
    "year": 2016
  }, {
    "title": "Multilingual joint parsing of syntactic and semantic dependencies with a latent variable model",
    "authors": ["James Henderson", "Paola Merlo", "Ivan Titov", "Gabriele Musillo."],
    "venue": "Computational Linguistics, 39(4):949–998.",
    "year": 2013
  }, {
    "title": "Improving neural networks by preventing co-adaptation of feature detectors",
    "authors": ["Geoffrey E. Hinton", "Nitish Srivastava", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov."],
    "venue": "CoRR, abs/1207.0580.",
    "year": 2012
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural Computation, 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Mining and summarizing customer reviews",
    "authors": ["Minqing Hu", "Bing Liu."],
    "venue": "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Seattle, Washington, USA, August 22-25, 2004, pages 168–177.",
    "year": 2004
  }, {
    "title": "Opinion mining with deep recurrent neural networks",
    "authors": ["Ozan Irsoy", "Claire Cardie."],
    "venue": "EMNLP, pages 720–728.",
    "year": 2014
  }, {
    "title": "Extracting opinion targets in a single and cross-domain setting with conditional random fields",
    "authors": ["Niklas Jakob", "Iryna Gurevych."],
    "venue": "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 Oc-",
    "year": 2010
  }, {
    "title": "Recommender systems handbook",
    "authors": ["Paul B Kantor", "Lior Rokach", "Francesco Ricci", "Bracha Shapira"],
    "year": 2011
  }, {
    "title": "Convolutional neural networks for sentence classification",
    "authors": ["Yoon Kim."],
    "venue": "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special",
    "year": 2014
  }, {
    "title": "Factorization meets the neighborhood: a multifaceted collaborative filtering model",
    "authors": ["Yehuda Koren."],
    "venue": "Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 426–434. ACM.",
    "year": 2008
  }, {
    "title": "Ask me anything: Dynamic memory networks for natural language processing",
    "authors": ["Ankit Kumar", "Ozan Irsoy", "Peter Ondruska", "Mohit Iyyer", "James Bradbury", "Ishaan Gulrajani", "Victor Zhong", "Romain Paulus", "Richard Socher."],
    "venue": "Proceedings of the 33nd In-",
    "year": 2016
  }, {
    "title": "Integrating collaborative filtering and sentiment analysis: A rating inference approach",
    "authors": ["Cane WK Leung", "Stephen CF Chan", "Fu-lai Chung."],
    "venue": "Proceedings of the ECAI 2006 workshop on recommender systems, pages 62–66.",
    "year": 2006
  }, {
    "title": "Incorporating reviewer and product information for review rating prediction",
    "authors": ["Fangtao Li", "Nathan Nan Liu", "Hongwei Jin", "Kai Zhao", "Qiang Yang", "Xiaoyan Zhu."],
    "venue": "IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artificial In-",
    "year": 2011
  }, {
    "title": "Suit: A supervised user-item based topic model for sentiment analysis",
    "authors": ["Fangtao Li", "Sheng Wang", "Shenghua Liu", "Ming Zhang."],
    "venue": "AAAI, pages 1636–1642.",
    "year": 2014
  }, {
    "title": "A nonnegative matrix tri-factorization approach to sentiment classification with lexical prior knowledge",
    "authors": ["Tao Li", "Yi Zhang", "Vikas Sindhwani."],
    "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International",
    "year": 2009
  }, {
    "title": "Joint sentiment/topic model for sentiment analysis",
    "authors": ["Chenghua Lin", "Yulan He."],
    "venue": "Proceedings of the 18th ACM Conference on Information and Knowledge Management, CIKM 2009, Hong Kong, China, November 2-6, 2009, pages 375–384.",
    "year": 2009
  }, {
    "title": "Rouge: A package for automatic evaluation of summaries",
    "authors": ["Chin-Yew Lin."],
    "venue": "Text summarization branches out: Proceedings of the ACL-04 workshop, volume 8. Barcelona, Spain.",
    "year": 2004
  }, {
    "title": "Fine-grained opinion mining with recurrent neural networks and word embeddings",
    "authors": ["Pengfei Liu", "Shafiq R. Joty", "Helen M. Meng."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon,",
    "year": 2015
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean."],
    "venue": "Advances in Neural Information Processing Systems 26: 27th Annual Conference on",
    "year": 2013
  }, {
    "title": "Optimizing informativeness and readability for sentiment summarization",
    "authors": ["Hitoshi Nishikawa", "Takaaki Hasegawa", "Yoshihiro Matsuo", "Gen-ichiro Kikui."],
    "venue": "ACL 2010, Proceedings of the 48th Annual Meeting of the Association for Computation-",
    "year": 2010
  }, {
    "title": "Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales",
    "authors": ["Bo Pang", "Lillian Lee."],
    "venue": "ACL 2005, 43rd Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference, 25-",
    "year": 2005
  }, {
    "title": "Opinion mining and sentiment analysis",
    "authors": ["Bo Pang", "Lillian Lee."],
    "venue": "Foundations and trends in information retrieval, 2(1-2):1–135.",
    "year": 2008
  }, {
    "title": "Opinion word expansion and target extraction through double propagation",
    "authors": ["Guang Qiu", "Bing Liu", "Jiajun Bu", "Chun Chen."],
    "venue": "Computational Linguistics, 37(1):9–27.",
    "year": 2011
  }, {
    "title": "The bag-of-opinions method for review rating prediction from sparse text patterns",
    "authors": ["Lizhen Qu", "Georgiana Ifrim", "Gerhard Weikum."],
    "venue": "COLING 1635",
    "year": 2010
  }, {
    "title": "User modeling with neural network for review rating prediction",
    "authors": ["Duyu Tang", "Bing Qin", "Ting Liu", "Yuekui Yang."],
    "venue": "Proceedings of the TwentyFourth International Joint Conference on Artificial Intelligence, IJCAI 2015, Buenos Aires, Argentina,",
    "year": 2015
  }, {
    "title": "Context-sensitive lexicon features for neural sentiment analysis",
    "authors": ["Zhiyang Teng", "Duy-Tin Vo", "Yue Zhang."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA,",
    "year": 2016
  }, {
    "title": "Recurrent memory networks for language modeling",
    "authors": ["Ke M. Tran", "Arianna Bisazza", "Christof Monz."],
    "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
    "year": 2016
  }, {
    "title": "Co-regression for cross-language review rating prediction",
    "authors": ["Xiaojun Wan."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, 4-9 August 2013, Sofia, Bulgaria, Volume 2: Short Papers, pages 526–531.",
    "year": 2013
  }, {
    "title": "Neural networkbased abstract generation for opinions and arguments",
    "authors": ["Lu Wang", "Wang Ling."],
    "venue": "NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
    "year": 2016
  }, {
    "title": "Memory-enhanced decoder for neural machine translation",
    "authors": ["Mingxuan Wang", "Zhengdong Lu", "Hang Li", "Qun Liu."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, US-",
    "year": 2016
  }, {
    "title": "FLAME: A probabilistic model combining aspect based opinion mining and collaborative filtering",
    "authors": ["Yao Wu", "Martin Ester."],
    "venue": "Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM 2015, Shanghai,",
    "year": 2015
  }, {
    "title": "Dynamic memory networks for visual and textual question answering",
    "authors": ["Caiming Xiong", "Stephen Merity", "Richard Socher."],
    "venue": "Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-",
    "year": 2016
  }, {
    "title": "Joint inference for fine-grained opinion extraction",
    "authors": ["Bishan Yang", "Claire Cardie."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association 1636",
    "year": 2013
  }, {
    "title": "A survey of collaborative filtering based social recommender systems",
    "authors": ["Xiwang Yang", "Yang Guo", "Yong Liu", "Harald Steck."],
    "venue": "Computer Communications, 41:1–10.",
    "year": 2014
  }, {
    "title": "Hierarchical attention networks for document classification",
    "authors": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."],
    "venue": "NAACL 2016, 15th Annual Conference of the North American Chapter of the Association for Computa-",
    "year": 2016
  }, {
    "title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis",
    "authors": ["Yongfeng Zhang", "Guokun Lai", "Min Zhang", "Yi Zhang", "Yiqun Liu", "Shaoping Ma."],
    "venue": "The 37th International ACM SIGIR Conference on Research and",
    "year": 2014
  }, {
    "title": "Stackpropagation: Improved representation learning for syntax",
    "authors": ["Yuan Zhang", "David Weiss."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016, August 7-12, 2016, Berlin, Germany, Vol-",
    "year": 2016
  }],
  "id": "SP:7b2c0632f9c7b3191616ca892035115cf66a2bd8",
  "authors": [{
    "name": "Zhongqing Wang",
    "affiliations": []
  }, {
    "name": "Yue Zhang",
    "affiliations": []
  }],
  "abstractText": "We present opinion recommendation, a novel task of jointly generating a review with a rating score that a certain user would give to a certain product which is unreviewed by the user, given existing reviews to the product by other users, and the reviews that the user has given to other products. A characteristic of opinion recommendation is the reliance of multiple data sources for multi-task joint learning. We use a single neural network to model users and products, generating customised product representations using a deep memory network, from which customised ratings and reviews are constructed jointly. Results show that our opinion recommendation system gives ratings that are closer to real user ratings on Yelp.com data compared with Yelp’s own ratings. our methods give better results compared to several pipelines baselines.",
  "title": "Opinion Recommendation Using A Neural Model"
}