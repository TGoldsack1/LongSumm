{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3654–3663 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n3654"
  }, {
    "heading": "1 Introduction",
    "text": "Sentiment analysis, a.k.a. opinion mining, is a task which aims to identify the user sentiment orientation of a product/brand/service by monitoring the online textual data, e.g., reviews and social media messages. It has attracted huge attention in both academic and industrial communities due to its widespread applications, such like recommendation (Zhang et al., 2014) and social media mining (Chambers et al., 2015). As the fundamental component in sentiment analysis, sentiment classification mainly classifies the sentiment polarity as positive or negative, and has been well-studied from both sentence-level (Kim and Hovy, 2004) and document-level (Xu et al., 2016).\n∗Corresponding author\nRecently, a new QA-style reviewing form, namely “customer questions & answers”, has become increasingly popular on the giant ecommerce platforms, e.g., Amazon and Taobao. In this new form, a potential customer asks question(s) about the target product/service while other experienced user(s) can provide answer(s). With the widespread of such QA-style reviews, users find a different channel to efficiently explore rich and useful information, and service providers and scholars are paying more attention to its specific characteristics comparing with traditional reviews (Wachsmuth et al., 2014; Zhou et al., 2015a). Comparing to the traditional reviews, the QA style reviews can be more informative and convincing. More importantly, because answer providers are randomly picked from the users who already purchased the target item, this new form of review can be more reliable and trustful.\nRegarding QA-style sentiment analysis, one straightforward method is to directly employ an existing sentiment classification approach that works well on traditional reviews, such as RNN (Nguyen and Shirai, 2015) and LSTM (Chen et al., 2016). However, because of the significant differences between QA-style and classical reviews, existing review mining algorithms, e.g., text-based sentiment analysis/classification, should not be di-\nrectly applied to this new kind of QA-style data. More detailed reasons can be found as the followings.\nFirst, in QA-style text, the question and answer text are more likely to be two parallel units rather than a sequence form. On the one hand, for instance, in Figure 1, sentence “It’s a nice phone with high-quality screen.” in Answer 1 actually does not follow sentence “How is the battery?” in Question 1 , but corresponds to sentence “Is the screen clear?” in Question 1. Therefore, when the question text and answer text are presented as two units in a sequence, it is rather difficult to capture the relationship between the question and its corresponding answer due to the possible long distance between them. On the other hand, there often exists both positive and negative sentiments in answer text according to different parts of question, and this specific case should be categorized as another category named conflict. For instance, in Figure 1, Answer 1 “It’s a nice phone with high-quality screen. But the battery is not durable.” is a conflict answer to Question 1. However, when this answer text is considered as a sequence, it is highly possible to be predicted as the category of positive or negative rather than conflict. In order to address these problems, a more appropriate approach is to segment both the question and answer text into some parallel sentences, and then construct the [Q-sentence, A-sentence] units in each QA text pair to detect in-depth sentiment information.\nSecond, although the main sentiment polarity is usually expressed from the answer text, the question text could also carry important sentiment tips to predict the sentiment polarity of a QA text pair. For instance, in Figure 1, we could hardly estimate the sentiment polarity solely based on Answer 2. However, when we take Question 2, “Is the sun cream really effective?”, into consideration, it can be easier to label this QA text pair with a negative tag. In this study, we propose an approach to match the sentences inside the question and answer text bidirectionally.\nThird, in each QA text pair, the importance degrees of different [Q-sentence, A-sentence] units can be different. For instance, in Figure 1, the [Qsentence, A-sentence] unit, i.e., sentence “Summer is coming, I’m afraid of getting darker.” in Answer 2 and sentence “No, just depending on my own experience.” in Question 2, makes tiny contribution to imply the sentiment polarity for the\nQA text pair. Therefore, a well-behaved network approach should consider the importance degrees of different [Q-sentence, A-sentence] units for predicting the sentiment polarity of a QA text pair.\nThe contribution of this paper is twofold. First, we propose a novel problem, QA-style sentiment analysis, and build a large-scale annotated corpus tailed for this task. The dataset is released to motivate future investigations for this track of research. Second, we propose a hierarchical matching network model to address the challenges of QA-style sentiment classification. Specifically, we first segment both the question and answer text into sentences and construct the [Q-sentence, A-sentence] units for each QA text pair. Then, by using a QA bidirectional matching layer, we encode each [Q-sentence, A-sentence] unit for exploring sentiment information. Finally, the self-matching attention layer in the model can capture the importance of these [Q-sentence, A-sentence] matching vectors obtained from QA bidirectional matching layer, which could effectively refine the evidence for inferring the sentiment polarity of a QA text pair. Experimental results show that the proposed approach significantly outperforms several strong baselines for QA-style sentiment classification."
  }, {
    "heading": "2 Related Work",
    "text": "Sentiment classification has become a hot research field in NLP since the pioneering work by Pang et al. (2002). In general, the research on traditional sentiment classification has been carried out in different text levels, such like word-level, documentlevel and aspect-level.\nWord-level sentiment classification has been studied in a long period in the research community of sentiment analysis. Some early studies have devoted their efforts to predicting the sentiment polarity of a word with different learning models and resources. Turney (2002) proposed an approach to predicting the sentiment polarity of words by calculating Pointwise Mutual Information (PMI) values between the seed words and the search hits. Hassan and Radev (2010) and Hassan et al. (2011) applied a Markov random walk model to determine the word polarities with a large word relatedness graph, and the synonyms and hypernyms in WordNet (Miller, 1995). More recently, some studies aim to learn better word embedding of a word rather than its polarity. Tang et al. (2014) developed three neural networks to learn word em-\nbedding by incorporating sentiment polarities of text in loss functions. Zhou et al. (2015b) employed both unsupervised and supervised neural networks to learn bilingual sentiment word embedding.\nDocument-level sentiment classification has also been studied in a long period in the research community of sentiment analysis. On one hand, many early studies have been devoted their efforts to various of aspects on learning approaches, such as supervised learning (Pang et al., 2002; Riloff et al., 2006), semi-supervised learning (Li et al., 2010; Xia et al., 2015; Li et al., 2015), and domain adaptation (Blitzer et al., 2007; He et al., 2011). On the other hand, many recent studies employ deep learning approaches to enhance the performances in sentiment classification. Tang et al. (2015) proposed a user-product neural network to incorporate both user and product information for sentiment classification. Xu et al. (2016) proposed a Cached Long Short-Term Memory neural networks (CLSTM) to capture the overall semantic information in long texts. More recently, Long et al. (2017) proposed a novel attention model, namely cognition-based attention, for sentiment classification.\nAspect-level sentiment classification is a relatively new research area in the research community of sentiment analysis and it is a fine-grained classification task. Recently, Wang et al. (2016) proposed an attention-based LSTM neural network to aspect-level sentiment classification by exploring the connection between an aspect and the content of a sentence. Tang et al. (2016) proposed a deep memory network with multiple attention-based computational layers to improve the performance. Wang et al. (2018) proposed a hierarchical attention network to explore both word-level and clause-level sentiment information towards a target aspect.\nUnlike all the prior studies, this paper focuses on a very different kind of text representation, i.e., QA-style text level, for sentiment classification. To the best of our knowledge, this is the first attempt to perform sentiment classification on this text level."
  }, {
    "heading": "3 Data Collection and Annotation",
    "text": "We collect QA text pairs from “Asking All” in Taobao (Alibaba)1, which is the world’s biggest ecommerce company. The QA text pairs are mainly from Beauty, Shoe and Electronic domains and each domain contains 10,000 QA text pairs.\nWe define four sentiment-related categories, i.e., positive, negative, conflict (both positive and negative sentiment) and neutral (neither positive nor negative sentiment). To guarantee a high annotation agreement, we propose some annotation guidelines after several times of annotation processes on a small size of data. Then, we ask more coders to annotate the whole data set according to these annotation guidelines.\nThe annotation guidelines contain two main groups. One contains the guidelines which aim to distinguish the categories of neutral and nonneutral, i.e., (a) A QA text pair in which the question and the answer do not match is annotated as a neutral sample. In this type of samples, the answer does not reply to the question correctly. E1 is an example of this type where the question talks about the screen while the answer talks about the battery.\nE1: Q: Is the screen clear? A: The battery life is decent.\n(b) A QA text pair with an unknown or uncertain answer is annotated as a neutral sample. E2 is an example of this type.\nE2: Q: What about these sneakers? A: I don’t know, I bought it for my dad.\n(c) A QA text pair with only objective description is annotated as a neutral sample. E3 is an example of this type.\nE3: Q: What’s the operation system of the phone? A: Android.\n(d) A QA text pair which compares two different products is annotated as a neutral sample. In this type of samples, two products are involved and it\n1https://www.taobao.com/\nis sometimes difficult to tell the sentiment orientation of one product. E4 is an example of this type.\nE4: Q: How about this phone when compared to iPhone 6s? A: It’s up to you, and they’re not comparable.\nThe other group contains the guidelines which aim to distinguish the categories of positive and negative, i.e., (e) If the answer text contains sentimental expressions to question like “disappointed”, “terrible”, and so on, we annotate it as negative. E5 is an example of this type.\nE5: Q: How is the rock climbing shoe? A: I am so disappointed, my feet felt hurt when I wore them.\n(f) If the answer text contains sentimental expressions to question like “perfect”, “satisfied”, and so on, we annotate it as positive. E6 is an example of this type.\nE6: Q: How about the fragrance? A: I am so satisfied, it smells distinctive.\n(g) If we cannot confirm the polarity of a QA text pair only depending on answer text, we annotate the polarity according to both the question and answer text. For instance, E7 is an example with positive polarity, while E8 is an example with negative polarity.\nE7: Q: Will the phone get hot when gaming? A: No.\nE8: Q: Is the sun cream really economic? A: No.\nWe assign two annotators to annotate each QA text pair, and the Kappa consistency check value of the annotation is 0.84. When annotators cannot reach an agreement, an expert will make the final decision, ensuring the quality of data annotation. Table 1 shows the category distribution of the corpus. To motivate other scholars to investigate this novel but important task, we share the data via Github2."
  }, {
    "heading": "4 Methodology",
    "text": "In this section, we introduce the proposed hierarchical matching network approach for QAstyle sentiment classification. Figure 2 depicts the overview of the proposed approach."
  }, {
    "heading": "4.1 QA Bidirectional Matching Mechanism",
    "text": "Word Encoding Layer: After sentence segmentation, the question text in a QA text pair contains N sentences, SQi represents the i-th sentence in the question text. Similarly, the answer text in this QA text pair contains M sentences, SAj represents the j-th sentence in the answer text. We then construct [Q-sentence, A-sentence] units by pairing one sentence in the question text and one sentence in the answer text, and we obtain N*M [Q-sentence, A-sentence] units at last.\nGiven a [SQi , SAj ] unit in this QA text pair, i.e., Q-sentence SQi with words wi,n, i ∈ [1, N ], n ∈\n2https://github.com/clshenNLP/QASC/\n[1, Ni] and A-sentence SAj with words wj,m, j ∈ [1,M ],m ∈ [1,Mj ], we first convert the words to their respective word embeddings (xi,n ∈ Rd, i ∈ [1, N ], n ∈ [1, Ni] and xj,m, j ∈ [1,M ],m ∈ [1,Mj ]). We then use Bi-directional LSTM (namely Bi-LSTM), which can efficiently make use of past features (via forward states) and future features (via backward states) for a specific time step, to get contextual representations of SQi and SAj individually. The representation of each word is formed by concatenating the forward and backward hidden states. For simplicity, we note contextual representation of SQi asHQi , and contextual representation of SAj as HAj respectively:\nHQi = [hi,1, hi,2, ..., hi,n, ..., hi,Ni ] (1)\nHAj = [hj,1, hj,2, ..., hj,m, ..., hj,Mj ] (2)\nwhere hi,n ∈ Rd ′\ndenotes the word representation in SQi at time step n, hj,m ∈ Rd ′ denotes the word representation in SAj at time step m, and d ′ is the dimensionality of word representation. QA Bidirectional Matching Layer: General neural network could not capture sentiment matching information in a [SQi , SAj ] unit well. For the sake of solving this problem, we introduce the QA bidirectional matching layer to encapsulate the clues and interactions between SQi and SAj synchronously (Tay et al., 2017; McCann et al., 2017). Figure 3 depicts the detail architecture of QA bidirectional matching mechanism. Specifically, we first calculate the bidirectional pair-wise matching matrix by using the fol-\nlowing formula:\nD[i,j] = (HQi) > · (HAj ) (3)\nwhere D[i,j] ∈ RNi×Mj denotes the bidirectional matching matrix for the [SQi , SAj ] unit. Each element in D[i,j] is the score that measures how well the word in SQi semantically matches the word in SAj and vice versa.\nGiven the bidirectional matching matrix D[i,j], we use attention mechanism (Yang et al., 2016; Cui et al., 2017) to mine the sentiment matching information between question and answer from two directions, which could be seen as an Answerto-Question attention and a Question-to-Answer attention as follows. • Answer-to-Question Attention: We employ row-wise operations to compute the attention weight vector αr[i,j] as follows:\nU r[i,j] = tanh(Wr ·D > [i,j]) (4)\nαr[i,j] = softmax(w > r · U r[i,j]) (5)\nwhere αr[i,j] ∈ R Ni is the Answer-to-Question attention weight vector regarding the importance degrees of all words in Q-sentence SQi , Wr ∈ Rd′×Mj and wr ∈ Rd ′ are weight matrices. After computing the Answer-to-Question attention weight vector, we can get the Answer-to-Question matching vector V r[i,j] ∈ R d′ as follows:\nV r[i,j] = (HQi) · α r [i,j] (6)\n• Question-to-Answer Attention: Simultaneously, we employ column-wise operations to calculate the attention weight vector αc[i,j] as follows:\nU c[i,j] = tanh(Wc ·D[i,j]) (7) αc[i,j] = softmax(w > c · U c[i,j]) (8)\nwhere αc[i,j] ∈ R Mj is the Question-to-Answer attention weight vector regarding the importance degrees of all words in A-sentence SAj , Wc ∈ Rd′×Ni and wc ∈ Rd ′ are weight matrices. After calculating the Question-to-Answer attention weight vector, we can get the Question-to-Answer matching vector V c[i,j] ∈ R d′ as follows:\nV c[i,j] = (HAj ) · α c [i,j] (9)\nThen, we combine Answer-to-Question and Question-to-Answer matching vectors to represent\nthe final bidirectional matching vector of the [SQi , SAj ] unit:\nV[i,j] = V r [i,j] ⊕ V c [i,j] (10)\nwhere ⊕ denotes the concatenate operator, and V[i,j] denotes the bidirectional matching vector which integrates SQi and SAj with each other."
  }, {
    "heading": "4.2 Self-Matching Attention Mechanism",
    "text": "Through the QA bidirectional matching layer, informative bidirectional matching vectors are generated to pinpoint the sentiment matching information in each [Q-sentence, A-sentence] unit. Intuitively, each matching vector for [Q-sentence, Asentence] unit holds different importance to a QA text pair. To better aggregate the evidence from these vectors for inferring the sentiment polarity of the QA text pair, we propose a self-matching attention layer, matching these informative vectors against themselves. Self-Matching Attention Layer: As aforementioned, we have obtained N*M bidirectional matching vectors through QA bidirectional matching layer, then we calculate the attention weight vector α with these matching vectors by following formulas:\nV = [V[1,1], V[1,2], ..., V[i,j], ..., V[N,M ]] (11)\nU = tanh(Wh · V ) (12) α = softmax(w>h · U) (13)\nwhere α is the attention weight vector which measures the importance of these matching vectors, Wh and wh are the weight matrices.\nFinally, we can get the QA text pair representation R as follows:\nR = V · α (14)"
  }, {
    "heading": "4.3 Classification Model",
    "text": "QA text pair representationR is a high level representation which can be used for classification. In our approach, we feed R to a softmax classifier:\np = softmax(Wl ·R+ bl) (15)\nwhere p is a set of predicted distribution of the sentiment categories, i.e., positive, negative, neutral, and conflict. Wl is the weight matrix and bl is the bias.\nTo learn the whole model, we train an end-toend model given the training data, and the goal of\ntraining is to minimize the cross-entropy loss, i.e.,\nL(θ) = − S∑\ns=1 K∑ k=1 yks · logŷks + λ‖θ‖ 2 2 (16)\nwhere S is the number of training data. ys is the true sentiment label of the s-th sample. ŷs is the predicted sentiment label of the s-th sample. K is number of all sentiment categories. λ is a L2regularization term, θ is the parameter set. In the above equation, the model parameters are optimized by using Adam (Kingma and Ba, 2014)."
  }, {
    "heading": "5 Experimentation",
    "text": "In this section, we evaluate the performances of the proposed approach for QA-style sentiment classification."
  }, {
    "heading": "5.1 Experimental Settings",
    "text": "• Data Sets: As introduced in Section 3, the annotated QA text pairs cover three different domains. In each domain, we randomly split the data into a training set (80% in each category) and a test set (20% in each category). In addition, we set aside 10% from the training set as the development data for parameters tuning. • Word Segmentation and Embeddings: FudanNLP3 (Qiu et al., 2013) is employed to segment text into Chinese words and word2vec4 (Mikolov et al., 2013) is employed to pre-train word embeddings. The vector dimensionality is set to be 100. • Sentence Segmentation: CoreNLP5 (Manning et al., 2014) is employed to segment both the question and answer text into sentences. • Hyper-parameters: In the experiment, all outof-vocabulary words are initialized by sampling from the uniform distribution U(−0.01, 0.01). All weight matrices are given their initial values by sampling from uniform distribution U(−0.01, 0.01). The LSTM hidden states are set to be 128 and all models are trained by mini-batch of 32 instances. The dropout rate is set to 0.2. The other hyper-parameters are tuned according to the development data. • Evaluation Metric: The performance is evaluated using standard Accuracy and Macro-F1.\n3https://github.com/FudanNLP/fnlp/ 4https://code.google.com/archive/p/word2vec/ 5http://stanfordnlp.github.io/CoreNLP/"
  }, {
    "heading": "5.2 Experimental Results",
    "text": "The following baseline approaches are employed for comparison. Note that all the approaches share the same word embeddings for fair comparison. • SVM: This baseline employs support vector machine along with word embedding features. The question and answer text in a QA text pair are chained as a sequence. • LSTM: A standard LSTM model utilizes word embeddings and concatenates the question and answer text as a sequence. • Bi-LSTM: A bidirectional LSTM model which concatenates the question and answer text as a sequence. • Bidirectional-Match: This approach employs QA bidirectional matching mechanism, without taking the sentence segmentation strategy and selfmatching attention mechanism. • AtoQ-Match: This approach takes the sentence segmentation strategy, and employs QA unidirectional matching mechanism (i.e., only using Answer-to-Question attention), but does not employ self-matching attention mechanism. We average the Answer-to-Question matching vectors to represent the QA text pair. • QtoA-Match: This approach takes the sentence segmentation strategy, and employs QA unidirectional matching mechanism (i.e., only using Question-to-Answer attention), but does not employ self-matching attention mechanism. • Bidirectional-Match QA: This approach takes the sentence segmentation strategy, and employs QA bidirectional matching mechanism, but does not employ self-matching attention mechanism. • HMN: This is our hierarchical matching network model which takes the sentence segmentation strategy and employs both QA bidirectional matching mechanism and self-matching attention mechanism.\nTable 2 summarizes the experimental results of all the approaches above, and we can find that:\n(1) All LSTM-based approaches are superior to SVM, indicating the effectiveness of neural network for this task. (2) The proposed approaches, with novel QA contextual representation, outperform the other baseline approaches. (3) When only employing QA bidirectional matching mechanism, Bidirectional-Match QA, which takes the sentence segmentation strategy, consistently outperforms Bidirectional-Match (without sentence segmentation) in all domains. It confirms our hypothesis that sentence segmentation helps to extract the sentiment matching information between the question and answer. (4) When comparing to QA unidirectional matching mechanism, Bidirectional-Match QA, which employs QA bidirectional matching mechanism, performs better than AtoQMatch and QtoA-Match. It confirms our hypothesis that both the question and answer information contribute to sentiment polarity of the QA text pair. (5) Impressively, the proposed approach HMN significantly outperforms all the other approaches in all domains (p-value<0.05 via ttest). It verifies the advantages of both QA bidirectional matching mechanism and selfmatching attention mechanism for this task.\nBesides, we also implement some more recent state-of-the-art approaches for sentiment classification, which are illustrated in Table 3. This result also supports the earlier findings.\n• CNN-Tensor (Lei et al., 2015): This is a stateof-the-art approach to sentence-level sentiment classification, which models n-gram interactions based on tensor product and evaluates all non-\nconsecutive n-gram vectors as a feature mapping operator for CNNs. • Attention-LSTM (Wang et al., 2016): This is a state-of-the-art approach to aspect-level sentiment classification. In our implementation, we ignore the aspect embedding and directly use the outputs of LSTM to yield the attention. • BiMPM (Wang et al., 2017): This is a state-ofthe-art approach to QA matching, which matches the question and answer from multiple perspectives. In our implementation, we use the matching representation to perform QA-style sentiment classification with a softmax classifier. • HMN: The proposed hierarchical matching network which employs both QA bidirectional matching mechanism and self-matching attention mechanism, and takes the sentence segmentation strategy.\nTable 3 shows the comparison results of these strong baseline approaches and the proposed approach (HMN) in all domains. From this table, we can find that: (1) the approaches that take matching strategy, i.e., BiMPM and our approach (HMN), outperform other approaches. (2) The proposed approach (HMN) significantly outperforms all the other baseline approaches in terms of both Macro-F1 and Accuracy (p-value<0.05 via ttest), which confirms the initial hypotheses of this study."
  }, {
    "heading": "5.3 Case Study",
    "text": "Table 4 shows some examples, along with the predicted categories via different approaches. We can find that: (1) the approaches based on matching strategy (BiMPM and HMN) are well-performed, as shown in E9, when question and answer carrying different kinds of information. This is a unique challenge for QA-style sentiment mining, and traditional sentiment classification approaches can hardly address this problem. (2) The proposed approach (HMN) performs better than other approaches when dealing with conflict instances, as shown in E10."
  }, {
    "heading": "5.4 Visualization of Attention",
    "text": "To get a better understanding of our proposed hierarchical matching network for QA-style sentiment classification, we picture the attention weights obtained from Equations (5), (8) and (13). For\nsimplicity, we directly use the English translation of E11 for illustration and adopt the visualization approach presented by Yang et al. (2016), as shown in Figure 2. Specifically, each line is a [Qsentence, A-sentence] unit, where the red denotes the [Q-sentence, A-sentence] unit weight, the blue denotes the word weight in each [Q-sentence, Asentence], and the color depth indicates the importance of attention weights (the darker the more important).\nFrom Figure 4, we can see that the QA bidirectional matching layer always assigns reasonable attention weights to words in each [Q-sentence, Asentence] unit which makes sentence from question and sentence from answer match correctly. In addition, the self-matching attention layer is able to select informative [Q-sentence, A-sentence] unit for predicting true sentiment polarity of this example."
  }, {
    "heading": "6 Conclusion",
    "text": "In this paper, we propose a novel but important sentiment analysis task, i.e., QA-style sentiment mining, and we build a large-scale highquality human annotated corpus for experiment. The dataset is shared to encourage other scholars to investigate this interesting problem. Moreover, we propose a hierarchical matching neural network model to enable QA bidirectional matching mechanism and self-matching attention mechanism for this task. Empirical studies show that the proposed approach significantly outperforms other strong baseline approaches in all the test domains for QA-style sentiment classification.\nIn the future, we would like to investigate some other network structures to explore deeper information in each QA text pair. Besides, we would like to test the effectiveness of the proposed approach to QA-style sentiment classification in some other languages."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to thank the anonymous reviewers for their valuable comments. This work is partially supported by the National Key R&D Program of China under Grant No.2017YFB1002101 and two NSFC grants No.61331011, No.61672366. This work is also supported by the joint research project of Alibaba Group and Soochow University."
  }],
  "year": 2018,
  "references": [{
    "title": "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification",
    "authors": ["John Blitzer", "Mark Dredze", "Fernando Pereira."],
    "venue": "Proceedings of ACL-2007, pages 440– 447.",
    "year": 2007
  }, {
    "title": "Identifying political sentiment between nation states with social media",
    "authors": ["Nathanael Chambers", "Victor Bowen", "Ethan Genco", "Xisen Tian", "Eric Young", "Ganesh Harihara", "Eugene Yang."],
    "venue": "Proceedings of EMNLP-2015, pages 65–75.",
    "year": 2015
  }, {
    "title": "Enhancing and combining sequential and tree LSTM for natural language inference",
    "authors": ["Qian Chen", "Xiaodan Zhu", "Zhenhua Ling", "Si Wei", "Hui Jiang."],
    "venue": "arXiv preprint arXiv:1609.06038.",
    "year": 2016
  }, {
    "title": "Attention-overattention neural networks for reading comprehension",
    "authors": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu."],
    "venue": "Proceedings of ACL-2017, pages 593–602.",
    "year": 2017
  }, {
    "title": "Identifying the semantic orientation of foreign words",
    "authors": ["Ahmed Hassan", "Amjad Abu-Jbara", "Rahul Jha", "Dragomir Radev."],
    "venue": "Proceedings of ACL-2011, pages 592–597.",
    "year": 2011
  }, {
    "title": "Identifying text polarity using random walks",
    "authors": ["Ahmed Hassan", "Dragomir Radev."],
    "venue": "Proceedings of ACL-2010, pages 395–403.",
    "year": 2010
  }, {
    "title": "Automatically extracting polarity-bearing topics for cross-domain sentiment classification",
    "authors": ["Yulan He", "Chenghua Lin", "Harith Alani."],
    "venue": "Proceedings of ACL-2011, pages 123–131.",
    "year": 2011
  }, {
    "title": "Determining the sentiment of opinions",
    "authors": ["Soo-Min Kim", "Eduard Hovy."],
    "venue": "Proceedings of COLING-2004, pages 1367–1374.",
    "year": 2004
  }, {
    "title": "Adam: A method for stochastic optimization",
    "authors": ["Diederik P Kingma", "Jimmy Ba."],
    "venue": "arXiv preprint arXiv:1412.6980.",
    "year": 2014
  }, {
    "title": "Molding CNNs for text: non-linear, non-consecutive convolutions",
    "authors": ["Tao Lei", "Regina Barzilay", "Tommi Jaakkola."],
    "venue": "Proceedings of EMNLP-2015, pages 1565–1575.",
    "year": 2015
  }, {
    "title": "Employing personal/impersonal views in supervised and semisupervised sentiment classification",
    "authors": ["Shoushan Li", "Chu-Ren Huang", "Guodong Zhou", "Sophia Yat Mei Lee."],
    "venue": "Proceedings of ACL-2010, pages 414–423.",
    "year": 2010
  }, {
    "title": "Semi-stacking for semi-supervised sentiment classification",
    "authors": ["Shoushan Li", "Lei Huang", "Jingjing Wang", "Guodong Zhou."],
    "venue": "Proceedings of ACLIJCNLP-2015, pages 27–31.",
    "year": 2015
  }, {
    "title": "A cognition based attention model for sentiment analysis",
    "authors": ["Yunfei Long", "Lu Qin", "Rong Xiang", "Minglei Li", "Chu-Ren Huang."],
    "venue": "Proceedings of EMNLP-2017, pages 462–471.",
    "year": 2017
  }, {
    "title": "The stanford CoreNLP natural language processing toolkit",
    "authors": ["Christopher Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven Bethard", "David McClosky."],
    "venue": "Proceedings of ACL-2014, pages 55–60.",
    "year": 2014
  }, {
    "title": "Learned in translation: Contextualized word vectors",
    "authors": ["Bryan McCann", "James Bradbury", "Caiming Xiong", "Richard Socher."],
    "venue": "Proceedings of NIPS2017, pages 6294–6305.",
    "year": 2017
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "Proceedings of NIPS-2013, pages 3111– 3119.",
    "year": 2013
  }, {
    "title": "Wordnet: a lexical database for English",
    "authors": ["George A Miller."],
    "venue": "Communications of the ACM, 38(11):39–",
    "year": 1995
  }, {
    "title": "Phrasernn: Phrase recursive neural network for aspect-based sentiment analysis",
    "authors": ["Thien Hai Nguyen", "Kiyoaki Shirai."],
    "venue": "Proceedings of EMNLP-2015, pages 2509–2514.",
    "year": 2015
  }, {
    "title": "Thumbs up?: sentiment classification using machine learning techniques",
    "authors": ["Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan."],
    "venue": "Proceedings of ACL-2002, pages 79–86.",
    "year": 2002
  }, {
    "title": "FudanNLP: A toolkit for Chinese natural language processing",
    "authors": ["Xipeng Qiu", "Qi Zhang", "Xuanjing Huang."],
    "venue": "Proceedings of ACL-2013, pages 49–",
    "year": 2013
  }, {
    "title": "Feature subsumption for opinion analysis",
    "authors": ["Ellen Riloff", "Siddharth Patwardhan", "Janyce Wiebe."],
    "venue": "Proceedings of EMNLP-2006, pages 440–448.",
    "year": 2006
  }, {
    "title": "Learning semantic representations of users and products for document level sentiment classification",
    "authors": ["Duyu Tang", "Bing Qin", "Ting Liu."],
    "venue": "Proceedings of ACL-IJCNLP-2015, pages 1014–1023.",
    "year": 2015
  }, {
    "title": "Aspect level sentiment classification with deep memory network",
    "authors": ["Duyu Tang", "Bing Qin", "Ting Liu."],
    "venue": "Proceedings of EMNLP-2016, pages 214– 224.",
    "year": 2016
  }, {
    "title": "Learning sentimentspecific word embedding for twitter sentiment classification",
    "authors": ["Duyu Tang", "Furu Wei", "Nan Yang", "Ming Zhou", "Ting Liu", "Bing Qin."],
    "venue": "Proceedings of ACL-2014, pages 1555–1565.",
    "year": 2014
  }, {
    "title": "A compare-propagate architecture with alignment factorization for natural language inference",
    "authors": ["Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui."],
    "venue": "arXiv preprint arXiv:1801.00102.",
    "year": 2017
  }, {
    "title": "Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews",
    "authors": ["Peter D Turney."],
    "venue": "Proceedings of ACL-2002, pages 417–424.",
    "year": 2002
  }, {
    "title": "Modeling review argumentation for robust sentiment analysis",
    "authors": ["Henning Wachsmuth", "Martin Trenkmann", "Benno Stein", "Gregor Engels."],
    "venue": "Proceedings of COLING-2014, pages 553–564.",
    "year": 2014
  }, {
    "title": "Aspect sentiment classification with both word-level and clause-level attention networks",
    "authors": ["Jingjing Wang", "Jie Li", "Shoushan Li", "Yangyang Kang", "Min Zhang", "Luo Si", "Guodong Zhou."],
    "venue": "Proceedings of IJCAI-2018, pages 4439–4445.",
    "year": 2018
  }, {
    "title": "Attention-based LSTM for aspectlevel sentiment classification",
    "authors": ["Yequan Wang", "Minlie Huang", "Li Zhao", "Zhu Xiaoyan."],
    "venue": "Proceedings of EMNLP-2016, pages 606–615.",
    "year": 2016
  }, {
    "title": "Bilateral multi-perspective matching for natural language sentences",
    "authors": ["Zhiguo Wang", "Wael Hamza", "Radu Florian."],
    "venue": "Proceedings of IJCAI-2017, pages 4144–4150.",
    "year": 2017
  }, {
    "title": "Co-training for semi-supervised sentiment classification based on dual-view bags-of-words representation",
    "authors": ["Rui Xia", "Cheng Wang", "Xin-Yu Dai", "Tao Li."],
    "venue": "Proceedings of ACL-IJCNLP-2015, pages 1054–1063.",
    "year": 2015
  }, {
    "title": "Cached long short-term memory neural networks for document-level sentiment classification",
    "authors": ["Jiacheng Xu", "Danlu Chen", "Xipeng Qiu", "Xuanjing Huang."],
    "venue": "Proceedings of EMNLP-2016, pages 1660–1669.",
    "year": 2016
  }, {
    "title": "Hierarchical attention networks for document classification",
    "authors": ["Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy."],
    "venue": "Proceedings of NAACL-HLT-2016, pages 1480– 1489.",
    "year": 2016
  }, {
    "title": "Explicit factor models for explainable recommendation based on phrase-level sentiment analysis",
    "authors": ["Yongfeng Zhang", "Guokun Lai", "Min Zhang", "Yi Zhang", "Yiqun Liu", "Shaoping Ma."],
    "venue": "Proceedings of SIGIR-2014, pages 83–92.",
    "year": 2014
  }, {
    "title": "A subspace learning framework for cross-lingual sentiment classification with partial parallel data",
    "authors": ["Guangyou Zhou", "Tingting He", "Jun Zhao", "Wensheng Wu."],
    "venue": "Proceedings of IJCAI-2015, pages 1426–1433.",
    "year": 2015
  }, {
    "title": "Learning bilingual sentiment word embeddings for cross-language sentiment classification",
    "authors": ["Huiwei Zhou", "Long Chen", "Fulin Shi", "Degen Huang."],
    "venue": "Proceedings of ACL-IJCNLP-2015, pages 430–440.",
    "year": 2015
  }],
  "id": "SP:81d50610638bcd2011622c51a3e56055b0fde290",
  "authors": [{
    "name": "Chenlin Shen",
    "affiliations": []
  }, {
    "name": "Changlong Sun",
    "affiliations": []
  }, {
    "name": "Jingjing Wang",
    "affiliations": []
  }, {
    "name": "Yangyang Kang",
    "affiliations": []
  }, {
    "name": "Shoushan Li",
    "affiliations": []
  }, {
    "name": "Xiaozhong Liu",
    "affiliations": []
  }, {
    "name": "Luo Si",
    "affiliations": []
  }, {
    "name": "Min Zhang",
    "affiliations": []
  }, {
    "name": "Guodong Zhou",
    "affiliations": []
  }],
  "abstractText": "In an e-commerce environment, user-oriented question-answering (QA) text pair could carry rich sentiment information. In this study, we propose a novel task/method to address QA sentiment analysis. In particular, we create a high-quality annotated corpus with speciallydesigned annotation guidelines for QA-style sentiment classification. On the basis, we propose a three-stage hierarchical matching network to explore deep sentiment information in a QA text pair. First, we segment both the question and answer text into sentences and construct a number of [Q-sentence, Asentence] units in each QA text pair. Then, by leveraging a QA bidirectional matching layer, the proposed approach can learn the matching vectors of each [Q-sentence, A-sentence] unit. Finally, we characterize the importance of the generated matching vectors via a selfmatching attention layer. Experimental results, comparing with a number of state-ofthe-art baselines, demonstrate the impressive effectiveness of the proposed approach for QA-style sentiment classification.",
  "title": "Sentiment Classification towards Question-Answering with Hierarchical Matching Network"
}