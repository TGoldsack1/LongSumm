{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1247–1256 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n1247\nral language processing. In the real world, it is a common phenomenon that multiple events existing in the same sentence, where extracting them are more difficult than extracting a single event. Previous works on modeling the associations between events by sequential modeling methods suffer a lot from the low efficiency in capturing very long-range dependencies. In this paper, we propose a novel Jointly Multiple Events Extraction (JMEE) framework to jointly extract multiple event triggers and arguments by introducing syntactic shortcut arcs to enhance information flow and attention-based graph convolution networks to model graph information. The experiment results demonstrate that our proposed framework achieves competitive results compared with state-of-the-art methods."
  }, {
    "heading": "1 Introduction",
    "text": "Extracting events from natural language text is an essential yet challenging task for natural language understanding. When given a document, event extraction systems need to recognize event triggers with their specific types and their corresponding arguments with the roles. Technically speaking, as defined by the ACE 2005 dataset1, a benchmark for event extraction (Grishman et al., 2005), the event extraction task can be divided into two subtasks, i.e., event detection (identifying and classifying event triggers) and argument extraction (identifying arguments of event triggers and labeling their roles).\nIn event extraction, it is a common phenomenon that multiple events exist in the same sentence. Extracting the correct multiple events from those\n∗*Corresponding author. 1https://catalog.ldc.upenn.edu/\nldc2006t06\nsentences is much more difficult than in the oneevent-one-sentence cases because those various types of events are often associated with each other. For example, in the sentence “He left the company, and planned to go home directly.”, the trigger word left may trigger a Transport (a person left a place) event or an End-Position (a person retired from a company) event. However, if we take the following event triggered by go into consideration, we are more confident to judge it as a Transport event rather than an End-Position event. This phenomenon is quite common in our real world, as Injure and Die events are more likely to co-occur with Attack events than others, whereas Marry and Born events are less likely to co-occur with Attack events. As we investigated in ACE 2005 dataset, there are around 26.2% (1042/3978) sentences belong to this category.\nSignificant efforts have been dedicated to solving this problem. Most of them exploiting various features (Liu et al., 2016b; Yang and Mitchell, 2016; Li et al., 2013; Keith et al., 2017; Liu et al., 2016a; Li et al., 2015), introducing memory vectors and matrices (Nguyen et al., 2016), introducing more transition arcs (Sha et al., 2018), keeping more contextual information (Chen et al., 2015) into sentence-level sequential modeling methods like RNNs and CRFs. Some also seek features in document-level methods (Liao and Grishman, 2010; Ji and Grishman, 2008). However, sentencelevel sequential modeling methods suffer a lot from the low efficiency in capturing very longrange dependencies while the feature-based methods require extensive human engineering, which also largely affects model performance. Besides, these methods do not adequately model the associations between events.\nAn intuitive way to alleviate this phenomenon is to introduce shortcut arcs represented by linguistic resources like dependency parsing trees to\ndrain the information flow from a point to its target through fewer transitions. Comparing to sequential order, modeling with these arcs often successfully reduce the needed hops from one event trigger to another in the same sentences. In Figure 1, for example, there are two events: a Die event triggered by the word killed with four arguments in red and an Attack event triggered by the word barrage with three arguments in blue. We need six hops from killed to barrage according to sequential order, but only three hops according to the arcs in dependency parsing tree (along the nmodarc from killed to witnesses, along the acl-arc from witnesses to called, and along the xcomp-arc from called to barrage). These three arcs consist of a shortcut path2, draining the dependency syntactic information flow from killed to barrage with fewer hops3.\nIn this paper, we propose a novel Jointly Multiple Events Extraction (JMEE) framework by introducing syntactic shortcut arcs to enhance information flow and attention-based graphic convolution networks to model the graph information. To implement modeling with the shortcut arcs, we adopt the graph convolutional networks (GCNs) (Kipf and Welling, 2016; Marcheggiani and Titov, 2017; Nguyen and Grishman, 2018) to learn syntactic contextual representations of each node by the representative vectors of its immediate neighbors in the graph. And then we utilize the syntactic contextual representations to extract triggers and arguments jointly by a self-attention mechanism to aggregate information especially keeping the associations between multiple events.\n2In a shortcut path which consists of existing arcs, some arcs may reverse their directions.\n3The length of the longest path in a tree is always no more than the sequential length consisting of the same number of nodes, which means even in the worst cases, the shortcut path will not perform worse than sequential modeling.\nWe extensively evaluate the proposed JMEE framework with the widely-used ACE 2005 dataset to demonstrate its benefits in the experiments especially in capturing the associations between events. To summary, our contribution in this work is as follows:\n• We propose a novel joint event extraction framework JMEE based on syntactic struc-\ntures which enhance information flow and alleviate the phenomenon where multiple events are in the same sentence.\n• We propose a self-attention mechanism to aggregate information especially keeping the\nassociations between multiple events and prove it is useful in event extraction.\n• We achieve the state-of-the-art performance on the widely used datasets for event extrac-\ntion using the proposed model with GCNs and self-attention mechanism."
  }, {
    "heading": "2 Approach",
    "text": "Generally, event extraction can be cast as a multiclass classification problem deciding whether each word in the sentence forms a part of event trigger candidate and whether each entity in the sentence plays a particular role in the event triggered by the candidate triggers. There are two main approaches to event extraction: (i) the joint approach that extracts event triggers and arguments simultaneously as a structured prediction problem, and (ii) the pipelined approach that first performs trigger prediction and then identifies arguments in separate stages. We follow the joint approach that can effectively avoid the propagated errors in the pipeline.\nAdditionally, we extract events in sentencelevel mainly for three reasons. Firstly, in our in-\n• The positional embedding vector of wi: If wc is the current word, we encode the rela-\ntive distance i − c from wi to wc as a realvalued vector by looking up the randomly initialized position embedding table (Nguyen et al., 2016; Liu et al., 2017; Nguyen and Grishman, 2018).\n• The entity type label embedding vector of wi: Similarly to the POS-tagging label em-\nbedding vector of wi, we annotate the entity mentions in a sentence using BIO annotation schema and transform the entity type labels to real-valued vectors by looking up the embedding table. It should be noticed that we use the whole entity extent in ACE 2005 dataset which contains overlapping entity mentions and we sum all the possible entity type label embedding vectors for each token.\nThe transformation from the token wi to the vector xi essentially converts the input sentence W into a sequence of real-valued vectors X = (x1, x2, ..., xn), which will be feed into later modules to learn more effective representations for event extraction."
  }, {
    "heading": "2.2 Syntactic Graph Convolution Network",
    "text": "Considering an undirected graph G = (V, E) as the syntactic parsing tree for sentence W , where V = v1, v2, ..., vn(|V| = n) and E are sets of nodes and edges, respectively. In V , each vi is the node representing token wi in W . Each edge (vi, vj) ∈ E is a directed syntactic arc from token wi to token wj , with the type label K(wi, wj). Additionally, to allow information to flow against the direction, we also\nadd reversed edge (vj , vi) with the type label K ′(wi, wj). Following Kipf and Welling (2016), we also add all the self-loops, i.e., (vi, vi) for any vi ∈ V . For example, in the dependency parsing tree shown in Figure 1, there are four arcs in the subgraph with only two nodes “killed” and “witnesses”: the dependency arc with the type label K(“killed”, “witnesses”) = nmod, the revresed dependency arc with the additional type label K(“witnesses”, “killed”) = nmod′, and the two self-loops of “killed” and “witnesses” with type label K(“killed”, “killed”) = K(“witnesses”, “witnesses”) = loop.\nTherefore, in the k-th layer of syntactic graph convolution network module, we can calculate the graph convolution vector h (k+1) v for node v ∈ V by:\nh(k+1)v = f( ∑\nu∈N (v)\n(W (k) K(u,v)h (k) u + b (k) K(u,v))) (1)\nwhere K(u, v) indicates the type label of the edge (u, v); W (k) K(u,v) and b (k) K(u,v) are the weight matrix and the bias for the certain type label K(u, v), respectively; N (v) is the set of neighbors of v including v (because of the self-loop); f is the activation function. Moreover, we use the output of the word representation module xi to initialize the node representation h0vi of the first layer of GCNs.\nAfter applying the above two changes, the number of predefined directed arc type label (let us say, N ) will be doubled (to 2N + 1). It means we will have 2N +1 sets of parameter pairs W (k) k and b (k) k for a single layer of GCN. In this work, we use Stanford Parser (Klein and Manning, 2003) to generate the arcs in dependency parsing trees for sentences as the shortcut arcs. The current representa-\ntion contains approximately 50 different grammatical relations, which is too high for the parameter number of a single layer of GCN and not compatible with the existing training data scale. To reduce the parameter numbers, following Marcheggiani and Titov (2017), we modify the definition of type label K(wi, wj) to:\nK(wi, wj) =\n\n\n along, (vi, vj) ∈ E rev, i! = j&(vj , vi) ∈ E loop, i == j\n(2)\nwhere the new K(wi, wj) only have three type labels.\nAs not all types of edges are equally informative for the downstream task, moreover, there are also noises in the generated syntactic parsing structures; we apply gates on the edges to weight their individual importances. Inspired by Dauphin et al. (2017); Marcheggiani and Titov (2017), we calculate a weight g (k) u,v for each edge (u, v) indicating the importance for event extraction by:\ng(k)u,v = σ(h (k) u V (k) K(u,v) + d (k) K(u,v)) (3)\nwhere σ is the logistic sigmoid function, V (k) K(u,v) and d (k) K(u,v) are the weight matrix and the bias of the gate. With this additional gating mechanism, the final syntactic GCN computation is formulated as\nh(k+1)v = f( ∑\nu∈N (v)\ng(k)u,v(W (k) K(u,v)h (k) u + b (k) K(u,v)))\n(4)\nAs stacking k layers of GCNs can model information in k hops, and sometimes the length of shortcut path between two triggers is less than k, to avoid information over-propagating, we adapt highway units (Srivastava et al., 2015), which allow unimpeded information flowing across stacking GCN layers. Typically, highway layers conduct nonlinear transformation as:\nt = σ(WTh k v + bT ) (5)\nh (k+1) v = h (k+1) v +t⊙g(WHh k v+bH)+(1−t)⊙h k v\n(6)\nwhere σ is the sigmoid function; ⊙ is the elementwise product operation; g is a nonlinear activation function; t is called transform gate and (1 − t) is\ncalled carry gate. Therefore, the input of the k-th GCN layers should be h (k) instead of h(k).\nThe GCNs are designed to capture the dependencies between shortcut arcs, while the layer number of GCNs limits the ability to capture local graph information. However, in this cases, we find that leveraging local sequential context will help to expand the information flow without increasing the layer number of GCNs, which means LSTMs and GCNs maybe complementary. Therefore, instead of feeding the word representation X = (x1, x2, ..., xn) into the first GCN layer, we follow Marcheggiani and Titov (2017), apply Bidirectional LSTM (Bi-LSTM) (Hochreiter and Schmidhuber, 1997) to encode the the word representation X as:\n−→p t = −−−−→ LSTM(−→p t−1, xt) (7) ←−p t = ←−−−− LSTM(←−p t−1, xt) (8)\nand the input of t-th token to GCNs is xt = [−→p t,\n←−p t], where [, ] is the concatenation operation. The Bi-LSTM adaptively accumulates and abstracts the context for each token in the sentence."
  }, {
    "heading": "2.3 Self-Attention Trigger Classification",
    "text": "When taking each token as the current word, we get the representation D from all tokens calculated by GCNs. Traditional event extraction systems often use max-pooling or its amelioration to aggregate information to each position. However, the max-pooling aggregation mechanisms tend to produce similar results after GCN modules in our framework. For example, if we get the aggregated vector Agi at each position i by this max-pooling mechanism Agi = max pooling n j=1(Hj) with the GCNs output {Hj |j = 1, ..., n} in which n is the sentence length, and the vector Agi is all the same at each position. Besides, predicting a trigger label for a token should take other possible trigger candidates into consideration. To capture the associations between triggers in a sentence, we design a self-attention mechanism to aggregate information especially keeping the associations between multiple events.\nGiven the current token wi, the self-attention score vector and the context vector at position i are calculated as:\nscore = norm(exp(W2f(W1D+b1)+b2)) (9)\nCi = [ n ∑\nj=1,j!=i\nscorej ∗Dj , Di] (10)\nwhere norm means the normalization operation. Then we feed the context vector Ci into a fullyconnected network to predict the trigger label in BIO annotation schema as:\nCi = f(WcCi + bc) (11)\nyti = softmax(WtCi + bt) (12)\nwhere f is a non-linear activation and yti is the final output of the i-th trigger label."
  }, {
    "heading": "2.4 Argument Classification",
    "text": "When we have extracted an entire trigger candidate, which is meeting an O label after an I-Type label or a B-Type label, we use the aggregated context vector C to perform argument classification on the entity list in the sentence.\nFor each entity-trigger pair, as both the entity and the trigger candidate are likely to be a subsequence of tokens, we aggregate the context vectors of subsequences to trigger candidate vector Ti and entity vector Ej by average pooling along the sequence length dimension. Then we concatenate them together and feed into a fully-connected network to predict the argument role as:\nyaij = softmax(Wa[Ti, Ej ] + ba) (13)\nwhere yaij is the final output of which role the jth entity plays in the event triggered by the i-th trigger candidate.\nWhen training our framework, if the trigger candidate that we focus on is not a correct trigger, we set all the golden argument labels concerning the trigger candidate to OTHER (not any roles). With this setting, the labels of the trigger candidate will be further adjusted to reach a reasonable probability distribution."
  }, {
    "heading": "2.5 Biased Loss Function",
    "text": "In order to train the networks, we minimize the joint negative log-likelihood loss function. Due to the data sparsity in the ACE 2005 dataset, we adapt our joint negative log-likelihood loss func-\ntion by adding a bias item as:\nJ(θ) = − N ∑\np=1\n(\nnp ∑\ni=1\nI(yti)log(p(yti |θ))\n+β\ntp ∑\ni=1\nep ∑\nj=1\nlog(p(yaij |θ)))\n(14)\nwhere N is the number of sentences in training corpus; np, tp and ep are the number of tokens, extracted trigger candidates and entities of the p-th sentence; I(yti) is an indicating function, if yti is not O, it outputs a fixed positive floating number α bigger than one, otherwise one; β is also a floating number as a hyper-parameter like α."
  }, {
    "heading": "3 Experiments",
    "text": ""
  }, {
    "heading": "3.1 Experiment Settings",
    "text": "Dataset, Resources and Evaluation Metric We evaluate our JMEE framework on the ACE 2005 dataset. The ACE 2005 dataset annotate 33 event subtypes and 36 role classes, along with the NONE class and BIO annotation schema, we will classify each token into 67 categories in event detection and 37 categories in argument extraction. To comply with previous work, we use the same data split as the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Liu et al., 2016b; Yang and Mitchell, 2016; Nguyen et al., 2016; Sha et al., 2018). This data split includes 40 newswire articles (881 sentences) for the test set, 30 other documents (1087 sentences) for the development set and 529 remaining documents (21,090 sentences) for the training set.\nWe deploy the Stanford CoreNLP toolkit5 to preprocess the data, including tokenizing, sentence splitting, pos-tagging and generating dependency parsing trees.\nAlso, we follow the criteria of the previous work (Ji and Grishman, 2008; Liao and Grishman, 2010; Li et al., 2013; Chen et al., 2015; Liu et al., 2016b; Yang and Mitchell, 2016; Nguyen et al., 2016; Sha et al., 2018) to judge the correctness of the predicted event mentions. Hyperparameter Setting For all the experiments below, in the word representation module, we use 300 dimensions for the embeddings and 50 dimensions for the rest\n5http://stanfordnlp.github.io/CoreNLP/\nthree embeddings including pos-tagging embedding, positional embedding and entity type embedding. In the syntactic GCN module, we use a three-layer GCN, a one-layer Bi-LSTM with 220 hidden units, self-attention with 300 hidden units and 200 hidden units for the rest transformation. We also set dropout rate to 0.5 and L2-norm to 1e8. The batch size in our experiments is 32, and we utilize a maximum length n = 50 of sentences in the experiments by padding shorter sentences and cutting off longer ones. These hyperparameters are either randomly searched or chosen by experiences when tuning in the development set.\nWe use ReLU (Glorot et al., 2011) as our nonlinear activate function. We apply the stochastic gradient descent algorithm with mini-batches and the AdaDelta update rule (Zeiler, 2012). The gradients are computed using back-propagation. During training, besides the weight matrices, we also fine-tune all the embedding tables."
  }, {
    "heading": "3.2 Overall Performance",
    "text": "We compare our performance with the following state-of-the-art methods:\n1 Cross-Event is proposed by Liao and Grishman\n(2010), which uses document level information to improve the performance of event extraction;\n2 JointBeam is the method proposed by Li et al.\n(2013), which extracts events based on structure prediction by manually designed features;\n3 DMCNN is proposed by Chen et al. (2015),\nwhich uses dynamic multi-pooling to keep multiple events’ information;\n4 PSL is proposed by Liu et al. (2016b), which\nuses a probabilistic reasoning model to classify events by using latent and global information to encode the associations between events;\n5 JRNN is proposed by Nguyen et al. (2016),\nwhich uses a bidirectional RNN and manually designed features to jointly extract event triggers and arguments.\n6 dbRNN is proposed by Sha et al. (2018), which"
  }, {
    "heading": "3.3 Effect on Extracting Multiple Events",
    "text": "To evaluate the effect of our framework for alleviating the multiple events phenomenon, we divide the test data into two parts (1/1 and 1/N) following Nguyen et al. (2016); Chen et al. (2015) and perform evaluations separately. 1/1 means that one sentence only has one trigger or one argument plays a role in one sentence; otherwise, 1/N is used.\nTable 2 illustrates the performance (F1 scores) of JRNN (Nguyen et al., 2016), DMCNN (Chen et al., 2015), the two baseline model Embedding+T and CNN in Chen et al. (2015) and our framework in trigger classification subtask and argument role labeling subatsk. Embedding+T uses word embedding vectors and the traditional sentence-level features in Li et al. (2013), while\ning the multiple-event phenomenon. In our framework, we introduce syntactic shortcut arcs to enhance information flow and adapt the graph convolution network to capture the enhanced representation. Then a self-attention aggregation mechanism is applied to aggregate the associations between events. Besides, we jointly extract event triggers and arguments by optimizing a biased loss function due to the imbalances in the dataset. The experiment results demonstrate the effectiveness of our proposed framework. In the future, we plan to exploit the information of one argument which plays different roles in various events to do better in event extraction task."
  }, {
    "heading": "Acknowledgments",
    "text": "We would like to thank Yansong Feng, Ying Zeng, Xiaochi Wei, Qian Liu and Changsen Yuan for their insightful comments and suggestions. We also very appreciate the comments from anonymous reviewers which will help further improve our work. This work is supported by National Natural Science Foundation of China (No. 61751201 and No. 61602490) and National Key R&D Plan (No. 2017YFB0803302)."
  }],
  "year": 2018,
  "references": [{
    "title": "Event extraction via dynamic multi-pooling convolutional neural networks",
    "authors": ["Yubo Chen", "Liheng Xu", "Kang Liu", "Daojian Zeng", "Jun Zhao."],
    "venue": "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the",
    "year": 2015
  }, {
    "title": "Language modeling with gated convolutional networks",
    "authors": ["Yann N. Dauphin", "Angela Fan", "Michael Auli", "David Grangier."],
    "venue": "Proceedings of the 34th International Conference on Machine Learning, pages 933–941.",
    "year": 2017
  }, {
    "title": "A languageindependent neural network for event detection",
    "authors": ["Xiaocheng Feng", "Lifu Huang", "Duyu Tang", "Heng Ji", "Bing Qin", "Ting Liu."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 66–71.",
    "year": 2016
  }, {
    "title": "Deep sparse rectifier neural networks",
    "authors": ["Xavier Glorot", "Antoine Bordes", "Yoshua Bengio."],
    "venue": "Proceedings of the 14th International Conference on Artificial Intelligence and Statistics, pages 315–323.",
    "year": 2011
  }, {
    "title": "Nyu’s english ace 2005 system description",
    "authors": ["Ralph Grishman", "David Westbrook", "Adam Meyers."],
    "venue": "Journal on Satisfiability, 51(11):1927–1938.",
    "year": 2005
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural Computation, 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Using cross-entity inference to improve event extraction",
    "authors": ["Yu Hong", "Jianfeng Zhang", "Bin Ma", "Jian-Min Yao", "Guodong Zhou", "Qiaoming Zhu."],
    "venue": "roceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human",
    "year": 2011
  }, {
    "title": "Refining event extraction through cross-document inference",
    "authors": ["Heng Ji", "Ralph Grishman."],
    "venue": "Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 254–262.",
    "year": 2008
  }, {
    "title": "Identifying civilians killed by police with distantly supervised entity-event extraction",
    "authors": ["Katherine A. Keith", "Abram Handler", "Michael Pinkham", "Cara Magliozzi", "Joshua McDuffie", "Brendan O’Connor"],
    "year": 2017
  }, {
    "title": "Semisupervised classification with graph convolutional networks",
    "authors": ["Thomas N. Kipf", "Max Welling."],
    "venue": "CoRR, abs/1609.02907.",
    "year": 2016
  }, {
    "title": "Accurate unlexicalized parsing",
    "authors": ["Dan Klein", "Christopher D. Manning."],
    "venue": "Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423–430.",
    "year": 2003
  }, {
    "title": "Joint event extraction via structured prediction with global features",
    "authors": ["Qi Li", "Heng Ji", "Liang Huang."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 73–82.",
    "year": 2013
  }, {
    "title": "Improving event detection with abstract meaning representation",
    "authors": ["Xiang Li", "Thien Huu Nguyen", "Kai Cao", "Ralph Grishman."],
    "venue": "Proceedings of the 1st Workshop on Computing News Storylines, pages 11–15.",
    "year": 2015
  }, {
    "title": "Using document level cross-event inference to improve event extraction",
    "authors": ["Shasha Liao", "Ralph Grishman."],
    "venue": "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 789–797.",
    "year": 2010
  }, {
    "title": "Event detection via gated multilingual attention mechanism",
    "authors": ["Jian Liu", "Yubo Chen", "Kang Liu", "Jun Zhao."],
    "venue": "Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 4865–4872.",
    "year": 2018
  }, {
    "title": "Leveraging framenet to improve automatic event detection",
    "authors": ["Shulin Liu", "Yubo Chen", "Shizhu He", "Kang Liu", "Jun Zhao."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2134–2143.",
    "year": 2016
  }, {
    "title": "Exploiting argument information to improve event detection via supervised attention mechanisms",
    "authors": ["Shulin Liu", "Yubo Chen", "Kang Liu", "Jun Zhao."],
    "venue": "In",
    "year": 2017
  }, {
    "title": "Automatic event extrac",
    "authors": ["Wei Lu", "Dan Roth"],
    "venue": "Artificial Intelligence,",
    "year": 2012
  }, {
    "title": "Glove: Global vectors for",
    "authors": ["pher D. Manning"],
    "year": 2014
  }, {
    "title": "Training very deep networks",
    "authors": ["Rupesh Kumar Srivastava", "Klaus Greff", "Jürgen Schmidhuber."],
    "venue": "Proceedings of the 28th Annual Conference on Neural Information Processing Systems, pages 2377–2385.",
    "year": 2015
  }, {
    "title": "Joint extraction of events and entities within a document context",
    "authors": ["Bishan Yang", "Tom M. Mitchell."],
    "venue": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
    "year": 2016
  }, {
    "title": "ADADELTA: an adaptive learning rate method",
    "authors": ["Matthew D. Zeiler."],
    "venue": "CoRR, abs/1212.5701.",
    "year": 2012
  }],
  "id": "SP:eae5661898519bfaaa3643a74d365714477feb52",
  "authors": [{
    "name": "Xiao Liu",
    "affiliations": []
  }, {
    "name": "Zhunchen Luo",
    "affiliations": []
  }, {
    "name": "Heyan Huang",
    "affiliations": []
  }],
  "abstractText": "Event extraction is of practical utility in natural language processing. In the real world, it is a common phenomenon that multiple events existing in the same sentence, where extracting them are more difficult than extracting a single event. Previous works on modeling the associations between events by sequential modeling methods suffer a lot from the low efficiency in capturing very long-range dependencies. In this paper, we propose a novel Jointly Multiple Events Extraction (JMEE) framework to jointly extract multiple event triggers and arguments by introducing syntactic shortcut arcs to enhance information flow and attention-based graph convolution networks to model graph information. The experiment results demonstrate that our proposed framework achieves competitive results compared with state-of-the-art methods.",
  "title": "Jointly Multiple Events Extraction via Attention-based Graph Information Aggregation"
}