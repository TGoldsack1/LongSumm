{
  "sections": [{
    "heading": "1. Introduction",
    "text": "The development of increasingly sophisticated Bayesian models in modern machine learning has accentuated the need for efficient generation of asymptotically exact samples from complex posterior distributions. Markov Chain Monte Carlo (MCMC) is an important framework for drawing samples from a target density function. MCMC sampling typically aims to estimate a desired expectation in terms of a collection of samples, avoiding the need to compute intractable integrals. The Metropolis algorithm (Metropolis et al., 1953) was originally proposed to tackle this task. Despite great success, this method is based on random walk exploration, which often leads to inefficient posterior sampling (with a finite number of samples). Alternatively, exploration of a target distribution can be guided using proposals inspired by Hamiltonian dynam-\n1Duke University, Durham, NC, 27708. Correspondence to: Yizhe Zhang <yizhe.zhang@duke.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nics, leading to Hamiltonian Monte Carlo (HMC) (Duane et al., 1987). Aided by gradient information, HMC is able to move efficiently in parameter space, thus greatly improving exploration. However, the emergence of big datasets poses a new challenge for HMC, as evaluation of gradients on whole datasets becomes computationally demanding, if not prohibitive, in many cases.\nTo scale HMC methods to big data, recent advances in Stochastic Gradient MCMC (SG-MCMC) have subsampled the dataset into minibatches in each iteration, to decrease computational burden (Welling & Teh, 2011; Chen et al., 2014; Ding et al., 2014; Ma et al., 2015). Stochastic Gradient Langevin Dynamics (SGLD) (Welling & Teh, 2011) was first proposed to generate approximate samples from a posterior distribution using minibatches. Since then, research has focused on leveraging the minibatch idea while also providing theoretical guarantees. For instance, Teh et al. (2014) showed that by appropriately injecting noise while using a stepsize-decay scheme, SGLD is able to converge asymptotically to the desired posterior. Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) (Chen et al., 2014) extended SGLD with auxiliary momentum variables, akin to HMC, and introduced a friction term to counteract the stochastic noise due to subsampling. However, exact estimation of such noise is needed to guarantee a correct SGHMC sampler. To alleviate this issue, the Stochastic Gradient Nosé-Hoover Thermostat (SGNHT) (Ding et al., 2014) algorithm introduced so-called thermostat variables to adaptively estimate stochastic noise via a thermal-equilibrium condition.\nOne standing challenge of SG-MCMC methods is inefficiency when exploring complex multimodal distributions. This limitation is commonly found in latent variable models with a multi-layer structure. Inefficiency is manifested because sampling algorithms have difficulties moving across modes, while traveling along the surface of the distribution. As a result, it may take a very large number of iterations (posterior samples) to cover more than one mode, greatly limiting scalability.\nWe investigate strategies for improving mixing in SGMCMC. We propose the Stochastic Gradient Monomial Gamma Thermostat (SGMGT), building upon the Monomial Gamma Sampler (MGS) proposed by Zhang et al.\n(2016). They showed that a generalized kinetic function typically improves the stationary mixing efficiency of HMC, especially when the target distribution has multiple modes. However, this advantage comes with numerical difficulties, and convergence problems due to poor initialization. By defining a smooth version of this generalized kinetic function, we can leverage its mixing efficiency, while satisfying the required conditions for stationarity of the corresponding stochastic process, as well as alleviating numerical difficulties arising from differentiability issues. To ameliorate the convergence issues, we further introduce i) a sampler with an underlying elliptic stochastic differential equation system and ii) a resampling scheme for auxiliary variables (momentum and thermostats) with theoretical guarantees. The result is an elegant framework to improve stationary mixing performance on existing SGMCMC algorithms augmented with auxiliary variables."
  }, {
    "heading": "2. Preliminaries",
    "text": "Hamiltonian Monte Carlo Suppose we are interested in sampling from a posterior distribution represented as π(θ|X) ∝ p(X|θ)p(θ) = exp[−U(θ|X)], where θ denotes model parameters and X = {x1, . . . , xN} represents N data points. Assuming i.i.d. data, the potential energy function U(θ|X) denotes the negative log posterior density, up to a normalizing constant, i.e., U(θ|X) = − ∑N i=1 log p(xi|θ) − log p(θ). For simplicity, in the following we omit the conditioning of X in U(θ|X), and write U(θ). In HMC, the posterior density is augmented with an auxiliary momentum random variable p; p is independent of θ, and typically has a marginal Gaussian distribution with zero-mean and covariance matrix M . The joint distribution is written as p(θ, p) ∝ exp[−H(θ, p)] , exp[−U(θ) − K(p)], where H(θ, p) is the total energy (or Hamiltonian) and K(p) = 12p\nTM−1p is the standard (Gaussian) kinetic energy function, and M is the mass matrix. HMC leverages Hamiltonian dynamics, driven by the following differential equations\ndθ = M−1pdt , dp = −∇U(θ)dt , (1)\nwhere t is the system’s time index.\nThe total Hamiltonian is preserved under perfect simulation, i.e., by solving (1) exactly. However, closed-form solutions for p and θ are often intractable, thus numerical integrators such as the leap-frog method are utilized to generate approximate samples of θ (Neal, 2011). This leads to the following update scheme:\npt+1/2 = pt − 2∇U(θt) , θt+1 = θt + M −1pt+1/2 ,\npt+1 = pt+1/2 − 2∇U(θt+1) , (2)\nwhere is the stepsize.\nMonomial Gamma HMC In the Monomial Gamma Hamiltonian Monte Carlo (MGHMC) (Zhang et al., 2016) algorithm, the following generalized kinetic function is employed as a substitute for the Gaussian kinetics of standard HMC:\nK(p) = (|p| 12a )TM−1|p| 12a , (3)\nwhere |p| 12a denotes the element-wise power operation, a is the monomial parameter. Note that when a = 1/2, (3) recovers the standard (Gaussian) kinetics. For general a, the update equations are identical to (2), except for\nθt+1 = θt + ∇K(pt+1/2) . (4)\nZhang et al. (2016) proved in the univariate case that MGHMC can yield better mixing performance when the sampler reaches its stationary distribution, under perfect dynamic simulation, i.e., infinitesimal stepsize in the limit and adequate (finite) simulation stepsize. Additionally, it was shown that for multimodal distributions sampled via MGMHC, the probability of getting trapped in a single mode goes to zero, as a→∞.\nHowever, these theoretical advantages are accompanied by two practical issues: i) the numerical difficulties accentuate dramatically as a increases, due to the lack of differentiability of K(p) for a ≥ 1, and ii) convergence is slow with poor initialization. For example, in (3) and (4), if θt is far away from the mode(s) of the distribution, ∇U(θt) will be large, causing the updated momentum pt+1/2 to blow up. This renders the change of θ, i.e., ∇K(pt+1/2), to be arbitrarily small for large a, thus slowing convergence.\nStochastic Gradient MCMC SG-MCMC is desirable when the dataset, X , is too large to evaluate the potential U(θ) using all N samples. The idea behind SG-MCMC is to replace U(θ) with an unbiased stochastic likelihood, Ũ(θ), evaluated from a subset of data (termed a minibatch)\nŨ(θ) = − NN ′ ∑N ′ i=1 log p(xτi |θ)− log p(θ) , (5)\nwhere {τ1, · · · , τN ′} is a random subset of {1, 2, · · · , N} of size N ′ N . SG-MCMC algorithms are typically driven by a continuous-time Markov stochastic process of the form (Chen et al., 2015)\ndΓ = V (Γ)dt+D(Γ)dW , (6)\nwhere Γ denotes the parameters of the augmented system, e.g., p and θ, V (·) and D(·) are referred as drift and diffusion vectors, respectively, and W denotes a standard Wiener process.\nIn SGHMC (Chen et al., 2014), the resulting stochastic dynamic process is governed by the following Stochastic Dif-\nferential Equations (SDEs) (with M = I):\ndθ = pdt , dp = −[∇Ũ(θ) +Ap]dt+ √ 2(AI − B̂(θ))dW , (7)\nwhere Γ = {θ, p}, V (Γ) is a function of {p,∇θŨ , A}, and D(Γ) is a function of {A, B̂(θ)}. ∇Ũ(θ) is modeled as ∇Ũ(θ) = ∇U(θ) + √ 2B(θ)ν, where ν ∼ N (0, 1) and h\nis the discretization stepsize. B̂(θ) is an estimator of B(θ), A is a user-specified diffusion factor and I is the identity matrix. Chen et al. (2014) set B̂(θ) = 0 for simplicity. The reasoning is that the injected noise N (0, 2Ah) will dominate as h → 0 (A remains as a constant), whereas B(θ) goes to zero. Unfortunately, the covariance function, B(θ), of the stochastic noise, ν, is difficult to estimate in practice.\nRecently, SGNHT (Ding et al., 2014) considered incorporating additional auxiliary variables (thermostats). The resulting SDEs correspond to\ndp = −[∇Ũ(θ) + ξ p]dt+ √\n2AIdW , (8) dθ = pdt , dξ = (p p− 1)dt , (9)\nwhere represents the Hadamard (element-wise) product and ξ are thermostat variables. Note that the diffusion factor, A, is decoupled in (8), thus ξ can adaptively fit to the unknown noise from the stochastic gradient∇Ũ(θ)."
  }, {
    "heading": "3. Stochastic Gradient Monomial Gamma Sampler",
    "text": "We now consider i) a more efficient (generalized) kinetic function, ii) adapting the proposed kinetics to satisfy stationary requirements and alleviate numerical difficulties, iii) incorporating an additional first-order stochastic process to (8) and iv) stochastic resampling of the momentum and thermostats to lessen convergence issues.\nGeneralized kinetics The statistical physics literature traditionally considers a quadratic form of the kinetics function, and a Gaussian distribution for the thermostats in (8), when analyzing the dynamic system of a canonical ensemble (Tuckerman, 2010). Inspired by this, one typical assumption in previous SG-MCMC work is that the marginal distribution for the momentum and thermostat is Gaussian (Ding et al., 2014; Li et al., 2016). However, this assumption, while convenient, does not necessarily guarantee an optimal sampler.\nIn recent work, Lu et al. (2016) extended the standard (Newtonian) kinetics to a more general form inspired by relativity theory. By bounding the momentum, their relativistic Monte Carlo can lessen the problem associated with large potential gradients, ∇U(θt), thus resulting in a more robust alternative to standard HMC. Further, Zhang et al.\n(2016) demonstrated that adopting non-Gaussian kinetics delivers better mixing and reduces sampling autocorrelation, especially for cases where the posterior distribution has multiple modes.\nThese ideas motivate a more general framework to characterize SG-MCMC, with potentially non-Gaussian kinetics and thermostats. As a relaxation of SGNHT (Ding et al., 2014; Ma et al., 2015), we consider a Hamiltonian system defined in a more general form\nH = K(p) + U(θ) + F (ξ) , (10)\nwhere K(·) and F (·) are any valid potential functions, inherently implying that exp[−K(·)] and exp[−F (·)], define valid probability density functions.\nWe first consider the SDEs of SGNHT with generalized kinetics K(p). The system can be obtained by generalizing K(p) = pT p/2 (with identity mass matrix M for simplicity) in (8) with arbitrary K(p), thus\ndθ = ∇K(p)dt , dp = −[∇Ũ(θ) + ξ ∇K(p)]dt+ √ 2AIdW ,\ndξ = (∇K(p) ∇K(p)−∇2K(p))dt . (11)\nHowever, if we setK(p) as in (3) with a ≥ 1, the dynamics governing the SDEs in (11) will often fail to converge. This is because the sufficient condition to guarantee that the Itô process governed by the SDEs in (11) converge to a stationary distribution generally requires the Fokker-Planck equation to hold (Risken, 1984). Further, the existence and uniqueness of the solutions to the Fokker-Planck equation require Lipschitz continuity of drift and diffusion vectors in (6) (Bris & Lions, 2008). Unfortunately, this is not the case for the drift vectors in (11) when a ≥ 1, as ∇K(p) is non-differentiable at the origin, i.e., p = 0.\nSoftened kinetics The above limitation can be avoided by using a softened kinetic function Kc(p). However, to keep the performance benefits from the original stiff kinetics, we must ensure that Kc(p) has the same tail behavior. We propose that for a = {1, 2}, the softened kinetics are (for clarity we consider 1D case, however higher dimensions still apply)\nKc(p) = { −p+ 2/c log(1 + ecp), a = 1 |p|1/2 + 4\nc(1+ec|p| 1/2 ) , a = 2 , (12)\nwhere c > 0 is a softening parameter. Note that Kc(p) is (infinitely) differentiable for any c and asymptotically approaches the stiff kinetics as c → ∞. A comparison between stiff kinetics, K(p), and softened kinetics Kc(p) is shown in Figure 1, for different values of c. Discussion and formulation of the softened kinetics for arbitrary a (andM ) are provided in the Supplementary Material (SM).\nTo generate samples of the momentum variable, p, from the density with softened kinetics, which is proportional to exp[−Kc(p)], we use a coordinate-wise rejection sampling, i.e., the proposed pd for the d-th dimension is rejected with probability 1− exp[K(pd)−Kc(pd)].\nIn practice, setting c to a relatively large value would still make the gradient ∇Kc(p) ill-posed close to p = 0, thus causing high integration error when simulating the Hamiltonian dynamics. Conversely, setting c to a small value will cause a high approximation error w.r.t. the original K(p), thus resulting in a less efficient sampler. Consequently, c has to be determined empirically as a trade-off between integration and approximation errors.\nAdditional First Order Dynamics Inspired by Ma et al. (2015), we consider adding Brownian motion to θ and ξ in (8), with variances σθ and σξ, respectively, while maintaining the stochastic process (asymptotically) converging to the correct marginal distribution of θ. Specifically, we consider the following SDEs:\ndθ =− σθ∇Ũ(θ)dt+∇Kc(p)dt+ √ 2σθdW ,\ndp =− (σp + γ∇F (ξ)) ∇Kc(p)dt −∇Ũ(θ)dt+ √ 2σpdW ,\ndξ = γ [ ∇Kc(p) ∇Kc(p)−∇2Kc(p) ] dt\n− σξ∇F (ξ)dt+ √ 2σξdW .\n(13)\nThe variances {σθ, σp, σξ} control the Brownian motion for {θ, p, ξ}, respectively, and γ > 0 denotes a rescaling factor for the friction term of momentum updates. The additional terms −σθ∇Ũ(θ)dt+ √ 2σθdW and\n−σξ∇F (ξ)dt+ √\n2σξdW can be understood as first-order Langevin dynamics (Welling & Teh, 2011). The variance term, σθ, controls the contribution of ∇Ũ(θ) to the update of θ w.r.t. ∇Kc(p). This is analogous to the hyperparameter balancing ∇Ũ(θ) and p in the SGD-with-momentum algorithm (Rumelhart et al., 1988). Derivation details for ∇Kc(p) and∇2Kc(p) in (12), as well as other values of a, are provided in the SM.\nThe following theorem, proven in the SM, shows that under regularity conditions, the SDEs in (13) lead to poste-\nrior samples from the invariant joint distribution p(Γ) ∝ exp[−H(Γ)], yielding the desired marginal distribution w.r.t. θ as p(θ) ∝ exp[−U(θ)]. Theorem 1. The stochastic process governed by (13) converges to a stationary distribution p(Γ) ∝ exp[−H(Γ)], where H(Γ) is as defined in (10), and Γ = {θ, p, ξ}.\nThe reasoning behind increasing stochasticity in the SDEs is two-fold. First, the additional Langevin dynamics are crucial to SG-MCMC with generalized kinetics for large a. For instance, for σθ = 0, the update for θ from (11) is θt+1 = θt + ∇K(pt)h. When a > 1 and |pt| is large, ∇K(p) = 1a |p|\n1/a−1 will be close to zero, thus θt+1 (the next sample) will be close to θt, i.e., the sampler moves arbitrarily slow. As discussed by Zhang et al. (2016), this can happen when θ moves to a region where the gradient ∇U(θ) takes a large absolute value, e.g., near the lowdensity regions in a light-tailed distribution. Fortunately, the additional Langevin dynamics in (13), −σθ∇Ũ(θ)dt+√\n2σθdW , compensate for the weak updating signal from ∇K(p), by an immediate gradient signal ∇Ũ(θ). Additionally, when Ũ(θ) becomes small, ∇K(p) will become large. As a result, these two updating signals ∇K(p) and ∇Ũ(θ) compensate each other, thereby delivering a stable updating scheme. Likewise, the immediate gradient∇F (ξ) in (13) can provide complementary updating signal for the thermostat variables, ξ, to offset the weak deterministic update∇Kc(p) ∇Kc(p)−∇2Kc(p), when p is large.\nSecond, (13) has noise components on all parameters, {θ, p, ξ}, making the corresponding SDEs elliptic. From a theoretical perspective, ellipticity/hypoellipticity are necessary conditions to guarantee existence of bounded solutions for a particular partial differential equation related to the diffusion’s infinitesimal generator, which lies in the core of most recent SG-MCMC theory (Teh et al., 2014; Vollmer et al., 2016; Chen et al., 2015). Ellipticity is characterized by a noise process (Brownian motion) covering all components of the system, via the diffusion, D(Γ), in (6). This means D(Γ) is block diagonal, thus a positive definite matrix (Mattingly et al., 2010). In a typical hypoelliptic case, the noise process is imposed on a subset of Γ. However, hypoellipticity also requires the noise to be able to spread through the system via the drift term, V (Γ), which may not be true for general V (Γ). For instance, in (8), Γ = {θ, p, ξ} and D(Γ) is block diagonal with entries {0, √ 2AI, 0}, i.e., θ and ξ are not explicitly influenced by the noise process, W , thus hypoellipticity cannot be guaranteed.\nTo the authors’ knowledge, for existing SG-MCMC algorithms, only SGLD where dθ = −∇θŨ(θ)dt+ √ 2dW , satisfies the ellipticity property, while other algorithms such as SGHMC and SGNHT assume hypoellipticity, thus their corresponding D(Γ) are not positive definite.\nOne caveat of (13) is that if σθ and σξ are too large, the up-\ndates will be dominated by first-order dynamics, thus losing the convergence benefits from second-order dynamics (Chen et al., 2014). In practice, σθ and σξ are problemspecific, thus need to be tuned, e.g. , by cross-validation.\nStochastic resampling When generating samples from the stochastic process in (13), we resample momentum and thermostats from their marginal distribution with a fixed frequency, instead of every iteration from their conditionals. Since the momentum and thermostats are drawn from the independent marginals of stationary distribution p(Γ) ∝ exp[−H(Γ)], it can be shown that reconstructing the stochastic process with the solution of the SDEs will still leave the stochastic process invariant to the target stationary distribution (Brunick et al., 2013).\nTo simplify the discussion, consider a stochastic process of a particle {θ, p} as in (11) with fixed ξ. As show in Figure 2, suppose the initial value of θ is far from the maximum a posteriori value. The dynamics governed by (11) will stochastically move along the Hamiltonian contour. The total Hamiltonian energy level is affected by the joint effect of the stochastic diffusion and momentum refraction (i.e., -ξpdt), which changes continuously over time.\nFrom previous discussions, moving on a high Hamiltonian contour when a > 1 is less efficient because the absolute value of the momentum, |p|, will get increasingly large, slowing down the movement of θ. Resampling of momentum according to its marginal will enable the sampler to immediately move to a lower Hamiltonian energy level.\nAt the burn-in stage, this momentum-accumulation/energydrop cycle seen in Figure 2(bottom) via resampling momentum can happen several times, until equilibrium is found. In practice, the resulting energy level is often much lower than initially, thereby delivering a more efficient and accurate dynamic updating.\nThe frequency of resampling from the marginal of the stationary distribution can have a direct impact on the mixing performance. Setting the frequency too high will result in a random-walk behavior. Conversely, with a low frequency resampling, the random-walk behavior is suppressed at a cost of fewer jumps between trajectories associated with different energy levels. It is advisable to increase the resampling frequency if the sampler is initialized on lowdensity (e.g. light-tailed) region.\nThe resampling step on p and ξ plays a role that is similar to adding a Langevin component to θ, in the sense that both improve convergence for a > 1. However, these two strategies (resampling and Langevin) are fundamentally different. We empirically observe that resampling is most helpful during burn-in, while the additional Langevin-style updates are more helpful with mixing during stationary sampling.\nSGMGT The specifications described above constitute an SG-MCMC method for the SDEs in (11), which we call Stochastic Gradient Monomial Gamma Thermostat (SGMGT). We denote the SG-MCMC method with additional Brownian motion on θ and ξ in (13) as SGMGT-D (Diagonal), i.e., with σθ > 0 and σξ > 0. The complete update scheme, with Euler integrator, for SGMGT is presented in the SM. Note that with a = 1/2, σθ = 0, σξ → 0, c → ∞, SGMGT-D recovers SGHMC as in Chen et al. (2014). Moreover, when a = 1/2, σθ = 0, c → ∞, it becomes SGNHT as in Ding et al. (2014).\nWe note that SGMGT-D improves upon SGNHT in three respects: (i) we introduce generalized kinetics, which provably yield lower autocorrelations than standard HMC, especially in multimodal cases; (ii) the additional stochastic noise on thermostat variables yields more efficient mixing; (iii) we use stochastic resampling to allow for faster interchange between different energy levels, thus alleviating sampling stickiness.\nTo the authors’ knowledge, despite existing analysis for Langevin Monte Carlo (Bubeck et al., 2015; Dalalyan, 2016), rigorous analysis and comparison of the mixing performance of general SG-MCMC is very difficult, thus not yet established. Toward understanding the mixing performance of SGMGT-D, we argue that as the minibatch size increases, and the contribution of the diffusion in (6) decreases, the SGMGT-D will approach MGHMC, in which case, a large a will result in high stationary mixing performance, especially when sampling multimodal distribution,\nas theoretically shown by Zhang et al. (2016). Although our experiments support our intuition, a more formal theoretical justification is needed. We leave this as interesting future work.\nWe observe empirically that when increasing the value of a, SGMGT-D may not always achieve superior mixing performance. One possible reason for this is a larger value of a induces “stiffer” behavior of exp[−K(p)] at p = 0, which typically requires a higher level of softening, thus higher rejection rates during the rejection sampling step. Also, when the dimensionality of p is higher, the rejection rate of the rejection sampling step increases (proportional to p). In such cases, the efficiency of the sampler decreases with large a. For these reasons, we limit our experiments to a = {1, 2}.\nWe clearly have more hyperparameters than SGNHT. In practice, we fix M = I , a = {1, 2}, and set the resampling frequency Tp = Tξ = 100, which provides robust performance. Thus, only two additional hyperparameters are employed (σθ and σξ) compared to SGNHT, and these parameters require further tuning. We use either validation or a hold-out set in our experiments.\nMore accurate numerical integrators Using a firstorder Euler integrator to approximate the solution of the continuous-time SDEs in (13), leads to O(h) errors in the approximate samples (Chen et al., 2016). Alternatively, we can use the symmetric splitting scheme of Chen et al. (2016) to reduce the order of the approximate error to O(h2). Details of the splitting used in this work are provided in the SM.\nConvergence properties The SGMGT framework, as an instance of SG-MCMC, enjoys the same convergence properties of general SG-MCMC algorithms studied in Chen et al. (2015). It’s worth to mention that on challenging problems the posterior may not be densely sampled to yield ideal posterior computation, and the asymptotic theory is being used as a useful heuristic. Specifically, it is of interest to quantify how fast the sample average, φ̂T , converges to the true posterior average, φ̄ , ∫ φ(θ)π(θ|X)dθ,\nfor φ̂T , 1T ∑T t=1 φ(θt), where T is number of iterations. Here we make the same assumptions of Chen et al. (2015), and further assume that a first-order Euler integrator and a fixed stepsize are used. Proposition 2. For the proposed SGMGT and SGMGT-D algorithms, if a fixed stepsize h is used, we have:\nBias: ∣∣∣Eφ̂T − φ̄∣∣∣ = O (1/(Th) + h) ,\nMSE: E ( φ̂− φ̄ )2 = O ( 1/(Th) + h2 ) .\nThis proposition indicates that with larger number of itera-\ntions and smaller step sizes, smaller bias and MSE bounds can be achieved. We note that these bounds have similar rates compared to other SG-MCMC algorithms such as SGLD, however, as we demonstrate below in the experiments, SGMGT and SGMGT-D usually converge faster than existing SG-MCMC methods.\nIn addition, for stochastic resampling, we can extend Proposition 2 to the following complementary results:\nLemma 1. Let πh be the stationary distribution of SGMGT-D. The stationary distribution of SGMGT-D with momentum resampling is the same as πh.\nLemma 2. The optimal finite-time bias and MSE bounds for SGMGT-D with momentum replacement remain the same as SGMGT-D.\nProofs of Lemma 1 and Lemma 2 are provided in the SM. The proposed SGMGT framework has a strong connection with second-order stochastic optimization methods, leading to a sampling scheme with minibatches with similar mixing performance as slice sampling (Neal, 2003). We discuss the details of this in the SM."
  }, {
    "heading": "4. Experiments",
    "text": ""
  }, {
    "heading": "4.1. Multiple-well Synthetic Potential",
    "text": "We first evaluate the mixing efficiency of SGMGT and SGMGT-D for a synthetic problem, to generate samples from a complex multimodal distribution. The distribution is shown in Figure 3(left). See SM for the definition of its potential energy. The modes are almost isolated with a low-density region connecting each other. Consequently, traversing between modes is difficult. In order to simulate the noise of the gradient estimates, we set ∇Ũ(θ) = ∇U(θ) + N (0, 2B), similar to Ding et al. (2014), where B = 1.\nWe compare SGNHT with SGMGT and SGMGT-D with monomial parameter a = 2 and fix γ = 1. For all three algorithms, we try a number of hyperparameter settings, e.g., stepsize h, {σθ, σp, σξ}, and the soft parameter c, and present the best results in Figure 3. Standard SGNHT fails to escape from one of the modes of the distribution. For\nSGMGT with a = 2, the generated samples reached 3 modes. For SGMGT-D with a = 2, the sampler identified all 5 modes. In Figure 3(right), SGMGT-D adequately moves across different modes and yields rapid mixing performance, unlike SGMGT which exhibits stickier behavior."
  }, {
    "heading": "4.2. Bayesian Logistic Regression",
    "text": "We evaluated the mixing efficiency and accuracy of SGMGT and SGMGT-D using Bayesian logistic regression (BLR) on 6 real-world datasets from the UCI repository (Bache & Lichman, 2013): German credit (G), Australian credit (A), Pima Indian (P), Heart (H), Ripley (R) and Caravan (C). The data dimensionality ranges from 7 to 87, and total observations vary between 250 to 5822. Gaussian priors are imposed on the regression coefficients. We set the minibatch size to 16. Other hyperparameters are provided in the SM. For each experiment, we draw 5000 iterations with 1000 burn-in samples.\nResults in terms of median Effective Sample Size (ESS) and prediction accuracies as Area Under Receiver Operating Characteristic (AUROC) are summarized in Table 1. All the results are averages over 5 independent runs with random initialization. In general, SGMGT-D performs better than SGMGT. For higher-dimensional dataset Cavaran, the performance of a = 2 decreases significantly, indicating numerical difficulties. The performance gap between SGMGT and SGMGT-D with a = 1 or a = 2 is usually larger than the gap between SGNHT (a = 0.5). Presumably when a is greater than 1, SGMGT-D has better convergence."
  }, {
    "heading": "4.3. Latent Dirichlet Allocation",
    "text": "We also test our methods on Latent Dirichlet Allocation (LDA) (Blei et al., 2003). Details of LDA and our implementation are provided in the SM. We use the ICML dataset (Chen et al., 2013), which contains 765 documents corresponding to abstracts of ICML proceedings from 2007 to 2011. After stopword removal, we obtain a vocabulary size of 1918 and about 44K words. We use 80% of the documents for training and the remaining 20% for testing. The number of topics is set to 30, resulting in 57,540 parameters. We use a symmetric Dirichlet prior with concentration\nβ = 0.1. All experiments are based on 5000 MCMC samples with 1000 burn-in rounds. We set the minibatch size to 16. Other hyperparameter settings are provided in the SM.\nTable 2 shows the test perplexities for SGMGT and SGMGT-D for different stepsizes. For each method we highlight the best perplexity. The SGMGT-D with a = 2 outperforms other methods, however SGMGT with a = 2 fails to achieve a comparable result with SGMGT with a = 1, probably because a good initialization is hard to achieve for a high-dimensional distribution."
  }, {
    "heading": "4.4. Discriminative RBM",
    "text": "We applied our SGMGT to the Discriminative Restricted Boltzmann Machine (DRBM) (Larochelle & Bengio, 2008) on MNIST data. We choose DRBM instead of RBM because it provides explicit stochastic gradient formulas.\nWe evaluated our methods empirically and compare them with SGNHT. We use one hidden layer with 500 units. For each method we performed 1500 iterations with 200 burnin samples. The minibatch size is set to 100. Details of the hyperparameter settings for SGMGT and SGMGT-D are provided in the SM. As shown in Figure 4(right-most 3 panels), we observe that SGMGT-D with a = 2 yields a superior mixing performance. For SGMGT-D with a = 2, the posterior samples demonstrated both rapid local mixing, and long-range movement. In contrast, SGLD seems trapped into a local mode after around 500 iterations.\nFigure 4(left) shows that SGMGT-D with a = 2 delivers the fastest convergence with the highest test accuracy, 0.976. The SGMGT-D improves over SGMGT, while performance of SGMGT-D seems to increase with a large value of a. We observed that the stochastic resampling played a crucial role for SGMGT, as removing the resampling step resulted in a large drop in testing performance and mixing efficiency."
  }, {
    "heading": "4.5. Recurrent Neural Network",
    "text": "We test our framework on Recurrent Neural Networks (RNNs) for sequence modeling (Gan et al., 2017). We consider two tasks: (i) polyphonic music prediction; and (ii) word-level language modeling, detailed below. Additional details of the experiment are provided in the SM.\nPolyphonic music prediction We use four datasets: Piano-midi.de (Piano), Nottingham (Nott), MuseData (Muse) and JSB chorales (JSB) (Boulanger-Lewandowski et al., 2012). Each of these are represented as a collection of 88-dimensional binary sequences, that span the whole range of piano from A0 to C8.\nWe use a one-layer LSTM (Hochreiter & Schmidhuber, 1997) model, and set the number of hidden units to 200. The total number of parameters is around 200K. Each model is trained for 100 epochs. We perform early stopping, while selecting the stepsize and other hyperparameters by monitoring the performance on validation sets. Updates are performed using minibatches from one sequence.\nLanguage modeling The Penn Treebank (PTB) corpus (Marcus et al., 1993) is used for word-level language modeling. We adopt the standard split (929K training words, 73K validation words, and 82K test words). The vocabulary size is 10K. We train a two-layer LSTM model on this dataset. The total number of parameters is approximately 6M. Each LSTM layer contains 200 units.\nResults are shown in Table 3. The best log-likelihood results on the test set are achieved by using SGMGT-D with either a = 1 or a = 2 (depending on the dataset). To compare with optimization-based methods, we also include results for SGD (Bottou, 2010) and RMSprop (Tieleman & Hinton, 2012). A more comprehensive comparison is provided in the SM.\nLearning curves for Nott and PTB datasets are shown in Figure 5. We omit the SGLD results since they are not com-\nparable with other methods. For both datasets, we observe that SGMGT-D delivers fastest convergence. The best negative log-likelihood is achieved by SGMGT-D a = 1. The difference between a = 1 and a = 2 is small, though SGMGT-D with a = 2 seems to decrease slightly faster after 20 epochs for PTB data.\nWe also observe that the SGMGT with a = 2 seems suboptimal compared with SGMGT with a = 1 and SGNHT. We hypothesize that numerical difficulties hinder the success of SGMGT with a = 2, especially in higher-dimensional cases, and without the additional Langevin components of SGMGT-D."
  }, {
    "heading": "5. Conclusions",
    "text": "We improve upon existing SG-MCMC methods with several generalizations. We employed a more-general kinetic function, which we have shown to have better mixing efficiency, especially for multimodal distributions. Since practical use of the generalized kinetics is limited by convergence issues during burn-in, we injected additional Langevin dynamics and incorporated a stochastic resampling step to obtain generalized SDEs that alleviate the convergence issues. Possible areas of future research include designing an algorithm in a slice-sampling fashion, which maintains the invariant distribution by leveraging the connections between HMC and slice sampling (Zhang et al., 2016). In addition, it is desirable to design an algorithm that can adaptively choose the monomial parameter a, thereby achieving better mixing while automatically avoiding numerical difficulties."
  }, {
    "heading": "Acknowledgments",
    "text": "This research was supported by ARO, DARPA, DOE, NGA, ONR and NSF."
  }],
  "year": 2017,
  "references": [{
    "title": "The fundamental incompatibility of Hamiltonian Monte Carlo and data subsampling",
    "authors": ["Betancourt", "MJ"],
    "venue": "ArXiv,",
    "year": 2015
  }, {
    "title": "Large-scale machine learning with stochastic gradient descent",
    "authors": ["Bottou", "Léon"],
    "venue": "In COMPSTAT,",
    "year": 2010
  }, {
    "title": "Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription",
    "authors": ["Boulanger-Lewandowski", "Nicolas", "Bengio", "Yoshua", "Vincent", "Pascal"],
    "venue": "In ICML,",
    "year": 2012
  }, {
    "title": "Existence and uniqueness of solutions to fokker–planck type equations with irregular coefficients",
    "authors": ["Bris", "C Le", "Lions", "P-L"],
    "venue": "Communications in Partial Differential Equations,",
    "year": 2008
  }, {
    "title": "Mimicking an itô process by a solution of a stochastic differential equation",
    "authors": ["Brunick", "Gerard", "Shreve", "Steven"],
    "venue": "The Annals of Applied Probability,",
    "year": 2013
  }, {
    "title": "Finite-time analysis of projected langevin monte carlo",
    "authors": ["Bubeck", "Sebastien", "Eldan", "Ronen", "Lehec", "Joseph"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Dependent normalized random measures",
    "authors": ["Chen", "Changyou", "Rao", "Vinayak", "Buntine", "Wray", "Whye Teh", "Yee"],
    "venue": "In ICML,",
    "year": 2013
  }, {
    "title": "On the convergence of stochastic gradient mcmc algorithms with high-order integrators",
    "authors": ["Chen", "Changyou", "Ding", "Nan", "Carin", "Lawrence"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Bridging the gap between stochastic gradient mcmc and stochastic optimization",
    "authors": ["Chen", "Changyou", "Carlson", "David", "Gan", "Zhe", "Li", "Chunyuan", "Carin", "Lawrence"],
    "year": 2016
  }, {
    "title": "Stochastic gradient hamiltonian monte carlo",
    "authors": ["Chen", "Tianqi", "Fox", "Emily B", "Guestrin", "Carlos"],
    "venue": "ArXiv,",
    "year": 2014
  }, {
    "title": "Theoretical guarantees for approximate sampling from smooth and log-concave densities",
    "authors": ["Dalalyan", "Arnak S"],
    "venue": "Journal of the Royal Statistical Society: Series B (Statistical Methodology),",
    "year": 2016
  }, {
    "title": "Bayesian sampling using stochastic gradient thermostats",
    "authors": ["Ding", "Nan", "Y Fang", "R Babbush", "C Chen", "Skeel", "R. D", "H. Neven"],
    "venue": "In NIPS,",
    "year": 2014
  }, {
    "title": "Hybrid Monte Carlo",
    "authors": ["Duane", "Simon", "Kennedy", "Anthony D", "Pendleton", "Brian J", "Roweth", "Duncan"],
    "venue": "Physics letters B,",
    "year": 1987
  }, {
    "title": "Approximate slice sampling for bayesian posterior inference",
    "authors": ["DuBois", "Christopher", "Balan", "Anoop Korattikara", "Welling", "Max", "Smyth", "Padhraic"],
    "venue": "In AISTATS,",
    "year": 2014
  }, {
    "title": "Scalable bayesian learning of recurrent neural networks for language modeling",
    "authors": ["Gan", "Zhe", "Li", "Chunyuan", "Chen", "Changyou", "Pu", "Yunchen", "Su", "Qinliang", "Carin", "Lawrence"],
    "year": 2017
  }, {
    "title": "Long shortterm memory",
    "authors": ["Hochreiter", "Sepp", "Schmidhuber", "Jürgen"],
    "venue": "Neural computation,",
    "year": 1997
  }, {
    "title": "Accelerating diffusions",
    "authors": ["Hwang", "Chii-Ruey", "Hwang-Ma", "Shu-Yin", "Sheu", "ShuennJyi"],
    "venue": "The Annals of Applied Probability,",
    "year": 2005
  }, {
    "title": "Classification using discriminative restricted boltzmann machines",
    "authors": ["H. Larochelle", "Y. Bengio"],
    "venue": "In ICML,",
    "year": 2008
  }, {
    "title": "High-order stochastic gradient thermostats for bayesian learning of deep models",
    "authors": ["Li", "Chunyuan", "Chen", "Changyou", "Fan", "Kai", "Carin", "Lawrence"],
    "venue": "In AAAI,",
    "year": 2016
  }, {
    "title": "Relativistic monte carlo",
    "authors": ["Lu", "Xiaoyu", "Perrone", "Valerio", "Hasenclever", "Leonard", "Teh", "Yee Whye", "Vollmer", "Sebastian J"],
    "year": 2016
  }, {
    "title": "A complete recipe for stochastic gradient mcmc",
    "authors": ["Ma", "Yi-An", "Chen", "Tianqi", "Fox", "Emily"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Building a large annotated corpus of english: The penn treebank",
    "authors": ["Marcus", "Mitchell P", "Marcinkiewicz", "Mary Ann", "Santorini", "Beatrice"],
    "venue": "Computational linguistics,",
    "year": 1993
  }, {
    "title": "Construction of numerical time-average and stationary measures via Poisson equations",
    "authors": ["J.C. Mattingly", "A.M. Stuart", "M.V. Tretyakov"],
    "venue": "SIAM J. NUMER. ANAL.,",
    "year": 2010
  }, {
    "title": "Equation of state calculations by fast computing machines",
    "authors": ["Metropolis", "Nicholas", "Rosenbluth", "Arianna W", "Marshall N", "Teller", "Augusta H", "Edward"],
    "venue": "The journal of chemical physics,",
    "year": 1953
  }, {
    "title": "MCMC using Hamiltonian dynamics",
    "authors": ["Neal", "Radford M"],
    "venue": "Handbook of Markov Chain Monte Carlo,",
    "year": 2011
  }, {
    "title": "Fokker-planck equation",
    "authors": ["Risken", "Hannes"],
    "venue": "In The FokkerPlanck Equation,",
    "year": 1984
  }, {
    "title": "Learning representations by back-propagating errors",
    "authors": ["Rumelhart", "David E", "Hinton", "Geoffrey E", "Williams", "Ronald J"],
    "venue": "Cognitive modeling,",
    "year": 1988
  }, {
    "title": "Consistency and fluctuations for stochastic gradient langevin dynamics",
    "authors": ["Teh", "Yee Whye", "Thiéry", "Alexandre", "Vollmer", "Sebastian"],
    "venue": "ArXiv,",
    "year": 2014
  }, {
    "title": "Lecture 6.5rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine",
    "authors": ["Tieleman", "Tijmen", "Hinton", "Geoffrey"],
    "year": 2012
  }, {
    "title": "Statistical mechanics: theory and molecular simulation",
    "authors": ["Tuckerman", "Mark"],
    "year": 2010
  }, {
    "title": "Exploration of the (non-) asymptotic bias and variance of stochastic gradient langevin dynamics",
    "authors": ["Vollmer", "Sebastian J", "Zygalakis", "Konstantinos C", "Teh", "Yee Whye"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Bayesian learning via stochastic gradient langevin dynamics",
    "authors": ["Welling", "Max", "Teh", "Yee W"],
    "venue": "In ICML,",
    "year": 2011
  }, {
    "title": "Towards unifying hamiltonian monte carlo and slice sampling",
    "authors": ["Zhang", "Yizhe", "Wang", "Xiangyu", "Chen", "Changyou", "Henao", "Ricardo", "Fan", "Kai", "Carin", "Lawrence"],
    "year": 2016
  }],
  "id": "SP:6d641c496ed20dedf1722cc3c0ef8fe0a27d5de0",
  "authors": [{
    "name": "Yizhe Zhang",
    "affiliations": []
  }, {
    "name": "Changyou Chen",
    "affiliations": []
  }, {
    "name": "Zhe Gan",
    "affiliations": []
  }, {
    "name": "Ricardo Henao",
    "affiliations": []
  }, {
    "name": "Lawrence Carin",
    "affiliations": []
  }],
  "abstractText": "Recent advances in stochastic gradient techniques have made it possible to estimate posterior distributions from large datasets via Markov Chain Monte Carlo (MCMC). However, when the target posterior is multimodal, mixing performance is often poor. This results in inadequate exploration of the posterior distribution. A framework is proposed to improve the sampling efficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A generalized kinetic function is leveraged, delivering superior stationary mixing, especially for multimodal distributions. Techniques are also discussed to overcome the practical issues introduced by this generalization. It is shown that the proposed approach is better at exploring complex multimodal posterior distributions, as demonstrated on multiple applications and in comparison with other stochastic gradient MCMC methods.",
  "title": "Stochastic Gradient Monomial Gamma Sampler"
}