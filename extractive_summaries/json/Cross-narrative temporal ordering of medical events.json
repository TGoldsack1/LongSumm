{
  "sections": [{
    "text": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 998–1008, Baltimore, Maryland, USA, June 23-25 2014. c©2014 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Discourse structure, logical flow of sentences, and context play a large part in ordering medical events based on temporal relations within a clinical narrative. However, cross-narrative temporal relation ordering is a challenging task as it is difficult to learn temporal relations among medical events which are not part of the logically coherent discourse of a single narrative. Resolving crossnarrative temporal relationships between medical events is essential to the task of generating an event timeline from across unstructured clinical narratives such as admission notes, radiology reports, history and physical reports and discharge summaries. Such a timeline has multiple applications in clinical trial recruitment (Luo et al., 2011), medical document summarization (Bramsen et al.,\n2006, Reichert et al., 2010) and clinical decision making (Demner-Fushman et al., 2009).\nGiven multiple temporally ordered medical event sequences generated from each clinical narrative in a patient record, how can we combine the events to create a timeline across all the narratives? The tendency to copy-paste text and summarize past information in newly generated clinical narratives leads to multiple mentions of the same medical event across narratives (Cohen et al., 2013). These cross-narrative coreferences act as important anchors for reasoning with information across narratives. We leverage crossnarrative coreference information along with confident cross-narrative temporal relation predictions and learn to align and temporally order medical event sequences across longitudinal clinical narratives. We model the problem as a sequence alignment task and propose solving this using two approaches. First, we use weighted finite state machines to represent medical events sequences, thus enabling composition and search to obtain the most probable combined sequence of medical events. As a contrast, we adapt dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) used to produce global and local alignments for aligning sequences of medical events across narratives. We also compare the proposed methods with an Integer Linear Programming (ILP) based method for timeline construction (Do et al., 2012). The cross-narrative coreference and temporal relation scores used in both these approaches are learned from a corpus of patient narratives from The Ohio State University Wexner Medical Center.\nThe main contribution of this paper is a general framework that allows aligning multiple event sequences using cascaded weighted finite state transducers (WFSTs) with the help of efficient composition and decoding. Moreover, we demonstrate that this method can be used for more accurate multiple sequence alignment when compared to\n998\ndynamic programming or other ILP-based methods proposed in literature."
  }, {
    "heading": "2 Related Work",
    "text": "In the areas of summarization and text-to-text generation, there has been prior work on several ordering strategies to order pieces of information extracted from different input documents (Barzilay et al., 2002, Lapata, 2003, Bollegala et al., 2010). In this paper, we focus on temporal ordering of information, as discussed next.\nRecent state-of-the art research has focused on the problem of temporal relation learning within the same document, and in many cases within the same sentence (Mani et al., 2006, Verhagen et al., 2009, Lapata and Lascarides, 2011). Chambers and Jurafsky (2009) describe a process to induce a partially ordered set of events related by a common protagonist by using an unsupervised distributional method to learn relations between events sharing coreferring arguments, followed by temporal classification to induce partial order. The task was carried out on the Timebank newswire corpus, but was limited to an intra-document setting. More recently, (Do et al., 2012) proposed an ILP-based method to combine the outputs of an event-interval and an event-event classifier for timeline construction on the ACE 2005 corpus. However, this approach is also restricted to events within documents and requires annotations for event intervals. We empirically compare our methods for timeline creation from longitudinal clinical narratives to such an ILP-based approach in Section 7. While a lot of this work has been done in the news domain, there is also some recent work in rule-based algorithms (Zhou et al., 2006) and machine learning (Roberts et al., 2008) applied to temporal relations between medical events in clinical text. Clinical narratives are written in a distinct sub-language with domain specific terminology and temporal characteristics, making them markedly different from newswire text.\nThere is limited prior work in learning relations across documents. Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents. Barzilay and McKeown (2005) propose a text-to-text generation technique for synthesizing common information across documents using sentence fusion. This involves multisequence dependency tree alignment to identify phrases conveying sim-\nilar information and statistical generation to combine common phrases into a sentence. Along with syntactic features, they combine knowledge from resources like WordNet to find similar sentences. In case of clinical narratives and medical event alignment, the objective is to identify a unique sequence of temporally ordered medical events from across longitudinal clinical data.\nTo the best of our knowledge, there is no prior work on cross-document alignment of event sequences. Multiple sequence alignment is a problem that arises in a variety of domains including gene/protein alignments in bioinformatics (Notredame, 2002), word alignments in machine translation (Kumar and Byrne, 2003), and sentence alignments for summarization (Lacatusu et al., 2004). Dynamic programming algorithms have been popularly leveraged to produce pairwise and global genetic alignments, where edit distance based metrics are used to compute the cost of insertions, deletions and substitutions. We use dynamic programming to compute the best alignment, given the temporal and coreference information between medical events across these sequences. More importantly, we propose a cascaded WFST-based framework for crossdocument temporal ordering of medical event sequences. Composition and search operations can be used to build a single transducer that integrates these components, directly mapping from input states to desired outputs, and obtain the best alignment (Mohri et al., 2000). In natural language processing, WFSTs have seen varied applications in machine translation (Kumar and Byrne, 2003), morphology (Sproat, 2006), named entity recognition (Krstev et al., 2011) and biological sequence alignment / generation (Whelan et al., 2010) among others. We demonstrate that the WFST-based approach outperforms popularly used dynamic programming algorithms for multiple sequence alignment."
  }, {
    "heading": "3 Problem Description",
    "text": "Medical events are temporally-associated concepts in clinical text that describe a medical condition affecting the patient’s health, or procedures performed on a patient. We represent medical events by splitting each event into a start and a stop. When there is insufficient information to discern the start or stop of an event, it is represented as a single concept. If only the start is known then the stop is set to +∞, whereas when only the stop is known , the start is set to the date of birth of the\npatient.1 Often, for chronic ailments like hypertension, we would only associate a start with the medical event and set the stop to +∞. The start of hypertension may be associated with the temporal expression history of in the narrative. This, when considered along with the admission date, allows us to relatively order hypertension with respect to other medical events. A medical event occurrence like chest pain may be associated with a start and a stop, where the start may be determined by the mention of “patient was complaining of chest pain yesterday” in the narrative text. Further, the narrative may state that “he continued to have chest pain on admission, but currently he is chest pain free”; this may be used to infer the relative stop of chest pain. Medical events may also be instantaneous, for e.g., injected with antibiotic. Such events are represented with the start and stop as being the same. Temporal relations exist between the start and stop of events as shown in Figure 1. Learning temporal relations before, after and simultaneous between the medical event starts and stops corresponds to learning all of Allen’s temporal relations (Allen, 1981) between the medical events. Following our previous work (Raghavan et al., 2012c), such a representation allows us to temporally order the event starts and stops within each clinical narrative by learning to rank them in relative order of time. The problem definition is as follows:\n1Patient date of birth, admission/ discharge date are usually available in the metadata associated with a clinical narrative.\nInput: Sequences of temporally ordered medical event starts and stops. This corresponds to N1, N2, and N3 in Figure 2. Each sequence corresponds to a clinical narrative. The total number of sequences correspond to the number of clinical narratives for a patient.\nProblem: Combine medical events across these sequences to generate a timeline i.e., a single comprehensive sequence of medical events over all clinical narratives of the patient.\nExpected Output: In the example shown in Figure 2, the output would be as follows: Timeline (N1, N2, N3)= {cocaine usestart < hypertensionstart = hypertensionstart < admission1 < chest painstart ∼ palpitationsstart < chest painstop < heart attackstart = myocardial infarctionstart < admission2 < infectionstart < MRSAstart < admission3 < woundsstart}.\nThe goal of multiple sequence alignment is to find an alignment that maximizes some overall alignment score. Thus, in order to align event sequences, we need to compute scores corresponding to cross-narrative medical event coreference resolution and cross-narrative temporal relations."
  }, {
    "heading": "4 Cross-Narrative Coreference Resolution and Temporal Relation Learning",
    "text": "The first approach to learning a temporal ordering of medical events across all clinical narratives is to consider all pairs of events across all narratives and learn to classify them as sharing one of Allen’s temporal relations (Allen, 1981) using a single learning model. Alternatively, a ranking ap-\nproach, similar to the one used to generate intranarrative temporal ordering, can also be extended to the cross-narrative case. However, the features related to narrative structure and relative and implicit temporal expressions used for temporal ordering within a clinical narrative may not be applicable across narratives. For instance, a history and physical report may have sections like “past medical history”, “history of present illness”, “assessment and plan”, and a certain logical pattern to the flow of text within and across these sections. Further, temporal cues like “thereafter”, “subsequently”, follow from the context around an event mention. The absence of such features in the cross-narrative case does not allow such a model to generate accurate temporal relation predictions.\nThus, for use in our sequence alignment models, we learn two independent classifiers for medical event coreference and temporal relation learning across narratives. We train a classifier to resolve cross-narrative coreferences by extracting semantic and temporal relatedness feature sets for each pair of medical concepts. Extracting these feature sets helps us train a classifier to predict medical event coreferences (Raghavan et al., 2012a). Another classifier is then trained to classify pairs of medical event starts and stops across narratives as sharing temporal relations {before, after, overlaps}. The learned cross-narrative coreference predictions can then be used along with confident temporal relation predictions to derive a joint probability to enable cross-narrative temporal ordering."
  }, {
    "heading": "5 Narrative Sequence Alignment for Cross-narrative Temporal Ordering",
    "text": "Sequence alignment algorithms have been developed and popularly used in bioinformatics. However, multiple sequence alignment (MSA) has been shown to be NP complete (Wang and Jiang, 1994) and various heuristic algorithms have been proposed to solve this problem (Notredame, 2002). We propose a novel WFST-based representation that enables accurate decoding for MSA when compared to popularly used dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) or other state of the art methods (Do et al., 2012).\nIn the problem of aligning events across multiple narrative sequences, we want to align temporally ordered medical events corresponding to clinical narratives of a patient. Unlike problems in biological sequence alignment where the sym-\nbols to be aligned across sequences are restricted to a fixed set, our symbol set is not fixed or certain because the symbols correspond to medical events in clinical narratives. Moreover, we cannot have fixed scores for symbol transformations since our transformations correspond to coreference and temporal relations between the medical events across sequences. The computation of these scores is described next."
  }, {
    "heading": "5.1 Scoring Scheme",
    "text": "Let us assume a, b are medical events in the first clinical narrative and have been temporally ordered so a < b. Similarly, x, y are medical events in the second clinical narrative such that x < y. There exists a match or an alignment between a pair of medical events, across the sequences, in the following cases:\n1. If the medical events are simultaneous and coreferring, denoted as a = x.\n2. If the medical events are simultaneous and non-coreferring, denoted as a ∼ x.\n3. If the a medical event from one sequence is before a medical event from another sequence, denoted as a < x.\n4. If the a medical event from one sequence is after a medical event from another sequence, denoted as a > x.\nWe now illustrate how the scores for candidate aligned sequences are computed using the learned cross-narrative coreference and temporal probabilities for the following three scenarios:\n• The medical events across sequences are simultaneous and corefer as illustrated in Figure 3. The joint score considers the probability of event temporal relations simultaneous conditioned on coreference.\n• Some medical events across sequences are simultaneous but do not corefer as illustrated in Figure 4. Here, the joint score considers the joint probability of temporal relations simultaneous or before and no-coreference.\n• The medical events across sequences are not simultaneous and do not corefer as illustrated in Figure 5. In this case, the joint score considers the probability of the temporal relation before and no coreference.\nThus, the coreference and temporal relation scores can be leveraged for aligning sequences of medical events. These scores are used in both the WFSTbased representation and decoding, as well as for dynamic programming."
  }, {
    "heading": "5.2 Alignment using a Weighted Finite State Representation",
    "text": "A weighted finite-state transducer (WFST) is an automaton in which each transition between states\nis associated with an input symbol, an output symbol, and a weight (Mohri et al., 2005). WFSTs can be used to efficiently represent and combine sequences of medical events based coreference and temporal relation information. The WFST representation gives us the ability to talk about the global joint probability derived from coreference and temporal relation scores described in Section 5.1. It allows us to build a weighted lattice of sequences that can be searched for the most probable sequence of medical events from across all clinical narratives of a patient. We use unweighted FSAs to represent the input described in Section 3, i.e. temporally ordered sequences of medical events corresponding to clinical narratives. This corresponds to N1 and N2 in Figure 6.\nBased on whether we want to align the sequences purely based on coreference scores or both coreference and temporal relation scores, the arc weights for the WFST can be determined. M c12 is a WFST that maps input symbols from N1 to output symbols inN2 and is weighted by the probability of coreference or no-coreference between medical events across N1 and N2. The representation in WFST M c+t12 shown in Figure 7 allows us to align N1 and N2 based on both coreference as well as temporal relation probabilities. The WFST has transitions to accommodate insertion and deletion of medical events when combining the sequences. Deletions correspond to the case when an event in the first sequence does not map to any event in the second sequence; similarly insertions correspond to the case where an event in the second sequence does not map to any event in the first sequence. The WFST composition operation allows the outputs of one WFST to be fed to the inputs of a second WFST or FSA. Thus, we build our final machine by composing the three sub-machines as,\nD = N1 ◦M i12 ◦N2. (1) where i = c or i = c + t. This gives us a combined weighted graph by mapping the output symbols of the first medical event sequence to the input symbols of the second medical event sequence. The scores on the decoding graph are derived from only the coreference probabilities if i = c and both coreference and temporal relation probabilities if i = c+ t.\nIn the medical event sequence alignment problem, we want to align multiple sequences of medical events that correspond to multiple clinical narratives of a patient. Since we want to now combine\nall narrative chains belonging to the same patient, the composition cascade to build the final combined sequence will be as,\nDf = N1◦M i12◦N2◦M i23◦N3◦M i34...◦Nn (2)\nwhere i = c or i = c + t and n is the number of medical event sequences corresponding to clinical narratives for a patient. During composition we retain intermediate paths like M i23 utilizing the ability to do lazy composition (Mohri and Pereira, 1998) in order to facilitate beam search through the multi-alignment. The best hypothesis corresponds to the highest scoring path which can be obtained using shortest path algorithms like Djikstra’s algorithm. The best path corresponds to the best alignment across all medical event sequences based on the joint probability of cross-narrative medical event coreferences and temporal relations across the narrative sequences.\nThe complexity of decoding increases exponentially with the number of narrative sequences in\nthe composition, and exact decoding becomes infeasible. One solution to this problem is to do the alignment greedily pairwise, starting from the most recent medical event sequences, finding the best path, and iteratively moving on to the next sequence, and proceeding until the oldest medical event sequence. The disadvantage of such a method is that it does not take into account constraints between medical events across multiple event sequences and may lead to a less accurate solution.\nAn alternative method is to use lazy composition to perform more efficient composition as it allows practical memory usage. We also use beam search to make for an efficient approximation to the best-path computation (Mohri et al., 2005). This allows accommodating constraints from across multiple sequences and generates a more accurate best path. Thus, this method generates more accurate alignments when we have more than two sequences to be aligned.\nFor instance, instance say a, b ∈ N1, x, y ∈ N2, and m,n ∈ N3 are temporally medical event sequences corresponding to narratives N1, N2 and N3. Based on the learned pairwise temporal relations, if we have the following constraints a < x, m > x, m < a. Aligning N1 and N2 greedily pairwise may give us the best combined sequence as a, x, b, y ∈ N12. Now in aligning N12 with N3, we won’t be able to accommodate m > x and m < a. However, performing a beam search over the composed WFST in equation 2 allows us to accommodate such constraints across multiple sequences. The complexity of composing two transducers is O(V1V2D1(logD2 + M2)) where each edge from the first sequence matches every edge in the second sequence and Vi is the number of states, Di is the maximum out-degree and Mi maximum multiplicity for the ith FST (Mohri et al., 2005).\nWe also use popular dynamic programming algorithms (Needleman et al., 1970, Smith and Waterman, 1981) for sequence alignment of medical events across narratives and compare it to the WFST-based representation and decoding."
  }, {
    "heading": "5.3 Pairwise Alignment using Dynamic Programming",
    "text": "As a contrast, we adapt two dynamic programming algorithms for sequence alignment: global alignment using the Needleman Wunsch algorithm (NW) (Needleman et al., 1970) and local alignment using the Smith-Waterman algorithm (SW) (Smith and Waterman, 1981). NW allows us to align all events in one sequence with all events in another sequence. A drawback of NW is that short and highly similar sequences maybe missed because they get overweighted by the rest of the sequence. NW is suitable when the two sequences are of similar length with significant degree of similarity throughout. On the other hand, SW gives the longest sub-sequence pair that yields maximum degree of similarity between the two original sequences. It does not force all events in a sequence to align with another sequence. SW is useful in aligning sequences that differ in length and have short patches of similarity. The time complexity of these methods for sequences of length m and n are O(mn).\nThe scoring scheme described earlier is used to update the scoring matrix for dynamic programming. In order to accommodate the temporal relations before and after, we insert a null symbol after every medical event in each sequence in the scoring matrix. A vertical or horizontal gap arises when cases 1, 2, 3 and 4 in Section 5.1 mentioned\nabove are not true. If the medical events are not simultaneous, not before or not after, the medical events will not align. Thus, the value of each cell in the scoring matrix is determined by computing the maximum score at each position C(i, j) as,\nmax{(C(i−1, j−1)+Sij), (C(i, j−1)+w), (C(i− 1, j) + w)} (3)\nwhere, Sij = max{P (i = j), P (i < j), P (i > j)}, and w = max{(1 − P (i = j)), (1 − P (i < j)), (1 − P (i > j))}. Here, C(i − 1, j − 1) corresponds to a match, whereas C(i, j − 1) and C(i − 1, j) correspond to a gaps in sequence one and two.\nIn case of the SW algorithm, the negative scoring matrix cells are set to zero, thus making the positively scoring local alignments visible. Backtracking starts at the highest scoring matrix cell and proceeds until a cell with score zero is encountered, yielding the highest scoring local alignment.\nThe time and space complexity grows exponentially with the number of sequences to be aligned and finding the global optimum has been shown to be a NP-complete problem. The time complexity of aligning N sequences of length L is O(2NLN ) (Wang and Jiang, 1994). Thus, for MSA using dynamic programming, we use a heuristic method where we combine pairwise alignments iteratively starting with the latest narrative and progressing towards the oldest narrative."
  }, {
    "heading": "6 Experiments and Evaluation",
    "text": "Corpus Description. The corpus consists of a dataset of clinical narratives obtained from the [redacted] medical center. The corpus has a total of 2060 patients, and 100704 clinical narratives. We gathered a gold standard set of seven patients (80 clinical narratives overall) with manual annotation of all medical events mentioned in the narratives, coreferences, and medical event sequence information. The annotation agreement across annotators is high, with 89.5% agreement corresponding to inter-annotator Cohen’s kappa statistic of 0.86 (Raghavan et al., 2012b). The types of clinical narratives included 27 discharge summaries, 30 history and physical reports, 15 radiology reports and 8 pathology reports. The distribution of the number of medical event sequences and unique medical events across patients is shown in Table 1. The annotated dataset is used to crossvalidate and train our coreference and temporal relation learning models and to evaluate our crossnarrative medical event timeline.\nEvaluation Metric. For each patient and each method (WFST or dynamic programming), the output timeline to evaluate is the highest scoring candidate hypothesis derived as described above. Accuracy of the timeline is calculated as the number of transformations required to obtain the reference sequence in the annotated gold-standard from the one generated by our system. Transformations are measured in terms of the minimum edit distance, insertions, deletions, and substitutions of medical events.\nExperiments and Results. We first temporally order medical events within each clinical narrative by learning to rank them in relative order of occurence as described in our previous work (Raghavan et al., 2012c). The overall accuracy of ranking medical events using leave-one-out cross validation is 82.1%. The resulting medical event sequences serve as the input to the problem of crossnarrative sequence alignment.\nThe cross-narrative coreference and temporal relation pairwise classification models described in Section 4 are trained using a Maximum entropy classifier. The coreference resolution performs with 71.5% precision and 82.3% recall. The temporal relation classifier performs with 60.2% precision and 76.3% recall. The learned pairwise coreference and temporal relation probabilities are now used to derive the score for the WFST and dynamic programming approaches.\nWFST representation and decoding. We build finite-state machines using the open source OpenFST library.2 We use a tropical semi-ring weighted using the negative log-likelihood of the computed scores. OpenFST provides tools that can search for the highest scoring sequences accepted by the machine, and can sample from highscoring sequences probabilistically, by treating the\n2www.openfst.org\nscores of each transition within the machine as a negative log probability. The decoding process to compute the most likely combined medical event sequence can be defined as searching for the best path in the combined graph representation (Equation 2). The best path is the one that minimizes the total weight on a path (since the arcs are negative log probabilities). In searching for the best path, the beam size is set to 5. The accuracy of the WFST-based representation and beam search across all sequences using the coreference and temporal relation scores to obtain the combined aligned sequence is 78.9%.\nDynamic Programming. We use the NW and SW algorithms described in Section 5.3 to produce local and global alignments respectively. We use the scoring scheme described in Section 5.1 to update the cost matrix for dynamic programming and implement the algorithms as described in Section 5.3. The overall accuracy of sequence alignment with both coreference and temporal relation scores using NW is 68.7% whereas SW gives an accuracy of 72.1%. In case of aligning just two sequences, both methods yield the same results. The accuracy of cross-narrative MSA for each patient, for each method, using cross validation, is shown in Table 1. Results indicate that the WFSTbased method outperforms the dynamic programming approach for multi-sequence alignment (statistical significance p<0.05). Morever, the results using both coreference and temporal realtion scores for alignment outperform using only coreference scores for alignment using all approaches. This indicates that cross-narrative temporal relations are important for accurately aligning medical event sequences across narratives."
  }, {
    "heading": "7 Discussion",
    "text": "We propose and evaluate different approaches to multiple sequence alignment of medical events.\nApproaches to multi-alignment. We address the problem of aligning medical event sequences using a novel WFST-based framework and empirically demonstrate that it outperforms pairwise progressive alignment using dynamic programming. This is mainly because the WFST-based allows us to consider temporal constraints from across multiple sequences when performing the alignment.\nMoreover, it also outperforms the integer linear programming (ILP) method for timeline construction proposed in (Do et al., 2012). We implemented the proposed method that also allows combining the output of classifiers subject to some constraints. We derive intervals from event starts and stops and learn two perceptron classifiers for classifying the temporal relations between events and assigning events to intervals. The classifier probabilities are then used to solve the optimization problem using the lpsolve solver.3 We also use intra-document coreference information to resolve coreference before performing the global optimization. We observe that in case of MSA, the optimal solution using ILP is still intractable as the number of constraints increases exponentially with the number of sequences. Aligning pairwise iteratively gives us an overall average accuracy of 68.2% similar to dynamic programming. While this is comparable to the dynamic programming performance, the WFST-based method significantly outperforms this in case of multialignments for cross-narrative temporal ordering.\nPerformance and error analysis. We perform multi-alignments over medical event sequences for a patient, where each sequence corresponds to temporally ordered medical events in a clinical narrative generated using the ranking model described in (Raghavan et al., 2012c). The accuracy of intra-narrative temporal ordering is 82.1%. The errors in performing this intra-narrative ordering may propagate to the cross-narrative model resulting in reduced accuracy. This may be addressed by considering n-best temporally ordered medical event sequences, generated by the ranking process, and aligning the n-best sequences using the WFST-based framework. This could be feasible as, practically, the WFST-based method for multialignment takes only a few secs to align a pair of medical event sequences with average length 40.\nThe accuracy of alignments across multiple medical event sequences is also affected by the error induced by the coreference and temporal relation scores. Often, insufficient temporal cues leads\n3http://lpsolve.sourceforge.net/5.5/\nto misclassification of events incorrectly as sharing the “simultaneous” temporal relation and often as coreferring. This induces errors in the score calculation and hence the alignments. Better methods to address the challenging problem of crossdocument temporal relation learning, perhaps with the help of structured data from the patient record, could improve the accuracy of alignments.\nThere is no clear trend with respect to the number of medical events and narratives for a patient (Table 1.), and the alignment accuracy. In future work, it would be interesting to examine any such correlation and also study the scalability of the WFST-based method for sequence alignment on longer medical event sequences and a larger dataset of patients. Further, the WFST-based method may be used to model multi-alignment tasks in other speech and language problems as well."
  }, {
    "heading": "8 Conclusion",
    "text": "We propose a novel framework for aligning medical event sequences across clinical narratives based on coreference and temporal relation information using cascaded WFSTs. FSTs provide a convenient and flexible framework to model sequences of temporally ordered medical events and compose them into a combined graph representation. Decoding this graph allows us to jointly maximize coreference as well as temporal relation probabilities to derive a timeline of the most likely temporal ordering of medical events. This approach to aligning multiple sequences of medical events significantly outperforms other approaches such as dynamic programming. Moreover, we demonstrate the importance of learning temporal relations for the task timeline generation from across multiple clinical narratives by empirically proving that decoding using both coreference and temporal relation scores is far more accurate than decoding with only coreference scores."
  }, {
    "heading": "Acknowledgments",
    "text": "The project was supported by Award Number Grant R01LM011116 from the National Library of Medicine. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Library of Medicine or the National Institutes of Health. The authors would like to thank Yanzhang He for his input on the WFST-based model."
  }],
  "year": 2014,
  "references": [{
    "title": "An interval-based representation of temporal knowledge",
    "authors": ["James F. Allen."],
    "venue": "IJCAI, pages 221– 226.",
    "year": 1981
  }, {
    "title": "Sentence fusion for multidocument news summarization",
    "authors": ["Regina Barzilay", "Kathleen R. McKeown."],
    "venue": "Comput. Linguist., 31(3):297–328, September.",
    "year": 2005
  }, {
    "title": "Inferring strategies for sentence ordering in multidocument summarization",
    "authors": ["Regina Barzilay", "Noemie Elhadad", "Kathleen McKeown."],
    "venue": "Journal of Artificial Intelligence Research (JAIR), 17:35–55.",
    "year": 2002
  }, {
    "title": "A bottom-up approach to sentence ordering for multi-document summarization",
    "authors": ["Danushka Bollegala", "Naoaki Okazaki", "Mitsuru Ishizuka."],
    "venue": "Information processing & management, 46(1):89–109.",
    "year": 2010
  }, {
    "title": "Inducing temporal graphs",
    "authors": ["Philip Bramsen", "Pawan Deshpande", "Yoong Keok Lee", "Regina Barzilay."],
    "venue": "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, EMNLP ’06, pages 189–198.",
    "year": 2006
  }, {
    "title": "Unsupervised learning of narrative schemas and their participants",
    "authors": ["Nathanael Chambers", "Dan Jurafsky."],
    "venue": "ACL/AFNLP, pages 602–610.",
    "year": 2009
  }, {
    "title": "Redundancy in electronic health record corpora: analysis, impact on text mining performance and mitigation strategies",
    "authors": ["Raphael Cohen", "Michael Elhadad", "Noémie Elhadad."],
    "venue": "BMC bioinformatics, 14(1):10.",
    "year": 2013
  }, {
    "title": "What can natural language processing do for clinical decision support",
    "authors": ["Dina Demner-Fushman", "Wendy Webber Chapman", "Clement J. McDonald"],
    "venue": "Journal of Biomedical Informatics,",
    "year": 2009
  }, {
    "title": "Joint inference for event timeline construction",
    "authors": ["Quang Xuan Do", "Wei Lu", "Dan Roth."],
    "venue": "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-",
    "year": 2012
  }, {
    "title": "Refining event extraction through cross-document inference",
    "authors": ["Heng Ji", "Ralph Grishman."],
    "venue": "Association for Computational Linguistics.",
    "year": 2008
  }, {
    "title": "E-dictionaries and Finite-state automata for the recognition of named entities",
    "authors": ["Cvetana Krstev", "Duško Vitas", "Ivan Obradović", "Miloš Utvić."],
    "venue": "Proceedings of the 9th International Workshop on Finite State Methods and Natural Language Pro-",
    "year": 2011
  }, {
    "title": "A weighted finite state transducer implementation of the alignment template model for statistical machine translation",
    "authors": ["Shankar Kumar", "William Byrne."],
    "venue": "Proceedings of the 2003 Conference of the North American Chapter of the Association",
    "year": 2003
  }, {
    "title": "Multi-document summarization using multiple-sequence alignment",
    "authors": ["V Finley Lacatusu", "Steven J Maiorano", "Sanda M Harabagiu."],
    "venue": "LREC.",
    "year": 2004
  }, {
    "title": "Learning sentence-internal temporal relations",
    "authors": ["Mirella Lapata", "Alex Lascarides."],
    "venue": "CoRR, abs/1110.1394.",
    "year": 2011
  }, {
    "title": "Probabilistic text structuring: Experiments with sentence ordering",
    "authors": ["Mirella Lapata."],
    "venue": "Proceedings of the 41st Annual Meeting on Association for Computational Linguistics-Volume 1, pages 545– 552. Association for Computational Linguistics.",
    "year": 2003
  }, {
    "title": "Extracting temporal constraints from clinical research eligibility criteria using conditional random fields",
    "authors": ["Zhihui Luo", "Stephen B. Johnson", "Albert M. Lai", "Chunhua Weng."],
    "venue": "Proc of AMIA Symposium.",
    "year": 2011
  }, {
    "title": "Machine learning of temporal relations",
    "authors": ["Inderjeet Mani", "Marc Verhagen", "Ben Wellner", "Chong Min Lee", "James Pustejovsky."],
    "venue": "ACL.",
    "year": 2006
  }, {
    "title": "Dynamic compilation of weighted context-free grammars",
    "authors": ["Mehryar Mohri", "Fernando CN Pereira."],
    "venue": "Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Compu-",
    "year": 1998
  }, {
    "title": "The design principles of a weighted finite-state transducer library",
    "authors": ["Mehryar Mohri", "Fernando C.N. Pereira", "Michael Riley."],
    "venue": "Theoretical Computer Science, 231(1):17–32.",
    "year": 2000
  }, {
    "title": "Weighted automata in text and speech processing",
    "authors": ["Mehryar Mohri", "Fernando Pereira", "Michael Riley."],
    "venue": "CoRR, abs/cs/0503077.",
    "year": 2005
  }, {
    "title": "A general method applicable to the search for similarities in the amino acid sequence of two proteins",
    "authors": ["S.B. Needleman", "C.D. Wunsch"],
    "venue": "Journal of molecular biology,",
    "year": 1970
  }, {
    "title": "Recent progress in multiple sequence alignment: a survey",
    "authors": ["Cédric Notredame."],
    "venue": "Pharmacogenomics, 3(1):131–144.",
    "year": 2002
  }, {
    "title": "Exploring semi-supervised coreference resolution of medical concepts using semantic and temporal features",
    "authors": ["Preethi Raghavan", "Eric Fosler-Lussier", "Albert M. Lai."],
    "venue": "North American Association for Computational Linguistics Annual Meeting - Hu-",
    "year": 2012
  }, {
    "title": "Inter-annotator reliability of medical events, coreferences and temporal relations in clinical narratives by annotators with varying levels of clinical expertise",
    "authors": ["Preethi Raghavan", "Eric Fosler-Lussier", "Albert M. Lai."],
    "venue": "To appear in Proceedings",
    "year": 2012
  }, {
    "title": "Learning to temporally order medical events in clinical text",
    "authors": ["Preethi Raghavan", "Eric Fosler-Lussier", "Albert M. Lai."],
    "venue": "ACL short paper. Association for Computational Linguistics.",
    "year": 2012
  }, {
    "title": "Cognitive analysis of the summarization of longitudinal patient records",
    "authors": ["Daniel Reichert", "David Kaufman", "Benjamin Bloxham", "Herbert Chase", "Noémie Elhadad."],
    "venue": "AMIA Annual Symposium Proceedings, volume 2010, page 667. American Medi-",
    "year": 2010
  }, {
    "title": "Semantic Annotation of Clinical Text: The CLEF Corpus",
    "authors": ["A. Roberts", "R. Gaizauskas", "M. Hepple", "G. Demetriou", "Y. Guo", "A. Setzer."],
    "venue": "Proceedings of the LREC 2008 Workshop on Building and Evaluating Resources for Biomedical Text Mining, pages",
    "year": 2008
  }, {
    "title": "Identification of common molecular subsequences",
    "authors": ["T.F. Smith", "M.S. Waterman."],
    "venue": "Journal of molecular biology, 147(1).",
    "year": 1981
  }, {
    "title": "A Computational Theory of Writing Systems (Studies in Natural Language Processing)",
    "authors": ["Richard Sproat."],
    "venue": "Cambridge University Press.",
    "year": 2006
  }, {
    "title": "The tempeval challenge: identifying temporal relations in text",
    "authors": ["Marc Verhagen", "Robert J. Gaizauskas", "Frank Schilder", "Mark Hepple", "Jessica Moszkowicz", "James Pustejovsky."],
    "venue": "Language Resources and Evaluation, 43(2):161–179.",
    "year": 2009
  }, {
    "title": "On the complexity of multiple sequence alignment",
    "authors": ["Lusheng Wang", "Tao Jiang."],
    "venue": "Journal of computational biology, 1(4):337–348.",
    "year": 1994
  }, {
    "title": "Designing antimicrobial peptides with weighted finite-state transducers",
    "authors": ["Christopher Whelan", "Brian Roark", "Kemal Sonmez."],
    "venue": "Proceedings of IEEE Engineering in Medical Biology Society, page 764.",
    "year": 2010
  }, {
    "title": "Unsupervised word sense disambiguation rivaling supervised methods",
    "authors": ["David Yarowsky."],
    "venue": "Association for Computational Linguistics, pages 189– 196.",
    "year": 1995
  }, {
    "title": "A temporal constraint structure for extracting temporal information from clinical narrative",
    "authors": ["Li Zhou", "Genevieve B. Melton", "Simon Parsons", "George Hripcsak."],
    "venue": "Journal of Biomedical Informatics, pages 424–439.",
    "year": 2006
  }],
  "id": "SP:9bea721047df1812ae1b772f939a93ccf35567bc",
  "authors": [{
    "name": "Preethi Raghavan",
    "affiliations": []
  }, {
    "name": "Eric Fosler-Lussier",
    "affiliations": []
  }, {
    "name": "Noémie Elhadad",
    "affiliations": []
  }, {
    "name": "Albert M. Lai",
    "affiliations": []
  }],
  "abstractText": "Cross-narrative temporal ordering of medical events is essential to the task of generating a comprehensive timeline over a patient’s history. We address the problem of aligning multiple medical event sequences, corresponding to different clinical narratives, comparing the following approaches: (1) A novel weighted finite state transducer representation of medical event sequences that enables composition and search for decoding, and (2) Dynamic programming with iterative pairwise alignment of multiple sequences using global and local alignment algorithms. The cross-narrative coreference and temporal relation weights used in both these approaches are learned from a corpus of clinical narratives. We present results using both approaches and observe that the finite state transducer approach performs performs significantly better than the dynamic programming one by 6.8% for the problem of multiple-sequence alignment.",
  "title": "Cross-narrative temporal ordering of medical events"
}