{
  "sections": [{
    "text": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2032–2043 Copenhagen, Denmark, September 7–11, 2017. c©2017 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Commonsense knowledge is fundamental in artificial intelligence, and has long been a key component in natural language understanding and human-like reasoning. For example, to understand the relation between sentences “Mary walked to a restaurant” and “She ordered some foods”, we need commonsense knowledge such as “Mary is a girl”, “restaurant sells food”, etc. The task of understanding natural language with commonsense knowledge is usually referred as commonsense machine comprehension, which has been a\nhot topic in recent years (Richardson et al., 2013; Weston et al., 2015; Zhang et al., 2016).\nRecently, RocStories (Mostafazadeh et al., 2016a), a commonsense machine comprehension task, has attached many researchers’ attention due to its significant difference from previous machine comprehension tasks. RocStories focuses on reasoning with implicit commonsense knowledge, rather than matching with explicit information in given contexts. In this task, a system requires choosing a sentence, namely hypothesis, to complete a given commonsense story, called as premise document. Table 1 shows two examples. RocStories proposes a challenging benchmark task for evaluating commonsensebased language understanding. As investigated by Mostafazadeh et al.(2016a), this dataset does not have any boundary cases and thus results in 100% human performance.\nCommonsense machine comprehension, however, is an natural ability for human but could be very challenging for computers. In general, any world knowledge whatsoever in the reader’s mind can affect the choice of an interpretation (Dahlgren et al., 1989). That is, a person can learn any heterogeneous commonsense knowledge and make inference of given information based on all knowledge in his mind. For example, to choose the right hypothesis for the first premise document in Table 1, we needs the event narrative knowledge that “X does a thorough job” will lead to “commends X”, rather than “fire X”. Besides, people can further confirm their judgement based on the sentimental coherence between “finish super early” and “job well done”. Furthermore, in the second example, even both hypothesises are consistent with the premise document in both event and sentimental facets, we can still infer the right answer easily using the commonsense knowledge that “puppy” is a dog, meanwhile “kitten” is a cat.\n2032\nIn recent years, many methods have been proposed for commonsense machine comprehension. However, these methods mostly either focus on matching explicit information in given texts (Weston et al., 2014; Wang and Jiang, 2016a,b; Wang et al., 2016b; Zhao et al., 2017), or paid attention to one specific kind of commonsense knowledge, such as event temporal relation (Chambers and Jurafsky, 2008; Modi and Titov, 2014; Pichotta and Mooney, 2016b; Hu et al., 2017) and event causality (Do et al., 2011; Radinsky et al., 2012; Hashimoto et al., 2015; Gui et al., 2016). As discussed above, it is obvious that commonsense machine comprehension problem is far from settled by considering only explicit or a single kind of commonsense knowledge. To achieve humanlike comprehension and reasoning, there exist two main challenges:"
  }, {
    "heading": "1) How to mine and represent different",
    "text": "kinds of implicit knowledge that commonsense machine comprehension needs. For example, to complete the first example in Table 1, we need a system equipped with the event narrative knowledge that “commends X” can be inferred from “X does a thorough job”, as well as the sentiment coherent knowledge that “insubordination” and “finish super early” are sentimental incoherent."
  }, {
    "heading": "2) How to reason with various kinds of",
    "text": "commonsense knowledge. As shown above, knowledge that reasoning process needs varies for different contexts. For human-like commonsense machine comprehension, a system should take various kinds of knowledge into consideration, decide what knowledge will be utilized in a specific reasoning contexts, and make the final decision by taking all utilized knowledge into consideration.\nTo address the above problems, this paper proposes a new commonsense reasoning approach, which can mine and exploit heterogeneous knowledge for commonsense machine comprehension. Specifically, we first mine different kinds of knowledge from raw text and relevant knowl-\nedge base, including event narrative knowledge, entity semantic knowledge and sentiment coherent knowledge. These heterogeneous knowledge are encoded into a uniform representation – inference rules between elements under different kinds of relations, with an inference cost for each rule. Then we design a rule selection model using attention mechanism, modeling which inference rules will be applied in a specific reasoning context. Finally, we propose a multi-knowledge reasoning model, which measures the reasoning distance from a premise document to a hypothesis as the expected cost sum of all inference rules applied in the reasoning process.\nBy modeling and exploiting heterogeneous knowledge during commonsense reasoning, our method can achieve more accurate and more robust performance than traditional methods. Furthermore, our method is a general framework, which can be extended to incorporate new knowledge easily. Experiments show that our method achieves a 13.7% accuracy improvement on the standard RocStories dataset, a significant improvement over previous work."
  }, {
    "heading": "2 Commonsense Knowledge Acquisition for Machine Comprehension",
    "text": "As described above, various knowledge can be exploited for machine comprehension. In this section, we describe how to mine different knowledge from different sources. Specifically, we mine three types of commonly used commonsense knowledge, including: 1)Event narrative knowledge, which captures temporal and causal relations between events; 2)Entity semantic knowledge, which captures semantic relations between entities; 3)Sentiment coherent knowledge, which captures sentimental coherence between elements.\nIn this paper, we represent commonsense knowledge as a set of inference rules given in the form of X f−→ Y : s, which means that element Y can be inferred from element X under relation f , with an inference cost s. An element can stand\nfor either event, entity or sentiment, and this paper represents elements using lemmatized nouns, verbs and adjectives. The lexical element representation can also be easily extended to structural representation, like the one in (Chambers and Jurafsky, 2008), if needed. However, in auxiliary experiments we found that using structural elements results in severe sparseness and noises which in turn will hurt the reasoning performance. Therefore, we think an individual work is needed to solve it. Table 2 demonstrates several examples of inference rules. In following, we describe how to mine different types of inference rules."
  }, {
    "heading": "2.1 Mining Event Narrative Knowledge",
    "text": "Event narrative knowledge captures structured temporal and casual knowledge about stereotypical event sequences, which is fundamental for commonsense machine comprehension. For example, we can infer “X ordered some foods” from “X walked to a restaurant” using event narrative knowledge. Previous work (Chambers and Jurafsky, 2008; Rudinger et al., 2015) proves that event narrative knowledge can be mined from raw texts unsupervisedly. So we propose two models to encode this knowledge using inference rules.\nThe first one is based on ordered PMI, which is also proposed by Rudinger et al. (2015). Given two element e1 and e2, this model calculates the cost of inference rule e1\nnarrative−−−−−−→ e2 as: cost(e1 −→ e2) = −log C(e1, e2)\nC(e1, ∗), C(∗, e2) (1)\nHereC(e1, e2) is the order sensitive count that element e1 occurs before element e2 in different sentences of the same document.\nThe second model is a variant of the skip-gram model (Mikolov et al., 2013). The goal of this model is to find element representations which can accurately predict relevant elements in sentences afterwards. Formally, given n asymmetric pairs of elements (e11, e 1 2), (e 2 1, e 2 2), ...., (e n 1 , e n 2 ) identified from training data, the objective of our model is to maximize the average log proba-\nbility 1n ∑n i=1 logP (e i 2|ei1). And the probability P (e2|e1) is defined using the softmax function: P (e2|e1) ∝ exp(v′e2 T ve1) (2) where ve and v′e are “antecedent” and “consequent” vector representation of element e, respectively. We use the negative inner product −v′e2Tve1 as the cost of inference rule e1 skip−gram−−−−−−−→ e2."
  }, {
    "heading": "2.2 Mining Entity Semantic Knowledge",
    "text": "Entities, often serving as event participants or environment variables, are important components of commonsense stories. Intuitively, an entity in hypothesis is reasonable if we can identify semantic relations between it and some parts of premise document. For example, if a premise document contains “Starbucks”, then “coffeehouse” and “latte” will be reasonable entities in hypothesis since “Starbucks” is a possible coreference of “coffeehouse” and it is semantically related to “latte”.\nSpecifically, we identify mainly two kinds of semantic relations between entities for commonsense machine comprehension:\n1) Coreference relation, which indicates that two elements refer to the same entity in environment. In stories, besides to pronouns, an entity is often referred using its hypernyms, e.g, the second example in Table 1 uses “dog” to refer to “puppy”. Motivated by this observation, we mine coreference knowledge between elements using Wordnet (Kilgarriff and Fellbaum, 2000): X coref−−−→ Y is an inference rule with cost 0 if X and Y are lemmas in the same Wordnet synset, or with hyponymy relation in Wordnet. Otherwise, the cost of inference rules between this element-pair under this relation will be 1.\n2) Associative relation, which captures the semantic relatedness between two entities, i.e., “starbucks” → “latte”, “restaurant” → “food”, etc. This paper mines associative relations between entities from Wikipedia1, using the method proposed by Milne and Witten(2008). Specifically, given two entities e1 and e2, we compute the semantic distance dist(e1, e2) between them as:\ndist(e1, e2) = log(max(|E1|, |E2|)− log(|E1⋂E2|)) log(|W |)− log(min(|E1|, |E2|))\n(3)\nwhere E1 and E2 are the sets of all entities that link to these two entities in Wikipedia respectively,\n1https://www.wikipedia.org/\nand W is the entire Wikipedia. We set the cost of inference rule e1\nassociative−−−−−−−→ e2 as dist(e1, e2)."
  }, {
    "heading": "2.3 Mining Sentiment Coherent Knowledge",
    "text": "Sentiment is one of the central and pervasive aspects of human experience (Ortony et al., 1990). It plays an important role in commonsense stories, i.e., a reasonable hypothesis should be sentimental coherent with its premise document. In this paper, we mine sentiment coherence rules using SentiWordnet (Baccianella et al., 2010), in which each synset of Wordnet is assigned with three sentiment scores: positivity, negativity and objectivity.\nConcretely, to identify sentimental coherence rule between two element e1 and e2, we first compute the positivity, negativity and objectivity scores of every element by averaging the scores of all synsets it’s in, then we identify an element to be subjective if its objectivity score is smaller than a threshold, and the distance between its positivity and negativity score is greater than a threshold. Finally, for an inference rule e1\nsenti−−−→ e2, we set its cost to 1 if e1 and e2 are both subjective and have opposite sentimental polarity, to -1 if they are both subjective and their sentimental polarity are the same, and to 0 for other cases. For example, we will mine inference rules “good senti−−−→ happy : −1”, “perfect senti−−−→ sad : 1” and “young senti−−−→ happy : 0”."
  }, {
    "heading": "2.4 Metric Learning to Calibrate Cost Measurement",
    "text": "So far, we have extracted many inference rules under different relations. However, because we extract them from different sources and estimate their costs using different measurements, the cost metrics of these rules may not be consistent with each other. To exploit different types of inference rules in a unified framework, we here propose a metric learning based method to calibrate their costs.\nGiven an input distance function, a metric learning method constructs a new distance function which is “better” than the original one with supervision regarding an ideal distance (Kulis, 2012). To calibrate inference rule cost, we add a nonlinear layer to the original cost sr of inference rule r under relation f :\ncr = sigmoid(wfsr + bf ) (4)\nHere cr is the metric-unified inference cost of inference rule r, wf and bf are calibration parame-\nters for inference rules of relation f . We use sigmoid function in order to normalize costs into 0 to 1. Calibration parameters will be trained along with other parameters in our model. See Section 3.4 for detail."
  }, {
    "heading": "2.5 Dealing with Negation",
    "text": "One important linguistic phenomenon needs to specifically consider is negation. Here we discuss how to solve negation in our model.\nWe use ¬X to represent an element X modified by a negation word (the existence of negation is detected using dependency relations). Under event narrative relation and sentiment coherent relation, the existence of negation will reverse the conclusion. So we add three additional negation related inference rules for rule X f−→ Y : s under these relations, including ¬X f−→ Y : 1 − s, X\nf−→ ¬Y : 1 − s and ¬X f−→ ¬Y : s. Here s is the calibrated cost of the original inference rule. For entity semantic relations, we just ignore the negation since it will not affect the inference under these relations."
  }, {
    "heading": "3 Machine Comprehension via Commonsense Reasoning",
    "text": "This section describes how to leverage acquired knowledge for commonsense machine comprehension. We first define how to infer from a premise document to a hypothesis using inference rules. Then we model how to choose inference rules for a specific reasoning context. Finally, we describe how to measure the reasoning distance from a premise document to a hypothesis by summarizing the costs of all possible inferences."
  }, {
    "heading": "3.1 Inference from Premise Document to Hypothesis",
    "text": "Given a premise document D = {d1, d2, ..., dm} containing m elements, a hypothesis H = {h1, h2, ..., hn} containing n elements, a valid inference R from D to H is a set of inference rules that all elements in H can be inferred from one element inD using one and only one rule inR. This definition means that all elements in H should be covered by consequents of inference rules in R, as well as all antecedents of inference rules in R should come from D. Figure 1 shows some inference examples, where (a), (b) and (d) are valid inferences, but (c) is not a valid inference because its rules can not cover all elements in hypothesis.\nBy the definition, the size of R and the size of H are equal. So we use ri to denote the inference rule in R that applied to derive element hi in H , i.e., R = {r1, r2, ..., rn}.\nBased on the above definition, we can naturally define the cost of an inference R as the cost sum of all inference rules in R. In Figure 1, the cost for inference (a) is 0.0 + 0.1 + 0.1 = 0.2, and for inference (d) is 0.0 + 0.8 = 0.8."
  }, {
    "heading": "3.2 Modeling Inference Probability using Attention Mechanism",
    "text": "Obviously, there exist multiple valid inferences for a premise document and a hypothesis. For example, in Figure 1, both (a) and (b) are valid inferences for the same premise document and hypothesis. To identify whether a hypothesis is reasonable, we need to consider all possible inferences. However, in human reasoning process, not all inference rules have the same possibility to be applied, because the more reasonable inference will be proposed more likely. In Figure 1, inference (a) should have a higher probability than inference (b) because it is more reasonable to infer “foods” from “a restaurant” with associative relation, rather than from “walked to” with narrative relation. Besides, the possibility of proposing an inference should not depend on its cost, e.g., inference (d) should have high possibility to be proposed despite its high cost, because we often infer event “sleep” from another event using inference rules under narrative relation. As examples mentioned above, the “cost” measures the “correctness” of an inference rule. A rule with low cost is more likely to be “reasonable”, and a rule with high cost is more likely to be a contradiction with commonsense. On the other hand, the “possibility” should measure how likely a rule will be applied in a given context, which does not depend on the “cost”\nbut on the nature of the rule and the given context. Motivated by above observations, we endow each inference a probability P (R|D,H), indicating the possibility thatR is chosen to infer hypothesis H from premise document D. For simplicity, we assume that each element in hypothesis is independently inferred using individual inference rule, then P (R|D,H) can be written as:\nP (R|D,H) = n∏\ni=1\nP (ri|D,H) (5)\n= n∏ i=1 P (ri|D,hi) (6)\n= n∏ i=1 m∑ j=1 P (ri, dj |D,hi) (7)\nEquation (7) clearly shows how an inference rule is selected given the premise document D and the element hi in hypothesis. It depends on which element dj inD will be selected and which relation f will be used to infer hi from dj . We then refactor the probability P (ri, dj |D,hi) to be:\nP (ri, dj |D,hi) = {\n0 , antecedent(ri) 6= dj g(hi, dj , f(ri);D) , otherwise (8)\nHere f(r) is the relation type of inference rule r, and g(h, d, f ;D) is defined as:\ng(h, d, f ;D) = s(h, d)a(h, f)a(d, f)∑ f∈F ∑ d∈D s(h, d)a(h, f)a(d, f) (9) Here F denotes all relation types of inference rules, s(e1, e2) is a matching function between two elements e1 and e2, measuring by cosine similarity based on GoogleNews word2vec (Mikolov et al., 2013). And a(e, f) is an attention function measuring how likely an element e will be involved with rules under relation f :\na(e, f) = vf T tanh(Wfe + bf ) (10)\nwhere vf ∈ RK , Wf ∈ RK×F and bf ∈ RK are attention parameters of relation f , and e ∈ RF is the feature vector of element e. Here K is the size of attention hidden layer and F is the dimension of feature vector. We consider three types of features, as shown in Table 3. Using attention mechanism, our method models the possibility that an inference rule is applied during the inference from a premise document to a hypothesis by considering the relatedness between elements and knowledge category, as well as the relatedness between two elements, which make it able to select the most reasonable inference rules to derive each part of the hypothesis."
  }, {
    "heading": "3.3 Reasoning Distance Between Premise Document and Hypothesis",
    "text": "Given a premise document, this section shows how to measure whether a hypothesis is coherent using above inference model. Given all valid inferences from D to H and the probability P (R|D,H) of selecting inference R to infer H from D, we measure the reasoning distance L(D → H) as the expected cost sum of all valid inferences:\nL(D → H) = EP (R|D,H)[cost(R)] (11)\n= EP (R|D,H)[ n∑\ni=1\ncost(ri)] (12)\nThen using Equation (6) and Equation (7), we can further rewrite the equation into:\nL(D → H) = ∑ R [ n∏ i=1 P (ri|D,hi)] · [ n∑ i=1 cost(ri)] (13)\n= n∑ i=1 P (ri|D,hi) · cost(ri) (14)\n= n∑ i=1 m∑ j=1 P (ri, dj |D,hi) · cost(ri) (15)\nEquation (15) shows that in our framework, the final cost of inferring the element hi in the hypothesis is the expected cost of all valid inference rules which can derive hi from one element in the premise document."
  }, {
    "heading": "3.4 Model Learning",
    "text": "Following Huang et al. (2013), our model measures the posterior probability of choosing hypothesis H as the answer of premise document D through a softmax function:\nP (H|D) = exp(−γL(D → H))∑ H′∈HD exp(−γL(D → H ′)\n(16)\nHere HD is all candidate hypothesises for D, and γ is a positive smoothing factor. We train our model by maximizing the likelihood of choosing right\nhypothesis H+ for D: L(θ) = −log ∏\n(D,H+)\nP (H+|D) (17)\nwhere θ is the parameter set of our model, including calibration parameters in Section 2.4 and attention parameters in Section 3.2. L(θ) is differentiable so we can estimate θ using any gradientbased optimization algorithm."
  }, {
    "heading": "4 Experiments",
    "text": ""
  }, {
    "heading": "4.1 Experimental Settings",
    "text": "Data Preparation. We evaluated our approach on the Test Set Spring 2016 of RocStories, which consists of 1871 commonsense stories, with each story has two candidate story endings. Because stories in the training set of RocStories do not contain wrong hypothesis, and our model has a compact size of parameters, we estimated the parameters of our model using the Validation Set Spring 2016 of RocStories with 1871 commonsense stories.\nWe mined event narrative knowledge from the Training Set Spring 2016 of RocStories, which consists of 45502 commonsense stories. We performed lemmatisation, part of speech annotation, named entity tagging, and dependency parsing using Stanford CoreNLP toolkits (Manning et al., 2014). We used the Jan. 30, 2010 English version of Wikipedia and processed it according to the method described by Hu et al. (2008).\nModel Training. We used normalized initialization (Glorot and Bengio, 2010) to initialize attention parameters in our model. For calibration parameters, we initialized all wf to 1 and bf to 0. The model parameters were trained using minibatch stochastic gradient descent algorithm. As for hyper-parameters, we set the batch size as 32, the learning rate as 1, the dimension of attention hidden layer K as 32, and the smoothing factor γ as 0.5.\nBaselines. We compared our approach with following three baselines:\n1) Narrative Event Chain (Chambers and Jurafsky, 2008), which scores hypothesis using PMI scores between events. We used a simplified version of the original model by using only verbs as event, ignoring the dependency relation between verbs and their participants. We found such a simplified version achieved better performance than its original one whose performance was reported in (Mostafazadeh et al., 2016a).\n2) Deep Structured Semantic Model (DSS-\nM) (Huang et al., 2013), which achieved the best performance on RocStories as reported by Mostafazadeh et al.(2016a). This model measures the reasoning score between a premise document D and a hypothesis H by calculating the cosine similarity between the overall vector representations of D and H , and do not consider any other task-relevant knowledge."
  }, {
    "heading": "3) Recurrent Neural Network(RNN) Model",
    "text": "proposed by Pichotta and Mooney(2015), which transforms all events and their arguments into a sequence and predict next events and arguments using a Long Short-Term Memory network. We used the average generating probability of all elements in H as the reasoning score, and choose the hypothesis with largest reasoning score as the system answer."
  }, {
    "heading": "4.2 Overall Performance",
    "text": "Table 4 shows the results. From this table, we can see that:\n1) Our model outperforms all baselines significantly. Compared with baselines, the accuracy improvement on test set is at least 13.7%. This demonstrates the effectiveness of our model by mining and exploiting heteregenous knowledge.\n2) The event narrative knowledge only is insufficient for commonsense machine comprehension. Compared with Narrative Event Chain Model, our model achieves a 16.3% accuracy improvement by considering richer commonsense knowledge, rather than only narrative event knowledge.\n3) It is necessary to distinguish different kinds of commonsense relations for machine comprehension and commonsense reasoning. Compared with DSSM and RNN, which model all relations between two elements using a single semantic similarity score, our model achieves significant accuracy improvements by modeling, distinguishing and selecting different types of commonsense relations between different kinds of elements."
  }, {
    "heading": "4.3 Effects of Different Knowledge",
    "text": "To investigate the effect of different kinds of knowledge in our model, we conducted two groups of experiments.\nThe first group of experiments was conducted using only one kind of knowledge at a time in our model. Table 5 shows the results. We can see that using a single kind of knowledge is insufficient for commonsense machine comprehension: all single-knowledge settings cannot achieve competitive performance to the all-knowledge setting.\nThe second group of experiments was conducted to investigate whether different knowledge can complement each other. We conducted experiments by removing one kind of knowledge from our final model at a time, and investigate the change of accuracy.\nTable 6 shows the results. We can find that removing any kind of knowledge will reduce the accuracy. This verified that all kinds of knowledge containing unique complementary information, which cannot be covered by other types of knowledge."
  }, {
    "heading": "4.4 Effect of Inference Probability",
    "text": "This section investigates the effect of inference rule selection probability, and whether our attention mechanism can effectively model the possibility of inference rule selection. We compared our method with following two heuristic settings:\n1) Minimum Cost Mechanism, which measures the reasoning distance by only selecting the inference rule with minimum cost for each hypothesis element.\n2) Average Cost Mechanism, which measures the reasoning distance by setting equal probabilities to all inference rules that can infer a hypothesis element from a premise document element.\nTable 7 show the results. We can see that: 1) the minimum cost mechanism cannot achieve competitive performance, we believe this is because the selection of rules should not depend on the cost of them, and considering all valid inferences is critical for reasoning; 2) our attention mechanism can effectively model the inference rule selection possibility. Compared with the average cost mechanism, our method achieved a 6.36% accuracy improvement. This also verified the necessity of an effective inference rule probability model."
  }, {
    "heading": "4.5 Effect of Negation Rules",
    "text": "This section investigates the effect of special handling of negation mentioned in Section 2.5. To investigate the necessity of negation rules proposed in our model, we conducted experiments by removing all negation rules from original system, and investigate the change of accuracy.\nTable 8 show the results. We can see that removing negation rules will significantly drop the system performance, which confirm the effectiveness of our proposed negation rules."
  }, {
    "heading": "5 Related Work",
    "text": "Endowing computers with the ability of understanding commonsense story has long a goal of natural language processing. There exist two big challenges: 1)Matching explicit information in the given context; 2)Incorporating implicit commonsense knowledge into human-like reasoning process. Previous machine comprehension tasks (Richardson et al., 2013; Weston et al., 2015; Hermann et al., 2015; Rajpurkar et al.,\n2016) mainly focus on the first challenge, leading their solutions focusing on semantic matching between texts (Weston et al., 2014; Kumar et al., 2015; Narasimhan and Barzilay, 2015; Smith et al., 2015; Sukhbaatar et al., 2015; Hill et al., 2015; Wang et al., 2015, 2016a; Cui et al., 2016; Trischler et al., 2016a,b; Kadlec et al., 2016; Kobayashi et al., 2016; Wang and Jiang, 2016b), but ignore the second issues. One notable task is SNLI (Bowman et al., 2015), which considers entailment between two sentences. This task, however, only provides shallow context and thus needs a few kinds of implicit knowledge (Rocktäschel et al., 2015; Wang and Jiang, 2016a; Angeli et al., 2016; Wang et al., 2016b; Parikh et al., 2016; Henderson and Popa, 2016; Zhao et al., 2017).\nRealizing that story understanding needs commonsense knowledge, many researches have been proposed to learn structural event knowledge. Chambers and Jurafsky (2008) first proposed an unsupervised approach to learn partially ordered sets of events from raw text. Many expansions have been introduced later, including unsupervisedly learning narrative schemas and scripts (Chambers and Jurafsky, 2009; Regneri et al., 2011), event schemas and frames (Chambers and Jurafsky, 2011; Balasubramanian et al., 2013; Sha et al., 2016; Huang et al., 2016; Mostafazadeh et al., 2016b), and some generative models to learn latent structures of event knowledge (Cheung et al., 2013; Chambers, 2013; Bamman et al., 2014; Nguyen et al., 2015). Another direction for learning event-centred knowledge is causality identification (Do et al., 2011; Radinsky et al., 2012; Berant et al., 2014; Hashimoto et al., 2015; Gui et al., 2016), which tried to identify the causality relation in text.\nFor reasoning over these knowledge, Jans et al. (2012) extend introduced skip-grams for collecting statistics. Further improvements include incorporating more information and more complicated models (Radinsky and Horvitz, 2013; Modi and Titov, 2014; Ahrendt and Demberg, 2016). Recent researches tried to solve event prediction problem by transforming it into an language modeling paradigm (Pichotta and Mooney, 2014, 2015, 2016a,b; Rudinger et al., 2015; Hu et al., 2017).\nThe principal difference between previous work and our method is that we not only take various kinds of implicit commonsense knowledge into consideration, but also provide a highly\nextensible framework to exploit these kinds of knowledge for commonsense machine comprehension. We also notice the recent progress in RocStories (Mostafazadeh et al., 2017). Rather than inferring a possible ending generated from document, recent systems solve this task by discriminatively comparing two candidates. This enables very strong stylistic features being added explicitly (Schwartz et al., 2017; Bugert et al., 2017) or implicitly (Schenk and Chiarcos, 2017), which can select hypothesis without any consideration of given document. Also, some augmentation strategies are introduced to produce more training data (Roemmele and Gordon, 2017; Mihaylov and Frank, 2017; Bugert et al., 2017). These methods are dataset-sensitive and are not the main concentration of our paper."
  }, {
    "heading": "6 Conclusions and Future Work",
    "text": "This paper proposes a commonsense machine comprehension method, which performs effective commonsense reasoning by taking heterogenous knowledge into consideration. Specifically, we mine commonsense knowledge from heterogeneous knowledge sources and simultaneously exploit them by proposing a highly extensible multiknowledge reasoning framework. Experiment results shown that our method surpasses baselines by a large margin.\nCurrently, there are little labeled training instances for commonsense machine comprehension, for future work we want to address this issue by developing semi-supervised or unsupervised approaches."
  }, {
    "heading": "Acknowledgments",
    "text": "This work is supported by the National Natural Science Foundation of China under Grants no. 61433015 and 61572477, the National High Technology Development 863 Program of China under Grants no. 2015AA015405, and the Young Elite Scientists Sponsorship Program no. YESS20160177. Moreover, we sincerely thank the reviewers for their valuable comments."
  }],
  "year": 2017,
  "references": [{
    "title": "Improving event prediction by representing script participants",
    "authors": ["Simon Ahrendt", "Vera Demberg."],
    "venue": "Proceedings of NAACL-HLT, pages 546–551.",
    "year": 2016
  }, {
    "title": "Combining natural logic and shallow",
    "authors": ["Gabor Angeli", "Neha Nayak", "Christopher D Manning"],
    "year": 2016
  }, {
    "title": "Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining",
    "authors": ["Stefano Baccianella", "Andrea Esuli", "Fabrizio Sebastiani"],
    "venue": "In LREC,",
    "year": 2010
  }, {
    "title": "Generating coherent event schemas at scale",
    "authors": ["Niranjan Balasubramanian", "Stephen Soderland", "Oren Etzioni Mausam", "Oren Etzioni."],
    "venue": "EMNLP, pages 1721–1731.",
    "year": 2013
  }, {
    "title": "Learning latent personas of film characters",
    "authors": ["David Bamman", "Brendan O’Connor", "Noah A Smith"],
    "venue": "In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),",
    "year": 2014
  }, {
    "title": "Modeling biological processes for reading comprehension",
    "authors": ["Jonathan Berant", "Vivek Srikumar", "Pei-Chun Chen", "Abby Vander Linden", "Brittany Harding", "Brad Huang", "Peter Clark", "Christopher D Manning."],
    "venue": "EMNLP.",
    "year": 2014
  }, {
    "title": "A large annotated corpus for learning natural language inference",
    "authors": ["Samuel R Bowman", "Gabor Angeli", "Christopher Potts", "Christopher D Manning."],
    "venue": "arXiv preprint arXiv:1508.05326.",
    "year": 2015
  }, {
    "title": "LSDSem 2017 : Exploring Data Generation Methods for the Story Cloze Test",
    "authors": ["Michael Bugert", "Yevgeniy Puzikov", "R Andreas", "Judith Eckle-kohler", "Teresa Martin", "Eugenio Mart."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and",
    "year": 2017
  }, {
    "title": "Event schema induction with a probabilistic entity-driven model",
    "authors": ["Nathanael Chambers."],
    "venue": "EMNLP, volume 13, pages 1797–1807.",
    "year": 2013
  }, {
    "title": "Unsupervised learning of narrative schemas and their participants",
    "authors": ["Nathanael Chambers", "Dan Jurafsky."],
    "venue": "Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Lan-",
    "year": 2009
  }, {
    "title": "Template-based information extraction without the templates",
    "authors": ["Nathanael Chambers", "Dan Jurafsky."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume",
    "year": 2011
  }, {
    "title": "Unsupervised learning of narrative event chains",
    "authors": ["Nathanael Chambers", "Daniel Jurafsky."],
    "venue": "ACL, volume 94305, pages 789–797. Citeseer.",
    "year": 2008
  }, {
    "title": "Probabilistic frame induction",
    "authors": ["Jackie Chi Kit Cheung", "Hoifung Poon", "Lucy Vanderwende."],
    "venue": "arXiv preprint arXiv:1302.4813.",
    "year": 2013
  }, {
    "title": "Attention-overattention neural networks for reading comprehension",
    "authors": ["Yiming Cui", "Zhipeng Chen", "Si Wei", "Shijin Wang", "Ting Liu", "Guoping Hu."],
    "venue": "arXiv preprint arXiv:1607.04423.",
    "year": 2016
  }, {
    "title": "Knowledge representation for commonsense reasoning with text",
    "authors": ["Kathleen Dahlgren", "Joyce McDowell", "Edward P Stabler."],
    "venue": "Computational Linguistics, 15(3):149–170.",
    "year": 1989
  }, {
    "title": "Minimally supervised event causality identification",
    "authors": ["Quang Xuan Do", "Yee Seng Chan", "Dan Roth."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 294–303. Association for Computational Linguistic-",
    "year": 2011
  }, {
    "title": "Understanding the difficulty of training deep feedforward neural networks",
    "authors": ["Xavier Glorot", "Yoshua Bengio."],
    "venue": "Aistats, volume 9, pages 249–256.",
    "year": 2010
  }, {
    "title": "Event-driven emotion cause extraction with corpus construction",
    "authors": ["Lin Gui", "Dongyin Wu", "Ruifeng Xu", "Qin Lu", "Yu Zhou."],
    "venue": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1639–1649.",
    "year": 2016
  }, {
    "title": "Generating event causality hypotheses through semantic relations",
    "authors": ["Chikara Hashimoto", "Kentaro Torisawa", "Julien Kloetzer", "Jong-Hoon Oh."],
    "venue": "AAAI, pages 2396–2403.",
    "year": 2015
  }, {
    "title": "A vector space for distributional semantics for entailment",
    "authors": ["James Henderson", "Diana Nicoleta Popa."],
    "venue": "arXiv preprint arXiv:1607.03780.",
    "year": 2016
  }, {
    "title": "Teaching machines to read and comprehend",
    "authors": ["Karl Moritz Hermann", "Tomas Kocisky", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom."],
    "venue": "Advances in Neural Information Processing Systems, pages 1693–",
    "year": 2015
  }, {
    "title": "The goldilocks principle: Reading children’s books with explicit memory representations",
    "authors": ["Felix Hill", "Antoine Bordes", "Sumit Chopra", "Jason Weston."],
    "venue": "arXiv preprint arXiv:1511.02301.",
    "year": 2015
  }, {
    "title": "Enhancing text clustering by leveraging wikipedia semantics",
    "authors": ["Jian Hu", "Lujun Fang", "Yang Cao", "Hua-Jun Zeng", "Hua Li", "Qiang Yang", "Zheng Chen."],
    "venue": "Proceedings of the 31st annual international ACM SIGIR conference on Research and development in",
    "year": 2008
  }, {
    "title": "What happens next? future subevent prediction using contextual hierarchical lstm",
    "authors": ["Linmei Hu", "Juanzi Li", "Liqiang Nie", "Xiao-Li Li", "Chao Shao."],
    "venue": "Proceedings of the 31th AAAI Conference on Artificial Intelligence.",
    "year": 2017
  }, {
    "title": "Liberal event extraction and event schema induction",
    "authors": ["Lifu Huang", "T Cassidy", "X Feng", "H Ji", "CR Voss", "J Han", "A Sil."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-",
    "year": 2016
  }, {
    "title": "Learning deep structured semantic models for web search using clickthrough data",
    "authors": ["Po-Sen Huang", "Xiaodong He", "Jianfeng Gao", "Li Deng", "Alex Acero", "Larry Heck."],
    "venue": "Proceedings of the 22nd ACM international conference on Conference on informa-",
    "year": 2013
  }, {
    "title": "Skip n-grams and ranking functions for predicting script events",
    "authors": ["Bram Jans", "Steven Bethard", "Ivan Vulić", "Marie Francine Moens."],
    "venue": "Proceedings of the 13th Conference of the European Chapter of the Association for Computa-",
    "year": 2012
  }, {
    "title": "Text understanding with the attention sum reader network",
    "authors": ["Rudolf Kadlec", "Martin Schmid", "Ondrej Bajgar", "Jan Kleindienst."],
    "venue": "arXiv preprint arXiv:1603.01547.",
    "year": 2016
  }, {
    "title": "Wordnet: An electronic lexical database",
    "authors": ["Adam Kilgarriff", "Christiane Fellbaum"],
    "year": 2000
  }, {
    "title": "Dynamic entity representation with max-pooling improves machine reading",
    "authors": ["Sosuke Kobayashi", "Ran Tian", "Naoaki Okazaki", "Kentaro Inui."],
    "venue": "Proceedings of NAACL-HLT, pages 850–855.",
    "year": 2016
  }, {
    "title": "Metric learning: A survey",
    "authors": ["Brian Kulis."],
    "venue": "Foundations and Trends in Machine Learning, 5(4):287– 364.",
    "year": 2012
  }, {
    "title": "Ask me anything: Dynamic memory networks for natural language processing",
    "authors": ["Ankit Kumar", "Ozan Irsoy", "Jonathan Su", "James Bradbury", "Robert English", "Brian Pierce", "Peter Ondruska", "Ishaan Gulrajani", "Richard Socher."],
    "venue": "CoRR, abs/1506.07285.",
    "year": 2015
  }, {
    "title": "The Stanford CoreNLP natural language processing toolkit",
    "authors": ["Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky."],
    "venue": "Association for Computational Linguistics (ACL) System Demonstrations,",
    "year": 2014
  }, {
    "title": "Story Cloze Ending Selection Baselines and Data Examination",
    "authors": ["Todor Mihaylov", "Anette Frank."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (ISDSEM 2017), pages 2–7, Valencia, Spain.",
    "year": 2017
  }, {
    "title": "Distributed representations of words and phrases and their compositionality",
    "authors": ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean."],
    "venue": "Advances in neural information processing systems, pages 3111–3119.",
    "year": 2013
  }, {
    "title": "Learning to link with wikipedia",
    "authors": ["David Milne", "Ian H Witten."],
    "venue": "Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.",
    "year": 2008
  }, {
    "title": "Inducing neural models of script knowledge",
    "authors": ["Ashutosh Modi", "Ivan Titov."],
    "venue": "CoNLL, volume 14, pages 49–57.",
    "year": 2014
  }, {
    "title": "A corpus and cloze evaluation for deeper understanding of commonsense stories",
    "authors": ["Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen."],
    "venue": "Proceedings of NAACL-",
    "year": 2016
  }, {
    "title": "Caters: Causal and temporal relation scheme for semantic annotation of event structures",
    "authors": ["Nasrin Mostafazadeh", "Alyson Grealish", "Nathanael Chambers", "James Allen", "Lucy Vanderwende."],
    "venue": "Proceedings of the The 4th Workshop on EVENTS: Def-",
    "year": 2016
  }, {
    "title": "LSDSem 2017 Shared Task : The Story Cloze Test",
    "authors": ["Nasrin Mostafazadeh", "Michael Roth", "Annie Louis", "Nathanael William Chambers", "James F. Allen."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics",
    "year": 2017
  }, {
    "title": "Machine comprehension with discourse relations",
    "authors": ["Karthik Narasimhan", "Regina Barzilay."],
    "venue": "ACL (1), pages 1253–1262.",
    "year": 2015
  }, {
    "title": "Generative event schema induction with entity disambiguation",
    "authors": ["Kiem-Hieu Nguyen", "Xavier Tannier", "Olivier Ferret", "Romaric Besançon."],
    "venue": "Proceedings of the 53rd annual meeting of the Association for Computational Linguistics (ACL-15).",
    "year": 2015
  }, {
    "title": "The cognitive structure of emotions",
    "authors": ["Andrew Ortony", "Gerald L Clore", "Allan Collins."],
    "venue": "Cambridge university press.",
    "year": 1990
  }, {
    "title": "A decomposable attention model for natural language inference",
    "authors": ["Ankur P Parikh", "Oscar Täckström", "Dipanjan Das", "Jakob Uszkoreit."],
    "venue": "arXiv preprint arXiv:1606.01933.",
    "year": 2016
  }, {
    "title": "Statistical script learning with multi-argument events",
    "authors": ["Karl Pichotta", "Raymond J Mooney."],
    "venue": "EACL, volume 14, pages 220–229.",
    "year": 2014
  }, {
    "title": "Learning statistical scripts with lstm recurrent neural networks",
    "authors": ["Karl Pichotta", "Raymond J Mooney."],
    "venue": "Proceedings of the 30th AAAI Conference on Artificial Intelligence.",
    "year": 2015
  }, {
    "title": "Statistical script learning with recurrent neural networks",
    "authors": ["Karl Pichotta", "Raymond J Mooney."],
    "venue": "EMNLP 2016, page 11.",
    "year": 2016
  }, {
    "title": "Using sentence-level lstm language models for script inference",
    "authors": ["Karl Pichotta", "Raymond J Mooney."],
    "venue": "arXiv preprint arXiv:1604.02993.",
    "year": 2016
  }, {
    "title": "Learning causality for news events prediction",
    "authors": ["Kira Radinsky", "Sagie Davidovich", "Shaul Markovitch."],
    "venue": "Proceedings of the 21st international conference on World Wide Web, pages 909–918. ACM.",
    "year": 2012
  }, {
    "title": "Mining the web to predict future events",
    "authors": ["Kira Radinsky", "Eric Horvitz."],
    "venue": "Proceedings of the sixth ACM international conference on Web search and data mining, pages 255–264. ACM.",
    "year": 2013
  }, {
    "title": "Squad: 100,000+ questions for machine comprehension of text",
    "authors": ["Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang."],
    "venue": "arXiv preprint arXiv:1606.05250.",
    "year": 2016
  }, {
    "title": "Learning script participants from unlabeled data",
    "authors": ["Michaela Regneri", "Alexander Koller", "Josef Ruppenhofer", "Manfred Pinkal."],
    "venue": "RANLP, pages 463–470.",
    "year": 2011
  }, {
    "title": "Mctest: A challenge dataset for the open-domain machine comprehension of text",
    "authors": ["Matthew Richardson", "Christopher JC Burges", "Erin Renshaw."],
    "venue": "EMNLP, volume 3, page 4.",
    "year": 2013
  }, {
    "title": "Reasoning about entailment with neural attention",
    "authors": ["Tim Rocktäschel", "Edward Grefenstette", "Karl Moritz Hermann", "Tomáš Kočiskỳ", "Phil Blunsom."],
    "venue": "arXiv preprint arXiv:1509.06664.",
    "year": 2015
  }, {
    "title": "An RNN-based Binary Classifier for the Story Cloze Test",
    "authors": ["Melissa Roemmele", "Andrew M Gordon."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (ISDSEM 2017), pages 74–80, Valencia, Spain.",
    "year": 2017
  }, {
    "title": "Script induction as language modeling",
    "authors": ["Rachel Rudinger", "Pushpendre Rastogi", "Francis Ferraro", "Benjamin Van Durme."],
    "venue": "EMNLP, pages 1681–1686.",
    "year": 2015
  }, {
    "title": "ResourceLean Modeling of Coherence in Commonsense Stories",
    "authors": ["Niko Schenk", "Christian Chiarcos."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (ISDSEM 2017), pages 68–73, Valencia, Spain.",
    "year": 2017
  }, {
    "title": "Story Cloze Task : UW NLP System",
    "authors": ["Roy Schwartz", "Maarten Sap", "Ioannis Konstas", "Leila Zilles", "Yejin Choi", "Noah A Smith", "Computer Science."],
    "venue": "The 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics (ISDSEM",
    "year": 2017
  }, {
    "title": "Joint learning templates and slots for event schema induction",
    "authors": ["Lei Sha", "Sujian Li", "Baobao Chang", "Zhifang Sui."],
    "venue": "Proceedings of NAACL-HLT, pages 428–434.",
    "year": 2016
  }, {
    "title": "A strong lexical matching method for the machine comprehension test",
    "authors": ["Ellery Smith", "Nicola Greco", "Matko Bosnjak", "Andreas Vlachos."],
    "venue": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1693–",
    "year": 2015
  }, {
    "title": "End-to-end memory networks. In Advances in neural information processing systems, pages 2440–2448",
    "authors": ["Sainbayar Sukhbaatar", "Jason Weston", "Rob Fergus"],
    "year": 2015
  }, {
    "title": "A parallel-hierarchical model for machine comprehension on sparse data",
    "authors": ["Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Jing He", "Phillip Bachman", "Kaheer Suleman."],
    "venue": "arXiv preprint arXiv:1603.08884.",
    "year": 2016
  }, {
    "title": "Natural language comprehension with the epireader",
    "authors": ["Adam Trischler", "Zheng Ye", "Xingdi Yuan", "Kaheer Suleman."],
    "venue": "arXiv preprint arXiv:1606.02270.",
    "year": 2016
  }, {
    "title": "Employing external rich knowledge for machine comprehension",
    "authors": ["Bingning Wang", "Shangmin Guo", "Kang Liu", "Shizhu He", "Jun Zhao."],
    "venue": "Proceedings of IJCAI.",
    "year": 2016
  }, {
    "title": "Machine comprehension with syntax, frames, and semantics",
    "authors": ["Hai Wang", "Mohit Bansal", "Kevin Gimpel", "David A McAllester."],
    "venue": "ACL (2), pages 700–706.",
    "year": 2015
  }, {
    "title": "Learning natural language inference with lstm",
    "authors": ["Shuohang Wang", "Jing Jiang."],
    "venue": "Proceedings of NAACL-HLT, pages 1442–1451.",
    "year": 2016
  }, {
    "title": "Machine comprehension using match-lstm and answer pointer",
    "authors": ["Shuohang Wang", "Jing Jiang."],
    "venue": "arXiv preprint arXiv:1608.07905.",
    "year": 2016
  }, {
    "title": "Sentence similarity learning by lexical decomposition and composition",
    "authors": ["Zhiguo Wang", "Haitao Mi", "Abraham Ittycheriah."],
    "venue": "arXiv preprint arXiv:1602.07019.",
    "year": 2016
  }, {
    "title": "Towards ai-complete question answering: A set of prerequisite toy tasks",
    "authors": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Alexander M Rush", "Bart van Merriënboer", "Armand Joulin", "Tomas Mikolov."],
    "venue": "arXiv preprint arXiv:1502.05698.",
    "year": 2015
  }, {
    "title": "Memory networks",
    "authors": ["Jason Weston", "Sumit Chopra", "Antoine Bordes."],
    "venue": "arXiv preprint arXiv:1410.3916.",
    "year": 2014
  }, {
    "title": "Ordinal common-sense inference",
    "authors": ["Sheng Zhang", "Rachel Rudinger", "Kevin Duh", "Benjamin Van Durme."],
    "venue": "arXiv preprint arXiv:1611.00601.",
    "year": 2016
  }, {
    "title": "Textual entailment with structured attentions and composition",
    "authors": ["Kai Zhao", "Liang Huang", "Mingbo Ma."],
    "venue": "arXiv preprint arXiv:1701.01126.",
    "year": 2017
  }],
  "id": "SP:d169cdb8644071d2b180fdd86247c85023f6fd50",
  "authors": [{
    "name": "Hongyu Lin",
    "affiliations": []
  }, {
    "name": "Le Sun",
    "affiliations": []
  }, {
    "name": "Xianpei Han",
    "affiliations": []
  }],
  "abstractText": "Reasoning with commonsense knowledge is critical for natural language understanding. Traditional methods for commonsense machine comprehension mostly only focus on one specific kind of knowledge, neglecting the fact that commonsense reasoning requires simultaneously considering different kinds of commonsense knowledge. In this paper, we propose a multi-knowledge reasoning method, which can exploit heterogeneous knowledge for commonsense machine comprehension. Specifically, we first mine different kinds of knowledge (including event narrative knowledge, entity semantic knowledge and sentiment coherent knowledge) and encode them as inference rules with costs. Then we propose a multiknowledge reasoning model, which selects inference rules for a specific reasoning context using attention mechanism, and reasons by summarizing all valid inference rules. Experiments on RocStories show that our method outperforms traditional models significantly.",
  "title": "Reasoning with Heterogeneous Knowledge for Commonsense Machine Comprehension"
}