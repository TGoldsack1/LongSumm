{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Given a dataset, similarity relationship between examples can be represented by a graph in which each example is represented by a vertex. While pairwise relationship between two vertices can be represented by an edge in a normal graph, a higher order relationship involving multiple vertices can be captured by a hyperedge, which means that all the corresponding examples are similar to one another. Hypergraphs have been used in several learning applications such as clustering of categorical data (Gibson et al., 1998), multi-label classification (Sun et al., 2008), Laplacian sparse coding (Gao et al., 2013), image classification (Yu et al., 2012), image retrieval (Huang et al., 2010), mapping users across different social networks (Tan et al., 2014) and predicting edge labels in hypernode graphs (Ricatte et al., 2014).\n*Equal contribution 1University of Hong Kong, Hong Kong. 2This research was partially supported by the Hong Kong RGC under the grant 17200214. Correspondence to: T-H. Hubert Chan <hubert@cs.hku.hk>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nIn this paper, we consider semi-supervised learning on an edge-weighted hypergraph H = (V,E,w), with a set L of labeled vertices, whose labels are given by f∗L ∈ {−1,+1}L. The task is to predict the labels of the unlabeled vertices N , with the working principle that vertices contained in a hyperedge e ∈ E are more similar to one another if the edge weight we is larger. This problem is also known as transductive inference and has been studied in (Zhou et al., 2006) and (Hein et al., 2013).\nHowever, the methods in (Zhou et al., 2006) have been criticized by (Agarwal et al., 2006), because essentially a hypergraph is converted into a normal graph. For instance, given a hyperedge e containing vertices S, either (i) a clique is added between the vertices in S, or (ii) a star is formed by adding a new vertex ve connecting every vertex in S to ve. Then, a standard convex program using a regularization potential function for normal graphs can be applied (Zhu et al., 2003). By choosing appropriate edge weights, it was shown in (Agarwal et al., 2006) that the two approaches are equivalent to the following convex program relaxation:\nmin Φold(f) := 1\n2 ∑ e∈E we ∑\n{u,v}∈(e2)\n(fu − fv)2\nsubject to fu ∈ [−1, 1], ∀u ∈ V fu = f ∗ u , ∀u ∈ L.\nOn the other hand, it was proposed in (Hein et al., 2013) that the following regularization function is more suitable to capture hyperedge expansion:\nΦnew(f) := 1\n2 ∑ e∈E we · (max u∈e fu −min v∈e fv) 2.\nIndeed, it was shown in (Hein et al., 2013) that their approach outperforms (Zhou et al., 2006) on several datasets from the UCI Machine Learning Repository (Lichman, 2013).\nLoss Function. In (Hein et al., 2013), a squared loss function was added by considering the convex program with objective function Φnew(f) + µ ‖f − f∗‖22 on f ∈ [−1, 1]V , where µ > 0 is a parameter to be tuned, f∗L is given by the labeled vertices L, and for the unlabeled vertices f∗N = 0.\nThe loss function allows errors in the labeled vertices, and also ensures that the minimizer is unique. However, as a result, unlabeled vertices have a tendency to acquire f values close to 0. This might remove useful information as illustrated in the following example.\nExample. In Figure 1.1, vertices a, b ∈ L are labeled as +1 and c ∈ L is labeled as −1. Vertices x, y ∈ N are unlabeled. There are three (undirected) edges: {a, x}, {b, x} and {x, y, c}, each with unit weight.\nBy choosing µ = 12 for squared loss function, the unique minimizer gives fx = 15 and fy = 0. Hence, this solution gives no useful information regarding the label for vertex y.\nOn the other hand, if we just use the objective function Φnew(f) with the constraints fL = f∗L, then in an optimal solution, fx = 13 , but fy could be anywhere in the confidence interval [−1, 13 ]. Hence, in this case, we could use the average value − 13 to predict −1 for vertex y.\nOur Contributions. In this paper, we revisit the approach used in (Hein et al., 2013) and consider several extensions and simplifications. We summarize our results and give an outline of the paper as follows.\n1. Unified Framework for Directed Hypergraphs. Inspired also from the recent result on Laplacians for directed normal graphs (Yoshida, 2016), we introduce a semisupervised learning framework using directed hypergraphs that can capture higher order causal relationships. This notion of directed hypergraph was first introduced in (Gallo et al., 1993), who considered applications in propositional logic, analyzing dependency in relational database, and traffic analysis. On a high level, a directed hyperedge e consists of a tail set Te pointing to a head set He such that a vertex in Te labeled +1 implies that a vertex in He is more likely to be labeled +1. (Equivalently in terms of its contrapositive, a vertex in He labeled −1 implies that a vertex in Te is more likely to be labeled −1.) In Section 2, we formally define the model and the corresponding potential function Φ. An additional advantage of our potential function is that there is no need to tune any parameters.\n2. Confidence Interval for Unlabeled Vertices. Observe that the minimizer for our convex program might not be unique. In Section 3, we introduce the concept of confidence interval for each unlabeled vertex that can be useful for predicting its label. Furthermore, we provide an algorithm to calculate the confidence interval given an optimal solution.\n3. Simpler Subgradient Method. Since the new potential function is not everywhere differentiable but still convex, we use the subgradient method (Shor et al., 1985) to obtain an estimated minimizer for label prediction. Inspired by the diffusion processes used for defining Laplacians in hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), in Section 4, we define a simple Markov operator that returns a subgradient for Φ, which is used to solve the underlying convex program. We remark that our framework is very easy to understand, because it is a variation on the well-known gradient descent.\nIn contrast, the primal-dual approach in (Hein et al., 2013) considers the convex conjugate of the primal objective and involves complicated update operations on the primal and dual variables. The subgradient used in our approach gives the update direction, and we can actually solve exactly the same convex program with a much simpler method."
  }, {
    "heading": "4. Experimental Results on Real-World Datasets. In",
    "text": "Section 5, we revisit some datasets in the UCI Machine Learning Repository (Lichman, 2013), and experiments confirm that our prediction model based on confidence interval gives better accuracy than that in (Hein et al., 2013). Our simpler subgradient method takes more iterations than the primal-dual method (Hein et al., 2013), but each iteration is much faster. Experiments show that overall both methods have similar running times, and the subgradient method has an advantage when the number of vertices is much larger than the number of edges.\nMoreover, using the DBLP dataset (Ley, 2009), our experiments also support that using directed hypergraphs to capture causal relationships can improve the prediction accuracy. The experiments for directed hypergraphs are described in the full version."
  }, {
    "heading": "2. Preliminaries",
    "text": "We consider an edge-weighted directed hypergraph H = (V,E,w) with vertex set V (with n = |V |), edge set E and weight function w : E → R+. Each hyperedge e ∈ E consists of a tail set Te ⊆ V and a head set He ⊆ V (which are not necessarily disjoint); we use the convention that the direction is from tail to head. For x ∈ R, we denote [x]+ := max{x, 0}.\nIn our application, each vertex v ∈ V is supposed to have a label in {−1,+1}. Intuitively, the directed hypergraph attempts to capture the rule that for each edge e ∈ E, if there is a vertex in Te having label +1, then it is more likely for vertices in He to receive label +1. In terms of its contrapositive, if there is a vertex in He having label −1, then it is more likely for vertices in Te to receive label −1.\nWe use f ∈ RV to denote a vector, where the coordi-\nnates are labeled by vertices in V . For U ⊆ V , we use fU ∈ RU to denote the vector restricting f to coordinates inU . In semi-supervised learning, we consider a setL ⊆ V of labeled vertices, which have labels f∗L ∈ {−1,+1}L. Typically, |L| |V | and the task is to assign a label in {−1,+1} to each unlabeled vertex in N := V \\ L, using information from the directed hypergraph H .\nBy relaxing labels to be in the interval [−1, 1], we consider the following regularization potential function Φ : RV → R:\nΦ(f) = 1\n2 ∑ e∈E we · ([∆e(f)]+)2,\nwhere ∆e(f) := max(u,v)∈Te×He(fu − fv) = maxu∈Te fu −minv∈He fv .\nIn particular, there is a penalty due to edge e only if some vertex in Te receives a label larger than that of some vertex in He. The convexity of Φ is proved in the full version.\nOur approach is to consider the following convex program to obtain an estimated minimizer f ∈ [−1, 1]V , which can be rounded to an integer solution for labeling all vertices.\nmin Φ(f) (CP1) subject to fu ∈ [−1, 1], ∀u ∈ V\nfu = f ∗ u , ∀u ∈ L\nSince the f values for the labeled vertices L are fixed in (CP1), we also view Φ : RN → R as a function on the f values of unlabeled vertices N . We use OPT ⊂ RV to denote the set of optimal solutions to (CP1).\nTrivial Edges. An edge e ∈ E is trivial if there exist vertices u ∈ Te ∩ L and v ∈ He ∩ L such that f∗u = +1 and f∗v = −1. As trivial edges contribute constant towards the objective function Φ, we shall assume that there are no trivial edges in the convex program (CP1).\nSpecial Cases. Our directed hypergraph model can capture other graph models as follows.\n1. Undirected Hypergraphs. For each hyperedge e, we can set Te = He to the corresponding subset of vertices. 2. Undirected Normal Graphs. For each edge e = {u, v}, we can set Te = He = e. Observe that in this case, the potential function becomes Φ(f) =∑\n(u,v)∈E wuv(fu− fv)2, which is differentiable, and hence, (CP1) can be solved by standard techniques like gradient descent.\nSoft Constraints. In (Hein et al., 2013), each labeled vertex u ∈ L can also have some weight µu ∈ R+, which can, for instance, indicate how trustworthy the label\nf∗u ∈ {−1,+1} is. The following relaxation is considered.\nmin Φ̂(f) := Φ(f) + 1\n2 ∑ u∈L µu(fu − f∗u)2 (CP2)\nsubject to fu ∈ [−1, 1],∀u ∈ V.\nObserve that (CP2) can also be expressed in the framework of (CP1). We simply consider an augmented hypergraph Ĥ such that all vertices V are treated as unlabeled, and for each u ∈ L, we add a new vertex û with label f∗u and a new undirected edge {u, û} with weight µu. Then, it follows that the convex program (CP1) for the augmented instance for Ĥ is exactly the same as (CP2).\nChallenges Ahead. We next outline how we resolve the encountered challenges when we use (CP1) for semisupervised learning.\n• Unlike the case for normal graphs, the set OPT can contain more than one optimal solution for (CP1). In Section 3, we prove some structural properties of the convex program, and illustrate that each u ∈ N has some confidence interval from which we can predict its label. • The function Φ is not everywhere differentiable. Hence, we use the subgradient method (Shor et al., 1985). In Section 4, we give a method to generate a subgradient, which is inspired by the continuous diffusion processes for hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016), and our method can in fact be viewed as a discretized version."
  }, {
    "heading": "3. Confidence Interval for Semi-supervised Learning",
    "text": "In general, a minimizer for (CP1) might not be unique. Hence, we introduce the concept of confidence interval.\nDefinition 3.1 (Confidence Interval) For each u ∈ V , we define its confidence interval to be [mu,Mu], where mu := minf∈OPT fu and Mu := maxf∈OPT fu. The confidence intervals induce the lower and the upper confidence vectors, ~m and ~M ∈ RV , respectively.\nIn Section 3.1, we give the proof of the following lemma, which states that the confidence vectors ~m and ~M are optimal solutions, and so are their convex combinations.\nLemma 3.1 (Confidence Vectors Give Optimal Solutions) For any λ ∈ [0, 1], the convex combination λ~m + (1− λ) ~M ∈ OPT is optimal for (CP1).\nSemi-supervised Learning via Confidence Interval. Lemma 3.1 suggests what one can do when (CP1) has more than one optimal solution. Specifically, in Algorithm 1, the\naverage vector 12 (~m + ~M) ∈ OPT can be used for label prediction. We show that the confidence vectors ~m and ~M can be recovered from any optimal solution f ∈ OPT, which in turn can be estimated by the subgradient method described in Section 4. Algorithm 1 Semi-Supervised Learning\n1: Input: Directed hypergraph H = (V,E,w), labels f∗L for labeled vertices L 2: Compute (estimated) confidence vectors (~m, ~M) ∈ RN × RN , either by Algorithm 2 or 3. 3: Compute average vector fN ← 12 (~m+ ~M). 4: Compute threshold θ ← 1|N | ∑ u∈N fu. 5: for each u ∈ N do 6: if fu ≥ θ then 7: f̂u ← +1; 8: else 9: f̂u ← −1;\n10: end if 11: end for 12: return f̂N\nFine-Tuning Parameters. In view of Lemma 3.1, one could further optimize the choice of λ ∈ [0, 1] in defining fN ← λ~m+ (1−λ) ~M in Line 3. Similarly, one could pick the threshold θ to be the ϑ-percentile of the sorted coordinates of fN , for some choice of ϑ ∈ [0, 1]. The parameters λ and ϑ can be tuned using standard techniques like cross-validation. However, to illustrate our concepts, we keep the description simple without introducing too many free parameters."
  }, {
    "heading": "3.1. Properties of Confidence Vectors",
    "text": "We derive some properties of the confidence vectors to prove Lemma 3.1. The full proofs of Lemma 3.2 and 3.3 are given in the full version.\nGiven a feasible solution f ∈ RV to (CP1), we define the following:\n1. Se(f) := arg maxu∈Te fu ⊆ Te and Ie(f) := arg minv∈He fv ⊆ He. 2. f(Se) := maxu∈Te fu and f(Ie) := minv∈He fv . Hence, we have ∆e(f) = f(Se)− f(Ie). 3. The set of active edges with respect to f is E(f) := {e ∈ E : ∆e(f) > 0}.\nThe following lemma states even though a minimizer for (CP1) might not be unique, there are still some structural properties for any optimal solution.\nLemma 3.2 (Active Edges in an Optimal Solution) Suppose f and g are optimal solutions to (CP1). Then, for all e ∈ E, [∆e(f)]+ = [∆e(g)]+. In particular, this implies that the set of active edges E∗ := E(f) = E(g) in any op-\ntimal solution is uniquely determined. Hence, for e ∈ E∗, we can define the corresponding ∆∗e = ∆e(f).\nDefinition 3.2 (Pinned Vertex) An unlabeled vertex u is pinned in a solution f ∈ RV if there exist active edges e and e′ ∈ E(f) such that u ∈ Se(f)∩ Ie′(f), in which case we say that the edges e and e′ pin the vertex u under f .\nLemma 3.3 (Extending an Active Edge) Suppose edge e ∈ E(f) is active in an optimal solution f . If He does not contain a vertex labeled with −1, then there exist u ∈ Ie(f) and another active edge e′ ∈ E(f) such that the following holds.\n(a) The edges e and e′ pin u under f , i.e., u ∈ Se′(f). (b) If g is an optimal solution, then Ie(f) ∩ Se′(f) =\nIe(g) ∩ Se′(g) and fu = gu."
  }, {
    "heading": "An analogous result holds when Te does not contain any",
    "text": "vertex labeled with +1."
  }, {
    "heading": "In particular, for any active edge e ∈ E∗, the extremal values f∗(Se) := maxu∈Te fu and f",
    "text": "∗(Ie) := minu∈He fu are uniquely determined by any optimal solution f .\nCorollary 3.1 (Pinned Vertices) In any optimal solution, the set of pinned vertices is uniquely determined. We use L∗ to denote the set of labeled or pinned vertices in an optimal solution. Then, for each u ∈ L∗, its value f∗u in any optimal solution is also uniquely determined.\nFrom Corollary 3.1, the confidence interval for any u ∈ L∗ contains exactly one value, namely the unique value f∗u in any optimal solution. The following lemma gives a characterization of an optimal solution.\nLemma 3.4 Characterization of Optimal Solutions A solution f to (CP1) is optimal iff the following conditions hold.\n(a) For each u ∈ L∗, fu = f∗u . (b) For each active edge e ∈ E∗, both the maximum\nmaxu∈Te fu and the minimum minv∈He fv are attained by vertices in L∗. (c) For each inactive edge e /∈ E∗, for all u ∈ Te and v ∈ He, fu ≤ fv .\nProof: We first observe that Corollary 3.1 states that the values of the vertices in L∗ are uniquely determined in any optimal solution. Hence, any optimal solution must satisfy the three conditions. We next show that the three conditions implies that the objective value is optimal.\nOnce the values for vertices in L∗ are fixed, Lemma 3.3 and condition (b) implies that the contribution of all active edges E∗ are determined and are the same as any optimal solution.\nFinally, condition (c) implies that edges not in E∗ do not have any contribution towards the objective function. Hence, any solution satisfying the three conditions must be optimal.\nDeriving Confidence Vectors. To prove Lemma 3.5, we define a procedure that returns a vector ~m ∈ V R such that for any optimal f ∈ OPT, we have f ≥ ~m. Moreover, we shall show that ~m ∈ OPT and hence ~m is the lower confidence vector. The argument for the upper confidence vector ~M is similar. For the special case of undirected hypergraphs, the procedure can be simplified to Algorithm 2 in Section 3.2.\nLemma 3.5 (Confidence Vectors are Optimal: Proof of Lemma 3.1) The confidence vectors ~m and ~M defined in Definition 3.1 are optimal solutions to (CP1). This implies that any of their convex combination is also optimal.\nProof: We give a procedure that returns a vector ~m such that at any moment during the procedure, the following invariant is maintained: for any f ∈ OPT, f ≥ ~m.\nThe following steps correspond to maintaining the conditions in Lemma 3.4.\n(a) Initialization. For v ∈ L∗, set mv := f∗v ; for v /∈ L∗, set mv := −1. This satisfies the invariant, because for any f ∈ OPT and any v ∈ L∗, fv = f∗v .\n(b) Preserving Active Edges. For each v /∈ L∗, set mv ← max{mv,maxe∈E∗:v∈He f∗(Ie)}. Observe that Lemma 3.4(b) implies that for any optimal f ∈ OPT, any e ∈ E∗ and any v ∈ He, fv ≥ f∗(Ie). Hence, the invariant is maintained.\n(c) Preserving Inactive Edges. While there is an inactive edge e /∈ E∗ such that u ∈ Te, v ∈ He and mu > mv , set mv ← mu. We argue why each such update preserves the invariant. Consider any optimal f ∈ OPT. Before this update, the invariant holds. Hence, we have mu ≤ fu. Moreover, Lemma 3.4 implies that fu ≤ fv . Therefore, after setting mv ← mu, we still have mv ≤ fv .\nFinally, observe that after step (b), the coordinates of ~m can take at most n distinct values. Moreover, after each update in step (c), one coordinate of ~m must increase strictly. Hence, this procedure will terminate.\nWe next argue that ~m is an optimal solution by checking that it satisfies the conditions in Lemma 3.4.\nCondition (a). Observe that for each v ∈ L∗, mv is initialized to f∗v . Afterwards the value mv could only be increased. However, because the invariant holds when the procedure terminates, it must be the case that mv = f∗v at the end.\nCondition (b). The procedure makes sure that at the end of\nstep (b), for every active edge e ∈ E∗, minv∈He mv can be attained by some vertex in L∗. Since only mv for v /∈ L∗ can be increased in step (c), it follows that in the end, the minimum can still be attained by some vertex in L∗.\nNext, consider u ∈ Te, where e ∈ E∗. For any optimal solution f , Lemma 3.3 implies that fu ≤ f∗(Se). Hence, the invariant implies thatmu ≤ fu ≤ f∗(Se). Since condition (a) holds, this means that maxv∈Te mv can be attained by some vertex in L∗.\nCondition (c). This is clearly satisfied because of the while-termination condition.\nTherefore, we have ~m ∈ OPT, as required.\nThe proof for the upper confidence vector ~M is similar. We omit the detailed proof and just give the corresponding procedure to return ~M .\n(a) Initialization. For v ∈ L∗, set Mv := f∗v ; for v /∈ L∗, set Mv := +1.\n(b) Preserving Active Edges. For each v /∈ L∗, set Mv ← min{Mv,mine∈E∗:v∈Te f∗(Se)}.\n(c) Preserving Inactive Edges. While there is an inactive edge e /∈ E∗ such that u ∈ Te, v ∈ He and Mu > Mv , set Mu ←Mv .\nThe same argument can show that for any optimal f ∈ OPT, we have f ≤ ~M . Moreover, we also have ~M ∈ OPT."
  }, {
    "heading": "3.2. Computing the Confidence Interval",
    "text": "As mentioned before, the proof of Lemma 3.5 implicitly gives a procedure to compute the confidence vectors from any optimal solution. For the special case of undirected hypergraphs, a simplified version of the procedure is given in Algorithm 2.\nAlternatively, we can try to solve the convex program (CP1), for example using Algorithm 5 in Section 4, from two initial feasible solutions to heuristically estimate the confidence vectors. In Algorithm 3, one instance approaches an optimal solution from high f values and the other from low f values."
  }, {
    "heading": "4. Subgradient Method via Markov Operator",
    "text": "Resolving Ties. Observe that Φ : RN → R is differentiable at fN ∈ RN that has distinct coordinates. For the purpose of computing a subgradient, we assume that there is some global ordering π on V to resolve ties among coordinates with the same value. In particular, the vertices in L having label +1 are the highest, and those in L labeled −1 are the lowest. Hence, in this section, we may assume that any arg max or arg min operator over a subset of vertices\nAlgorithm 2 Confidence Intervals for Undirected Hypergraphs\n1: Input: Undirected hypergraph H = (V,E,w), label vector f∗L and tolerance ≥ 0. 2: Let f be a solution of (CP1), either by Algorithm 5 or by PDHG method (Hein et al., 2013) 3: For all v ∈ V , set p(v)← v, mv ← −1, Mv ← +1. 4: Ê := {e ∈ E : ∆e(f) ≤ } 5: while ∃e1 6= e2 ∈ Ê, e1 ∩ e2 6= ∅ do 6: Ê ← (Ê \\ {e1, e2}) ∪ {e1 ∪ e2} 7: end while 8: for each e ∈ Ê do 9: x← an arbitrary vertex in e\n10: for each vertex v ∈ e do 11: p(v)← p(x) 12: end for 13: end for 14: for each vertex v ∈ L do 15: mp(v) ← f∗v , Mp(v) ← f∗v 16: end for 17: for each edge e ∈ E such that ∆e(f) > do 18: for each vertex v ∈ e do 19: mp(v) ← max{mp(v), f(Ie)} 20: Mp(v) ← min{Mp(v), f(Se)} 21: end for 22: end for 23: for each vertex v ∈ V do 24: mv ← mp(v), Mv ←Mp(v) 25: end for 26: return vectors (~m, ~M)\nwill return a unique vertex.\nWe next define a Markov operator that is inspired from the diffusion processes on hypergraphs (Louis, 2015) and directed graphs (Yoshida, 2016) in the context of defining Laplacians. We denote the projection operator ΠN : RV → RN that takes f ∈ RV and returns the restricted vector fN ∈ RN .\nLemma 4.1 For f ∈ [−1, 1]V that is feasible in (CP1), the Markov operator Mf given in Algorithm 4 returns a subgradient of Φ : RN → R at fN .\nProof: (Sketch) Observe that if fN ∈ RN has distinct coordinates, then Φ is differentiable at fN , and Mf gives exactly the gradient (which is the only possible subgradient in this case). Observe that in our subgradient method application, we could imagine that at every iteration, infinitesimal perturbation is performed on the current solution to ensure that all coordinates are distinct, and ties are resolved according to our global ordering π.\nAlgorithm 3 Estimate confidence interval 1: Input: Directed hypergraph H = (V,E,w), labels f∗L\nfor labeled vertices L 2: Construct feasible f (0,+)N ← +1 ∈ RN with all entries\nbeing +1; 3: Construct feasible f (0,−)N ← −1 ∈ RN with all entries\nbeing −1; 4: ~M ← SGM(f (0,+)N ); 5: ~m← SGM(f (0,−)N ); 6: return the vectors (~m, ~M)\nAlgorithm 4 Markov Operator M : RV → RN\n1: Input: Directed hypergraph H = (V,E,w), feasible f ∈ RV for (CP1) 2: Construct symmetric matrix A ∈ RV×V ; set A← 0. 3: for each e ∈ E such that ∆e(f) > 0 do 4: u← arg maxu∈Te fu; 5: v ← arg minv∈He fv; 6: Auv ← Auv + we; 7: (The same is done forAvu becauseA is symmetric.) 8: end for 9: Construct diagonal matrix W ∈ RN×N ; set W ← 0.\n10: for each u ∈ N do 11: Wuu ← ∑ v∈V Auv; 12: end for 13: return (WΠN −ΠNA)f\nHence, as the magnitude of the perturbation tends to zero, if the global ordering π is preserved, then the gradient remains the same, which implies that the gradient is also the subgradient when the perturbation reaches 0.\nUsing the Markov operator M as a subroutine to generate a subgradient, we have the following subgradient method (SGM) (Shor et al., 1985).\nAlgorithm 5 Subgradient Method SGM(f (0)N ∈ RN ) 1: Input: Directed hypergraph H = (V,E,w) with la-\nbels f∗L for labeled vertices L, initial feasible solution f (0) N ∈ RN , step size {ηt := 1 t }t≥1\n2: t← 1; 3: (Throughout the algorithm, f (t)L = f ∗ L is given by the\nlabeled vertices.) 4: while Solution f (t)N has not “stabilized” do 5: g(t)N ← Mf (t−1) ∈ RN ; 6: f (t)N = f (t−1) N − ηt ·\ng (t) N∥∥∥g(t)N ∥∥∥\n2\n;\n7: t← t+ 1; 8: end while 9: return f (t)\nStabilizing Condition. Our experiments in Section 5 suggest that it suffices to run the solver for a short time, after which a better feasible solution f does not improve the prediction accuracy."
  }, {
    "heading": "5. Experimental Results",
    "text": "Our experiments are run on a standard PC. In our graphs, each point refers to a sample mean, and the height of the vertical bar is the standard error of the mean."
  }, {
    "heading": "5.1. Undirected Hypergraph: Comparing Accuracy of Prediction Methods",
    "text": "We show that our treatment of hypergraphs performs better than the previously best method in (Hein et al., 2013).\nHypergraph Model. We use three datasets from the UCI Machine Learning Repository (Lichman, 2013): mushroom, covertype45 and covertype67. As in (Hein et al., 2013), each dataset fits into the hypergraph learning model in the following way. Each entry in the dataset corresponds to a vertex, which is labeled either +1 or −1. Moreover, each entry has some categorical attributes. For each attribute and each realized value for that attribute, we form a unit-weight hyperedge containing all the vertices corresponding to entries having that attribute value. To summarize, below are the properties of the resulting hypergraphs.\nDataset mushroom covertype45 covertype67\nn = |V | 8124 12240 37877 m = |E| 112 104 123 k =∑\ne∈E |e| m\n1523 1412 3695\nSemi-supervised Learning Framework. We compare our semi-supervised learning framework with that in (Hein et al., 2013), which was previously the best (compared to (Zhou et al., 2006), for instance). Specifically, we compare the prediction accuracy of the following two prediction algorithms.\n1. Confidence Interval (CI). We use hard constraints (CP1) and confidence intervals for prediction, as described in Algorithm 1 in Section 3. 2. Hein et al. We implement the method described in (Hein et al., 2013), which uses soft constraints (regularized version), plus 5-fold cross validation to determine the regularization parameter.\nTesting Methodology. Since we focus on prediction accuracy, using either subgradient method or PDHG (Hein et al., 2013) for solving the underlying convex programs in each algorithm produces the same results. For each algorithm candidate, we try different sizes of labeled vertices L, where l = |L| ranges from 20 to 200. For each size l\nof labeled vertices, we randomly pick l vertices from the dataset to form the set L and treat the rest as unlabeled vertices; we re-sample if only one label (+1 or −1) appears in L. For each size l, we perform 100 trials to report the average error rate together with its standard error.\nResults. Our experiment can recover the results reported in (Hein et al., 2013). The test error for the two algorithms on the three datasets is presented in Figure 5.1, which shows that our CI method consistently has lower test error than the one in (Hein et al., 2013)."
  }, {
    "heading": "5.2. Comparing Running Times of Solvers",
    "text": "Different Solvers. We compare the running times of the following two convex program solvers:\n• Subgradient Method (SG), proposed by us. Empirically, the step size ηt := 1\n(t+1) min( 0.16t 105 ,1)\ngives good\nperformance. For large t, ηt grows like 1t and so the method converges; however, for small t, we would like a larger step size to speed up convergence. • Primal-Dual Hybrid Gradient (PDHG), proposed in (Hein et al., 2013). We choose σ = τ = 1√\n1+d ,\nwhere d is the maximum degree.\nTheoretical Analysis. Given a hypergraph with n vertices and m edges, where the average size of an edge is k, each vertex on average appears in mkn edges. For SG, we use a heap-based data structure to maintain the vertices within a hyperedge. Vertices attaining the maximum and the minimum value within a hyperedge can be retrieved in O(1) time, and a value update takes O(log k) time. In each iteration, at most 2m vertices will have their values updated. Hence, in each iteration, SG takes time 2m·mkn ·O(log k) = O(m\n2k n log k). In the description of PDHG in (Hein et al., 2013), each iteration takesO(mk log k) time. Hence, when n m, each iteration of SG will be significantly faster, although in general, the number of iterations required by the subgradient method can be larger than that for PDHG.\nTesting Methodology. In each experiment, we consider the hypergraph from one of the above three datasets. We pick l = 160 vertices at random as the labeled vertices L, and form the corresponding convex program (CP1) for the two solvers, where the initial values for unlabeled vertices are chosen independently to be uniformly at random from [−1, 1]. To compare the performance, we run the two solvers on the same convex program, and record each trajectory of the objective value versus the time duration. According to experience, 100 seconds is good enough for either solver to reach an almost optimal solution, and we use the minimum value achieved by the two solvers after 100 seconds as an estimate for the true optimal value OPT. Then, we scan each trajectory, and for each relative gap\n∈ {10−i : i = 1, 2, . . . , 6}, we find the smallest time T ( ) after which the objective value is at most OPT away from the estimate OPT. Each instance of the experiment is repeated 100 times (with different sets of labeled vertices) to obtain an average of those T ( )’s and their standard error. For each relative gap , we also report the test error for using a feasible solution that is OPT away from the presumed optimal value OPT.\nResults. Both solvers have similar performance. As predicted by our theoretical analysis, we see in Figure 5.2 that SG has an advantage when the number n of vertices is much larger than the number m of edges, which is the case for the the last dataset covertype67. Moreover, in Figure 5.3, we see that achieving a relative gap smaller than 10−4 has almost no effect on improving the prediction accuracy. Hence, we can conclude that for either solver, it takes roughly 10 to 20 seconds to produce a solution for the underlying convex program that can give good predic-\ntion accuracy."
  }, {
    "heading": "5.3. Directed Hypergraph: More Powerful",
    "text": "DBLP Dataset. We use the DBLP (Ley, 2009) dataset. Each paper is represented by a vertex. We include papers from year 2000 to 2015 from conferences belonging to the following research areas to conduct our experiments:\n• 7049 papers from machine learning (ML): NIPS, ICML • 2539 papers from theoretical computer science (TCS): STOC, FOCS • 3374 papers from database (DB): VLDB, SIGMOD\nWe perform the following prediction tasks: (a) ML (+1) vs TCS (-1), and (b) ML (+1) vs DB (-1).\nThe details of the experiment setup and the results are given in the full version."
  }],
  "year": 2017,
  "references": [{
    "title": "Higher order learning with graphs",
    "authors": ["Agarwal", "Sameer", "Branson", "Kristin", "Belongie", "Serge"],
    "venue": "In Proceedings of the 23rd international conference on Machine learning,",
    "year": 2006
  }, {
    "title": "Directed hypergraphs and applications",
    "authors": ["Gallo", "Giorgio", "Longo", "Giustino", "Pallottino", "Stefano", "Nguyen", "Sang"],
    "venue": "Discrete applied mathematics,",
    "year": 1993
  }, {
    "title": "Laplacian sparse coding, hypergraph laplacian sparse coding, and applications",
    "authors": ["Gao", "Shenghua", "Tsang", "Ivor Wai-Hung", "Chia", "LiangTien"],
    "venue": "Pattern Analysis and Machine Intelligence, IEEE Transactions on,",
    "year": 2013
  }, {
    "title": "Clustering categorical data: An approach based on dynamical systems",
    "authors": ["Gibson", "David", "Kleinberg", "Jon", "Raghavan", "Prabhakar"],
    "year": 1998
  }, {
    "title": "The total variation on hypergraphs-learning on hypergraphs revisited",
    "authors": ["Hein", "Matthias", "Setzer", "Simon", "Jost", "Leonardo", "Rangapuram", "Syama Sundar"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2013
  }, {
    "title": "Image retrieval via probabilistic hypergraph ranking",
    "authors": ["Huang", "Yuchi", "Liu", "Qingshan", "Zhang", "Shaoting", "Metaxas", "Dimitris N"],
    "venue": "In Computer Vision and Pattern Recognition (CVPR),",
    "year": 2010
  }, {
    "title": "Dblp: some lessons learned",
    "authors": ["Ley", "Michael"],
    "venue": "Proceedings of the VLDB Endowment,",
    "year": 2009
  }, {
    "title": "Hypergraph markov operators, eigenvalues and approximation algorithms",
    "authors": ["Louis", "Anand"],
    "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,",
    "year": 2015
  }, {
    "title": "Hypernode graphs for spectral learning on binary relations over sets",
    "authors": ["Ricatte", "Thomas", "Gilleron", "Rémi", "Tommasi", "Marc"],
    "venue": "In Joint European Conference on Machine Learning and Knowledge Discovery in Databases,",
    "year": 2014
  }, {
    "title": "Minimization Methods for Non-differentiable Functions",
    "authors": ["N.Z. Shor", "Kiwiel", "Krzysztof C", "Ruszcayǹski", "Andrzej"],
    "year": 1985
  }, {
    "title": "Hypergraph spectral learning for multi-label classification",
    "authors": ["Sun", "Liang", "Ji", "Shuiwang", "Ye", "Jieping"],
    "venue": "In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,",
    "year": 2008
  }, {
    "title": "Mapping users across networks by manifold alignment on hypergraph",
    "authors": ["Tan", "Shulong", "Guan", "Ziyu", "Cai", "Deng", "Qin", "Xuzhen", "Bu", "Jiajun", "Chen", "Chun"],
    "venue": "In AAAI,",
    "year": 2014
  }, {
    "title": "Nonlinear laplacian for digraphs and its applications to network analysis",
    "authors": ["Yoshida", "Yuichi"],
    "venue": "In Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,",
    "year": 2016
  }, {
    "title": "Adaptive hypergraph learning and its application in image classification",
    "authors": ["Yu", "Jun", "Tao", "Dacheng", "Wang", "Meng"],
    "venue": "IEEE Transactions on Image Processing,",
    "year": 2012
  }, {
    "title": "Learning with hypergraphs: Clustering, classification, and embedding",
    "authors": ["Zhou", "Dengyong", "Huang", "Jiayuan", "Schölkopf", "Bernhard"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2006
  }, {
    "title": "Semi-supervised learning using gaussian fields and harmonic functions",
    "authors": ["Zhu", "Xiaojin", "Ghahramani", "Zoubin", "Lafferty", "John D"],
    "venue": "In ICML,",
    "year": 2003
  }],
  "id": "SP:247d928063a419f32ac86f18c774e4a34bb40ca0",
  "authors": [{
    "name": "Chenzi Zhang",
    "affiliations": []
  }, {
    "name": "Shuguang Hu",
    "affiliations": []
  }, {
    "name": "Zhihao Gavin Tang",
    "affiliations": []
  }, {
    "name": "Hubert Chan",
    "affiliations": []
  }],
  "abstractText": "We revisit semi-supervised learning on hypergraphs. Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable. We exploit the non-uniqueness of the optimal solutions, and consider confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution. Moreover, we give a much simpler approach for solving the convex program based on the subgradient method. Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges.",
  "title": "Re-revisiting Learning on Hypergraphs:  Confidence Interval and Subgradient Method"
}