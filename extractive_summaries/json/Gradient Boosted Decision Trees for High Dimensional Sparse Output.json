{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Gradient boosted decision tree (GBDT) is a powerful machine-learning technique that has a wide range of commercial and academic applications and produces state-ofthe-art results for many challenging data mining problems. The algorithm builds one decision tree at a time to fit the residual of the trees that precede it. GBDT has been widely used recently mainly due to its high accuracy, fast training and prediction time, and small memory footprint.\nIn this paper, we study the GBDT algorithm for problems with high-dimension and sparse output space. Extreme\n1Google Research, Mountain View, USA 2University of California at Davis, Davis, USA 3Microsoft, Mountain View, USA 4Facebook, Menlo Park, USA 5University of Texas at Austin, Austin, USA. Correspondence to: Cho-Jui Hsieh <chohsieh@ucdavis.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nmulti-label learning and multi-class classification belong to this problem, where the goal is to automatically assign one or a subset of relevant labels from a very large label set. Dealing with problems with high dimensional output leads to multiple computational challenges. In this paper we mainly focus on two important issues that limit the application of the existing methods to real world applications: prediction time and model size. As the output space size increases, these dimensions become the bottleneck, both during training and testing. As an example, if a one-versusall model is used on a classification problem with 1 million labels, then we need to evaluate 1 million models for any testing sample. If these models cannot be kept in memory, reading them from disks will further increase the prediction time substantially. The linear dependency on number of labels makes most of the existing approaches very slow during testing, especially when we do not want to access the cloud for every test point.\nThe computation of GBDT is also prohibitively expensive for applications with high dimensional sparse output. At each iteration, GBDT builds a regression tree that fits the residuals from the previous trees. The density of the residual grows dramatically even after just one single iteration, and it will soon become an L by N dense matrix where N is number of samples and L is the number of labels (size of output space). As a consequence, at least O(NL) time and memory are required to build GBDT trees. This makes GBDT infeasible for large scale applications where N and L can be both large, e.g., several millions.\nOur goal is to develop a new approach for problems with high-dimensional and sparse output spaces that achieves faster prediction time and smaller model size than existing algorithms, but has similar prediction accuracy and training time. To this end, we develop the first Gradient Boosted Decision Tree (GBDT) algorithm for high dimensional and sparse output, with applications in extreme multilabel learning problems. We make the crucial observation that each data point has very few labels; based on that we solve a L0 regularized optimization problem to enforce the prediction of each leaf node in each tree to have only a small number (k) of nonzero elements or labels. Hence, after T trees have been added during GBDT iterations, there will be at most Tk nonzero gradients for any data point. Another important challenge discussed in this paper is pre-\ndiction time. Given the sparsified output, we discuss efficient algorithms to conduct prediction for both top-K recommendation or the whole sparse output vector. Finally, we discuss how to handle sparse data, where each feature is active only on a small fraction of training examples. To handle this, we use several unsupervised and supervised dimensional reduction algorithms as pre-processing steps. This also has the positive effect of reducing the search space of each node.\nFor extreme multi-label applications, our algorithm has competitive accuracy compared with existing state-of-theart algorithms, while achieving substantial reductions in prediction time and model size. For example, on the Wiki10-31K dataset with 30938 labels, our method takes only 1.3 secs. for prediction and achieves 84.34% accuracy with a model size of 85.8MB, while the state-of-the-art fast multi-label method FASTXML takes more than 10 secs. to achieve 82.71% accuracy and uses 853.5MB memory to store the model. Our method can be efficiently parallelized and achieve almost linear speed up in multi-core settings.\nThe rest of the paper is outlined as follows. We present related work in Section 2. Traditional GBDT is explained in Section 3. Our main algorithm GBDT-SPARSE is proposed and analyzed in Section 4. Experimental results are given in Section 5. We present conclusions in Section 6."
  }, {
    "heading": "2. Related Work",
    "text": "Ensemble methods have shown excellent performance in various machine learning applications and analytics competitions, e.g., Kaggle challenges. Common ensemble methods include random forests (Liaw & Wiener, 2002), bagging (Breiman, 1996), and boosting (Schapire, 1999; Friedman, 2001; 2002). Out of these, boosting is very effective in reducing model size and prediction time since it uses the output of previous models to train the next one.\nMany classical boosting methods have shown their efficiency in practice. Among them, gradient boosted decision trees (GBDT) (Friedman, 2001; 2002) has received much attention because of its high accuracy, small model size and fast training and prediction. It been widely used for binary classification, regression, and ranking. In GBDT, each new tree is trained on the per-point residual defined as the negative of gradient of loss function wrt. output of previous trees. GBDT is well studied in the literature: some research has been done to speed up the computation of GBDT under different parallel settings (multi-core or distributed), e.g., XGBoost (Chen & Guestrin, 2016), LightGBM,1 PLANET (Panda et al., 2009), PV-Tree (Meng et al., 2016), and YGGDRASIL(Abuzaid et al., 2016) or exploit its benefit for different machine learning applications, e.g., using GBDT for CRFs (Chen et al., 2015). How-\n1https://github.com/Microsoft/LightGBM\never, to the best of our knowledge none of them can be efficiently applied to problems with high dimensional output.\nRecently, machine learning problems with high dimensional output have drawn considerable attention. Two popular and representative problems are extreme multiclass classification and extreme multi-label learning problem (Prabhu & Varma, 2014; Bhatia et al., 2015; Yu et al., 2014; Agrawal et al., 2013; Jasinska et al., 2016; Si et al., 2016) and both deal with very large number of labels. LOMtree proposed in (Choromanska & Langford, 2015) constructs trees for extreme multi-class problem, and obtains training and test time complexity logarithmic in the number of classes, but its extension to multi-label case is not straightforward. Many algorithms have been developed to solve extreme multi-label learning problem. For instances, embedding based methods LEML (Yu et al., 2014) and SLEEC (Bhatia et al., 2015) project the labels and features to some low-dimensional space while preserving distances either with the neighboring label vectors or the full training set; PLT(Jasinska et al., 2016) considers using sparse probability estimates restricted to the most probable labels to speed up the F-measure maximization for extreme multi-label learning; PD-Sparse (Yen et al., 2016) formulates multilabel learning problem as a primal-dual sparse problem given by margin-maximizing loss with L1 and L2 penalties. Tree based methods (Prabhu & Varma, 2014; Agrawal et al., 2013) generalize the impurity measures defined for binary classification and ranking tasks to multilabel scenario for splitting the nodes, but require hundreds of trees to achieve good accuracy. FASTXML (Prabhu & Varma, 2014) uses NDCG based ranking loss function and solves a non-convex optimization problem to find a sparse linear separator for splitting each node. All the approaches discussed above either do not give good accuracy (Yu et al., 2014), or, require large sized models with high prediction times to do so (Prabhu & Varma, 2014).\nIn contrast, to solve extreme multi-label learning problem, our method is based on GBDT and hence requires only a few trees to build a good model. During training, we also enforce sparsity in the label vector at each leaf node to reduce the model size and prediction time. Our approach is different from FASTXML in three aspects:(1) we do not need to solve a non-convex optimization at each node, but, rather do a much simpler and faster feature selection; (2) we follow the idea of GBDT to build trees, while FASTXML is a random forest based method; (3) we can achieve similar accuracy as FASTXML, but with much faster prediction time and smaller model size."
  }, {
    "heading": "3. Background",
    "text": "We first discuss the original GBDT algorithm, and present the difficulty when applying GBDT to solve problems with\nhigh dimensional output space.\nGBDT for binary classification Let us explain the main idea behind GBDT using binary classification, in which a scalar score function is formed to distinguish the two classes. Given training data X = {xi}Ni=1 with xi ∈ RD and their labels Y = {yi}Ni=1 with yi ∈ {0, 1}, the goal is to choose a classification function F (x) to minimize the aggregation of some specified loss function L(yi, F (xi)):\nF ∗ = argmin F N∑ i=1 L(yi, F (xi)). (1)\nGradient boosting considers the function estimation F in an additive form:\nF (x) = T∑ m=1 fm(x), (2)\nwhere T is the number of iterations. The {fm(x)} are designed in an incremental fashion; at the m-th stage, the newly added function, fm is chosen to optimize the aggregated loss while keeping {fj}m−1j=1 fixed.\nEach function fm belongs to a set of parametrized ‘baselearners’; let θ denote the vector of parameters of the the base-learner. GBDT uses decision trees to be the base learners. For this choice, θ consists of parameters that represent the tree structure, such as the feature to split in each internal node, the threshold for splitting each node, etc.\nAt stage m, we form an approximate function of the loss:\nL(yi, Fm−1(xi) + fm(xi)) ≈\nL(yi, Fm−1(xi)) + gifm(xi) + 1\n2 fm(xi)\n2, (3)\nwhere Fm−1(xi) = ∑m−1 j=1 fj(xi) and\ngi = ∂L(yi, F (xi))\n∂F (xi) |F (xi)=Fm−1(xi) .\nNote that throughout the paper we will only take differentiation with the second parameter of L(·, ·), so we define L′(yi, Fm−1(xi)) to be the above differentiation.\nWe want to choose fm to minimize the right hand side of (3), which can be written as the following minimization problem:\narg min fm N∑ i=1 1 2 (fm(xi)− gi)2. (4)\nSince only the direction is fitted, a suitable step size (shrinkage parameter) is usually applied to fm before it is added to Fm−1. The advantage of this gradient boosting approach is that only the expression of the gradient varies for different loss functions, while the rest of the procedure, and in particular the decision tree induction step, remains the same for different loss functions."
  }, {
    "heading": "4. Proposed Algorithm (GBDT-SPARSE)",
    "text": "Now we discuss the problem with sparse high dimensional output. For input data X = {xi}Ni=1 with xi ∈ RD, we assume the corresponding output Y = {yi}Ni=1 with yi ∈ RL are high-dimensional and sparse—L is very large but each yi only contains a few nonzero elements. We denote the average number of nonzero elements S = ∑ i ‖yi‖0/N , and S L. Multilabel learning is an example, where each xi is the input features for a training sample, yi ∈ {0, 1}L where L is the number of labels, and (yi)q = 1 if sample i has label q.\nNow we discuss the proposed GBDT-SPARSE algorithm. For a general loss function with high dimensional output yi, we consider\nF ∗ = argmin F n∑ i=1 L(yi, F (xi)) +R(F ), (5)\nwhere R(F ) is the regularization term. For simplicity we assume an L2 regularization, so\nR(F ) = λ T∑ m=1 Mm∑ j=1 ‖wmj ‖2, (6)\nwhere fm(x) = wmJ(x) with J(x) : R D → Mm representing the tree structure which maps a data point x into one of the Mm leaves of the m-th tree, and wmj ∈ RL is the prediction vector of the j-th leaf node in the m-th tree.\nWe assume L is differentiable and satisfies the following properties:\n1. L(y, z) is decomposable:\nL(y, z) = L∑ q=1 `(yq, zq). (7)\n2. Each `(·, ·) satisfies that\n`′(yq, zq) = 0 if yq = zq. (8)\nExamples include but not limited to the square loss: `(yq, zq) = (yq − zq)2 and the square hinge loss (note that this is the square-hinge loss with center shifted to 0.5 and width scaled to 0.5):\n`(yq, zq) = { max(1− zq, 0)2 if yq = 1 max(zq, 0) 2 if yq = 0 (9)\nUsing the same Taylor expansion, at each iteration we want to construct fm by solving\nL(yi, Fm−1(xi) + fm(xi)) ≈\nL(yi, Fm−1(xi)) + 〈gi, fm(xi)〉+ 1\n2 ‖fm(xi)‖2, (10)\nwhere gi is the L-dimensional gradient for the i-th sample with (gi)q = `\n′((yi)q, (Fm−1(xi))q). Following the same steps as the previous section, for each tree we want to find the cut value to minimize the following objective function:\nmin fm\n1\nN N∑ i=1 ‖gi − fm(xi)‖22 + λ Mm∑ j=1 ‖wmj ‖22. (11)\nVanilla extension of GBDT to high-dimensional output space. As in most decision tree induction methods, we follow a greedy approach, that is, starting from a single node and iteratively adding branches to the tree until some stopping conditions are met. At a general step, we want to split an existing leaf node e in the m-th tree. Let Ve = {i|J(xi) = e} denote the set of examples that pass through the leaf e. Suppose we fix a split, t = [feature id, threshold], consisting of the variable to split and at what threshold it has to be split. This partitions Ve into two disjoint sets: a set Vr associated with the right node and a set Vl associated with the left node. Then we can compute the prediction vectors (hr and hl) associated with the right and left nodes based on the loss function restricted to the corresponding sets of examples:\nhr = argmin hr\n1\nN ∑ i∈Vr ‖gi − hr‖22 + λ‖hr‖22\nhl = argmin hl\n1\nN ∑ i∈Vl ‖gi − hl‖22 + λ‖hl‖22. (12)\nSince the objectives follow a simple quadratic form, these problems can be solved in closed form as\nhr = 1 λN + |Vr| ∑ i∈Vr gi, hl = 1 λN + |Vl| ∑ i∈Vl gi (13)\nNow we can use hr and hl to form prediction: the prediction for example i is he,i = hr if i ∈ Vr and is hl if i ∈ Vl. This leads to the objective, obj(t) for the split t:\nobj(t) = 1\nN ∑ i∈Ve ‖gi − he,i‖2 + λ(‖hr‖2 + ‖hl‖2) (14)\nThe best split is chosen to optimize obj(t):\nt∗ = min t obj(t) (15)\nThis completes a general step of the vanilla extension of GBDT for high dimensional sparse output.\nWhy vanilla GBDT fails on high dimensional sparse output? The vanilla GBDT extension described above faces several difficulties when it is applied on high dimensional sparse output:\n1. The first issue is the size of gradient gi in (11). Each gi is an L-dimensional vector. Although in the first step gi is sparse, after one step, hl (hr) in (12) will be the average of |Vr|(|Vl|) sparse vectors, which will be dense. A dense prediction Fm will then lead to dense gradients in all the trees after the first step, and this NL space and time complexity is prohibitive in large scale applications where N and L can be both several millions. 2. The second issue is the model size. The prediction vector in each leaf of each tree is a dense vector of length L. This will result in a total model size of O(TML), where T is the number of trees and M is the average number of leaves in each tree. Given that L is large in extreme multi-label learning, the model size will also become very large. 3. The third issue is also related to the dense prediction vector in the tree leaves, and concerns the prediction time. The prediction time for a test point is O(T l̄+ TL),2 where l̄ is the average depth of the trees. Thus, when L is large, the prediction is very expensive. 4. The fourth issue relates to the sparsity and large dimension of the input vector x. For many real-world problems, the input x is sparse. Induction on such data leads to very unbalanced decision trees with a large number of leaves; this in turn increases the model size and prediction time. It is worth noting that decision trees are generally found to be unsuitable for data with such sparsity."
  }, {
    "heading": "4.1. Our proposed algorithm: GBDT-SPARSE",
    "text": "We now propose a sparsified approach for resolving the above mentioned issues, which leads to the first effective GBDT algorithm for high dimensional sparse output. These modifications lead to models with high accuracy, small model size and fast prediction time.\nWe first discuss the case when the input features are dense. To handle the first three issues (dense residual vectors, model size, and prediction time), we use the fact that the labels yi are high dimensional but very sparse. For the loss function satisfies our assumptions (Assumption (7) and (8)), and if both yi and zi are sparse, then the gradient vector gi in (11) will also be a sparse vector, and the sparsity is at most ‖yi‖0 + ‖zi‖0.\nThus, we enforce a sparsity constraint on the prediction vector in each leaf of each tree and maintain non-zero prediction values only for a small number (k L) of labels. Typically, after each tree induction, each leaf contains a coherent set of examples related to a small set of labels and thus the above sparsity constraint makes a lot of sense. Additionally, the constraint offers a nice form of regularization. Note that by definition of gi, it can have at most\n2The first term is the cost of tree traversal while second is the cost of getting predictions from the leaf nodes.\nTk+‖yi‖0 non-zeros after T iterations (the label vector yi is also sparse). This strategy makes the computation very efficient and also reduces memory footprint substantially.\nTo enforce the sparsity, we add L0 constraint into the objective function (11), and we have\nmin fm,wmj N∑ i=1 ‖gi − fm(xi)‖22 + λ Mm∑ j=1 ‖wmj ‖22\ns.t. ‖wmj ‖0 ≤ k, ∀j. (16)\nFor each cut t, the objective of the left partition becomes:\nmin ‖hl‖0=k {∑ i∈Vl ‖gi − hl‖22 + λ‖hl‖22 } := fl(hl), (17)\nwhere, like before, Vl denotes the set of examples that fall in leaf l. Interestingly, (17) has a closed form solution, and there is no additional time cost by enforcing the sparse constraints. Let plq = ∑ i∈Vl(gi)q be sorted by the absolute values with the order to be π, such that\n|plπ(1)| ≥ |p l π(2)| ≥ . . . ≥ |p l π(|Vl|)|, (18)\nthen the optimal solution of (17) is\n(hl) ∗ q = { plq/(|Vl|+ λ) if π(q) ≤ k 0 otherwise ,\n(19)\nand the objective function is\nfl(h ∗ l ) = fl(0)− ∑ q:π(q)≤k (plq) 2 |Vl|+ λ . (20)\nSimilarly we can get the same h∗r and fr(h ∗ r) for the right child, and compute the objective function gain.\nUsing this closed form solution of the objective function, we want to find the best split t = [feature id, threshold] for the current node by minimizing the objective function fl(h ∗ l ) + fr(h ∗ r). For simplicity, we assume all the data are in the current node (e.g. the root) in order to simplify the notation, while the same algorithm can be applied to a node with partial samples. Also, we assume a sorted list σj(·) according to each feature j’s value is given, where\n(xσj(1))j ≤ (xσj(2))j ≤ · · · ≤ (xσj(N))j .\nThis can be typically done as a pre-processing step before building GBDT because the ordering will not be changed. We then test the decrease of objective function for each threashold according to this order, and select the best one. See Algorithm 1 for detail.\nFor each feature, although selecting the best threshold from all potential values can optimize objective function, we\nAlgorithm 1: GBDT-SPARSE tree node splitting algorithm Input: {xi,yi}Ni=1, sorted list according to each feature\n{σj}Dj=1, λ (the regularization parameter), k (sparsity constraint)\nOutput: Best split t = [feature id, threshold] 1 Initial: f best = 0 ; 2 for j = 1, · · · , D do 3 (pl)s = 0, ∀s = 1, · · · , L ; 4 (pr)s = ∑ i(gi)s, ∀s = 1, · · · , L ; 5 for i = 1, . . . , N do 6 for s with (gσj(i))s 6= 0 do 7 (pl)s ← (pl)s + (gσj(i))s ; 8 (pr)s ← (pr)s − (gσj(i))s ;\n9 Compute the f = − ∑ s∈Ql (pls) 2 i+λ − ∑ s∈Qr (p r s) 2\nN−i+λ , where Ql and Qr are the index set of top-k |pls| and |prs| values respectively;\n10 If f < f best, set f best = f , tbest = [j, (xσj(i))j ] ;\nfound this also leads to over-fitting. Therefore, in our implementation we consider the “inexact” version where we only test the threshold for every S̄ values in the sorted list: {(xσj(i))j}i=1,1+S̄,1+2S̄,...,n.\nAlgorithm 1 can be implemented in O(D‖G‖0 log(k)) time, where ‖G‖0 = ∑N i=1 ‖gi‖0 is the number of nonzero elements in the current gradient. The main trick is to use two priority queues to maintain two lists of k features with top-k ps values (correspond to sum of gradient) for left tree and right tree. When scanning through one sample in the inner step, only one term of ps will change, which has O(log k) complexity using a priority queue. However, in practice we set S̄ to be very large (5% of samples), so a sorting algorithm for finding the top-k list is fast enough, since it only needs to be executed 20 times."
  }, {
    "heading": "4.2. GBDT-SPARSE: Dealing with Sparse Features",
    "text": "Decision trees usually have difficulty handling sparse features. When feature vectors are sparse, e.g., only 100 out of 10,000 training samples have nonzero values on a feature, the tree will be always imbalanced and extremely deep.\nTo handle sparse input features, we consider several projection methods that transform sparse features to dense ones. The most simple yet useful one is to use random projection, that is, projecting the data point to x̄i = Ḡxi using a fixed random Gaussian matrix Ḡ ∈ Rd×D as projection matrix. To reduce reconstruction error, another approach is to use Principal Component Analysis (PCA) (Halko et al., 2011) via SVD (Si et al., 2014).\nBoth random projection and PCA are un-supervised learn-\ning approaches—in the sense that they do not use any label information; however, in our problem setting there is rich information in the high dimensional output space Y . Therefore, we can use a supervised algorithm LEML (Yu et al., 2014) to construct dense features, which solves the following optimization problem:\nmin W∈RD×d̄,H∈RL×d̄\n‖Y −XWHT ‖2F + γ(‖W‖2F + ‖H‖2F )\nwhere γ is a regularization term to control the over-fitting and d̄ is the projected dimension. This has been discussed in (Yu et al., 2014) for solving the multi-label classification problems, and the resulting algorithm uses an alternating minimization algorithm to compute the solutions W and H . After we get W from LEML, we use the new features X̄ as X̄ = XW to construct the decision trees. Using this projection has two benefits:(1) the projection incorporates the label information; and, (2) the new data after projection, X̄ is dense, and thus results in shallow and balanced trees.\nWe compare GBDT-SPARSE with different projection methods as well as vanilla GBDT for extreme multilabel learning problem in Table 1. We used the Wiki10-31K dataset with training parameters the same as the ones in section 5, except we terminate all methods (except vanilla GBDT) in about 1000 seconds. Three dimension reduction techniques, LEML, PCA and random projections are used to reduce the feature size to 100. We also include FASTXML as a comparison for training time. From Table 1 we can see that using LEML is more accurate than using PCA and random projections, but takes longer time to train the model. Different from vanilla GDBT, GBDTSPARSE enforces the sparsity in the leaf nodes, which brings significant speedup (about 40x) for training. This table shows the benefits of using feature projection and enforcing sparsity in leaf nodes when applying GDBT on problems with high-dimensional sparse output."
  }, {
    "heading": "4.3. GBDT-SPARSE: Fast Prediction",
    "text": "When performing prediction, the data points will go through each tree and then the prediction is f(xi) =∑T m=1 hm(xi). In vanilla GBDT, this requires O(LT ) time since we have to sum over the prediction for T trees, each one is an L-dimensional dense vector. Note that the tree traversal time can be omitted because each node only takes 1 comparison to look at whether a feature is larger or smaller than the threshold.\nIn GBDT-SPARSE, when making prediction for a new data point, we can utilize the sparsity structure of each prediction vector to achieve fast prediction time: adding up T of the k-sparse vectors together. The naive approach is to create an array of size Tk, copy all the index-value pairs to the array, and sort them by index. This has O(Tk log(Tk)) time complexity. A more efficient approach is to use a minheap data structure to merge these k lists which can reduce time complexity: first, sort each list according to the index orders, and then create a min heap of size k and insert the first element in all lists to the heap. Then repeatedly conduct the following process: (1) get the minimum element from heap, store to the output array, and (2) update the heap root value by the next index from the list that the element is fetched. The overall algorithm will take O(Tk log k) time.\nIn some real world applications, only top-B labels are needed with very small B (typically 1,3,5). In those cases, we can further reduce the prediction time to O(Tk logB) (see details in appendix B). Since we test on small k for all our experiments, we do not use this technique in practice."
  }, {
    "heading": "4.4. Summary of GBDT-SPARSE",
    "text": "In summary, the training time of GBDT-SPARSE is O(D‖G‖0 log(k)) for each node, where ‖G‖0 is total number of nonzeros of the samples belonging to the node. So each level of the tree requires O(D‖X‖0 log(k)) time. If we build T trees and each with h levels, the total training time is O(DTh‖X‖0 log(k)).\nAs discussed in the previous section, the prediction time is O(Tk log k) for prediction. k (sparsity constraint) is usually set to be less than 50; T (number of tress) is usually less than 100. Therefore GBDT-SPARSE has a sub-linear (constant) prediction time.\nNow we discuss model size. Each intermediate node only stores the [feature id, threshold] pair, which is one integer and one floating point. Each leaf node only stores the k index-value pairs. Therefore, the model size is O(kT2h). As long as tree depth h is not too large (usually less than 12), the model size is very small."
  }, {
    "heading": "5. Experiments",
    "text": "We compare GBDT-SPARSE against other key methods for extreme multi-label classification problems and demonstrate its value with respect to model size, prediction time and performance.\nData: We conducted experiments on 5 standard and publicly available multi-label learning datasets.3 Table 2 shows the associated details. Note the diversity in the number of training samples, label size and feature dimensionality. Delicious-200K has more than 200, 000 labels.\nBaselines: We compare our method to four state-of-the-art extreme multi-label learning baselines.\n1. LEML (Yu et al., 2014) is an embedding technique based on low-rank empirical risk minimization. 2. FASTXML (Prabhu & Varma, 2014) is a random forest based approach where each tree is constructed by jointly optimizing both nDCG ranking loss and tree structure. A sparse linear separator is used as the splitting criteria at each node. 3. SLEEC (Bhatia et al., 2015) learns an ensemble of local distance preserving embeddings. Pairwise distances are preserved between only the nearest label vectors. 4. PD-SPARSE (Yen et al., 2016) proposes to solve L1 regularized multi-class loss using Frank-Wolfe based algorithm. However, it needs to store weight vectors in size O(DL), which is hard to scale to large datasets.\nFor the baselines, we use their highly optimized C++ implementation published along with the original papers. We also compare with DisMEC (Babbar & Schölkopf, 2017) in the Appendix.\nParameter Setting: For FASTXML and LEML, we use the default parameter settings in the code. SLEEC’s code also has optimal parameter settings for all the datasets except NUS-WIDE. It has 7 parameters and their settings vary widely for different datasets. For PD-SPARSE, we use\n3NUS-WIDE is available at http://lms.comp.nus.edu.sg/ research/NUS-WIDE.htm. All other datasets are available at http://manikvarma.org/downloads/XC/XMLRepository.html.\na grid search to find the best regularization parameter λ and cost C. For our method, we kept most of the parameters fixed for all the datasets: hmax = 10, nleaf = 100, and, λ = 5, where hmax and nleaf are the maximum level of the tree and the minimal number of data points in each leaf. Leaf node sparsity k was set to 100 for Delicious-200K and 20 for all others. This parameter can be very intuitively set as an increasing function of label set size. We hand tuned the projection dimensionality d and set it to 100 for Delicious and Wiki10-31K, and 50 for others.\nResults: Table 3 shows the performance of different methods along the dimensions of prediction time, model size and prediction accuracy (Precision@1 (P@1) and Precision@3(P@3)). Note that the strength of our method is to achieve similar accuracy with smaller memory footprint and prediction time. Also note that LEML has inferior performance to all other methods. However, its prediction times are similar to our method on many datasets. FASTXML, SLEEC and GBDT-SPARSE achieve similar accuracy on almost all the datasets. For PD-SPARSE, we observe that its accuracy can fluctuate badly across iterations in dataset Delicious and Delicious-200K despite of trying different set of parameters, even though the reported dual objective is monotonically decreasing. Also, due to its linear nature, its model size is small, but accuracy is also limited by the capacity of the learner. In terms of accuracy P@1 and P@3, there is no clear trend of GBDT-SPARSE being better or worse than others. However, GBDT-SPARSE gives an order of magnitude speedup in prediction times for almost all the datasets. For example, for Delicious-200K, our method is 10.58x and 14.72x faster than FASTXML and SLEEC respectively. Similar gains can be observed for the model size. It is worth noting that we do not fine-tune most hyper parameters for decision tree building process, and the set of parameters can get good accuracy on all of our datasets.\nFigure 1(a)-(c) shows the P@1 as a function of time for three datasets. For GBDT-SPARSE and FASTXML, we vary the number of trees to get different prediction times. For LEML and SLEEC, experiments are ran for different embedding sizes to generate the curve. The more the curve is towards top left, better is the performance. For GBDT-SPARSE, the curves sharply rise in performance; though not shown, they become stable at the highest performance values shown. Though GBDT-SPARSE does not always beat all methods on performance, we can observe that for any fixed prediction time our approach impressively outperforms all others. Figure 1(d)-(f) shows the corresponding curves as a function of model size. Again similar observations can be made, except for Wiki10-31K where SLEEC has a similar model size. In summary, we can see from Figure 1 that to achieve similar accuracy, GBDTSPARSE takes much less prediction time and the model size\nis much smaller than other methods.\nMulticore Implementation: Unlike random-forest based methods, paralllelizing GBDT is not straightforward. In our problem, because L is large, existing frameworks like XGBoost (Chen & Guestrin, 2016) do not scale well as it needs O(L) storage per leaf, and histogram based methods need O(L) space per bin to accumulate gradients. We implement our algorithm by finding best splits for different features on a single leaf in parallel. Although this requires extra time to sort feature values on each leaf, we find that for datasets with a big L the sorting time is insignificant. We run our algorithm with Delicious-200K on a 28-core dual socket E5-2683v3 machine to build a GBDT with 5 trees, and record the average time for building one tree in Table 4. The good scaling shows that our algorithm is capable for handling big data. Also, the huge speedup from parallelization is a big advantage to use our algorithm in practice, comparing to algorithms that cannot be easily parallelized, like PD-SPARSE."
  }, {
    "heading": "6. Conclusion",
    "text": "We apply GBDT to solve problems with high dimensional sparse output. Applying GBDT to this setting has sev-\neral challenges: large dense gradient/residual matrix, imbalanced trees due to data sparsity, and large memory footprint for leaf nodes. We made non-trivial modifications to GBDT (use embeddings to make features dense, introduce label vector sparsity at leaf nodes) to make it suitable for handling high dimensional output. These improvements can significantly reduce the prediction time and model size. As an application, we use our proposed method to solve extreme multi-label learning problem. Compared to the stateof-the-art baselines, our method shows an order of magnitude speed-up (reduction) in prediction time (model size) on datasets with label set size 1000− 200000.\nAcknowledgments This research was supported by NSF grants CCF-1320746, IIS-1546452 and CCF-1564000. Cho-Jui Hsieh also acknowledges support from XSEDE."
  }],
  "year": 2017,
  "references": [{
    "title": "Yggdrasil: An optimized system for training deep decision trees at scale",
    "authors": ["Abuzaid", "Firas", "Bradley", "Joseph K", "Liang", "Feynman T", "Feng", "Andrew", "Yang", "Lee", "Zaharia", "Matei", "Talwalkar", "Ameet S"],
    "year": 2016
  }, {
    "title": "Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages",
    "authors": ["Agrawal", "Rahul", "Gupta", "Archit", "Prabhu", "Yashoteja", "Varma", "Manik"],
    "venue": "In WWW,",
    "year": 2013
  }, {
    "title": "Dismec: Distributed sparse machines for extreme multi-label classification",
    "authors": ["Babbar", "Rohit", "Schölkopf", "Bernhard"],
    "venue": "In WSDM,",
    "year": 2017
  }, {
    "title": "Sparse local embeddings for extreme multi-label classification",
    "authors": ["Bhatia", "Kush", "Jain", "Himanshu", "Kar", "Purushottam", "Varma", "Manik", "Prateek"],
    "venue": "In NIPS,",
    "year": 2015
  }, {
    "title": "Xgboost: A scalable tree boosting system",
    "authors": ["Chen", "Tianqi", "Guestrin", "Carlos"],
    "venue": "In KDD,",
    "year": 2016
  }, {
    "title": "Efficient second-order gradient boosting for conditional random fields",
    "authors": ["Chen", "Tianqi", "Singh", "Sameer", "Taskar", "Ben", "Guestrin", "Carlos"],
    "venue": "In AISTATS,",
    "year": 2015
  }, {
    "title": "Logarithmic time online multiclass prediction",
    "authors": ["Choromanska", "Anna", "Langford", "John"],
    "venue": "In NIPS, pp",
    "year": 2015
  }, {
    "title": "Greedy function approximation: A gradient boosting machine",
    "authors": ["Friedman", "Jerome H"],
    "venue": "The Annals of Statistics,",
    "year": 2001
  }, {
    "title": "Stochastic gradient boosting",
    "authors": ["Friedman", "Jerome H"],
    "venue": "Computational Statistics and Data Analysis,",
    "year": 2002
  }, {
    "title": "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions",
    "authors": ["Halko", "Nathan", "Martinsson", "Per-Gunnar", "Tropp", "Joel A"],
    "venue": "SIAM review,",
    "year": 2011
  }, {
    "title": "Extreme f-measure maximization using sparse probability estimates",
    "authors": ["Jasinska", "Kalina", "Dembczynski", "Krzysztof", "Busa-Fekete", "Róbert", "Pfannschmidt", "Karlson", "Klerx", "Timo", "Hüllermeier", "Eyke"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "Classification and regression by random forest",
    "authors": ["Liaw", "Andy", "Wiener", "Matthew"],
    "venue": "R News,",
    "year": 2002
  }, {
    "title": "A communication-efficient parallel algorithm for decision tree",
    "authors": ["Meng", "Qi", "Ke", "Guolin", "Wang", "Taifeng", "Chen", "Wei", "Ye", "Qiwei", "Ma", "Zhi-Ming", "Liu", "Tie-Yan"],
    "year": 2016
  }, {
    "title": "PLANET: massively parallel learning of tree ensembles with mapreduce",
    "authors": ["Panda", "Biswanath", "Herbach", "Joshua S", "Basu", "Sugato", "Bayardo", "Roberto J"],
    "venue": "Proceedings of VLDB,",
    "year": 2009
  }, {
    "title": "Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning",
    "authors": ["Prabhu", "Yashoteja", "Varma", "Manik"],
    "venue": "In KDD,",
    "year": 2014
  }, {
    "title": "A brief introduction to boosting",
    "authors": ["Schapire", "Robert E"],
    "venue": "In IJCAI,",
    "year": 1999
  }, {
    "title": "Multi-scale spectral decomposition of massive graphs",
    "authors": ["Si", "Shin", "Donghyuk", "Dhillon", "Inderjit S", "Parlett", "Beresford N"],
    "venue": "In NIPS,",
    "year": 2014
  }, {
    "title": "Goal-directed inductive matrix completion",
    "authors": ["Si", "Chiang", "Kai-Yang", "Hsieh", "Cho-Jui", "Rao", "Nikhil", "Dhillon", "Inderjit S"],
    "venue": "In ACM SIGKDD,",
    "year": 2016
  }, {
    "title": "Pd-sparse : A primal and dual sparse approach to extreme multiclass and multilabel classification",
    "authors": ["Yen", "Ian En-Hsu", "Huang", "Xiangru", "Ravikumar", "Pradeep", "Zhong", "Kai", "Dhillon", "Inderjit S"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "Large-scale multi-label learning with missing labels",
    "authors": ["Yu", "Hsiang-Fu", "Jain", "Prateek", "Kar", "Purushottam", "Dhillon", "Inderjit S"],
    "venue": "In ICML,",
    "year": 2014
  }],
  "id": "SP:4a9d00ddba1eaff8f0737e38ac235dea2018134e",
  "authors": [{
    "name": "Si Si",
    "affiliations": []
  }, {
    "name": "Huan Zhang",
    "affiliations": []
  }, {
    "name": "S. Sathiya Keerthi",
    "affiliations": []
  }, {
    "name": "Dhruv Mahajan",
    "affiliations": []
  }, {
    "name": "Inderjit S. Dhillon",
    "affiliations": []
  }, {
    "name": "Cho-Jui Hsieh",
    "affiliations": []
  }],
  "abstractText": "In this paper, we study the gradient boosted decision trees (GBDT) when the output space is high dimensional and sparse. For example, in multilabel classification, the output space is a L-dimensional 0/1 vector, where L is number of labels that can grow to millions and beyond in many modern applications. We show that vanilla GBDT can easily run out of memory or encounter near-forever running time in this regime, and propose a new GBDT variant, GBDT-SPARSE, to resolve this problem by employing L0 regularization. We then discuss in detail how to utilize this sparsity to conduct GBDT training, including splitting the nodes, computing the sparse residual, and predicting in sublinear time. Finally, we apply our algorithm to extreme multilabel classification problems, and show that the proposed GBDT-SPARSE achieves an order of magnitude improvements in model size and prediction time over existing methods, while yielding similar performance.",
  "title": "Gradient Boosted Decision Trees for High Dimensional Sparse Output"
}