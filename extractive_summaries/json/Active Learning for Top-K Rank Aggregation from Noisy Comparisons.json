{
  "sections": [{
    "text": "n2 logn log logn . We also present an\nalgorithm that is applicable to both settings."
  }, {
    "heading": "1. Introduction",
    "text": "Ranking is prevalent in a wide variety of applications: social choice (Caplin & Nalebuff, 1991; Azari Soufiani et al., 2013), web search and information retrieval (Dwork et al., 2001), recommendation systems (Baltrunas et al., 2010), and crowd sourcing (Chen et al., 2013), to name a few. The goal of the problem is to bring a consistent ordering to a collection of items, given partial preference information. The two main paradigms among a large volume of works on ranking include spectral ranking algorithms (Negahban et al., 2016; Dwork et al., 2001; Brin & Page, 1998) and maximum likelihood estimation (Ford, 1957). These methods focus on finding the entire ordering, not being tailored for many practical applications in which only a few signifi-\n1ECE, University of Minnesota, Twin Cities, MN, USA. 2EE, KAIST, Daejeon, South Korea. Correspondence to: Soheil Mohajer <soheil@umn.edu>, Changho Suh <chsuh@kaist.ac.kr>, Adel Elmahdy <adel@umn.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\ncant items, say top-K, are often desired to be retrieved.\nIn an effort to exploit the more practically relevant scenario, (Chen & Suh, 2015) investigated the top-K rank aggregation which aims to recover the correct set of topranked items only. It characterized the minimax limit on the sample size (i.e., sample complexity) under the BradleyTerry-Luce (BTL) model (Bradley & Terry, 1952; Luce, 1959) where pairs of two items are compared. However, this development is limited to a passive measurement setting in which pairwise data are simply given prior to analysis.\nMany applications of interest often admit interaction with users. This enables us to select comparison pairs of items in an adaptive manner. This way of ranking provides the potential to reduce a large number of blindly collected measurements while maintaining a ranking accuracy (Tschopp et al., 2011). This motivates us to examine an adaptive measurement setting, in which pairwise comparisons are gathered interacting with a ranker (termed active ranking). In particular, we intend to address the following two questions: (a) how much can active ranking offer performance improvements over passive ranking? (b) how does the limit on the sample size for top-K ranking scale with K?\nTo answer this question, we consider a general model in which the pairwise comparison probabilities are arbitrary subject to a mild condition (see (5) in Section 2 for details) and thus which includes as special cases various models like the BTL model, Strong Stochastic Transitivity (SST) model (Fishburn, 1973; Shah et al., 2016), and uniform noise model (Braverman & Mossel, 2008). Two ranking tasks are taken into consideration: (i) top-K sorting which takes care of detailed ordering within top-K items; (ii) topK partitioning which concerns only the correct set of them.\nContribution. Our contributions are two-folded. The first lies in deriving an upper bound on the sample size:\nO ( (n+K logK) max(log log n, logK)\n∆K\n) (1)\nwhere1\n∆K =\n{ ∆K,S = min\ni∈[K] min j:j≥i (Pij−0.5)2, Sorting; ∆K,P = (PK,K+1−0.5)2, Partitioning.\n(2)\n1Note that the notation ∆K here is defined slightly differently from the one in (Chen & Suh, 2015).\nHere Pij = Pi,j indicates the probability of item i being preferred over item j, and ∆K,S (or ∆K,P) denotes the parameter w.r.t. top-K sorting (or partitioning). Without loss of generality, we assume that the ground truth ranking is the order of 1 2 · · · n. Notice that the sample complexity bound reads O(n log log n/∆K) for the small K regime (e.g, K = O(log n)), and O(K log2K/∆K) for the large K regime (e.g., K = Θ(n)). For the regime K = O(log n) of practical interest, this exhibits significant multiplicative gains of active ranking over passive ranking. For instance, in the case of top-K sorting, when specializing our result into the uniform noise model and BTL model, one can demonstrate that the factor gains are Ω ( n2 logn log logn ) and\nΩ (\nlogn log logn\n) , respectively. See Table 1 for further details.\nOur second contribution is to develop a computationallyefficient (nearly)-linear-time algorithm that can achieve the above bound promised. The algorithm is based on standard algorithms in TCS literature for the noiseless sorting and partitioning, where each pairwise order can be retrieved using a single comparison or the transitive property of the ranking. However, in a noisy setting of our interest, single comparison results are not reliable. A key distinction in our work is to employ repeated pairwise comparisons for each comparison to combat the noise effect.\nHere is how our algorithm works in details. It builds upon a HEAP data-structure and can be applied to both settings of sorting and partitioning. The main idea of identifying top-K items in a dataset of n items is to partition the set of n items into K subsets, and then identify the top item in each subset using single-elimination tournament. Next, a max-HEAP is built to single out the top-1 item among the K winners of the tournaments. After that, this item is removed from the system and the max-HEAP is updated by replacing it by the second top item of the subset this top item belongs to. We repeat this process until we identify top-K items. See Fig. 2 for an explanatory example.\nIt is worth mentioning that the performance of our algorithm depends on the separability parameter ∆K . The algorithm is supposed to correctly distinguish between items K and (K + 1) (in partitioning), or the top K items and the rest (in sorting). The smaller ∆K , the less reliable the results of comparison between to-be-distinguished items; hence, more repetitions are needed for a decision. We characterize the minimum number of repeated comparisons required to ensure that the retrieved items are the correct winners. The carefully chosen number for repeated comparisons together with a couple of bounding techniques play a key role to derive the above sample complexity bound. Finally, we conduct several experiments to corroborate our main results.\nRelated work. (Chen & Suh, 2015) explored the top-K partitioning problem under the non-adaptive comparison model,\nand characterized the optimal sample complexity. Subsequently, sample complexity analyses were made with regard to different yet popular ranking paradigms such as simple counting methods (Shah & Wainwright, 2016) and spectral methods (Jang et al., 2016) (e.g., RankCentrality (Negahban et al., 2016)). In this work, we examine an adaptive measurement setting under a fairly general model, thereby showing that active ranking can significantly outperform passive ranking for a variety of scenarios.\nRecently, (Braverman et al., 2016) developed an active ranking algorithm. Interesingly, for the K = 1 case and under the uniform noise model, their algorithm can achieve the same sample complexity as ours for a certain target error rate. (Szörényi et al., 2015) also focused on the K = 1 case but under the BTL model, thus developing an algorithm which however yields a larger sample complexity than ours. Most recently, (Heckel et al., 2016) proposed an algorithm for a general problem setting which encompasses top-K sorting and partitioning of our interest. We found that their algorithm is outperformed by ours when specializing it to our settings. See 3.2 for detailed discussion.\nThere has been a proliferation of active ranking algorithms (Busa-Fekete et al., 2014; Jamieson & Nowak, 2011; Maystre & Grossglauser, 2015; Ailon, 2012; Braverman & Mossel, 2008; Wauthier et al., 2013). While interesting ranking schemes are developed for perfect ranking (BusaFekete et al., 2014; Jamieson & Nowak, 2011; Maystre & Grossglauser, 2015) and approximate ranking (Jamieson & Nowak, 2011; Ailon, 2012; Braverman & Mossel, 2008; Wauthier et al., 2013), they are not customized for top-K ranking of our interest.\nMoreover, the best-K identification with adaptive sampling has been extensively explored under the name of the multiarmed bandit problem (Gabillon et al., 2011; Bubeck et al., 2013; Jamieson et al., 2014; Yue et al., 2012) for a so-called value-based model in which the observation on each item is drawn only from the distribution underlying this individual. Also there are many related yet different problem settings considered in prior literature (Azari Soufiani et al., 2013; Hajek et al., 2014; Lu & Boutilier, 2011; Eriksson, 2013)."
  }, {
    "heading": "2. Problem Formulation",
    "text": "Comparison model. We denote by G = ([n], E) a comparison graph in which items i and j are compared if and only if (i, j) belongs to the edge set E . More precisely, a multi-edge graph is taken into consideration to accommodate repeated measurements for an observed pair. We take into account an adaptive comparison graph in which the edge set is dynamically selected interacting with a ranker. Specifically, for a sample instance t ∈ [1 : S] where S indicates the total sample size, an edge et = (it, jt) is chosen based on the pairwise outcomes obtained up to (t− 1).\nPairwise comparisons. Given et = (i, j), the outcome of the tth comparison, denoted by Yt, is generated according to\nYt = { 1 with probability Pij 0 with probability 1− Pij , (3)\nwhere Yt = 1 indicates that item i is preferred over item j. The outcomes Yt’s are independent across t. We also represent the collection of sufficient statistics as\nYij := ∑\nt:et=(i,j),et∈E\nYt; Y := {Yij : (i, j) ∈ E}. (4)\nSorted-by-Probabilities (SP) model. Without loss of generality, assume that the ground truth ranking is the order of 1 2 · · · n. In fact, the SST model (Fishburn, 1973; Shah et al., 2016) suggests one way to relate the ranking to the model parameters Pij’s by putting the following constraint2: Pik > Pjk for all k 6= {i, j} whenever item i item j. In this work, we introduce a more general model, which we call Sorted-by-Probabilities (SP) model, by relaxing the constraint as:\nPij > 1\n2 whenever i j. (5)\nNotice that the new constraint (5) is weaker, thus spanning a larger parameter space. One can readily verify that our model also subsumes as special cases other prominent models. Observe that whenever i j,\nPij =\n{ 1 2 + γ > 1 2 , (uniform noise model);\nwi wi+wj > 12 , (BTL model), (6)\nwhere γ denotes an arbitrary constant ∈ (0, 0.5) and wi indicates the score of item i.\nPerformance metric and goal. Given the pairwise comparisons, one wishes to know whether or not the top-K ordered items (or the top-K set) are identifiable. In light of this, we consider the probability of error Pe:\nPe(ψ) = { P {ψ(Y ) 6= (1 · · · K)} , sorting; P {ψ(Y ) 6= [K]} , partitioning,\nwhere ψ is any ranking scheme that returns an order of K indices. Our goal in this work is to characterize the sample complexity S∗K , defined as the minimum sample size above which top-K ranking is feasible, in other words, Pe can be vanishingly small as n grows.\nRemark 1 It should be noted that there are other frameworks in which different performance metrics are taken into consideration: “regret” (Yue et al., 2012), and “PAClearning” (Szörényi et al., 2015), both introduced in the\n2We ignore the tie situation as we consider a strict order of ranking. Precisely speaking, the constraint is called Strict Strong Stochastic Transitivity (SSST) property (Fishburn, 1973).\nbandit literature. Actually our work focuses on the worst case scenario as the “error rate (0/1 loss)” that we considered is the most stringent criterion among others. Hence, the sample complexity of our model provides an upper bound for other criteria. Interestingly, the sample complexity of the proposed algorithm is superior (lower) to that of the PLPAC algorithm (Szörényi et al., 2015) under the PAC criterion. See Section 3.2 for details."
  }, {
    "heading": "3. Main Results",
    "text": "As noted in the passive ranking setup (Chen & Suh, 2015), the most crucial part of top-K partitioning under the BTL model hinges on separating the two items near the bound-\nary, being reflected in ( wK−wK+1 wK+wK+1 )2 . Similarly for top-K sorting, one can easily show that the key measure would be:\nmini∈[K] ( wi−wi+1 wi+wi+1 )2 . We find that in our general model, the corresponding key measure is the one defined in (2). Observe in (2) that Pij − 0.5 = wi−wj2(wi+wj) under the BTL model. Hence, we will use this measure to express our upper bound on sample complexity as below.\nTheorem 1 With probability exceeding 1− (log n)−c0 , the top-K order (or top-K set3) can be identified provided that\nSK ≥ c1(n+K logK) max(log log n, logK)\n∆K . (7)\nHere, (c0, c1) are some universal positive constants.\nSee Section 4 for the proof of Theorem 1 and algorithm description. There are three points to make. The first is that the above bound is w.r.t. a target error rate that scales like\n1 poly(logn) . Aiming at a smaller target error, we need a larger sample size. Secondly, the term ∆K , affected by (Pij−0.5) (see (2)), captures how noisy the comparison data is, i.e., (Pij − 0.5) is a sort of the difficulty level of separating item i from item j. So the result in Theorem 1 coincides with our intuition because smaller ∆K means more difficult to rank, which results in an increase of sample complexity. The last point is regarding the performance of our algorithm. Since sorting naturally produces a partitioning, our algorithm is tailored for the sorting, and hence favors the sorting performance relative to partitioning. Notice for partitioning that when K = n, the sample complexity bound reads the order of n(log n)2, which is certainly far from optimality. Hence, in the next subsection, we provide several interesting remarks with an emphasis on top-K sorting in which we advocate the performance of our algorithm.\n3For top-K partitioning, we assume monotonicity in Pij : Pij ≥ Pik whenever i ≤ j ≤ k, which holds still under a fairly general model like SST.\n3.1. Top-K Sorting\nPenalty due to noisy measurements: As mentioned earlier, top-K sorting has been extensively explored in the TCS literature, but only the noiseless setting has been the main focus, in which sample complexity is characterized as (Cormen et al., 2009)\nSnoiseless,K = Θ(n+K logK). (8)\nComparing (8) to (7), we see that the penalty factor in sample complexity due to noisy measurements is:\nO\n( max(log log n, logK)\n∆K\n) . (9)\nActually it is not clear whether or not this penalty factor is fundamental due to the lack of the optimality result. However, the gap, if any, is up to poly(log n), as long as ∆K is not too small (scales at most with poly(log n)). This implies that the degradation over the noiseless setting is low and therefore our algorithm performs very close to optimum.\nHow the limit scales with K: Observe in (7) that:\nSK =  O ( n log logn ∆K ) , K = O(log n); O ( K log2K\n∆K\n) , K = Θ(n).\nWe make one interesting observation in the K = O(log n) regime of practical interest: the bound is irrelevant to K under some measurement model. One such example is the uniform noise model where ∆K = γ2:\nSuniform,K = O\n( n log log n\nγ2\n) , (10)\nfor every K. However, this phenomenon does not carry over to other noisy models, like the BTL model in which the noise quality varies according to associated preference scores. Note that\nSBTL,K = O\n( n log log n\nmini∈[K] (wi−wi+1 wi+wi+1\n)2 ) . (11)\nBut our result still suggests that the phenomenon may hold universally for a variety of statistical models as long as K is small enough.\nActive vs. passive ranking: For illustrative purpose, let us focus on the interesting regime of K = O(log n), and consider two models: (1) uniform noise model; (2) BTL model. In the uniform noise model, Shah-Wainwright (Shah & Wainwright, 2016) characterized the passive ranking sample complexity for a certain observation model:\nSpassiveuniform,K = Θ\n( n3 log n\nγ2\n) , (12)\nfor every choice of K. This together with (10) demonstrates that the factor gain due to active measurements is quite substantial: Ω ( n2 logn log logn ) . In the BTL model, Chen-Suh (Chen\n& Suh, 2015) characterized the sample complexity under passive ranking as:\nSpassiveBTL,K = O\n( n log n\nmini∈[K] ( wi−wi+1 wi+wi+1\n)2 ) . (13)\nComparing this to (11), we see that the factor gain is Ω (\nlogn log logn\n) , which is not quite significant but still scales\nwith n and hence exhibits respectful improvements in high dimensional regimes. The comparisons are summarized in Table 1. See Section 5 for experimental results on this.\nRobustness: Theorem 1 suggests that the performance gap between sorting and partitioning is not significant. For instance, under the uniform noise model, ∆K’s are the same, yielding the same sample complexity bound. For the BTL model, ∆K’s would be similar if wi’s are equidistant. Experimental results on this are provided in the supplemental.\nComputational complexity: A noticeable feature of our algorithm is its low computational complexity. It runs in time O(n) in the practically-relevant regime of K = O(log n). For general K, it is nearly linear in n, i.e., O(n+K logK). Here, this complexity assumes that the input fed to our algorithm is the sufficient statistic of the outcome comparisons: Yij (see (4)), rather than the entire collection of Yt’s associated with the pair (i, j). This will be evident later when describing the algorithm."
  }, {
    "heading": "3.2. Comparison to Related Work",
    "text": "(Braverman et al., 2016) developed an active ranking algorithm for the K = 1 case and derived the order-wise tight sample complexity in terms of target error rate under the uniform noise model. More concretely, suppose we want the error probability not to exceed a target error rate δ. Then, the result of (Braverman et al., 2016) implies\nS1,δ = Θ\n( n log(1/δ)\nγ2\n) . (14)\nNotice that our result (7) admits the target error rate that scales like 1logn , implying that their algorithm can achieve the same sample complexity as ours for a certain scenario in which δ ≤ 1logn (see Section 5 for experimental results). For a relaxed target error like 1log logn , their algorithm achieves a slightly smaller sample complexity by a factor of\nlog logn log log logn .\n(Szörényi et al., 2015) also developed a top-selection algorithm and analyzed sample complexity under the BTL model as well as a less-stringent PAC criterion. Their sample complexity bound reads around O(n log n), thus yields a larger one compared to ours.\nIn another relevant paper, (Heckel et al., 2016) proposed an active ranking algorithm for a general setting, which subsumes top-K sorting (as well as top-K partitioning)\nas a special case. They also provided a lower bound on the sample complexity for a class of parametric models, which is only O(log n) away from the achievable sample complexity. It is worth mentioning that under the uniform noise model, the algorithm in (Heckel et al., 2016) requires O ( n2 log(1/δ)\nγ2\n) pairwise comparisons to achieve an error\nrate of δ, which is very expensive compared to our algorithm. Here a key to note is that the uniform noise model does not fit to the class of parametric models considered by (Heckel et al., 2016), in which the CDF function Φ in Pij = Φ(wi− wj) is assumed to be differentiable, which does not hold in the uniform noise model where Φ(t) = 12 + γ sign(t).\nOn the other hand, applying the result of (Heckel et al., 2016) on the BTL model, we get lower and upper bounds on the sample complexity. To see this in details, consider a special case of the top-K partitioning problem, where w1 = w2 = · · · = wK , and wK+1 = wK+2 = · · · = wn. In this case, (Heckel et al., 2016) implies\ncl n\n∆K log\n( 1\n2δ\n) ≤SBTL,K≤ cu n ∆K log (n δ ) log log ( 4 ∆K ) where cl = 1/16 and cu ≈ 654. Notice that the asymptotic multiplicative gap between the lower and upper bounds are on the order of log(n) log log(1/∆K). Moreover, the large constant-factor gap yields a significant performance gap in the actual experiment. For instance, see Fig. 3(b) where n = 1024, ∆K = 0.0225, and δ = 0.1. Observe that the lower and upper bounds are 6.6 × 103 and 4.5 × 108 comparisons, respectively, which are far apart."
  }, {
    "heading": "4. Proposed Ranking Algorithm",
    "text": "In this section we present our algorithms for sorting and partitioning tasks, and provide upper bounds for the sample complexity. We use N (·) to denote the number of pairwise comparisons required in the algorithm."
  }, {
    "heading": "4.1. Top-1 Selection: Single-Elimination Tournament",
    "text": "We first focus on the special case of identifying the top item, i.e., K = 1. The proposed algorithm is essentially a customized single-elimination tournament, which consists of multiple layers. In each layer items are paired in a ran-\nAlgorithm 1 SELECT(X;m) Input: m Data: X = {x[1], x[2], . . . , x[n]}. Output: a∗: the index of item with the highest score. (Assume |X| is a power of 2 for simplicity) n← |X| for i← 1 to |X| do a(i)← i end for for `← 1 to log n do\nfor i← 1 to n/2` do T ← 0 for t← 1 to m do et ← (a(2i− 1), a(2i)) T ← T + Yt (Yt is defined in Eq. 3)\nend for if T ≥ m2 then a(i)← a(2i− 1) else a(i)← a(2i) end if\nend for end for a∗ ← a(1)\ndom manner, and one of the items in each pair is selected to proceed to the next layer, while the other one is eliminated. This decision is made based on pairwise comparisons between the two items. The distinctive feature relative to conventional single-elimination tournament is that in order to combat against the uncertainty of the observations, we repeat each binary comparison multiple (saym) times. It turns out that for a sufficiently large m, the algorithm will output the index of the top item with overwhelming probability.\nThe algorithm builds a binary tree of depth dlog |X|e (see Fig. 1). We denote the i-th item index in layer ` by x`,i. Initially, we randomly locate items on the leaves of the tree, that are denoted by x1,i for i = 1, . . . , n. Then, in each iteration, a pair in layer ` is tested, and the winner will proceed to layer (`+ 1). Hence, half of the existing items will be eliminated in each iteration, until we get to the root layer in which there would be only one surviving item. The algorithm is formally presented in Algorithm 1.\nNumber of measurements: The algorithm consists of dlog |X|e layers, and |X|/2` pairs are being tested in layer `.\nHence, the total number of tests is ∑dlog |X|e `=1 n2\n−` ≤ |X|. Each test requires m binary comparisons, yielding a total number of measurements given by\nN (SELECT(X;m)) = O(m|X|) = O(mn), (15) for a dataset of size |X| = n. It can be shown that if\nm ≥ (1 + ε) ln 2 2 log log |X| ∆1,S , (16)\nthen Pe(TopSelection) ≤ (log n)−ε for any ε > 0. This implies that, with high probability, the SELECT algorithm can successfully select the top item using a total of\nN (SELECT(X;m)) = O ( |X| log log |X|\n∆1\n) (17)\npairwise comparisons.\nRemark 2 Parallel to this work, the top-selection problem is studied in (Braverman et al., 2016) under the uniform noise model. The algorithm in (Braverman et al., 2016) first identifies the top item in a subset of size n/ log n items, and then iteratively refines the estimate by further comparing that to other items in the set. It is shown that the number of measurements required grows linearly with n, when a constant (non-vanishing) error probability is desired. However, in order to achieve a vanishing error probability scaling as 1/poly(log n), the algorithm of (Braverman et al., 2016) requires the same number (up to a constant factor) of pairwise comparisons, as the one presented above.\n4.2. Top-K Sorting: A Heap-based Algorithm\nIn this section we generalize our proposed algorithm to find the top K items along with their order. The proposed algorithm is built based on the single-elimination algorithm, which can find the the single top item with high probability. A trivial generalization is to repeat the SELECT algorithm for K times, which requires a large number of comparisons\nAlgorithm 2 TOP(X;K,m) Input: Integers K and m Data: Array X = {x[1], x[2], . . . , x[n]}. Output: Indices of top-K: π(1), π(2), . . . , π(K) n← |X|, Q← dn/Ke for i← 0 to K − 1 do Ci+1←{x[iQ+1], x[iQ+2],. . ., x[min{(i+1)Q,n}]} b(i+ 1)← iQ+ SELECT(Ci+1;m)\nend for Z ← {b(1), b(2), . . . , b(K)} BuildHeap(Z,X;m) for i← 1 to K do π(i)← Z[1] j ← bZ[1]/Kc Cj ← Cj \\ {x[Z[1]]} Z[1]← SELECT(Ci;m) Heapify(Z,X, 1;m) end for\nwhen K scales with n = |X|. Rather, we first split the dataset X of n items into K groups each of size n/K, namely groups C1, C2, . . . , CK . Then we identify the top item in each sub-group using SELECT, and form a short list that includes all winners from the sub-groups. Then we build a (max-)HEAP data-structure for the short list obtained from the K winners. The HEAP structure allows us to easily extract the top item from the short list. Once the top item of the short list is identified and removed from the list, we go back to its home sub-group, identify the second top item in that sub-group, and insert it to the short list. We maintain the HEAP structure of the short list during the process, to be able to easily extract the next top item of the list. We repeat this procedure for (K−1) rounds until we retrieve all the top K items. The main algorithm, TOP is presented in Algorithm 2. For the sake of completeness, we also present the algorithms required to build the heap structure and to insert a new item to an existing heap in the supplemental.\nSample complexity: The sample complexity of the algorithm can be simply evaluated in terms of the input parameters as follows. We first identify the top entry of each of the K sub-groups. Later, during the iterative phase of the algorithm, we need to repeat SELECT algorithm on the remaining elements of sub-groups for another K iterations, which results in 2K runs of SELECT, each on subgroups of size at most n/K items. Each run of algorithm SELECT with parameter m on a dataset Ci requires N [SELECT(Ci;m)] pairwise comparison, as given in (16).\nIn order to build the heap structure on K sub-winners we need to make O(K) binary decisions, where we repeat each comparison m times to deal with the noise. Moreover, in each iteration one new item is added to the short list. We need to make O(logK) binary decisions to maintain the\nheap structure. Similar to BuildHeap, we repeat each comparison form times, and then decide based on a majority rule. Therefore, we have\nN [TOP(X,K;m)] , 2K · N [SELECT(Ci;m)] +N [BuildHeap(Z;m)]+KN [InsertHeap(Z;m)] = 2K ·O(mn/K) +m ·O(K) +m ·O(K logK) = O(mn+mK logK). (18)\nIt turns out, from the analysis of probability of error, that the proposed algorithm can successfully sort the top K items if\nm = O\n( max{logK, log log n}\n∆K\n) .\nPlugging this into (18), we can find the sample complexity of the TOP algorithm as\nSK = O\n( (n+K logK) max{logK, log log n}\n∆K\n) .\nRemark 3 The repetition parameter used in SELECT algorithm, and the one used in HEAP can be potentially different, and accordingly optimized. However, our analysis shows that a choice of distinct parameters can provide a marginal gain only for a tiny range of K. Thus, we rather choose the same parameter for the sake of simplicity."
  }, {
    "heading": "4.3. Partitioning",
    "text": "The algorithm we propose for partitioning is exactly identical to that of the sorting. We (randomly) split the items\ninto K groups, and run the single-elimination tournament in each group. The winners will proceed to the HEAP algorithm, and then the HEAP outputs items one by one. The only difference lies in the performance metric which concerns only the set of K items reported by the algorithm, regardless of the order. It turns our that a similar analysis holds for this problem, except the fact that the number of repeated comparisons, m, has a weaker dependency on the data. More precisely, the algorithm is robust against wrong binary decision between two items from [K], and similarly between two items from X \\ [K]. One needs to choose m such that the algorithm (with high probability) can correctly distinguish when s ∈ [K] is compared against q ∈ X \\ [K]. Consequently, we show that m depends only on ∆K,P, which captures the gap between PK,K+1 and 1/2.\nRemark 4 Note that the proposed algorithms do not require the knowledge of ∆K , and can be executed with anym. It depends only on the measurement budget. However, dependency of the performance of the algorithms on ∆K is inevitable, since the success rate depends on the separability parameter as discussed earlier."
  }, {
    "heading": "5. Simulation Results",
    "text": "In this section, we empirically evaluate the performance of the proposed algorithm by conducting Monte Carlo simulations on synthetic data and developing a benchmark comparison against the state-of-the-art active and passive ranking algorithms in the literature. In an effort to guarantee fairness in the performance comparison, we jointly investigate the average number of pairwise comparisons and the corresponding empirical success rate of identifying top-K items. The source code of our algorithm4 is provided to allow for reproducible research. In addition, we present a more detailed discussion on the performance of our algorithm under various simulation parameters in the supplemental."
  }, {
    "heading": "5.1. Comparison to Prior Active Ranking Algorithms",
    "text": "We assess the performance of the proposed algorithm against two recent active ranking algorithms; the first is proposed by (Braverman et al., 2016), coined “Braverman”, while the second algorithm is proposed by (Heckel et al., 2016), coined “Heckel”. For Braverman algorithm, we sweep over an algorithm parameter (denoted by c in the paper), such that c ≥ 10, to measure the corresponding success rate. Heckel algorithm employs a confidence interval during the process, and we select the following empirical confidence interval model, that is a function of the algorithm round, t, and the tolerance parameter δ ∈ (0, 0.14]: αt = √ log(n/3(log(t) + 1)/δ)/16t.\n4The source code is accessible via GitHub at https://github.com/a-elmahdy/ Active-Learning-from-Noisy-Comparisons.git\nThe plots in Fig. 3(a) indicate the performance of different active ranking algorithms under the uniform noise model to identify the top-1 and top-16 items, respectively, when n = 210 = 1024, ∆K = γ2 = 0.0225 and δ = 0.1. The first plot shows slight improvement in the total number of pairwise comparisons required to achieve a target success rate for Braverman algorithm over our Top-1 algorithm. We also observe that the performance gap between the two algorithms is negligible at a higher success rate. On the other hand, the second plot in Fig. 3(a) depicts the significant improvement of our Top-K algorithm over Braverman algorithm5 when K = 16. It is evident that the sample complexity of Braverman algorithm scales with K when it is employed for top-K identification. We can also see that the performance gap between Partitioning and Sorting is insignificant. These findings are consistent with our analysis of the sample complexity of both algorithms. Hence, the two prime merits of the proposed Top-K algorithm are: (1) its superior performance compared to Braverman algorithm when K > 1; and (2) error and sample complexity of Braverman algorithm is limited to uniform noise model, while our algorithm provably performs well for a wide class of pairwise comparison models, defined by (5). We refer the reader to the supplemental for an insightful remark about our algorithm.\n5Braverman algorithm is extended to top-K ranking. We first run the algorithm to retrieve the top-item. Then, we remove it from the set of items and rerun the algorithm to find the second top item. We keep doing that until we find the top-K items.\nThe plots in Fig. 3(a) also depict performance comparison between our and Heckel algorithm for Top-K ranking under the uniform noise model. As it is clear from the figure, the proposed algorithm in this work performs significantly better than Heckel algorithm for this noise model. Furthermore, Fig. 3(b) shows that our algorithm for identifying top-1 and top-16 ranked items also achieves a better performance compared to Heckel algorithm under the BTL model."
  }, {
    "heading": "5.2. Active vs. Passive Ranking",
    "text": "We compare the performance of our active ranking algorithm against a passive ranking algorithm proposed by (Shah & Wainwright, 2016), coined “Shah”. This simple yet robust algorithm hinges on Copeland counting algorithm that recovers the top-K items that win the maximum number of pairwise comparisons. Moreover, the algorithm makes no assumptions on the probability model of pairwise comparisons. The algorithm parameters are the probability of making a comparison on any trial, p, the number of trials, r, and α ≥ 8. Note that the number of noisy comparisons associated with each pair of items follows a binomial distribution with parameters p and r.\nThe plots in Fig. 3(c) illustrate the performance of the two algorithms under the uniform noise model to recover the top-1 and top-8, respectively, when n = 27 = 128, ∆K = γ\n2 = 0.1, α = 8 and p = 0.6. As predicted by our analysis of the sample complexity gain, we can observe the considerable gain due to active measurements, even when the total number of items is modest."
  }, {
    "heading": "Acknowledgment",
    "text": "The authors would like to thank the reviewers who gave useful comments. C. Suh was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP; Ministry of Science, ICT & Future Planning) (No. 2015R1C1A1A02036561)."
  }],
  "year": 2017,
  "references": [{
    "title": "Active learning ranking from pairwise preferences with almost optimal query complexity",
    "authors": ["N. Ailon"],
    "venue": "Journal of Machine Learning,",
    "year": 2012
  }, {
    "title": "Generalized method-of-moments for rank aggregation",
    "authors": ["H. Azari Soufiani", "W. Chen", "D.C. Parkes", "L. Xia"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2013
  }, {
    "title": "Group recommendations with rank aggregation and collaborative filtering",
    "authors": ["L. Baltrunas", "T. Makcinskas", "F. Ricci"],
    "venue": "In ACM Conference on Recommender Systems,",
    "year": 2010
  }, {
    "title": "Rank analysis of incomplete block designs: I. the method of paired comparisons",
    "authors": ["R.A. Bradley", "M.E. Terry"],
    "year": 1952
  }, {
    "title": "Noisy sorting without resampling",
    "authors": ["M. Braverman", "E. Mossel"],
    "venue": "In ACM-SIAM symposium on Discrete algorithms,",
    "year": 2008
  }, {
    "title": "Parallel algorithms for select and partition with noisy comparisons",
    "authors": ["M. Braverman", "J. Mao", "S.M. Weinberg"],
    "year": 2016
  }, {
    "title": "The anatomy of a large-scale hypertextual web search engine",
    "authors": ["S. Brin", "L. Page"],
    "venue": "Computer Networks and ISDN systems,",
    "year": 1998
  }, {
    "title": "Multiple identification in multi-armed bandits",
    "authors": ["S. Bubeck", "T. Wang", "N. Viswanathan"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "Preference-based rank elicitation using statistical models: The case of mallows",
    "authors": ["R. Busa-Fekete", "E. Hüllermeier", "B. Szörényi"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2014
  }, {
    "title": "Aggregation and social choice: a mean voter theorem",
    "authors": ["A. Caplin", "B. Nalebuff"],
    "venue": "Econometrica, pp",
    "year": 1991
  }, {
    "title": "Pairwise ranking aggregation in a crowdsourced setting",
    "authors": ["X. Chen", "P.N. Bennett", "K. Collins-Thompson", "E. Horvitz"],
    "venue": "In ACM Conference on Web Search and Data Mining,",
    "year": 2013
  }, {
    "title": "Spectral MLE: Top-K rank aggregation from pairwise comparisons",
    "authors": ["Y. Chen", "C. Suh"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2015
  }, {
    "title": "Rank aggregation methods for the web",
    "authors": ["C. Dwork", "R. Kumar", "M. Naor", "D. Sivakumar"],
    "venue": "In International conference on World Wide Web,",
    "year": 2001
  }, {
    "title": "Learning to top-K search using pairwise comparisons",
    "authors": ["B. Eriksson"],
    "venue": "In International Conference on Artificial Intelligence and Statistics,",
    "year": 2013
  }, {
    "title": "Binary choice probabilites: on the varieties of stochastic transitivity",
    "authors": ["P.C. Fishburn"],
    "venue": "Journal of Mathematical Psychology,",
    "year": 1973
  }, {
    "title": "Solution of a ranking problem from binary comparisons",
    "authors": ["L.R. Ford"],
    "venue": "American Mathematical Monthly,",
    "year": 1957
  }, {
    "title": "Multi-bandit best arm identification",
    "authors": ["V. Gabillon", "M. Ghavamzadeh", "A. Lazaric", "S. Bubeck"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2011
  }, {
    "title": "Minimax-optimal inference from partial rankings",
    "authors": ["B. Hajek", "S. Oh", "J. Xu"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Active ranking from pairwise comparisons and when parametric assumptions don’t help",
    "authors": ["R. Heckel", "N. Shah", "K. Ramchandran", "M. Wainwright"],
    "year": 2016
  }, {
    "title": "liiUCB: An optimal exploration algorithm for multi-armed bandits",
    "authors": ["K. Jamieson", "M. Malloy", "R. Nowak", "S. Bubeck"],
    "venue": "In Conference on Learning Theory,",
    "year": 2014
  }, {
    "title": "Active ranking using pairwise comparisons",
    "authors": ["K.G. Jamieson", "R. Nowak"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2011
  }, {
    "title": "Top-k ranking from pairwise comparisons: When spectral ranking is optimal",
    "authors": ["M. Jang", "S Kim", "C Suh", "S. Oh"],
    "venue": "arXiv preprint arXiv:1603.04153,",
    "year": 2016
  }, {
    "title": "Learning Mallows models with pairwise preferences",
    "authors": ["T. Lu", "C. Boutilier"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2011
  }, {
    "title": "Individual choice behavior: A theoretical analysis",
    "authors": ["R.D. Luce"],
    "year": 1959
  }, {
    "title": "Robust active ranking from sparse noisy comparisons",
    "authors": ["L. Maystre", "M. Grossglauser"],
    "venue": "In arXiv:1502.05556,",
    "year": 2015
  }, {
    "title": "Rank centrality: Ranking from pairwise comparisons",
    "authors": ["S. Negahban", "S. Oh", "D. Shah"],
    "venue": "Operations Research,",
    "year": 2016
  }, {
    "title": "Simple, robust and optimal ranking from pairwise comparisons",
    "authors": ["N.B. Shah", "M.J. Wainwright"],
    "year": 2016
  }, {
    "title": "Stochastically transitive models for pairwise comparisons: Statistical and computational issues",
    "authors": ["Shah", "N. B", "S. Balakrishnan", "A. Guntuboyina", "M.J. Wainwright"],
    "venue": "International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "Online rank elicitation for Plackett-Luce: A dueling bandits approach",
    "authors": ["B. Szörényi", "R. Busa-Fekete", "A. Paul", "E. Hüllermeier"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Randomized algorithms for comparison-based search",
    "authors": ["D. Tschopp", "S. Diggavi", "P. Delgosha", "S. Mohajer"],
    "venue": "In Neural Information Processing Systems,",
    "year": 2011
  }, {
    "title": "Efficient ranking from pairwise comparisons",
    "authors": ["F. Wauthier", "M. Jordan", "N. Jojic"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2013
  }, {
    "title": "The k-armed dueling bandits problem",
    "authors": ["Y. Yue", "J. Broder", "R Kleinberg", "T. Joachims"],
    "venue": "Journal of Computer and System Sciences,",
    "year": 2012
  }],
  "id": "SP:0d3e33f5c486e67b0c8d894ea059c3243704d21c",
  "authors": [{
    "name": "Soheil Mohajer",
    "affiliations": []
  }, {
    "name": "Changho Suh",
    "affiliations": []
  }, {
    "name": "Adel Elmahdy",
    "affiliations": []
  }],
  "abstractText": "We explore an active top-K ranking problem based on pairwise comparisons that are collected possibly in a sequential manner as per our design choice. We consider two settings: (1) top-K sorting in which the goal is to recover the top-K items in order out of n items; (2) top-K partitioning where only the set of top-K items is desired. Under a fairly general model which subsumes as special cases various models (e.g., Strong Stochastic Transitivity model, BTL model and uniform noise model), we characterize upper bounds on the sample size required for top-K sorting as well as for top-K partitioning. As a consequence, we demonstrate that active ranking can offer significant multiplicative gains in sample complexity over passive ranking. Depending on the underlying stochastic noise model, such gain varies from around logn log logn to n logn log logn . We also present an algorithm that is applicable to both settings.",
  "title": "Active Learning for Top-K Rank Aggregation from Noisy Comparisons"
}