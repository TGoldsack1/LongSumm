{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Sleep plays a vital role in an individual’s health and wellbeing. Sleep progresses in cycles that involve multiple sleep stages: Awake, Light sleep, Deep sleep and REM (Rapid Eye Movement). Different stages are associated with different physiological functions. For example, deep sleep is essential for tissue growth, muscle repair, and memory consolidation, while REM helps procedural memory and emotional health. At least, 40 million Americans each year suffer from chronic sleep disorders (National Institute of Health). Most sleep disorders can be managed once they are correctly diagnosed (National Institute of Health). Monitoring sleep stages is beneficial for diagnosing sleep disorders, and tracking the response to treatment (Carskadon & Rechtschaffen, 2000).\nPrevailing approaches for monitoring sleep stages are inconvenient and intrusive. The medical gold standard relies on Polysomnography (PSG), which is typically con-\n1MIT CSAIL, Cambridge, MA, USA 2Massachusetts General Hospital, Boston, MA, USA. Correspondence to: Mingmin Zhao <mingmin@mit.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nducted in a hospital or sleep lab, and requires the subject to wear a plethora of sensors, such as EEG-scalp electrodes, an ECG monitor, multiple chest bands, and nasal probes. As a result, patients can experience sleeping difficulties, which renders the measurements unrepresentative (Herbst, 2010). Furthermore, the cost and discomfort of PSG limit the potential for long term sleep studies.\nRecent advances in wireless systems have demonstrated that radio technologies can capture physiological signals without body contact (Kaltiokallio et al., 2014; Adib et al., 2015; Zhao et al., 2016). These technologies transmit a low power radio signal (i.e., 1000 times lower power than a cell phone transmission) and analyze its reflections. They extract a person’s breathing and heart beats from the radio frequency (RF) signal reflected off her body. Since the cardio-respiratory signals are correlated with sleep stages, in principle, one could hope to learn a subject’s sleep stages by analyzing the RF signal reflected off her body. Such a system would significantly reduce the cost and discomfort of today’s sleep staging, and allow for long term sleep stage monitoring.\nThere are multiple challenges in realizing the potential of RF measurements for sleep staging. In particular, we must learn RF signal features that capture the sleep stages and their temporal progression, and the features should be transferable to new subjects and different environments. The problem is that RF signals carry much information that is irrelevant to sleep staging, and are highly dependent on the individuals and the measurement conditions. Specifically, they reflect off all objects in the environment including walls and furniture, and are affected by the subject’s position and distance from the radio device. These challenges were not addressed in past work which used hand-crafted signal features to train a classifier (Zaffaroni et al., 2014; Tataraidze et al., 2016b). The accuracy was relatively low (∼64%) and the model did not generalize beyond the environment where the measurements were collected.\nThis paper presents a new model that delivers a significantly higher accuracy and generalizes well to new environments and subjects. The model adapts a convolutional neural network (CNN) to extract stage-specific features from RF spectrograms, and couples it with a recurrent\nneural network (RNN) to capture the temporal dynamics of sleep stages.\nHowever, a CNN-RNN combination alone would remain liable to distracting features pertaining to specific individuals or measurement conditions (i.e., the source domains), and hence would not generalize well. To address this issue, we introduce a new adversarial training regime that discards extraneous information specific to individuals or measurement conditions, while retaining all information relevant to the predictive task –i.e., the adversary ensures conditional independence between the learned representation and the source domains.\nOur training regime involves 3 players: the feature encoder (CNN-RNN), the sleep stage predictor, and the source discriminator. The encoder plays a cooperative game with the predictor to predict sleep stages, and a minimax game against the source discriminator. Our source discriminator deviates from the standard domain-adversarial discriminator in that it takes as input also the predicted distribution of sleep stages in addition to the encoded features. This dependence facilitates accounting for inherent correlations between stages and individuals, which cannot be removed without degrading the performance of the predictive task.\nWe analyze this game and demonstrate that at equilibrium, the encoded features discard all extraneous information that is specific to the individuals or measurement conditions, while preserving all information relevant to predicting the sleep stages. We also evaluate our model on a dataset of RF measurements and corresponding sleep stages1. Experimental results show that our model significantly improves the prediction accuracy of sleep stages. In particular, our model has a prediction accuracy of 79.8% and a Cohen’s Kappa of 0.70, whereas the best prior result for predicting sleep stages from RF signals (Tataraidze et al., 2016b) has an accuracy of 64% and a Cohen’s Kappa of 0.49."
  }, {
    "heading": "2. Related Work",
    "text": "(a) Sleep Staging: The gold standard in sleep staging is based on Polysomnography (PSG) conducted overnight in a hospital or sleep lab. The subject has to sleep while wearing multiple sensors including an EEG monitor, an EMG monitor, an EOG monitor, nasal probes, etc. A sleep technologist visually inspects the output of the sensors and assigns to each 30-second window a stage label (Rechtschaffen & Kales, 1968).\nA few past proposals have tried to automate the process and reduce the number of sensors. These solutions can be classified into four categories according to their source\n1Dataset is available at: http://sleep.csail.mit.edu/\nsignal: EEG-based, Cardiorespiratory-based, Actigraphybased, or RF-based. Table 1 summarizes the state of the art performance in each category. The table shows both the classification accuracy and the Cohen’s Kappa coefficient, κ. The most accurate methods rely on EEG signals (Ebrahimi et al., 2008; Fraiwan et al., 2012; Popovic et al., 2014; Shambroom et al., 2012). However, EEG monitors are also the most intrusive because they require the subject to sleep with a skullcap or a head-band equipped with multiple electrodes, which is uncomfortable and can cause headaches and skin irritation.The second category requires the subject to wear a chest-band and analyzes the resulting cardiorespiratory signals. It is more comfortable than the prior method but also less accurate (Tataraidze et al., 2016a; Long et al., 2014). The third approach is based on actigraphy; it leverages accelerometers in FitBit or smart phones (Hao et al., 2013; Gu et al., 2014) to monitor body movements and infer sleep quality. Yet, motion is known to be a poor metric for measuring sleep stages and quality (Pollak et al., 2001). The last approach relies on RF signals reflected off the subject body during her sleep. It allows the subject to sleep comfortably without any onbody sensors. Yet past approaches in this category have the worst performance in comparison to other solutions.\nThis paper builds on the above literature but delivers significant new contributions. In comparison to methods that use sources other than RF signals, the paper enables accurate monitoring of sleep stages while allowing the subject to sleep comfortably in her own bed without sensors on her body. Furthermore, due to differences between RF signals and other signal sources, our model has to eliminate extraneous information that are specific to the environment and irrelevant to sleep stage classification. In comparison to past work on learning sleep stages from RF signals (Rahman et al., 2015; Tataraidze et al., 2016b; Liu et al., 2014), our approach significantly improves the prediction accuracy as shown in Table 1. This improvement is due to intrinsic differences between past models and the model in this paper, which avoids hand-crafted features, and learns\nfeatures that capture the temporal dependencies and transfer well to new subjects and different environments.\n(b) Representation Learning: We build on a rich body of literature on CNNs and RNNs which have been successfully used to model spatial patterns (Szegedy et al., 2015; He et al., 2016) and temporal dynamics (Sutskever et al., 2014), including combinations of the two (Pigou et al., 2015). Our CNN differs slightly in terms of convolutions that are adapted to our domain while, architecturally, our RNN is a standard variety LSTM.\nOur work also contributes to learning invariant representations in deep adversarial networks. Adversarial networks were introduced to effectively train complex generative models of images (Goodfellow et al., 2014; Radford et al., 2015; Chen et al., 2016) where the adversary (discriminator) was introduced so as to match generated samples with observed ones. The broader approach has since been adopted as the training paradigm across a number of other tasks as well, from learning representations for semisupervised learning (Makhzani et al., 2015), and modeling dynamic evolution (Vondrick et al., 2016; Purushotham et al., 2017) to inverse maps for inference (Donahue et al., 2017; Dumoulin et al., 2017), and many others. Substantial work has also gone into improving the stability of adversarial training (Metz et al., 2016; Arjovsky et al., 2017; Arjovsky & Bottou, 2017).\nOn a technical level, our work is most related to adversarial architectures for domain adaptation (Ganin & Lempitsky, 2015; Ganin et al., 2016; Tzeng et al., 2015; 2016). Yet, there are key differences between our approach and the above references, beyond the main application of sleep staging that we introduce. First, our goal is to remove conditional dependencies rather than making the representation domain independent. Thus, unlike the above references which do not involve conditioning in the adversary, our adversary takes the representation but is also conditioned on the predicted label distribution. Second, our game theoretic setup controls the information flow differently, ensuring that only the representation encoder is modified based on the adversary performance. Specifically, the predicted distribution over stages is strategically decoupled from the adversary (conditioning is uni-directional). Third, we show that this new conditioning guarantees an equilibrium solution that fully preserves the ability to predict sleep staging while removing, conditionally, extraneous information specific to the individuals or measurement conditions. Guarantees of this kind are particularly important for healthcare data where the measurements are noisy with a variety of dependencies that need to be controlled.\nFinally, our work is naturally also related to other non-adversarial literature on multi-source domain adaptation (Crammer et al., 2008; Long et al., 2015), and work on\nmetrics for measuring distance between distributions (BenDavid et al., 2010; Fernando et al., 2013)."
  }, {
    "heading": "3. Model",
    "text": "Let x ∈ Ωx be an input sample, and y ∈ {1, 2, ..., ny} an output label. Let s ∈ {1, 2, ..., ns} denote an auxiliary label that refers to the source of a specific input sample. We define x = [x1, x2..., xt] ∈ Ωx as the sequence of input samples from the beginning of time until the current time t.\nIn the context of our application, the above notation translates into the following: The input sample x is a 30-second RF spectrogram, and the output label y is a sleep stage that takes one of four values: Awake, Light Sleep, Deep Sleep, or REM. The vector x refers to the sequence of RF spectrograms from the beginning of the night until the current time. Since RF signals carry information about the subject and the measurement environment, we assign each input x an auxiliary label s which identifies the subjectenvironment pair, hereafter referred to as the source.\nOur goal is to learn a latent representation (i.e., an encoder) that can be used to predict label y; yet, we want this representation to generalize well to predict sleep stages for new subjects without having labeled data from them. Simply making the representation invariant to the source domains could hamper the accuracy of the predictive task. Instead we would like to remove conditional dependencies between the representation and the source domains.\nWe introduce a multi-domain adversarial model that achieves the above goal. Our model is shown in Fig. 1(a). It has three components: An encoder E, a label predictor F , and a source discriminator D. Our model is set up as a game, where the representation encoder plays a cooperative game with the label predictor to allow it to predict the correct labels using the encoded representation. The encoder also plays a minimax game against the source discrimina-\ntor to prevent it from decoding the source label from the encoded representation.\nA key characteristic of our model is the conditioning of the source discriminator on the label distribution, Py(·|x) (see Fig. 1(a)). This conditioning of the adversary allows the learned representation to correlate with the domains, but only via the label distribution –i.e., removes conditional dependencies between the representation and the sources.\nThe rest of this section is organized as follows. We first formally define three players E, F , and D and the representation invariance they are trained to achieve. In Sec. 3.1, we analyze the game and prove that at equilibrium the encoder discards all extraneous information about the source that is not beneficial for label prediction (i.e., predicting y). Training the ideal model in Fig. 1(a) is challenging because it requires access to the label distribution Py(·|x). To drive an efficient training algorithm, we define in Sec. 3.2 an extended game where the source discriminator uses the output of the label predictor as an approximation of the posterior probabilities, as shown in Fig. 1(b). We prove that the equilibriums of the original game are also equilibriums in the extended one.\nEncoder E: An encoder E(·) : Ωx → Ωz is a function that takes a sequence of input samples x, and returns a vector summary of x as z = E(x).\nLabel Predictor F : A label predictor F (·) : Ωz → [0, 1]ny takes a latent representationE(x) as input and predicts the probability of each label y associated with input x as QF (y|E(x)). The goal of an ideal predictor F is to approximate Py(·|x) with QF (·|E(x)). The loss of the label predictor, F , given the encoder E, is defined as the cross-entropy between the label distribution Py(·|x) and QF (·|E(x)):\nLf (F ;E) = Ex,y[− logQF (y|E(x))] (1) During training, the encoder E and predictor F play a cooperative game to minimize the label prediction loss.\nSource Discriminator D: We define a source discriminator as D(·, ·) : Ωz × [0, 1]ny → [0, 1]ns . It takes the latent representation E(x) and the label distribution Py(·|x) as inputs, and predicts which source domain (i.e., subject and environment) they are sampled from as QD(·|E(x), Py(·|x)). Next, we define the desired representation invariance. Definition 1 (Representation invariance). We say that representation E is invariant if E(x) contains no information about s beyond what is already contained in Py(·|x); that is, QD(·|E(x), Py(·|x)) = QD(·|Py(·|x)) for the optimal D.\nTo measure the invariance of an encoder E, we define the\nloss of the source discriminator D as the cross-entropy between Ps(·|x) and QD(·|E(x), Py(·|x)):\nLd(D;E) = Ex,s[− logQD(s|E(x), Py(·|x))] (2)\nDuring training, encoder E and discriminator D play a minimax game: while D is trained to minimize the source prediction loss, encoderE is trained to maximize it in order to achieve the above invariance."
  }, {
    "heading": "3.1. Ideal Game",
    "text": "During training, encoder E plays a co-operative game with predictor F , and a minimax game with discriminator D. We define a value function of E, F and D with λ > 0:\nV(E,F,D) = Lf (F ;E)− λ · Ld(D;E) (3)\nThe training procedure can be viewed as a three-player minimax game of E, F and D:\nmin E min F max D V(E,F,D) = min E,F max D V(E,F,D) (4)\nProposition 2 (Optimal predictor). Given encoder E,\nLf (E) , min F Lf (F ;E) ≥ H(y|E(x)), (5)\nwhere H(·) is entropy. The optimal predictor F ∗ that achieves equality is:\nQF∗(y|E(x)) = p(y|E(x)) (6)\nProof.\nLf (F ;E) =Ex,y[− logQF (y|E(x))] =EE(x),y[− logQF (y|E(x))] =Ez∼P (E(x)) Ey∼P (y|z)[− logQF (y|z)] =Ez∼P (E(x))[H(y|z) +DKL(P (y|z) ‖QF (y|z))] ≥Ez∼P (E(x))[H(y|z)] =H(y|E(x))\nThe equality holds when DKL(P (y|E(x)) ‖QF (y|E(x))) = 0 for almost every x ∈ Supp(Px). That is QF∗(y|E(x)) = p(y|E(x)) for almost every y and x ∈ Supp(Px).\nSimilarly we can prove the following Proposition.\nProposition 3 (Optimal discriminator). Given encoder E,\nLd(E) , min D Ld(D;E) ≥ H(s|E(x), Py(·|x)) (7)\nThe optimal discriminator D∗ that achieves this value is:\nQD∗(s|E(x), Py(·|x)) = P (s|E(x), Py(·|x)) (8)\nCorollary 3.1. H(s) is an upper bound of the loss of the optimal discriminator D∗ for any encoder E.\nNext, we state the virtual training criterion of the encoder.\nProposition 4. If predictor F and discriminator D have enough capacity and are trained to achieve their optimal losses, the minimax game (4) can be rewritten as the following training procedure of encoder E:\nmin E\n[H(y|E(x))− λ ·H(s|E(x), Py(·|x))] (9)\nProof. Based on the losses of the optimal predictor F ∗ and the optimal discriminator D∗ in Proposition 2 and Proposition 3, the minimax game (4) can be rewritten as (9). Thus, encoderE is trained to minimize a virtual training criterion C(E) = H(y|E(x))− λ ·H(s|E(x), Py(·|x)).\nNext, we describe the optimal encoder.\nTheorem 5 (Optimal encoder). If encoder E, predictor F and discriminatorD have enough capacity and are trained to reach optimum, any global optimal encoder E∗ has the following properties:\nH(y|E∗(x)) = H(y|x) (10a) H(s|E∗(x), Py(·|x)) = H(s|Py(·|x)) (10b)\nProof. Since E(x) is a function of x:\nLf (E) = H(y|E(x)) ≥ H(y|x) (11a) Ld(E) = H(s|E(x), Py(·|x)) ≤ H(s|Py(·|x)) (11b)\nHence, C(E) = H(y|E(x)) − λ ·H(s|E(x), Py(·|x)) ≥ H(y|x)−λ ·H(s|Py(·|x)). The equality holds if and only if both (10a) and (10b) are satisfied. Therefore, we only need to prove that the optimal value of C(E) is equal to H(y|x)−λ·H(s|Py(·|x)) in order to prove that any global encoder E∗ satisfies both (10a) and (10b).\nWe show thatC(E) can achieveH(y|x)−λ·H(s|Py(·|x)) by considering the following encoder E0: E0(x) = Py(·|x). It can be examined that H(y|E0(x)) = H(y|x) and H(s|E0(x), Py(·|x)) = H(s|Py(·|x)).\nAdversarial training of D can be viewed as a regularizer, which leads to a common representation space for multiple source domains. From Theorem 5, the optimal encoder E∗ using adversarial training satisfies H(y|E∗(x)) = H(y|x), which is the maximal discriminative capability that any encoder E can achieve. Thus, we have the following corollary.\nCorollary 5.1. Adversarial training of the discriminator does not reduce the discriminative capability of the representation.\nRemark 5.1. During the proof of Theorem 5, we construct an encoder E0(x) = Py(·|x) that can achieve the optimal value of C(E). However, we argue that training will not converge to this trivial encoder in practice. This is because Py(·|x) is a mapping from the full signal history to the distribution over stages at the current step, therefore itself highly complex. Since we use the RNN state as the encodingE(x), and it feeds into the LSTM gates, distribution over stages at previous step does not represent a sufficient summary of the history until the current one. Therefore, E(x) must be able to anticipate the temporal evolution of the signal and contain a more effective summary than Py(·|x) would be. Corollary 5.2. If encoder E and predictor F have enough capacity and are trained to reach optimum, the output of F is equal to Py(·|x).\nProof. When predictor F is optimal (Proposition 2), QF (y|E(x)) = p(y|E(x)). When E is optimal (Theorem 5), H(y|E(x)) = H(y|x), that is p(y|E(x)) = p(y|x). Therefore, QF (y|E(x)) = p(y|x)."
  }, {
    "heading": "3.2. Extended Game",
    "text": "In practice, estimating the posterior label distribution Py(·|x) from labeled data is a non-trivial task. Fortunately however our predictor F and encoderE are playing a cooperative game to approximate this posterior label distribution Py(·|x) withQF (·|E(x)). Therefore, we useQF (·|E(x)), the output of predictor F , as a proxy of Py(·|x) and feed it as input to discriminator D (Fig. 1(b)).\nAn extended three-player game arises: while encoder E still plays a cooperative game with predictor F and a minimax game with discriminator D, discriminator D depends strategically on predictor F but not vice versa. The dotted line in Fig. 1(b) illustrates this dependency.\nThe relationship between the ideal minimax game (Sec. 3.1) and the extended one is stated below.\nProposition 6. If encoder E, predictor F and discriminator D have enough capacity, the solution that encompasses the optimal encoder, E∗, predictor, F ∗ and discriminator, D∗, in the ideal minimax game is also an equilibrium solution of the extended game.\nProof. By Corollary 5.2, when encoder E and predictor F are optimal, QF (·|E(x)) is equal to Py(·|x). Thus, the extended game becomes equivalent to the ideal game, and E∗, F ∗ and D∗ is an equilibrium solution of both games.\nAlgorithm 1 Encoder, predictor and discriminator training Input: Labeled data {(xi, yi, si)}Mi=1, learning rate η. Compute stop criterion for inner loop: δd ← H(s) for number of training iterations do\nSample a mini-batch of training data {(xi, yi, si)}mi=1 Lif ← − logQF (yi|E(xi))\nwi ← QF (·|E(xi)) I stop gradient along this link Lid ← − logQD(si|E(xi),wi)\nVi = Lif − λ · Lid Update encoder E:\nθe ← θe − ηe∇θe 1m ∑m i=1 Vi\nUpdate predictor F : θf ← θf − ηf∇θf 1m ∑m i=1 Vi repeat Update discriminator D:\nθd ← θd + ηd∇θd 1m ∑m i=1 Vi\nuntil 1m ∑m i=1 Lid ≤ δd\nend for"
  }, {
    "heading": "3.3. Training Algorithm",
    "text": "We implement the extended three-player game with iterative updates of the players (Algorithm 1). Note that, since the output of the label predictor is a proxy of the underlying posterior, and since the source discriminator depends strategically on the predictor but not vice versa, the gradient does not back-propagate from the discriminator to the predictor (i.e., the dotted link in Fig. 1(b)).\nThe number of training steps in the inner loop usually needs to be carefully chosen (Goodfellow et al., 2014). A large number of steps is computationally inefficient but a small one will cause the model to collapse. This is because the outer players, E and F , can be over-trained against a nonoptimal inner player D, and they will try to maximize Ld at the cost of increasing Lf . To prevent the model collapse phenomenon, we use an adaptive number of training steps in the inner loop and adjust it dynamically based on Ld (Algorithm 1). The idea is to use the upper bound in Corollary 3.1 as the stopping criterion for the inner loop."
  }, {
    "heading": "3.4. Discussion of the Model Benefits",
    "text": "While we described our model in the context of sleep staging, we believe the model can be applied more broadly. Our model is characterized by the 3-way game and the adversarial conditioning on the label distribution. This combination yields the following benefits: 1) It guarantees an equilibrium solution that fully preserves the ability to perform the predictive task while removing any distracting information specific to the source domains. Guarantees of this kind are particularly important in healthcare where the measurements are noisy and have a variety of dependencies that need to be controlled. 2) It allows to properly leverage the\nadversarial feedback even when the target labels are uncertain. For example, in the sleep staging problem, each 30-second window is given one label. Yet, many such windows include transitions between sleep stages, e.g., a transition from light to deep sleep. These transitions are gradual and hence the transition windows can be intrinsically different from both light and deep sleep. It would be desirable to have the learned representation capture the concept of transition and make it invariant to the source (see the results in Sec. 4.5). 3) It allows the conditioning to remain available for additional guiding of representations based on unlabeled data. The model can incorporate unlabeled data for either semi-supervised learning or transductive learning within a unified framework."
  }, {
    "heading": "4. Experiments",
    "text": "In this section, we empirically evaluate our model."
  }, {
    "heading": "4.1. RF-Sleep Dataset",
    "text": "RF-Sleep is a dataset of RF measurements during sleep with corresponding sleep stage labels. All studies that involve human subjects were approved by our IRB.\nStudy setup: The sleep studies are done in the bedroom of each subject. We install a radio device in the bedroom. It transmits RF signals and measure their reflections while the subject is sleeping alone in the bed.\nGround truth: During the study, each subject sleeps with an FDA-approved EEG-based sleep monitor (Popovic et al., 2014), which collects 3-channel frontal EEG. The monitor labels every 30-second of sleep with the subject’s sleep stage. This system has human-level comparable accuracy (Popovic et al., 2014), and has already been used in several sleep studies(Lucey et al., 2016; Shah et al., 2016).\nSize of dataset: The dataset collects 100 nights of sleep from 25 young healthy subjects (40% females). It contains over 90k 30-second epochs of RF measurements and their corresponding sleep stages provided by the EEG-based sleep monitor. Each epochs has one of four labels Awake, REM, Light Sleep (N1 or N2) and Deep Sleep (N3)."
  }, {
    "heading": "4.2. Parameterization",
    "text": "We parameterize encoder E, predictor F and discriminator D as neural networks. Encoder E is parameterized by a hybrid CNN-RNN model. We adapt a residual networks architecture (He et al., 2016) with 24 convolutional layers to extract features from each 30-second RF spectrogram, and an RNN with LSTM cell (Hochreiter & Schmidhuber, 1997) that takes sequences of CNN features as input. Both predictor F and discriminator D are parameterized by networks with two fully-connected layers."
  }, {
    "heading": "4.3. Classification Results",
    "text": "We evaluate the model on every subject while training on the data collected from the other subjects (i.e., the model is never trained on data from the test subject). The training data is randomly split into a training set and validation set (75%/25%).\nWe use two metrics commonly used in automated sleep staging, namely Accuracy and Cohen’s Kappa. While accuracy measures the percent agreement with ground truth, Cohen’s Kappa coefficient κ (Cohen, 1960) takes into account the possibility of the agreement occurring by chance and is usually a more robust metric. κ > 0.4, κ > 0.6, κ > 0.8 are considered to be moderate, substantial and almost perfect agreement (Landis & Koch, 1977).\nTable 2 shows the accuracy and Cohen’s Kappa of our model compared to the state-of-the-art in classifying sleep stages using RF reflections. Since neither the dataset nor the code used in past papers is publicly available, we compare with their published results. We note however that the Cohen’s Kappa provides some normalization since it accounts for the underlying uncertainty in the data. The table shows that our model has an accuracy of 79.8% and a κ = 0.70, which significantly outperforms past solutions.\nFig. 2(a) shows the confusion matrix of our model. Fig. 2(b) also shows the accuracy on each subject. It has a standard deviation of 2.9%, suggesting that our model is capable of adapting to different subjects and environments.\nFinally, we show in Fig. 3 the full-night predictions along with the ground truth for the average, best, and worst classification accuracy."
  }, {
    "heading": "4.4. Understanding the Role of CNN & RNN",
    "text": "We analyze the role of CNN and RNN in predicting sleep stages. To do so, we use t-SNE embedding (Maaten & Hinton, 2008) to visualize the response of our network after CNN and RNN, respectively. Fig. 4 shows the visualization results from one of the subjects. Data points are randomly sub-sampled for better viewing. The result shows that the CNN succeeds at separating the Wake, REM from Light and Deep Sleep. However it fails at separate Light Sleep and Deep Sleep from each other. In contrast, Light Sleep and Deep Sleep form different clusters in the RNN response. These results demonstrate the role of CNN and RNN in our model: CNN learns stage-specific features that can distinguish Wake, REM and from Deep and Light Sleep. RNN captures the dynamics of those features to fur-\nther determine whether the sleep is light or deep. Note that Light and Deep Sleep are more similar to each other and are typically referred to as NREM, i.e., non-REM.\nWe have trained a similar model without the RNN layer on top of CNN. In this case, the overall accuracy decreases by 12.8%, specifically the precision light and deep sleep decreases by 23.5%. This suggests that there are stagespecific information embedded in the temporal dynamics of the RF measurements, and therefore can only be captured and exploited with RNN. Moreover, these temporal dynamics are particularly crucial for distinguishing light and deep sleep. Indeed, there are known temporal patterns that govern the progression of light and deep sleep through the night (Carskadon et al., 2005). For example, the probability of being in deep sleep decreases as sleep progresses. Also, people usually need to go through light sleep before they can get into deep sleep. These temporal dynamics of sleep stages can be captured by RNN and might be exploited to distinguish light and deep sleep."
  }, {
    "heading": "4.5. Role of Our Adversarial Discriminator",
    "text": "We evaluate the role of our adversarial discriminator in learning transferable features for predicting sleep stages. We first look at the losses on the validation set as training progresses to check whether the extraneous information specific to the individuals and environments can be removed. As a baseline, we compare with a version of our model without the source discriminator. For this baseline,\nwe train a (non-adversarial) discriminator to determine the source of features. Fig. 5 shows that the loss of the source discriminator in the baseline model decreases very quickly while ours stays high (upper bounded by H(s) = 2.81 in this case), suggesting that our learned representation is invariant across sources. The figure also shows that adding an adversarial discriminator increases the performance on the test set and can be helpful in reducing over-fitting.\nTo check that our adversarial model has learned transferable features, we visualize the learned featuresE(x) on the test data for both models. Color-coding the sources, Fig. 6 shows that our learned features have almost the same distribution on different sources, while the baseline model learns features that are separable.\nNext, we illustrate the benefits of conditioning on the posterior distribution, and that it can recover underlying concepts not specified in the labels. We consider the learned features for transition periods between light and deep sleep, which might be a class that is different from both light and deep sleep. We define transition periods as epochs that have both light and deep sleep as neighbors. We visualize it with a different color. Color-coding stages and shape-coding sources, Fig. 7 shows the learned features from transition periods are segregated, as those from light sleep and deep sleep. This indicates that our learned features have recovered the concept of a transition period, which is helpful in understanding and predicting sleep stages."
  }, {
    "heading": "5. Conclusion",
    "text": "This paper introduce a new predictive model that learns sleep stages from RF signals and achieves a significant improvement over the state-of-the-art. We believe this work marks an important step in sleep monitoring. We also believe that the proposed adversarial setup, which extracts task-specific domain-invariant features, is applicable to other predictive tasks, particularly in health sensing where variations across subjects and measurement conditions could be a major challenge."
  }, {
    "heading": "Acknowledgments",
    "text": "The authors thank the anonymous reviewers for their helpful comments in revising the paper. We are grateful to the members of the CSAIL for their insightful discussions and to all the human subjects for their participation in our experiments."
  }],
  "year": 2017,
  "references": [{
    "title": "Smart homes that monitor breathing and heart",
    "authors": ["Adib", "Fadel", "Mao", "Hongzi", "Kabelac", "Zachary", "Katabi", "Dina", "Miller", "Robert C"],
    "venue": "rate. ACM CHI,",
    "year": 2015
  }, {
    "title": "Towards principled methods for training generative adversarial networks",
    "authors": ["Arjovsky", "Martin", "Bottou", "Léon"],
    "year": 2017
  }, {
    "title": "Wasserstein generative adversarial networks",
    "authors": ["Arjovsky", "Martin", "Chintala", "Soumith", "Bottou", "Léon"],
    "year": 2017
  }, {
    "title": "A theory of learning from different domains",
    "authors": ["Ben-David", "Shai", "Blitzer", "John", "Crammer", "Koby", "Kulesza", "Alex", "Pereira", "Fernando", "Vaughan", "Jennifer Wortman"],
    "venue": "Machine learning,",
    "year": 2010
  }, {
    "title": "Monitoring and staging human sleep",
    "authors": ["Carskadon", "Mary A", "Rechtschaffen", "Allan"],
    "venue": "Principles and practice of sleep medicine,",
    "year": 2000
  }, {
    "title": "Normal human sleep: an overview",
    "authors": ["Carskadon", "Mary A", "Dement", "William C"],
    "venue": "Principles and practice of sleep medicine,",
    "year": 2005
  }, {
    "title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
    "authors": ["Chen", "Xi", "Duan", "Yan", "Houthooft", "Rein", "Schulman", "John", "Sutskever", "Ilya", "Abbeel", "Pieter"],
    "year": 2016
  }, {
    "title": "A coefficient of agreement for nominal scales",
    "authors": ["Cohen", "Jacob"],
    "venue": "Educational and psychological measurement,",
    "year": 1960
  }, {
    "title": "Learning from multiple sources",
    "authors": ["Crammer", "Koby", "Kearns", "Michael", "Wortman", "Jennifer"],
    "year": 2008
  }, {
    "title": "Single-channel eeg sleep stage classification based on a streamlined set of statistical features in wavelet domain",
    "authors": ["da Silveira", "Thiago LT", "Kozakevicius", "Alice J", "Rodrigues", "Cesar R"],
    "venue": "Medical & biological engineering & computing,",
    "year": 2016
  }, {
    "title": "Adversarial feature learning",
    "authors": ["Donahue", "Jeff", "Krähenbühl", "Philipp", "Darrell", "Trevor"],
    "year": 2017
  }, {
    "title": "Automatic sleep stage classification based on eeg signals by using neural networks and wavelet packet coefficients",
    "authors": ["Ebrahimi", "Farideh", "Mikaeili", "Mohammad", "Estrada", "Edson", "Nazeran", "Homer"],
    "venue": "IEEE EMBC,",
    "year": 2008
  }, {
    "title": "Unsupervised visual domain adaptation using subspace alignment",
    "authors": ["Fernando", "Basura", "Habrard", "Amaury", "Sebban", "Marc", "Tuytelaars", "Tinne"],
    "year": 2013
  }, {
    "title": "Unsupervised domain adaptation by backpropagation",
    "authors": ["Ganin", "Yaroslav", "Lempitsky", "Victor"],
    "year": 2015
  }, {
    "title": "Domainadversarial training of neural networks",
    "authors": ["Ganin", "Yaroslav", "Ustinova", "Evgeniya", "Ajakan", "Hana", "Germain", "Pascal", "Larochelle", "Hugo", "Laviolette", "François", "Marchand", "Mario", "Lempitsky", "Victor"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Generative adversarial nets",
    "authors": ["Goodfellow", "Ian", "Pouget-Abadie", "Jean", "Mirza", "Mehdi", "Xu", "Bing", "Warde-Farley", "David", "Ozair", "Sherjil", "Courville", "Aaron", "Bengio", "Yoshua"],
    "year": 2014
  }, {
    "title": "Intelligent sleep stage mining service with smartphones",
    "authors": ["Gu", "Weixi", "Yang", "Zheng", "Shangguan", "Longfei", "Sun", "Wei", "Jin", "Kun", "Liu", "Yunhao"],
    "venue": "ACM UbiComp,",
    "year": 2014
  }, {
    "title": "isleep: unobtrusive sleep quality monitoring using smartphones",
    "authors": ["Hao", "Tian", "Xing", "Guoliang", "Zhou", "Gang"],
    "venue": "ACM SenSys,",
    "year": 2013
  }, {
    "title": "Deep residual learning for image recognition",
    "authors": ["He", "Kaiming", "Zhang", "Xiangyu", "Ren", "Shaoqing", "Sun", "Jian"],
    "year": 2016
  }, {
    "title": "Adaptation effects to sleep studies in participants with and without chronic posttraumatic stress disorder",
    "authors": ["Herbst", "Ellen"],
    "year": 2010
  }, {
    "title": "Long shortterm memory",
    "authors": ["Hochreiter", "Sepp", "Schmidhuber", "Jürgen"],
    "venue": "Neural computation,",
    "year": 1997
  }, {
    "title": "Non-invasive respiration rate monitoring using a single cots tx-rx",
    "authors": ["Kaltiokallio", "Ossi", "Yigitler", "Huseyin", "Jantti", "Riku", "Patwari", "Neal"],
    "venue": "pair. IPSN,",
    "year": 2014
  }, {
    "title": "The measurement of observer agreement for categorical data",
    "authors": ["Landis", "J Richard", "Koch", "Gary G"],
    "year": 1977
  }, {
    "title": "Wi-sleep: Contactless sleep monitoring via wifi signals",
    "authors": ["Liu", "Xuefeng", "Cao", "Jiannong", "Tang", "Shaojie", "Wen", "Jiaqi"],
    "year": 2014
  }, {
    "title": "Learning transferable features with deep adaptation",
    "authors": ["Long", "Mingsheng", "Cao", "Yue", "Wang", "Jianmin", "Jordan", "Michael I"],
    "year": 2015
  }, {
    "title": "Measuring dissimilarity between respiratory effort signals based on uniform scaling for sleep staging",
    "authors": ["Long", "Xi", "Yang", "Jie", "Weysen", "Tim", "Haakma", "Reinder", "Foussier", "Jérôme", "Fonseca", "Pedro", "Aarts", "Ronald M"],
    "venue": "Physiological measurement,",
    "year": 2014
  }, {
    "title": "Comparison of a single-channel eeg sleep study to polysomnography",
    "authors": ["Lucey", "Brendan P", "Mcleland", "Jennifer S", "Toedebusch", "Cristina D", "Boyd", "Jill", "Morris", "John C", "Landsness", "Eric C", "Yamada", "Kelvin", "Holtzman", "David M"],
    "venue": "Journal of sleep research,",
    "year": 2016
  }, {
    "title": "Visualizing data using t-sne",
    "authors": ["Maaten", "Laurens van der", "Hinton", "Geoffrey"],
    "year": 2008
  }, {
    "title": "Unrolled generative adversarial networks",
    "authors": ["Metz", "Luke", "Poole", "Ben", "Pfau", "David", "Sohl-Dickstein", "Jascha"],
    "venue": "arXiv preprint arXiv:1611.02163,",
    "year": 2016
  }, {
    "title": "Beyond temporal pooling: Recurrence and temporal convolutions for gesture recognition",
    "authors": ["Pigou", "Lionel", "Van Den Oord", "Aäron", "Dieleman", "Sander", "Van Herreweghe", "Mieke", "Dambre", "Joni"],
    "venue": "in video. IJCV,",
    "year": 2015
  }, {
    "title": "How accurately does wrist actigraphy identify the states of sleep and wakefulness? SLEEP-NEW YORK",
    "authors": ["Pollak", "Charles P", "Tryon", "Warren W", "Nagaraja", "Haikady", "Dzwonczyk", "Roger"],
    "year": 2001
  }, {
    "title": "Automatic scoring of sleep stages and cortical arousals using two electrodes on the forehead: validation in healthy adults",
    "authors": ["Popovic", "Djordje", "Khoo", "Michael", "Westbrook", "Philip"],
    "venue": "Journal of sleep research,",
    "year": 2014
  }, {
    "title": "Variational recurrent adversarial deep domain adaptation",
    "authors": ["Purushotham", "Sanjay", "Carvalho", "Wilka", "Nilanon", "Tanachat", "Liu", "Yan"],
    "year": 2017
  }, {
    "title": "Unsupervised representation learning with deep convolutional generative adversarial networks",
    "authors": ["Radford", "Alec", "Metz", "Luke", "Chintala", "Soumith"],
    "venue": "arXiv preprint arXiv:1511.06434,",
    "year": 2015
  }, {
    "title": "Dopplesleep: A contactless unobtrusive sleep sensing system using shortrange doppler radar",
    "authors": ["Rahman", "Tauhidur", "Adams", "Alexander T", "Ravichandran", "Ruth Vinisha", "Zhang", "Mi", "Patel", "Shwetak N", "Kientz", "Julie A", "Choudhury", "Tanzeem"],
    "venue": "ACM UbiComp,",
    "year": 2015
  }, {
    "title": "A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects",
    "authors": ["Rechtschaffen", "Allan", "Kales", "Anthony"],
    "venue": "US Government Printing Office, US Public Health Service,",
    "year": 1968
  }, {
    "title": "Validation of an automated wireless system to monitor sleep in healthy adults",
    "authors": ["Shambroom", "John R", "Fábregas", "Stephan E", "Johnstone", "Jack"],
    "venue": "Journal of sleep research,",
    "year": 2012
  }, {
    "title": "Sequence to sequence learning with neural networks",
    "authors": ["Sutskever", "Ilya", "Vinyals", "Oriol", "Le", "Quoc V"],
    "year": 2014
  }, {
    "title": "Sleep architecture measurement based on cardiorespiratory parameters",
    "authors": ["Tataraidze", "Alexander", "Korostovtseva", "Lyudmila", "Anishchenko", "Lesya", "Bochkarev", "Mikhail", "Sviryaev", "Yurii"],
    "venue": "IEEE EMBC,",
    "year": 2016
  }, {
    "title": "Bioradiolocation-based sleep stage classification",
    "authors": ["Tataraidze", "Alexander", "Korostovtseva", "Lyudmila", "Anishchenko", "Lesya", "Bochkarev", "Mikhail", "Sviryaev", "Yurii", "Ivashov", "Sergey"],
    "venue": "IEEE EMBC,",
    "year": 2016
  }, {
    "title": "Simultaneous deep transfer across domains and tasks",
    "authors": ["Tzeng", "Eric", "Hoffman", "Judy", "Darrell", "Trevor", "Saenko", "Kate"],
    "year": 2015
  }, {
    "title": "Adversarial discriminative domain adaptation",
    "authors": ["Tzeng", "Eric", "Hoffman", "Judy", "Saenko", "Kate", "Darrell", "Trevor"],
    "venue": "NIPS Workshop on Adversarial Training,",
    "year": 2016
  }, {
    "title": "Generating videos with scene dynamics",
    "authors": ["Vondrick", "Carl", "Pirsiavash", "Hamed", "Torralba", "Antonio"],
    "year": 2016
  }, {
    "title": "Automated sleep staging classification using a non-contact biomotion sensor",
    "authors": ["A Zaffaroni", "L Gahan", "L Collins", "E O’hare", "C Heneghan", "C Garcia", "I Fietze", "T. Penzel"],
    "venue": "Journal of Sleep Research,",
    "year": 2014
  }, {
    "title": "Emotion recognition using wireless signals",
    "authors": ["Zhao", "Mingmin", "Adib", "Fadel", "Katabi", "Dina"],
    "venue": "ACM MobiCom,",
    "year": 2016
  }],
  "id": "SP:54bd458d0076bdacd86695fd28ba334caf581ccc",
  "authors": [{
    "name": "Mingmin Zhao",
    "affiliations": []
  }, {
    "name": "Shichao Yue",
    "affiliations": []
  }, {
    "name": "Dina Katabi",
    "affiliations": []
  }, {
    "name": "Tommi S. Jaakkola",
    "affiliations": []
  }, {
    "name": "Matt T. Bianchi",
    "affiliations": []
  }],
  "abstractText": "We focus on predicting sleep stages from radio measurements without any attached sensors on subjects. We introduce a new predictive model that combines convolutional and recurrent neural networks to extract sleep-specific subjectinvariant features from RF signals and capture the temporal progression of sleep. A key innovation underlying our approach is a modified adversarial training regime that discards extraneous information specific to individuals or measurement conditions, while retaining all information relevant to the predictive task. We analyze our game theoretic setup and empirically demonstrate that our model achieves significant improvements over state-of-the-art solutions.",
  "title": "Learning Sleep Stages from Radio Signals: A Conditional Adversarial Architecture"
}