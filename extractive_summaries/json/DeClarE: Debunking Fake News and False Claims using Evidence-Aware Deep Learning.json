{
  "sections": [{
    "text": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 22–32 Brussels, Belgium, October 31 - November 4, 2018. c©2018 Association for Computational Linguistics\n22"
  }, {
    "heading": "1 Introduction",
    "text": "Motivation: Modern media (e.g., news feeds, microblogs, etc.) exhibit an increasing fraction of misleading and manipulative content, from questionable claims and “alternative facts” to completely faked news. The media landscape is becoming a twilight zone and battleground. This societal challenge has led to the rise of fact-checking and debunking websites, such as Snopes.com and PolitiFact.com, where people research claims, manually assess their credibility, and present their verdict along with evidence (e.g., background articles, quotations, etc.). However, this manual verification is time-consuming. To keep up with the scale and speed at which misinformation spreads, we need tools to automate this debunking process.\nState of the Art and Limitations: Prior work on “truth discovery” (see Li et al. (2016) for survey)1 largely focused on structured facts, typically in the form of subject-predicate-object triples, or on social media platforms like Twitter, Sina Weibo, etc. Recently, methods have been proposed to assess the credibility of claims in natural language form (Popat et al., 2017; Rashkin et al., 2017; Wang, 2017), such as news headlines, quotes from speeches, blog posts, etc.\nThe methods geared for general text input address the problem in different ways. On the one hand, methods like Rashkin et al. (2017); Wang (2017) train neural networks on labeled claims from sites like PolitiFact.com, providing credibility assessments without any explicit feature modeling. However, they use only the text of questionable claims and no external evidence or interactions that provide limited context for credibility analysis. These approaches also do not offer any explanation of their verdicts. On the other hand, Popat et al. (2017) considers external evidence in the form of other articles (retrieved from the Web) that confirm or refute a claim, and jointly assesses the language style (using subjectivity lexicons), the trustworthiness of the sources, and the credibility of the claim. This is achieved via a pipeline of supervised classifiers. On the upside, this method generates user-interpretable explanations by pointing to informative snippets of evidence articles. On the downside, it requires substantial feature modeling and rich lexicons to detect bias and subjectivity in the language style. Approach and Contribution: To overcome the limitations of the prior works, we present DeClarE2, an end-to-end neural network model for assessing and explaining the credibility of arbi-\n1As fully objective and unarguable truth is often elusive or ill-defined, we use the term credibility rather than “truth”.\n2Debunking Claims with Interpretable Evidence\ntrary claims in natural-language text form. Our approach combines the best of both families of prior methods. Similar to Popat et al. (2017), DeClarE incorporates external evidence or counterevidence from the Web as well as signals from the language style and the trustworthiness of the underlying sources. However, our method does not require any feature engineering, lexicons, or other manual intervention. Rashkin et al. (2017); Wang (2017) also develop an end-to-end model, but DeClarE goes far beyond in terms of considering external evidence and joint interactions between several factors, and also in its ability to generate userinterpretable explanations in addition to highly accurate assessments. For example, given the natural-language input claim “the gun epidemic is the leading cause of death of young AfricanAmerican men, more than the next nine causes put together” by Hillary Clinton, DeClarE draws on evidence from the Web to arrive at its verdict credible, and returns annotated snippets like the one in Table 6 as explanation. These snippets, which contain evidence in the form of statistics and assertions, are automatically extracted from web articles from sources of varying credibility.\nGiven an input claim, DeClarE searches for web articles related to the claim. It considers the context of the claim via word embeddings and the (language of) web articles captured via a bidirectional LSTM (biLSTM), while using an attention mechanism to focus on parts of the articles according to their relevance to the claim. DeClarE then aggregates all the information about claim source, web article contexts, attention weights, and trustworthiness of the underlying sources to assess the claim. It also derives informative features for interpretability, like source embeddings that capture trustworthiness and salient words captured via attention. Key contributions of this paper are:\n• Model: An end-to-end neural network model which automatically assesses the credibility of natural-language claims, without any handcrafted features or lexicons.\n• Interpretability: An attention mechanism in our model that generates user-comprehensible explanations, making credibility verdicts transparent and interpretable.\n• Experiments: Extensive experiments on four datasets and ablation studies, demonstrating effectiveness of our method over state-of-theart baselines."
  }, {
    "heading": "2 End-to-end Framework for Credibility Analysis",
    "text": "Consider a set of N claims 〈Cn〉 from the respective origins/sources 〈CSn〉, where n ∈ [1, N ]. Each claim Cn is reported by a set of M articles 〈Am,n〉 along with their respective sources 〈ASm,n〉, where m ∈ [1,M ]. Each corresponding tuple of claim and its origin, reporting articles and article sources – 〈Cn, CSn, Am,n, ASm,n〉 forms a training instance in our setting, along with the credibility label of the claim used as ground-truth during network training. Figure 1 gives a pictorial overview of our model. In the following sections, we provide a detailed description of our approach."
  }, {
    "heading": "2.1 Input Representations",
    "text": "The input claim Cn of length l is represented as [c1, c2, ..., cl] where cl ∈ <d is the d-dimensional word embedding of the l-th word in the input claim. The source/origin of the claim CSn is represented by a ds-dimensional embedding vector csn ∈ <ds .\nA reporting article Am,n consisting of k tokens is represented by [am,n,1, am,n,2, ..., am,n,k], where am,n,k ∈ <d is the d-dimensional word embedding vector for the k-th word in the reporting article Am,n. The claim and article word embeddings have shared parameters. The source of the reporting article ASm,n is represented as a dsdimensional vector, asm,n ∈ <ds . For the sake of brevity, we drop the notation subscripts n and m in the following sections by considering only a single training instance – the input claim Cn from source CSn, the corresponding article Am,n and its sources ASm,n given by: 〈C,CS,A,AS〉."
  }, {
    "heading": "2.2 Article Representation",
    "text": "To create a representation of an article, which may capture task-specific features such as whether it contains objective language, we use a bidirectional Long Short-Term Memory (LSTM) network as proposed by Graves et al. (2005). A basic LSTM cell consists of various gates to control the flow of information through timesteps in a sequence, making LSTMs suitable for capturing long and short range dependencies in text that may be difficult to capture with standard recurrent neural networks (RNNs). Given an input word embedding of tokens 〈ak〉, an LSTM cell performs various nonlinear transformations to generate a hidden vector state hk for each token at each timestep k.\nWe use bidirectional LSTMs in place of standard LSTMs. Bidirectional LSTMs capture both the previous timesteps (past features) and the future timesteps (future features) via forward and backward states respectively. Correspondingly, there are two hidden states that capture past and future information that are concatenated to form the final output as: hk = [ −→ hk, ←− hk]."
  }, {
    "heading": "2.3 Claim Specific Attention",
    "text": "As we previously discussed, it is important to consider the relevance of an article with respect to the claim; specifically, focusing or attending to parts of the article that discuss the claim. This is in contrast to prior works (Popat et al., 2017; Rashkin et al., 2017; Wang, 2017) that ignore either the article or the claim, and therefore miss out on this important interaction.\nWe propose an attention mechanism to help our model focus on salient words in the article with respect to the claim. To this end, we compute the importance of each term in an article with respect to an overall representation of the corresponding claim. Additionally, incorporating attention helps in making our model transparent and interpretable, because it provides a way to generate the most salient words in an article as evidence of our model’s verdict.\nFollowing Wieting et al. (2015), the overall representation of an input claim is generated by taking an average of the word embeddings of all the\nwords therein:\nc̄ = 1\nl ∑ l cl\nWe combine this overall representation of the claim with each article term:\nâk = ak ⊕ c̄\nwhere, âk ∈ <d+d and ⊕ denotes the concatenate operation. We then perform a transformation to obtain claim-specific representations of each article term:\na′k = f(Waâk + ba)\nwhere Wa and ba are the corresponding weight matrix and bias terms, and f is an activation function3, such as ReLU , tanh, or the identity function. Following this, we use a softmax activation to calculate an attention score αk for each word in the article capturing its relevance to the claim context:\nαk = exp(a′k)∑ k exp(a ′ k)\n(1)"
  }, {
    "heading": "2.4 Per-Article Credibility Score of Claim",
    "text": "Now that we have article term representations given by 〈hk〉 and their relevance to the claim given by 〈αk〉, we need to combine them to predict the claim’s credibility. In order to create an\n3In our model, the tanh activation function gives best results.\nattention-focused representation of the article considering both the claim and the article’s language, we calculate a weighted average of the hidden state representations for all article tokens based on their corresponding attention scores:\ng = 1\nk ∑ k αk · hk (2)\nWe then combine all the different feature representations: the claim source embedding (cs), the attention-focused article representation (g), and the article source embedding (as). In order to merge the different representations and capture their joint interactions, we process them with two fully connected layers with non-linear activations.\nd1 = relu(Wc(g ⊕ cs⊕ as) + bc) d2 = relu(Wdd1 + bd)\nwhere, W and b are the corresponding weight matrix and bias terms.\nFinally, to generate the overall credibility label of the article for classification tasks, or credibility score for regression tasks, we process the final representation with a final fully connected layer:\nClassification: s = sigmoid(d2) (3)\nRegression: s = linear(d2) (4)"
  }, {
    "heading": "2.5 Credibility Aggregation",
    "text": "The credibility score in the above step is obtained considering a single reporting article. As previously discussed, we have M reporting articles per claim. Therefore, once we have the per-article credibility scores from our model, we take an average of these scores to generate the overall credibility score for the claim:\ncred(C) = 1\nM ∑ m sm (5)\nThis aggregation is done after the model is trained."
  }, {
    "heading": "3 Datasets",
    "text": "We evaluate our approach and demonstrate its generality by performing experiments on four different datasets: a general fact-checking website, a political fact-checking website, a news review community, and a SemEval Twitter rumour dataset."
  }, {
    "heading": "3.1 Snopes",
    "text": "Snopes (www.snopes.com) is a general factchecking website where editors manually investigate various kinds of rumors reported on the Internet. We used the Snopes dataset provided by Popat et al. (2017). This dataset consists of rumors analyzed on the Snopes website along with their credibility labels (true or false), sets of reporting articles, and their respective web sources."
  }, {
    "heading": "3.2 PolitiFact",
    "text": "PolitiFact is a political fact-checking website (www.politifact.com) in which editors rate the credibility of claims made by various political figures in US politics. We extract all articles from PolitiFact published before December 2017. Each article includes a claim, the speaker (political figure) who made the claim, and the claim’s credibility rating provided by the editors.\nPolitiFact assigns each claim to one of six possible ratings: true, mostly true, half true, mostly false, false and pants-on-fire. Following Rashkin et al. (2017), we combine true, mostly true and half true ratings into the class label true and the rest as false – hence considering only binary credibility labels. To retrieve the reporting articles for each claim (similar to Popat et al. (2017)), we issue each claim as a query to a search engine4 and retrieve the top 30 search results with their respective web sources."
  }, {
    "heading": "3.3 NewsTrust",
    "text": "NewsTrust is a news review community in which members review the credibility of news articles. We use the NewsTrust dataset made available by Mukherjee and Weikum (2015). This dataset contains NewsTrust stories from May 2006 to May 2014. Each story consists of a news article along with its source, and a set of reviews and ratings by community members. NewsTrust aggregates these ratings and assigns an overall credibility score (on a scale of 1 to 5) to the posted article. We map the attributes in this data to the inputs expected by DeClarE as follows: the title and the web source of the posted (news) article are mapped to the input claim and claim source, respectively. Reviews and their corresponding user identities are mapped to reporting articles and article sources, respectively. We use this dataset for the regression task of predicting the credibility score of the posted article.\n4We use the Bing search API."
  }, {
    "heading": "3.4 SemEval-2017 Task 8",
    "text": "As the fourth dataset, we consider the benchmark dataset released by SemEval-2017 for the task of determining credibility and stance of social media content (Twitter) (Derczynski et al., 2017). The objective of this task is to predict the credibility of a questionable tweet (true, false or unverified) along with a confidence score from the model. It has two sub-tasks: (i) a closed variant in which models only consider the questionable tweet, and (ii) an open variant in which models consider both the questionable tweet and additional context consisting of snapshots of relevant sources retrieved immediately before the rumor was reported, a snapshot of an associated Wikipedia article, news articles from digital news outlets, and preceding tweets about the same event. Testing and development datasets provided by organizers have 28 tweets (1021 reply tweets) and 25 tweets (256 reply tweets), respectively."
  }, {
    "heading": "3.5 Data Processing",
    "text": "In order to have a minimum support for training, claim sources with less than 5 claims in the dataset are grouped into a single dummy claim source, and article sources with less than 10 articles are grouped similarly (5 articles for SemEval as it is a smaller dataset).\nFor Snopes and PolitiFact, we need to extract relevant snippets from the reporting articles for a claim. Therefore, we extract snippets of 100 words from each reporting article having the maximum relevance score: sim = simbow×simsemantic where simbow is the fraction of claim words that are present in the snippet, and simsemantic represents the cosine similarity between the average of claim word embeddings and snippet word embeddings. We also enforce a constraint that the sim score is at least δ. We varied δ from 0.2 to 0.8 and found 0.5 to give the optimal perfor-\nmance on a withheld dataset. We discard all articles related to Snopes and PolitiFact websites from our datasets to have an unbiased model. Statistics of the datasets after pre-processing is provided in Table 1. All the datasets are made publicly available at https://www.mpi-inf. mpg.de/dl-cred-analysis/."
  }, {
    "heading": "4 Experiments",
    "text": "We evaluate our approach by conducting experiments on four datasets, as described in the previous section. We describe our experimental setup and report our results in the following sections."
  }, {
    "heading": "4.1 Experimental Setup",
    "text": "When using the Snopes, PolitiFact and NewsTrust datasets, we reserve 10% of the data as validation data for parameter tuning. We report 10-fold cross validation results on the remaining 90% of the data; the model is trained on 9-folds and the remaining fold is used as test data. When using the SemEval dataset, we use the data splits provided by the task’s organizers. The objective for Snopes, PolitiFact and SemEval experiments is binary (credibility) classification, while for NewsTrust the objective is to predict the credibility score of the input claim on a scale of 1 to 5 (i.e., credibility regression). We represent terms using pre-trained GloVe Wikipedia 6B word embeddings (Pennington et al., 2014). Since our training datasets are not very large, we do not tune the word embeddings during training. The remaining model parameters are tuned on the validation data; the parameters chosen are reported in Table 2. We use Keras with a Tensorflow backend to implement our system. All the models are trained using Adam optimizer (Kingma and Ba, 2014) (learning rate: 0.002) with categorical cross-entropy loss for classification and mean squared error loss for regression task. We use L2-regularizers with the\nfully connected layers as well as dropout. For all the datasets, the model is trained using each claimarticle pair as a separate training instance.\nTo evaluate and compare the performance of DeClarE with other state-of-the-art methods, we report the following measures:\n• Credibility Classification (Snopes, PolitiFact and SemEval): accuracy of the models in classifying true and false claims separately, macro F1-score and Area-Under-Curve (AUC) for the ROC (Receiver Operating Characteristic) curve.\n• Credibility Regression (NewsTrust): Mean Square Error (MSE) between the predicted and true credibility scores."
  }, {
    "heading": "4.2 Results: Snopes and Politifact",
    "text": "We compare our approach with the following state-of-the-art models: (i) LSTM-text, a recent approach proposed by Rashkin et al. (2017). (ii) CNN-text: a CNN based approach proposed by Wang (2017). (iii) Distant Supervision: stateof-the-art distant supervision based approach proposed by Popat et al. (2017). (iv) DeClare (Plain): our approach with only biLSTM (no attention and source embeddings). (v) DeClarE (Plain+Attn): our approach with only biLSTM and attention (no source embeddings). (vi) DeClarE (Plain+SrEmb): our approach with only biLSTM and source embeddings (no attention). (vii) DeClarE (Full): end-to-end system with biLSTM, attention and source embeddings.\nThe results when performing credibility classification on the Snopes and PolitiFact datasets are\nshown in Table 3. DeClarE outperforms LSTMtext and CNN-text models by a large margin on both datasets. On the other hand, for the Snopes dataset, performance of DeClarE (Full) is slightly lower than the Distant Supervision configuration (p-value of 0.04 with a pairwise t-test). However, the advantage of DeClarE over Distant Supervision approach is that it does not rely on hand crafted features and lexicons, and can generalize well to arbitrary domains without requiring any seed vocabulary. It is also to be noted that both of these approaches use external evidence in the form of reporting articles discussing the claim, which are not available to the LSTM-text and CNN-text baselines. This demonstrates the value of external evidence for credibility assessment.\nOn the PolitiFact dataset, DeClarE outperforms all the baseline models by a margin of 7-9% AUC (p-value of 9.12e−05 with a pairwise t-test) with similar improvements in terms of Macro F1. A performance comparison of DeClarE’s various configurations indicates the contribution of each component of our model, i.e, biLSTM capturing article representations, attention mechanism and source embeddings. The additions of both the attention mechanism and source embeddings improve performance over the plain configuration in all cases when measured by Macro F1 or AUC."
  }, {
    "heading": "4.3 Results: NewsTrust",
    "text": "When performing credibility regression on the NewsTrust dataset, we evaluate the models in terms of mean squared error (MSE; lower is better) for credibility rating prediction. We use the\nfirst three models described in Section 4.2 as baselines. For CNN-text and LSTM-text, we add a linear fully connected layer as the final layer of the model to support regression. Additionally, we also consider the state-of-the-art CCRF+SVR model based on Continuous Conditional Random Field (CCRF) and Support Vector Regression (SVR) proposed by Mukherjee and Weikum (2015). The results are shown in Table 4. We observe that DeClarE (Full) outperforms all four baselines, with a 17% decrease in MSE compared to the bestperforming baselines (i.e., LSTM-text and Distant Supervision). The DeClarE (Plain) model performs substantially worse than the full model, illustrating the value of including attention and source embeddings. CNN-text performs substantially worse than the other baselines."
  }, {
    "heading": "4.4 Results: SemEval",
    "text": "On the SemEval dataset, the objective is to perform credibility classification of a tweet while also producing a classification confidence score. We compare the following approaches and consider both variants of the SemEval task: (i) NileTMRG (Enayet and El-Beltagy, 2017): the best performing approach for the close variant of the task, (ii) IITP (Singh et al., 2017): the best performing approach for the open variant of the task, (iii) DeClare (Plain): our approach with only biLSTM (no attention and source embeddings), and (iv) DeClarE (Full): our end-to-end system with biLSTM, attention and source embeddings.\nWe use the evaluation measure proposed by the task’s organizers: macro F1-score for overall classification and Root-Mean-Square Error (RMSE) over confidence scores. Results are shown in Table 5. We observe that DeClarE (Full) outperforms all the other approaches — thereby, re-affirming its power in harnessing external evidence."
  }, {
    "heading": "5 Discussion",
    "text": ""
  }, {
    "heading": "5.1 Analyzing Article Representations",
    "text": "In order to assess how our model separates articles reporting false claims from those reporting true ones, we employ dimensionality reduction using Principal Component Analysis (PCA) to project the article representations (g in Equation 2) from a high dimensional space to a 2d plane. The projections are shown in Figure 2a. We observe that DeClarE obtains clear separability between credible versus non-credible articles in Snopes dataset."
  }, {
    "heading": "5.2 Analyzing Source Embeddings",
    "text": "Similar to the treatment of article representations, we perform an analysis with the claim and article source embeddings by employing PCA and plotting the projections. We sample a few popular news sources from Snopes and claim sources from PolitiFact. These news sources and claim sources are displayed in Figure 2b and Figure 2c, respectively. From Figure 2b we observe that DeClarE clearly separates fake news sources like nationalreport, empirenews, huzlers, etc. from mainstream news sources like nytimes, cnn, wsj, foxnews, washingtonpost, etc. Similarly, from Figure 2c we observe that DeClarE locates politicians with similar ideologies and opinions close to each other in the embedding space."
  }, {
    "heading": "5.3 Analyzing Attention Weights",
    "text": "Attention weights help understand what DeClarE focuses on during learning and how it affects its decisions – thereby, making our model transparent to the end-users. Table 6 illustrates some interesting claims and salient words (highlighted) that DeClarE focused on during learning. Darker shades indicate higher weights given to the corresponding words. As illustrated in the table, DeClarE gives more attention to important words in the reporting article that are relevant to the claim and also\nplay a major role in deciding the corresponding claim’s credibility. In the first example on Table 6, highlighted words such as “..barely true...” and “..sketchy evidence...” help our system to identify the claim as not credible. On the other hand, highlighted words in the last example, like, “..reveal...” and “..documenting reports...” help our system to assess the claim as credible."
  }, {
    "heading": "6 Related Work",
    "text": "Our work is closely related to the following areas: Credibility analysis of Web claims: Our work builds upon approaches for performing credibility analysis of natural language claims in an opendomain Web setting. The approach proposed in Popat et al. (2016, 2017) employs stylistic lan-\nguage features and the stance of articles to assess the credibility of the natural language claims. However, their model heavily relies on handcrafted language features. Rashkin et al. (2017); Wang (2017) propose neural network based approaches for determining the credibility of a textual claim, but it does not consider external sources like web evidence and claim sources. These can be important evidence sources for credibility analysis. The method proposed by Samadi et al. (2016) uses the Probabilistic Soft Logic (PSL) framework to estimate source reliability and claim correctness. Vydiswaran et al. (2011) proposes an iterative algorithm which jointly learns the veracity of textual claims and trustworthiness of the sources. These approaches do not consider\nthe deeper semantic aspects of language, however. Wiebe and Riloff (2005); Lin et al. (2011); Recasens et al. (2013) study the problem of detecting bias in language, but do not consider credibility. Truth discovery: Prior approaches for truth discovery (Yin et al., 2008; Dong et al., 2009, 2015; Li et al., 2011, 2014, 2015; Pasternack and Roth, 2011, 2013; Ma et al., 2015; Zhi et al., 2015; Gao et al., 2015; Lyu et al., 2017) have focused on structured data with the goal of addressing the problem of conflict resolution amongst multisource data. Nakashole and Mitchell (2014) proposed a method to extract conflicting values from the Web in the form of Subject-Predicate-Object (SPO) triplets and uses language objectivity analysis to determine the true value. Like the other truth discovery approaches, however, this approach is mainly suitable for use with structured data. Credibility analysis in social media: Mukherjee et al. (2014); Mukherjee and Weikum (2015) propose PGM based approaches to jointly infer a statement’s credibility and the reliability of sources using language specific features. Approaches like (Castillo et al., 2011; Qazvinian et al., 2011; Yang et al., 2012; Xu and Zhao, 2012; Gupta et al., 2013; Zhao et al., 2015; Volkova et al., 2017) propose supervised methods for detecting deceptive content in social media platforms like Twitter, Sina Weibo, etc. Similarly, approaches like Ma et al. (2016); Ruchansky et al. (2017) use neural network methods to identify fake news and rumors on social media. Kumar et al. (2016) studies the problem of detecting hoax articles on Wikipedia. All these rely on domain-specific and community-specific features like retweets, likes, upvotes, etc."
  }, {
    "heading": "7 Conclusion",
    "text": "In this work, we propose a completely automated end-to-end neural network model, DeClarE, for evidence-aware credibility assessment of natural language claims without requiring hand-crafted features or lexicons. DeClarE captures signals from external evidence articles and models joint interactions between various factors like the context of a claim, the language of reporting articles, and trustworthiness of their sources. Extensive experiments on real world datasets demonstrate our effectiveness over state-of-the-art baselines."
  }],
  "year": 2018,
  "references": [{
    "title": "Information credibility on twitter",
    "authors": ["Carlos Castillo", "Marcelo Mendoza", "Barbara Poblete."],
    "venue": "Proceedings of the 20th International Conference on World Wide Web, WWW ’11, pages 675–684, New York, NY, USA. ACM.",
    "year": 2011
  }, {
    "title": "Semeval-2017 task 8: Rumoureval: Determining rumour veracity and support for rumours",
    "authors": ["Leon Derczynski", "Kalina Bontcheva", "Maria Liakata", "Rob Procter", "Geraldine Wong Sak Hoi", "Arkaitz Zubiaga."],
    "venue": "Proceedings of the 11th International",
    "year": 2017
  }, {
    "title": "Integrating conflicting data: The role of source dependence",
    "authors": ["Xin Luna Dong", "Laure Berti-Equille", "Divesh Srivastava."],
    "venue": "Proc. VLDB Endow., 2(1):550–561.",
    "year": 2009
  }, {
    "title": "Knowledge-based trust: Estimating the trustworthiness of web sources",
    "authors": ["Xin Luna Dong", "Evgeniy Gabrilovich", "Kevin Murphy", "Van Dang", "Wilko Horn", "Camillo Lugaresi", "Shaohua Sun", "Wei Zhang."],
    "venue": "Proc. VLDB Endow., 8(9):938–949.",
    "year": 2015
  }, {
    "title": "Niletmrg at semeval-2017 task 8: Determining rumour and veracity support for rumours on twitter",
    "authors": ["Omar Enayet", "Samhaa R. El-Beltagy."],
    "venue": "Proceedings of the 11th International Workshop on Semantic Evaluation, SemEval@ACL 2017, Van-",
    "year": 2017
  }, {
    "title": "Truth discovery and crowdsourcing aggregation: A unified perspective",
    "authors": ["Jing Gao", "Qi Li", "Bo Zhao", "Wei Fan", "Jiawei Han."],
    "venue": "PVLDB, 8(12):2048– 2049.",
    "year": 2015
  }, {
    "title": "Bidirectional lstm networks for improved phoneme classification and recognition",
    "authors": ["Alex Graves", "Santiago Fernández", "Jürgen Schmidhuber."],
    "venue": "Proceedings of the 15th International Conference on Artificial Neural Networks: Formal",
    "year": 2005
  }, {
    "title": "Faking sandy: Characterizing and identifying fake images on twitter during hurricane sandy",
    "authors": ["Aditi Gupta", "Hemank Lamba", "Ponnurangam Kumaraguru", "Anupam Joshi."],
    "venue": "Proceedings of the 22Nd International Conference on World Wide Web,",
    "year": 2013
  }, {
    "title": "Adam: A method for stochastic optimization",
    "authors": ["Diederik P. Kingma", "Jimmy Ba."],
    "venue": "CoRR, abs/1412.6980.",
    "year": 2014
  }, {
    "title": "Disinformation on the web: Impact, characteristics, and detection of wikipedia hoaxes",
    "authors": ["Srijan Kumar", "Robert West", "Jure Leskovec."],
    "venue": "Proceedings of the 25th International Conference on World Wide Web, WWW ’16, pages 591–602, Republic and",
    "year": 2016
  }, {
    "title": "A confidence-aware approach for truth discovery on long-tail data",
    "authors": ["Qi Li", "Yaliang Li", "Jing Gao", "Lu Su", "Bo Zhao", "Murat Demirbas", "Wei Fan", "Jiawei Han."],
    "venue": "Proc. VLDB Endow., 8(4):425–436.",
    "year": 2014
  }, {
    "title": "Tverifier: Verifying truthfulness of fact statements",
    "authors": ["Xian Li", "Weiyi Meng", "Clement Yu."],
    "venue": "Proceedings of the 2011 IEEE 27th International Conference on Data Engineering, ICDE ’11, pages 63–74, Washington, DC, USA. IEEE Computer So-",
    "year": 2011
  }, {
    "title": "A survey on truth discovery",
    "authors": ["Yaliang Li", "Jing Gao", "Chuishi Meng", "Qi Li", "Lu Su", "Bo Zhao", "Wei Fan", "Jiawei Han."],
    "venue": "SIGKDD Explor. Newsl., 17(2):1–16.",
    "year": 2016
  }, {
    "title": "On the discovery of evolving truth",
    "authors": ["Yaliang Li", "Qi Li", "Jing Gao", "Lu Su", "Bo Zhao", "Wei Fan", "Jiawei Han."],
    "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’15, pages 675–684, New",
    "year": 2015
  }, {
    "title": "Sentence subjectivity detection with weaklysupervised learning",
    "authors": ["Chenghua Lin", "Yulan He", "Richard Everson."],
    "venue": "Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1153–1161. Asian Federation of Nat-",
    "year": 2011
  }, {
    "title": "Truth discovery by claim and source embedding",
    "authors": ["Shanshan Lyu", "Wentao Ouyang", "Huawei Shen", "Xueqi Cheng."],
    "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM ’17, pages 2183–2186, New York,",
    "year": 2017
  }, {
    "title": "Faitcrowd: Fine grained truth discovery for crowdsourced data aggregation",
    "authors": ["Fenglong Ma", "Yaliang Li", "Qi Li", "Minghui Qiu", "Jing Gao", "Shi Zhi", "Lu Su", "Bo Zhao", "Heng Ji", "Jiawei Han."],
    "venue": "Proceedings of the 21th ACM SIGKDD International Conference",
    "year": 2015
  }, {
    "title": "Detecting rumors from microblogs with recurrent neural networks",
    "authors": ["Jing Ma", "Wei Gao", "Prasenjit Mitra", "Sejeong Kwon", "Bernard J. Jansen", "Kam-Fai Wong", "Meeyoung Cha."],
    "venue": "Proceedings of the Twenty-Fifth International Joint Conference on Ar-",
    "year": 2016
  }, {
    "title": "Leveraging joint interactions for credibility analysis in news communities",
    "authors": ["Subhabrata Mukherjee", "Gerhard Weikum."],
    "venue": "Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM ’15.",
    "year": 2015
  }, {
    "title": "Language-aware truth assessment of fact candidates",
    "authors": ["Ndapandula Nakashole", "Tom M. Mitchell."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Vol-",
    "year": 2014
  }, {
    "title": "Making better informed trust decisions with generalized factfinding",
    "authors": ["Jeff Pasternack", "Dan Roth."],
    "venue": "IJCAI 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, Barcelona, Catalonia, Spain, July 16-22,",
    "year": 2011
  }, {
    "title": "Latent credibility analysis",
    "authors": ["Jeff Pasternack", "Dan Roth."],
    "venue": "Proceedings of the 22Nd International Conference on World Wide Web, WWW ’13, pages 1009–1020, New York, NY, USA. ACM.",
    "year": 2013
  }, {
    "title": "Glove: Global vectors for word representation",
    "authors": ["Jeffrey Pennington", "Richard Socher", "Christopher D. Manning."],
    "venue": "Empirical Methods in Natural Language Processing, EMNLP ’14.",
    "year": 2014
  }, {
    "title": "Credibility assessment of textual claims on the web",
    "authors": ["Kashyap Popat", "Subhabrata Mukherjee", "Jannik Strötgen", "Gerhard Weikum."],
    "venue": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Man-",
    "year": 2016
  }, {
    "title": "Where the truth lies: Explaining the credibility of emerging claims on the web and social media",
    "authors": ["Kashyap Popat", "Subhabrata Mukherjee", "Jannik Strötgen", "Gerhard Weikum."],
    "venue": "Proceedings of the 26th International Conference on World Wide",
    "year": 2017
  }, {
    "title": "Rumor has it: Identifying misinformation in microblogs",
    "authors": ["Vahed Qazvinian", "Emily Rosengren", "Dragomir R. Radev", "Qiaozhu Mei."],
    "venue": "Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages",
    "year": 2011
  }, {
    "title": "Truth of varying shades: Analyzing language in fake news and political fact-checking",
    "authors": ["Hannah Rashkin", "Eunsol Choi", "Jin Yea Jang", "Svitlana Volkova", "Yejin Choi."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language",
    "year": 2017
  }, {
    "title": "Linguistic models for analyzing and detecting biased language",
    "authors": ["Marta Recasens", "Cristian Danescu-Niculescu-Mizil", "Dan Jurafsky."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association",
    "year": 2013
  }, {
    "title": "Csi: A hybrid deep model for fake news detection",
    "authors": ["Natali Ruchansky", "Sungyong Seo", "Yan Liu."],
    "venue": "Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM ’17, pages 797–806, New York, NY, USA. ACM.",
    "year": 2017
  }, {
    "title": "Claimeval: Integrated and flexible framework for claim evaluation using credibility of sources",
    "authors": ["Mehdi Samadi", "Partha Talukdar", "Manuela Veloso", "Manuel Blum."],
    "venue": "Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence,",
    "year": 2016
  }, {
    "title": "IITP at semeval-2017 task 8 : A supervised approach for rumour evaluation",
    "authors": ["Vikram Singh", "Sunny Narayan", "Md. Shad Akhtar", "Asif Ekbal", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of the 11th International Workshop on Semantic Evaluation, Se-",
    "year": 2017
  }, {
    "title": "Separating facts from fiction: Linguistic models to classify suspicious and trusted news posts on twitter",
    "authors": ["Svitlana Volkova", "Kyle Shaffer", "Jin Yea Jang", "Nathan Hodas."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational",
    "year": 2017
  }, {
    "title": "Content-driven trust propagation framework",
    "authors": ["V.G. Vinod Vydiswaran", "ChengXiang Zhai", "Dan Roth."],
    "venue": "Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’11, pages 974–982, New",
    "year": 2011
  }, {
    "title": "liar, liar pants on fire”: A new benchmark dataset for fake news detection",
    "authors": ["William Yang Wang."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 2:",
    "year": 2017
  }, {
    "title": "Creating subjective and objective sentence classifiers from unannotated texts",
    "authors": ["Janyce Wiebe", "Ellen Riloff."],
    "venue": "Proceedings of the 6th International Conference on Computational Linguistics and Intelligent Text Processing, CICLing’05, pages 486–497,",
    "year": 2005
  }, {
    "title": "Towards universal paraphrastic sentence embeddings",
    "authors": ["John Wieting", "Mohit Bansal", "Kevin Gimpel", "Karen Livescu."],
    "venue": "Proceedings of the International Conference on Learning Representations (ICLR).",
    "year": 2015
  }, {
    "title": "Using deep linguistic features for finding deceptive opinion spam",
    "authors": ["Qiongkai Xu", "Hai Zhao."],
    "venue": "Proceedings of COLING 2012: Posters, pages 1341–1350. The COLING 2012 Organizing Committee.",
    "year": 2012
  }, {
    "title": "Automatic detection of rumor on sina weibo",
    "authors": ["Fan Yang", "Yang Liu", "Xiaohui Yu", "Min Yang."],
    "venue": "Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics, MDS ’12, pages 13:1–13:7, New York, NY, USA. ACM.",
    "year": 2012
  }, {
    "title": "Truth discovery with multiple conflicting information providers on the web",
    "authors": ["Xiaoxin Yin", "Jiawei Han", "Philip S. Yu."],
    "venue": "IEEE Trans. on Knowl. and Data Eng., 20(6):796–808.",
    "year": 2008
  }, {
    "title": "Enquiring minds: Early detection of rumors in social media from enquiry posts",
    "authors": ["Zhe Zhao", "Paul Resnick", "Qiaozhu Mei."],
    "venue": "Proceedings of the 24th International Conference on World Wide Web, WWW ’15, pages 1395–1405, Republic and Canton",
    "year": 2015
  }, {
    "title": "Modeling truth existence in truth discovery",
    "authors": ["Shi Zhi", "Bo Zhao", "Wenzhu Tong", "Jing Gao", "Dian Yu", "Heng Ji", "Jiawei Han."],
    "venue": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD ’15, pages",
    "year": 2015
  }],
  "id": "SP:ff513668841e9a2475b740540b464da55dc62ee5",
  "authors": [{
    "name": "Kashyap Popat",
    "affiliations": []
  }, {
    "name": "Subhabrata Mukherjee",
    "affiliations": []
  }, {
    "name": "Andrew Yates",
    "affiliations": []
  }, {
    "name": "Gerhard Weikum",
    "affiliations": []
  }],
  "abstractText": "Misinformation such as fake news is one of the big challenges of our society. Research on automated fact-checking has proposed methods based on supervised learning, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deficit by considering external sources related to a claim. However, these methods require substantial feature modeling and rich lexicons. This paper overcomes these limitations of prior work with an end-toend model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Experiments with four datasets and ablation studies show the strength of our method.",
  "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep Learning"
}