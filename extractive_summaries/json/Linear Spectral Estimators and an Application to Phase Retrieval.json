{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Phase retrieval refers to the problem of recovering an unknown N -dimensional signal vector x 2 HN , with H being the set of either real (R) or complex (C) numbers, from the following nonlinear measurement process:\ny = f(Ax+ e z ) + e y . (1)\nHere, the measurement vector y 2 RM contains M realvalued observations, for example measured through the nonlinear function f(z) = |z|2 that operates element-wise on vectors, A 2 HM⇥N is a given measurement matrix, and the vectors ez 2 HM and ey 2 RN model signal and measurement noises, respectively. In contrast to the majority of\n1School of Electrical and Computer Engineering, Cornell University, Ithaca, NY 2Department of EE, Princeton University 3University of Maryland. Correspondence to: Ramina Ghods <rg548@cornell.edu>, Christoph Studer <studer@cornell.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nexisting results on phase retrieval that assume randomness in the measurement matrix A, we focus on the practical scenario in which the measurement matrix A is deterministic, but the signal vector x to be recovered as well as the two noise sources ez and ey are random."
  }, {
    "heading": "1.1. Phase Retrieval",
    "text": "Phase retrieval has been studied extensively over the last decades (Gerchberg & Saxton, 1972; Fienup, 1982) and finds use in a range of applications, including imaging (Fogel et al., 2016; Yeh et al., 2015; Holloway et al., 2016), microscopy (Kou et al., 2010; Faulkner & Rodenburg, 2004), and X-ray crystallography (Harrison, 1993; Miao et al., 2008; Pfeiffer et al., 2006). Phase retrieval problems were solved traditionally using alternating projection methods, such as the Gerchberg-Saxton (Gerchberg & Saxton, 1972) and Fienup (Fienup, 1982) algorithms. More recent results have shown that semidefinite programming enables the design of algorithms with performance guarantees (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015). These methods lift the problem to a higher dimension, resulting in excessive complexity and memory requirements. To perform phase retrieval for highdimensional problems with performance guarantees, a range of convex (Bahmani & Romberg, 2017; Goldstein & Studer, 2017; Hand & Voroninski, 2016; Dhifallah et al., 2017; Dhifallah & Lu, 2017; Yuan & Wang, 2017; Salehi et al., 2018) and nonconvex methods (Netrapalli et al., 2013; Schniter & Rangan, 2015; Candès et al., 2015b; Chen & Candès, 2015; Zhang & Liang, 2016; Wang et al., 2017a; Zhang et al., 2016; Wei, 2015; Sun et al., 2016; Zeng & So, 2017; Lu & Li, 2017; Ma et al., 2018) have been proposed recently."
  }, {
    "heading": "1.2. Spectral Initializers",
    "text": "All of the above non-lifting-based phase retrieval methods rely on accurate initial estimates of the signal vector to be recovered. Such estimates are typically obtained by means of so-called spectral initializers put forward in (Netrapalli et al., 2013). Spectral initializers first compute a Hermitian matrix of the following form:\nD =\nMX\nm=1\nT (ym)amaHm, (2)\nwhere > 0 is a suitably-chosen scaling factor, ym denotes the mth measurement, aHm corresponds to the mth row of the measurement matrix A and T : R ! R is a (possibly nonlinear) preprocessing function. While the identity T (y) = y was used originally in (Netrapalli et al., 2013), recent results revealed that carefully crafted preprocessing functions yield more accurate estimates (Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b; Lu & Li, 2017; Mondelli & Montanari, 2017). From the matrix D in (2), one then extracts the (scaled) eigenvector ˆx associated with the largest eigenvalue, which serves as an initial estimate of the solution to the phase retrieval problem.\nAs shown in (Netrapalli et al., 2013; Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b; Lu & Li, 2017; Mondelli & Montanari, 2017), for i.i.d. Gaussian measurement matrices A, sufficiently large measurement ratios = M/N , and carefully crafted preprocessing functions T , spectral initializers provide accurate initialization vectors. In fact, the results in (Mondelli & Montanari, 2017) for the large-system limit with fixed and M ! 1 show that spectral initializers in combination with an optimal preprocessing function T achieve the fundamental informationtheoretic limits of phase retrieval. However, the assumption of having i.i.d. Gaussian measurement matrices A is impractical—it is more natural to assume that the signal vector x is random and the measurement matrix A is deterministic and structured (Bendory & Eldar, 2017)."
  }, {
    "heading": "1.3. Contributions",
    "text": "We propose a novel class of estimators, called linear spectral estimators (LSPEs), that provide accurate estimates for general nonlinear measurement systems of the form (1) and enable a nonasymptotic mean-squared error (MSE) analysis. We showcase the efficacy of LSPEs by applying them to phase retrieval problems, where we compute initialization vectors for real- and complex-valued systems with deterministic and finite-dimensional measurement matrices. For the proposed LSPEs, we derive nonasymptotic and sharp bounds on the MSE for signal estimation from phaseless measurements. We use synthetic and real-world phase retrieval problems to demonstrate that LSPEs are able to significantly outperform existing spectral initializers on systems that acquire structured measurements. We furthermore show that preprocessing the phaseless measurements enables LSPEs to generate improved initialization vectors for an even broader class of measurement systems."
  }, {
    "heading": "1.4. Notation",
    "text": "Lowercase and uppercase boldface letters represent column vectors and matrices, respectively. For a matrix A, its transpose and Hermitian conjugate is AT and AH , respectively, and the kth row and `th column entry is [A]k,` = Ak,`. For\na vector a, the kth entry is [a]k = ak. The `2-norm of a is denoted by kak2 and the Frobenius norm of A by kAkF . The Kronecker product is ⌦, the Hadamard product is , the Hadamard division is ↵, and the trace operator is tr(·). The N ⇥N identity matrix is denoted by IN ; the M ⇥N all-zeros and all-ones matrices are denoted by 0M⇥N and 1M⇥N , respectively. For a vector a, diag(a) is a square matrix with a on the main diagonal; for a matrix A, diag(A) is a column vector containing the diagonal elements of A."
  }, {
    "heading": "2. Linear Spectral Estimators",
    "text": "We start by reviewing the essentials of spectral initializers and then, introduce linear spectral estimators (LSPEs) for measurement systems of the form (1) with general nonlinearities f . We furthermore provide nonasymptotic expressions for the associated estimation error, and we compare our analytical results to that of conventional spectral initializers in (2). In Section 3, we will apply LSPEs to phase retrieval."
  }, {
    "heading": "2.1. Spectral Estimation and Initializers",
    "text": "One of the key issues of the phase retrieval problem is the fact that if x is a solution to (1), then ej x for any 2 [0, 2⇡) is also a valid solution (assuming H = C). Put simply, the solution is nonunique up to a global phase shift. One way of combating this issue is to directly recover the outer product xxH instead of x, which is unaffected by phase shifts; this insight is the key underlying lifting-based phase retrieval methods (Candès et al., 2013; Candès & Li, 2014; Candès et al., 2015a; Waldspurger et al., 2015). With this in mind, one could envision the design of an estimator that directly minimizes the conditional MSE:\n˙ x = arg min x̃2HN E ⇥kxxH ˜x˜xHk2F | y ⇤ . (3)\nHere, expectation is with respect to the signal vector x and the two noise sources ez and ey . This optimization problem resembles that of a posterior mean estimator (PME) which is, in general, difficult to derive, even for simple observation models—for phase retrieval, we have two additional challenges: (i) nonlinear phaseless measurements as in (1) and (ii) the quantity ˜x˜xH has rank-1.\nSpectral initializers avoid the issues of the estimator in (3) by first replacing the true outer product xxH with a socalled spectral estimator matrix D as in (2) that depends on the measurement vector y. In a second step, one then computes the best rank-1 approximation as follows:\nˆ x = arg min x̃2HN kD ˜x˜xHk2F (4)\nfrom which the estimate ˆx can be extracted. By performing an eigenvalue decomposition D = U⇤UH with U H U = IM and the eigenvalues in the diagonal matrix\n⇤ = diag([ 1, . . . , M ] T ) are sorted in descending order of their magnitudes, a spectral initializer is given by the scaled leading eigenvector ˆx = p 1u1. In practice, one can use power iterations to efficiently compute ˆx."
  }, {
    "heading": "2.2. Linear Spectral Estimators",
    "text": "We now propose a novel class of estimators, which we call linear spectral estimators (LSPEs), that provide accurate estimates for general nonlinear measurement systems of the form (1). To this end, we borrow ideas from the spectral initializer, the PME in (3), and the linear phase retrieval algorithm put forward in (Ghods et al., 2018). In the first step, LSPEs apply a linear estimator to the nonlinear observations in T (y) to construct a spectral estimator matrix D\ny\nfor which the spectral MSE (or matrix MSE) defined as\nS-MSE = E h D\ny xxH 2 F\ni (5)\nis minimal. We restrict ourselves to spectral estimator matrices D\ny\nthat are affine in T (y), i.e., are of the form\nD\ny = W0 +\nMX\nm=1\nT (ym)Wm (6)\nwith Wm 2 HN⇥N , m = 0, . . . ,M . In the second step, we use the spectral estimator matrix D\ny to extract a (scaled) leading eigenvector as in (3), which is the linear spectral estimate of the signal vector x. Intuitively, if we can construct a matrix D\ny from the preprocessed measurements in T (y) for which the S-MSE in (5) is minimal, then we expect that computing its best rank-1 approximation would yield an accurate estimate of the signal vector x up to a global phase shift. We will justify this claim in Section 2.3.\nMathematically, we wish to compute a matrix D y of the form (6) that is the solution to the following problem:\nminimize\nf Wm2HN⇥N m=0,...,M\nE\n2\n4 f W0 +\nMX\nm=1\nT (ym)fWm xxH\n2\nF\n3\n5 . (7)\nClearly, the spectral estimator matrix D y will depend on the measurement matrix A, the statistics of the signal to be estimated x and the two noise sources ez and ey, the nonlinearity f , as well as the preprocessing function T . For this setting, we have the following general result which summarizes the LSPE; the proof is given in Appendix A.\nTheorem 1 (Linear Spectral Estimator). Let the measurement vector y be a result of the general measurement model in (1) and select a preprocessing function T . Define the vector T (y) = E[T (y)] and assume the matrix\nT = E ⇥ (T (y) T (y))(T (y) T (y))T ⇤\nis full rank. Let t 2 RM satisfy Tt = T (y) T (y) and Vm = E ⇥ (T (ym) T (ym))(xxH Kx) ⇤\nfor m = 1, . . . ,M with K x = E ⇥ xx H ⇤ . Then, the LSPE matrix that minimizes the S-MSE in (5) is given by\nD\ny\n= K\nx\n+\nMX\nm=1\ntmVm. (8)\nThe linear spectral estimate ˆx is then given by the scaled leading eigenvector of the matrix D\ny\nin (8).\nThe vector t is the only quantity in Theorem 1 that depends on the actual (nonlinear) observations contained in the measurement vector y. All other quantities depend only on the first two moments of xxH as well as the considered signal, noise, and measurement models. The key features of the LSPE are as follows: (i) the involved quantities can often be computed in closed form (see Section 3 for two applications to phase retrieval) and (ii) LSPEs enable a nonasymptotic and sharp analysis of the associated estimation error. Remark 1. Theorem 1 requires the matrix T to be invertible. This condition is satisfied in most practical situations with nondegenerate measurement matrices A or in situations with nonzero measurement noise."
  }, {
    "heading": "2.3. Estimation Error Analysis of LSPEs",
    "text": "The remaining piece of the proposed LSPE is to show that the result of this two-step estimation procedure indeed yields a vector that is close to the signal vector x. We start with the following result; the proof is given in Appendix B. Theorem 2 (S-MSE of the LSPE). Let the assumptions of Theorem 1 hold. Then, the S-MSE in (5) for the LSPE matrix in (8) is given by\nS-MSELSPE = C xx\nH MX\nm=1\nMX\nm0=1\n[T 1 ]m,m0 tr V H mVm0\n(9)\nwith C xx\nH = E h xx H K x 2 F i .\nWith this result, we are ready to establish a bound on the estimation error of the LSPE. The proof of the following result follows from Theorem 2 and is given in Appendix C. Corollary 1 (LSPE Estimation Error). Let the assumptions of Theorem 1 hold. Then, the estimation error (EER) of the LSPE satisfies the following inequality:\nEERLSPE = E ⇥kˆxˆxH xxHk2F ⇤  4 S-MSELSPE. (10)\nThis result implies that by minimizing the S-MSE in (5) via (7), we are also reducing the EER of the LSPE. In other words, if the spectral error E = D\ny ˆxˆxH is small, then the EER of the LSPE (10) will be small.\nRemark 2. Corollary 1 is nonasymptotic and depends on the instance of measurement matrix A. This result is in stark contrast to existing performance bounds for spectral initializers (Netrapalli et al., 2013; Chen & Candès, 2015; Chen et al., 2015; Wang et al., 2017a;b) that strongly rely on randomness in the measurement matrix. In addition to randomness, the sharp performance guarantees in (Lu & Li, 2017; Mondelli & Montanari, 2017) focus on the asymptotic regime for which = M/N is fixed and M ! 1."
  }, {
    "heading": "2.4. S-MSE of Spectral Initializers",
    "text": "We can also derive an exact expression for the S-MSE of the conventional spectral initializer in (2). We assume optimal scaling, i.e., the parameter is set to minimize the S-MSE. The following result characterizes the S-MSE of such a scaled spectral initializer; the proof is given in Appendix D. Proposition 1 (S-MSE of the Spectral Initializer). Let D be the conventional spectral initializer matrix in (2). Then, the optimally-scaled S-MSE defined as\nS-MSESI = min 2H\nE ⇥kD xxHk2F ⇤ (11)\nis given by\nS-MSESI = R xx\nH PM m=1 a H m e Vmam 2\nPM m=1 PM m0=1 e Tm,m0 |aHmam0 |2 ,\n(12)\nwhere R xx H = E ⇥kxxHk2F ⇤ , eVm = E ⇥T (ym)xxH ⇤ , m = 1, . . . ,M , and eT = E ⇥T (y)T (y)T ⇤.\nSince the matrix in (2) is a special case of the LSPE matrix in (6), we have the following simple yet important property:\nS-MSELSPE  S-MSESI. In words, the spectral MSE of the LSPE cannot be worse than that of a spectral initializer. As we will show in Section 4, LSPEs are able to outperform spectral initializers on both synthetic and real-world phase retrieval problems given that the same preprocessing function T is used."
  }, {
    "heading": "3. LSPEs for Phase Retrieval Problems",
    "text": "The LSPE provides a framework for estimating signal vectors from the general observation model in (1). To make the concept of LSPEs explicit and to demonstrate their efficacy in practice, we now show two application examples to phase retrieval in complex-valued systems. The LSPE for real-valued phase retrieval can be found in Appendix E."
  }, {
    "heading": "3.1. Phase Retrieval without Preprocessing",
    "text": "We first focus on the case where the signal vector x to be estimated and the measurement matrix A are both complex-\nvalued. The phaseless measurements y, however, remain real-valued. We need the following assumptions.\nAssumptions 1. Let H = C. Assume square absolute measurements f(z) = |z|2 and the identity preprocessing function T (y) = y. Assume that the signal vector x 2 CN is i.i.d. circularly-symmetric complex Gaussian with covariance matrix C\nx\n= 2 xIN , i.e., x ⇠ CN (0N⇥1, 2xIN ). As-\nsume that the signal noise vector ez is circularly-symmetric complex Gaussian with covariance matrix C\ne z , i.e., ez ⇠ CN (0M⇥1,Cez ), and the measurement noise vector ey is a real-valued Gaussian vector with mean ¯ey and covariance matrix C\ne y , i.e., ey ⇠ N (¯ey,C e y ). Furthermore assume\nthat x, ez , and ey are independent.\nUnder these assumptions, we can derive the following LSPE which we call LSPE-C; the detailed derivations of this spectral estimator are given in Appendix G.\nEstimator 1 (LSPE-C). Let Assumptions 1 hold. Then, the spectral estimation matrix is given by\nD C y = K x +\nMX\nm=1\ntmVm, (13)\nwhere K x = 2 xIN , the vector t 2 RM is given by the solution to the linear system Tt = y y with\ny = diag(C\nz\n) +\n¯ e\ny\nC\nz\n= 2 xAA H +C e z\nT = C\nz C⇤ z +C e y\nand Vm = 4xamaHm, m = 1, . . . ,M . The spectral estimate ˆx is given by the (scaled) leading eigenvector of DC\ny\nin (13). Furthermore, the S-MSE is given by Theorem 2.\nWe emphasize that the spectral estimator matrix in (13) resembles that of the conventional spectral initializer matrix (2) with the following key differences. First and foremost, each outer product contained in Vm = 4xamaHm in Estimator 1 is weighted by tm, which is a function of all phaseless measurements in y and of the covariance matrix C\nx . In contrast, each outer product in the conventional spectral initializer matrix in (2) is only weighted by the associated measurement ym. This difference enables the LSPE to weight each outer product depending on correlations in the phaseless measurements caused by structure in the matrix A. Second, the spectral estimator matrix includes a mean term K\nx , which is absent in the spectral initializer matrix. As we will show in Section 4, for the same preprocessing function T , Estimator 1 is able to outperform spectral initializers for systems with structured measurement matrices A. For large i.i.d. Gaussian measurement matrices, there is no particular correlation structure to exploit and LSPEs perform on par with spectral initializers."
  }, {
    "heading": "3.2. Phase Retrieval with Exponential Preprocessing",
    "text": "To demonstrate the flexibility and generality of our framework, we now design an LSPE with an exponential preprocessing function for complex-valued phase retrieval. We derive the LSPE under the following assumptions. Assumptions 2. Let H = C. Assume square absolute measurements f(z) = |z|2 and the exponential preprocessing function T (y) = exp( y) with > 0, i.e., we consider\nT (y) = exp (|z|2 + ey) and z = Ax+ ez, where the exponential function is applied element-wise to vectors. The remaining assumptions are the same as in Assumptions 1.\nWe now derive the following LSPE called LSPE-Exp; the derivation of this spectral estimator is given in Appendix H. Estimator 2 (LSPE-Exp). Let Assumptions 2 hold. Then, the spectral estimation matrix is given by\nD Exp y = K x +\nMX\nm=1\ntmVm, (14)\nwhere K x = 2 xIN , the vector t 2 RM is given by the solution to the linear system Tt = T (y) T (y) with T (y) = p ↵ q\nT = (p p T ) exp( 2Cey )↵(q qT 2Cz C⇤z)\n(p pT )↵ (q qT )\nVm = 4 x[p ]m\n( [C\nz ]m,m + 1) 2 ama\nH m, m = 1, . . . ,M,\nwhere we use the following definitions:\nq = diag(Cz) + 1M⇥1 p = exp\n¯ey + 2 12 diag(Cey )\nC\nz\n= 2 xAA H +C e z .\nThe spectral estimate ˆx is given by the (scaled) leading eigenvector of DExp\ny in (14). Furthermore, the S-MSE of this estimator is given by Theorem 2.\nAt first sight, the choice of the exponential preprocessing function used in Estimator 2 seems to be arbitrary. We emphasize, however, that this particular function is inspired by the asymptotically-optimal preprocessing function for properly-normalized Gaussian measurement ensembles proposed in (Mondelli & Montanari, 2017) which is given by\nTopt(y) = y 1 y + p 1 . (15)\nAs it turns out, we can scale, negate, and shift the exponential preprocessing function T (y) = exp( y) to make it\ntake a similar shape as the function in (15). More concretely, exponential preprocessing as well as Topt(y) enables one to attenuate the effect of measurements with large magnitude, which is also the idea underlying the class of orthogonal spectral initializers, as proposed in (Chen et al., 2015; Wang et al., 2017a;b), that perform well in practice."
  }, {
    "heading": "4. Numerical Results",
    "text": "We now compare the performance of our LSPEs against existing spectral initializers proposed for phase retrieval on synthetic and real image data. All our results use the spectral initializers and experimental setups provided by PhasePack (Chandra et al., 2017)."
  }, {
    "heading": "4.1. Impact of Measurement Ensemble",
    "text": "We start by comparing the normalized MSE (N-MSE) defined as (Chandra et al., 2017)\nN-MSE = min↵2H kx ↵ˆxk2\nkxk2 for a range of spectral initializers on different measurement ensembles. Specifically, we focus on the complex-valued case and consider (i) an i.i.d. Gaussian measurement matrix with signal dimension N = 16, (ii) an i.i.d. Gaussian measurement matrix with N = 256, and (iii) the structured “transmission matrix” used for image recovery through multiple scattering media as detailed in (Metzler et al., 2017). We vary the oversampling ratio = M/N and compare the N-MSE of the proposed complex-valued LSPEs, LSPE-C (Estimator 1) and LSPE-Exp (Estimator 2 with = 0.001), to the following spectral initializers: the original spectral initializer (Netrapalli et al., 2013; Candès et al., 2015a) called “spectral,” truncated spectral initializer (Chen & Candès, 2015) called “truncated,” weighted spectral initializer (Wang et al., 2017b) called “weighted,” amplitude spectral initializer (Wang et al., 2017a) called “amplitude,” orthogonal spectral initializer (Chen et al., 2015) called “orthogonal,” and the asymptotically-optimal spectral initializer (Mondelli & Montanari, 2017) called “optimal.” For the following synthetic experiments, we generate the signals to be recovered according to Assumptions 1 and Assumptions 2 for LSPE-C and LSPE-Exp, respectively.\nFigure 1a shows that the proposed LSPEs significantly outperform all existing spectral initializers for small problem dimensions with Gaussian measurements; this improvement is even more pronounced for large oversampling ratios. The reason is that since we randomly generate a low-dimensional sensing matrix, the system will exhibit strong correlations among the measurements that can be exploited by LSPEs. For larger dimensions with Gaussian measurements, we see in Figure 1b that the proposed LSPEs do not provide an advantage over other methods. In fact, only LSPE-Exp is\nable to perform as well as the orthogonal spectral initializer, which achieves the best performance in this scenario. This behavior can be attributed to the facts that (i) for large random matrices there is no particular correlation structure among the measurements to exploit and (ii) ignoring measurements associated to large values in ym is increasingly important. For structured measurements, as it is the case for the transmission matrix from (Metzler et al., 2017), we see in Figure 1c that LSPEs significantly outperform existing methods that are designed for random measurement ensembles. In this scenario, exponential preprocessing does not improve performance since correlations in the transmission matrix are dominating the performance."
  }, {
    "heading": "4.2. S-MSE Expressions and Approximation Error",
    "text": "We now validate our theoretical S-MSE expressions in Theorem 2 and Proposition 1, and confirm the accuracy of the EER bound given in Corollary 1. In the following experiment, we set M = 8N and vary the dimension N from 8 to 64. For each pair (M,N), we randomly generate one instance of an i.i.d. circularly symmetric complex Gaussian measurement matrix and average the different errors (S-MSE and EER) over 10, 000 Monte-Carlo trials. We consider a noiseless setting and assume identity preprocessing, i.e., T (y) = y. The signal vectors are generated according to an i.i.d. circularly complex Gaussian random vector. From Figure 2, we see that our analytical S-MSE expressions for the LSPE-C and spectral initializers match their empirical values. We furthermore see that the empirical EER is only about 6 dB to 10 dB lower than our non-asymptotic upper bound given in Corollary 1."
  }, {
    "heading": "4.3. Real-World Image Recovery",
    "text": "We finally illustrate the efficacy of LSPEs in a more realistic scenario. In particular, we show results for a real image reconstruction task by using LSPEs and spectral initializers\nonly, i.e., we are not using any additional phase retrieval algorithm. Our goal is to recover a 16⇥16-pixel and a 40⇥40- pixel image that was captured through a multiple scattering media using the deterministic and highly-structured transmission matrix as detailed in (Metzler et al., 2017). We compare the proposed LSPEs to the same set of spectral initializers as in Section 4.1. The signal priors are as in Assumptions 1 (LSPE-C) and Assumptions 2 (LSPE-Exp).\nFigures 3 and 4 show the recovered images along with the N-MSE values. The proposed LSPEs (often significantly) outperform all spectral initializers in terms of visual quality as well as the N-MSE. This result confirms the observations made in Figure 1c that LSPEs outperform existing spectral initializers for structured measurement matrices. We note that exponential preprocessing for LSPEs does not noticeably improve the N-MSE (over LSPE-C) in this setting since correlations in the transmission measurement matrix are dominating the recovery performance."
  }, {
    "heading": "5. Conclusions",
    "text": "We have proposed a novel class of estimators, called linear spectral estimators (LSPEs), which are suitable for the recovery of signals from general nonlinear measurement systems. We have developed nonasymptotic and deterministic performance guarantees for LSPEs that provide accurate bounds on the estimation error, especially for structured or low-dimensional measurement systems. To demonstrate the efficacy of LSPEs in practice, we have applied them to complex-valued phase retrieval problems, in which LSPEs can be used to compute accurate signal estimates or initialization vectors for other convex or nonconvex phase retrieval algorithms. We have shown that properly preprocessing the nonlinear measurements can further improve the performance of LSPEs in practical scenarios. Our simulations with synthetic and real data have shown that LSPEs are able to significantly outperform existing spectral initializers, especially for low-dimensional problems, for structured measurement matrices, or for large oversampling ratios.\nThere are many avenues for future work. First, one could derive LSPEs for the asymptotically-optimal preprocessing function in (15) or for other commonly used functions, which may lead to further performance improvements. Second, the proposed error analysis could be used to generate improved measurement matrices. Third, an exploration of LSPEs for other nonlinearities that arise in machine learning and signal processing applications is left for future work."
  }, {
    "heading": "Acknowledgments",
    "text": "R. Ghods and C. Studer were supported in part by Xilinx, Inc. and by the US National Science Foundation (NSF) under grants ECCS-1408006, EECS-1740286, CCF-1535897, CCF-1652065, and CNS-1717559. T. Goldstein was supported by the US NSF under grant CCF-1535902, the US ONR under grant N00014-15-1-2676, the DARPA Lifelong Learning Machines program, and the Sloan Foundation."
  }, {
    "heading": "A. Proof of Theorem 1",
    "text": "The proof proceeds in two steps detailed as follows.\nMean Matrix We first compute the mean matrix W0. Since (7) is a quadratic form, we can take the derivative in fWH0 and set it to zero, i.e.,\nd\nd f W\nH 0\nE\n2\n4 f W0 +\nMX\nm=1\nT (ym)fWm xxH\n2\nF\n3\n5 = 0.\nBasic matrix calculus yields\nf W0 = Kx PM m=1 T (ym)fWm (16)\nwith T (ym) = E[T (ym)] and Kx = E ⇥ xx H ⇤ .\nLinear Estimation Matrix With (16) and the fact that (7) is a quadratic form in the matrices Wm, m = 1, . . . ,M ,\nwe take the derivatives in WHm and setting them to zero:\nd dfWHm\nE \" MX\nm=1\n(T (ym) T (ym))fWm (xxH Kx) 2\nF\n# =0.\nBy interchanging the derivative with expectation and with basic manipulations, we obtain the following set of optimality conditions for Wm for m = 1, . . . ,M : PM\nm0=1 f Wm0 E ⇥ (T (ym) T (ym))(T (ym0) T (ym0)) ⇤\n= E ⇥ (T (ym) T (ym))(xxH Kx) ⇤ . (17)\nIn compact matrix form, the above condition reads\n(T⌦ IN⇥N )W = V, (18) where we used the following shortcuts:\nT = E ⇥ (T (y) T (y))(T (y) T (y))T ⇤\nW = [ f W T 1 , . . . , f W T m, . . . , f W T M ] T\nVm= E ⇥ (T (ym) T (ym))(xxH Kx) ⇤ ,m = 1, . . . ,M\nV = [V T 1 , . . . ,V T m, . . . ,V T M ] T .\nThe condition in (18) can be solved for the estimation matrices in W leading to W = (T 1 ⌦ IN⇥N )V, where we require the matrix T to be full rank. To obtain the linear spectral estimator matrix, we simplify as\nD\ny\n= K\nx + ((T (y) T (y))T ⌦ IN⇥N )W = K\nx\n+ PM m=1 tmVm,\nwhere we define the vector t = T 1(T (y) T (y))."
  }, {
    "heading": "B. Proof of Theorem 2",
    "text": "To compute the spectral MSE in (5), we simplify\nS-MSE = E  PM m=1 tmVm (xxH Kx) 2\nF\n.\nWe expand this expression into four terms\nE  PM m=1 tmVm (xxH Kx) 2\nF\n= E  PM m=1 tmVm 2\nF\n(19)\n+ E h xx H K x 2 F i\nE h tr ⇣ (xx H K x ) H ⇣PM\nm=1 tmVm\n⌘⌘i (20)\nE  tr ✓⇣PM m=1 tmVm ⌘H (xx H K x ) ◆ (21)\nand simplify each expression individually. We start with (19) and use the fact that\nPM m=1 tmVm = ((T (y) T (y))TT 1 ⌦ IN⇥N )V\nand rewrite the quantity within expectation as follows:\nV H (T 1 (T (y) T (y))⌦ IN⇥N )\n⇥ ((T (y) T (y))TT 1 ⌦ IN⇥N )V = V H ((T 1 (T (y) T (y))\n⇥ (T (y) T (y))TT 1)⌦ IN⇥N )V. We now evaluate the expectation which leads to\nE  PM m=1 tmVm 2\nF\n= tr ⇣ V H (T 1 ⌦ IN⇥N )V ⌘\nor, equivalently, to E  PM m=1tmVm 2\nF\n=\nMX\nm=1\nMX\nm0=1\n[T 1 ]m,m0 tr V H mVm0 .\nWe next will simplify (20). Recall that\ntm = PM m0=1[T 1\n]m,m0(T (ym0) T (ym0)), which enables us to write (20) as\nE h tr ⇣ (xx H K x ) H ⇣PM\nm=1 tmVm\n⌘⌘i\n= PM m=1 PM m0=1[T 1 ]m,m0\n⇥ tr E⇥(xxH K x ) H (T (ym0) T (ym0)) ⇤ Vm\n= PM m=1 PM m0=1[T 1 ]m,m0 tr V H m0Vm . (22)\nSeeing as (21) is the Hermitian conjugate of (20), we have\nE  tr ✓⇣PM m=1 tmVm ⌘H (xx H K x ) ◆\n= PM m=1 PM m0=1[T 1 ] ⇤ m,m0 tr V H mVm0 . (23)\nCombining all these terms yield the spectral MSE\nS-MSE = E  PM m=1 tmVm (xxH Kx) 2\nF\n= C\nxx\nH tr ⇣ V H (T 1 ⌦ IN⇥N )V ⌘ .\nwith C xx\nH = E h xx H K x 2 F i ."
  }, {
    "heading": "C. Proof of Corollary 1",
    "text": "We bound the estimation error with the spectral MSE of the LSPE as follows. For a given instance, we have\nkˆxˆxH xxHk2F = kˆxˆxH Dy +Dy xxHk2F (a) 2kˆxˆxH D\ny k2F + 2kDy xxHk2F (b) 4kD\ny xxHk2F , where (a) follows from the squared triangle inequality and (b) because ˆxˆxH is the best rank-1 approximation of D\ny . Averaging over all instances finally yields\nE ⇥kˆxˆxH xxHk2F ⇤  4 S-MSELSPE."
  }],
  "year": 2018,
  "references": [{
    "title": "Phase retrieval meets statistical learning theory: A flexible convex relaxation",
    "authors": ["S. Bahmani", "J. Romberg"],
    "venue": "In Proc. Intl. Conf. Artif. Intell. and Stat.,",
    "year": 2017
  }, {
    "title": "Non-convex phase retrieval from STFT measurements",
    "authors": ["T. Bendory", "Y.C. Eldar"],
    "venue": "IEEE Trans. Inf. Theory,",
    "year": 2017
  }, {
    "title": "Solving quadratic equations via PhaseLift when there are about as many equations as unknowns",
    "authors": ["E.J. Candès", "X. Li"],
    "venue": "Found. Comput. Math.,",
    "year": 2014
  }, {
    "title": "PhaseLift: Exact and stable signal recovery from magnitude measurements via convex programming",
    "authors": ["E.J. Candès", "S. Thomas", "V. Voroninski"],
    "venue": "Commun. Pure Appl. Math.,",
    "year": 2013
  }, {
    "title": "Phase retrieval via matrix completion",
    "authors": ["E.J. Candès", "Y.C. Eldar", "T. Strohmer", "V. Voroninski"],
    "venue": "SIAM Rev.,",
    "year": 2015
  }, {
    "title": "Phase retrieval via Wirtinger flow: Theory and algorithms",
    "authors": ["E.J. Candès", "X. Li", "M. Soltanolkotabi"],
    "venue": "IEEE Trans. Inf. Theory,",
    "year": 1985
  }, {
    "title": "PhasePack: A phase retrieval library",
    "authors": ["R. Chandra", "Z. Zhong", "J. Hontz", "V. McCulloch", "C. Studer", "T. Goldstein"],
    "venue": "arXiv preprint: 1711.10175,",
    "year": 2017
  }, {
    "title": "Phase retrieval with one or two diffraction patterns by alternating projections of the null vector",
    "authors": ["P. Chen", "A. Fannjiang", "G. Liu"],
    "venue": "arXiv preprint:",
    "year": 2015
  }, {
    "title": "Solving random quadratic systems of equations is nearly as easy as solving linear systems",
    "authors": ["Y. Chen", "E.J. Candès"],
    "venue": "In Proc. Adv. Neural Info. Proc. Syst.,",
    "year": 2015
  }, {
    "title": "Fundamental limits of PhaseMax for phase retrieval: A replica analysis",
    "authors": ["O. Dhifallah", "Y. Lu"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Phase retrieval via linear programming: Fundamental limits and algorithmic improvements",
    "authors": ["O. Dhifallah", "C. Thrampoulidis", "Y. Lu"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Movable aperture lensless transmission microscopy: A novel phase retrieval",
    "authors": ["H.M.L. Faulkner", "J.M. Rodenburg"],
    "year": 2004
  }, {
    "title": "Phase retrieval algorithms: a comparison",
    "authors": ["J.R. Fienup"],
    "venue": "Appl. Opt.,",
    "year": 1982
  }, {
    "title": "Phase retrieval for imaging problems",
    "authors": ["F. Fogel", "I. Waldspurger", "A. d’Aspremont"],
    "venue": "Math. Prog. Comp.,",
    "year": 2016
  }, {
    "title": "A practical algorithm for the determination of phase from image and diffraction plane pictures",
    "authors": ["R.W. Gerchberg", "W.O. Saxton"],
    "venue": "Optik,",
    "year": 1972
  }, {
    "title": "PhaseLin: Linear phase retrieval",
    "authors": ["R. Ghods", "A.S. Lan", "T. Goldstein", "C. Studer"],
    "venue": "In Proc. 52nd Ann. Conf. Info. Sci",
    "year": 2018
  }, {
    "title": "Convex phase retrieval without lifting via PhaseMax",
    "authors": ["T. Goldstein", "C. Studer"],
    "venue": "In Proc. Intl. Conf. Mach. Learn.,",
    "year": 2017
  }, {
    "title": "An elementary proof of convex phase retrieval in the natural parameter space via the linear program PhaseMax",
    "authors": ["P. Hand", "V. Voroninski"],
    "venue": "arXiv preprint: 1611.03935,",
    "year": 2016
  }, {
    "title": "Phase problem in crystallography",
    "authors": ["R.W. Harrison"],
    "venue": "J. Opt. Soc. Am. A,",
    "year": 1993
  }, {
    "title": "Toward long-distance subdiffraction imaging using coherent camera arrays",
    "authors": ["J. Holloway", "M.S. Asif", "M.K. Sharma", "N. Matsuda", "R. Horstmeyer", "O. Cossairt", "A. Veeraraghavan"],
    "venue": "IEEE Trans. Comput. Imag.,",
    "year": 2016
  }, {
    "title": "On moments of folded and truncated multivariate normal distributions",
    "authors": ["R. Kan", "C. Robotti"],
    "venue": "J. Comput. Graph Stat.,",
    "year": 2017
  }, {
    "title": "Transport-of-intensity approach to differential interference contrast (TI-DIC) microscopy for quantitative phase imaging",
    "authors": ["S.S. Kou", "L. Waller", "G. Barbastathis", "C.J.R. Sheppard"],
    "year": 2010
  }, {
    "title": "Phase transitions of spectral initialization for high-dimensional nonconvex estimation",
    "authors": ["Y. Lu", "G. Li"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Optimization-based AMP for phase retrieval: The impact of initialization and `2regularization",
    "authors": ["J. Ma", "J. Xu", "A. Maleki"],
    "venue": "arXiv preprint:",
    "year": 2018
  }, {
    "title": "Coherent inverse scattering via transmission matrices: Efficient phase retrieval algorithms and a public dataset",
    "authors": ["C.A. Metzler", "M.K. Sharma", "S. Nagesh", "R.G. Baraniuk", "O. Cossairt", "A. Veeraraghavan"],
    "venue": "In Proc. IEEE Intl. Conf. Comput. Photograph.,",
    "year": 2017
  }, {
    "title": "Extending X-ray crystallography to allow the imaging of noncrystalline materials, cells, and single protein complexes",
    "authors": ["J. Miao", "T. Ishikawa", "Q. Shen", "T. Earnest"],
    "venue": "Ann. Rev. Phys. Chem.,",
    "year": 2008
  }, {
    "title": "Fundamental limits of weak recovery with applications to phase retrieval",
    "authors": ["M. Mondelli", "A. Montanari"],
    "venue": "arXiv preprint: 1708.05932,",
    "year": 2017
  }, {
    "title": "Phase retrieval using alternating minimization",
    "authors": ["P. Netrapalli", "P. Jain", "S. Sanghavi"],
    "venue": "In Proc. Adv. Neural Info. Proc. Syst.,",
    "year": 2013
  }, {
    "title": "Phase retrieval and differential phase-contrast imaging with lowbrilliance X-ray sources",
    "authors": ["F. Pfeiffer", "T. Weitkamp", "O. Bunk", "C. David"],
    "venue": "Nat. Phys.,",
    "year": 2006
  }, {
    "title": "A precise analysis of PhaseMax in phase retrieval",
    "authors": ["F. Salehi", "E. Abbasi", "B. Hassibi"],
    "venue": "arXiv preprint:",
    "year": 2018
  }, {
    "title": "Compressive phase retrieval via generalized approximate message passing",
    "authors": ["P. Schniter", "S. Rangan"],
    "venue": "IEEE Trans. Sig. Process.,",
    "year": 2015
  }, {
    "title": "A geometric analysis of phase retrieval",
    "authors": ["J. Sun", "Q. Qu"],
    "venue": "IEEE Intl. Symp. Info. Th.,",
    "year": 2016
  }, {
    "title": "Phase recovery, maxcut and complex semidefinite programming",
    "authors": ["I. Waldspurger", "A. d’Aspremont", "S. Mallat"],
    "venue": "Math. Prog.,",
    "year": 2015
  }, {
    "title": "Solving systems of random quadratic equations via truncated amplitude flow",
    "authors": ["G. Wang", "G.B. Giannakis", "Y.C. Eldar"],
    "venue": "arXiv preprint: 1605.08285,",
    "year": 2017
  }, {
    "title": "Solving almost all systems of random quadratic equations",
    "authors": ["G. Wang", "G.B. Giannakis", "Y. Saad", "J. Chen"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Solving systems of phaseless equations via Kaczmarz methods: A proof of concept study",
    "authors": ["K. Wei"],
    "venue": "Inverse Probl.,",
    "year": 2015
  }, {
    "title": "Experimental robustness of Fourier ptychography phase retrieval algorithms",
    "authors": ["L. Yeh", "J. Dong", "J. Zhong", "L. Tian", "M. Chen", "G. Tang", "M. Soltanolkotabi", "L. Waller"],
    "venue": "Opt. Express,",
    "year": 2015
  }, {
    "title": "Phase retrieval via reweighted Wirtinger flow",
    "authors": ["Z. Yuan", "H. Wang"],
    "venue": "Appl. Op.,",
    "year": 2017
  }, {
    "title": "Coordinate descent algorithms for phase retrieval",
    "authors": ["W. Zeng", "H.C. So"],
    "venue": "arXiv preprint:",
    "year": 2017
  }, {
    "title": "Reshaped Wirtinger flow for solving quadratic system of equations",
    "authors": ["H. Zhang", "Y. Liang"],
    "venue": "In Proc. Adv. Neural Info. Proc. Syst.,",
    "year": 2016
  }, {
    "title": "Provable non-convex phase retrieval with outliers: Median truncated Wirtinger flow",
    "authors": ["H. Zhang", "Y. Chi", "Y. Liang"],
    "venue": "In Proc. Intl. Conf. Mach. Learn.,",
    "year": 2016
  }],
  "id": "SP:e689c1f346af6b6841ac4ebd6ee1717adcf55302",
  "authors": [{
    "name": "Ramina Ghods",
    "affiliations": []
  }, {
    "name": "Andrew S. Lan",
    "affiliations": []
  }, {
    "name": "Tom Goldstein",
    "affiliations": []
  }, {
    "name": "Christoph Studer",
    "affiliations": []
  }],
  "abstractText": "Phase retrieval refers to the problem of recovering realor complex-valued vectors from magnitude measurements. The best-known algorithms for this problem are iterative in nature and rely on so-called spectral initializers that provide accurate initialization vectors. We propose a novel class of estimators suitable for general nonlinear measurement systems, called linear spectral estimators (LSPEs), which can be used to compute accurate initialization vectors for phase retrieval problems. The proposed LSPEs not only provide accurate initialization vectors for noisy phase retrieval systems with structured or random measurement matrices, but also enable the derivation of sharp and nonasymptotic mean-squared error bounds. We demonstrate the efficacy of LSPEs on synthetic and real-world phase retrieval problems, and show that our estimators significantly outperform existing methods for structured measurement systems that arise in practice.",
  "title": "Linear Spectral Estimators and an Application to Phase Retrieval"
}