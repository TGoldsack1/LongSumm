{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2336–2346, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "As deceptive behavior occurs on a daily basis in different areas of life (Meyer, 2010; Smith et al., 2014), the need arises for automated methodologies to detect deception in an efficient, yet reliable manner. There are many applications that can benefit from automatic deception identification, such as airport security screening, crime investigation and interrogation, interviews, advertisement, and others. In many of these settings, the polygraph test has been used as the main method to identify deceptive behavior. However, this method requires the use of skin-contact devices and human expertise, making it infeasible for large-scale applications. Moreover, polygraph tests were shown to be misleading in multiple cases (Vrij, 2001; Gannon et al., 2009), as human judgment is often biased.\nGiven the difficulties associated with the use of polygraph-like methods, learning-based approaches have been proposed to address the deception detection task using a number of modalities, including text (Feng et al., 2012) and speech (Hirschberg et al., 2005; Newman et al., 2003). Unlike the polygraph methods, learning-based methods for deception detection rely mainly on data collected from deceivers and truth-tellers. The data is usually elicited from human contributors, in a lab setting or via crowdsourcing. An important problem identified in this data-driven research is the lack of real data. Because of the artificial setting, the subjects may not be emotionally aroused, as they may not take the experiments seriously given the lack of motivation and/or penalty.\nIn this paper, we describe what we believe is a first attempt at building a multimodal system that detects deception in real-life settings. We collect a dataset consisting of 118 deceptive and truthful video clips, from real trials and live street interviews aired in television shows. We use the transcription of these videos to extract several linguistic features, and we manually annotate the videos for the presence of several gestures that are used to extract nonverbal features. We then build a system that jointly uses the verbal and nonverbal modalities to automatically detect the presence of deception. Our experiments show that the multimodal system can identify deception with an accuracy in the range of 77-82%, significantly improving over the baseline. In addition, we present a study on the human ability to detect deception in single or multimodal data streams, and show that our system outperforms humans on this task."
  }, {
    "heading": "2 Dataset",
    "text": "Our goal is to build a multimodal collection of occurrences of real deception, which will allow us to analyze both verbal and nonverbal behaviors in relation to deception.\n2336"
  }, {
    "heading": "2.1 Data Collection",
    "text": "To collect real deception data, we start by identifying online multimedia sources where deceptive behavior can be observed and verified. We specifically target videos of people, on which we enforce some of the constraints imposed by current data processing technologies: the person in the video should be in front of the camera; her face should be clearly visible; visual quality should be clear enough to identify the facial expressions; and finally, audio quality should be clear enough to hear the voices and understand what the person is saying. We collect video clips from public real trials and interviews aired during television shows, where the truth or falsehood of the partic-\nipant’s statements ends up being known. Video clips from trials consist of statements from witnesses and defendants in the same trial. In order to have a clear distinction between deceptive and truthful trial videos portraying defendants, the process of labeling the trial relies on the verdict. Thus, clips with a guilty verdict are considered deceptive whereas clips with a non-guilty verdict or exoneration are labeled as truthful. Clips containing witness testimonies are labeled as truthful if their statements are verified by police investigations. Examples of trials included in our dataset are Jodi Arias, Andrea Sneiderman, and Amanda Hayes. Exoneree’s statements were taken from “The Innocence Project” (http://www. innocenceproject.org).\nDeceptive and truthful responses are also collected from TV shows and interviews. Examples of such shows are “Lie Witness,” “Golden Balls,” and the “American Film Institute” and “RevYOU” You-Tube channels. Deceptive videos portray scenarios where interviewees’ responses were known to be a lie. For example, the interviewer asks a random individual on his opinion on a non-existing film where the interviewee fabricates a story. On the other hand, truthful videos are collected from individuals asked on their opinions on real movies.\nGiven our goals and constraints, data collection ended up being a lengthy and laborious process consisting of several iterations of Web mining, data processing and analysis, and content validation.\nThe final dataset includes 118 videos, including 59 that are labeled as deceptive and 59 labeled as truthful. Among them, 62 belong to the TV street interviews and shows category (Interviews) with 28 deceptive and 34 truthful video clips, and 56 belong to the trials category (Trials) with 31 deceptive and 25 truthful clips. The average length of the videos in the dataset is 27.28 seconds, with an average length of 33.02 seconds for the truthful clips and 21.54 seconds for the deceptive clips. Collected trial samples cover famous murder cases, while street interviews cover several topics such as movies, music, politics, and religion. The dataset contains 23 unique female and 39 unique male speakers, with their ages ranging approximately between 16 and 60 years."
  }, {
    "heading": "2.2 Transcriptions and Nonverbal Behavior Annotations",
    "text": "Our goal is to analyze both verbal and nonverbal behavior to understand their relation to deception.\nFirst, all the video clips were manually transcribed. The transcription was performed by two transcribers using the Elan software (Wittenburg et al., 2006). We asked transcribers to include word repetitions and fillers such as um, ah, and uh, as well as long pauses that were marked using three consecutive dots. The final set of transcriptions contain 7835 words, with an average of 66 words per transcript. Table 1 shows transcriptions of sample deceptive and truthful statements from both trials and reality shows.\nSecond, we annotate the gestures1 observed during the interactions in the video clips. We\n1As done in the Human-Computer Interaction community, we use the term “gesture” to broadly refer to body movements, including facial expressions and hand gestures.\nspecifically focus on the annotation of facial displays and hand movements, as they have been previously found to correlate with deceptive behavior (Depaulo et al., 2003). The gesture annotation is performed using the MUMIN coding scheme (Allwood et al., 2007).\nIn the MUMIN scheme, facial displays consist of several different facial expressions associated with eyebrows, eyes, gaze, and mouth. Smile, laughter, and scowl are also included, as well as general head and hand movements.\nThe multimodal annotation was performed by two annotators using the Elan software (Wittenburg et al., 2006). We decided to perform the gesture annotations at video level, rather than at utterance level, because the overall judgment of truthfulness and deceitfulness is based on the whole video content. During the annotation process, annotators were allowed to watch each video clip as many times as they needed. They were asked to identify the facial displays and hand gestures that were most frequently observed or dominating during the entire clip duration. For each video clip, the annotators had to choose one label for each of the nine gestures listed in Table 3.\nTable 3 shows the frequency counts associated with the nine gestures considered during the annotation. Note that the counts under each gesture add up to 118, reflecting the fact that for every gesture, the annotators had to choose one label for every video clip. When none of the labels applied, the “Other” category was selected. In the case of gestures associated with hand movements, the “Other” label also accounted for those cases where the speaker’s hands were not moving or were not visible.\nAfter all the video clips were annotated for gestures, the inter-annotator agreement was mea-\nsured. Table 2 shows the observed annotation agreement between the two annotators, along with the Kappa statistic. The agreement measure represents the percentage of times the two annotators agreed on the same label for each gesture category. For instance, 72.88% of the time the annotators agreed on the label assigned to the General Face category. On average, the observed agreement was measured at 75%, with a Kappa of 0.58 (macroaveraged over the nine categories), which reflects substantial agreement. Observed agreement for Head Movements and Gaze is noticeably lower than other categories, which can be attributed to a higher number of available gesture choices, as seen in Table 3."
  }, {
    "heading": "3 Features of Verbal and Nonverbal Behaviors",
    "text": "Given the multimodal nature of our dataset, we decided to focus on the linguistic and gesture components. In this section, we describe the sets of features extracted for each modality, which will then be used to build classifiers of deception."
  }, {
    "heading": "3.1 Verbal Features",
    "text": "We implement three types of features, consisting of unigrams, psycholinguistic features, and syntactic complexity features.\nUnigrams. We extract unigrams derived from the bag-of-words representation of the video transcripts. The unigram features are encoded as word frequencies and include all the words present in the transcripts.\nPsycholinguistic Features. The Linguistic Word Count (LIWC) is a psycholinguistics lexicon that has been frequently used to incorporate semantic and psychological information into linguistic analysis (Pennebaker and Francis, 1999). It has been successfully used in previous work on deception detection (Newman et al., 2003; Mihalcea and Strapparava, 2009; Ott et al., 2011). We obtain features for each of the 80 psycholinguistic classes present in the lexicon by calculating the percentage of words in the transcription belonging to each class.\nSyntactic Complexity. We also extract features to measure the syntactic complexity of the speech produced by the speakers in truthful and deceptive clips. This set of features is motivated by previous research that has suggested that deceivers’ speech has lower complexity (Depaulo et al., 2003). We use the tool described in (Lu, 2010), which generates indexes of syntactic complexity, including general complexity metrics, length of production, and amount of coordination. The set of features consists of fourteen indexes including statistics related to T-units, which are linguistic units that include a main clause in addition to attached subordinate clauses. T-unit analysis is extensively used to analyze syntactic complexity in speech and written content. The set of features includes the mean length of sentence, mean length of T-\nunit, mean length of clause, clauses per sentence, verb phrases per T-unit, clauses per Tunit, dependent clauses per clause, dependent clauses per T-unit, T-units per sentence, complex T-unit ratio, coordinate phrases per Tunit, coordinate phrases per clause, complex nominals per T-unit, and complex nominals per clause."
  }, {
    "heading": "3.2 Nonverbal Features",
    "text": "The nonverbal features are derived from the annotations performed using the MUMIN coding scheme as described in section 2.2. We create a binary feature for each of the 40 available gesture labels. Each feature indicates the presence of a gesture only if it is observed during the majority of the interaction duration. The generated features represent nine different gesture categories covering facial displays and hand movements.\nFacial Displays. These are facial expressions or head movements displayed by the speaker during the deceptive or truthful interaction. They include all the behaviors listed in Table 3 under the General Facial Expressions, Eyebrows, Eyes, Mouth Openness, Mouth Lips, and Head Movements.\nHand Gestures. The second broad category covers gestures made with the hands, and it includes the Hand Movements and Hand Trajectories listed in Table 3."
  }, {
    "heading": "4 Experiments",
    "text": "We start our experiments with an analysis of the nonverbal behaviors occurring in deceptive and truthful videos. We compare the percentage of each behavior as observed in each class. For instance, there is a total of 41 videos in the dataset\nthat include the Smile feature (as shown in Table 3), out of which 12 are part of the deceptive set of 59 videos, and 29 are part of the truthful set (again, of 59 videos). Hence, the percentages for this feature are 20.33% in the deceptive class, and 49.13% in the truthful class. Figure 2 shows the percentages of all the nonverbal features for which we observe noticeable differences for the deceptive and truthful groups. As the figure suggests, facial displays seem to help differentiate between the deceptive and truthful conditions. For instance, we can observe that truth-tellers smile (Smile) and blink more (Close-R). Interestingly deceivers seem to make more eye contact (Interlocutor gaze) and nod (Side-Turn-R) more frequently than truth-tellers. This agrees with the findings in (Depaulo et al., 2003) that liars who are more motivated to get away with their lies (i.e., trials) are likely to increase their eye-contact behavior.\nMotivated by these results, we proceed to conduct further experiments to evaluate the performance of the extracted features using a machine learning approach.\nWe run our learning experiments on the realdeception dataset introduced earlier. Given the even distribution between deceptive and truthful clips, the baseline on this dataset is 50%. For each video clip, we create feature vectors formed by combinations of the verbal and nonverbal features described in the previous section. We build deception classifiers using three classification algorithms: Support Vector Machines (SVM), Decision Trees (DT), and Random Forest (RF).2 We run several comparative experiments using leaveone-out cross-validation. Table 4 shows the accuracy figures obtained by the three classifiers on the major feature groups described in Section 3. As shown in this table, the facial displays classifier achieves the highest accuracy among the individual classifiers, followed by the unigrams classifier.\nWe also evaluate classifiers that rely on combined sets of features. The nonverbal features clearly outperform the verbal features, and the classifier that includes all the features improves over the classifiers that rely on all the verbal features or all the nonverbal features. Importantly, several of the classifiers improve significantly over the baseline."
  }, {
    "heading": "4.1 Analysis of Feature Contribution",
    "text": "To better understand the contribution of the different feature sets to the overall classifier performance, we conduct an ablation study where we remove one group of features at a time. Given that SVM had the best performance in our initial set of experiments, we run all our analysis experiments only using this classifier. Table 5 shows the accuracies obtained when one feature group is removed and the deception classifier is built using the remaining features. From this table, we can again observe that Facial Displays contribute the most to the classifier performance, while Syntactic Features show the lowest contribution.\n2We use the implementation available in the Weka toolkit with the default parameters.\nFeature  Weights  \nFor a closer look at the contribution of individual features included in the group of Facial Displays, we analyzed the absolute values of the weights assigned by the learning algorithm to the features in this group. Figure 3 shows the features normalized with respect to the largest feature weight. The five most predictive features are the presence of side turns, up gazes, blinking, and smiling, which we previously identified as possible indicators of deception. This further confirms our initial hypothesis that gestures associated with human interaction are an important component of human deception.\nWe also analyze the contribution of the linguistic features. Using the linguistic ethnography method (Mihalcea and Pulman, 2009), we obtain the most dominant LIWC word classes associated with deceptive and truthful transcripts extracted from trials and interviews clips. Results are shown in Table 6. Interestingly, the most dominant classes in truthful clips, regardless of being from interviews or trials, correspond to words related to Family, Home, and Humans. This suggests that truth-tellers show similar word usage when interviewed on a real scenario. On the other hand, dominant classes associated to deceivers are less consistent as they discuss aspects related to the topic being discussed. For instance, while being interviewed about a non-existing movie, deceivers talk about their Past, Assent, and use Motion words in order to support their lies. In contrast, while being on trial stating their (false) innocence, they use Anxiety, Anger, and negative emo-\ntion words (class Negemo). In line with earlier observations (Mihalcea and Strapparava, 2009), deceptive texts include more words that reflect certainty (class Certain, with words such as completely, truly, always) and more references to others (class Other, with words such as she, day, him)."
  }, {
    "heading": "4.2 Domain Experiments",
    "text": "We perform three sets of experiments to determine the role played by the domain. The first set of experiments uses only the Interviews video clips (62 in total), and the results are shown in the left column of Table 7. The second set uses only the Trials instances (56 in total), with results shown in the right column of Table 7. Finally, we also perform cross-domain experiments, with the training data drawn from one domain and the test data from the other. The results of these experiments are shown in Table 8. Given the uneven distribution of the truthful and deceptive video clips in two domains, the baselines are 54.83% for the Interviews domain (34 truthful, 28 deceptive), and 55.35% for the Trials domain (25 truthful, 31 deceptive).\nWhat we learn from these experiments is that the domain does matter. Despite the smaller dataset, the experiments run on one domain at a time lead to results that are higher than the ones obtained with more data but with a mix of domains. The cross-domain experiments also support this argument, as the performance drops sig-\nnificantly when there is no overlap in domain between the training and the test instances. Overall, in all our machine learning experiments, the combined classifier that makes use of all the verbal and nonverbal features achieves the best trade-off between performance and robustness, as it always leads to the best or second best performance across all the experiments using individual or combined feature sets. While a classifier based on an individual feature set can sometime lead to a better performance (e.g., the Facial Displays classifier has better performance when all the video clips are used), that same classifier may not perform well in another setting (e.g., the Facial Displays classifier is significantly below the All Features classifier in the domain experiments)."
  }, {
    "heading": "5 Human Performance",
    "text": "An important remaining question is concerned with the human performance on the task of deception detection. An answer to this question can shed light on the difficulty of the task, and can also place our results in perspective.\nWe conduct a study where we evaluate the human ability to identify deceit when exposed to four different modalities: Text, consisting of the language transcript; Audio, consisting of the audio track of the clip; Silent video, consisting of only the video with muted audio; and Full video, where\naudio and video are played simultaneously. We create an annotation interface that shows an annotator instances for each modality in random order, and ask him or her to select a label of either “Deception” or “Truth” according to his or her perception of truthfulness or falsehood.\nTo avoid annotation bias, we show the modalities in the following order: first we show either Text or Silent video, then we show Audio, followed by Full video. Note that apart from this constraint which is enforced over the four modalities belonging to each video clip, the order in which instances are presented to an annotator is random. Furthermore, the annotators did not have access to any information that would reveal the true label of an instance. The only exception to this could have been the annotators’ previous knowledge of some of the public trials in our dataset. A discussion with the annotators after the annotation took place indicated however that this was not the case.\nThree annotators labeled all the 118 video clips in the dataset. Since four modalities were extracted from each video, each annotator annotated a total of 412 instances. Annotators were not offered a monetary reward and we considered their judgments to be honest as they participated voluntarily in this experiment. Table 9 shows the observed agreement and Kappa statistics among the three annotators for each modality.3 The agreement for most modalities is rather low and the Kappa scores range between slight to fair agreement. As noted before (Ott et al., 2011), this low\n3Inter-rater agreement with multiple raters and variables. https://mlnl.net/jg/software/ira/\nagreement can be interpreted as an indication that people are poor judges of deception.\nWe also determine each annotator’s performance for each modality. The results, shown in Table 10, additionally support the argument that human judges have difficulty performing the deception detection task. An interesting, yet perhaps unsurprising observation is that the human performance increases with the availability of modalities. The poorest accuracy is obtained in Silent video, followed by Text, Audio, and Full Video where the judges have the highest performance.\nOverall, our study indicates that detecting deception is indeed a difficult task for humans and further verifies previous findings where human ability to spot liars was found to be slightly better than chance (Aamodt and Custer, 2006). Moreover, the performance of the human annotators appears to be significantly below that of our system."
  }, {
    "heading": "6 Related Work",
    "text": "Verbal Deception Detection. To date, several research publications on verbal-based deception detection have explored the identification of deceptive content in a variety of domains, including online dating websites (Toma and Hancock, 2010; Guadagno et al., 2012), forums (Warkentin et al., 2010; Joinson and Dietz-Uhler, 2002), social networks (Ho and Hollister, 2013), and consumer report websites (Ott et al., 2011; Li et al., 2014). Research findings have shown the effectiveness of features derived from text analysis, which frequently includes basic linguistic representations such as n-grams and sentence count statistics (Mihalcea and Strapparava, 2009), and also more complex linguistic features derived from syntactic CFG trees and part of speech tags (Feng et al., 2012; Xu and Zhao, 2012). Research work has also relied on the LIWC lexicon to build deception models using machine learning approaches (Mihalcea and Strapparava, 2009; Ángela Almela et al., 2012) and showed that the use of psycholinguistic information is helpful for the automatic identification of deceit. Following the hypothesis that deceivers might create less complex sentences in an effort to conceal the truth and being able to recall their lies more easily, several researchers have also studied the relation between text syntactic complexity and deception (Yancheva and Rudzicz, 2013).\nNonverbal Deception Detection. Earlier approaches to nonverbal deception detection relied\non polygraph tests to detect deceptive behavior. These tests are mainly based on such physiological features such as heart rate, respiration rate, skin temperature. Several studies (Vrij, 2001; Gannon et al., 2009; Derksen, 2012) indicated that relying solely on physiological measurements can be biased and misleading. Chittaranjan et al. (Chittaranjan and Hung, 2010) created an audio visual recording of the “Are you a Werewolf?” game in order to detect deceptive behaviour using non-verbal audio cues and to predict the subjects’ decisions in the game. For hand gestures, blob analysis was used to detect deceit by tracking the hand movements of the subjects (Lu et al., 2005; Tsechpenakis et al., 2005), or using geometric features related to the hand and head motion (Meservy et al., 2005). Caso et al. (Caso et al., 2006) identified particular hand gestures that can be related to the act of deception using data from simulated interviews. Cohen et al. (2010) found that fewer iconic hand gestures were a sign of a deceptive narration, and Hillman et al. (2012) determined that increased speech prompting gestures were associated with deception while increased rhythmic pulsing gestures were associated with truthful behavior. Also related is the taxonomy of hand gestures developed by (Maricchiolo et al., ) for deception and social behavior. Facial expressions also played a critical role in the identification of deception. (Ekman, 2001) defined micro-expressions as relatively short involuntary expressions, which can be indicative of deceptive behavior. Moreover, these expressions were analyzed using smoothness and asymmetry measurements to further relate them to an act of deceit (Ekman, 2003). Tian et al. (Tian et al., 2005) considered features such as face orientation and facial expression intensity. Owayjan et al. (Owayjan et al., 2012) extracted geometricbased features from facial expressions, and Pfister and Pietikainen (Pfister and Pietikäinen, 2012) developed a micro-expression dataset to identify expressions that are clues for deception. Recently, features from different modalities were integrated in order to find a combination of multimodal features with superior performance (Burgoon et al., 2009; Jensen et al., 2010). A multimodal deception dataset consisting of linguistic, thermal, and physiological features was introduced in (PérezRosas et al., 2014), which was then used to develop a multimodal deception detection system (Abouelenien et al., 2014). An extensive review\nof approaches for evaluating human credibility using physiological, visual, acoustic, and linguistic features is available in (Nunamaker et al., 2012)."
  }, {
    "heading": "7 Conclusions",
    "text": "In this paper we presented a study of multimodal deception detection using real-life occurrences of deceit. We introduced a novel dataset covering recordings from public real trials and street interviews, and used this dataset to perform both qualitative and quantitative experiments. Our analysis of nonverbal behaviors occurring in deceptive and truthful videos brought insight into the gestures that play a role in deception. We also built classifiers relying on individual or combined sets of verbal and nonverbal features, and showed that we can achieve accuracies in the range of 77-82%.\nAdditional analyses showed the role played by the various feature sets used in the experiments, and the importance of the domain. To place our results in perspective and better understand the difficulty of the task, we performed a study of human ability to detect deception, which revealed high disagreement among the annotators. Our automatic system outperforms the human detection of deceit by 6-15%.\nTo our knowledge this is the first work to automatically detect instances of deceit using both verbal and nonverbal features extracted from real deception data. In order to develop a fully automated deception deception system, our future work will address the use of automatic gesture and facial expression identification and automated speech transcription. Our goal is to move forward towards a real-time deception detection system.\nThe dataset introduced in this paper is publicly available from http://lit.eecs.umich.edu."
  }, {
    "heading": "Acknowledgments",
    "text": "This material is based in part upon work supported by National Science Foundation awards #1344257 and #1355633, by grant #48503 from the John Templeton Foundation, and by DARPABAA-12-47 DEFT grant #12475008. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation, the John Templeton Foundation, or the Defense Advanced Research Projects Agency."
  }],
  "year": 2015,
  "references": [{
    "title": "Who can best catch a liar? a meta-analysis of individual differences in detecting deception",
    "authors": ["Michael G. Aamodt", "Heather Custer."],
    "venue": "Forensic Examiner, 15(1):6–11.",
    "year": 2006
  }, {
    "title": "Deception detection using a multimodal approach",
    "authors": ["Mohamed Abouelenien", "Veronica Pérez-Rosas", "Rada Mihalcea", "Mihai Burzo."],
    "venue": "Proceedings of the 16th International Conference on Multimodal Interaction, pages 58–65, New York, NY,",
    "year": 2014
  }, {
    "title": "The mumin coding scheme for the annotation of feedback, turn management and sequencing phenomena",
    "authors": ["Jens Allwood", "Loredana Cerrato", "Kristiina Jokinen", "Costanza Navarretta", "Patrizia Paggio."],
    "venue": "Language Resources and Evaluation,",
    "year": 2007
  }, {
    "title": "Seeing through deception: A computational approach to deceit detection in written communication",
    "authors": ["Ángela Almela", "Rafael Valencia-Garcı́a", "Pascual Cantos"],
    "venue": "In Proceedings of the Workshop on Computational Approaches to Deception Detection,",
    "year": 2012
  }, {
    "title": "Detecting concealment of intent in transportation screening: A",
    "authors": ["Judee K. Burgoon", "Douglas P. Twitchell", "Matthew L. Jensen", "Thomas O. Meservy", "Mark Adkins", "John Kruse", "Amit V. Deokar", "Gabriel Tsechpenakis", "Shan Lu", "Dimitris N. Metaxas"],
    "year": 2009
  }, {
    "title": "The impact of deception and suspicion on different hand movements",
    "authors": ["Letizia Caso", "Fridanna Maricchiolo", "Marino Bonaiuto", "Aldert Vrij", "Samantha Mann."],
    "venue": "Journal of Nonverbal Behavior, 30(1):1–19.",
    "year": 2006
  }, {
    "title": "Are you awerewolf? detecting deceptive roles and outcomes in a conversational role-playing game",
    "authors": ["Gokul Chittaranjan", "Hayley Hung."],
    "venue": "2010 IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP), pages 5334–5337,",
    "year": 2010
  }, {
    "title": "Nonverbal indicators of deception: How iconic gestures reveal thoughts that cannot be suppressed",
    "authors": ["Doron Cohen", "Geoffrey Beattie", "Heather Shovelton."],
    "venue": "Semiotica, 2010(182):133–174.",
    "year": 2010
  }, {
    "title": "Cues to deception",
    "authors": ["Bella Depaulo", "Brian Malone", "James Lindsay", "Laura Muhlenbruck", "Kelly Charlton", "Harris Cooper."],
    "venue": "Psychological Bulletin, pages 74–118.",
    "year": 2003
  }, {
    "title": "Control and resistance in the psychology of lying",
    "authors": ["Maarten Derksen."],
    "venue": "Theory and Psychology, 22(2):196–212.",
    "year": 2012
  }, {
    "title": "Telling Lies: Clues to Deceit in the Marketplace, Politics and Marriage",
    "authors": ["Paul Ekman"],
    "year": 2001
  }, {
    "title": "Darwin, deception, and facial expression",
    "authors": ["Paul Ekman."],
    "venue": "Annals of the New York Academy of Sciences, 1000(EMOTIONS INSIDE OUT: 130 Years after Darwin’s The Expression of the Emotions in Man and Animals):205–221.",
    "year": 2003
  }, {
    "title": "Syntactic stylometry for deception detection",
    "authors": ["Song Feng", "Ritwik Banerjee", "Yejin Choi."],
    "venue": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 171–175, Jeju Island, Korea,",
    "year": 2012
  }, {
    "title": "Risk Assessment and the Polygraph, pages 129–154",
    "authors": ["Theresa Gannon", "Anthony Beech", "Tony Ward"],
    "year": 2009
  }, {
    "title": "Dating deception: Gender, online dating, and exaggerated self-presentation",
    "authors": ["Rosanna E. Guadagno", "Bradley M. Okdie", "Sara A. Kruse."],
    "venue": "Comput. Hum. Behav., 28(2):642–647, March.",
    "year": 2012
  }, {
    "title": "Um they were wearing : The effect of deception on specific hand gestures",
    "authors": ["Jackie Hillman", "Aldert Vrij", "Samantha Mann."],
    "venue": "Legal and Criminological Psychology, 17(2):336–345.",
    "year": 2012
  }, {
    "title": "Distinguishing deceptive from non-deceptive speech",
    "authors": ["Julia Hirschberg", "Stefan Benus", "Jason M. Brenier", "Frank Enos", "Sarah Friedman", "Sarah Gilman", "Cynthia Girand", "Martin Graciarena", "Andreas Kathol", "Laura Michaelis"],
    "year": 2005
  }, {
    "title": "Guess who? an empirical study of gender deception and detection in computer-mediated communication",
    "authors": ["Shuyuan Mary Ho", "Jonathan M Hollister."],
    "venue": "Proceedings of the American Society for Information Science and Technology, 50(1):1–4.",
    "year": 2013
  }, {
    "title": "Automatic, multimodal evaluation of human interaction",
    "authors": ["Matthew Jensen", "Thomas Meservy", "Judee Burgoon", "Jay Nunamaker."],
    "venue": "Group Decision and Negotiation, 19(4):367–389.",
    "year": 2010
  }, {
    "title": "Explanations for the perpetration of and reactions to deception in a virtual community",
    "authors": ["Adam N. Joinson", "Beth Dietz-Uhler."],
    "venue": "Social Science Computer Review, 20(3):275–289.",
    "year": 2002
  }, {
    "title": "Towards a general rule for identifying deceptive opinion spam",
    "authors": ["Jiwei Li", "Myle Ott", "Claire Cardie", "Eduard Hovy."],
    "venue": "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, Baltimore, Maryland, June.",
    "year": 2014
  }, {
    "title": "Blob analysis of the head and hands: A method for deception detection",
    "authors": ["Shan Lu", "Gabriel Tsechpenakis", "Dimitris Metaxas", "Matthew Jensen", "John Kruse."],
    "venue": "Proceedings of the 38th Annual Hawaii International Conference on System Sci-",
    "year": 2005
  }, {
    "title": "Automatic analysis of syntactic complexity in second language writing",
    "authors": ["Xiaofei Lu."],
    "venue": "International Journal of Corpus Linguistics, 15(4):474– 496.",
    "year": 2010
  }, {
    "title": "Deception detection through automatic, unobtrusive analysis of nonverbal behavior",
    "authors": ["Thomas Meservy", "Matthew Jensen", "John Kruse", "Douglas Twitchell", "Gabriel Tsechpenakis", "Judee Burgoon", "Dimitris Metaxas", "Jay Nunamaker."],
    "venue": "IEEE Intelligent",
    "year": 2005
  }, {
    "title": "Liespotting: Proven Techniques to Detect Deception",
    "authors": ["Pamela Meyer."],
    "venue": "New York: St. Martin’s.",
    "year": 2010
  }, {
    "title": "Linguistic ethnography: Identifying dominant word classes in text",
    "authors": ["Rada Mihalcea", "Stephen Pulman."],
    "venue": "Computational Linguistics and Intelligent Text Processing, pages 594–602. Springer.",
    "year": 2009
  }, {
    "title": "The lie detector: Explorations in the automatic recognition of deceptive language",
    "authors": ["Rada Mihalcea", "Carlo Strapparava."],
    "venue": "Proceedings of the Association for Computational Linguistics (ACL 2009), Singapore. Association for Computational Linguis-",
    "year": 2009
  }, {
    "title": "Lying words: Predicting deception from linguistic styles",
    "authors": ["Matthew L. Newman", "James W. Pennebaker", "Diane S. Berry", "Jane M. Richards."],
    "venue": "Personality and Social Psychology Bulletin, 29.",
    "year": 2003
  }, {
    "title": "Establishing a foundation for automated human credibility screening",
    "authors": ["Jay F. Nunamaker", "Judee K. Burgoon", "Nathan W. Twyman", "Jeffrey Gainer Proudfoot", "Ryan M. Schuetzler", "Justin Scott Giboney."],
    "venue": "2012 IEEE International Conference",
    "year": 2012
  }, {
    "title": "Finding deceptive opinion spam by any stretch of the imagination",
    "authors": ["Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey Hancock."],
    "venue": "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technolo-",
    "year": 2011
  }, {
    "title": "The design and development of a lie detection system using facial micro-expressions",
    "authors": ["Michel Owayjan", "Ahmad Kashour", "Nancy Al Haddad", "Maurice Fadel", "Ghinwa Al Souki."],
    "venue": "2012 2nd International Conference on Advances in Computational",
    "year": 2012
  }, {
    "title": "Linguistic inquiry and word count: LIWC",
    "authors": ["James W. Pennebaker", "Martha E. Francis."],
    "venue": "Erlbaum Publishers.",
    "year": 1999
  }, {
    "title": "A multimodal dataset for deception detection",
    "authors": ["Verónica Pérez-Rosas", "Rada Mihalcea", "Alexis Narvaez", "Mihai Burzo."],
    "venue": "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014), Reykjavik, Iceland, May",
    "year": 2014
  }, {
    "title": "Electronic imaging & signal processing automatic identification of facial clues to lies",
    "authors": ["Tomas Pfister", "Matti Pietikäinen."],
    "venue": "SPIE Newsroom, January.",
    "year": 2012
  }, {
    "title": "Everyday deception or a few prolific liars? the prevalence of lies in text messaging",
    "authors": ["Madeline Smith", "Jeffrey Hancock", "Lindsay Reynolds", "Jeremy Birnholtz."],
    "venue": "Computers in Human Behavior, 41(0):220–227.",
    "year": 2014
  }, {
    "title": "Facial expression analysis",
    "authors": ["Ying-Li Tian", "Takeo Kanade", "Jeffrey F. Cohn."],
    "venue": "Handbook of Face Recognition, pages 247–275. Springer New York.",
    "year": 2005
  }, {
    "title": "Reading between the lines: linguistic cues to deception in online dating profiles",
    "authors": ["Catalina L. Toma", "Jeffrey T. Hancock."],
    "venue": "Proceedings of the 2010 ACM conference on Computer supported cooperative work, CSCW ’10, pages 5–8.",
    "year": 2010
  }, {
    "title": "Hmmbased deception recognition from visual cues",
    "authors": ["Gabriel Tsechpenakis", "Dimitris Metaxas", "Mark Adkins", "John Kruse", "Judee K. Burgoon", "Matthew L. Jensen", "Thomas Meservy", "Douglas P. Twitchell", "Amit Deokar", "Jay F. Nunamaker."],
    "venue": "In",
    "year": 2005
  }, {
    "title": "Detecting Lies and Deceit: The Psychology of Lying and the Implications for Professional Practice",
    "authors": ["Aldert Vrij."],
    "venue": "Wiley series in the psychology of crime, policing and law. Wiley.",
    "year": 2001
  }, {
    "title": "Warrants and deception in computer mediated communication",
    "authors": ["Darcy Warkentin", "Michael Woodworth", "Jeffrey T Hancock", "Nicole Cormier."],
    "venue": "Proceedings of the 2010 ACM conference on Computer supported cooperative work, pages 9–12.",
    "year": 2010
  }, {
    "title": "Elan: a professional framework for multimodality research",
    "authors": ["Peter Wittenburg", "Hennie Brugman", "Albert Russel", "Alex Klassmann", "Han Sloetjes."],
    "venue": "Language Resources and Evaluation, volume 2006.",
    "year": 2006
  }, {
    "title": "Using deep linguistic features for finding deceptive opinion spam",
    "authors": ["Qiongkai Xu", "Hai Zhao."],
    "venue": "Proceedings of COLING 2012: Posters, Mumbai, India, December.",
    "year": 2012
  }, {
    "title": "Automatic detection of deception in child-produced speech using syntactic complexity features",
    "authors": ["Maria Yancheva", "Frank Rudzicz."],
    "venue": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
    "year": 2013
  }],
  "id": "SP:cfa46e029cdab2279211711257c1264612bf098d",
  "authors": [{
    "name": "Verónica Pérez-Rosas",
    "affiliations": []
  }, {
    "name": "Mohamed Abouelenien",
    "affiliations": []
  }, {
    "name": "Rada Mihalcea",
    "affiliations": []
  }, {
    "name": "Yao Xiao",
    "affiliations": []
  }, {
    "name": "CJ Linton",
    "affiliations": []
  }, {
    "name": "Mihai Burzo",
    "affiliations": []
  }],
  "abstractText": "Deception detection has been receiving an increasing amount of attention from the computational linguistics, speech, and multimodal processing communities. One of the major challenges encountered in this task is the availability of data, and most of the research work to date has been conducted on acted or artificially collected data. The generated deception models are thus lacking real-world evidence. In this paper, we explore the use of multimodal real-life data for the task of deception detection. We develop a new deception dataset consisting of videos from reallife scenarios, and build deception tools relying on verbal and nonverbal features. We achieve classification accuracies in the range of 77-82% when using a model that extracts and fuses features from the linguistic and visual modalities. We show that these results outperform the human capability of identifying deceit.",
  "title": "Verbal and Nonverbal Clues for Real-life Deception Detection"
}