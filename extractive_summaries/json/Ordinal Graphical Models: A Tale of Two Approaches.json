{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Undirected graphical models, also know as Markov random fields (MRF), are very popular for modeling multivariate random variables. They use undirected graphs to model the conditional independence structure among the\n*Equal contribution 1Carnegie Mellon University, Pittsburgh, USA 2School of Computing, KAIST, Daejeon, South Korea 3AITrics, Seoul, South Korea. Correspondence to: Arun Sai Suggala <asuggala@andrew.cmu.edu>, Eunho Yang <eunhoy@kaist.ac.kr>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nvariables. This conditional independence structure provides us with useful insights about how different variables interact with each other. As a result MRFs are extensively used in a variety of fields, including Natural Language Processing (Manning & Schütze, 1999), Biology (Friedman, 2004) and Medicine (Allen & Liu, 2012).\nPopular parametric families in the general class of MRFs are Gaussian graphical models (Speed & Kiiveri, 1986; Rue & Held, 2005) for continuous (and bell-shaped) data, Ising and discrete graphical models (Ising, 1925; Jalali et al., 2011) for nominal data, and mixed cases of these two instances (Lauritzen & Wermuth, 1989; Yang et al., 2014). However, variables that occur in many real world applications have ordered categorical scales. For example, in medical data, diseases are graded from mild to fatal, severity of an injury is rated from mild injury to death, stages of a disease is rated from I to III. Ordinal variables also occur very commonly in data collected from surveys. For example, each subject taking a survey could be asked to respond to a question using categories such as strongly disagree, disagree, undecided, agree, strongly agree. These examples clearly show that ordinal data is pervasive in many real world applications.\nIt will be instructive at this juncture to review univariate distributions for ordinal data, which fall into two main categories. The first category of distributions consists of parameterizing various odds ratios involving the ordinal variable, and include the cumulative ratio, continuation ratio, and consecutive ratio logit models (Armstrong & Sloan, 1989; Agresti, 2010). In practice, cumulative ratio and continuation ratio models are know to work better than the consecutive ratio model (McCullagh, 1984), and as a consequence, the consecutive ratio model is relatively less well considered among these three models. Some generalizations of the above models have been considered in literature (e.g., Partial Proportional Odds model (Peterson & Harrell Jr., 1990)), which fall in between the simpler class of models listed earlier and the multinomial logistic regression model in terms of their parametric complexity, but are nonetheless not as popular as the simpler class of models. The second category of univariate ordinal distributions are based on the natural generative assumption that the ordinal variable is a quantization of a real-valued latent variable. Common distributions imposed on the latent variable\ninclude the logistic distribution, in which case it reduces to the classical cumulative ratio model (Agresti, 2010), as well as the more popular standard normal distribution, in which case it is called the ordered probit model (Becker & Kennedy, 1992).\nThere has been some effort to construct multivariate ordinal distributions, and they again fall into two categories, namely the multivariate extensions of the corresponding two categories of univariate ordinal distributions. In the first category, there has been a line of work (see Bartolucci et al., 2007, and references therein) on designing parametrized odds ratio based models. Bartolucci et al. (2007) provide a general framework for designing multivariate ordinal models by parameterizing marginal distributions using various odds ratios. However, the parametric form of these models are complex, and have a large number of parameters, and so do not necessarily scale to highdimensional settings. Moreover, these models cannot be readily expressed as graphical model distributions.\nIn the second category of multivariate ordinal distributions, the ordinal random vector is modeled as a quantization of a real-valued latent random vector. Here, the efforts have focused on the use of the multivariate normal distribution for the latent random vector, due plausibly to its more convenient mathematical nature; the resulting model is also known as the multivariate probit model (Ashford & Sowden, 1970; Amemiya, 1974). But even with this modeling assumption, the likelihood of the observed ordinal random vector is not available in closed-form, is considerably complex due to the presence a multi-dimensional integral, and in particular is non-convex, so that learning the model given just the ordinal observations is typically computationally intractable. Consequently Expectation Maximization (EM) and approximate EM based approaches (Chib & Greenberg, 1998; Guo et al., 2015) have been proposed to compute the Maximum Likelihood Estimate (MLE). A caveat with these is that they do not come with statistical guarantees, and moreover, as our experiments show, are still computationally expensive. Because of the computational intractability of the MLE, alternative approaches have been proposed which maximize the pairwise, composite likelihood of the data, which involve only the univariate and bivariate marginals (Lindsay, 1988; De Leon, 2005; Han & Pan, 2012). Another class of methods have been proposed which estimate the model parameters in multiple stages (Muthén, 1984; Jöreskog, 1994), unlike the previous approaches which estimate all the parameters using a single estimating equation. Although these approaches are computationally very efficient they do not provide consistent estimates in high dimensional settings.\nThus, in spite of the ubiquity of multivariate ordinal data, there have been limited popular applications of these mul-\ntivariate ordinal distributions to model such data, particularly in high-dimensional settings, with a large number of ordinal variables.\nIn this paper, we develop multivariate ordinal graphical model distributions, for which the estimators are computationally tractable. Following the development of classical univariate ordinal distributions, our investigations fall into two categories. In the first category, we investigate multivariate extensions of the log-odds parameterized univariate ordinal distributions. Towards this, we leverage the line of work in Yang et al. (2012), which provides a mechanism to extend a univariate distribution to a multivariate graphical model distribution, by using the univariate distributions to specify node-conditional distributions. Their theoretical treatment requires the univariate distributions to belong to exponential families, while as we show, the logodds based univariate ordinal distributions, namely cumulative and continuation ratio models (Agresti, 2010), do not belong to exponential families. Could perhaps the framework of Yang et al. (2012) be nonetheless be extended to this case? We provide a definitive answer in the negative, and show that using these univariate ordinal distributions as node-conditional distributions cannot lead to a consistent joint distribution. Whereas, the consecutive ratio model (Agresti, 2010) does belong to the exponential family, and can be extended to a multivariate graphical model distribution. However, as we will demonstrate in our experiments, this resulting novel class of consecutive ratio MRFs has mixed empirical results.\nIn the second category, we investigate the multivariate extensions of latent variable quantization based univariate ordinal distributions. We focus on the case where the latent random vector is multivariate Gaussian. Here, we leverage the structure of the ordinal data, and provide a very simple multistage estimator along the lines of Muthén (1984); Jöreskog (1994), that finesses computing the likelihood, and accordingly is computationally tractable, but interestingly, also comes with strong statistical guarantees. We corroborate our findings on both simulated and real data."
  }, {
    "heading": "2. Multivariate Odds Ratio based Models",
    "text": "In the first part of the paper, we investigate the approach of Yang et al. (2012) i.e., specifying node-conditional distributions via classical univariate ordinal distributions, and then exploring the corresponding joint distribution via Hammersley-Clifford-esque analyses."
  }, {
    "heading": "2.1. MRFs via Univariate Latent Quantized Ordinal Models",
    "text": "The most popular class of univariate ordinal distributions rely on a generative model that quantizes a latent variable.\nSuppose we have a real-valued latent random variable Z 2 R with CDF denoted by P[Z  z] = g(z µ), where µ is a location parameter of the distribution. Suppose that the ordinal random variable Y 2 {0, . . . ,M} can be written as a discretized version of the real-valued variable Z, as Y = j, iff Z 2 (✓j 1, ✓j ], for some location (or cutpoint) parameters {✓j}Mj= 1, and with ✓ 1 = 1, ✓M = 1. It then follows that the probability mass function of the ordinal variable Y can be written as\nP[Y = j] = g(✓j µ) g(✓j 1 µ). (1)\nA popular distribution for the latent real-valued variable Z is the univariate logistic distribution, where Z ⇠ logistic(µ, 1), so that the function g(·) above is the logistic function, g(t) = (t) = 1/(1+ exp( t)). In this case, the distribution above can also be expressed in a more compact form in terms of log-odds ratios as: log ⇣\nP(Yj) P(Y >j)\n⌘\n= ✓j µ. Accordingly, this class of ordinal distributions are also called cumulative ratio models. We now consider the general framework of Yang et al. (2012), of using univariate ordinal distribution in (1) to specify node-conditional distributions, and deriving a consistent joint distribution.\nLet Y = (Y 1 , . . . , Yp) be a p-dimensional ordinal random vector. To simplify the notation, in the sequel we assume that the domains of all the random variables {Ys}ps=1 are same and equal to {0, 1, . . . ,M}. Let G = (V,E) be a graph with nodes corresponding to each of the random variables {Ys}ps=1. Suppose that for each s 2 V , we have\nP[Ys = j|Y\\s] = g(✓s;j µs(Y\\s)) g(✓s;j 1 µs(Y\\s)), (2)\nwhere the location parameter µs(Y\\s) is an arbitrary function of the rest of the variables and g is the logistic function. We now present the following theorem which shows that these node-conditional distributions do not lead to a consistent joint distribution. Theorem 1. Consider a p-dimensional random vector Y = (Y\n1 , . . . , Yp) with domain {0, 1, . . . ,M}p. And let G = (V,E) be a graph with nodes corresponding to each of the random variables {Ys}ps=1. Suppose that all nodeconditional distributions of this random vector follow the univariate cumulative ratio model in (2), where for each s 2 V , the location parameter µs(Y\\s) is an arbitrary function of the rest of the variables.\nThen, for M 1, there exist real valued parameters {✓s;j}s2V,j2[M ] for which the specified node-conditional distributions are not consistent with any joint distribution over Y that is Markov with respect to the graph G with factors of size at most 2.\nThe proof of the above theorem can be found in Appendix A and follows the Hammersley Clifford type analysis of Besag (1974)."
  }, {
    "heading": "2.2. MRFs via Continuation Ratio Models",
    "text": "One modification to the cumulative ratio model that has been considered in the literature is that of a closely related log-odds ratio: log ⇣\nP(Y=j) P(Y >j)\n⌘\n= ✓j µ. This class of univariate ordinal distributions are also called continuation ratio models. From the log-odds ratio above, denoting ⌘j := ✓j µ, the Probability Mass Function (PMF) of the random variable Y can be derived as\nP[Y = j] := exp(⌘j) Qj\ni=0\n1 + exp(⌘i)\n, (3)\nfor j = 0, . . . ,M 1. Then, the probability P(Y = M) is fixed as: 1\nPM 1 i=0 P (Y = i) =\n1\nQM 1 i=0 1+exp(⌘i) , so\nthat the summation of the PMF equals 1.\nAs in the previous section, given this univariate ordinal distribution, we ask if we could employ the strategy of Yang et al. (2012), of using these to specify node-conditional distributions, and deriving a consistent joint distribution? Specifically, suppose that for each node s 2 V we have\nP[Ys = j|Y\\s] = exp(⌘s;j(Y\\s))\nQj i=0 1 + exp(⌘s;j(Y\\s))\n, (4)\nwhere ⌘s;j(Y\\s) = ✓s;j µs(Y\\s)) and the location parameter µs(Y\\s) is an arbitrary function of the rest of the variables. The following theorem shows that these node conditional distributions do not lead to a consistent joint distribution. The proof of this theorem is provided in Appendix B.\nTheorem 2. Consider a p-dimensional random vector Y = (Y\n1 , . . . , Yp) with domain {0, 1, . . . ,M}p. And let G = (V,E) be a graph with nodes corresponding to each of the random variables {Ys}ps=1. Suppose that all nodeconditional distributions of this random vector follow the univariate continuation ratio model in (4), where for each s 2 V , the location parameter µs(Y\\s) is an arbitrary function of the rest of the variables.\nThen, for M 1, there exist real valued parameters {✓s;j}s2[p],j2[M ] for which the specified node-conditional distributions are not consistent with any joint distribution over Y that is Markov with respect to the undirected graph G."
  }, {
    "heading": "2.3. MRFs via a Consecutive Ratio model",
    "text": "A key caveat with the univariate cumulative and continuation ratio models is that they do not belong to exponential families, and in particular do not possess the regularities that allow for existence of consistent joint given node-conditionals belonging to these distributions. We now consider the third class of univariate ordinal distribu-\ntions called consecutive ratio model which is defined as: log ⇣\nP(Y=j) P(Y=j+1)\n⌘\n= ✓j µ, for j = 0, . . . ,M 1.\nAs we show below, this ordinal distribution belongs to an exponential family, unlike ordinal distributions in earlier sections. Proposition 1. The consecutive ratio model for an ordinal random variable Y 2 {0, . . . ,M} belongs to an exponential family with sufficient statistics {I[Y  j]}M 1j=0 : P[Y ] = exp ⇣\nPM 1 j=0 ⌘j I[Y  j] A(⌘)\n⌘\n, where as before, ⌘j := ✓j µ, for j 2 {0, . . . ,M 1}.\nWe now consider the counterpart of our key question in the earlier sections. Suppose we use the univariate ordinal distribution above to specify node-conditional distributions for an ordinal random vector Y = (Y\n1 , . . . Yp). Specifically, suppose that for each node s 2 V , we have\nP[Ys|Y\\s] / exp ⇣\nM 1 X\nj=0\n⌘s;j(Y\\s) I[Ys  j] ⌘ (5)\nwhere ⌘s;j = ✓s;j µs(Y\\s), for j = 0, . . . ,M 1, where the location parameter µs(Y\\s) is an arbitrary function of the rest of the variables. Since these node-conditional distributions belong to a univariate exponential family, an application of Proposition 1 of Yang et al. (2012) yields the following theorem: Theorem 3. The node-conditional distributions in (5) are consistent with a joint distribution that is Markov with respect to an undirected graph G = (V,E), which in the pairwise case with factors of size atmost two necessarily has the following form: P(Y) / exp ⇣ P\ns2V,j2[M 1] ✓s;j I[Ys  j] P (s,t)2E P j,k2[M 1]\n✓st I[Ys  j] I[Yt  k] ⌘ .\nThe distribution in Theorem 3 can be rewritten in the following equivalent form\nP(Y) / exp ⇣\nX\ns2V,j2[M 1]\n✓s;j I[Ys  j] +\nX\n(s,t)2E\n✓st M Ys M Yt\n⌘\n. (6)\nNote that the pairwise interaction terms in the above distribution utilize the ordinality of Y through the term\nM Ys M Yt .\nTo estimate the parameters of the consecutive ratio model (6), we solve the following regularized node conditional log likelihood maximization problem at each node s 2 [p]\nargmin\n¯✓s\nn X\ni=1\nlogP(yi;s|yi;\\s) + n X\nt2V \\s\n|✓st|,\nwhere {yi}ni=1 are training samples and ¯✓s = {✓s;j}j2[M 1] [ {✓st}t2V \\s.\nWe briefly note that existing results on statistical guarantees for estimators of exponential family graphical models (Yang et al., 2015; Tansey et al., 2015) carry over to the consecutive ratio model.\nContrast with Discrete/Nominal Graphical models: We now contrast the consecutive ratio model in (6) with the classical discrete nominal graphical model which treats the random variables at each node as nominal variables. Consider the following discrete graphical model over the random vector Y:\nP(Y) / exp ⇣\nX\ns2V,j2[M 1]\n✓s;j I[Ys = j]\n+\nX\n(s,t)2E\nX\nj,k2[M 1]\n✓st;jk I[Ys = j] I[Yt = k] ⌘ . (7)\nUnlike the consecutive ratio model, the above model doesn’t have a common edge parameter ✓st for different values of Ys, Yt. Each edge in the categorical model is parametrized using M2 variables. As a result this model does not utilize the ordinality of Y and is also more complex compared to the consecutive ratio model. While this parameterization does encompass the consecutive ratio model parameterization, the key disadvantage is that the nominal graphical model has a larger number of parameters and hence greater sample complexity."
  }, {
    "heading": "3. Multivariate Latent Quantized Models",
    "text": "In the previous section we considered using the mechanism of Yang et al. (2012) to directly construct multivariate ordinal graphical models from univariate ordinal distributions. In this section we revisit the classical and most popular class of univariate ordinal distributions based on the quantization of a real-valued latent variable. A natural class of multivariate distributions can be obtained by taking a multivariate latent random vector, and quantizing this to obtain a multivariate ordinal random vector."
  }, {
    "heading": "3.1. Probit Graphical Model",
    "text": "The most popular instance of such multivariate quantized ordinal distributions is the case where the multivariate latent random vector is multivariate Gaussian, which is also known as the multivariate probit model (Ashford & Sowden, 1970; Amemiya, 1974). Thus the dependencies are all represented in the latent random vector via the underlying Gaussian distribution.\nIn the probit model, the ordinal random vector Y = (Y\n1 , . . . Yp) is assumed to be generated from a latent multivariate Gaussian random vector Z = (Z\n1 , . . . , Zp), where\nZ ⇠ N (0,⌃) and Zi ⇠ N (0, 1) 8i 2 [1, p]. Each Yi is obtained through discretization of Zi as follows: Yi = k, iff Zi 2 [✓(i)k 1, ✓ (i) k ), where {✓ (i) k }Mk= 1 is the set of thresholds, ✓(i) 1 = 1, ✓ (i) M = 1. Then the density function of Y, P(Y;⌃,⇥), is given by\nP(✓(1)Y1 1  Z1 < ✓ (1) Y1 , . . . , ✓(p)Yp 1  Zp < ✓ (p) Yp ;⌃)\n=\nZ\nz2C(Y,⇥)\n1\np\n(2⇡)p|⌃| exp\n✓\n1 2\nz⌃ 1zT ◆ dz (8)\nwhere ⇥ = {✓(j)k : j 2 [1, p], k 2 [ 1,M ]} and C(Y,⇥) is the hypercube defined by [✓(1)Y1 1, ✓ (1) Y1 )⇥ . . .⇥ [✓(p)Yp 1, ✓ (p) Yp ).\nLet Yn = {yi}ni=1 be n i.i.d realizations of the random vector Y, drawn from probit model with parameters ⇥⇤,⌃⇤. Then the `\n1 -regularized Maximum Likelihood (ML) estimator to learn the parameters ⌃, ⇥ from Yn takes the form\nminimize\n⌃,⇥\nn X\ni=1\nlogP(yi;⌃,⇥) + nk⌃ 1k1,off (9)\nwhere k·k 1,off is the element-wise `1 norm excluding diagonal entries. It can be seen that the objective is non-convex, and intractable to optimize in general. Accordingly, approximate EM based approaches (Chib & Greenberg, 1998; Guo et al., 2015) have been proposed for learning the model parameters, but these are still relatively computationally demanding, and also do not come with the strong statistical guarantees of the actual regularized MLE solutions."
  }, {
    "heading": "3.2. A Direct Estimation Method",
    "text": "In the second contribution of the paper, we propose an alternative procedure for the estimation of the unknown parameters ⇥,⌃ in the probit graphical model distribution in (8). This is a two stage procedure where in the first stage we estimate the thresholds, ⇥, from the univariate marginals and in the second stage we estimate the polychoric correlations, ⌃, from bivariate marginal distributions."
  }, {
    "heading": "3.2.1. ESTIMATION OF THRESHOLDS",
    "text": "We define b⇥, our estimator of ⇥ as follows\nb✓(j)k =\n8\n> <\n> :\n1 if k = 1\n1 (\n1 n Pn i=1 I(yi,j  k)) if k = 0, . . . ,M 1\n1 if k = M ,\nwhere (.) is the CDF of standard normal distribution, I(.) is the indicator function, yi,j is the jth coordinate of vector yi. It can be seen that b⇥ consistently estimates ⇥⇤."
  }, {
    "heading": "3.2.2. ESTIMATION OF POLYCHORIC CORRELATIONS AND LATENT GRAPH STRUCTURE",
    "text": "We present a two step approach for estimation of ⌃. In the first step, we compute a raw estimate e⌃ from the bivariate marginal likelihoods. In the next step we plugin the estimated covariance matrix e⌃ into the graphical lasso estimator (Friedman et al., 2008) to estimate the sparse latent graph structure and a smoothed estimate b⌃.\nStep 1: To estimate each entry of ⌃ we solve an independent optimization problem. Lets suppose we want to estimate ⌃jk, for j 6= k. The joint distribution of (Yj , Yk) is multinomial with probabilities P(Yj , Yk;⇥,⌃jk) = P(✓(j)Yj 1  Zj  ✓ (j) Yj , ✓(k)Yk 1  Zk  ✓ (k) Yk\n;⌃jk), where the joint distribution of random variables Zj , Zk is bivariate normal with mean [0, 0] and covariance  1 ⌃jk\n⌃jk 1\n.\nIf ⇥⇤ is known, then one could estimate the unknown parameter ⌃jk by maximizing the bivariate marginal log likelihood function, which has the following form\n`jk( ;⇥ ⇤,Yn) =\nMX\na=0\nMX\nb=0\nnab n log P(Yj = a, Yk = b;⇥⇤, )\n=\nMX\na=0\nMX\nb=0\nnab n log ab;jk( ;⇥ ⇤ ), (10)\nwhere nab = Pn i=1 I(yi,j = a,yi,k = b) and ab;jk( ;⇥) = P(Yj = a, Yk = b;⇥, ). However, the thresholds ⇥⇤ are unknown. So to estimate ⌃jk, we replace ⇥⇤ with its estimator b⇥ and maximize the following log likelihood\ne ⌃jk = argmax 2M\n`jk( ; b⇥,Yn).\nwhere M is the domain of , which is ( 1, 1) unless no additional constraint on covariance is placed. Note that this is a one-dimensional optimization problem which, under certain regularity conditions such as smoothness of the objective, allow us to solve to within error ✏ in time O(1/✏) by simply evaluating the objective over a fine grid in M, and selecting the optimal grid point.\nStep 2: In this step we plug-in e⌃ into a parametric Gaussian graphical model estimator to obtain the graph structure and the final covariance matrix. While any consistent parametric Gaussian estimator (e.g., graphical lasso estimator (Friedman et al., 2008), CLIME (Cai et al., 2011), graphical Dantzig selector (Yuan, 2010)) can be used to estimate the latent graph structure, in this work we focus on the graphical lasso estimator (glasso), which involves solving the following optimization problem b ⌃ = argmin\n⌃ 1 0 hh⌃ 1, e⌃ii log det ⌃ 1 + nk⌃ 1k1,off,\n(11)\nwhere hhA,Bii denotes the trace inner product of A and B."
  }, {
    "heading": "3.3. Theoretical Properties",
    "text": "In this section, we show that the direct estimation method we proposed in Section 3.2 is not just simple but has strong statistical guarantees. Specifically, we provide an `1 bound for the inverse covariance estimator b⌃ 1, and show its sparsistency with respect to graphical model structure recovery. For simplicity, we assume that ⇥⇤ is given. However, extension to the case where ⇥⇤ is unknown should be fairly straightforward.\nWe begin with introducing some notation. Let ⇤ := ⌃⇤ ⌦ ⌃\n⇤, where ⌦ denotes the Kronecker matrix product, denote the Hessian of log det(A) evaluated at (⌃⇤) 1. Let S be the set of indices corresponding to all nonzero entries in (⌃ ⇤ )\n1, and Sc be the complement of S. We also define K\n⌃ ⇤ := |||⌃⇤|||1, and K ⇤ := |||( ⇤SS) 1|||1 for notational simplicity where ||| · |||1 denotes the maximum absolute row sum of matrix. Let d be the maximum node-degree in the latent graph. Finally, let ¯`jk( ;⇥⇤) = E[`jk( ;⇥⇤)] be the population version of the sample loss defined in Equation (10). We now state our assumptions.\n(C-1) There exists some ↵ 2 (0, 1] such that ||| ⇤ScS( ⇤SS) 1|||1  1 ↵. (C-2) There is a constant > 0 such that |⌃⇤jk|  1 , 8j < k. Moreover, the likelihood function ab;jk( ;⇥⇤), is strictly positive 8| |  1 , i.e., 9 > 0 such that 8| |  1 , ab;jk( ;⇥⇤) 1/ . (C-3) The absolute value of the 1st, 2nd and 3rd-order derivatives of ab;jk( ;⇥⇤) w.r.t. are upper-bounded respectively by L\n1 , L 2 , L 3 , 8| |  1 . Furthermore, the mild regularity property that ¯`jk( ;⇥⇤) not have degenerate critical points in [ 1 + , 1 ] holds.\n(C-1) is the standard incoherence assumption that is made for the guarantees of glasso estimator (Ravikumar et al., 2011). (C-2) is a mild condition which ensures that no two latent variables are perfectly collinear and all the categories of the ordinal variables have non zero probabilities. Theorem 4. Consider our estimator (11) for solving a latent Gaussian model with true parameter ⌃⇤. And suppose conditions (C-1)-(C-3) are satisfied. Then there exist some known quantities c\n1 , c 2 and c 3 depending on L 1 , L 2 , L 3 , M , ↵, , , K\n⌃\n⇤ and K ⇤ such that if n = c1 p log p0/n and n is lower bounded as n c\n2 d2 log p0 where p0 = max{n, p}, then the inverse of estimate b⌃ satisfies the following bound\nb ⌃ 1 (⌃⇤) 1\n1  c3\nr\nlog p0\nn (12)\nand, moreover, the graph structure of latent Gaussian encoded in (⌃⇤) 1 is consistently recovered by b⌃ 1, as long\nas min := minij [(⌃ ⇤ ) 1 ]ij\nc 3\nq\nlog p0\nn , with probability at least 1 1/p ! 1.\nProof Sketch: The proof of the theorem involves two main steps. In the first step we show that our estimate ˜⌃ from step 1 satisfies: supj,k |˜⌃jk ⌃⇤jk|  c3 q log p0\nn , with high probability. Next, we utilize the consistency properties of glasso (Ravikumar et al., 2008) to show that our estimate b⌃ from step 2 satisfies Equation (12) with high probability. To bound supj,k |˜⌃jk ⌃⇤jk|, we utilize recent results of Mei et al. (2017), who study the properties of the stationary points of non-convex empirical risk minimization problems. See Appendix C for the proof of the Theorem."
  }, {
    "heading": "4. Experiments",
    "text": "In this section we present the performance of Consecutive Ratio model (Consec model), and our estimator for probit model (ProbitDirect) on various synthetic and real world datasets."
  }, {
    "heading": "4.1. Synthetic Experiments",
    "text": "Baselines: In the synthetic experiments we compare our estimators with the following estimators:\na) ProbitEM: EM+MCMC based estimator for probit model described in Guo et al. (2015). This uses MCMC sampling to approximate the E-step. b) ProbitEMApprox: Approximate EM based estimator for probit model proposed by Guo et al. (2015). This approach uses mean field approximation in the E-step to speed up the EM procedure. c) Discrete model: This model ignores the order in the categories and treats each ordinal variable as a nominal variable. Here we restrict ourselves to a pairwise model. To learn this model we use the pseudo-likelihood based estimator of Jalali et al. (2011). d) Oracle: When the data is generated from a probit model, we also compare with an oracle estimator which has access to the latent variables of the model. Here we run glasso on the latent variables to estimate the graph structure.\nModel Selection: The best tuning parameter for all the estimators described above is selected using 5 fold cross validation. For ProbitEMApprox we use the cross validation technique proposed in (Guo et al., 2015). For ProbitEM, Discrete model, Consec model and Oracle we use the standard cross validation technique where we pick the best tuning parameter based on log likelihood on validation set. For ProbitDirect we use the following k-fold cross validation technique. We partition the data set into k subsets. Let b⌃ i be the covariance matrix output by Step 2 of ProbitDirect, when trained using all the subsets except ith subset. And let ˜⌃i be the raw estimate obtained from Step 1 of ProbitDirect, using ith subset. We pick a which maximizes the following score:\nPk i=1 log det(b⌃ 1 i ) hhb⌃ 1 i , ˜ ⌃iii.\nEvaluation Metrics: We compare the performance of our estimators against baselines, on graph structure recovery, using ROC curves computed by varying the regularization parameter. When the data is generated from a probit model, we compare the parameter estimation performance of Oracle, ProbitEM, ProbitEMApprox and ProbitDirect using Frobenius Loss and Entropy Loss which are defined as: Frobenius Loss = k⌃\n⇤ 1 b⌃ 1kF k⌃⇤ 1kF , Entropy Loss =\nhh⌃⇤, b⌃ 1ii log det(⌃⇤b⌃ 1) p, where ⌃⇤ is the true covariance matrix and b⌃ is the estimated covariance matrix. Finally, we also compare ProbitEM, ProbitEMApprox, ProbitDirect on log likelihood computed on 500 test samples (we do not compare with Discrete model, Consec model because computation of likelihood for these models is infeasible). For comparison on these three metrics, we select the best tuning parameter for each of the methods using cross validation.\nExperimental Settings: In all our experiments we fix the number of nodes in the graph to 50 and set number of categories for each ordinal variable to 5. To reduce the variance, we average results over 10 repetitions."
  }, {
    "heading": "4.1.1. DATA FROM PROBIT MODEL",
    "text": "In our first experiment we generate ordinal data from a probit model. We simulate data from a chain graph. The inverse covariance matrix of the latent variables is chosen as follows:\n⌃ 1 j,k = ( !|j k| if |j k|  1 0 otherwise . (13)\nWe pick an ! 2 ( 1, 1) in our experiments and set the thresholds (✓) at node j as : ✓(j) = [ Inf, 10, 0.7, 0.7, 10, Inf]. Finally we scale the covariance matrix so that all the variances are equal to 1. Fig-\n0 0.1 0.2 0.3 0.4 0.5\nFPR\n0\n0.2\n0.4\n0.6\n0.8\n1\nT P\nR\nn = 50\n0 0.1 0.2 0.3 0.4 0.5\nFPR\n0\n0.2\n0.4\n0.6\n0.8\n1\nT P\nR\nn = 100\n0 0.1 0.2 0.3 0.4 0.5\nFPR\n0\n0.2\n0.4\n0.6\n0.8\n1\nT P\nR\nn = 200\nProbitEMApprox ProbitEM ProbitDirect Consec Model Discrete Model\n0 0.1 0.2 0.3 0.4 0.5\nFPR\n0\n0.2\n0.4\n0.6\n0.8\n1\nT P\nR\nn = 400\nFigure 2. Data sampled from a Consec model with 2D grid structure (10 ⇥ 5 grid). Node specific parameters (✓s) are uniformly sampled from [ 1, 1]. Pairwise interaction terms (✓st) are set to 0.1 for all horizontal edges and to 0.1 for all vertical edges.\nure 1 shows the results obtained using ! = 0.3, 0.9. More results for large n and grid and random graphs can be found in Appendix D. We can seen that ProbitDirect and ProbitEM have similar performance. However, ProbitDirect is 1-2 orders of magnitude faster than ProbitEM. ProbitEMApprox has very poor performance, especially in low sample complexity setting. This could be because of the mean field approximation that is made by Guo et al. (2015), where in the E-step they approximate E[ZjZk|Y ; b⇥, b⌃] as E[Zj |Y ; b⇥, b⌃] ⇥ E[Zk|Y ; b⇥, b⌃]. This decouples the interactions between any two random variables. Also note that ProbitDirect is ⇡ 5 times faster than ProbitEMApprox (See\nTable 1 in Appendix)."
  }, {
    "heading": "4.1.2. DATA FROM CONSECUTIVE RATIO MODEL",
    "text": "In this experiment we sample data from Consec model. Figures 2, 3 present the results on a grid graph along with the details of exact parameters used. When the interaction between variables is low, Consec model has similar performance as other estimators (Figure 2). However, when the interactions are high (Figure 3), its performance degrades. We noticed similar poor performance of Consec model on other graphs. This could suggest that either the node conditional likelihood based estimator for Consecutive Ratio model is not efficient or latent graphical models such as Probit model are better models than Consecutive Ratio model."
  }, {
    "heading": "4.2. Health Information National Trends Survey study",
    "text": "The Health Information National Trends Survey (HINTS) is a nationally representative survey conducted by the National Cancer Institute (NCI) every few years. In this work we analyze HINTS-FDA data which is a special data col-\nlected by NCI in partnership with the Food and Drug Administration (FDA) and is made publicly available by NCI. This survey collected detailed information on the following topics: Tobacco Product Use, Beliefs about Tobacco Products, Beliefs About Cancer, How people access Health Information?, Socio Demographic Indicators. The survey has 3738 respondents on ⇡ 350 questions. Almost all the questions in the survey have either ordinal or categorical responses. Refer to Appendix D for summary statistics of the data and details about preprocessing performed on the data. We treat each question in the survey as a node in the graph and responses of individuals to these questions as samples drawn from the graph. We selected 114 questions from the dataset, that are relevant for our analysis. We fit the probit model using ProbitDirect on the selected questions. To choose the best tuning parameter we use 10 fold cross validation. We obtain 95% confidence intervals for the edge strengths of the latent graph through jackknife resampling technique. We place an edge in the graph only if its confidence interval doesn’t intersect with [ 0.1, 0.1].\nFigure 4 shows how various variables related to sociodemographic indicators are associated with smoking behavior of a person. In particular, it shows that SmokeNow has a very significant association with Education. This indicates that if a person is well educated then conditioned on all the other variables, there is lower chance that the person smokes. In Appendix D, we provide an additional Figure 9, which shows how the perceptions of smoking risks vary with smoking behavior. It shows that SmokeNow and FewCigarettesHarmHealth have a positive partial correlation, indicating that conditioned on the rest of the variables, people who smoke, perceive smoking as less harmful than people who don’t smoke. Table 2 in Appendix D describes some highly relevant nodes in the learned graphs, from which several other insights can be obtained. We believe these insights can be helpful in designing efficient strategies for communicating smoking related health information to the public."
  }, {
    "heading": "5. Acknowledgments",
    "text": "E.Y. acknowledges the support of MSIP/NRF (National Research Foundation of Korea) via NRF2016R1A5A1012966 and MSIP/IITP (Institute for Information & Communications Technology Promotion of Korea) via ICT R&D program 2016-0-00563, 2017-0-00537. A.S., P.R. acknowledge the support of ARO via W911NF-12-1-0390 and NSF via IIS1149803, IIS-1447574, DMS-1264033, and NIH via R01 GM117594-01."
  }],
  "year": 2017,
  "references": [{
    "title": "Analysis of ordinal categorical data, volume 656",
    "authors": ["A. Agresti"],
    "year": 2010
  }, {
    "title": "A log-linear graphical model for inferring genetic networks from high-throughput sequencing data",
    "authors": ["G.I. Allen", "Z. Liu"],
    "venue": "In Bioinformatics and Biomedicine (BIBM),",
    "year": 2012
  }, {
    "title": "Bivariate probit analysis: Minimum chisquare methods",
    "authors": ["T. Amemiya"],
    "venue": "Journal of the American Statistical Association,",
    "year": 1974
  }, {
    "title": "Ordinal regression models for epidemiologic data",
    "authors": ["B. Armstrong", "M. Sloan"],
    "venue": "American Journal of Epidemiology,",
    "year": 1989
  }, {
    "title": "An extended class of marginal link functions for modelling contingency tables by equality and inequality constraints",
    "authors": ["F. Bartolucci", "R. Colombi", "A. Forcina"],
    "venue": "Statistica Sinica,",
    "year": 2007
  }, {
    "title": "A graphical exposition of the ordered probit",
    "authors": ["W.E. Becker", "P.E. Kennedy"],
    "venue": "Econometric theory,",
    "year": 1992
  }, {
    "title": "Spatial interaction and the statistical analysis of lattice systems",
    "authors": ["J. Besag"],
    "venue": "J. Roy. Stat. Soc. Series B,",
    "year": 1974
  }, {
    "title": "A constrained l1 minimization approach to sparse precision matrix estimation",
    "authors": ["T. Cai", "W. Liu", "X. Luo"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2011
  }, {
    "title": "Analysis of multivariate probit models",
    "authors": ["S. Chib", "E. Greenberg"],
    "venue": "Biometrika, pp. 347–361,",
    "year": 1998
  }, {
    "title": "Pairwise likelihood approach to grouped continuous model and its extension",
    "authors": ["A.R. De Leon"],
    "venue": "Statistics & probability letters,",
    "year": 2005
  }, {
    "title": "Sparse inverse covariance estimation with the graphical lasso",
    "authors": ["J. Friedman", "T. Hastie", "R. Tibshirani"],
    "year": 2008
  }, {
    "title": "Inferring cellular networks using probabilistic graphical models",
    "authors": ["N. Friedman"],
    "venue": "Science, 303(5659):799–805,",
    "year": 2004
  }, {
    "title": "Graphical models for ordinal data",
    "authors": ["J. Guo", "E. Levina", "G. Michailidis", "J. Zhu"],
    "venue": "Journal of Computational and Graphical Statistics,",
    "year": 2015
  }, {
    "title": "A composite likelihood approach to latent multivariate gaussian modeling of snp data with application to genetic association",
    "authors": ["F. Han", "W. Pan"],
    "venue": "testing. Biometrics,",
    "year": 2012
  }, {
    "title": "Beitrag zur theorie der ferromagnetismus",
    "authors": ["E. Ising"],
    "venue": "Zeitschrift für Physik,",
    "year": 1925
  }, {
    "title": "On learning discrete graphical models using group-sparse regularization",
    "authors": ["A. Jalali", "P. Ravikumar", "V. Vasuki", "S. Sanghavi"],
    "venue": "In Inter. Conf. on AI and Statistics (AISTATS),",
    "year": 2011
  }, {
    "title": "On the estimation of polychoric correlations and their asymptotic covariance matrix",
    "authors": ["K.G. Jöreskog"],
    "year": 1994
  }, {
    "title": "Graphical models for associations between variables, some of which are qualitative and some quantitative",
    "authors": ["S.L. Lauritzen", "N. Wermuth"],
    "venue": "The Annals of Statistics,",
    "year": 1989
  }, {
    "title": "Composite likelihood methods. Statistical Inference from Stochastic Processes",
    "authors": ["Lindsay", "Bruce G"],
    "venue": "Contemporary Mathematics, pp. 221239,",
    "year": 1988
  }, {
    "title": "The nonparanormal skeptic",
    "authors": ["H. Liu", "F. Han", "M. Yuan", "J. Lafferty", "L. Wasserman"],
    "venue": "In International Conference on Machine learning (ICML),",
    "year": 2012
  }, {
    "title": "Foundations of statistical natural language processing, volume 999",
    "authors": ["C.D. Manning", "H. Schütze"],
    "year": 1999
  }, {
    "title": "Generalized linear models",
    "authors": ["P. McCullagh"],
    "venue": "European Journal of Operational Research,",
    "year": 1984
  }, {
    "title": "The landscape of empirical risk for non-convex losses",
    "authors": ["S. Mei", "Y. Bai", "A. Montanari"],
    "venue": "Arxiv preprint arXiv:1607.06534,",
    "year": 2017
  }, {
    "title": "A general structural equation model with dichotomous, ordered categorical, and continuous latent variable indicators",
    "authors": ["B. Muthén"],
    "year": 1984
  }, {
    "title": "Partial proportional odds models for ordinal response variables",
    "authors": ["B. Peterson", "F.E. Harrell Jr."],
    "venue": "Applied statistics,",
    "year": 1990
  }, {
    "title": "Gaussian Markov distributions over finite graphs",
    "authors": ["T.P. Speed", "H.T. Kiiveri"],
    "venue": "Annals of Statistics,",
    "year": 1986
  }, {
    "title": "Vector-space markov random fields via exponential families",
    "authors": ["W. Tansey", "O.H.M. Padilla", "A.S. Suggala", "P. Ravikumar"],
    "venue": "In ICML, pp",
    "year": 2015
  }, {
    "title": "Graphical models via generalized linear models",
    "authors": ["E. Yang", "P. Ravikumar", "G.I. Allen", "Z. Liu"],
    "venue": "In Neur. Info. Proc. Sys. (NIPS),",
    "year": 2012
  }, {
    "title": "Mixed graphical models via exponential families",
    "authors": ["E. Yang", "Y. Baker", "P. Ravikumar", "G.I. Allen", "Z. Liu"],
    "venue": "In Inter. Conf. on AI and Statistics (AISTATS),",
    "year": 2014
  }, {
    "title": "Graphical models via univariate exponential family distributions",
    "authors": ["E. Yang", "P. Ravikumar", "G.I. Allen", "Z. Liu"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2015
  }, {
    "title": "High dimensional inverse covariance matrix estimation via linear programming",
    "authors": ["M. Yuan"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }],
  "id": "SP:5604c3ce1e25afd0a1500eea630d4e26eb7314f8",
  "authors": [{
    "name": "Arun Sai Suggala",
    "affiliations": []
  }, {
    "name": "Eunho Yang",
    "affiliations": []
  }, {
    "name": "Pradeep Ravikumar",
    "affiliations": []
  }],
  "abstractText": "Undirected graphical models or Markov random fields (MRFs) are widely used for modeling multivariate probability distributions. Much of the work on MRFs has focused on continuous variables, and nominal variables (that is, unordered categorical variables). However, data from many real world applications involve ordered categorical variables also known as ordinal variables, e.g., movie ratings on Netflix which can be ordered from 1 to 5 stars. With respect to univariate ordinal distributions, as we detail in the paper, there are two main categories of distributions; while there have been efforts to extend these to multivariate ordinal distributions, the resulting distributions are typically very complex, with either a large number of parameters, or with non-convex likelihoods. While there have been some work on tractable approximations, these do not come with strong statistical guarantees, and moreover are relatively computationally expensive. In this paper, we theoretically investigate two classes of graphical models for ordinal data, corresponding to the two main categories of univariate ordinal distributions. In contrast to previous work, our theoretical developments allow us to provide correspondingly two classes of estimators that are not only computationally efficient but also have strong statistical guarantees.",
  "title": "Ordinal Graphical Models: A Tale of Two Approaches"
}