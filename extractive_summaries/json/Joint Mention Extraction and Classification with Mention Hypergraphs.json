{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 857–867, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics.\nWe present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets."
  }, {
    "heading": "1 Introduction",
    "text": "One of the essential goals in natural language processing (NLP) is the development of effective systems that can capture the underlying semantics conveyed by human languages. An important step towards such a goal is the development of practical systems that can efficiently extract useful shallow semantic information such as entities and at the same time identify their semantic classes (e.g., person, organization, etc).\nSuch a task is often known as named entity recognition and classification (NERC), one of the standard tasks in information extraction (IE). While such a task focuses on the extraction and classification of entities in the texts which are named, recently researchers also showed interest in a closely related task – mention extraction and classification/typing. Unlike a named entity, a mention is typically defined as a reference to an entity in natural language text that can be either named, nominal or pronominal (Florian et al., 2004). The task of mention detection and tracking has received substantial attention, largely due\nto its important role in conducting several downstream tasks, such as relation extraction (Mintz et al., 2009), entity linking (Guo et al., 2013), and coreference resolution (Chang et al., 2013).\nWhile most existing work on named entity recognition and mention extraction and classification have been effective, there remain several key limitations associated with existing models. In fact, one can view these problems as instances of the more general problem of semantic tagging – the task of assigning appropriate semantic tags to certain text spans for a given input sentence. Unlike part-of-speech (POS) tagging, which has been extensively studied in the past few decades by the community, such a semantic tagging task presents several additional new challenges. First, a mention can consist of multiple words, so its length can be arbitrarily long. Second, the mentions can overlap with one another. Popular models used for POS tagging, such as linear-chain conditional random fields (Lafferty et al., 2001) or semi-Markov conditional random fields (Sarawagi and Cohen, 2004) have difficulties coping with these issues. While approaches on addressing these issues exist, current algorithms typically suffer from high time complexity (Finkel and Manning, 2009) and are therefore difficult to scale to large datasets. On the other hand, the problem of designing efficient and scalable models for mention extraction and classification from natural language texts becomes increasingly important in this era where a large volume of textual data is becoming available on the Web every day – users need systems which are able to scale to extremely large datasets to support efficient semantic analysis for timely decisonmaking.\nIn this paper, we tackle the above-mentioned issue by introducing a novel model for joint mention extraction and classification. We make the following major contributions in this work:\n• We propose a model that is able to effectively\n857\nhandle overlapping mentions with unbounded lengths. • The learning and inference algorithms of our\nproposed model have a time complexity that is linear in the number of words in the input sentence and also linear in the number of possible semantic classes/types, making our model scalable to extremely large datasets. • Our model can additionally capture mentions’\nhead information in a joint manner under the same time complexity.\nOur system and code are available for download from http://statnlp.org/research/ie/."
  }, {
    "heading": "2 Related Work",
    "text": "Existing work has been largely focused on the task of named entity recognition and classification (NERC). The survey of (Nadeau and Sekine, 2007) is a comprehensive study of this topic.\nMost prior work took a supervised learning approach. Zhou and Su (2002) presented a system for recognizing named entities using an HMMbased approach. Florian et al. (2003) presented a system for named entity recognition by combining different classifiers. McDonald and Pereira (2005) used conditional random fields for extracting gene and protein mentions from biomedical texts. Ratinov and Roth (2009) presented a systematic analysis over several issues related to the design of a named entity recognition and classification system where issues such as chunk representations and the choice of inference algorithms were discussed. Researchers also looked into semi-supervised and unsupervised approaches for such a task (Cucchiarelli and Velardi, 2001; Etzioni et al., 2005). Additional efforts on addressing the NERC problem under a multilingual or cross lingual setting also exist (Florian et al., 2004; Che et al., 2013; Wang et al., 2013).\nAs pointed out by Finkel and Manning (2009), named entities are often nested. This fact was often ignored by the community largely due to technical reasons. They therefore proposed to use a constituency parser with a O(n3) time complexity (n is the number of words in the input sentence) to handle nested entities, and showed its effectiveness across several datasets. Alex et al. (2007) also presented several approaches by building models on top of linear-chain conditional random fields for recognizing nested entities in biomedical texts. Hoffmann et al. (2011) looked into a separate\nissue, which is to identify overlapping relations amongst entities.\nNamed entity recognition and classification still remains a popular topic in the field of statistical natural language processing. Ritter et al. (2011) looked into recognizing entities from social media data that involves informal and potentially noisy texts. Pasupat and Liang (2014) looked into the issue of zero-shot entity extraction from Web pages with natural language queries where minimal supervision was used. Neelakantan and Collins (2014) looked into the problem of automatically constructing dictionaries with minimal supervision for improved named entity extraction. Li and Ji (2014) presented an approach to perform the task of extraction of mentions and their relations in a joint and incremental manner."
  }, {
    "heading": "3 Approach",
    "text": ""
  }, {
    "heading": "3.1 Mentions and Their Combinations",
    "text": "Typically, a mention that appears in a natural language sentence consists of a contiguous sequence of natural language words. Consider a sentence that consists of n words where each word is indexed with its position in the sentence. A mention m can be uniquely represented with a tuple 〈bm, em, τ〉, where bm and em are the indices of the first and last word of the mention, respectively, and τ is its semantic class (type).\nWe can see that for a given sentence consisting of n words, there are altogether tn(n + 1)/2 possible different mention candidates, where t is the total number of possible mention types. Now, for each such candidate in the given sentence, it can be either a mention, or not a mention. This leads to a total number of 2tn(n+1)/2 possible mention combinations. This number is prohibitively large even for small values of n and t, which prevents us from exhaustively enumerating all of them during learning and inference.\nOne approach to performing inference over such a large space is to introduce compact representations that are able to encode exponentially many mentions that would enable tractable inference algorithms to be employed. We discuss in the next section our novel mention hypergraph representation proposed for such a purpose."
  }, {
    "heading": "3.2 Mention Hypergraphs",
    "text": "Central to our approach is the introduction of the novel mention hypergraphs that allow us to\ncompactly represent exponentially many possible combinations of potentially overlapping, lengthunbounded mentions of different types.\nA hypergraph is a generalization of a conventional graph, whose edges (a.k.a. hyperedges) can connect two or more nodes. In this work, we consider a special class of hypergraphs, where each hyperedge consists of a designated parent node and an ordered list of child nodes. Hypergraphs have also been used in other fields, such as syntactic parsing (Klein and Manning, 2001), semantic parsing (Lu, 2015) and machine translation (Cmejrek et al., 2013).\nOur mention hypergraphs consist of five types of nodes which are used to compactly represent many mentions of different semantic types and boundaries, namely, A nodes, E nodes, T nodes, I nodes, and X nodes. A partial mention hypergraph is depicted in Figure 1. We describe the definition of each type of nodes next.\n• A nodes. These nodes are used to sequentially arrange mentions with different left boundaries. Specifically, each A node at position k (the k-th word), or Ak, is used to compactly represent all such mentions in the sentence whose left boundaries are exactly at or strictly after k. • E nodes. The node Ek is used to compactly represent all possible mentions (possibly of length zero) whose left boundaries are exactly at the current position k.\n• T nodes. The node Tkj is used to compactly represent all mentions (possibly of length zero) whose left boundaries are exactly at position k, and have the mention type j. • I nodes. The node Ikj is used to compactly\nrepresent all incomplete mentions which contain the current word at position k as part of the mention, and have the mention type j. • X nodes. These are the “terminal” nodes indi-\ncating the completion of a path. No additional node will be attached to such nodes as a child.\nThere are also various hyperedges that connect different nodes in the mention hypergraph. We use 〈α← β1, . . . , βn〉 to denote a hyperedge which connects a parent node α and child nodes β1, . . . , βn. Each hyperedge essentially provides one possible way of re-expressing the semantics conveyed by the parent node using the child nodes. For example, as shown in Figure 1, the hyperedge connecting the parent node Ak and the child nodes Ek,Ak+1 explains the fact that any mention covered by Ak either has a left boundary that is “exactly at k” (Ek), or “exactly at or strictly after k + 1” (Ak+1).\nSimilarly, for each I node, there exist 3 hyperedges that connect it to other child nodes. The top hyperedge (in green) encodes the fact that the current word appears in the middle of a mention; the bottom hyperedge (in yellow) encodes the fact that the current word appears in a mention as the last word; the middle hyperedge (in brown) encodes the fact that both cases can occur at the same time (i.e., the current word belongs to multiple overlapping mentions of the same type). We have the following theorem: Theorem 3.1 Any combination of mentions in a sentence can be represented with exactly one subhypergraph of the complete mention hypergraph.\nProof For each mention, there exists a unique path in the mention hypergraph to represent it. For any combination of mentions, there exist unique paths in the mention hypergraph to represent such a combination. These paths altogether form a unique sub-hypergraph of the original hypergraph.\nFor example, consider the following sentence: “he also talked with the egyptian president .” This sentence contains three mentions. The first is “he” with type PER, the second is “the egyptian president’’ with type PER, and the third mention is “egyptian” with type GPE. Figure 2 gives the subhypergraph structure showing how these mentions\nare jointly represented. The mention hypergraph defined over the input sentence contains exponentially many such sub-hypergraph structures.\nWe note that the converse of Theorem 3.1 is not true. In certain cases, it is possible for two different overlapping mention combinations to share the same mention hypergraph.\nFor example, consider a toy example sentence A B C D shown in Figure 3, both B C and A B C D are mentions of the same type PER (i.e. one is strictly contained by the other. We call such combinations type-I combinations). The above sub-hypergraph shows how to encode such a combination. However, if both A B C and B C D are mentions of the same type PER (i.e., two mentions overlap but no one is contained by the other. We call such com-\nbinations type-II combinations), such a combination shares the same representation as the above sub-hypergraph. Note that such an ambiguity happens only when two overlapping mentions have the same type, and one mention is strictly contained by the other and their boundaries are all different. In practice, however, we found that in the two datasets that we used for evaluations, if two mentions overlap with one another, they almost always form a type-I combination, and type-II combinations are very rare. Empirically, as we will see later in our experiments, our model is effective in handling overlapping mentions."
  }, {
    "heading": "3.3 Log-Linear Modeling",
    "text": "Following the conditional random fields (Lafferty et al., 2001), we adopted a log-linear approach for such a joint mention extraction and typing task. Specifically, for a given input sentence x, the probability of predicting a possible output y (a mention sub-hypergraph that represents a particular combination of mentions) is given as follows:\np(y|x) = exp(w T f(x,y))∑\ny′ exp(wT f(x,y′)) (1)\nwhere f(x,y) is the feature vector defined over the input-output pair (x,y), and the weight vector w gives the parameters of the model.\nOur objective is to minimize the regularized negative joint log-likelihood of the dataset:\nL(w) = ∑\ni log ∑ y′ exp(wT f(xi,y′))\n− ∑\ni\nwT f(xi,yi) + λwTw (2)\nwhere (xi,yi) refers to the i-th training instance, and the last term is a L2 regularization term with λ being a positive scalar (fixed to 0.01 in this work).\nThe gradient of the above objective function is:\n∂L(w) ∂wk\n= ∑\ni\nEp(y′|xi)[fk(xi,y ′)]\n− ∑\ni\nfk(xi,yi) + 2λwk (3)\nwhere wk is the weight of the k-th feature fk. We note that unlike many recent latent-variable approaches to structured prediction (Petrov and Klein, 2007; Blunsom et al., 2008), we are able to represent each of our outputs y with a single fullyobserved structure. Thus, our objective function essentially defines a standard regularized softmax regression model, and is therefore convex (Boyd and Vandenberghe, 2004), where a global optimum can be found.\nThe objective function defined in Equation 2 can be optimized with standard gradient-based methods. We used L-BFGS (Liu and Nocedal, 1989) as our optimization method."
  }, {
    "heading": "3.4 Algorithms",
    "text": "In order to solve the optimization problem described above, one needs to compute the values of the gradient scores in Equation 3. Computation of the second and third terms in this equation is straightforward. The first term in Equation 3 involves the computation of an expectation of feature values over all possible mention combinations for a given input sentence. Following classic dynamic programming algorithms used in graphical models, we develop analogous efficient dynamic programming algorithms that work on hypergraphs and generalize the conventional forward-backward/inside-outside algorithm to efficiently compute such values.\nTime Complexity At each time step k, we need to compute scores for m I nodes, m T nodes, 1 E node, and 1 A node. Hence, the overall time complexity for our algorithm is in O(mn) (assuming computation of the feature scores at each node involves a constant time), where m is the total number of possible mention types, and n is the total number of words in the given sentence. 1\n1Note that the time complexity for the linear chain CRF is in O(m2n) due to their first-order assumption."
  }, {
    "heading": "3.5 Features",
    "text": "The features that we use are inspired by the work of (Carreras et al., 2002). Specifically, we consider the following features defined over the inputs:\n• Words (and POS tags, if available) that appear around the current word (with position information), with a window of size 3. • Word n-grams (and POS n-grams, if available)\nthat contain the current word (with position information), for n = 2, 3, 4. • Bag of words around the current word, with a\nwindow of size 5. • Word pattern features 2.\nNote that these are the indicator functions defined over the inputs. The final set of features are defined over (x,y) tuples, which is obtained as a cross-product between the above indicator functions and the following indicator function:\n• The type of the node (such as T or I). In addition, we also introduce the following fea-\nture defined over the output structure only:\n• The number of such hyperedges that exactly connect one T node and one I node.\nWe call this feature mention penalty. This feature learns a global preference of the number of mentions that should appear in any input sentence."
  }, {
    "heading": "3.6 Joint Modeling of Mention Heads",
    "text": "One additional assumption for the mention extraction and typing task is that each mention comes with a head. A head is strictly a substring of the mention and provides important information about the mention. It is possible to extend our model to support joint modeling of mention heads, while still maintaining the same time complexity.\nDue to space limitations, we could only give a relatively brief description of this extension in this section. The idea is to replace the I nodes with three different types of nodes, namely Ij–B nodes (used to represent words that appear within a mention of type j and before its head), Ij–W nodes (used to represent words that appear within the head of a mention of type j), and Ij–A nodes (used to represent words that appear within a mention of type j and after its head). The hyperedges also need to be established accordingly in order to properly model all possible mention and head\n2all-caps, all-digits, all-alphanumeric, contains-digits, contains-dots, contains-hyphen, initial-caps, lonely-initial, punctuaion-mark, roman-number, single-character, URL.\ncombinations. Since in such a new hypergraph, at each time step, only a constant number (2) of additional nodes are involved, the time complexity for learning and inference with such a model remains the same, which is in O(mn)."
  }, {
    "heading": "3.7 Optimization of F measure",
    "text": "One standard evaluation metric for named entity recognition is the F (F1) measure. In our task, the F measure is defined as the harmonic mean of the precision (P ) and recall (R) scores, where precision is the ratio between the number of correctly predicted mentions and the total number of predicted mentions, and recall is the ratio between the number of correctly predicted mentions and the total number of gold mentions. We will also adopt these metrics in our evaluations later. Unfortunately, the model only optimizes its objective function defined in Equation 2, which is the negative (regularized) joint log-likelihood. Previous work showed it was possible to optimize the F measure in a log-linear model (Suzuki et al., 2006). Culotta and McCallum (2004) also proposed a method for optimizing information extraction performance based on confidence estimation. Their work is based on linear-chain CRF and estimate the confidence of extracted fields based on marginal probabilities. The technique is not directly applicable to our task where a hypergraph representation is used to encode overlapping mentions. In this work, we used a very simple and intuitive technique for optimizing the F measure. The idea is to further tune the weight of a single parameter – mention penalty based on the development set, after the training process completes.\nThis is based on the observation that by increasing the value of the mention penalty, we are essentially forcing our model to predict more mentions. Therefore the recall is a monotonic function with respect to the mention penalty. Based on this fact, we use a simple search algorithm with a fixed step size (we set it to 0.01) to determine the optimal value of the modified mention penalty so that the F measure of the development set is optimized."
  }, {
    "heading": "4 Experiments",
    "text": "In this section, we present empirical evaluations. Our main experiments were conducted on the standard ACE2004 and ACE2005 datasets which contain overlapping mentions. Two additional experiments on the GENIA and CONLL2003 dataset were also conducted ."
  }, {
    "heading": "4.1 Results on ACE",
    "text": "Our primary experiments were conducted based on the English portion of the ACE2004 dataset3 and the ACE2005 dataset4. Following previous work, for ACE2004, we considered all documents from arabic treebank, bnews, chinese treebank, and nwire, and for ACE2005, we considered all documents from bc, bn, nw, and wl . We randomly split the documents for each dataset into three portions: 80% for training, 10% for development, and the remaining 10% for evaluations. The statistics of the datasets are summarized in Table 15. We\n3https://catalog.ldc.upenn.edu/LDC2005T09 4https://catalog.ldc.upenn.edu/LDC2006T06 5Exact train/dev/test splits information can be found on\nhttp://statnlp.org/research/ie/.\ncan observe that overlapping mentions are common – over 30% of the sentences contain overlapping mentions (see row 3 of the table). Mentions can also be very long – over 5% of the mentions consist of more than 6 words, and the longest mention consists of 57 words.\nWe compared our system’s performance with those of several baseline approaches. We first built two simple baseline approaches based on sequence labelling models using the conditional random fields (CRFs). Such approaches can not handle overlapping mentions. To train such models, whenever two mentions overlap with one another in the training set, we remove the mention that is shorter in length. Following (Ratinov and Roth, 2009), we considered the BIO (Begin, Inside, Outside) approach and the BILOU (Begin, Inside, Last, Outside, Unit) approach for designing the output labels. Results show the BILOU approach yields better results. Similar observations were reported in Ratinov and Roth (2009).\nIn the work of (Alex et al., 2007), the authors proposed several approaches for building models to handle nested named entities in biomedical texts. Their best results were obtained from a cascaded approach where they built one model for each named entity class. Outputs from one model can then served as the inputs to the next model for predicting the named entity class of a different type. One fundamental limitation of such an approach is that it being unable to handle overlapping mentions of the same type. Nevertheless, this approach worked very well on both datasets. The results are shown in the row of “CRF (CC)”.6\nAnother class of models that is often used in information extraction are the semi-Markov conditional random fields (semi-CRFs) (Sarawagi and Cohen, 2004). Semi-CRF models are able to capture the non-Markovian properties of mentions. However, they are unable to handle nested or overlapping mentions. We thus used the same method as discussed above to exclude certain mentions for training. Such semi-CRF models typically assume there is a length restriction for the mentions – each mention can consist of up to c words – in order to scale linearly. When such a restriction is lifted, the time complexity of such models becomes quadratic in the number of words in the in-\n6For all such linear chain CRF-related experiments, we used the CRF++ toolkit (https://code.google.com/p/crfpp/) with L-BFGS, which gives us the most competitive results over several different CRF implementations (see: http://www.chokkan.org/software/crfsuite/benchmark.html).\nput sentence. We train two models: one with a length restriction, where c = 6, and the other without a length restriction (c = ∞). For features defined over the inputs, besides the Markovian features described in Sec 3.5, we also used the surface forms of complete mention spans as features. The results of these two models are reported in the fourth and fifth row of Table 2, respectively. Interestingly, imposing the length restriction appears to be helpful for precision, and as a result it makes a positive contribution towards the final F measure.\nOur basic model (MH: mention hypergraph) that optimizes the negative joint log likelihood is able to obtain the best precision across these two datasets. When the model is further augmented with the F measure optimization step described in Sec 3.7 (MH (F )) it consistently yields the best results in terms of both recall score and F measure across these two datasets."
  }, {
    "heading": "4.1.1 Running Time",
    "text": "We also conducted controlled experiments to report the actual execution time of our model and make a comparison with the linear-chain CRF model (BILOU approach). The experiments are all conducted on the ACE2004 dataset on the same machine. To make a proper comparison here, we implemented the linear-chain CRF model using Java (the same language is used when implementing our model), and employed the same data structures for creating features as well as the same learning and inference routines used by our mention hypergraph model.\nTo understand how the features and speed change as we increase the number of mention types (i.e., semantic types), we also conducted experiments where we increase the number of possible mention types. Specifically, we created subtypes from each original type annotated in the dataset. For example, we randomly replaced the type “GPE” by sub-types “GPE1” or “GPE2” in the dataset. This gave us 14 different mention types. Similarly, we could randomly replace the type “GPE” by sub-types “GPE1” – “GPE4”, re-\nsulting in 28 different mention types in total. Our purpose of doing so is to understand how the models behave when the number of possible mention types becomes large. We found that training on the entire training set of ACE2004 using the linearchain CRF model with a large number of mention types was very expensive due to the extremely large number of features involved. We instead trained the models on the development set and presented decoding time on the test set.\nTable 3 shows the results. We empirically captured the relationship between the speed of each system (average number of words processed per second) and the number of mention types. Specifically, we found that as we linearly increased the number of mention types, for the linear-chain CRF model, the number of features grew quadratically and the speed dropped quadratically, whereas for our model, the number of features grew linearly and the speed dropped linearly. This indicates that our model is more scalable to large, practical datasets with a large number of fine-grained mention types."
  }, {
    "heading": "4.1.2 Joint Modeling of Heads",
    "text": "We also conducted experiments on these two datasets for the task of joint modeling of mention boundaries, types and heads. We used the same training and tuning methodology for optimizing the F measure. In such experiments, we adopted a very strict evaluation criterion: a predicted mention is regarded as correct iff and only if its boundaries, type and head all exactly match those of the gold standard.\nWe compared our system’s results with those of several baseline approaches based on CRF where the cascaded BILOU approach described above was always used. Specifically, we considered approaches that always regarded the complete span (CC-S), the first word (CC-F), and the last word (CC-L) as the predicted mention’s head, respectively. We also considered a cascaded approach (CC-CC) where we first predicted mentions, and\nthen predicted their heads by following a similar approach used for predicting overlapping mentions discussed above. The first four rows of Table 4 give the results of these baseline approaches. We can observe that always predicting the last word as the head gives the best performance. Inspired by this, we performed a simple approach by training a model presented in the previous section without considering head information. When making predictions, we always regarded the last word of each predicted mention as its head. The results for such an approach are given in the fifth row of Table 4. The sixth row shows the results obtained by optimizing our model’s objective function. The last row gives the results obtained by tuning the mention penalty based on the development set. As seen, our joint models significantly outperformed all those baseline approaches. We are not aware of any prior work in the literature that performs joint modeling of mention boundaries, types, and heads."
  }, {
    "heading": "4.2 Additional Experiments",
    "text": "We also additionally evaluated on the GENIA dataset (v3.02) whose focus was on biomedical related named entity recognition and classification, where the entities may overlap with one another. Furthermore, to see how our model works on datasets where mentions do not overlap with one another, we also conducted evaluations on the standard CONLL2003 NER dataset."
  }, {
    "heading": "4.2.1 Results on GENIA",
    "text": "We followed the description of Finkel and Manning (2009) to set up our experiments on the GENIA dataset. Specifically, we used the first 90% of the sentences as the training data and the remaining 10% as the evaluation data. We also adhered to the paper’s prescription of collapsing all DNA subtypes into DNA; RNA subtypes into RNA; and all protein subtypes into protein. We kept cell line and cell type, and removed all other entities.\nTo optimize the F measure, we further split the\ntraining set into two portions. We trained a model using the first 90% of the training data, and used the remaining 10% for development. For features, no POS and no bag-of-words features are used.\nWe compared our model’s performance with that of a model based on a constituency parser proposed by (Finkel and Manning, 2009), as well as the semi-CRF model reported there. The results are shown in Table 5. Our model yields a better F measure than the semi-CRF model, but gives a lower performance than the model of (Finkel and Manning, 2009). We note that, however, these results are not directly comparable. Specifically, both of these two previous models relied on an additional 200 million words from PubMed abstracts to learn word clusters as additional features, which we do not have access to.\nOne distinctive advantage of our model is the efficiency and scalability. The model of (Finkel and Manning, 2009) had a time complexity that is cubic in the number of words in the input sentence. In contrast, our model scales linearly as the length of the input sentence increases. 7"
  }, {
    "heading": "4.2.2 Results on CONLL2003",
    "text": "To understand how well our model works on datasets where mentions or entities do not overlap with one another, we conducted additional experiments on the standard dataset used in the CONLL 2003 shared task (Tjong Kim Sang and De Meulder, 2003), where the named entities strictly do not overlap with one another. We compared our system’s performance against that of a baseline version of the state-of-the-art Illinois NER system (Ratinov and Roth, 2009). Their system performed sequential prediction over the input words and adopted the BILOU approach. Their full model also incorporates external knowledge resources (e.g., gazetteers and word class).\nIn order to make a proper comparison with the baseline version of their model, besides the general features we mentioned earlier, we also fol-\n7In our experiments, for this dataset our model tagged over 5,000 words/second. In (Finkel and Manning, 2009), the authors mentioned that their model tagged about 38 words/second, and the semi-CRF model tagged about 45 words/second. However, we note these numbers are not directly comparable due to the advancement of CPU speed.\nlowed (Ratinov and Roth, 2009) in incorporating word’s prefixes and suffixes (of length up to 5) as features, and normalized words referring to months, dates and numbers. Table 6 shows that our system gives an F measure that is comparable to that of the baseline version of their system, where no external resources are used.\nThis additional experiment showed that while our model is designed for handling more realistic scenarios where mentions can overlap, it yields a performance competitive to a state-of-theart system which only handles datasets with nonoverlapping mentions."
  }, {
    "heading": "5 Conclusions",
    "text": "In this work, we have introduced a novel model for the task of joint modeling of mention boundaries, types, as well as their heads. Unlike many previous research efforts for mention extraction and classification, our novel mention hypergraph representations for compactly representing exponentially many possible mentions enables a mention’s boundaries, type and head information to be jointly learned in a single framework. The model scales linearly with respect to the number of words in the input sentence, and performs exact learning where a unique global optimum can be found. Empirically, we have demonstrated the effectiveness of such a model across several standard datasets.\nFuture work include explorations of efficient algorithms for other information extraction tasks, such as joint mention and relation extraction (Li and Ji, 2014) and event extraction (Li et al., 2013). Our system and code can be downloaded from http://statnlp.org/research/ie/."
  }, {
    "heading": "Acknowledgements",
    "text": "We would like to thank Kian Ming A. Chai, Hai Leong Chieu and the three anonymous reviewers for their comments on this work. This work is supported by Temasek Lab of Singapore University of Technology and Design project IGDSS1403011 and IGDST1403013, and is partly supported by DARPA (under agreement number FA8750-13-20008)."
  }],
  "year": 2015,
  "references": [{
    "title": "Recognising nested named entities in biomedical text",
    "authors": ["Beatrice Alex", "Barry Haddow", "Claire Grover."],
    "venue": "BioNLP, pages 65–72. Association for Computational Linguistics.",
    "year": 2007
  }, {
    "title": "A Discriminative Latent Variable Model for Statistical Machine Translation",
    "authors": ["Phil Blunsom", "Trevor Cohn", "Miles Osborne."],
    "venue": "ACL, pages 200–208.",
    "year": 2008
  }, {
    "title": "Convex optimization",
    "authors": ["Stephen Boyd", "Lieven Vandenberghe."],
    "venue": "Cambridge university press.",
    "year": 2004
  }, {
    "title": "Named entity extraction using adaboost",
    "authors": ["Xavier Carreras", "Lluis Marquez", "Lluı́s Padró"],
    "year": 2002
  }, {
    "title": "A Constrained Latent Variable Model for Coreference Resolution",
    "authors": ["Kai-Wei Chang", "Rajhans Samdani", "Dan Roth."],
    "venue": "EMNLP, pages 601– 612.",
    "year": 2013
  }, {
    "title": "Named Entity Recognition with Bilingual Constraints",
    "authors": ["Wanxiang Che", "Mengqiu Wang", "Christopher D Manning", "Ting Liu."],
    "venue": "NAACL-HLT, pages 52–62.",
    "year": 2013
  }, {
    "title": "Flexible and efficient hypergraph interactions for joint hierarchical and forest-to-string decoding",
    "authors": ["Martin Cmejrek", "Haitao Mi", "Bowen Zhou."],
    "venue": "EMNLP, pages 545–555.",
    "year": 2013
  }, {
    "title": "Unsupervised named entity recognition using syntactic and semantic contextual evidence",
    "authors": ["Alessandro Cucchiarelli", "Paola Velardi."],
    "venue": "Computational Linguistics, 27(1):123–131.",
    "year": 2001
  }, {
    "title": "Confidence estimation for information extraction",
    "authors": ["Aron Culotta", "Andrew McCallum."],
    "venue": "HLT-NAACL, pages 109–112.",
    "year": 2004
  }, {
    "title": "Unsupervised named-entity extraction from the web: An experimental study",
    "authors": ["Oren Etzioni", "Michael Cafarella", "Doug Downey", "AnaMaria Popescu", "Tal Shaked", "Stephen Soderland", "Daniel S Weld", "Alexander Yates."],
    "venue": "Artificial Intelligence,",
    "year": 2005
  }, {
    "title": "Nested named entity recognition",
    "authors": ["Jenny Rose Finkel", "Christopher D Manning."],
    "venue": "EMNLP, pages 141–150. Association for Computational Linguistics.",
    "year": 2009
  }, {
    "title": "Named entity recognition through classifier combination",
    "authors": ["Radu Florian", "Abe Ittycheriah", "Hongyan Jing", "Tong Zhang."],
    "venue": "CONLL, pages 168–171. Association for Computational Linguistics.",
    "year": 2003
  }, {
    "title": "A statistical model for multilingual entity detection and tracking",
    "authors": ["Radu Florian", "Hany Hassan", "Abraham Ittycheriah", "Hongyan Jing", "Nanda Kambhatla", "Xiaoqiang Luo", "H Nicolov", "Salim Roukos."],
    "venue": "HLT-NAACL, pages 1–8. DTIC Document.",
    "year": 2004
  }, {
    "title": "To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking",
    "authors": ["Stephen Guo", "Ming-Wei Chang", "Emre Kiciman."],
    "venue": "NAACL-HLT, pages 1020–1030.",
    "year": 2013
  }, {
    "title": "Knowledgebased weak supervision for information extraction of overlapping relations",
    "authors": ["Raphael Hoffmann", "Congle Zhang", "Xiao Ling", "Luke Zettlemoyer", "Daniel S Weld."],
    "venue": "ACL, pages 541–550. Association for Computational Linguistics.",
    "year": 2011
  }, {
    "title": "Parsing and hypergraphs",
    "authors": ["Dan Klein", "Christopher D. Manning."],
    "venue": "IWPT, pages 123–134.",
    "year": 2001
  }, {
    "title": "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
    "authors": ["John Lafferty", "Andrew McCallum", "Fernando CN Pereira."],
    "venue": "ICML.",
    "year": 2001
  }, {
    "title": "Incremental Joint Extraction of Entity Mentions and Relations",
    "authors": ["Qi Li", "Heng Ji."],
    "venue": "ACL, pages 402–412.",
    "year": 2014
  }, {
    "title": "Joint Event Extraction via Structured Prediction with Global Features",
    "authors": ["Qi Li", "Heng Ji", "Liang Huang."],
    "venue": "ACL, pages 73–82.",
    "year": 2013
  }, {
    "title": "On the limited memory BFGS method for large scale optimization",
    "authors": ["Dong C Liu", "Jorge Nocedal."],
    "venue": "Mathematical programming, 45(1-3):503–528.",
    "year": 1989
  }, {
    "title": "Constrained semantic forests for improved discriminative semantic parsing",
    "authors": ["Wei Lu."],
    "venue": "ACL.",
    "year": 2015
  }, {
    "title": "Identifying gene and protein mentions in text using conditional random fields",
    "authors": ["Ryan McDonald", "Fernando Pereira."],
    "venue": "BMC bioinformatics, 6(S6).",
    "year": 2005
  }, {
    "title": "Distant supervision for relation extraction without labeled data",
    "authors": ["Mike Mintz", "Steven Bills", "Rion Snow", "Dan Jurafsky."],
    "venue": "ACL-IJCNLP, pages 1003–1011. Association for Computational Linguistics.",
    "year": 2009
  }, {
    "title": "A survey of named entity recognition and classification",
    "authors": ["David Nadeau", "Satoshi Sekine."],
    "venue": "Lingvisticae Investigationes, 30(1):3–26.",
    "year": 2007
  }, {
    "title": "Learning Dictionaries for Named Entity Recognition using Minimal Supervision",
    "authors": ["Arvind Neelakantan", "Michael Collins."],
    "venue": "EACL, pages 452–461.",
    "year": 2014
  }, {
    "title": "Zero-shot Entity Extraction from Web Pages",
    "authors": ["Panupong Pasupat", "Percy Liang."],
    "venue": "ACL, pages 391–401.",
    "year": 2014
  }, {
    "title": "Discriminative log-linear grammars with latent variables",
    "authors": ["Slav Petrov", "Dan Klein."],
    "venue": "NIPS, pages 1153–1160.",
    "year": 2007
  }, {
    "title": "Design challenges and misconceptions in named entity recognition",
    "authors": ["Lev Ratinov", "Dan Roth."],
    "venue": "CONLL, pages 147–155. Association for Computational Linguistics.",
    "year": 2009
  }, {
    "title": "Named entity recognition in tweets: an experimental study",
    "authors": ["Alan Ritter", "Sam Clark", "Mausam", "Oren Etzioni."],
    "venue": "EMNLP, pages 1524–1534. Association for Computational Linguistics.",
    "year": 2011
  }, {
    "title": "Semimarkov conditional random fields for information extraction",
    "authors": ["Sunita Sarawagi", "William W Cohen."],
    "venue": "NIPS, pages 1185–1192.",
    "year": 2004
  }, {
    "title": "Training conditional random fields with multivariate evaluation measures",
    "authors": ["Jun Suzuki", "Erik McDermott", "Hideki Isozaki."],
    "venue": "COLING/AC, pages 217–224.",
    "year": 2006
  }, {
    "title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
    "authors": ["Erik F Tjong Kim Sang", "Fien De Meulder."],
    "venue": "CONLL, pages 142–147. Association for Computational Linguistics.",
    "year": 2003
  }, {
    "title": "Joint Word Alignment and Bilingual Named Entity Recognition Using Dual Decomposition",
    "authors": ["Mengqiu Wang", "Wanxiang Che", "Christopher D Manning."],
    "venue": "ACL, pages 1073–1082.",
    "year": 2013
  }, {
    "title": "Named entity recognition using an hmm-based chunk tagger",
    "authors": ["GuoDong Zhou", "Jian Su."],
    "venue": "ACL, pages 473–480.",
    "year": 2002
  }],
  "id": "SP:242e786b439aa8bc138902fbf003151f78885a77",
  "authors": [{
    "name": "Wei Lu",
    "affiliations": []
  }, {
    "name": "Dan Roth",
    "affiliations": []
  }],
  "abstractText": "We present a novel model for the task of joint mention extraction and classification. Unlike existing approaches, our model is able to effectively capture overlapping mentions with unbounded lengths. The model is highly scalable, with a time complexity that is linear in the number of words in the input sentence and linear in the number of possible mention classes. Our model can be extended to additionally capture mention heads explicitly in a joint manner under the same time complexity. We demonstrate the effectiveness of our model through extensive experiments on standard datasets.",
  "title": "Joint Mention Extraction and Classification with Mention Hypergraphs"
}