{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Deep neural networks (NNs) have achieved impressive performance in a wide variety of tasks in recent years, however, success is generally in terms of aggregated accuracy metrics. For many real-world applications, it is not enough that on average a model performs well, rather the uncertainty of each prediction must also be quantified. This can be particularly important where there is a large downside to an incorrect prediction: Examples can be found in prognostics, manufacturing, finance, weather, traffic and energy networks. There is therefore interest in how NNs can be modified to meet this requirement (Krzywinski & Altman, 2013; Gal, 2016).\nIn this work the output of prediction intervals (PIs) in regression tasks is considered. Whilst NNs by default output point estimates, PIs directly communicate uncertainty, offering a lower and upper bound for a prediction and assurance that, with some high probability (e.g. 95% or 99%), the realised data point will fall between these bounds. Having this information allows for better-informed decisions.\n1Department of Engineering, University of Cambridge, UK 2Alan Turing Institute, UK. Correspondence to: Tim Pearce <tp424@cam.ac.uk>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nAs an example, a point estimate stating that a machine will fail in 60 days may not be sufficient to schedule a repair, however given a PI of 45-65 days with 99% probability, timing of a repair is easily scheduled.\nA diverse set of approaches have been developed to quantify NN uncertainty, ranging from fully Bayesian NNs (BNNs) (MacKay, 1992), to interpreting dropout as performing variational inference (Gal & Ghahramani, 2015). These require either high computational demands or strong assumptions.\nIn this work we formulate PI output as a constrained optimisation problem. It is self evident that high-quality PIs should be as narrow as possible, whilst capturing some specified proportion of data points (hereafter referred to as the HQ principle). Indeed it is through these metrics that PI quality is often assessed (Papadopoulos et al., 2000; Khosravi et al., 2011b; Galván et al., 2017). We show how a loss function can be derived directly from this HQ principle, and used in an ensemble to produce PIs accounting for both model uncertainty and data noise variance. The key advantages of the method are its intuitive objective, low computational demand, robustness to outliers, and lack of distributional assumption.\nNotably we build on the work of Khosravi et al. (2011a) who developed the Lower Upper Bound Estimation (LUBE) method, incorporating the HQ principle directly into the NN loss function for the first time. LUBE is gaining popularity in several communities, for example in the forecasting of energy demand and wind speed (section 2). However, we have identified several limitations of its current form.\n• Gradient Descent - It was stated that the method was incompatible with gradient descent (GD), a belief carried forward, unchallenged, in all subsequent work (section 2). Implementations therefore require nongradient based methods for training, such as Simulated Annealing (SA) and Particle Swarm Optimisation (PSO). This is inconvenient since GD has become the standard training method for NNs (Goodfellow et al., 2016), used by all modern NN APIs.\n• Loss Form - Its current form suffers from several problems. The function is at a global minimum when all\nPIs are reduced to zero. It was also designed through qualitative assessment of the desired behaviour rather than on a statistical basis.\n• Model Uncertainty - LUBE accounts only for datanoise variance and not model uncertainty (section 2.1). This is an oversimplification (Heskes, 1996), implicitly assuming that training data fully populates the input space, which is seldom the case.\nIn this work we develop a model addressing each of these issues - henceforth referred to as the quality-driven PI method (QD), and QD-Ens when explicitly referring to the ensembled form.\nWe link early literature on PIs for NNs (Tibshirani, 1996; Heskes, 1996; Papadopoulos et al., 2000; Khosravi et al., 2011a), with recent work on uncertainty in deep learning (Hernández-Lobato & Adams, 2015; Gal & Ghahramani, 2015; Lakshminarayanan et al., 2017) - areas which have remained surprisingly distinct. We achieve this by following the same experimental procedure of recent work, assessing performance across ten benchmark regression datasets. We compare QD’s performance with the current best performing model, originally named Deep Ensembles (Lakshminarayanan et al., 2017), here referred to as MVE-Ens. We show that QD outperforms in PI quality metrics, achieving closer to the desired coverage proportion, and reducing average PI width by around 10%."
  }, {
    "heading": "2. Related Work",
    "text": "In this section we consider methods to quantify uncertainty in regression with NNs. Three review papers catalogued early work (Tibshirani, 1996; Papadopoulos et al., 2000; Khosravi et al., 2011b), the latter two specifically considering PIs. Three primary methods were presented:\n• The Delta method adopts theory for building confidence intervals (CIs) used by general non-linear regression models, estimating model uncertainty. It is computationally demanding as it requires use of the Hessian matrix.\n• Mean Variance Estimation (MVE) (Nix & Weigend, 1994) uses a NN with two output nodes - one representing the mean and the other the variance of a normal distribution, allowing estimation of data noise variance. The loss function used is the Negative Log Likelihood (NLL) of the predicted distribution given the data.\n• The Bootstrap (Heskes, 1996) estimates model uncertainty. It trains multiple NNs with different parameter initialisations on different resampled versions of the training dataset. It is easily combined with MVE to estimate total variance.\nIn addition, BNNs treat model parmeters as distributions rather than point estimates (MacKay, 1992), and hence can predict distributions rather than point estimates. Their drawback is that the computational cost of running MCMC algorithms can be prohibitive. Recent work has focused on addressing this (Graves, 2011; Hernández-Lobato & Adams, 2015; Blundell et al., 2015), notably NNs with dropout may be interpreted as performing variational inference (Gal & Ghahramani, 2015).\nLakshminarayanan et al. (2017) produced a modernisation of Heskes’ work (1996), ensembling individual MVE NNs (without resampling the dataset - section 4), and including adversarial training examples. We henceforth refer to this as MVE Ensemble (MVE-Ens). Another MVE extention encourages high uncertainty in data regions not observed by augmenting training data with synthetic ‘out-of-distribution’ samples of high variance (Malinin et al., 2017).\nMany of these modern works complied with an experimental protocol laid out by Hernandez-Lobato & Adams (2015), assessing NLL & RMSE across ten benchmark regression datasets, with MVE-Ens the current best performer. By contrast, the PI literature reports metrics around coverage proportion and PI width.\nLUBE (Khosravi et al., 2011a) was developed on the HQ principle. Originally it was proposed with SA as the training method, and much effort has gone toward trialling it with various non-gradient based training methods including Genetic Algorithms (Ak et al., 2013b), Gravitational Search Algorithms (Lian et al., 2016), PSO (Galván et al., 2017; Wang et al., 2017), Extreme Learning Machines (Sun et al., 2017), and Artificial Bee Colony Algorithms (Shen et al., 2018). Multi-objective optimisation has been found useful in considering the tradeoff between PI width and coverage (Galván et al., 2017; Shen et al., 2018).\nLUBE has been used in a plethora of application-focused work: Particularly in energy load (Pinson & Kariniotakis, 2013; Quan et al., 2014) and wind speed forecasting (Wang et al., 2017; Ak et al., 2013b), but also prediction of landslide displacement (Lian et al., 2016), gas flow (Sun et al., 2017), solar energy (Galván et al., 2017), condition-based maintenance (Ak et al., 2013a), and others. All work has used LUBE as a single NN, making no attempt to account for model uncertainty (section 2.1)."
  }, {
    "heading": "2.1. The Uncertainty Framework",
    "text": "This section describes uncertainty in regression, it is an agglomeration of several prominent works (Tibshirani, 1996; Heskes, 1996; Papadopoulos et al., 2000; Shafer & Vovk, 2008; Mazloumi et al., 2011; Khosravi et al., 2011b; Lakshminarayanan et al., 2017), each of who presented similar concepts but under different guises and terminology. We\nattempt to reconcile them here.\nThe philosophy behind regression is that some data generating function, f(x), exists, combined with additive noise, to produce observable target values y,\ny = f(x) + . (1)\nThe component is termed irreducible noise or data noise. It may exist due to exclusion of (minor) explanatory variables in x, or due to an inherently stochastic process. Some models, for example the Delta method, assume is constant across the input space (homoskedastic), others allow for it to vary (heteroskedastic), for example MVE.\nGenerally the goal of regression is to produce an estimate f̂(x), which allows prediction of point estimates ( is assumed to have mean zero). However, when estimating the uncertainty of y, additional terms must be estimated. Given that both terms of eq. (1) have associated sources of uncertainty, and assuming they are independent, the total variance of observations is given by,\nσ2y = σ 2 model + σ 2 noise, (2)\nwith σ2model termed model uncertainty or epistemic uncertainty - uncertainty in f̂(x) - and σ2noise irreducible variance, data noise variance, or aleatoric uncertainty.\nIt is worth here distinguishing CIs from PIs. CIs consider the distribution Pr(f(x)|f̂(x)), and hence only require estimation of σ2model, whilst PIs consider Pr(y|f̂(x)) and must also consider σ2noise. PIs are necessarily wider than CIs.\nModel uncertainty can be attributed to several factors.\n• Model misspecification or bias - How closely f̂(x) is able to approximate f(x), assuming ideal parameters and plentiful training data.\n• Training data uncertainty or variance - Training data is a sample from an input distribution. There is uncertainty over how representative the sample is, and how sensitive the model is to other samples.\n• Parameter uncertainty - Uncertainty exists around the optimum parameters of the model, increasing in regions sparsely represented in the training data.\nDifferent model types have different weightings for each of these factors (bias-variance trade-off ). Provided the number of hidden neurons is large relative to the complexity of f(x), NNs are considered to have low bias and high variance. Work on uncertainty in NNs therefore generally ignores model misspecification, and only estimates training data uncertainty and parameter uncertainty (Heskes, 1996).\nTo construct PIs, σ2y must be estimated at each prediction point. In regions of the input space with more data, σ2model decreases, and σ2noise may become the larger component\n1. In regions of the input space with little data, σ2model grows.\nLakshminarayanan et al. (2017) recognise this in more intuitive terms - that two sources of uncertainty exist.\n1. Calibration - Data noise variance in regions which are well represented by the training data.\n2. Out-of-distribution - Uniqueness of an input2 - inputs less similar to training data should lead to less certain estimates."
  }, {
    "heading": "3. A Quality-Driven, Distribution-Free Loss Function",
    "text": ""
  }, {
    "heading": "3.1. Derivation",
    "text": "We now derive a loss function based on the HQ principle. Let the set of input covariates and target observations be X and y, for n data points, and with xi ∈ RD denoting the ith D dimensional input corresponding to yi, for 1 ≤ i ≤ n. The predicted lower and upper PI bounds are ŷL, ŷU. A PI should capture some desired proportion of the observations, (1− α), common choices of α being 0.01 or 0.05,\nPr(ŷLi ≤ yi ≤ ŷUi) ≥ (1− α). (3)\nA vector, k, of length n represents whether each data point has been captured by the estimated PIs, with each element ki ∈ {0, 1} given by,\nki = { 1, if yLi ≤ yi ≤ yUi 0, else.\n(4)\nWe define the total number of data points captured as c,\nc := n∑ i=1 ki. (5)\nLet Prediction Interval Coverage Probability (PICP ) and Mean Prediction Interval Width (MPIW ) be defined as,\nPICP := c\nn , (6)\nMPIW := 1\nn n∑ i=1 ŷUi − ŷLi. (7)\n1At the same time, σ2noise may be estimated with more certainty, although uncertainty of this value itself is not generally considered.\n2Conformal prediction provides a framework to assess this.\nAccording to the HQ principle, PIs should minimise MPIW subject to PICP ≥ (1 − α). To minimise MPIW , eq. (7) could simply be included in the loss function, however PIs that fail to capture their data point should not be encouraged to shrink further. We therefore introduce captured MPIW as the MPIW of only those points for which ŷL ≤ y ≤ ŷL holds,\nMPIWcapt. := 1\nc n∑ i=1 (ŷUi − ŷLi) · ki. (8)\nRegarding PICP , we take a likelihood-based approach, seeking NN parameters, θ, that maximise,\nLθ := L(θ|k, α). (9)\nRecognising that each element, ki, is a binary variable taking 1 with probability (1−α), we represent it as a Bernoulli random variable (one per prediction), ki ∼ Bernoulli(1− α). We further assume that each ki is iid. This independence assumption may not hold for data points clustered close together, however we believe holds sufficiently for a randomly sampled subset of all data points, as used in mini-batches for GD. This iid assumption allows the total number of captured points, c, to be represented by a binomial distribution, c ∼ Binomial(n, (1− α)). Substituting in the pmf,\nLθ = ( n\nc\n) (1− α)cαn−c. (10)\nThe factorials in the binomial coefficient make computation inconvenient. However using the central limit theorem (specifically the de Moivre-Laplace theorem) it can further be approximated by a normal distribution. For large n,\nBinomial(n, (1− α)) ≈ N ( n(1− α), nα(1− α) ) (11)\n= 1√\n2πnα(1− α) exp− (c− n(1− α)) 2 2nα(1− α) . (12)\nWe consider this a mild assumption provided a mini-batch size of reasonable number, say > 50, is used.\nIt is common to minimise the NLL rather than maximise the likelihood, this simplifies eq. (12) to,\n− logLθ ∝ (n(1− α)− c)2\nnα(1− α) (13)\n= n\nα(1− α) ((1− α)− PICP )2. (14)\nRemembering that a penalty should only occur in the case where PICP < (1− α) results in a one-sided loss. Combining with eq. (8) and adding a Lagrangian, λ, controlling the importance of width vs. coverage gives a new loss,\nLossQD =\nMPIWcapt. + λ n\nα(1− α) max(0, (1− α)− PICP )2.\n(15)"
  }, {
    "heading": "3.2. Comparison to LUBE",
    "text": "The derived loss function in eq. (15) may be compared to the LUBE loss (Khosravi et al., 2011a),\nLossLUBE =\nMPIW\nr\n( 1 + exp ( λ max(0, (1− α)− PICP ) )) ,\n(16)\nwhere r = max(y) − min(y), is the range of the target variable.\nWhilst still recognisable as having the same objective, the differences are significant, and are summarised as follows.\n• The inclusion of n intuitively makes sense since a larger sample size provides more confidence in the value of PICP , and hence a larger loss should be incurred. Similar arguments follow for α. They remove the need to adjust λ based on batch size and target coverage.\n• A squared term has replaced the exponential. Whilst the RHS for both is minimised when PICP ≥ (1 − α), the squared term was derived based on likelihood whilst the exponential term was selected qualitatively.\n• MPIW now has an additive rather than multiplicative effect. Multiplying has the attractive property of ensuring both terms are of the same magnitude. However it also means that a global minimum is found when all PIs are of zero width. We found in practise that NNs occasionally did produce this undesirable solution.\n• MPIW is no longer normalised by the range of y. Data for a NN should already be normalised during preprocessing. Further normalisation is therefore redundant. It also merely scales the loss by a constant, having no overall effect on the optimisation.\n• MPIWcapt. is used rather than MPIW . As discussed in section 3.1 this avoids the NN benefiting by further reduction of PI widths for missed data."
  }, {
    "heading": "3.3. Training QD with Gradient Descent",
    "text": "It was originally believed that the LUBE loss function was, “nonlinear, complex, and non-differentiable... gradient descent-based algorithms cannot be applied for its minimization” (Khosravi et al., 2011a). This belief has been carried forward, unchallenged, in all subsequent work - see section 2 for numerous examples. It is inconvenient since GD is the standard method for training NNs, so implementations require extra coding effort.\nRegarding the quoted justification, most standard loss functions are nonlinear - e.g. L2 errors - and whilst the LUBE loss function is complex, this does not affect its compatibility with GD3. The non-differentiability comment is partially valid. Because the loss function requires the use of step functions, it is not differentiable everywhere. But this is not an unsurmountable problem: ReLUs are a common choice of activation function in modern NNs, despite not being differentiable when the input is exactly zero4."
  }, {
    "heading": "3.3.1. GD TOY EXAMPLE",
    "text": "LossQD can be directly implemented as shown in Algorithm 1 (LossH ), however it fails to converge to a minimum. We demonstrate why this is the case and how it can be remedied through a toy example.\nConsider a NN as in figure 1 with one input and two output\n3Modern NN APIs generally handle gradient computation automatically, through application of the chain rule to the predefined operations. Provided functions within the API library are used, gradient calculations are automatically handled.\n4Software implementations return one of the derivatives either side of zero when the input corresponds to the undefined point rather than raising an error (Goodfellow et al., 2016).\nneurons, linear activations and no bias. For purposes of clarity, one weight is fixed, w2 = 0.15, to create a one dimensional problem with a single trainable weight, w1. Given 10 data points evenly spaced at x = 1.0, and α = 0.2, the optimal value for ŷU (and therefore w1) is 0.9, which gives the lowest MPIW , subject to PICP ≥ 1−α = 0.8.\nLossQD is plotted in figure 2 (black line). Whilst the global minimum occurs at the desired point, this solution is not found through GD. Given the steepest descent weight update rule with some learning rate τ ,\nw1,t+1 = w1,t − τ ∂LossQD ∂w1,t , (17)\nthe weight shrinks without converging. This is because the gradient, ∂Loss∂w1 , at any point is positive, except for the discontinuities which are never realised.\nTo remediate this, we introduce an approximation of the step function. The sigmoid function has been used in the past as a differentiable alternative (Yan et al., 2004). In eq. (4), k, the captured vector was defined. We redefine this as khard and introduce a relaxed version as follows,\nksoft = σ(s(y − ŷL)) σ(s(ŷU − y)), (18)\nwhere σ is the sigmoid function, and s > 0 is some softening factor. We further define PICPsoft and LossQD−soft by replacing khard with ksoft in equations (6) & (15) respectively - see also LossS in Algorithm 1.\nFigure 2 shows the result of using LossQD−soft (red & blue lines). By choosing an appropriate value for s, following the steepest gradient does lead to a minimum, making GD a\nAlgorithm 1 Construction of loss function using basic operations\nInput: Target values, y, predictions of lower and upper bound, ŷL, ŷU, desired coverage, (1− α), and sigmoid softening factor, s, denotes the element-wise product.\n# hard uses sign step fn, sign returns -1 if -ve, +1 if +ve kHU = max(0, sign(ŷU − y)) kHL = max(0, sign(y − ŷL)) kH = kHU kHL\n# soft uses sigmoid fn kSU = sigmoid((ŷU − y) · s) kSL = sigmoid((y − ŷL) · s) kS = kSU kSL\nMPIWc = reduce sum((ŷU − ŷL) kH)/reduce sum(kH) PICPH = reduce mean(kH) PICPS = reduce mean(kS) LossH = MPIWc+ λ · nα(1−α) ·max(0, (1− α)− PICPH) 2 LossS = MPIWc+ λ · nα(1−α) ·max(0, (1− α)− PICPS) 2\nviable method. Setting s = 160 worked well in experiments in section 6, requiring no alteration across datasets."
  }, {
    "heading": "3.4. Particle Swarm Optimisation",
    "text": "The original LUBE loss function, eq. (16), has been implemented with various evolutionary training schemes that do not require derivatives of the loss function. In order to test the efficacy of LossQD−soft with GD, we compared to an evolutionary-based training method (section 5.1). PSO (Kennedy & Eberhart, 1995) was chosen due to use in recent work with LUBE (Galván et al., 2017; Wang et al., 2017). We make the assumption that other evolutionary methods would offer similar performance (Jones, 2005). See Kennedy & Eberhart (2001) for an introduction to PSO."
  }, {
    "heading": "4. Ensembles to Estimate Model Uncertainty",
    "text": "In section 2.1, two components of uncertainty were defined; model uncertainty and data noise variance. It appears that previous work assumed both were accounted for (section 2). In fact, LUBE & QD only estimate data noise variance, and there is a need to consider the uncertainty of these estimates themselves. This becomes particularly important when new data is encountered. Consider a NN trained for the example in figure 1: Despite being capable of estimating the data noise variance at x = 1.0, if shown new data at x = 2.0 it would predict ŷU = 1.8, with little basis.\nEnsembling models provides a conceptually simple way to deal with this. Recall from section 2.1 that three sources of model uncertainty exist, and that the first, model misspecification, is assumed zero for NNs. Parameter uncertainty can be measured by training multiple NNs with different parameter initialisations (parameter resampling). Training data uncertainty can be done similarly: Sub-sampling from the training set, and fitting a NN to each subset (bootstrap resampling). The resulting ensemble of NNs contains some diversity, and the variance of their predictions can be used as an estimate of model uncertainty.\nRecent work reported that parameter resampling offered superior performance to both bootstrap resampling, and a combination of the two (Lee et al., 2015; Lakshminarayanan et al., 2017). No robust justification has been given for this.\nGiven an ensemble of m NNs trained with LossQD−soft, let ỹU, ỹL represent the ensemble’s upper and lower estimate of the PI. We calculate model uncertainty and hence the ensemble’s PIs as follows,\nȳUi = 1\nm m∑ j=1 ŷUij , (19)\nσ̂2model = σ 2 Ui =\n1\nm− 1 m∑ j=1 (ŷUij − ȳUi)2, (20)\nỹUi = ȳUi + 1.96σUi, (21)\nwhere ŷUij represents the upper bound of the PI for data point i, for NN j. A similar procedure is followed for ỹLi, subtracting rather than adding 1.96σLi."
  }, {
    "heading": "5. Qualitative Experiments",
    "text": "In this section behaviour of QD is qualitatively assessed on synthetic data. Firstly, the GD method of training explained in section 3.3 is compared to PSO. Next, the advantage of QD over MVE (section 2) in data with non-normal variance is shown. Finally, the effectiveness of the ensembled QD approach at estimating model uncertainty is demonstrated.\nSupplementary material contains experimental details as well as numerical results for this synthetic data, covering a full permutation of loss functions and training methods [LUBE, QD, MVE]x[GD, PSO]."
  }, {
    "heading": "5.1. Training method: PSO vs. GD",
    "text": "Comparison of evolutionary methods vs. GD for NN training is its own research topic, and as such analysis here is limited. Preliminary experiments showed that GD performed slightly better than PSO in terms of PICP and MPIW ,\nproducing smoother, tighter boundaries, both more consistently and with lower computational effort. See figure 3 for a graphical comparison of typical PI boundaries. Data was generated by y = 0.3 sin(x) + 0.2 , with ∼ N(0, x4)."
  }, {
    "heading": "5.2. Loss function: QD vs. MVE",
    "text": "Here, the advantage of a distribution-free loss function is demonstrated by comparing MVE, which assumes Gaussian data noise, to QD, which makes no such assumption, on two synthetic datasets. The first was generated as in 5.1 with normal noise, the second with exponential noise, ∼ exp(1/x2).\nFigure 4 shows, unsurprisingly, that MVE outputs PIs very close to the ideal for normal noise, but struggles with exponential noise. QD approximates both reasonably, though does not learn the boundaries well where data is sparse. Though possible to alter MVE to assume an exponential distribution, this would require significant work. With real data, the distribution would be unknown, and likely irregular, putting QD at an advantage."
  }, {
    "heading": "5.3. Model Uncertainty Estimation: Ensembles",
    "text": "This experiment demonstrated the ability of ensembling to estimate model uncertainty. Data was generated through y = 0.02x3 + 0.02 , with ∼ N(0, 32). Figure 5 shows ten individual QD PIs as well as the ensembled PIs. The estimated model uncertainty, σ̂2model, calculated from eq. (20) is overlaid5. Whilst it is difficult to reason about the correctness of the absolute value, its behaviour agrees with the intuition that uncertainty should increase in regions of the input space that are not represented in the training set, here x ∈ [−1, 1], and x > 4, x < −4."
  }, {
    "heading": "6. Benchmarking Experiments",
    "text": "To compare QD to recent work on uncertainty in deep learning, we adopted their shared experimental procedure\n5With uncertainty of the upper and lower bound averaged.\n(Hernández-Lobato & Adams, 2015; Gal & Ghahramani, 2015; Lakshminarayanan et al., 2017). Experiments were run across ten open-access datasets. Models were asked to output 95% PIs and used five NNs per ensemble. See supplementary material for full experimental details. Code is made available online6.\nPrevious work reported NLL & RMSE metrics. However, the important metrics for PI quality areMPIW and PICP (section 1). This meant that we had to reimplement a competing method. We chose to compare QD-Ens to MVE-Ens, since it had reported the best NLL results to date (Lakshminarayanan et al., 2017). We did not include LUBE since ensembling and GD had already been justified in section 5.\nQD-Ens and MVE-Ens both output fundamentally different things; MVE-Ens a distribution, and QD-Ens upper and lower estimates of the PI. To compute NLL & RMSE for QD-Ens is possible only by imposing a distribution on the PI. This is not particularly fair since the attraction of the method is its lack of distributional assumption. Purely for comparison purposes we did this in the supplementary material.\nA fairer comparison is to convert the MVE-Ens output distributions to PIs, and compute PI quality metrics. This was done by trimming the tails of the MVE-Ens output normal distributions by the appropriate amount, which allowed extraction of MPIW , PICP , and LossQD−soft. In our experiments we ensured MVE-Ens achieved NLL & RMSE scores at least as good as those reported in the original work, before PI metrics were calculated.\n6https://github.com/TeaPearce"
  }, {
    "heading": "6.1. Discussion",
    "text": "Full results of PI quality metrics are given in table 1, NLL & RMSE results are included in supplementary material. Given that LossQD−soft is representative of PI quality, QDEns outperformed MVE-Ens on all but one dataset. PICP was generally closer to the 95% target, and MPIW was on average 11.6% narrower. The exception to this was the Kin8nm dataset. In fact, this dataset was synthetic (Danafar et al., 2010), and we suspect that Gaussian noise may have been used in its simulation, which would explain the superior performance of MVE-Ens.\nOne drawback of QD-Ens was the fragility of the training process. Compared to MVE-Ens it required a lower learning rate, was more sensitive to decay rate, and hence needed from two to ten times more training epochs.\nOther comments are as follows. We found λ a convenient lever providing some control over PICP . Bootstrap resampling gave worse performance than parameter resampling, which agrees with work discussed in 4 - we suspect it would work give a much larger ensemble size. We tried to establish a relationship between the normality of residual errors and improvement of QD-Ens over MVE-Ens, but due to the variable power of normality tests analysis was unreliable."
  }, {
    "heading": "7. Conclusions and Future Work",
    "text": "In this paper we derived a loss function for the output of PIs based on the assumption that high-quality PIs should be as narrow as possible subject to a given coverage proportion. We contrasted it with a previous work, justifying differences and showed that it can be used successfully with GD with only slight modification. We described why a single NN using the derived loss function underestimates uncertainty, and that this can be addressed by using the model in an ensemble. On ten benchmark regression datasets, the new model reduced PI widths by over 10%.\nSeveral areas are worth further investigation: Why parameter resampling provides better performance than bootstrap resampling, how model uncertainty could be estimated through dropout or conformal prediction rather than ensembling, and the role that NN architecture plays in estimates of model uncertainty."
  }, {
    "heading": "Acknowledgements",
    "text": "The authors thank EPSRC for funding (EP/N509620/1), the Alan Turing Institute for accommodating the lead author during his work (TU/D/000016), and Microsoft for Azure credits. Personal thanks to Mr Ayman Boustati, Mr HenryLouis de Kergorlay, and Mr Nicolas Anastassacos."
  }],
  "year": 2018,
  "references": [{
    "title": "Uncertainty in Deep Learning",
    "authors": ["Y. Gal"],
    "venue": "PhD thesis,",
    "year": 2016
  }, {
    "title": "Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks",
    "authors": ["J.M. Hernández-Lobato", "R.P. Adams"],
    "venue": "In Proceedings of the 32nd International Conference on Machine Learning,",
    "year": 2015
  }, {
    "title": "Practical confidence and prediction intervals",
    "authors": ["T. Heskes"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 1996
  }, {
    "title": "Comparison of Genetic Algorithm and Particle Swarm Optimisation",
    "authors": ["K.O. Jones"],
    "venue": "International Conference on Computer Systems and Technologies - CompSysTech’2005 COMPARISON,",
    "year": 2005
  }, {
    "title": "Particle swarm optimization",
    "authors": ["J. Kennedy", "R. Eberhart"],
    "venue": "Neural Networks,",
    "year": 1995
  }, {
    "title": "ISBN 978-3-540-74088-9",
    "authors": ["J. Kennedy", "Eberhart", "R. Swarm Intelligence."],
    "venue": "doi: 10.1007/978-3540-74089-6. URL http://link.springer.com/",
    "year": 2001
  }, {
    "title": "Lower upper bound estimation method for construction of neural network-based prediction intervals",
    "authors": ["A. Khosravi", "S. Nahavandi", "D. Creighton", "A.F. Atiya"],
    "venue": "IEEE Transactions on Neural Networks,",
    "year": 2011
  }, {
    "title": "A Comprehensive Review of Neural Network-based Prediction Intervals and New Advances",
    "authors": ["A. Khosravi", "S. Nahavandi", "D. Creighton", "A.F. Atiya"],
    "venue": "IEEE Transactions on Neural Networks,",
    "year": 2011
  }, {
    "title": "Points of Significance",
    "authors": ["M. Krzywinski", "N. Altman"],
    "venue": "Nature Methods,",
    "year": 2013
  }, {
    "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
    "authors": ["B. Lakshminarayanan", "A. Pritzel", "C. Blundell"],
    "venue": "In 31st Conference on Neural Information Processing Systems,",
    "year": 2017
  }, {
    "title": "Why M Heads are Better than One: Training a Diverse Ensemble of Deep Networks",
    "authors": ["S. Lee", "S. Purushwalkam", "M. Cogswell", "D. Crandall", "D. Batra"],
    "year": 2015
  }, {
    "title": "Landslide Displacement Prediction With Uncertainty Based on Neural Networks With Random Hidden Weights",
    "authors": ["C. Lian", "Z. Zeng", "S. Member", "W. Yao", "H. Tang", "C. Lung", "P. Chen"],
    "venue": "IEEE Transactions on Neural Networks and Learning Systems,",
    "year": 2016
  }, {
    "title": "A Practical Bayesian Framework for Backpropagation Networks",
    "authors": ["D.J.C. MacKay"],
    "venue": "Neural Computation,",
    "year": 1992
  }, {
    "title": "Incorporating uncertainty into deep learning for spoken language assessment. ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics",
    "authors": ["A. Malinin", "A. Ragni", "K.M. Knill", "M.J.F. Gales"],
    "venue": "Proceedings of the Conference (Long Papers),",
    "year": 2017
  }, {
    "title": "Prediction intervals to account for uncertainties in neural network predictions: Methodology and application in bus travel time prediction",
    "authors": ["E. Mazloumi", "G. Rose", "G. Currie", "S. Moridpour"],
    "venue": "Engineering Applications of Artificial Intelligence,",
    "year": 2011
  }, {
    "title": "Estimating the mean and variance of the target probability distribution",
    "authors": ["D. Nix", "A. Weigend"],
    "venue": "IEEE International Conference on Neural Networks (ICNN’94), pp. 55–60",
    "year": 1994
  }, {
    "title": "Confidence Estimation Methods for Neural Networks: A Practical Comparison",
    "authors": ["G. Papadopoulos", "P.J. Edwards", "A.F. Murray"],
    "venue": "In European Symposium on Artificial Neural Networks,",
    "year": 2000
  }, {
    "title": "Optimal Prediction Intervals of Wind Power Generation",
    "authors": ["P. Pinson", "G. Kariniotakis"],
    "venue": "IEEE Transactions on Power Systems,",
    "year": 2013
  }, {
    "title": "Uncertainty handling using neural network-based prediction intervals for electrical load",
    "authors": ["H. Quan", "D. Srinivasan", "A. Khosravi"],
    "venue": "forecasting. Energy,",
    "year": 2014
  }, {
    "title": "A tutorial on conformal prediction",
    "authors": ["G. Shafer", "V. Vovk"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2008
  }, {
    "title": "Wind Power Forecasting Using Multi-Objective Evolutionary Algorithms for Wavelet Neural Network-Optimized Prediction Intervals",
    "authors": ["Y. Shen", "X. Wang", "J. Chen"],
    "venue": "Applied Sciences,",
    "year": 2018
  }, {
    "title": "Prediction Interval Construction for Byproduct Gas Flow Forecasting Using Optimized Twin Extreme Learning Machine",
    "authors": ["X. Sun", "Z. Wang", "J. Hu"],
    "venue": "Mathematical Problems in Engineering,",
    "year": 2017
  }, {
    "title": "A Comparison of Some Error Estimates for Neural Network Models",
    "authors": ["R. Tibshirani"],
    "venue": "Neural Computation,",
    "year": 1996
  }, {
    "title": "Wind power interval prediction based on improved PSO and BP neural network",
    "authors": ["J. Wang", "K. Fang", "W. Pang", "J. Sun"],
    "venue": "Journal of Electrical Engineering and Technology,",
    "year": 1975
  }, {
    "title": "Predicting prostate cancer recurrence via maximizing the concordance index",
    "authors": ["L. Yan", "D. Verbel", "O. Saidi"],
    "venue": "In Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining KDD ’04,",
    "year": 2004
  }],
  "id": "SP:a9529ba4a90c5a2111598afed2bb6bbdf4a0d76e",
  "authors": [{
    "name": "Tim Pearce",
    "affiliations": []
  }, {
    "name": "Mohamed Zaki",
    "affiliations": []
  }, {
    "name": "Alexandra Brintrup",
    "affiliations": []
  }, {
    "name": "Andy Neely",
    "affiliations": []
  }],
  "abstractText": "This paper considers the generation of prediction intervals (PIs) by neural networks for quantifying uncertainty in regression tasks. It is axiomatic that high-quality PIs should be as narrow as possible, whilst capturing a specified portion of data. We derive a loss function directly from this axiom that requires no distributional assumption. We show how its form derives from a likelihood principle, that it can be used with gradient descent, and that model uncertainty is accounted for in ensembled form. Benchmark experiments show the method outperforms current state-of-the-art uncertainty quantification methods, reducing average PI width by over 10%.",
  "title": "High-Quality Prediction Intervals for Deep Learning:  A Distribution-Free, Ensembled Approach"
}