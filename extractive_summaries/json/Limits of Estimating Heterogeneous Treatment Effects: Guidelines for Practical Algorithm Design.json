{
  "sections": [{
    "heading": "1. Introduction",
    "text": "The problem of estimating heterogeneous (individualized) causal effects of a treatment from observational data is central in many application domains, including public health and drug development (Foster et al., 2011), computational\n1University of California, Los Angeles, USA 2University of Oxford, Oxford, UK 3Alan Turing Institute, London, UK. Correspondence to: Ahmed M. Alaa <ahmedmalaa@ucla.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nadvertising (Bottou et al., 2013), and social sciences (Xie et al., 2012). The increasing availability of observational data in all these domains has encouraged the development of various machine learning algorithms tailored for inferring treatment effects using observational data (e.g. (Li & Fu, 2017; Wager & Athey, 2017; Shalit et al., 2017; Alaa & van der Schaar, 2017)). Due to the peculiarity of the treatment effect estimation problem, these algorithms needed to address various modeling aspects that are foreign to standard supervised learning setups; such aspects include ways to handle sample selection bias (Heckman, 1977), and ways to model treated and untreated data points. Despite a variety of recent algorithmic approaches, principled guidelines for model design are lacking.\nIn this paper, we identify guiding principles for designing practical treatment effect estimation algorithms in the context of Bayesian nonparametric inference, and propose one an algorithm that follows these guidelines. We set these guidelines by characterizing the fundamental limits of estimating treatment effects, and studying the impact of various common modeling choices on the achievability of those limits. In what follows, we provide a brief technical background for the treatment effect estimation problem, along with a summary of our contributions."
  }, {
    "heading": "1.1. Background and Summary of Contributions",
    "text": "Our analysis hinges on the Rubin-Neyman potential outcomes model (Rubin, 2005). That is, we consider an observational dataset with a population of subjects, where each subject i is endowed with a d-dimensional feature Xi ∈ X . We assume that X = [0, 1]d, but most of our results hold for general compact metric spaces (bounded, closed sets in Rd). A treatment assignment indicator Wi ∈ {0, 1} is associated with subject i; Wi = 1 if the treatment under study was applied to subject i, and Wi = 0 otherwise. Subject i’s responses with and without the treatment (the potential outcomes) are denoted as Y (1)i and Y (0)\ni , respectively. Treatments are assigned to subjects according to an underlying policy that depends on the subjects’ features, i.e. Wi ⊥̸⊥ Xi. This dependence is quantified via the conditional distribution p(x) = P(Wi = 1|Xi = x), also known as the propensity score of subject i (Rosenbaum & Rubin,\n1984). The response Y (Wi)i is the “factual outcome” which we observe in the data, whereas Y (1 − Wi)i is the unrealized “counterfactual outcome” (Bottou et al., 2013). An observational dataset Dn comprises n samples of the form: Dn = {Xi,Wi, Y (Wi)i }ni=1 (1) The causal effect of the treatment on subject i with a feature Xi = x is characterized through the conditional average treatment effect (CATE) function T (x), which is defined as the expected difference between the two potential outcomes (Rubin, 2005), i.e. T (x) = E[Y (1)i − Y (0)i |Xi = x ] (2) Our goal is to identify a set of guiding principles for building estimators of the CATE T (x) using samples from Dn. Throughout the paper, we will assume that the joint density dP(Xi,Wi, Y (0)i , Y (1)\ni ) supports the assumptions of unconfoundedness and overlap, which are necessary for causal identifiability and consistency. Unconfoundedness requires that (Y (0)i , Y (1)\ni )⊥⊥ Wi |Xi, whereas overlap requires that 0 < p(x) < 1 (Rosenbaum & Rubin, 1984). Selection bias occurs in Dn since the distribution of the treated/control subjects does not match that of the overall population.\nIn order to come up with principled guidelines for building estimators of T (x), we characterize the fundamental (information-theoretic) limits of estimating the CATE using samples from Dn, and identify the modeling choices that would allow achieving those limits. To this end, in Section 3 we tackle the following question: what are the fundamental limits of CATE estimation? We answer this question by deriving the optimal minimax rate for estimating T (x) using Dn. Interestingly, it turns out that the optimal rate does not depend on selection bias, but rather on the smoothness and sparsity of the more “complex” of the functions E[Y (0)i |Xi = x ] and E[Y (1) i |Xi = x ]. We focus our analysis on Bayesian nonparametric methods, since they have the appealing properties of being robust to misspecification and are accessible for theoretical analysis.\nOur analysis reveals that the relative importance of the different modeling aspects vary with the sample size. In particular, in the large-sample regime, selection bias does not pose a serious problem, and the model’s performance would be mainly determined by its structure, i.e. the way the outcomes Y (0)i and Y (1) i are modeled, and the impact of that on variable selection and hyperparameter tuning. On the contrary, selection bias can seriously harm a model’s generalization performance in small-sample regimes. A good model should then be carefully designed so that it operates well in both regimes by possessing the right model structure that would allow learning at a fast rate, and the right model selection (hyperparameter optimization) scheme that would account for selection bias.\nIn Section 4, we build a practical CATE estimation algorithm guided by the results of the analyses in Section 3. We model the outcomes Y (0)i and Y (1) i using a Gaussian process with a non-stationary kernel that captures the different relevant variables and different levels of smoothness of the functions E[Y (0)i |Xi = x ] and E[Y (1) i |Xi = x ]. We prove that this model structure can achieve the optimal rate of CATE estimation when tuned with the right hyperparameters. We also propose a doubly-robust hyperparameter optimization scheme that accounts for selection bias in smallsample regimes, without hindering the model’s minimaxoptimality in the large sample limit. We show that our algorithm outperforms state-of-the-art methods using a wellknown semi-synthetic simulation setup."
  }, {
    "heading": "1.2. Related Work",
    "text": "Very few works have attempted to characterize the limits of CATE estimation, or study the impact of different modeling choices on the CATE estimation performance in a principled manner. (Alaa & van der Schaar, 2018) characterized the asymptotic “information rates” for different CATE estimators, but provided no clear guidelines on practical model design or an analysis of the impact of sample selection bias. The study in (Künzel et al., 2017) was rather empirical in nature, comparing the performance of different regression structures for the potential outcomes while ignoring selection bias. A similar study, but focusing only on random forest models, was conducted in (Lu et al., 2017).\nMost of the previous works have been algorithmic in nature, focusing mainly on devising algorithms that correct for selection bias (e.g. (Johansson et al., 2016; Yoon et al., 2018; Wager & Athey, 2017; Li & Fu, 2017)). Some of these works cast the selection bias problem as a problem of covariate shift (Sugiyama et al., 2007), and use techniques from representation learning to learn feature maps that balance the biased data (e.g. (Li & Fu, 2017; Shalit et al., 2017; Johansson et al., 2016)). However, those works report much bigger improvements in CATE estimation when changing their model structure (e.g. architecture of a neural network), as compared to the gains attained by only accounting for bias (see the comparisons between the TARnet and BNN models in (Shalit et al., 2017)). Similar observations are reported in (Alaa & van der Schaar, 2017; Atan et al., 2018), where the selection of the model structure seemed to influence the achieved CATE estimation performance even when selection bias is not accounted for. However, none of these works offer a discussion on whether selection bias is actually the main challenge in CATE estimation, or whether the outcomes’ model structure may have a bigger influence on performance.\nIn contrast to the works above, this paper does not attempt to develop a model by presupposing that particular model-\ning aspects are of greater importance than others, but rather provides a framework for understanding the limits on the achievable performance, and how different modeling aspects influence a model’s chance of achieving those limits. We use our analyses to both reflect on the modeling choices made in the works above, and also devise a novel, principled CATE estimation algorithms that achieves the fundamental performance limits."
  }, {
    "heading": "2. Estimating CATE: Problem Setup",
    "text": ""
  }, {
    "heading": "2.1. Potential Outcomes & Propensity Score",
    "text": "We consider the following random design regression model for the potential outcomes:\nY (w)i = fw(Xi) + εi,w, w ∈ {0, 1}, (3)\nwhere εi,w ∼ N (0, σ2w) is a Gaussian noise variable. It follows from (2) that the CATE is T (x) = f1(x) − f0(x). The response surfaces f1(x) and f0(x) correspond to the subjects’ responses with and without the treatment.\nWe assume that fw(.) : X → R, w ∈ {0, 1}, is a totally bounded function that lives in a space of “smooth” or “regular” functions, with an unknown smoothness parameter αw. We use Hölder balls for concreteness, although our results extend to other function spaces. A function fw(.) lies in the Hölder ball Hαw , with a Hölder exponent αw > 0, if and only if it is bounded in sup-norm by a constant C > 0, all its partial derivatives up to order ⌊αw⌋ exist, and all its partial derivatives of order ⌊αw⌋ are Lipschitz with exponent (αw − ⌊αw⌋) and constant C. The Hölder exponents quantify the complexities of f0 and f1, and hence the hardness of estimating T (x) would depend on α0 and α1."
  }, {
    "heading": "2.2. Bayesian Nonparametric Inference",
    "text": "Nonparametric inference is immune to misspecification of the outcomes’ and propensity models (Kennedy, 2018), and hence we focus on Bayesian nonparametric methods for inferring T (.) on the basis of Dn. Bayesian inference entails specifying a prior distribution Π over f1(.) and f0(.), i.e.\nf0, f1 ∼ Π(φ̄β0 , φ̄β1), (4)\nwhere φ̄βw = {φkβw} ∞ k=1, w ∈ {0, 1}, are complete orthonormal bases (indexed by a parameter βw > 0) with respect to Lebesgue measure in X , fw = ∑ k f̄ k w ·φkβw , and f̄kw = ⟨fw, φkβw⟩. Thus, for given bases φ̄β0 and φ̄β1 , Π places a probability distribution on the projections {f̄kw}k. Potential choices for the basis φ̄βw that would give rise to implementable Bayesian inference algorithms include regular wavelet basis (Zhang, 1997), radial basis for a reproducing kernel Hilbert space (RKHS) (van der Vaart et al., 2008), etc. In general, the parameter βw would determine the smoothness of the function space spanned by φ̄βw ."
  }, {
    "heading": "2.3. Towards Principled CATE Estimation",
    "text": "To evaluate the predictive accuracy of the Bayesian inference procedure, we analyze the “frequentist” loss of point estimators T̂ (x) induced by the Bayesian posterior dΠn(T (x) | Dn), assuming that Dn is generated based on fixed, true response surfaces f1(x) and f0(x). (This type of analysis is sometimes referred to as the “FrequentistBayes” analysis (Sniekers et al., 2015).) In particular, we quantify the performance of a point estimator T̂ (x) = δ(dΠn(T (x) | Dn)) by its squared-L2(P) error, which was dubbed the precision of estimating heterogeneous effects (PEHE) in (Hill, 2011), and is formally defined as:\nψ(T̂ ) , E ∥ T̂ − T ∥2 L2(P), (5)\nwhere L2(P) is the L2 norm with respect to the feature distribution, i.e. ∥f(x)∥2 L2(P) = ∫ f2(x) dP(X = x).\nNot a standard supervised learning problem...\nThe “fundamental problem of causal inference” is that for every subject i in Dn, we only observe the factual outcome Y (Wi)i , whereas the counterfactual Y (1 − Wi) i remains unknown, which renders empirical evaluation of the PEHE in (5) impossible. Moreover, Dn would generally exhibit sample selection bias (Heckman, 1977), because the treatment assignment mechanism (decided by p(x)) creates a discrepancy between the feature distributions of the treated/control population and the overall population. Thus, standard supervised learning approaches based on empirical risk minimization cannot be used to learn a generalizable model for the CATE from samples in Dn. This gives rise to the following fundamental modeling questions that are peculiar to the CATE estimation problem:\n• [Q1]: How should the treatment assignment indicator Wi be incorporated into the learning model?\n• [Q2]: How should selection bias be handled?\nAdequate answers to [Q1] and [Q2] would provide guidelines for selecting the prior Π(φ̄β0 , φ̄β1). Addressing the modeling questions above requires a profound understanding of the fundamental limits of CATE estimation, in addition to an understanding of the impact of different modeling choices on the achievability of such limits. The next Sections provide principled answers to [Q1] and [Q2] by addressing the following, more fundamental questions:\nSection 3: What are the limits on the performance that can be achieved by any estimator of the CATE?\nSection 4: How can we build practical algorithms that can achieve the performance limits?"
  }, {
    "heading": "3. Fundamental Limits of CATE Estimation",
    "text": "In this Section, we establish an information-theoretic limit on the performance of any CATE estimator. In what follows, we use the standard Bachmann-Landau order notation, and write a∨ b = max{a, b}, a∧ b = min{a, b}. The notation a . b means that a ≤ Cb for a universal constant C, and ≍ denotes asymptotic equivalence."
  }, {
    "heading": "3.1. Optimal Minimax Rates",
    "text": "The “hardness” of a nonparametric estimation problem is typically characterized by its minimax risk (Stone, 1982), i.e. the minimum worst case risk achieved by any estimator when the estimand is known to live in a given function space (Yang et al., 2015). In the following Theorem, we establish the optimal minimax rate for the PEHE risk in terms of the complexity of the response surfaces f0 and f1.\nTheorem 1. Suppose that X = [0, 1]d, and that fw depends on a subset of dw features with dw ≤ min{n, d} for w ∈ {0, 1}. If f0 ∈ Hα0 and f1 ∈ Hα1 , then the optimal minimax rate is:\ninf T̂ sup f0,f1\nψ(T̂ ) ≍ n− ( 1+ 1 2 ( d0 α0 ∨ d1 α1 ))−1︸ ︷︷ ︸ CATE estimation\n∨ log ( dd0+d1\nd d0 0 d d1 1\n) 1 n\n.︸ ︷︷ ︸ Variable selection\nThe above holds for any p(.) ∈ Hαp , αp > 0.\nIn Theorem 1, the supremum is taken over αw-Hölder balls (w ∈ {0, 1}), whereas the infimum is taken over all possible Bayesian estimators. The minimax rate in Theorem 1 corresponds to the fastest rate by which any (Bayesian) estimator T̂ (.) can approximate the CATE function T (.). The proof of Theorem 1 (provided in the supplement) uses information-theoretic techniques based on Fano’s method to derive algorithm-independent estimation rates (Yang & Barron, 1999). In the following set of remarks, we revisit [Q1] and [Q2] in the light of the results of Theorem 1.\nHow can Theorem 1 help us address [Q1] & [Q2]?\n◃ Remark 1 (Smoothness & sparsity)\nTheorem 1 says that estimating CATE is as hard as nonparametric regression for functions with additive sparsity (Raskutti et al., 2009; Yang et al., 2015). The minimax rate in Theorem 1 decomposes into a term reflecting the complexity of CATE estimation under correct variable selection for f0 and f1, and a term reflecting the complexity of variable selection. Variable selection complexity remains small as long as log(d) = Θ(nζ), for some ζ ∈ (0, 1), and approaches the parametric rates as ζ → 0. The minimax rate will generally be dominated by the complexity of CATE estimation, and will approach the parametric rates only for very smooth response surfaces with small number of relevant dimensions, i.e. d0α0 ∨ d1 α1 → 0.\nThe main takeaway from Theorem 1 is that the CATE learning rate is determined by the more “complex” of the surfaces f0 and f1, where complexity is quantified by the sparsity-to-smoothness ratio dw/αw for w ∈ {0, 1}. Thus, a model would achieve the optimal CATE learning rate only if it selects the correct relevant variables for f0 and f1, and tunes its “hyperparameters” (i.e. smoothness of the prior) to cope with a complexity of d0α0 ∨ d1 α1 . When d0α0 and d1 α1\nare very different (e.g. f0 and f1 have different relevant features), rate-optimal estimation is possible only if the model incorporates such differences in Π(φ̄β0 , φ̄β1).\nThe discussion above provides a concrete answer to [Q1]: the treatment assignment variablew should be incorporated into the model in such a way that it encodes the different relevant dimensions and smoothness levels of f0 and f1 in the bases φ̄β0 and φ̄β1 . (The simplest way to achieve this is to use two separate models for f0 and f1.) This is not fulfilled by many of the previous models that built a single regression function of the from f : X ×{0, 1} → R, and estimated the CATE as T̂ (x) = f(x, 1)−f(x, 0) (Hill, 2011; Johansson et al., 2016; Powers et al., 2017). This is because such models enforced the smoothness of the prior along all features to be the same for w = 0 and w = 1.\n◃ Remark 2 (Selection bias)\nTheorem 1 gives a rather surprising answer to [Q2]: the optimal learning rate is oblivious to selection bias. Such a finding is consistent with previous results on nonparametric kernel density estimation under selection bias (Borrajo et al., 2017), and parametric Bayesian inference under covariate shift (Shimodaira, 2000; Sugiyama & Storkey, 2007). It shows that many of the recent works have missed the target; the works in (Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017) cast the problem of CATE estimation as one of covariate shift that results from selection bias. However, Theorem 1 says that selection bias is not a problem when we have a sufficiently large amount of data. This is because selection bias is inherently a misspecification problem, and hence its impact on nonparametric inference is washed away in large-sample regimes.\nRemarks 1 and 2 posit an explanation for various recurrent (empirical) findings reported in previous literature. For instance, (Hahn et al., 2017) found that separate modeling of f0 and f1 via Bayesian additive regression trees (BART) outperforms the well-known single-surface BART model developed in (Hill, 2011). Similar findings were reported for models based on Gaussian processes (Alaa & van der Schaar, 2017), and models based on deep neural networks (Shalit et al., 2017). All such findings can be explained in the light of Remark 1. On the other hand, Remark 2 may provide an explanation as to why the “TARnet” model in (Shalit et al., 2017), which models f0 and f1 using separate neural networks and does not account for selection\nbias, outperformed the “BNN” model in (Johansson et al., 2016), which regularizes for selection bias but fits a singleoutput network for f0 and f1."
  }, {
    "heading": "3.2. Backing off from “Asymptopia”",
    "text": "Theorem 1 shows that selection bias does not hinder the optimal minimax rates, and that it is only the structural properties of the prior Π(φ̄β0 , φ̄β1) that determine a model’s rate of learning. But does the achieved learning rate suffice as a sole criterion for addressing the modeling questions [Q1] and [Q2]? The answer is “yes” only if Dn comes from a large observational dataset, in which case the learning rate suffices as a descriptor for the large-sample performance. However, if Dn is small, which is typical in posthoc analyses of clinical trials (Foster et al., 2011), then one should make the design choices that would optimize the small-sample performance. In order to give a more complete picture of the performance in large and small-sample regimes, we derive the following bound on the PEHE:\nψ(T̂ ) ≤ C̄ · exp(D2(Q0 ∥Q)) · ∥f0 − f̂0∥2L2(P0) + C̄ · exp(D2(Q1 ∥Q)︸ ︷︷ ︸\nRéyni Divergence ) · ∥f1 − f̂1∥2L2(P1)︸ ︷︷ ︸ Supervised learning loss , (6)\nfor some C̄ > 0, where L2(Pw), for w ∈ {0, 1}, is the L2 norm with respect to dP(X = x |W = w), Q = dP(X = x), Qw = dP(X = x |W = w), and Dm(p ∥ q) is the mth order Réyni divergence. The bound in (6) holds for all n > 0, and is tight (refer to the supplement); it shows that the PEHE is a weighted linear combination of the mean squared losses for the two underlying supervised problems of learning f0 and f1 with no covariate shift, where the weights are determined by the extent of the mismatch between the distributions of the treated and control populations, quantified by the Réyni divergence measure. If Dn is a dataset obtained from a randomized controlled trial (Q = Q0 = Q1), then we have D2(Q0 ∥Q) = D2(Q1 ∥Q) = 0, and the bound boils down to a sum of two supervised learning losses, i.e. ψ(T̂ ) ≤ C̄ · ∥f0 − f̂0∥2L2(P) + C̄ · ∥f1 − f̂1∥ 2 L2(P).\nSince the minimax rate for standard nonparametric regression is ∥fw − f̂w∥22 ≍ Cw · n −2αw 2αw+dw (Stone, 1982), when d0/α0 >> d1/α1, the first-order Taylor approximation for the logarithm of the PEHE in (6) is given by:\nlog(ψ(T̂ )) ≈D2(Q0∥Q)︸ ︷︷ ︸ Selection\nbias\n+ log(C0)︸ ︷︷ ︸ Bias\ncorrection\n− 2α0 2α0 + d0︸ ︷︷ ︸\nLearning rate\nlog(n)\n+O ( n −2α1 2α1+d1 + 2α0 2α0+d0 ) . (7)\nThat is, when viewed on a log-log scale, the behavior of the PEHE versus the number of samples can be described\nas follows. log(PEHE) is a linear function of log(n). Selection bias adds a constant offset to log(PEHE), but does not affect its slope, which harms the performance only in the small-sample regime. In the large-sample regime, the slope of log(PEHE), which depends solely on the smoothness and sparsity of the response surfaces, dominates the performance, and selection bias becomes less of a problem. Figure 1 depicts the PEHE in (7) on a log-log scale."
  }, {
    "heading": "4. CATE Estimation using Non-Stationary Gaussian Process Regression",
    "text": "In this Section, we build on the analyses conducted in Section 3 to design a practical algorithm for CATE estimation."
  }, {
    "heading": "4.1. Non-Stationary Gaussian Process Priors",
    "text": "We specify the prior Π(φ̄β0 , φ̄β1) as a Gaussian process (GP) over functions of the form g : X × {0, 1} → R, with a kernel Kβ , and a hyperparameter set β as follows:\ng ∼ GP (0,Kβ(z, z′)) , (8)\nwhere z = (x,w) ∈ X × {0, 1}, and fw(x) = g(x,w). The kernel Kβ specifies the bases φ̄β0 and φ̄β1 through its induced canonical feature map Kβ(., z) (Rasmussen & Williams, 2006; Alvarez et al., 2012). As pointed out in remark 1, the treatment assignment variable w should encode the different relevant dimensions and smoothness levels of f0 and f1. Thus, we model Kβ as a non-stationary kernel that depends explicitly on w as follows:\nKβ(z, z ′)= Γ(w,w′) · kTβ (x, x′), kβ(x, x ′)= [kβ0(x, x ′), kβ1(x, x ′), kβ0(x, x ′) + kβ1(x, x ′)],\nΓ(w,w′)= [Γ0(w,w ′), Γ1(w,w ′), 1− Γ0(w,w′)− Γ1(w,w′)],\nwhere Γ0(w,w′) = (1− w)(1− w′), Γ1(w,w′) = w · w′, and kβw(x, x ′) is a Matérn kernel with a length-scale parameter\nβw, for w ∈ {0, 1}. The kernel defined above ensures that any covariance matrix induced by points in X × {0, 1} is positive definite. Variable selection is implemented by using the automatic relevance determination version of the Matérn kernel (Rasmussen & Williams, 2006). The nonstationarity of Kβ allows setting different length-scales and relevant variables for the marginal priors on f0 and f1 while sharing data between the two surfaces, i.e.\nKβ((x,w), (x ′, w))= kβw (x, x ′), w ∈ {0, 1}, Kβ((x,w), (x ′, w′))= kβ0(x, x ′) + kβ1(x, x ′), w ̸= w′. (9)\nThat is, all draws from the prior give Matérn sample paths with different smoothness levels (β0 and β1) for f0 and f1, respectively, and the correlations between the paths are captured via the kernel mixture kβ0(x, x ′) + kβ1(x, x ′). Note that draws from a Matérn prior with length-scale β are almost surely β̄-Hölder for all β̄ ≤ β (Vaart & Zanten, 2011). Thus, GP(0,Kβ) specifies a βw-Hölder ball as an a priori regularity class for response surface fw, w ∈ {0, 1}.\nIn the following Theorem, we show that point estimators induced by the prior GP(0,Kβ) can achieve the optimal minimax rate in Theorem 1.\nTheorem 2. Suppose that the dw relevant features for fw are known a priori for w ∈ {0, 1}. If f0 ∈ Hα0 , f1 ∈ Hα1 , Π = GP(0,Kβ), and T̂ = EΠ [T | Dn ], then we have that\nψ(T̂ ) . n− 2(α0∧β0) 2β0+d0 ∨ n− 2(α1∧β1) 2β1+d1\nwhenever min{α0, α1, β0, β1} ≥ d/2.\nNote that posterior consistency holds for all combinations of (α0, α1, β0, β1) since the support of the Matérn prior is the space of bounded continuous functions1. The bound in Theorem 2 can be shown to be tight using the results in (Castillo, 2008). Theorem 2 says that the posterior induced by the prior GP(0,Kβ) contracts around the true CATE function at the optimal rate given in Theorem 1 provided that the following matching condition is met:\nβv = αv\nαv d1−v dv ≤ β1−v ≤ α1−v + α1−v ·dv2αv − d1−v 2 , (10)\nwhere v = 1 if d1/α1 > d0/α0, and v = 0 otherwise. The condition in (10) implies that achieving the optimal rate (steepest slope in Figure 1) via the non-stationary GP prior in Section 4.1 is only a matter of hyperparameter tuning: the smoothness of the prior needs to match the smoothness of the “more complex” of the two response surfaces. Note that Theorem 2 implies that we do not need to handle selection bias in order to achieve the optimal rate, which is consistent with the earlier discussion in remark 2.\n1This is because the RKHS associated with the prior lies dense in the space of bounded continuous functions (van der Vaart & van Zanten, 2008; van der Vaart et al., 2008)."
  }, {
    "heading": "4.2. Doubly-Robust Hyperparameters",
    "text": "Theorem 2 says that the optimal minimax rate for CATE estimation can be achieved by satisfying the smoothness matching condition in (10). However, in practice, the smoothness levels of the true response functions are unknown and need to be learned from the data. Moreover, since selection bias is impactful in small-sample regimes, ignoring it may lead to a poor generalization performance when the size of Dn is small. In this Section, we propose a hyperparameter optimization algorithm that accounts for selection bias while ensuring minimax-optimality in the large-sample limit.\nPrevious works tend to adjust for selection bias “mechanically” using variants of importance sampling approaches based on inverse-propensity-weighting (IPW) (Sugiyama et al., 2007; Shimodaira, 2000), and kernel mean matching (Huang et al., 2007), or by learning a “balanced representation” of treated and control populations (Li & Fu, 2017). We do not attempt to explicitly adjust for selection bias using ad-hoc approaches, and rather seek the “informationally optimal” estimator of the PEHE. That is, we seek the most efficient (unbiased) estimator ψ̂∗(T̂ ) of ψ(T̂ ), which satisfies an analog of the Cramér-Rao bound (information-inequality) in parametric estimation, i.e. Var[ψ̂∗(T̂ )] ≤ Var[ψ̂(T̂ )], for any estimator ψ̂(T̂ ).\nClassical Cramér-Rao bounds do not apply to estimators of the form ψ̂∗(T̂ ), since such estimators are functionals of nonparametric objects. There are, however, analogous information inequalities for nonparametric estimation, including Bhattacharyya’s variance bound (Bhattacharyya, 1946), and its generalization due to Bickel (Bickel et al., 1998). We proceed by realizing that the PEHE ψ(T̂ ) is simply a functional that belongs to the doubly-robust class of functionals analyzed by Robins in (Robins et al., 2008). Thus, one can construct the “most” efficient estimator of ψ(T̂ ) using the most efficient influence function of ψ(T̂ ) as follows (Robins et al., 2008; Robins, 2004):\nψ̂∗(T̂ ) = ∑n\ni=1\n( Y\n(Wi) i −(Wi−p(Xi))·T̂ (Xi)\np(Xi)·(1−p(Xi))\n)2 .\nThe derivation of the estimator above can be found in Theorem 9 in (Robins, 2004) and Section 5 in (Robins et al., 2008). When the propensity function p(.) is known, this estimator approximate the PEHE at its optimal minimax rate. We estimate p(.) via standard kernel density estimation methods. It can be easily shown using the results in (Dudoit & van der Laan, 2005) that when using the estimator above to tune the GP hyperparameters via crossvalidation, then the learned length-scale parameters will satisfy the matching condition for minimax optimality."
  }, {
    "heading": "5. Experiments",
    "text": "In this Section, we check the validity of our analyses using a synthetic simulation setup (Subsection 5.1), and then evaluate the performance of our proposed model using data from a real-world clinical trial with simulated potential outcomes (Subsection 5.2). We will use the acronym NSGP to refer to the non-stationary GP model proposed in Section 4."
  }, {
    "heading": "5.1. Learning Brownian Response Surfaces",
    "text": ""
  }, {
    "heading": "5.1.1. SYNTHETIC MODEL",
    "text": "Let X = [0, 1], and define a κ-fold integrated Brownian motion Bκ, κ ∈ N+, on X as follows:\nBκ(x) = ∫ x 0 ∫ xκ 0 · · · ∫ x2 0 B0(x1) dx1 dx2 · · · dxxκ ,\nwhere B0(.) is a standard Brownian motion (Wiener process). Sample paths of B0 are almost surely Hölder regular with exponent 1\n2 (Karatzas & Shreve, 2012). Since\nB0(x) is almost surely non-differentiable everywhere in X , then sample paths of Bκ(x) are Hölder with exponent κ+ 1\n2 , i.e. Bκ ∈ Hκ+\n1 2 with probability 1. Therefore, when\nthe true response surfaces are κ-fold integrated Brownian paths, the optimality and achievability results in Theorems 1 and 2 should hold. To this end, we simulate the true response surfaces f0 ∈ Hα0 and f1 ∈ Hα1 as f0 ∼ Bα0− 12 , and f1 ∼ Bα1− 12 , where we set α0 = 2.5 and α1 = 5.5.\nThe propensity score is modeled as a parametrized logistic function p(x |η) = (1 + e−η (x− 12 ))−1, where η ∈ R is a parameter that determines the severity of selection bias. For a pair of fixed Brownian paths f0 and f1, synthetic observational samples (Xi,Wi, Y (Wi)i )i are generated as follows: Xi ∼ Uniform[0,1], Wi ∼ Bernoulli(p(x |η)), and Y\n(Wi) i ∼ fWi +N (0, σ 2), where σ2 = 0.1."
  }, {
    "heading": "5.1.2. EXPERIMENTS AND RESULTS",
    "text": "Using the setup in Section 5.1.1, we conducted the following Monte Carlo simulations to verify our theoretical findings and highlight the merits of our NSGP model.\n• Verifying Theorems 1 and 2: In order to check the validity of the results of Theorems 1 and 2, we use a NSGP Matérn prior GP(0,Kβ), with length-scale parameters β0 and β1 that are matched exactly with the regularities of the Brownian paths f0 and f1 (i.e. β0 = 2.5 and β1 = 5.5). According to Theorem 1, the optimal rate for estimating the CATE T = f1 − f0 is n −5 6 , and from Theorem 2, the NSGP with β0 = 2.5 and β1 = 5.5 should achieve that rate.\nFigure 2a provides a scatter-plot for the PEHE achieved by the NSGP with respect to the number of samples on a loglog scale for different settings of η. We fit a linear regression model that describes the PEHE behavior in the log-log scale. We found the slope of the linear fit to be 0.8437, which is very close2 to the slope of 56 ≈ 0.833 predicted by Theorem 1. Moreover, by changing the magnitude of η from 0 to 12 , the PEHE curve did not exhibit any significant change in its slope, and was only moved upwards by a constant offset. On the contrary, Figure 2b shows the PEHE behavior when the NSGP prior is over-smoothed (β0 > α0) for η = 0: as predicted by Theorem 2, learning becomes sluggish (slopes become less steep) as β0 increase since the matching condition in (10) does not hold any more.\n• NSGPs do not leave any money on the table: In this experiment, we show that the different components of the NSGP model allow it to perform well in small and large sample regimes. We set a strong selection bias of η = 12 and compare the log(PEHE) characteristic of NSGP with a model that uses the same non-stationary kernel as NSGP, and another model that uses a standard stationary kernel, but both models are tuned using marginal likelihood maximization. As we can see in Figure 2c, the model with the non-stationary kernel achieves the same learning rate as NSGP, but exhibits a large offset as it does not account for selection bias, whereas the stationary model fails to learn the smoothness of the rougher Brownian motion since it assigns the same length-scale to both surfaces, and hence it over-smooths the prior, achieving a suboptimal rate.\n2The minor discrepancy is a result of the residual error in the linear regression fit."
  }, {
    "heading": "5.2. The Infant Health and Development Program",
    "text": "We evaluated the performance of the NSGP model presented in Section 4.1 using the standard semi-synthetic experimental setup designed by Hill in (Hill, 2011). We report a state-of-the-art result in this setup, and draw connections between our experimental results and our analyses."
  }, {
    "heading": "5.2.1. DATA AND BENCHMARKS",
    "text": "The Infant Health and Development Program (IHDP) is an interventional program intended to enhance the health of premature infants (Hill, 2011). (Hill, 2011) extracted features and treatment assignments from a real-world clinical trial, and introduced selection bias to the data artificially by removing a subset of the patients. The potential outcomes are simulated according to the standard non-linear ”Response Surface B” setting in (Hill, 2011). The dataset comprised 747 subjects, with 25 features for each subject. Our experimental setup is identical to (Hill, 2011; Johansson et al., 2016; Shalit et al., 2017; Alaa & van der Schaar, 2017): we run 1000 experiments in which we compute the in-sample and out-of-sample √ PEHE (with 80/20 training/testing splits), and report average results in Table 1.\nWe compared the performance of NSGP with a total of 23 CATE estimation benchmarks. We considered: tree-based algorithms (BART (Hill, 2011), Causal forests (Wager & Athey, 2017), Bayesian causal forests (Hahn et al., 2017)), methods based on deep learning (CFR Wass., CFR MMD, BNN, TARnet (Shalit et al., 2017)), multivariate additive regression splines (MARS) (Powers et al., 2017), Gaussian processes (CMGP) (Alaa & van der Schaar, 2017), nearest neighbor matching (k-NN), propensity score matching (PSM), and targeted maximum likelihood (TMLE) (Porter et al., 2011). We also composed a number of T-learners and S-learners as in (Künzel et al., 2017), using a variety of baseline machine learning algorithms (DNN stands for deep networks and OLS stands for linear regression)."
  }, {
    "heading": "5.2.2. RESULTS AND CONCLUSIONS",
    "text": "As we can see in Table 1, the proposed NSGP model significantly outperforms all competing benchmarks. The combined benefit of the two components of an NSGP (nonstationary kernel and doubly-robust hyperparameters) is highlighted by comparing its performance to a vanilla SGP (stationary GP) with marginal likelihood maximization. The gain with respect to such a model is a 2-fold improvement in the PEHE.\nBecause the IHDP dataset has a “moderate” sample size, both selection bias and learning rate seem to impact the performance. Thus, our method took advantage of having addressed modeling questions [Q1] and [Q2] appropriately by being both “rate-optimal” and “bias-aware”.\nThe check marks in columns [Q1] and [Q2] designate methods that address modeling questions [Q1] and [Q2] “appropriately” in the light of the analysis presented in Section 3. Methods with [Q1] checked use a regression structure with “outcome-specific” hyperparameters, and methods with [Q2] checked adjust for selection bias. A general observation is that the structure of the regression model seem to matter much more than the strategy for handling selection bias. This is evident from the fact that the TARnet model (does not handle bias but models outcomes separately) significantly outperforms BNN (handles bias but uses a single-surface model (Shalit et al., 2017)), and that all T-learners (models 2 separate response surfaces) outperformed their S-shaped counterparts (models a single surface). For parametric models, such as OLS, the issue of selecting the right regression structure is even more crucial.\nTo sum up, the results in Table 1 imply that selecting the right regression structure is crucial for rate-optimality in sufficiently large dataset, whereas handling selection bias provides an extra bonus. In Table 1, methods that address both [Q1] and [Q2] (NSGP, CMGP, and CFR. Wass and MMD) displayed a superior performance."
  }, {
    "heading": "Acknowledgements",
    "text": "The authors would like to thank the reviewers for their helpful comments. The research presented in this paper was supported by the Office of Naval Research (ONR) and the NSF (Grant number: ECCS1462245, ECCS1533983, and ECCS1407712)."
  }],
  "year": 2018,
  "references": [{
    "title": "Bayesian inference of individualized treatment effects using multitask gaussian processes",
    "authors": ["Alaa", "Ahmed M", "van der Schaar", "Mihaela"],
    "venue": "Advances in Neural Information Processing Systems (NIPS),",
    "year": 2017
  }, {
    "title": "Bayesian nonparametric causal inference: Information rates and learning algorithms",
    "authors": ["Alaa", "Ahmed M", "van der Schaar", "Mihaela"],
    "venue": "Journal on Selected Topics in Signal Processing,",
    "year": 2018
  }, {
    "title": "Deep-treat: Learning optimal personalized treatments from observational data using neural networks",
    "authors": ["O Atan", "J Jordan", "M. van der Schaar"],
    "year": 2018
  }, {
    "title": "On some analogues of the amount of information and their use in statistical estimation",
    "authors": ["A. Bhattacharyya"],
    "venue": "Sankhyā: The Indian Journal of Statistics,",
    "year": 1946
  }, {
    "title": "Efficient and adaptive estimation for semiparametric models, volume 2",
    "authors": ["Bickel", "Peter J", "Klaassen", "Chris A", "Y Ritov", "J Klaassen", "Wellner", "Jon A", "Ritov", "YA’Acov"],
    "year": 1998
  }, {
    "title": "Bandwidth selection for kernel density estimation with length-biased data",
    "authors": ["Borrajo", "Marıa Isabel", "González-Manteiga", "Wenceslao", "Martı́nez-Miranda", "Marı́a Dolores"],
    "venue": "Journal of Nonparametric Statistics,",
    "year": 2017
  }, {
    "title": "Lower bounds for posterior rates with gaussian process priors",
    "authors": ["I. Castillo"],
    "venue": "Electron. J. Stat.,",
    "year": 2008
  }, {
    "title": "Asymptotics of cross-validated risk estimation in estimator selection and performance assessment",
    "authors": ["Dudoit", "Sandrine", "van der Laan", "Mark J"],
    "venue": "Statistical Methodology,",
    "year": 2005
  }, {
    "title": "Subgroup identification from randomized clinical trial data",
    "authors": ["Foster", "Jared C", "Taylor", "Jeremy MG", "Ruberg", "Stephen J"],
    "venue": "Statistics in medicine,",
    "year": 2011
  }, {
    "title": "Bayesian regression tree models for causal inference: regularization, confounding, and heterogeneous effects",
    "authors": ["Hahn", "P Richard", "Murray", "Jared S", "Carvalho", "Carlos M"],
    "year": 2017
  }, {
    "title": "Sample selection bias as a specification error (with an application to the estimation of labor supply",
    "authors": ["Heckman", "James J"],
    "year": 1977
  }, {
    "title": "Bayesian nonparametric modeling for causal inference",
    "authors": ["Hill", "Jennifer L"],
    "venue": "Journal of Computational and Graphical Statistics,",
    "year": 2011
  }, {
    "title": "Correcting sample selection bias by unlabeled data",
    "authors": ["Huang", "Jiayuan", "Gretton", "Arthur", "Borgwardt", "Karsten M", "Schölkopf", "Bernhard", "Smola", "Alex J"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2007
  }, {
    "title": "Learning representations for counterfactual inference",
    "authors": ["Johansson", "Fredrik", "Shalit", "Uri", "Sontag", "David"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "Brownian motion and stochastic calculus, volume 113",
    "authors": ["Karatzas", "Ioannis", "Shreve", "Steven"],
    "venue": "Springer Science & Business Media,",
    "year": 2012
  }, {
    "title": "Nonparametric causal effects based on incremental propensity score interventions",
    "authors": ["Kennedy", "Edward H"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2018
  }, {
    "title": "Meta-learners for estimating heterogeneous treatment effects using machine learning",
    "authors": ["Künzel", "Sören", "Sekhon", "Jasjeet", "Bickel", "Peter", "Yu", "Bin"],
    "venue": "arXiv preprint arXiv:1706.03461,",
    "year": 2017
  }, {
    "title": "Matching on balanced nonlinear representations for treatment effects estimation",
    "authors": ["Li", "Sheng", "Fu", "Yun"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2017
  }, {
    "title": "Estimating individual treatment effect in observational data using random forest methods",
    "authors": ["Lu", "Min", "Sadiq", "Saad", "Feaster", "Daniel J", "Ishwaran", "Hemant"],
    "venue": "Journal of Computational and Graphical Statistics,",
    "year": 2017
  }, {
    "title": "The relative performance of targeted maximum likelihood estimators",
    "authors": ["Porter", "Kristin E", "Gruber", "Susan", "Van Der Laan", "Mark J", "Sekhon", "Jasjeet S"],
    "venue": "The International Journal of Biostatistics,",
    "year": 2011
  }, {
    "title": "Some methods for heterogeneous treatment effect estimation in high-dimensions",
    "authors": ["Powers", "Scott", "Qian", "Junyang", "Jung", "Kenneth", "Schuler", "Alejandro", "Shah", "Nigam H", "Hastie", "Trevor", "Tibshirani", "Robert"],
    "venue": "arXiv preprint arXiv:1707.00102,",
    "year": 2017
  }, {
    "title": "Lower bounds on minimax rates for nonparametric regression with additive sparsity and smoothness",
    "authors": ["Raskutti", "Garvesh", "Yu", "Bin", "Wainwright", "Martin J"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2009
  }, {
    "title": "Gaussian processes for machine learning, volume 1",
    "authors": ["Rasmussen", "Carl Edward", "Williams", "Christopher KI"],
    "venue": "MIT press Cambridge,",
    "year": 2006
  }, {
    "title": "Higher order influence functions and minimax estimation of nonlinear functionals. In Probability and Statistics: Essays in Honor of David A",
    "authors": ["Robins", "James", "Li", "Lingling", "Tchetgen", "Eric", "van der Vaart", "Aad"],
    "venue": "Institute of Mathematical Statistics,",
    "year": 2008
  }, {
    "title": "Optimal structural nested models for optimal sequential decisions",
    "authors": ["Robins", "James M"],
    "venue": "In Proceedings of the second seattle Symposium in Biostatistics,",
    "year": 2004
  }, {
    "title": "Reducing bias in observational studies using subclassification on the propensity score",
    "authors": ["Rosenbaum", "Paul R", "Rubin", "Donald B"],
    "venue": "Journal of the American statistical Association,",
    "year": 1984
  }, {
    "title": "Causal inference using potential outcomes: Design, modeling, decisions",
    "authors": ["Rubin", "Donald B"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2005
  }, {
    "title": "Estimating individual treatment effect: generalization bounds and algorithms",
    "authors": ["Shalit", "Uri", "Johansson", "Fredrik", "Sontag", "David"],
    "year": 2017
  }, {
    "title": "Improving predictive inference under covariate shift by weighting the log-likelihood function",
    "authors": ["Shimodaira", "Hidetoshi"],
    "venue": "Journal of statistical planning and inference,",
    "year": 2000
  }, {
    "title": "Adaptive bayesian credible sets in regression with a gaussian process prior",
    "authors": ["Sniekers", "Suzanne", "van der Vaart", "Aad"],
    "venue": "Electronic Journal of Statistics,",
    "year": 2015
  }, {
    "title": "Optimal global rates of convergence for nonparametric regression",
    "authors": ["Stone", "Charles J"],
    "venue": "The annals of statistics,",
    "year": 1982
  }, {
    "title": "Mixture regression for covariate shift",
    "authors": ["Sugiyama", "Masashi", "Storkey", "Amos J"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2007
  }, {
    "title": "Covariate shift adaptation by importance weighted cross validation",
    "authors": ["Sugiyama", "Masashi", "Krauledat", "Matthias", "MÃžller", "Klaus-Robert"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2007
  }, {
    "title": "Information rates of nonparametric gaussian process methods",
    "authors": ["Vaart", "Aad van der", "Zanten", "Harry van"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2011
  }, {
    "title": "Rates of contraction of posterior distributions based on gaussian process priors",
    "authors": ["van der Vaart", "Aad W", "van Zanten", "J Harry"],
    "venue": "The Annals of Statistics,",
    "year": 2008
  }, {
    "title": "Reproducing kernel hilbert spaces of gaussian priors",
    "authors": ["van der Vaart", "Aad W", "van Zanten", "J Harry"],
    "venue": "Institute of Mathematical Statistics,",
    "year": 2008
  }, {
    "title": "Estimation and inference of heterogeneous treatment effects using random forests",
    "authors": ["Wager", "Stefan", "Athey", "Susan"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2017
  }, {
    "title": "Estimating heterogeneous treatment effects with observational data",
    "authors": ["Xie", "Yu", "Brand", "Jennie E", "Jann", "Ben"],
    "venue": "Sociological methodology,",
    "year": 2012
  }, {
    "title": "Information-theoretic determination of minimax rates of convergence",
    "authors": ["Yang", "Yuhong", "Barron", "Andrew"],
    "venue": "Annals of Statistics,",
    "year": 1999
  }, {
    "title": "Minimax-optimal nonparametric regression in high dimensions",
    "authors": ["Yang", "Yun", "Tokdar", "Surya T"],
    "venue": "The Annals of Statistics,",
    "year": 2015
  }, {
    "title": "Ganite: Estimation of individualized treatment effects using generative adversarial nets",
    "authors": ["Yoon", "Jinsung", "Jordon", "James", "van der Schaar", "Mihaela"],
    "venue": "International Conference on Learning Representations (ICLR),",
    "year": 2018
  }, {
    "title": "Using wavelet network in nonparametric estimation",
    "authors": ["Zhang", "Qinghua"],
    "venue": "IEEE Transactions on Neural networks,",
    "year": 1997
  }],
  "id": "SP:badcfae286bbe1882cd7725ea6a5e7fbd4f6cffe",
  "authors": [{
    "name": "Ahmed M. Alaa",
    "affiliations": []
  }, {
    "name": "Mihaela van der Schaar",
    "affiliations": []
  }],
  "abstractText": "Estimating heterogeneous treatment effects from observational data is a central problem in many domains. Because counterfactual data is inaccessible, the problem differs fundamentally from supervised learning, and entails a more complex set of modeling choices. Despite a variety of recently proposed algorithmic solutions, a principled guideline for building estimators of treatment effects using machine learning algorithms is still lacking. In this paper, we provide such guidelines by characterizing the fundamental limits of estimating heterogeneous treatment effects, and establishing conditions under which these limits can be achieved. Our analysis reveals that the relative importance of the different aspects of observational data vary with the sample size. For instance, we show that selection bias matters only in small-sample regimes, whereas with a large sample size, the way an algorithm models the control and treated outcomes is what bottlenecks its performance. Guided by our analysis, we build a practical algorithm for estimating treatment effects using a non-stationary Gaussian processes with doubly-robust hyperparameters. Using a standard semi-synthetic simulation setup, we show that our algorithm outperforms the state-of-the-art, and that the behavior of existing algorithms conforms with our analysis.",
  "title": "Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design"
}