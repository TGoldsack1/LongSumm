{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Low rank matrix optimization stands as a major tool in modern dimensionality reduction and unsupervised learning. The singular value decomposition can be used when the optimization objective is rotationally invariant to the parameters. However, if we wish to optimize over more complex, non-convex objectives we must choose to either rely on convex relaxations (Recht et al., 2010; Negahban & Wainwright, 2011; Rohde & Tsybakov, 2011) or directly optimize over the non-convex space (Park et al., 2016; Jain et al., 2013; Chen & Wainwright, 2015; Lee & Bresler, 2013; Jain et al., 2014).\nMore concretely, in the low rank matrix optimization problem, we wish to solve\nargmax\n⇥\n`(⇥) s.t. rank(⇥)  r. (1)\nRather than perform the computationally intractable optimization above researchers have studied convex relaxations of the form\nargmax\n⇥\n`(⇥) |||⇥||| nuc .\n1UT Austin 2Yale University. Correspondence to: Rajiv Khanna <rajivak@utexas.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nUnfortunately, the above optimization can be computationally taxing. General purpose solvers for the above optimization problem that rely on semidefinite programming (SDP) require ⇥(n3d3) computation, which is prohibitive. Gradient descent techniques require ⇥(✏ 1/2(n3 + d3)) computational cost for an epsilon accurate solution. This improvement is sizable in comparison to SDP solvers. Unfortunately, it is still prohibitive for large scale matrix estimation.\nAn alternate vein of research has focused on directly optimizing the non-convex problem (1). To that end, authors have seen recent theoretical success in studying the convergence properties of\nargmax U2Rn⇥r,V2Rd⇥r `(UVT ).\nSolving the problem above automatically forces the solution to be low rank, and recent results have shown promising behavior.\nAnother approach is to optimize (1) incrementally via rank one updates to the current estimate (Shalev-Shwartz et al., 2011; Wang et al., 2015). This approach has also been studied in more general contexts such as boosting (Buhlmann & Yu, 2009), coordinate descent (Jaggi, 2013; Jaggi & Sulovský, 2010), and incremental atomic norm optimization (Gribonval & Vandergheynst, 2006; Barron et al., 2008; Khanna et al., 2016; Rao et al., 2015; Dudik et al., 2012; Locatello et al., 2017)."
  }, {
    "heading": "1.1. Set Function Optimization and Coordinate Descent",
    "text": "In this paper, we interpret low rank matrix estimation as a set optimization problem over an infinite set of atoms. Specifically, we wish to optimize\nargmax {X1,...Xk}2A `\nkX\ni=1\n↵iXi\n! ,\nwhere the set of atoms A is the set of all rank one matrices with unit operator norm. This settings is analogous to that taken in the results studying atomic norm optimization, coordinate descent via the total variation norm, and Frank-Wolfe style algorithms for atomic optimization. This formulation allows us to connect the problem of low rank matrix estimation to that of submodular set function optimization, which\nwe discuss in the sequel. Before proceeding we discuss related work and an informal statement of our main result."
  }, {
    "heading": "1.2. Informal Result and Related Work",
    "text": "Our result demonstrates an exponential decrease in the amount of error incurred by greedily adding rank one matrices to the low rank matrix approximation. Theorem 1 (Approximation Guarantee, Informal). If we let ⇥k be our estimate of the rank r matrix ⇥⇤ at iteration k, then for some universal constant c related to the restricted condition number of the problem we have\n`(⇥k) `(0) (1 exp( ck/r))(`(⇥⇤) `(0)).\nNote that after k iterations the matrix ⇥k will be at most rank k.\nRelated work: There has been a wide array of studies looking at the computational and statistical benefits of rank one updates to estimating a low rank matrix. At its most basic, the singular value decomposition will keep adding rank one approximations through deflation steps. This work can be generally segmented into two sets of results – the ones that present sublinear rates of convergence and those that obtain linear rates. Interestingly, parallel lines of work have also demonstrated similar convergence bounds for more general atomic or dictionary element approximations (Buhlmann & Yu, 2009; Gribonval & Vandergheynst, 2006; Barron et al., 2008; Khanna et al., 2016). For space constraints, we will summarize these results into two categories rather than explicitly state the results for each individual paper.\nIf we define the atomic norm of a matrix M 2 Rn⇥d written as |||M|||\nnuc to be the sum of the singular values of that matrix, then the bounds establishing sublinear convergence behave as\n`(⇥⇤) `(⇥k)  |||⇥⇤|||2 nuc\nk ,\nwhere we take ⇥⇤ to be the best rank r solution. What we then see is convergence towards the optimal bound. However, we expect our statistical error to behave as r(n+ d)/n where n is the number of samples that we have received from our statistical model and ⇥⇤ is rank r (Negahban & Wainwright, 2011; Rohde & Tsybakov, 2011). We can take |||⇥⇤|||\nnuc ⇡ r, which would then imply that we would need k to behave as n/(n+ d). However, that would then imply that the rank of our matrix should grow linearly in the number of observations in order to achieve the same statistical error bounds. The above error bounds are “fast”. If we consider a model that yields slow error bounds, then we expect the error to behave like |||⇥⇤|||\nnuc q n+d n . In that case,\nwe can take k |||⇥⇤||| nuc\nq n\nn+d , which looks better, but\nstill requires significant growth in k as a function of n. To overcome the above points, some authors have aimed to study similar greedy algorithms that then enjoy exponential rates of convergence as we show in our paper. These results share the most similarities with our own and behave as\n`(⇥k) (1 k)`(⇥⇤).\nThis result decays exponentially. However, when one looks at the behavior of it will typically act as exp ( 1/min(n,d)), for an n⇥ d matrix. As a result, we would need to choose k of the order of the dimensionality of the problem in order to begin to see gains. In contrast, for our result listed above, if we seek to only compare to the best rank r solution, then the gamma we find is = exp ( 1/r). Of course, if we wish to find a solution with full rank, then the bounds we stated above match the existing bounds.\nIn order to establish our results we rely on a notion introduced in the statistical community called restricted strong convexity. This assumption has connections to ideas such as the restricted isometry property, restricted eigenvalue condition, and incoherence (Negahban & Wainwright, 2012). In the work by Shalev-Shwartz, Gonen, and Shamir (2011) a form of strong convexity condition is imposed over matrices. Under that setting, the authors demonstrate that\n`(⇥k) `(⇥⇤) `(0)r\nk ,\nwhere r is the rank of ⇥⇤. In contrast, our bound behaves as\n`(⇥k) `(⇥⇤) (`(⇥⇤) `(0)) exp ( k/r).\nOur contributions: We improve upon the linear rates of convergence for low rank approximation using rank one updates by connecting the coordinate descent problem to that of submodular optimization. We present this result in the sequel along with the algorithmic consequences. We demonstrate the good performance of these rank one updates in the experimental section."
  }, {
    "heading": "2. Background",
    "text": "We begin by fixing some notation. We represent sets using sans script fonts e.g. A,B. Vectors are represented using lower case bold letters e.g. x,y, and matrices are represented using upper case bold letters e.g. X,Y. Non-bold face letters are used for scalars e.g. j,M, r and function names e.g. f(·). The transpose of a vector or a matrix is represented by > e.g. X>. Define [p] := {1, 2, . . . , p}. For singleton sets, we write f(j) := f({j}). Size of a set S is denoted by |S|. h·, ·i is used for matrix inner product.\nOur goal is to analyze greedy algorithms for low rank estimation. Consider the classic greedy algorithm that picks up\nthe next element myopically i.e. given the solution set built so far, the algorithm picks the next element as the one which maximizes the gain obtained by adding the said element into the solution set. Approximation guarantees for the greedy algorithm readily imply for the class of functions defined as follows. Definition 1. A set function f(·) : [p]! R is submodular if for all A,B ✓ [p],\nf(A) + f(B) f(A [ B) + f(A \\ B).\nSubmodular set functions are well studied and have many desirable properties that allow for efficient minimization and maximization with approximation guarantees. Our low rank estimation problem also falls under the purview of another class of functions called monotone functions. A function is called monotone if and only if f(A)  f(B) for all A ✓ B. For the specific case of maximizing monotone submodular set functions, it is known that the greedy algorithm run for k iterations is guaranteed to return a solution that is within (1 1/e) of the optimum set of size k (Nemhauser et al., 1978). Without further assumptions or knowledge of the function, no other polynomial time algorithm can provide a better approximation guarantee unless P=NP (Feige, 1998).\nMore recently, the aforementioned greedy approximation guarantee has been extended to a larger class of functions called weakly submodular functions (Elenberg et al., 2016; Khanna et al., 2017). Central to the notion of weak submodularity is a quantity called the submodularity ratio. Definition 2 (Submodularity Ratio (Das & Kempe, 2011)). Let S, L ⇢ [p] be two disjoint sets, and f(·) : [p]! R. The submodularity ratio of L with respect to S is given by\nL,S := P j2S [f(L [ {j}) f(L)] f(L [ S) f(L) . (2)\nThe submodularity ratio of a set U with respect to an integer k is given by\nU,k := min L,S:L\\S=;, L✓U,|S|k\nL,S. (3)\nIt is easy to show that f(·) is submodular if and only if L,S 1 for all sets L and S. However, an approximation guarantee is obtained when 0 < L,S 8 L, S (Das & Kempe, 2011; Elenberg et al., 2016). The subset of monotone functions which have L,S > 0 8 L, S are called weakly submodular functions in the sense that even though the function is not submodular, it still provides a provable bound for greedy selections.\nAlso vital to our analysis is the notion of restricted strong concavity and smoothness (Negahban et al., 2012; Loh & Wainwright, 2015).\nDefinition 3 (Low Rank Restricted Strong Concavity (RSC), Restricted Smoothness (RSM)). A function ` : Rn⇥d ! R is said to be restricted strong concave with parameter m\n⌦\nand restricted smooth with parameter M ⌦ if for all X,Y 2 ⌦ ⇢ Rn⇥d,\nm⌦ 2 kY Xk2F `(Y) `(X) hr`(X),Y Xi\nM⌦ 2 kY Xk2F .\nRemark 1. If a function `(·) has restricted strong concavity parameter m, then its negative `(·) has restricted strong convexity parameter m. We choose to use the nomenclature of concavity for ease of exposition in terms of relationship to submodular maximization. Further, note that we define RSC/RSM conditions on the space of matrices rather than vectors, on a domain ⌦ constrained by rank rather than sparsity. It is straightforward to see that if ⌦0 ✓ ⌦, then M\n⌦ 0 M ⌦ and m ⌦ 0 m ⌦ ."
  }, {
    "heading": "3. Setup",
    "text": "In this section, we delineate our setup of low rank estimation. In order to connect to the weak submodular maximization framework more easily, we operate in the setting of maximization of a concave matrix variate function under a low rank constraint. This is equivalent to minimizing a convex matrix variate function under the low rank constraint as considered by Shalev-Shwartz et al. (2011) or under nuclear norm constraint or regularization as considered by Jaggi & Sulovský (2010). The goal is to maximize a function ` : Rn⇥d ! R:\nmax rank(X)r `(X). (4)\nInstead of using a convex relaxation of (4), our approach is to enforce the rank constraint directly by adding rank 1 matrices greedily until X is of rank k. The rank 1 matrices to be added are obtained as outer product of vectors from the given vector sets U and V . While our results hold for general vector sets U ,V assuming an oracle access to subroutines GreedySel and OMPSel (to be detailed later), for the rest of the paper we focus on the case of norm 1 balls U := {x 2 Rn s.t. kxk\n2 = 1} and V := {x 2 Rd s.t. kxk 2 = 1}.\nThe problem (4) can be interpreted in the context of sparsity assuming U and V are enumerable. For example, by the SVD theorem, it is known that we can rewrite X asPk\ni=1 ↵iuiv > i , where 8i, ui 2 U and vi 2 V . By enumerating U and V under a finite precision representation of real values, one can rethink of the optimization (4) as finding a sparse solution for the infinite dimensional vector ↵ (Shalev-Shwartz et al., 2011; Dudik et al., 2012). We can also optimize over support sets, similar to the classical setting of support selection for sparse vectors. For a specified support set L consisting of vectors from U and V , let\nUL and VL be the matrices formed by stacking the chosen elements of U and V respectively. We define the following set function to maximize `(·) given L.\nf(L) = max H2R|L|⇥|L|\n`(U>L HVL) `(0). (5)\nWe will denote the optimizing matrix for a support set L as B(L). In other words, letting ˆHL be the argmax obtained in (5), then B(L) := U>L ˆHLVL. Thus, the low rank matrix estimation problem (4) can be reinterpreted as the following equivalent combinatorial optimization problem:\nmax |S|k f(S). (6)"
  }, {
    "heading": "3.1. Algorithms",
    "text": "Our greedy algorithm, illustrated in Algorithm 1, builds the support set incrementally – adding rank 1 matrices one at a time such that at iteration i for 1  i  k the size of the chosen support set (and hence rank of the current iterate) is i. We assume access to a subroutine GreedySel for the greedy selection (Step 4). This subroutine solves an inner optimization problem by calling a subroutine GreedySel which returns an atom s from the candidate support set that ensures\nf(SGi 1 [ {s}) f(SGi 1) ⌧ f(SGi 1 [ {s?}) f(SGi 1) ,\nwhere\ns? argmax a2(U⇥V)?SGi 1 f(SGi 1 [ {a}) f(SGi 1).\nIn words, the subroutine GreedySel ensures that the gain in f(·) obtained by using the selected atom is within ⌧ 2 (0, 1] multiplicative approximation to the atom with the best possible gain in f(·). The hyperparameter ⌧ governs a tradeoff allowing a compromise in myopic gain for a possibly quicker selection.\nThe greedy selection requires fitting and scoring every candidate support, which is often prohibitively expensive. An alternative is to choose the next atom by using the linear maximization oracle used by Frank-Wolfe (Jaggi, 2013) or Matching Pursuit algorithms (Gribonval & Vandergheynst, 2006; Locatello et al., 2017). This step replaces Step 4 of Algorithm 1 as illustrated in Algorithm 2. Let L = SOi 1 be the set constructed by the algorithm at iteration (i 1). The linear oracle OMPSel returns an atom s for iteration i ensuring\nhr`(B(L)),usv>s i ⌧ max (u,v)2(U⇥V)?SOi 1 hr`(B(L)),uv>i.\nThe linear problem OMPSel can be considerably faster that GreedySel. OMPSel reduces to finding the left and right\nsingular vectors of r`(B(L)) corresponding to its largest singular value. If t is the number of non-zero entries in r`(B(L)), then this takes O( t\n1 ⌧ (log n+ log d)) time.\nWe note that Algorithm 2 is the same as considered by Shalev-Shwartz et al. (2011) as GECO (Greedy Efficient Component Optimization). However, as we shall see, our analysis provides stronger bounds than their Theorem 2.\nAlgorithm 1 GREEDY(U , V , k, ⌧ ) 1: Input: vector sets U , V , sparsity parameter k, subrou-\ntine hyperparameter ⌧ 2: SG\n0 ; 3: for i = 1 . . . k do 4: s GreedySel(⌧) 5: SGi SGi 1 [ {s} 6: end for 7: return SGk , B(S G k ), f(SGk ).\nAlgorithm 2 GECO(U , V , k, ⌧ ) same as Algorithm 1 except\n4: s OMPSel(⌧)\nRemark 2. We note that Step 5 of Algorithms 1 and 2 requires solving the RHS of (5) which is a matrix variate problem of size i2 at iteration i. This refitting is equivalent to the “fully-corrective” versions of Frank-Wolfe/Matching Pursuit algorithms (Locatello et al., 2017; Lacoste-Julien & Jaggi, 2015) which, intuitively speaking, extract out all the information w.r.t `(·) from the chosen set of atoms, thereby ensuring that the next rank 1 atom chosen has row and column space orthogonal to the previously chosen atoms. Thus the constrained maximization on the orthogonal complement of SOi in subroutine OMPSel (SGi in GreedySel) need not be explicitly enforced, but is still shown for clarity."
  }, {
    "heading": "4. Analysis",
    "text": "In this section, we prove that low rank matrix optimization over the rank one atoms satisfies weak submodularity. We explicitly delineate some notation and assumptions. With slight abuse of notation, we assume `(·) is mi-strongly concave and Mi-smooth over pairs of matrices of rank i. For i  j, note that mi mj and Mi Mj . Additionally, let ˜\n⌦ := {(X,Y) : rank(X Y)  1}, and assume `(·) is ˜M 1 -smooth over ˜⌦. It is easy to see ˜M 1 M 1 .\nFirst we prove that if the low rank RSC holds (Definition 3), then the submodularity ratio (Definition 2) is lower-bounded by the inverse condition number. Theorem 2. Let L be a set of k rank 1 atoms and S be a set of r rank 1 atoms where we sequentially orthogonalize the atoms against L. If `(·) is mi-strongly con-\ncave over matrices of rank i, and ˜M 1 -smooth over the set ˜\n⌦ := {(X,Y) : rank(X Y) = 1}, then\nL,r :=\nP a2S [f(L [ {a}) f(L)]\nf(L [ S) f(L) mr+k ˜M 1 .\nThe proof of Theorem 2 is structured around individually obtaining a lower bound for the numerator and an upper bound for the denominator of the submodularity ratio by exploiting the concavity and convexity conditions."
  }, {
    "heading": "4.1. Greedy Improvement",
    "text": "Bounding the submodularity ratio is crucial to obtaining approximation guarantees for Algorithm 1. Theorem 3. Let S := SGk be the greedy solution set obtained by running Algorithm 1 for k iterations, and let S? be an optimal support set of size r. Let `(·) be mi strongly concave on the set of matrices with rank less than or equal to i, and ˜M\n1 smooth on the set of matrices in the set ˜⌦. Then,\nf(S) ✓ 1 1\nec1\n◆ f(S?) ✓ 1 1\nec2\n◆ f(S?),\nwhere c 1 = ⌧ S,r k r and c2 = ⌧ mr+k ˜M1 k r .\nThe proof technique for the first inequality of Theorem 3 relies on lower bounding the progress made in each iteration of Algorithm 1. Intuitively, it exploits weak submodularity to make sure that each iteration makes enough progress, and then applies an induction argument for r iterations. We also emphasize that the bounds in Theorem 3 are for normalized set function f(·) (which means f(;) = 0). A more detailed proof is presented in the appendix.\nThe bounds obtained in Theorem 3 are similar to the one obtained in submodular maximization of monotone normalized functions (Nemhauser et al., 1978). In fact, our result can be re-interpreted as an extension to previous results. The greedy algorithm for submodular maximization assumes finite ground sets. We extend this for infinite ground sets. We can do this (for matrices) as long as we have an implementation of the oracle GreedySel. Once the choice is made by the oracle, standard analysis holds. Remark 3. Theorem 3 provides the approximation guarantees for running the greedy selection algorithm up to k iterations to obtain a rank k matrix iterate vis-a-vis the best rank r approximation. For r = k, and ⌧ = 1, we get an approximation bound (1 e m/M) which is reminiscent of the greedy bound of (1 1/e) under the framework of submodularity. Note that our analysis can not be used to establish classical submodularity. However, establishing weak submodularity that lower bounds is sufficient to provide slightly weaker than classical submodularity guarantees.\nRemark 4. Theorem 3 implies that to obtain (1 ✏) approximation guarantee in the worst case, running Algorithm 1 for k = rMm⌧ log 1 ✏ ) = O(r log 1/✏) iterations suffices. This is useful when the application allows a tradeoff: compromising on the low rank constraint a little to achieve tighter approximation guarantees. Remark 5. Das & Kempe (2011) considered the special case of greedily maximizing R2 statistic for linear regression, which corresponds to classical sparsity in vectors. They also obtain a bound of (1 1/e ), where is the submodularity ratio for their respective setup. This was generalized by Elenberg et al. (2016) to general concave functions under sparsity constraints. Our analysis is for the low rank constraint, as opposed to sparsity in vectors that was considered by them."
  }, {
    "heading": "4.2. GECO Improvement",
    "text": "In this section, we obtain approximation guarantees for Algorithm 2. The greedy search over the infinitely many candidate atoms is infeasible, especially when ⌧ = 1. Thus while Algorithm 1 establishes interesting theoretical connections with submodularity, it is not practical in general. To obtain a tractable and practically useful algorithm, the greedy search is replaced by a Frank Wolfe or Matching Pursuit style linear optimization which can be easily implemented as finding the top singular vectors of the gradient at iteration i. In this section, we show that despite the speedup, we lose very little in terms of approximation guarantees. In fact, if the approximation factor ⌧ in OMPSel() is 1, we get the same bounds as those obtained for the greedy algorithm. Theorem 4. Let S := SOk be the greedy solution set obtained using Algorithm 2 for k iterations, and let S? be the optimum size r support set. Let `(·) be mr+k strongly concave on the set of matrices with rank less than or equal to (r + k), and ˜M\n1 smooth on the set of matrices with rank in the set ˜⌦. Then,\nf(S) ✓ 1 1\nec3\n◆ f(S?),\nwhere c 3 = ⌧2mr+k ˜M1 k r .\nThe proof of Theorem 4 follows along the lines of Theorem 3. The central idea is similar – to exploit the RSC conditions to make sure that each iteration makes sufficient progress, and then provide an induction argument for r iterations. Unlike the greedy algorithm, however, using the submodularity ratio is no longer required. Note that the bound obtained in Theorem 4 is similar to Theorem 3, except the exponent on the approximation factor ⌧ . Remark 6. Our proof technique for Theorem 4 can be applied for classical sparsity to improve the bounds obtained by Elenberg et al. (2016) for OMP for support selection\nunder RSC, and by Das & Kempe (2011) for R2 statistic. If ⌧ = 1, r = k, their bounds involve terms of the form O(m2/M2) in the exponent, as opposed to our bounds which only has m/M in the exponent.\nRemark 7. Similar to the greedy algorithm, to achieve a tighter approximation to best rank k solution, one can relax the low rank constraint a little by running the algorithm for r > k greedy iterations. The result obtained by our Theorem 4 can be compared to the bound obtained by (ShalevShwartz et al., 2011) [Theorem 2] for the same algorithm. For an ✏ multiplicative approximation, Theorem 4 implies we need r/k = O(log 1/✏). On the other hand, Shalev-Shwartz et al. (2011) obtain an additive approximation bound with r/k = O(1/\"), which is an exponential improvement."
  }, {
    "heading": "5. Recovery Guarantees",
    "text": "While understanding approximation guarantees are useful, providing parameter recovery bounds can further help us understand the practical utility of greedy algorithms. In this section, we present a general theorem that provides us with recovery bounds of the true underlying low rank structure. Theorem 5. Suppose that an algorithm achieves the approximation guarantee:\nf(Sk) Cr,kf(S?r),\nwhere Sk is the set of size k at iteration k of the algorithm, S?r be the optimal solution for r-cardinality constrained maximization of f(·), and Cr,k be the corresponding approximation ratio guaranteed by the algorithm. Recall that we represent by US,VS the matrices formed by stacking the vectors represented by the support set S chosen from U ,V respectively, s.t. |S| = r. Then under mk+r RSC, with Br = U>S HVS for any H 2 Rr⇥r, we have\nkB(Sk) Brk2F  4(k + r) kr`(Br)k2 2\nm2k+r\n+ 4(1 Cr,k) mk+r [`(Br) `(0)]\nTheorem 5 can be applied for Br = B(S ? r), which is the argmax for maximizing `(·) under the low rank constraint. It is general in the sense that it can be applied for getting recovery bounds from approximation guarantees for any algorithm, and hence is applicable for both Algorithms 1 and 2.\nStatistical recovery guarantees can be obtained from Theorem 5 for specific choice of `(·) and statistical model. Consider the case of low rank matrix estimation from noisy linear measurements. Let Xi 2 Rm1⇥m2 for i 2 [n] be generated so that each entry of Xi is N (0, 1). We observe yi = hXi,⇥?i + \", where ⇥? is low rank, and say \" ⇠\nN (0, 2). Let N = m 1 m 2 , and let '(⇥) : Rm1⇥m2 ! Rn be the linear operator so that ['(⇥)]i = hXi,⇥i. Our corresponding function is now `(⇥) = 1nky '(⇥)k 2 2\n. For this function, using arguments by Negahban et al. (2012), we know kr`(BS?r )k2\n2  logNn and `(B S?r ) `(0)  (r + 1)\nwith high probability. It is also straightforward to apply their results to bound mk+r ⇣ 1\n32 162(k+r) logNn ⌘\n, and M\n1  1, which gives explicit bounds as per Theorem 5 for Algorithms 1, 2 for the considered function and the design matrix."
  }, {
    "heading": "6. Experiments",
    "text": "In this section, we empirically evaluate the proposed algorithms."
  }, {
    "heading": "6.1. Clustering under Stochastic Block Model",
    "text": "First, we test empirically the performance of GECO (Algorithm 2 with ⌧ = 1) for a clustering task. We are provided with a graph with nodes and the respective edges between the nodes. The observed graph is assumed to have been noisily generated from a true underlying clustering. The goal is to recover the underlying clustering structure from the noisy graph provided to us. Our greedy framework is applicable because the adjacency matrix of the true clustering is low rank. We compare performance of Algorithm 2 on simulated data against standard baselines of spectral clustering which are commonly used for this task. We begin by describing a generative model for creating edges between nodes given the ground truth.\nThe Stochastic Block Model is a model to generate random graphs. It takes its input the set of n nodes, and a partition of [n] which form a set of disjoint clusters, and returns the graph with nodes and the generated edges. The model has two additional parameters, the generative probabilities (p, q). A pair of nodes within the same cluster have an edge between them with probability p, while a pair of nodes belonging to different clusters have an edge between them with probability q. For simplicity we assume q = (1 p). The model then iterates over each pair of nodes. For each such pair that belongs to same cluster, it samples an edge as Bernoulli(p), otherwise as Bernoulli(1 p). This provides us with a {0, 1} adjacency matrix.\nWe compare against two versions of spectral clustering, which is a standard technique applied to find communities in a graph. The method takes as input the n⇥ n adjacency matrix A, which is a {0, 1} matrix with an entry Aij = 1 if there is an edge between node i and j, and is 0 otherwise. From the adjacency matrix, the graph Laplacian L is constructed. The Laplacian may be unnormalized, in which case it is simply L = D A, where D is the diagonal matrix of degrees of nodes. A normalized Laplacian is\ncomputed as Lnorm = D 1/2LD 1/2. After calculating the Laplacian, the algorithm solves for bottom k eigenvectors of the Laplacian, and then apply k-means clustering on the rows of the thus obtained eigenvector matrix. We refer to the works of Shi & Malik (2000); Ng et al. (2001) for the specific details of clustering algorithms using unnormalized and normalized graph Laplacian respectively.\nWe use our greedy algorithm to cluster the graph by optimizing a logistic PCA objective function, which is a special case of the exponential family PCA (Collins et al., 2001). For a given matrix X, each entry Xij is assumed to be independently drawn with likelihood proportional to exp h⇥ij ,Xiji G(⇥ij), where ⇥ is the true underlying parameter, and G(·) is the partition function corresponding to a generalized linear model (GLM). It is easy to see we can apply our framework of greedy selection by defining `(·) as the log-likelihood:\n`(⇥) = h⇥,Xi X\ni,j\nlogG(⇥ij),\nwhere ⇥ is the true parameter matrix of p and q that generates a realization of A. Since the true ⇥ is low rank, we get the low rank constrained optimization problem:\nmax rank(⇥)k `(⇥),\nwhere k is a hyperparameter suggesting the true number of clusters. Note that lack of knowledge of true value of k is not more restrictive than spectral clustering algorithms which typically also require the true value of k. Having cast the clustering problem in the same form as (4), we can apply our greedy selection algorithm as opposed to the more costly alternating minimizing algorithms suggested by Collins et al. (2001).\nWe generate the data as follows. For n = 100 nodes, and fixed number of cluster k = 5, we vary the within cluster edge generation probability p from 0.55 to 0.95 in increments of 0.05, and use the Stochastic Block model to generate a noisy graph with each p. Note that smaller p implies that the sampled graph will be more noisy and likely to be more different than the underlying clustering.\nWe compare against the spectral clustering algorithm using unnormalized Laplacian of Shi & Malik (2000) which we label “Spectral unnorm{k}” for k = {3, 5, 10}, and the spectral clustering algorithm using normalized Laplacian of Ng et al. (2001) which we label “Spectral norm{k}” for k = {3, 5, 10}. We use Algorithm 2 which we label “Greedy{k}” for k = {3, 5, 10}. For each of these models, the referred k is the supplied hyperparameter. We report the least squares error of the output from each model to the true underlying ⇥ (generalization error), and to the instantiation used for training X (reconstruction error).\nFigure 1 shows that the greedy logistic PCA performs well in not only recreating the given noisy matrix (reconstruction) but also captures the true low rank structure better (generalization). Further, note that providing the true hyperparameter k is vital for spectral clustering algorithms, while on the other hand greedy is less sensitive to k. This is very useful in practice as k is typically not known. Spectral clustering algorithms typically select k by computing an SVD and rerunning k-means for different values of k. In addition to being more robust, our greedy algorithm does not need to be rerun for different values of k – it produces solutions incrementally."
  }, {
    "heading": "6.2. Word Embeddings",
    "text": "Algorithms for embedding text into a vector space yield representations that can be quite beneficial in many applications, e.g. features for sentiment analysis. Mikolov et al. (2013b) proposed a context-based embedding called skipgram or word2vec. The context of a word can be defined as a set of words before, around, or after the respective word. Their model strives to find an embedding of each word so that the representation predicts the embedding of each context word around it. Levy & Goldberg (2014) subsequently showed that the word embedding model proposed by Mikolov et al. (2013b) can be reinterpreted as matrix factorization of the PMI matrix constructed as follows. A word c is in context of w if it lies within the respective window of w. The PMI matrix is then calculated as\nPMIw,c = log ✓ p(w, c)\np(w)p(c)\n◆ .\nIn practice the probabilities p(w, c), p(w), p(c) are replaced by their empirical counterparts. Further, note that p(w, c) is 0 if words c and w do not coexist in the same context, which yields 1 for PMI. Levy & Goldberg (2014) suggest using an alternative: PPMIw,c = max{PMIw,c, 0}. They also suggest variations of PMI hyper parameterized by k which corresponds to the number of negative samples in the training of the original skip gram model.\nWe employ the binomial PCA model on the normalized count matrix (instead of the PMI), in a manner similar to the clustering approach in Section 6.1. The normalized count matrix is calculated simply as p(w,c)p(w) , without taking logarithms. This gives us a probability matrix which has each entry between 0 and 1, and which can be factorized under the binomial model greedily as per Algorithm 2.\nWe empirically study the embeddings obtained by binomial factorization on two tasks – word similarity and analogies. For word similarity, we use the W353 dataset (Finkelstein et al., 2001) and the MEN data (Bruni et al., 2012). Both these datasets contain words with human assigned similarity scores. We evaluate the embeddings by their cosine similarity, and measuring the correlation with the available human ratings. The fraction of correctly answered queries are returned as the metric. For the analogy task, we use the Microsoft Research (MSR) syntactic analogies (Mikolov et al., 2013c) and the Google mixed analogies dataset (Mikolov et al., 2013a). For completing analogy a:b::c:x, the prediction is calculated as argmaxx cos(c,x) cos(b,x) cos(a,x) . To compute accuracy, we use the multiplication similarity metric as used by Levy & Goldberg (2014). To train the word embeddings, we use the 2013 news crawl dataset1. We filter out stop words, non-ASCII characters, and words occurring less than\n1http://www.statmt.org/wmt14/ training-monolingual-news-crawl\n2000 times (which yields a vocabulary of 6713). Note that since we keep only the most common words, several queries from the datasets are invalid because we do not have embeddings for words appearing in them. However, we do include them by assigning invalid queries a value of 0 and reporting the overall average over the entire dataset.\nTable 1 shows the empirical evaluation. SVD and PPMI are the models proposed by Levy & Goldberg (2014), while SGNS is the skipgram with negative sampling model of Mikolov et al. (2013b). We run each of these for k = {5, 10, 15, 20} and report the best results. This shows that alternative factorizations such as our application of binomial PCA can be more consistent and competitive with other embedding methods.\nConclusion: We have connected the problem of greedy low rank matrix estimation to that of submodular optimization. Through that connection we have provided improved exponential rates of convergence for the algorithm. An interesting area of future study will be to connect these ideas to general atoms or dictionary elements."
  }, {
    "heading": "Acknowledgements",
    "text": "We thank the anonymous reviewers for their helpful feedback. Research supported by William Hartwig Fellowship, NSF Grants CCF 1344179, 1344364, 1407278, 1422549, 1618689, IIS 1421729, and ARO YIP W911NF-14-1-0258."
  }],
  "year": 2017,
  "references": [{
    "title": "Approximation and learning by greedy algorithms",
    "authors": ["Barron", "Andrew R", "Cohen", "Albert", "Dahmen", "Wolfgang", "DeVore", "Ronald A"],
    "venue": "The Annals of Statistics,",
    "year": 2008
  }, {
    "title": "Fast low-rank estimation by projected gradient descent: General statistical and algorithmic guarantees",
    "authors": ["Chen", "Yudong", "Wainwright", "Martin J"],
    "venue": "arXiv, abs/1509.03025,",
    "year": 2015
  }, {
    "title": "A generalization of principal component analysis to the exponential family",
    "authors": ["Collins", "Michael", "Dasgupta", "Sanjoy", "Schapire", "Robert E"],
    "venue": "In Advances in Neural Information Processing Systems. MIT Press,",
    "year": 2001
  }, {
    "title": "Submodular meets Spectral: Greedy Algorithms for Subset Selection, Sparse Approximation and Dictionary Selection",
    "authors": ["Das", "Abhimanyu", "Kempe", "David"],
    "year": 2011
  }, {
    "title": "Lifted coordinate descent for learning with trace-norm regularization",
    "authors": ["Dudik", "Miro", "Harchaoui", "Zaid", "Malick", "Jerome"],
    "venue": "In AISTATS,",
    "year": 2012
  }, {
    "title": "Restricted Strong Convexity Implies Weak Submodularity",
    "authors": ["Elenberg", "Ethan R", "Khanna", "Rajiv", "Dimakis", "Alexandros G", "Negahban", "Sahand"],
    "venue": "Proc. NIPS Workshop on Learning in High Dimensions with Structure,",
    "year": 2016
  }, {
    "title": "A threshold of ln n for approximating set cover",
    "authors": ["Feige", "Uriel"],
    "venue": "Journal of the ACM (JACM),",
    "year": 1998
  }, {
    "title": "Placing search in context: the concept revisited",
    "authors": ["Finkelstein", "Lev", "Gabrilovich", "Evgeniy", "Matias", "Yossi", "Rivlin", "Ehud", "Solan", "Zach", "Wolfman", "Gadi", "Ruppin", "Eytan"],
    "year": 2001
  }, {
    "title": "On the exponential convergence of matching pursuits in quasi-incoherent dictionaries",
    "authors": ["Gribonval", "Rémi", "P. Vandergheynst"],
    "venue": "IEEE Trans. Inform. Theory,",
    "year": 2006
  }, {
    "title": "Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization",
    "authors": ["Jaggi", "Martin"],
    "venue": "In ICML, pp",
    "year": 2013
  }, {
    "title": "A simple algorithm for nuclear norm regularized problems",
    "authors": ["Jaggi", "Martin", "Sulovský", "Marek"],
    "venue": "Proceedings of the 27th International Conference on Machine Learning",
    "year": 2010
  }, {
    "title": "Low-rank matrix completion using alternating minimization",
    "authors": ["Jain", "Prateek", "Netrapalli", "Praneeth", "Sanghavi", "Sujay"],
    "venue": "In Symposium on Theory of Computing Conference,",
    "year": 2013
  }, {
    "title": "On iterative hard thresholding methods for high-dimensional m-estimation",
    "authors": ["Jain", "Prateek", "Tewari", "Ambuj", "Kar", "Purushottam"],
    "venue": "In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems",
    "year": 2014
  }, {
    "title": "Pursuits in Structured Non-Convex Matrix Factorizations",
    "authors": ["Khanna", "Rajiv", "Tschannen", "Michael", "Jaggi", "Martin"],
    "year": 2016
  }, {
    "title": "Scalable Greedy Support Selection via Weak Submodularity",
    "authors": ["Khanna", "Rajiv", "Elenberg", "Ethan R", "Dimakis", "Alexandros G", "Neghaban", "Sahand", "Ghosh", "Joydeep"],
    "year": 2017
  }, {
    "title": "On the Global Linear Convergence of Frank-Wolfe Optimization Variants",
    "authors": ["Lacoste-Julien", "Simon", "Jaggi", "Martin"],
    "venue": "NIPS",
    "year": 2015
  }, {
    "title": "Corrections to ”admira: Atomic decomposition for minimum rank approximation",
    "authors": ["Lee", "Kiryung", "Bresler", "Yoram"],
    "venue": "IEEE Trans. Information Theory,",
    "year": 2013
  }, {
    "title": "Neural word embedding as implicit matrix factorization",
    "authors": ["Levy", "Omer", "Goldberg", "Yoav"],
    "venue": "Advances in Neural Information Processing Systems",
    "year": 2014
  }, {
    "title": "A unified optimization view on generalized matching pursuit and frank-wolfe",
    "authors": ["Locatello", "Francesco", "Khanna", "Rajiv", "Tschannen", "Michael", "Jaggi", "Martin"],
    "venue": "In Proc. International Conference on Artificial Intelligence and Statistics (AISTATS),",
    "year": 2017
  }, {
    "title": "Regularized mestimators with nonconvexity: Statistical and algorithmic theory for local optima",
    "authors": ["Loh", "Po-Ling", "Wainwright", "Martin J"],
    "venue": "J. Mach. Learn. Res.,",
    "year": 2015
  }, {
    "title": "Efficient estimation of word representations in vector space",
    "authors": ["Mikolov", "Tomas", "Chen", "Kai", "Corrado", "Greg", "Dean", "Jeffrey"],
    "venue": "CoRR, abs/1301.3781,",
    "year": 2013
  }, {
    "title": "Linguistic regularities in continuous space word representations",
    "authors": ["Mikolov", "Tomas", "Yih", "Scott Wen-tau", "Zweig", "Geoffrey"],
    "venue": "In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo-",
    "year": 2013
  }, {
    "title": "Estimation of (near) low-rank matrices with noise and high-dimensional scaling",
    "authors": ["Negahban", "Sahand", "Wainwright", "Martin J"],
    "venue": "The Annals of Statistics,",
    "year": 2011
  }, {
    "title": "Restricted strong convexity and weighted matrix completion: Optimal bounds with noise",
    "authors": ["Negahban", "Sahand", "Wainwright", "Martin J"],
    "year": 2012
  }, {
    "title": "A Unified Framework for HighDimensional Analysis of M-Estimators with Decomposable Regularizers",
    "authors": ["Negahban", "Sahand", "Ravikumar", "Pradeep", "Yu", "Bin", "Wainwright", "Martin J"],
    "venue": "Statistica Sinica,",
    "year": 2012
  }, {
    "title": "An analysis of approximations for maximizing submodular set functionsi",
    "authors": ["Nemhauser", "George L", "Wolsey", "Laurence A", "Fisher", "Marshall L"],
    "venue": "Mathematical Programming,",
    "year": 1978
  }, {
    "title": "On spectral clustering: Analysis and an algorithm",
    "authors": ["Ng", "Andrew Y", "Jordan", "Michael I", "Weiss", "Yair"],
    "venue": "In ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS,",
    "year": 2001
  }, {
    "title": "Provable non-convex projected gradient descent for a class of constrained matrix optimization problems",
    "authors": ["Park", "Dohyung", "Kyrillidis", "Anastasios", "Bhojanapalli", "Srinadh", "Caramanis", "Constantine", "Sanghavi", "Sujay"],
    "venue": "arXiv, abs/1606.01316,",
    "year": 2016
  }, {
    "title": "Forward backward greedy algorithms for atomic norm regularization",
    "authors": ["Rao", "Nikhil", "Shah", "Parikshit", "Wright", "Stephen"],
    "venue": "IEEE Transactions on Signal Processing,",
    "year": 2015
  }, {
    "title": "Estimation of high-dimensional low-rank matrices",
    "authors": ["Rohde", "Angelika", "Tsybakov", "Alexandre B"],
    "venue": "The Annals of Statistics,",
    "year": 2011
  }, {
    "title": "Large-scale convex minimization with a low-rank constraint",
    "authors": ["S Shalev-Shwartz", "A Gonen", "O. Shamir"],
    "venue": "In ICML,",
    "year": 2011
  }, {
    "title": "Normalized cuts and image segmentation",
    "authors": ["Shi", "Jianbo", "Malik", "Jitendra"],
    "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
    "year": 2000
  }, {
    "title": "Orthogonal rank-one matrix pursuit for low rank matrix completion",
    "authors": ["Wang", "Zheng", "Lai", "Ming-Jun", "Lu", "Zhaosong", "Fan", "Wei", "Davulcu", "Hasan", "Ye", "Jieping"],
    "venue": "SIAM Journal on Scientific Computing,",
    "year": 2015
  }],
  "id": "SP:46f9878bd27d148bd277670f0a8407adf5debbce",
  "authors": [{
    "name": "Rajiv Khanna",
    "affiliations": []
  }, {
    "name": "Ethan R. Elenberg",
    "affiliations": []
  }, {
    "name": "Alexandros G. Dimakis",
    "affiliations": []
  }, {
    "name": "Joydeep Ghosh",
    "affiliations": []
  }, {
    "name": "Sahand Negahban",
    "affiliations": []
  }],
  "abstractText": "We provide new approximation guarantees for greedy low rank matrix estimation under standard assumptions of restricted strong convexity and smoothness. Our novel analysis also uncovers previously unknown connections between the low rank estimation and combinatorial optimization, so much so that our bounds are reminiscent of corresponding approximation bounds in submodular maximization. Additionally, we also provide statistical recovery guarantees. Finally, we present empirical comparison of greedy estimation with established baselines on two important real-world problems.",
  "title": "On Approximation Guarantees for Greedy Low Rank Optimization"
}