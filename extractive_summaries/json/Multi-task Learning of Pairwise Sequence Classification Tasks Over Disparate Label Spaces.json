{
  "sections": [{
    "text": "Proceedings of NAACL-HLT 2018, pages 1896–1906 New Orleans, Louisiana, June 1 - 6, 2018. c©2018 Association for Computational Linguistics"
  }, {
    "heading": "1 Introduction",
    "text": "Multi-task learning (MTL) and semi-supervised learning are both successful paradigms for learning in scenarios with limited labelled data and have in recent years been applied to almost all areas of NLP. Applications of MTL in NLP, for example, include partial parsing (Søgaard and Goldberg, 2016), text normalisation (Bollman et al., 2017), neural machine translation (Luong et al., 2016), and keyphrase boundary classification (Augenstein and Søgaard, 2017).\nContemporary work in MTL for NLP typically focuses on learning representations that are useful across tasks, often through hard parameter sharing of hidden layers of neural networks (Collobert et al., 2011; Søgaard and Goldberg, 2016). If tasks share optimal hypothesis classes at the level of these representations, MTL leads to improvements (Baxter, 2000). However, while sharing hidden layers of neural networks is an effective regulariser (Søgaard and Goldberg, 2016), we potentially loose synergies between the classification functions trained to associate these representations with class labels. This paper sets out to build an architecture in which such synergies are exploited,\n?The first two authors contributed equally.\nwith an application to pairwise sequence classification tasks. Doing so, we achieve a new state of the art on topic-based sentiment analysis.\nFor many NLP tasks, disparate label sets are weakly correlated, e.g. part-of-speech tags correlate with dependencies (Hashimoto et al., 2017), sentiment correlates with emotion (Felbo et al., 2017; Eisner et al., 2016), etc. We thus propose to induce a joint label embedding space (visualised in Figure 2) using a Label Embedding Layer that allows us to model these relationships, which we show helps with learning.\nIn addition, for tasks where labels are closely related, we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions. To this end, we propose to train a Label Transfer Network (LTN) jointly with the model to produce pseudo-labels across tasks.\nThe LTN can be used to label unlabelled and auxiliary task data by utilising the ‘dark knowledge’ (Hinton et al., 2015) contained in auxiliary model predictions. This pseudo-labelled data is then incorporated into the model via semisupervised learning, leading to a natural combination of multi-task learning and semi-supervised learning. We additionally augment the LTN with data-specific diversity features (Ruder and Plank, 2017) that aid in learning.\nContributions Our contributions are: a) We model the relationships between labels by inducing a joint label space for multi-task learning. b) We propose a Label Transfer Network that learns to transfer labels between tasks and propose to use semi-supervised learning to leverage them for training. c) We evaluate MTL approaches on a variety of classification tasks and shed new light on settings where multi-task learning works. d) We perform an extensive ablation study of our model.\n1896\ne) We report state-of-the-art performance on topicbased sentiment analysis."
  }, {
    "heading": "2 Related work",
    "text": "Learning task similarities Existing approaches for learning similarities between tasks enforce a clustering of tasks (Evgeniou et al., 2005; Jacob et al., 2009), induce a shared prior (Yu et al., 2005; Xue et al., 2007; Daumé III, 2009), or learn a grouping (Kang et al., 2011; Kumar and Daumé III, 2012). These approaches focus on homogeneous tasks and employ linear or Bayesian models. They can thus not be directly applied to our setting with tasks using disparate label sets.\nMulti-task learning with neural networks Recent work in multi-task learning goes beyond hard parameter sharing (Caruana, 1993) and considers different sharing structures, e.g. only sharing at lower layers (Søgaard and Goldberg, 2016) and induces private and shared subspaces (Liu et al., 2017; Ruder et al., 2017). These approaches, however, are not able to take into account relationships between labels that may aid in learning. Another related direction is to train on disparate annotations of the same task (Chen et al., 2016; Peng et al., 2017). In contrast, the different nature of our tasks requires a modelling of their label spaces.\nSemi-supervised learning There exists a wide range of semi-supervised learning algorithms, e.g., self-training, co-training, tri-training, EM, and combinations thereof, several of which have also been used in NLP. Our approach is probably most closely related to an algorithm called coforest (Li and Zhou, 2007). In co-forest, like here, each learner is improved with unlabeled instances labeled by the ensemble consisting of all the other learners. Note also that several researchers have proposed using auxiliary tasks that are unsupervised (Plank et al., 2016; Rei, 2017), which also leads to a form of semi-supervised models.\nLabel transformations The idea of manually mapping between label sets or learning such a mapping to facilitate transfer is not new. Zhang et al. (2012) use distributional information to map from a language-specific tagset to a tagset used for other languages, in order to facilitate crosslingual transfer. More related to this work, Kim et al. (2015) use canonical correlation analysis to transfer between tasks with disparate label spaces. There has also been work on label transformations\nin the context of multi-label classification problems (Yeh et al., 2017)."
  }, {
    "heading": "3 Multi-task learning with disparate label spaces",
    "text": ""
  }, {
    "heading": "3.1 Problem definition",
    "text": "In our multi-task learning scenario, we have access to labelled datasets for T tasks T1, . . . , TT at training time with a target task TT that we particularly care about. The training dataset for task Ti consists of Nk examples XTi = {xTi1 , . . . , xTiNk} and their labels YTi = {yTi1 , . . . ,yTiNk}. Our base model is a deep neural network that performs classic hard parameter sharing (Caruana, 1993): It shares its parameters across tasks and has task-specific softmax output layers, which output a probability distribution pTi for task Ti according to the following equation:\npTi = softmax(WTih+ bTi) (1)\nwhere softmax(x) = ex/ ∑‖x‖\ni=1 e xi , WTi ∈\nRLi×h, bTi ∈ RLi is the weight matrix and bias term of the output layer of task Ti respectively, h ∈ Rh is the jointly learned hidden representation, Li is the number of labels for task Ti, and h is the dimensionality of h.\nThe MTL model is then trained to minimise the sum of the individual task losses:\nL = λ1L1 + . . .+ λTLT (2) where Li is the negative log-likelihood objec-\ntive Li = H(pTi ,yTi) = − 1N ∑ n ∑ j logp Ti j y Ti j and λi is a parameter that determines the weight of task Ti. In practice, we apply the same weight to all tasks. We show the full set-up in Figure 1a."
  }, {
    "heading": "3.2 Label Embedding Layer",
    "text": "In order to learn the relationships between labels, we propose a Label Embedding Layer (LEL) that embeds the labels of all tasks in a joint space. Instead of training separate softmax output layers as above, we introduce a label compatibility function c(·, ·) that measures how similar a label with embedding l is to the hidden representation h:\nc(l,h) = l · h (3) where · is the dot product. This is similar to the Universal Schema Latent Feature Model introduced by Riedel et al. (2013). In contrast to\n12/6/2017 multi-task_learning.html\n1/2\n12/6/2017 label_embedding_layer.html\n1/2\n12/6/2017 label_transfer_network.html\n2/3\nother models that use the dot product in the objective function, we do not have to rely on negative sampling and a hinge loss (Collobert and Weston, 2008) as negative instances (labels) are known. For efficiency purposes, we use matrix multiplication instead of a single dot product and softmax instead of sigmoid activations:\np = softmax(Lh) (4)\nwhere L ∈ R( ∑\ni Li)×l is the label embedding matrix for all tasks and l is the dimensionality of the label embeddings. In practice, we set l to the hidden dimensionality h. We use padding if l < h. We apply a task-specific mask to L in order to obtain a task-specific probability distribution pTi . The LEL is shared across all tasks, which allows us to learn the relationships between the labels in the joint embedding space. We show MTL with the LEL in Figure 1b."
  }, {
    "heading": "3.3 Label Transfer Network",
    "text": "The LEL allows us to learn the relationships between labels. In order to make use of these relationships, we would like to leverage the predictions of our auxiliary tasks to estimate a label for the target task. To this end, we introduce the Label Transfer Network (LTN). This network takes the auxiliary task outputs as input. In particular, we define the output label embedding oi of task Ti as\nthe sum of the task’s label embeddings lj weighted with their probability pTij :\noi =\nLi∑\nj=1\npTij lj (5)\nThe label embeddings l encode general relationship between labels, while the model’s probability distribution pTi over its predictions encodes finegrained information useful for learning (Hinton et al., 2015). The LTN is trained on labelled target task data. For each example, the corresponding label output embeddings of the auxiliary tasks are fed into a multi-layer perceptron (MLP), which is trained with a negative log-likelihood objective LLTN to produce a pseudo-label zTT for the target task TT :\nLTNT = MLP([o1, . . . ,oT−1]) (6)\nwhere [·, ·] designates concatenation. The mapping of the tasks in the LTN yields another signal that can be useful for optimisation and act as a regulariser. The LTN can also be seen as a mixtureof-experts layer (Jacobs et al., 1991) where the experts are the auxiliary task models. As the label embeddings are learned jointly with the main model, the LTN is more sensitive to the relationships between labels than a separately learned mixture-of-experts model that only relies on the experts’ output distributions. As such, the LTN\ncan be directly used to produce predictions on unseen data."
  }, {
    "heading": "3.4 Semi-supervised MTL",
    "text": "The downside of the LTN is that it requires additional parameters and relies on the predictions of the auxiliary models, which impacts the runtime during testing. Instead, of using the LTN for prediction directly, we can use it to provide pseudolabels for unlabelled or auxiliary task data by utilising auxiliary predictions for semi-supervised learning.\nWe train the target task model on the pseudolabelled data to minimise the squared error between the model predictions pTi and the pseudo labels zTi produced by the LTN:\nLpseudo =MSE(pTT , zTT ) = ||pTT − zTT ||2 (7)\nWe add this loss term to the MTL loss in Equation 2. As the LTN is learned together with the MTL model, pseudo-labels produced early during training will likely not be helpful as they are based on unreliable auxiliary predictions. For this reason, we first train the base MTL model until convergence and then augment it with the LTN. We show the full semi-supervised learning procedure in Figure 1c."
  }, {
    "heading": "3.5 Data-specific features",
    "text": "When there is a domain shift between the datasets of different tasks as is common for instance when learning NER models with different label sets, the output label embeddings might not contain sufficient information to bridge the domain gap.\nTo mitigate this discrepancy, we augment the LTN’s input with features that have been found useful for transfer learning (Ruder and Plank, 2017). In particular, we use the number of word types, type-token ratio, entropy, Simpson’s index, and Rényi entropy as diversity features. We calculate each feature for each example.1 The features are then concatenated with the input of the LTN."
  }, {
    "heading": "3.6 Other multi-task improvements",
    "text": "Hard parameter sharing can be overly restrictive and provide a regularisation that is too heavy when jointly learning many tasks. For this reason, we propose several additional improvements that seek\n1For more information regarding the feature calculation, refer to Ruder and Plank (2017).\nto alleviate this burden: We use skip-connections, which have been shown to be useful for multitask learning in recent work (Ruder et al., 2017). Furthermore, we add a task-specific layer before the output layer, which is useful for learning taskspecific transformations of the shared representations (Søgaard and Goldberg, 2016; Ruder et al., 2017)."
  }, {
    "heading": "4 Experiments",
    "text": "For our experiments, we evaluate on a wide range of text classification tasks. In particular, we choose pairwise classification tasks—i.e. those that condition the reading of one sequence on another sequence—as we are interested in understanding if knowledge can be transferred even for these more complex interactions. To the best of our knowledge, this is the first work on transfer learning between such pairwise sequence classification tasks. We implement all our models in Tensorflow (Abadi et al., 2016) and release the code at https://github.com/ coastalcph/mtl-disparate."
  }, {
    "heading": "4.1 Tasks and datasets",
    "text": "We use the following tasks and datasets for our experiments, show task statistics in Table 1, and summarise examples in Table 2:\nTopic-based sentiment analysis Topic-based sentiment analysis aims to estimate the sentiment of a tweet known to be about a given topic. We use the data from SemEval-2016 Task 4 Subtask B and C (Nakov et al., 2016) for predicting on a twopoint scale of positive and negative (Topic-2) and five-point scale ranging from highly negative to highly positive (Topic-5) respectively. An example from this dataset would be to classify the\ntweet “No power at home, sat in the dark listening to AC/DC in the hope it’ll make the electricity come back again” known to be about the topic “AC/DC”, which is labelled as a positive sentiment. The evaluation metrics for Topic-2 and Topic-5 are macro-averaged recall (ρPN ) and macro-averaged mean absolute error (MAEM ) respectively, which are both averaged across topics.\nTarget-dependent sentiment analysis Targetdependent sentiment analysis (Target) seeks to classify the sentiment of a text’s author towards an entity that occurs in the text as positive, negative, or neutral. We use the data from Dong et al. (2014). An example instance is the expression “how do you like settlers of catan for the wii?” which is labelled as neutral towards the target “wii’.’ The evaluation metric is macroaveraged F1 (FM1 ).\nAspect-based sentiment analysis Aspect-based sentiment analysis is the task of identifying\nwhether an aspect, i.e. a particular property of an item is associated with a positive, negative, or neutral sentiment (Ruder et al., 2016). We use the data of SemEval-2016 Task 5 Subtask 1 Slot 3 (Pontiki et al., 2016) for the laptops (ABSA-L) and restaurants (ABSA-R) domains. An example is the sentence “For the price, you cannot eat this well in Manhattan”, labelled as positive towards both the aspects “restaurant prices” and “food quality”. The evaluation metric for both domains is accuracy (Acc).\nStance detection Stance detection (Stance) requires a model, given a text and a target entity, which might not appear in the text, to predict whether the author of the text is in favour or against the target or whether neither inference is likely (Augenstein et al., 2016). We use the data of SemEval-2016 Task 6 Subtask B (Mohammad et al., 2016). An example from this dataset would be to predict the stance of the tweet “Be prepared - if we continue the policies of the liberal left, we will be #Greece” towards the topic “Donald Trump”, labelled as “favor”. The evaluation metric is the macro-averaged F1 score of the “favour” and “against” classes (FFA1 ).\nFake news detection The goal of fake news detection in the context of the Fake News Challenge2 is to estimate whether the body of a news article agrees, disagrees, discusses, or is unrelated towards a headline. We use the data from the first stage of the Fake News Challenge (FNC-1). An example for this dataset is the document “Dino Ferrari hooked the whopper wels catfish, (...), which could be the biggest in the world.” with the headline “Fisherman lands 19 STONE catfish which could be the biggest in the world to be hooked” labelled as “agree”. The evaluation metric is accuracy (Acc)3.\nNatural language inference Natural language inference is the task of predicting whether one sentences entails, contradicts, or is neutral towards another one. We use the Multi-Genre NLI corpus (MultiNLI) from the RepEval 2017 shared task (Nangia et al., 2017). An example for an instance would be the sentence pair “Fun for only children”, “Fun for adults and children”, which are in a “contradiction” relationship. The evaluation metric is accuracy (Acc).\n2http://www.fakenewschallenge.org/ 3We use the same metric as Riedel et al. (2017)."
  }, {
    "heading": "4.2 Base model",
    "text": "Our base model is the Bidirectional Encoding model (Augenstein et al., 2016), a state-of-theart model for stance detection that conditions a bidirectional LSTM (BiLSTM) encoding of a text on the BiLSTM encoding of the target. Unlike Augenstein et al. (2016), we do not pre-train word embeddings on a larger set of unlabelled indomain text for each task as we are mainly interested in exploring the benefit of multi-task learning for generalisation."
  }, {
    "heading": "4.3 Training settings",
    "text": "We use BiLSTMs with one hidden layer of 100 dimensions, 100-dimensional randomly initialised word embeddings, a label embedding size of 100. We train our models with RMSProp, a learning rate of 0.001, a batch size of 128, and early stopping on the validation set of the main task with a patience of 3."
  }, {
    "heading": "5 Results",
    "text": "Our main results are shown in Table 3, with a comparison against the state of the art. We present the results of our multi-task learning network with label embeddings (MTL + LEL), multi-task learning with label transfer (MTL + LEL + LTN), and the semi-supervised extension of this model. On 7/8 tasks, at least one of our architectures is better than single-task learning; and in 4/8, all our architectures are much better than single-task learning.\nThe state-of-the-art systems we compare against are often highly specialised, taskdependent architectures. Our architectures, in contrast, have not been optimised to compare\nfavourably against the state of the art, as our main objective is to develop a novel approach to multi-task learning leveraging synergies between label sets and knowledge of marginal distributions from unlabeled data. For example, we do not use pre-trained word embeddings (Augenstein et al., 2016; Palogiannidi et al., 2016; Vo and Zhang, 2015), class weighting to deal with label imbalance (Balikas and Amini, 2016), or domainspecific sentiment lexicons (Brun et al., 2016; Kumar et al., 2016). Nevertheless, our approach outperforms the state-of-the-art on two-way topic-based sentiment analysis (Topic-2).\nThe poor performance compared to the stateof-the-art on FNC and MultiNLI is expected; as we alternate among the tasks during training, our model only sees a comparatively small number of examples of both corpora, which are one and two orders of magnitude larger than the other datasets. For this reason, we do not achieve good performance on these tasks as main tasks, but they are still useful as auxiliary tasks as seen in Table 4."
  }, {
    "heading": "6 Analysis",
    "text": ""
  }, {
    "heading": "6.1 Label Embeddings",
    "text": "Our results above show that, indeed, modelling the similarity between tasks using label embeddings sometimes leads to much better performance. Figure 2 shows why. In Figure 2, we visualise the label embeddings of an MTL+LEL model trained on all tasks, using PCA. As we can see, similar labels are clustered together across tasks, e.g. there are two positive clusters (middle-right and top-right), two negative clusters (middle-left and bottom-left), and two neutral clusters (middle-top\nand middle-bottom). Our visualisation also provides us with a picture of what auxilary tasks are beneficial, and to what extent we can expect synergies from multitask learning. For instance, the notion of positive sentiment appears to be very similar across the topic-based and aspect-based tasks, while the conceptions of negative and neutral sentiment differ. In addition, we can see that the model has failed to learn a relationship between MultiNLI labels and those of other tasks, possibly accounting for its poor performance on the inference task. We did not evaluate the correlation between label embeddings and task performance, but Bjerva (2017) recently suggested that mutual information of target and auxiliary task label sets is a good predictor of gains from multi-task learning."
  }, {
    "heading": "6.2 Auxilary Tasks",
    "text": "For each task, we show the auxiliary tasks that achieved the best performance on the development data in Table 4. In contrast to most existing work, we did not restrict ourselves to performing multitask learning with only one auxiliary task (Søgaard and Goldberg, 2016; Bingel and Søgaard, 2017). Indeed we find that most often a combination of auxiliary tasks achieves the best performance. Indomain tasks are less used than we assumed; only Target is consistently used by all Twitter main tasks. In addition, tasks with a higher number of labels, e.g. Topic-5 are used more often. Such tasks provide a more fine-grained reward signal, which may help in learning representations that generalise better. Finally, tasks with large amounts\nof training data such as FNC-1 and MultiNLI are also used more often. Even if not directly related, the larger amount of training data that can be indirectly leveraged via multi-task learning may help the model focus on relevant parts of the representation space (Caruana, 1993). These observations shed additional light on when multi-task learning may be useful that go beyond existing studies (Bingel and Søgaard, 2017)."
  }, {
    "heading": "6.3 Ablation analysis",
    "text": "We now perform a detailed ablation analysis of our model, the results of which are shown in Table 5. We ablate whether to use the LEL (+ LEL), whether to use the LTN (+ LTN), whether to use the LEL output or the main model output for prediction (main model output is indicated by , main model), and whether to use the LTN as a regulariser or for semi-supervised learning (semisupervised learning is indicated by + semi). We further test whether to use diversity features (– diversity feats) and whether to use main model predictions for the LTN (+ main model feats).\nOverall, the addition of the Label Embedding Layer improves the performance over regular MTL in almost all cases."
  }, {
    "heading": "6.4 Label transfer network",
    "text": "To understand the performance of the LTN, we analyse learning curves of the relabelling function vs. the main model. Examples for all tasks without semi-supervised learning are shown in Figure 3. One can observe that the relabelling model does not take long to converge as it has fewer parameters than the main model. Once the relabelling model is learned alongside the main\nmodel, the main model performance first stagnates, then starts to increase again. For some of the tasks, the main model ends up with a higher task score than the relabelling model. We hypothesise that the softmax predictions of other, even highly related tasks are less helpful for predicting main labels than the output layer of the main task model. At best, learning the relabelling model alongside the main model might act as a regulariser to the main model and thus improve the main model’s performance over a baseline MTL model, as it is the case for TOPIC-5 (see Table 5).\nTo further analyse the performance of the LTN, we look into to what degree predictions of the main model and the relabelling model for individual instances are complementary to one another. Or, said differently, we measure the percentage of correct predictions made only by the relabelling\nmodel or made only by the main model, relative to the number of correct predictions overall. Results of this for each task are shown in Table 6 for the LTN with and without semi-supervised learning. One can observe that, even though the relabelling function overall contributes to the score to a lesser degree than the main model, a substantial number of correct predictions are made by the relabelling function that are missed by the main model. This is most prominently pronounced for ABSA-R, where the proportion is 14.6."
  }, {
    "heading": "7 Conclusion",
    "text": "We have presented a multi-task learning architecture that (i) leverages potential synergies between classifier functions relating shared representations with disparate label spaces and (ii) enables learning from mixtures of labeled and unlabeled data. We have presented experiments with combinations of eight pairwise sequence classification tasks. Our results show that leveraging synergies between label spaces sometimes leads to big improvements, and we have presented a new state of the art for topic-based sentiment analysis. Our analysis further showed that (a) the learned label embeddings were indicative of gains from multitask learning, (b) auxiliary tasks were often beneficial across domains, and (c) label embeddings almost always led to better performance. We also investigated the dynamics of the label transfer network we use for exploiting the synergies between disparate label spaces."
  }, {
    "heading": "Acknowledgments",
    "text": "Sebastian Ruder is supported by the Irish Research Council Grant Number EBPPG/2014/30 and Science Foundation Ireland Grant Number SFI/12/RC/2289. Anders Søgaard is supported by the ERC Starting Grant Number 313695. Isabelle Augenstein is supported by Eurostars grant Number E10138. We further gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU used for this research."
  }],
  "year": 2018,
  "references": [{
    "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
    "authors": ["Martín Abadi", "Ashish Agarwal", "Paul Barham", "Eugene Brevdo", "Zhifeng Chen", "Craig Citro", "Greg S Corrado", "Andy Davis", "Jeffrey Dean", "Matthieu Devin"],
    "year": 2016
  }, {
    "title": "Twitter Stance Detection with Bidirectional Conditional Encoding",
    "authors": ["Isabelle Augenstein", "Tim Rocktäschel", "Andreas Vlachos", "Kalina Bontcheva."],
    "venue": "Proceedings of EMNLP.",
    "year": 2016
  }, {
    "title": "Multitask learning of keyphrase boundary detection",
    "authors": ["Isabelle Augenstein", "Anders Søgaard."],
    "venue": "Proceedings of ACL.",
    "year": 2017
  }, {
    "title": "TwiSE at SemEval-2016 Task 4: Twitter Sentiment Classification",
    "authors": ["Georgios Balikas", "Massih-Reza Amini."],
    "venue": "Proceedings of SemEval.",
    "year": 2016
  }, {
    "title": "A Model of Inductive Bias Learning",
    "authors": ["Jonathan Baxter."],
    "venue": "JAIR 12:149–198.",
    "year": 2000
  }, {
    "title": "Identifying beneficial task relations for multi-task learning in deep neural networks",
    "authors": ["Joachim Bingel", "Anders Søgaard."],
    "venue": "Proceedings of EACL.",
    "year": 2017
  }, {
    "title": "Will my auxiliary tagging task help? Estimating Auxiliary Tasks Effectivity in Multi-Task Learning",
    "authors": ["Johannes Bjerva."],
    "venue": "Proceedings of NODALIDA.",
    "year": 2017
  }, {
    "title": "Learning attention for historical text normalization by learning to pronounce",
    "authors": ["Marcel Bollman", "Joachim Bingel", "Anders Søgaard."],
    "venue": "Proceedings of ACL.",
    "year": 2017
  }, {
    "title": "XRCE at SemEval-2016 Task 5: Feedbacked Ensemble Modelling on Syntactico-Semantic Knowledge for Aspect Based Sentiment Analysis",
    "authors": ["Caroline Brun", "Julien Perez", "Claude Roux."],
    "venue": "Proceedings of SemEval .",
    "year": 2016
  }, {
    "title": "Multitask Learning: A Knowledge-Based Source of Inductive Bias",
    "authors": ["Rich Caruana."],
    "venue": "Proceedings of ICML.",
    "year": 1993
  }, {
    "title": "Neural Network for Heterogeneous Annotations",
    "authors": ["Hongshen Chen", "Yue Zhang", "Qun Liu."],
    "venue": "Proceedings of EMNLP.",
    "year": 2016
  }, {
    "title": "Recurrent neural network-based sentence encoder with gated attention for natural language inference",
    "authors": ["Qian Chen", "Xiaodan Zhu", "Zhen-Hua Ling", "Si Wei", "Hui Jiang", "Diana Inkpen."],
    "venue": "arXiv preprint arXiv:1708.01353 .",
    "year": 2017
  }, {
    "title": "A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning",
    "authors": ["Ronan Collobert", "Jason Weston."],
    "venue": "Proceedings of ICML.",
    "year": 2008
  }, {
    "title": "Natural language processing (almost) from scratch",
    "authors": ["Ronan Collobert", "Jason Weston", "Léon Bottou", "Michael Karlen", "Koray Kavukcuoglu", "Pavel Kuksa."],
    "venue": "The Journal of Machine Learning Research 12:2493–2537.",
    "year": 2011
  }, {
    "title": "Bayesian multitask learning with latent hierarchies",
    "authors": ["Hal Daumé III."],
    "venue": "Proceedings of UAI.",
    "year": 2009
  }, {
    "title": "Adaptive Recursive Neural Network for Target-dependent Twitter Sentiment Classification",
    "authors": ["Li Dong", "Furu Wei", "Chuanqi Tan", "Duyu Tang", "Ming Zhou", "Ke Xu."],
    "venue": "Proceedings of ACL. pages 49–54.",
    "year": 2014
  }, {
    "title": "emoji2vec: Learning Emoji Representations from their Description",
    "authors": ["Ben Eisner", "Tim Rocktäschel", "Isabelle Augenstein", "Matko Bosnjak", "Sebastian Riedel."],
    "venue": "Proceedings of SocialNLP.",
    "year": 2016
  }, {
    "title": "Learning multiple tasks with kernel methods",
    "authors": ["Theodoros Evgeniou", "Charles A. Micchelli", "Massimiliano Pontil."],
    "venue": "Journal of Machine Learning Research 6:615–637.",
    "year": 2005
  }, {
    "title": "Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm",
    "authors": ["Bjarke Felbo", "Alan Mislove", "Anders Søgaard", "Iyad Rahwan", "Sune Lehmann."],
    "venue": "Proceedings of EMNLP.",
    "year": 2017
  }, {
    "title": "A Joint ManyTask Model: Growing a Neural Network for Multiple NLP Tasks",
    "authors": ["Kazuma Hashimoto", "Caiming Xiong", "Yoshimasa Tsuruoka", "Richard Socher."],
    "venue": "Proceedings of EMNLP.",
    "year": 2017
  }, {
    "title": "Distilling the Knowledge in a Neural Network",
    "authors": ["Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean."],
    "venue": "arXiv preprint arXiv:1503.02531 .",
    "year": 2015
  }, {
    "title": "Clustered Multi-Task Learning: A Convex Formulation",
    "authors": ["Laurent Jacob", "Jean-Philippe Vert", "Francis R Bach", "Jean-philippe Vert."],
    "venue": "Proceedings of NIPS. pages 745–752.",
    "year": 2009
  }, {
    "title": "Adaptive Mixtures of Local Experts",
    "authors": ["Robert a. Jacobs", "Michael I. Jordan", "Steven J. Nowlan", "Geoffrey E. Hinton."],
    "venue": "Neural Computation 3(1):79–87.",
    "year": 1991
  }, {
    "title": "Learning with Whom to Share in Multi-task Feature Learning",
    "authors": ["Zhuoliang Kang", "Kristen Grauman", "Fei Sha."],
    "venue": "Proceedings of ICML.",
    "year": 2011
  }, {
    "title": "New Transfer Learning Techniques for Disparate Label Sets",
    "authors": ["Young-Bum Kim", "Karl Stratos", "Ruhi Sarikaya", "Minwoo Jeong."],
    "venue": "Proceedings of ACL.",
    "year": 2015
  }, {
    "title": "Learning Task Grouping and Overlap in Multi-task Learning",
    "authors": ["Abhishek Kumar", "Hal Daumé III."],
    "venue": "Proceedings of the 29th International Conference on Machine Learning pages 1383–1390.",
    "year": 2012
  }, {
    "title": "IIT-TUDA at SemEval2016 Task 5: Beyond Sentiment Lexicon: Combining Domain Dependency and Distributional Semantics Features for Aspect Based Sentiment Analysis",
    "authors": ["Ayush Kumar", "Sarah Kohail", "Amit Kumar", "Asif Ekbal", "Chris Biemann"],
    "year": 2016
  }, {
    "title": "Improve ComputerAided Diagnosis With Machine Learning Techniques Using Undiagnosed Samples",
    "authors": ["Ming Li", "Zhi-Hua Zhou."],
    "venue": "IEEE Transactions on Systems, Man and Cybernetics 37(6):1088– 1098.",
    "year": 2007
  }, {
    "title": "Adversarial Multi-task Learning for Text Classification",
    "authors": ["Pengfei Liu", "Xipeng Qiu", "Xuanjing Huang."],
    "venue": "Proceedings of ACL.",
    "year": 2017
  }, {
    "title": "Multi-task Sequence to Sequence Learning",
    "authors": ["Minh-Thang Luong", "Quoc V. Le", "Ilya Sutskever", "Oriol Vinyals", "Lukasz Kaiser."],
    "venue": "Proceedings of ICLR.",
    "year": 2016
  }, {
    "title": "Semeval-2016 task 6: Detecting stance in tweets",
    "authors": ["Saif Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry."],
    "venue": "Proceedings of SemEval.",
    "year": 2016
  }, {
    "title": "SemEval2016 Task 4: Sentiment Analysis in Twitter",
    "authors": ["Preslav Nakov", "Alan Ritter", "Sara Rosenthal", "Veselin Stoyanov", "Fabrizio Sebastiani."],
    "venue": "Proceedings of SemEval. San Diego, California.",
    "year": 2016
  }, {
    "title": "The RepEval 2017 Shared Task: Multi-Genre Natural Language Inference with Sentence Representations",
    "authors": ["Nikita Nangia", "Adina Williams", "Angeliki Lazaridou", "Samuel R. Bowman."],
    "venue": "Proceedings of RepEval.",
    "year": 2017
  }, {
    "title": "Deep Multitask Learning for Semantic Dependency Parsing",
    "authors": ["Hao Peng", "Sam Thomson", "Noah A Smith", "Paul G Allen."],
    "venue": "Proceedings of ACL 2017.",
    "year": 2017
  }, {
    "title": "Multilingual Part-of-Speech Tagging with Bidirectional Long Short-Term Memory Models and Auxiliary Loss",
    "authors": ["Barbara Plank", "Anders Søgaard", "Yoav Goldberg."],
    "venue": "Proceedings of ACL.",
    "year": 2016
  }, {
    "title": "Jiménez-Zafra, and Gülşen Eryiğit",
    "authors": ["talia Loukachevitch", "Evgeniy Kotelnikov", "Núria Bel", "Salud Maria"],
    "venue": "In Proceedings of SemEval",
    "year": 2016
  }, {
    "title": "Semi-supervised Multitask Learning for Sequence Labeling",
    "authors": ["Marek Rei."],
    "venue": "Proceedings of ACL 2017.",
    "year": 2017
  }, {
    "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance detection task",
    "authors": ["Benjamin Riedel", "Isabelle Augenstein", "Georgios P Spithourakis", "Sebastian Riedel."],
    "venue": "arXiv preprint arXiv:1707.03264.",
    "year": 2017
  }, {
    "title": "Relation Extraction with Matrix Factorization and Universal Schemas",
    "authors": ["Sebastian Riedel", "Limin Yao", "Andrew McCallum", "Benjamin M. Marlin."],
    "venue": "Proceedings of NAACL-HLT pages 74–84.",
    "year": 2013
  }, {
    "title": "Sluice networks: Learning what to share between loosely related tasks",
    "authors": ["Sebastian Ruder", "Joachim Bingel", "Isabelle Augenstein", "Anders Søgaard."],
    "venue": "CoRR, abs/1705.08142.",
    "year": 2017
  }, {
    "title": "A Hierarchical Model of Reviews for Aspectbased Sentiment Analysis",
    "authors": ["Sebastian Ruder", "Parsa Ghaffari", "John G. Breslin."],
    "venue": "Proceedings of EMNLP pages 999–1005.",
    "year": 2016
  }, {
    "title": "Learning to select data for transfer learning with Bayesian Optimization",
    "authors": ["Sebastian Ruder", "Barbara Plank."],
    "venue": "Proceedings of EMNLP.",
    "year": 2017
  }, {
    "title": "Deep multi-task learning with low level tasks supervised at lower layers",
    "authors": ["Anders Søgaard", "Yoav Goldberg."],
    "venue": "Proceedings of ACL.",
    "year": 2016
  }, {
    "title": "Target-Dependent Twitter Sentiment Classification with Rich Automatic Features",
    "authors": ["Duy-Tin Vo", "Yue Zhang."],
    "venue": "Proceedings of IJCAI. pages 1347–1353.",
    "year": 2015
  }, {
    "title": "Multi-Task Learning for Classification with Dirichlet Process Priors",
    "authors": ["Ya Xue", "Xuejun Liao", "Lawrence Carin", "Balaji Krishnapuram."],
    "venue": "Journal of Machine Learning Research 8:35–63.",
    "year": 2007
  }, {
    "title": "Learning Deep Latent Space for Multi-Label Classification",
    "authors": ["Chih-Kuan Yeh", "Wei-Chieh Wu", "Wei-Jen Ko", "YuChiang Frank Wang."],
    "venue": "Proceedings of AAAI.",
    "year": 2017
  }, {
    "title": "Learning Gaussian processes from multiple tasks",
    "authors": ["Kai Yu", "Volker Tresp", "Anton Schwaighofer."],
    "venue": "Proceedings of ICML 22:1012–1019.",
    "year": 2005
  }, {
    "title": "Learning to Map into a Universal POS Tagset",
    "authors": ["Yuan Zhang", "Roi Reichart", "Regina Barzilay", "Amir Globerson."],
    "venue": "Proceedings of EMNLP.",
    "year": 2012
  }],
  "id": "SP:e03e2d39a6bdcd1e2a3170f280853874a2c10e89",
  "authors": [{
    "name": "Isabelle Augenstein",
    "affiliations": []
  }, {
    "name": "Sebastian Ruder",
    "affiliations": []
  }, {
    "name": "Anders Søgaard",
    "affiliations": []
  }],
  "abstractText": "We combine multi-task learning and semisupervised learning by inducing a joint embedding space between disparate label spaces and learning transfer functions between label embeddings, enabling us to jointly leverage unlabelled data and auxiliary, annotated datasets. We evaluate our approach on a variety of sequence classification tasks with disparate label spaces. We outperform strong single and multi-task baselines and achieve a new stateof-the-art for topic-based sentiment analysis.",
  "title": "Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces"
}