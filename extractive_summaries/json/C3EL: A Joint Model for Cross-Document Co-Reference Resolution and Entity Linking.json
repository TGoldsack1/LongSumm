{
  "sections": [{
    "text": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c©2015 Association for Computational Linguistics."
  }, {
    "heading": "1 Introduction",
    "text": "With the advent of large knowledge bases (KB) like DBpedia, YAGO, Freebase, and others, entities (people, places, organizations, etc.) along with their attributes and relationships form the basis of smart applications like search, analytics, recommendations, question answering, and more. The major task that arises in both the KB construction process and the entity-centric applications involves precise recognition, resolution, and linking of named entities distributed across web pages, news articles, and social media.\nNamed Entity Recognition (NER) deals with the identification of entity mentions in a text and their classification into coarse-grained semantic types (person, location, etc.) (Finkel et al., 2005; Nadeau\n& Sekine, 2007; Ratinov & Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively.\nNamed Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu & Paşca, 2006; Cucerzan, 2007; Milne & Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein.\nEntity Co-reference Resolution (CR) (Haghighi & Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein.\nWhen CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga & Baldwin, 1998; Culotta et al., 2007; Singh et al., 2011; Dutta & Weikum, 2015). Note that CCR is not the same as merely concatenating all documents in the corpus and utilizing existing CR methods. The linguistic diversity across documents and high computational cost for huge numbers of mentions in the corpus would typically make such a CR-based simulation perform poorly. Neither CR nor CCR links mention groups to corresponding KB entities. Thus, they represent both in-KB entities and out-of-KB entities (e.g., long-tail or emerging entities that do not have a Wikipedia article) in the same way.\n1Named Entity Disambiguation (NED) and “Wikification” are often used to denote the same task. The latter may be more broadly used, though, to include the disambiguation of common nouns and phrases onto concepts, whereas NED restricts itself to noun phrases that denote individual entities.\n846\nState-of-the-Art and its Limitations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi & Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman & Ng, 2011) and multi-sieve methods (Ratinov & Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga & Baldwin, 1998) along with features extracted from external KBs (Dutta & Weikum, 2015).\nNEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne & Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases.\nAlthough NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen & Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi & Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett & Klein, 2014). However, to the best of our knowledge, no method exists for jointly handling CCR and NEL on large text corpora."
  }, {
    "heading": "1.1 Approach and Contributions",
    "text": "This paper proposes the novel C3EL (CrossdoCument Co-reference resolution and Entity Linking) framework for jointly modeling crossdocument co-reference resolution (CCR) and linkage of mention groups to entities in a knowledge base (NEL). Example: To illustrate the potential synergies between CCR and NEL, consider the 3 documents in Figure 1 containing 9 mentions (on the left) with candidate entities from a KB (on the right). CCR alone would likely miss the coreference relation between Logan (Doc 1) and its alias Wolverine (Doc 2), leaving NEL with the difficult task of disambiguating “Logan” in a document with sparse and highly ambiguous context (Doc 1). On the other hand, NEL alone would likely map Australia (Doc 3) to the country (not the movie) and could easily choose the wrong link for mention “Hugh”. Moreover, the presence of Ava Eliot as an out-of-KB mention complicates the task.\nHowever, if we could more freely interleave\nCCR and NEL and could iterate them several times, we would be in a much stronger position. An initial NEL step for the easiest mention, namely “Wolverine”, maps it to the character of X-Men movies. This indicates that the three “Hugh” mentions could all be the same actor, and are thus easily merged into a co-reference group using CCR. We now have enough cues for NEL to choose the right entity for the “Hugh” mention group, which in turn enables the proper mapping of “Australia” to the movie. Finally, it becomes clear that mentions “Ava Eliot” and “his daughter Ava” should be merged into the same group and represented as an out-of-KB entity mapped to null.\nThe above example clearly demonstrates that interleaving CCR and NEL is highly beneficial. However, appropriate choices for the ordering of CCR and NEL steps are usually not obvious at all. The proposed C3EL algorithm solves this problem: automatically determining an efficient interleaving of CCR and NEL. Approach: C3EL iteratively aggregates intermediate information obtained from alternating steps of CCR and NEL, thus forming a feedback loop for propagating mention features and entity knowledge. Intuitively, co-referring mentions obtained via CCR generate global context for improved NEL performance, while mentions linked to KB entities (by NEL) provide distant semantic features with additional cues for CCR. C3EL couples several building blocks like unsupervised hierarchical clustering, context summaries for mentions and distant KB features for entities, drawing inspiration from the CCR-only method of (Dutta & Weikum, 2015). Mention linking to the KB (NEL) is performed using distant knowledge and co-occurring mentions.\nIn a nutshell, the major contributions of this paper are: • the C3EL framework for joint computation of\ncross-document co-reference resolution (CCR) and entity linking to a KB (NEL), based on propagating information across iterative CCR and NEL steps; • techniques for considering co-occurring men-\ntions in context summaries and for harnessing\ncontext-based keywords for link validation in NEL, improving accuracy on out-of-KB entities; • an experimental evaluation with two different\ncorpora, one based on news articles and one based on web pages, demonstrating substantial gains for both CCR and NEL over state-of-theart methods.\n2 C3EL: Joint CCR-NEL Framework\nGiven an input corpus C of n documents, C = {D1, D2, · · · , Dn} with entity mentions EM = {m11,m12, · · · ,m21,m22, · · · } (mij ∈ Di), C3EL aims to jointly compute:\n• CCR: an equivalence relation over EM with equivalence classesEi, such thatEi ∩i 6=j Ej = ∅ and ∪i Ei = EM , and • NEL: linking each of the classes Ei to entities\npresent in a KB or map it to null if there is no proper entity in the KB.\nTo this end, C3EL consists of 3 algorithmic stages: (i) Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization."
  }, {
    "heading": "2.1 Pre-Processing Stage",
    "text": "HTML pages in the input corpusC are transformed into plain text using standard tools like jsoup. org. Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005). The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains). The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.).\nFor each of the mention groups Mi, C3EL then constructs a context summary using:\n• Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentences for other men-\ntion groups that contain mentions co-occurring in any of the sentences of Mi (as obtained above).\nFormally, for each mention groupMi, let S(Mi) = {sentence(mj) |mj ∈ Mi} represent the set of extracted sentences, where sentence(mj) denotes the sentences in which mention mj occurs. Also, let the co-occurring mention set of Mi be Co(Mi) = {m′ |m′ ∈ S(Mi) ∧ m′ /∈ Mi}. The\ncontext summary of Mi is defined as:\nCS(Mi) = S(Mi) ∪  ⋃\nm′∈Co(Mi) S(m′)  The context summaries intentionally do not include any distant KB features for mentions. The intuition is to minimize potential noise from overly speculative mappings to the KB at this initial stage."
  }, {
    "heading": "2.2 Interleaved NEL & CCR Approach",
    "text": "After the preliminary CR step on each document and the construction of context summaries, C3EL now performs an initial NEL step for each of the mention groups Mi, using the extracted sentences S(Mi) as inputs to NEL. It obtains the best matching entity, the confidence of the match, and its corresponding Wikipedia page. Off-the-shelf NEL software (like WikipediaMiner or Illinois-Wikifier) is used for mention-entity mapping based on prior popularity of the named-entities (from the KB) and textual similarity between S(Mi) (context of the mention group) and the entity descriptions in KB.\nFor each Mi, the entity link obtained (from NEL) is then “validated” using a similarity measure between features from the context summary, CS(Mi) (including co-occurring mentions) and distant KB labels – forming the link validation procedure of C3EL. This explicit use of co-occurring mentions’ (Co(Mi)) contexts helps to better identify out-of-KB entities compared to direct fullfledged NEL using the entire input text (shown in Section 3). Also the use of NEL on S(Mi) alone, makes C3EL “light-weighted”.\nThe mappings between the mention groups and KB entries are then classified, on the basis of the NEL confidence scores, into Strong Evidence (SE), Weak Evidence (WE), and No Evidence (NE) classes. For mention groups placed in SE, the KB features (obtained previously) are appended to their context summaries, while mentions strongly linked to same KB entities are considered to be coreferring and hence grouped together (performing implicit CCR).\nConsidering our example (Figure 1), we now outline the iterative steps of C3EL interleaving NEL & CCR. 1. During Iteration 1, C3EL performs: • NEL: The initial NEL step maps the unam-\nbiguous mentions, Wolverine to the X-Men movie character and Australia to the country, with high confidence. However, link validation fails for “Australia” as there is very low similarity between the mention context features (e.g., Hugh, Wolverine, etc.) and the distant KB labels extracted from its Wikipedia page (e.g., Commonwealth, population, etc.); thus the link is dropped and the mention is added to NE. So only the mention “Wolverine” is added to the\nSE class and enriched with KB features (e.g., alias Logan). On the other hand, the 3 “Hugh” mentions exhibit low NEL confidence due to the high ambiguity of this first name and are therefore classified into WE. The remaining mentions have extremely low NEL confidence (due to sparse contextual information) and are added to NE. • CCR: The WE and NE classes are fed sep-\narately to the CCR procedure. Based on the context summary similarities between mentions, C3EL performs hierarchical clustering to group together the “Hugh” mentions (in the WE class) and creates a co-referring mention group with the individual mentions’ context summaries concatenated. This merging of summaries grows and strengthens captured contexts, which propagates across documents. This concludes the first iteration of C3EL.\n2. The above results are provided to the second Iteration: • NEL: The context summary of the “Hugh”\nmention group in WE now provides definitive cues to correctly map it to the actor Hugh Jackman with high confidence, thus placing it in the SE class. • CCR: The ensuing CCR step groups together\n“Ava Eliot” and “Ava” (in NE) using cooccurrence context of the co-referring Hugh mentions.\n3. Subsequent NEL iterations (on WE and NE) identify “Ava” as an out-of-KB entity and correctly links “Australia” to the movie using CCRgenerated mention-group contexts and link validation. CCR finally groups together “Logan” with “Wolverine” based on context similarity with distant KB features. This process of alternating CCR and NEL is repeated until all mention groups are strongly connected to KB entities (placed in SE), or no changes are made anymore.\nThe NEL and CCR procedures are performed separately on the different mention types (like PER, LOC, etc.), since different mention types rarely co-refer. We next present the internal working details of the NEL and CCR stages of C3EL."
  }, {
    "heading": "2.2.1 Named-Entity Linking (NEL) Stage",
    "text": "In its NEL procedure, C3EL disambiguates mentions to entities in the YAGO knowledge base (yago-knowledge.org). We perform NEL on the sentences (S(Mi)) of a mention group, using named-entity popularity statistics and context, to obtain the best matching entity, its confidence score, and the corresponding Wikipedia page (from sameAs link in YAGO). Assume a mention group Mi to be mapped to an entity ei with a confidence score of φ(Mi, ei). A. Link Validation: For each mention group (e.g., Hugh), we extract distant KB labels such as se-\nmantic types or categories (e.g., actor), title (e.g., Golden Globe winner), alias (e.g., Wolverine), location, and gender (for person) from the Wikipedia page infoboxes. The similarity of these features to keywords obtained from the context summary CS(Mi) is computed using IR-style term frequencies within a document (tf) and inverse document frequencies within the corpus (idf). We utilize the bag-of-words model based tf × idf -weighted cosine similarity measure. If the similarity score is above a threshold, τ , the NEL result is accepted, otherwise it is discarded – thus avoiding noisy linkage of sparse mentions to prominent KB entries. This subtle introduction of controlled distant supervision within the C3EL framework enables efficient detection of out-of-KB mentions. B. Classification: To sift out well-known and long-tail entities from new ones, and prevent “noisy” interactions among the contexts of inKB and out-of-KB mentions (with similar surface forms), mention groups Mi (linked to ei with score φ(Mi, ei)) are classified into 3 classes by 2 threshold parameters, δs and δw, as: • Strong Evidence (SE): For φ(Mi, ei) ≥ δs,\nmention group Mi exhibits high linkage confidence with ei and is placed in SE. If two or more mentions in SE are independently mapped to the same KB entity, they co-refer transitively and are hence grouped together with their context summaries merged (implicit CCR). Distant KB features for mentions in SE are extracted and appended to CS(Mi), providing additional cues for later steps. • Weak Evidence (WE): Mention groups with δw ≤ φ(Mi, ei) < δs are placed in this class. They mostly represent long-tail in-KB entities (sparsely represented in KB) with limited semantic information (for detection) but might also be new/emerging entities absent from KB. • No Evidence (NE): φ(Mi, ei) < δw represents\nmentions groups that have been mapped to null (or have near-zero match confidence) or have failed link validation during the NEL procedure. These entities are most likely to be outof-KB and are allocated to this class."
  }, {
    "heading": "2.2.2 Cross-Document CR (CCR) Stage",
    "text": "The CCR stage of C3EL adopts the samplingbased hierarchical clustering approach of (Dutta & Weikum, 2015), to obtain co-referring mention clusters. A. Similarity Measure: To infer whether two mention groups represent the same entity, the similarity between the context summaries are computed based on (i) tf-idf -weighted bag-of-words cosine distance, and (ii) partial-match scores of multiword keyphrases in bounded text windows (Taneva et al., 2011). The context summaries (with stopwords removed) are re-interpreted as, (i) bag of words, and (ii) bag of keyphrases, to extract fea-\nture vectors for similarity computation. Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta & Weikum, 2015) is used to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed. Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METIS software (Karypis & Kumar, 1999)2, to partition noncoreferent mentions groups. The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Grünwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged.\nCCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections."
  }, {
    "heading": "2.3 Finalization Stage",
    "text": "For the remaining mention groups in WE, we finally perform threshold based disambiguation of mention clusters using the context summaries. For each mention groupMi ∈WE, we compute (1) its context summary similarities (as in Section 2.2.2) to all other mention groups Mj in SE by also using distance features from the weakly linked KB entities, and (2) textual overlap between the mention group representatives. Mi is concatenated with the best matching entity Mk (in SE) if the similarity score is above a threshold θ; else Mi is marked as an out-of-KB entity (mapped to null) and is placed in theNE class. This helps in reducing propagated CR errors like erroneous mention boundary detection (in NER), omissions in co-reference chain, etc. (leading to “phantom” out-of-KB entities).\nThe obtained mention groups represent the final equivalence classes of co-referring mentions across documents – capturing both in-KB entities (with links to the KB) in the SE class and out-of-KB entities (mapped to null) in the NE class."
  }, {
    "heading": "3 Experimental Evaluation",
    "text": "In this section, we empirically study the performance of C3EL against various state-of-the-art methods. We analyze the individual gains in CCR and NEL due to the joint modeling. Datasets: We use the following 2 publicly available corpora:\n• EventCorefBank (ECB) corpus3 (Bejan & Harabagiu, 2010): contains 482 news and Web articles (classified into 43 topics) with a total\n2 glaros.dtc.umn.edu/gkhome/metis/metis/overview 3 faulty.washington.edu/bejan/data/ECB1.0.tar.gz\nof 5447 mentions corresponding to 1068 distinct named-entities. Entity co-reference annotations (across documents within each topic cluster) were provided by (Lee et al., 2012), and we performed manual examination of the annotations for KB linking of the entities to Wikipedia entries, if present; thus providing ground truth for both CCR and NEL. • ClueWeb2009 FACC1 dataset4 (Gabrilovich\net al., 2013): provides machine automated entity-linkage annotations of the ClueWeb09 corpus (ca. 1 Billion crawled Web pages) with Freebase entries5. The corpus contains many topical domains and highly diverse documents from news, movie reviews, people home pages to blogs and other social media posts. We randomly select 500K documents containing 4.64 Million mentions associated with 1.29 Million distinct entities to form our corpus. For NEL ground-truth construction, we link the entities to their Wikipedia pages (using Freebase’s “on the web” property). Since no explicit annotations of inter-document entity co-references exists, we consider two mentions (in different documents) to co-refer if they are linked with the same Freebase entity.\nEvaluation: To assess the output quality of C3EL we use the following established metrics: • B3 F1 score (Bagga & Baldwin, 1998): mea-\nsures the F1 score as the harmonic mean of average precision and recall computed over all mention groups in the final equivalence classes. Precision (for a mention group) represents the ratio of the number of correctly reported coreferences (or linking) to the actual number; while recall computes the fraction of the goldstandard annotations correctly identified. • φ3 − CEAF score (Luo, 2005): provides\nan alternate F1 score computed as in the B3 measure; but calculates precision and recall of mention groups using the best 1-to-1 mapping (i.e., mapping with maximum mention overlap) between the resultant equivalence classes and those in the ground truth. Normalization with the number of mentions for each of the resultant classes yields the φ4-CEAF score.\nWe consider only the 3 most notable mention types: person (PER), location (LOC), and organization (ORG) – accounting for 99.7% of entities present in the ECB corpus and 96.3% of our ClueWeb09 corpus. All experiments were conducted on a 4 core Intel i5 2.50 GHz processor with 8GB RAM running Ubuntu 12.04 LTS."
  }, {
    "heading": "3.1 Parameter Tuning & Sensitivity Study",
    "text": "Validation of entity linkage to KB and their subsequent classification into confidence classes (as de-\n4 lemurproject.org/clueweb09/FACC1\n5Human analysis of a subset of the annotations generated revealed a precision of 80− 85% (Gabrilovich et al., 2013)\nscribed in Section 2) during the NEL step ofC3EL are based on 3 parameters: confidence thresholds (δs and δw) and validation threshold (τ ); the values of which can be tuned based on cross-validation approach with train and test data subsets. Using the “gold annotations” of the train-set (30% of total data), parameter values providing the best precision score are individually learnt using line search with small step size.\nIn our experimental setup, we systematically vary the parameter values and observe its effects on C3EL for the training data. With increase in δs, the number of mentions mapped to the Strong Evidence (SE) class decreases. This in turn limits the influx of external KB features, thus degrading CCR performance as observed in Table 1(a). While for low values of δs, even weak mention links are placed in SE, leading to a decrease in precision due to noisy KB feature inclusion. On the other hand, a high δw value increases the number of mentions in the NE class, while low values tends to accumulate mentions in the WE class. This adversely affects the detection of out-of-KB entities due to noise from other co-occurring similar KB mentions (refer Table 1(b)) during clustering in CCR step.\nThe effect of τ on C3EL has be shown in Table 1(c). Similar to the behavior induced by δs, we observe that a high τ limits entity linking and possible KB feature inclusion, while an extremely low value (near to zero) allows for noisy feature incorporation – both situations leading to lowered CCR efficiency. However, since τ prevents gross mis-alignment of mentions to KB entities, a wide range of small value (0.1− 0.35) is seen to provide comparable performance.\nHence, for our remaining experimental study we set δs = 0.11 and δw = 0.06 (as in (Hoffart et al., 2014)), while τ is set to 0.1, and threshold for the finalization stage θ = 2× δs = 0.22."
  }, {
    "heading": "3.2 CCR Performance Results",
    "text": "We initially benchmark the performance improvement in cross-document co-reference resolution (CCR) procedure by C3EL against two competing approaches: (1) state-of-the art sampling based hierarchical clustering method, CROCS (Dutta & Weikum, 2015); and (2) iterative joint entity-event CCR, EECR (Lee et al., 2012).\nTable 2 tabulates the results obtained on the ECB dataset. We observe C3EL to decisively outperform both the existing methods, providing a B3 F1 improvement of around 7% over CROCS and 17% over EECR. We further attain around 6% φ3−CEAF score enhancement over CROCS, and\na significant 20% improved φ4 − CEAF score compared to EECR. A. Gold Results: Errors introduced during the preprocessing stage of C3EL (e.g., mention omission, tag mis-classification, intra-document CR errors, etc., by the Stanford CoreNLP toolkit) propagate to subsequent computing stages and adversely impacts the overall system performance. To provide an unbiased viewpoint of the actual performance of C3EL, we manually provided “exact” mentions, mention tags, and intra-document CR mention chains for the ECB corpus; thereby obtaining gold performance results. From Table 3 we observe a 6% F1 points improvement (for both B3 & CEAF-φ3) in C3EL compared to CROCS. B. Mention Categorization: Person mention type (PER) provides the greatest challenge for CCR systems (compared to other types like LOC, ORG, etc.) due to associated nicknames, titles, and varied surface forms (abbreviations, spellings, etc.). We thus evaluate the CCR performance of C3EL (and compare it with CROCS) on the ECB data, with “exact” input mentions, for the different mention categories. Table 4 validates that our joint modeling provides better global information cues, reporting a B3 F1 score enhancement of around 11% over CROCS for PER mentions; along with improved results for the other mention types as well. C. Large Data: To study the robustness of C3EL and the effects of large datasets on CCR, we performed evaluations on the ClueWeb09-FACC1 dataset. Similar to the ECB dataset, C3EL exhibits a B3 F1 score improvement of nearly 10% and a φ3-CEAF F1 improvement of 12% over CROCS (refer Table 5).\nThe above experimental results showcase that a combined approach helps overcome challenges faced in CCR by entity linkage and corresponding distant KB feature extraction; improving the overall accuracy."
  }, {
    "heading": "3.3 Named-Entity Linking (NEL) Results",
    "text": "We now benchmark the performance of namedentity linking (NEL) procedure for C3EL against the state-of-the-art open-source AIDA software (github.com/yago-naga/aida). We separately inspect the precision of mention linking for prominent entities (in-KB) as well as new/emerging (out-of-KB) entities, and characterize the links as\nCorrect (C), Incorrect (I), or Unlinked (U). The results on the ECB corpus are reported in Table 6. C3EL attains comparable performance (∼ 85% precision) to that of AIDA for well-known entitymentions present in KB; albeit with a few mentions remaining unlinked due to our cautious link validation (using τ ) approach. However, the use of τ reduces aggressive KB linking to provide a significant 15% improvement (over AIDA) in precise detection of new/emerging entities absent in KB. Overall, an 1.5% precision gain is observed by the joint formulation. A. Large Data: The diverse nature of the webscale ClueWeb09 dataset clearly portrays the performance gains in NEL procedure due to CCR generated information integration. For entities present in the KB, we observe an accuracy improvement of 0.5% over AIDA (refer Table 7). Similar to that of the ECB data, C3EL attains a significant ∼ 14% improvement in the detection of new/emerging entities not represented in KB. For the 1 million mentions, C3EL provides around 4% overall performance improvements.\nUsing a bootstrap re-sampling t-test (as in (Durrett & Klein, 2014)), we observed high statistical significance (p < 0.01) for Out-of-KB and Overall NEL, whereas the difference for Within-KB NEL is not statistically significant. Coping with Out-ofKB entities is essential for joint CCR+NEL, and an improved NEL performance using propagated information from CCR using semantics along with link validation enables highly efficient detection of new or emerging entities. 3.4 Comparison with Joint Models Traditional CR methods fail to cope with the heterogeneity of mentions and contexts across multiple documents, and some form of clustering or joint reasoning over all mentions is thus mandatory. These methods have quadratic or cubic (sometimes even exponential) complexity, and hence running CR+NEL on a concatenated super-document works only for small corpora, and would be prohibitively expensive for large corpora, even in offline processing mode (Singh et al., 2011).\nHowever, to study the behavior of existing CRNEL joint models under “small” CCR environ-\nments, we compare C3EL with: (1) multi-sieve based NECo (Hajishirzi et al., 2013)6; and (2) conditional random field based BER (Durrett & Klein, 2014) 7.\nThree topic clusters from the ECB corpus with 3, 4, and 5 articles respectively were selected, and the documents within each cluster were merged to form 3 “super-articles” (one per topic), forming a simulated CR setting. NECo and BER were then used to perform CR and NEL on these 3 articles, and the results compared with that obtained by C3EL on the original documents. We repeatedly sample 12 articles across 3 topic clusters, and execute the approaches to report the micro-averaged results across 5 independent runs.\nFrom Table 8(a) we observe that the algorithms exhibit comparable co-reference resolution performance; thus validating propagation of global semantics in C3EL due to the joint formulation. However, such CR methods using multi-sieves and CRF do not scale beyond few documents (upon concatenation), and require at least 4× more runtime compared to C3EL. Hence, CCR cannot be efficiently tackled by simply employing CR methods on a “super-document”.\nHowever, harnessing of non-local mention features (via CCR) and efficient detection of new mentions using link validation enables C3EL to achieve a gain of around 5% in NEL compared to others (see Table 8(b)). For both procedures, we observed statistically significant improvements of C3EL over BER and NECo with p < 0.05, using the bootstrap re-sampling t-test.\nTo further study the effect of larger corpus, we sampled 25 documents (with co-referring mentions) from the ClueWeb09 dataset and performed analysis among the algorithms. As previously, we observed significant computational complexity for traditional CR methods when applied to CCR setting making them far slower (6− 7×) than C3EL. Table 9 reports the CCR and NEL averaged results obtained across 5 independent runs. We attained comparable performance in CCR with around 3% improvement in NEL. All the algorithms are seen to achieve high NEL results due to the large presence of well-known (in-KB) entities.\n6 cs.washington.edu/research-projects/nlp/neco 7 nlp.cs.berkeley.edu/projects/entity.shtml"
  }, {
    "heading": "3.5 Algorithmic Baseline Study",
    "text": "We explore the performance of variants of C3EL (on both corpora) ablating various system components (see Table 10). Explicitly, we consider:\n• Co-occurring Mentions: Removal of cooccurrence mentions context from the context summaries constructed, reduces semantic information and adversely affects both NEL and CCR procedures. We thus observe a sharp decrease in CCR performance and also a degradation in entity linking. • Link Validation: Filtering of mention linking\nto KB entities using link validation step (with threshold τ ) in C3EL enables corroboration of mention context keywords with the linked entity features. This leads to enhanced detection of new or emerging entities by reducing induction of noise during the CCR phase. Removal of this process permits aggressive entity linking and introduces noise, affecting new/emerging entity detection. We observe (from Table 10) nearly 20% reduction of precision (on both datasets) in identification of out-of-KB entitymentions compared to C3EL. • NEL Categorization: The differentiation of\nmentions (into classes) confidently mapped to KB entity reduces the collusion of “strong” linked mentions with other “noisy” mention contexts. This reduces incorrect grouping of different mentions with similar surface forms, contexts, etc., thereby improving precision of the CCR process. Use of a single NEL classification approach is observed to degrade CCR results, which in turn increases spurious entity linkage, decreasing NEL efficiency (Table 10). • Distant KB features: As observed in (Baker,\n2012; Zheng et al., 2013), extracted external KB features provide global and enhanced information cues promoting CR. We similarly observe CCR to attain the lowest F1 scores (compared to other baselines) when KB features are ignored. This in turn affects the linking of (some) well-known entities due to reduced context, leading to incorrect or low confidence NEL. Since no feature inclusion is performed for out-of-KB mentions, no effect is observed.\nWe observe that a joint formulation encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative feedback based framework, C3EL."
  }, {
    "heading": "4 Related Work",
    "text": "Co-reference Resolution (CR): Traditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi & Klein, 2009; Raghunathan et al., 2010; Rahman & Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daumé & Marcu, 2005; Ponzetto & Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi & Klein, 2009; Rahman & Ng, 2011). An overview of CR methods is given in (Ng, 2010).\nRecent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman & Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov & Roth, 2012) and distant knowledge inclusion (Durrett & Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen & Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman & Ng, 2011; Baker, 2012). CR methods with confidence-thresholds were proposed in (Ratinov & Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech-\nniques by ranking the matching entities for distant labeling. However, such prior methods utilize distance labels of the current mention and considers all matching mentions making the procedure expensive. On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga & Baldwin, 1998; Gooi & Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron & Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010).\nCo-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann & Yarowsky, 2003; Niu et al., 2004; Chen & Martin, 2007; Baron & Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta & Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne & Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne & Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also\nbased on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for NEL. The first study on the benefits of CR for NEL was by (Ratinov & Roth, 2012); but a joint model was not proposed, instead attributes from Wikipedia categories were used as features. An overview and evaluation of different NEL methods has been given by (Hachey et al., 2013). Joint Models: Jointly solving CR for entities and events utilizing cluster construction based on feature semantic dependencies was devised in (Lee et al., 2012). The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen & Roth, 2013). Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluster update CR system with automatic linking of mentions to Wikipedia. An integrated belief propagation-based framework for CR, NER, and relation extraction was developed in (Singh et al., 2013). Subsequently, the model was enhanced by the use of structured conditional random fields, to solve CR, NER, and NEL in combination (Durrett & Klein, 2014). Other works involving joint formulation of NER and NEL use uncertainty of mention boundaries along with segmentation information extracted from Wikipedia (Sil & Yates, 2013). However, to the best of our knowledge, this work provides the first approach to jointly tackle CCR and NEL across documents in an entire corpus."
  }, {
    "heading": "5 Conclusions",
    "text": "This paper presented the novel C3EL framework for joint computation of cross-document coreference resolution (CCR) and named-entity linking (NEL). Our approach utilizes: (1) context summaries including co-occurring mention groups allowing for global context and feature propagation, and (2) link validation for NEL using distant KB features. This is embedded in an interleaved CCR and NEL model allowing for global semantics and feature propagation. The iterative approach enables information feedback between CCR (provides corpus-wide cues) and NEL (providing distant KB features). Experimental results on news and web data demonstrate improved performance of both CCR and NEL compared to prior methods."
  }],
  "year": 2015,
  "references": [{
    "title": "Entity-Based CrossDocument Coreferencing Using the Vector Space Model",
    "authors": ["Amit Bagga", "Breck Baldwin"],
    "venue": "COLING-ACL",
    "year": 1998
  }, {
    "title": "FrameNet, Current Collaborations and Future Goals",
    "authors": ["Collin F. Baker"],
    "venue": "LREC",
    "year": 2012
  }, {
    "title": "Who is Who and What is What: Experiments in Cross-Document CoReference",
    "authors": ["Alex Baron", "Marjorie Freedman"],
    "venue": "EMNLP",
    "year": 2008
  }, {
    "title": "Unsupervised Event Coreference Resolution with Rich Linguistic Features",
    "authors": ["Cosmin A. Bejan", "Sanda Harabagiu"],
    "venue": "ACL",
    "year": 2010
  }, {
    "title": "Recent Advances in Graph Partitioning",
    "authors": ["Aydin Buluc", "Henning Meyerhenke", "Ilya Safro", "Peter Sanders", "Christian Schulz"],
    "venue": "Karlsruhe Institute of Technology,",
    "year": 2013
  }, {
    "title": "Using Encyclopedic Knowledge for Named Entity Disambiguation",
    "authors": ["Razvan Bunescu", "Marius Paşca"],
    "venue": "EACL",
    "year": 2006
  }, {
    "title": "Towards Robust Unsupervised Personal Name Disambiguation",
    "authors": ["Ying Chen", "James Martin"],
    "venue": "EMNLP",
    "year": 2007
  }, {
    "title": "Relational Inference for Wikification",
    "authors": ["Xiao Cheng", "Dan Roth"],
    "venue": "EMNLP",
    "year": 2013
  }, {
    "title": "A Framework for Benchmarking EntityAnnotation Systems",
    "authors": ["Marco Cornolti", "Paolo Ferragina", "Massimiliano Ciaramita"],
    "venue": "WWW",
    "year": 2013
  }, {
    "title": "Large-Scale Named Entity Disambiguation Based on Wikipedia Data",
    "authors": ["Silviu Cucerzan"],
    "venue": "EMNLPCoNLL",
    "year": 2007
  }, {
    "title": "First-Order Probabilistic Models for Coreference Resolution",
    "authors": ["Aron Culotta", "Michael L. Wick", "Andrew McCallum"],
    "venue": "In HLT-NAACL",
    "year": 2007
  }, {
    "title": "A large-scale exploration of effective global features for a joint entity detection and tracking model",
    "authors": ["Hal Daumé III", "Daniel Marcu"],
    "venue": "HLT-EMNLP",
    "year": 2005
  }, {
    "title": "Easy victories and uphill battles in coreference resolution",
    "authors": ["Greg Durrett", "Dan Klein"],
    "venue": "EMNLP",
    "year": 2013
  }, {
    "title": "A Joint Model for Entity Analysis: Coreference, Typing, and Linking",
    "authors": ["Greg Durrett", "Dan Klein"],
    "venue": "TACL 2014,",
    "year": 2014
  }, {
    "title": "Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling",
    "authors": ["Jenny R. Finkel", "Trond Grenager", "Christopher D. Manning"],
    "venue": "ACL",
    "year": 2005
  }, {
    "title": "Joint Parsing and Named Entity Recognition",
    "authors": ["Jenny R. Finkel", "Christopher D. Manning"],
    "venue": "EMNLPCoNLL",
    "year": 2009
  }, {
    "title": "FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Format version 1, Correction level",
    "authors": ["Evgeniy Gabrilovich", "Michael Ringgaard", "Amarnag Subramanya"],
    "year": 2013
  }, {
    "title": "Cross-Document Coreference on a Large Scale Corpus",
    "authors": ["Chung H. Gooi", "James Allan"],
    "venue": "HLTNAACL",
    "year": 2004
  }, {
    "title": "The Minimum Description Length Principle",
    "authors": ["Peter D. Grünwald"],
    "year": 2007
  }, {
    "title": "Evaluating entity linking with Wikipedia",
    "authors": ["Ben Hachey", "Will Radford", "Joel Nothman", "Matthew Honnibal", "James R. Curran"],
    "venue": "Artificial Intelligence Journal",
    "year": 2013
  }, {
    "title": "Simple Coreference Resolution with Rich Syntactic and Semantic Features",
    "authors": ["Aria Haghighi", "Dan Klein"],
    "venue": "EMNLP",
    "year": 2009
  }, {
    "title": "Coreference Resolution in a Modular, Entity-Centered Model",
    "authors": ["Aria Haghighi", "Dan Klein"],
    "venue": "HLTNAACL",
    "year": 2010
  }, {
    "title": "Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves",
    "authors": ["Hannaneh Hajishirzi", "Leila Zilles", "Daniel S. Weld", "Luke Zettlemoyer"],
    "venue": "EMNLP",
    "year": 2013
  }, {
    "title": "Robust Disambiguation of Named Entities in Text",
    "authors": ["Johannes Hoffart", "Mohamed A. Yosef", "Ilaria Bordino", "Hagen Fürstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum"],
    "year": 2011
  }, {
    "title": "Discovering Emerging Entities with Ambiguous Names",
    "authors": ["Johannes Hoffart", "Yasemin Altun", "Gerhard Weikum"],
    "venue": "WWW",
    "year": 2014
  }, {
    "title": "Hierarchical Clustering in Medical Document Collections: the BICMeans Method",
    "authors": ["Nikos Hourdakis", "Michalis Argyriou", "Euripides G.M. Petrakis", "Evangelos E. Milios"],
    "venue": "Journal of Digital Information Management",
    "year": 2010
  }, {
    "title": "A Fast and Highly Quality Multilevel Scheme for Partitioning Irregular Graphs",
    "authors": ["George Karypis", "Vipin Kumar"],
    "venue": "Journal on Scientific Computing",
    "year": 1999
  }, {
    "title": "Efficient Active Algorithms for Hierarchical Clustering",
    "authors": ["Akshay Krishnamurty", "Sivaraman Balakrishnan", "Min Xu", "Aarti Singh"],
    "venue": "ICML",
    "year": 2012
  }, {
    "title": "Collective annotation of Wikipedia entities in Web text",
    "authors": ["Sayali Kulkarni", "Amit Singh", "Ganesh Ramakrishnan", "Soumen Chakrabarti"],
    "venue": "KDD",
    "year": 2009
  }, {
    "title": "Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task",
    "authors": ["Heeyoung Lee", "Yves Peirsman", "Angel Chang", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky"],
    "year": 2011
  }, {
    "title": "Joint Entity and Event Coreference Resolution across Documents",
    "authors": ["Heeyoung Lee", "Marta Recasens", "Angel Chang", "Mihai Surdeanu", "Dan Jurafsky"],
    "venue": "EMNLP",
    "year": 2012
  }, {
    "title": "Deterministic Coreference Resolution based on Entity-centric, Precision-ranked Rules",
    "authors": ["Heeyoung Lee", "Angel Chang", "Yves Peirsman", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky"],
    "venue": "Computational Linguistics",
    "year": 2013
  }, {
    "title": "On Coreference Resolution Performance Metrics",
    "authors": ["Xiaoqiang Luo"],
    "venue": "EMNLP",
    "year": 2005
  }, {
    "title": "Unsupervised Personal Name Disambiguation",
    "authors": ["Gideon S. Mann", "David Yarowsky"],
    "venue": "In CoNLL",
    "year": 2003
  }, {
    "title": "Learning to Link with Wikipedia",
    "authors": ["David Milne", "Ian H. Witten"],
    "venue": "In CIKM",
    "year": 2008
  }, {
    "title": "A survey of named entity recognition and classification",
    "authors": ["David Nadeau", "Satoshi Sekine"],
    "venue": "Lingvisticae Investigationes",
    "year": 2007
  }, {
    "title": "Shallow semantics for coreference resolution",
    "authors": ["Vincent Ng"],
    "venue": "IJCAI",
    "year": 2007
  }, {
    "title": "Supervised Noun Phrase Coreference Research: The First Fifteen Years",
    "authors": ["Vincent Ng"],
    "venue": "ACL",
    "year": 2010
  }, {
    "title": "Weakly Supervised Learning for Cross-document Person Name Disambiguation Supported by Information Extraction",
    "authors": ["Cheng Niu", "Wei Li", "Rohini K. Srihari"],
    "venue": "ACL",
    "year": 2004
  }, {
    "title": "Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution",
    "authors": ["Simone P. Ponzetto", "Michael Strube"],
    "venue": "In HLT-NAACL",
    "year": 2006
  }, {
    "title": "A Multi-Pass Sieve for Coreference Resolution",
    "authors": ["Karthik Raghunathan", "Heeyoung Lee", "Sudarshan Rangarajan", "Nathanael Chambers", "Mihai Surdeanu", "Dan Jurafsky", "Christopher Manning"],
    "venue": "EMNLP",
    "year": 2010
  }, {
    "title": "Coreference Resolution with World Knowledge",
    "authors": ["Altaf Rahman", "Vincent Ng"],
    "venue": "ACL",
    "year": 2011
  }, {
    "title": "Ensemble-Based Coreference Resolution",
    "authors": ["Altaf Rahman", "Vincent Ng"],
    "venue": "IJCAI",
    "year": 2011
  }, {
    "title": "Design Challenges and Misconceptions in Named Entity Recognition",
    "authors": ["Lev A. Ratinov", "Dan Roth"],
    "venue": "In CoNLL",
    "year": 2009
  }, {
    "title": "Local and Global Algorithms for Disambiguation to Wikipedia",
    "authors": ["Lev A. Ratinov", "Dan Roth", "Doug Downey", "Mike Anderson"],
    "venue": "ACL",
    "year": 2011
  }, {
    "title": "Learning-based MultiSieve Co-reference Resolution with Knowledge",
    "authors": ["Lev A. Ratinov", "Dan Roth"],
    "venue": "EMNLP-CoNLL",
    "year": 2012
  }, {
    "title": "Estimating the Dimension of a Model",
    "authors": ["Gideon E. Schwarz"],
    "venue": "Annals of Statistics",
    "year": 1978
  }, {
    "title": "Re-ranking for Joint Named-Entity Recognition and Linking",
    "authors": ["Avirup Sil", "Alexander Yates"],
    "venue": "In CIKM",
    "year": 2013
  }, {
    "title": "Distantly Labeling Data for Large Scale CrossDocument Coreference",
    "authors": ["Sameer Singh", "Michael L. Wick", "Andrew McCallum"],
    "venue": "CoRR abs/1005.4298,",
    "year": 2010
  }, {
    "title": "Large-Scale CrossDocument Coreference Using Distributed Inference and Hierarchical Models",
    "authors": ["Sameer Singh", "Amarnag Subramanya", "Fernando Pereira", "Andrew McCallum"],
    "venue": "ACL",
    "year": 2011
  }, {
    "title": "Joint Inference of Entities, Relations, and Coreference",
    "authors": ["Sameer Singh", "Sebastian Reidel", "Brian Martin", "Jiaping Zheng", "Andrew McCallum"],
    "venue": "In Workshop of AKBC",
    "year": 2013
  }, {
    "title": "YAGO: a Core of Semantic Knowledge",
    "authors": ["Fabian M. Suchanek", "Gjergji Kasneci", "Gerhard Weikum"],
    "venue": "WWW",
    "year": 2007
  }, {
    "title": "Finding Images of Difficult Entities in the Long Tail",
    "authors": ["Bilyana Taneva", "Mouna Kacimi", "Gerhard Weikum"],
    "venue": "In CIKM",
    "year": 2011
  }, {
    "title": "AIDA: An Online Tool for Accurate Disambiguation of Named Entities in Text and Tables",
    "authors": ["Mohamed A. Yosef", "Johannes Hoffart", "Marc Spaniol", "Gerhard Weikum"],
    "year": 2011
  }, {
    "title": "Dynamic knowledgebase alignment for coreference resolution",
    "authors": ["Jiaping Zheng", "Luke Vilnis", "Sameer Singh", "Jinho D. Choi", "Andrew McCallum"],
    "venue": "In CoNLL",
    "year": 2013
  }],
  "id": "SP:f19d785c1cdedd15b4cb196b3ab57a601bb1cb35",
  "authors": [{
    "name": "Sourav Dutta",
    "affiliations": []
  }, {
    "name": "Gerhard Weikum",
    "affiliations": []
  }],
  "abstractText": "Cross-document co-reference resolution (CCR) computes equivalence classes over textual mentions denoting the same entity in a document corpus. Named-entity linking (NEL) disambiguates mentions onto entities present in a knowledge base (KB) or maps them to null if not present in the KB. Traditionally, CCR and NEL have been addressed separately. However, such approaches miss out on the mutual synergies if CCR and NEL were performed jointly. This paper proposes C3EL, an unsupervised framework combining CCR and NEL for jointly tackling both problems. C3EL incorporates results from the CCR stage into NEL, and vice versa: additional global context obtained from CCR improves the feature space and performance of NEL, while NEL in turn provides distant KB features for already disambiguated mentions to improve CCR. The CCR and NEL steps are interleaved in an iterative algorithm that focuses on the highest-confidence still unresolved mentions in each iteration. Experimental results on two different corpora, news-centric and web-centric, demonstrate significant gains over state-of-the-art baselines for both CCR and NEL.",
  "title": "C3EL: A Joint Model for Cross-Document Co-Reference Resolution and Entity Linking"
}