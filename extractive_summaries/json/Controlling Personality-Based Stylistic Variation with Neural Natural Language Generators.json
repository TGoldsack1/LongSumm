{
  "sections": [{
    "text": "Proceedings of the SIGDIAL 2018 Conference, pages 180–190, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics\n180"
  }, {
    "heading": "1 Introduction",
    "text": "The primary aim of natural language generators (NLGs) for task-oriented dialogue is to effectively realize system dialogue actions and their associated content parameters. This requires training data that allows the NLG to learn how to map\nsemantic representations for system dialogue acts to one or more possible outputs (see Figure 1, (Novikova et al., 2016)). Because neural generators often make semantic errors such as deleting, repeating or hallucinating content, to date previous work on task-oriented neural generation has primarily focused on faithfully rendering the meaning of the system’s dialogue act (Dusek and Jurcı́cek, 2016b; Lampouras and Vlachos, 2016; Mei et al., 2015; Wen et al., 2015).\nHowever, in many applications it is also desirable for generators to control the style of an utterance independently of its content. For example, in Figure 1, the first output uses more formal language and complex syntactic structures, as one might see in written language, while the other uses simpler syntax and pragmatic markers characteristic of oral language (Biber, 1991). In this paper, we create several different sequenceto-sequence models and compare how well they can disentangle content and style. Controlling the style of the output requires disentangling the content from the style, but previous neural models aimed at achieving stylistic goals have not focused on task-oriented dialogue where specific semantic attributes and values must be communicated (as per the MR in Figure 1), and where semantic fi-\ndelity can be precisely measured.1\nOne of the main challenges is the lack of parallel corpora realizing the same content with different styles. Thus we create a large, novel parallel corpus with specific style parameters and specific semantics, by using an existing statistical generator, PERSONAGE (Mairesse and Walker, 2010), to synthesize over 88,000 utterances in the restaurant domain that vary in style according to psycholinguistic models of personality.2 PERSONAGE can generate a very large number of stylistic variations for any given dialogue act, thus yielding, to our knowledge, the largest style-varied NLG training corpus in existence. The strength of this new corpus is that: (1) we can use the PERSONAGE generator to generate as much training data as we want; (2) it allows us to systematically vary a specific set of stylistic parameters and the network architectures; (3) it allows us to systematically test the ability of different models to generate outputs that faithfully realize both the style and content of the training data.3\nWe develop novel neural models that vary the amount of explicit stylistic supervision given to the network, and we explore, for the first time, explicit control of multiple interacting stylistic parameters. We show that the no-supervision (NO-SUP) model, a baseline sequence-to-sequence model (Sutskever et al., 2014; Dusek and Jurcı́cek, 2016b), produces semantically correct outputs, but\n1We leave a detailed review of related work to Section 6. 2Our stylistic variation for NLG corpus is available at:\nnlds.soe.ucsc.edu/stylistic-variation-nlg 3 Section 4 quantifies the naturalness of PERSONAGE outputs.\neliminates much of the stylistic variation that it saw in the training data. MODEL TOKEN provides minimal supervision by allocating a latent variable in the encoding as a label for each style, similar to the use of language labels in machine translation (Johnson et al., 2017). This model learns to generate coherent and stylistically varied output without explicit exposure to language rules, but makes more semantic errors. MODEL CONTEXT adds another layer to provide an additional encoding of individual stylistic parameters to the network. We show that it performs best on both measures of semantic fidelity and stylistic variation. The results suggest that neural architectures can benefit from explicit stylistic supervision, even with a large training set."
  }, {
    "heading": "2 Corpus Creation",
    "text": "We aim to systematically create a corpus that can be used to test how different neural architectures affect the ability of the trained model to disentangle style from content, and faithfully produce semantically correct utterances that vary style. We use PERSONAGE, an existing statistical generator: due to space, we briefly explain how it works, referring the interested reader to Mairesse and Walker (2010, 2011) for details.\nPERSONAGE requires as input: (1) a meaning representation (MR) of a dialogue act and its content parameters, and (2) a parameter file that tells it how frequently to use each of its stylistic parameters. Sample model outputs are shown in the second row of Figure 1 and in Table 1, illustrating some stylistic variations PERSONAGE produces.\nTo generate our novel corpus, we utilize the\nMRs from the E2E Generation Challenge.4 The MR in Figure 1 illustrates all 8 available attributes. We added a dictionary entry for each attribute to PERSONAGE so that it can express that attribute.5 These dictionary entries are syntactic representations for very simple sentences: the NO-AGG/NOPRAG row of Table 1 shows a sample realization of each attribute in its own sentence based on its dictionary entry.\nWe took advantage of the setup of the E2E Generation Challenge and used their MRs, exactly duplicating their split between training, dev and test MRs, because they ensured that the dev and test MRs had not been seen in training. The frequencies of longer utterances (more attribute MRs) vary across train and test, with actual distributions in Table 2, showing how the test set was designed to be challenging, while the test set in Wen et al. (2015) averages less than 2 attributes per MR (Nayak et al., 2017). We combine their dev and training MRs resulting in 3784 unique MRs in the training set, and generate 17,771 reference utterances per personality for a training set size of 88,855 utterances. The test set consists of 278 unique MRs and we generate 5 references per personality for a test size of 1,390 utterances.\nThe experiments are based on two types of parameters provided with PERSONAGE: aggregation parameters and pragmatic parameters.6 The NOAGG/NO-PRAG row of Table 1 shows what PERSONAGE would output if it did not use any of its stylistic parameters. The top half of Table 3 illustrates the aggregation parameters: these parameters control how the NLG combines attributes into sentences, e.g., whether it tries to create complex sentences by combining attributes into phrases and\n4http://www.macs.hw.ac.uk/ InteractionLab/E2E/\n5PERSONAGE supports a one-to-many mapping from attributes to elementary syntactic structures for expressing that attribute, but here we use only one dictionary entry. PERSONAGE also allows for discourse relations such as justification or contrast to hold between content items, but the E2E MRs do not include such relations.\n6We disable parameters related to content selection, syntactic template selection and lexical choice.\nwhat types of combination operations it uses. The pragmatic operators are shown in the second half of Table 3. Each parameter value can be set to high, low, or don’t care.\nTo use PERSONAGE to create training data mapping the same MR to multiple personality-based variants, we set values for all of the parameters in Table 3 using the stylistic models defined by Mairesse and Walker (2010) for the following Big Five personality traits: agreeable, disagreeable, conscientiousness, unconscientiousness, and extravert. Figure 2 shows that each personality produces data that represents a stylistically distinct distribution. These models are probabilistic and specified values are automatically broadened within a range, thus each model can produce 10’s of variations for each MR. Note that while each personality type distribution can be characterized by a single stylistic label (the personality), Figure 2 illustrates that each distribution is characterized by multiple interacting stylistic parameters.\nEach parameter modifies the linguistic structure in order to create distributionally different subcorpora. To see the effect of each personality using a different set of aggregation operators, crossreference the aggregation operations in Table 3 with an examination of the outputs in Table 1. The\nsimplest choice for aggregation does not combine attributes at all: this is represented by the PERIOD operator, which, if used persistently, results in an output with each content item in its own sentence as in the NO-AGG/NO-PRAG row, or the content being realized over multiple sentences as in the DISAGREEABLE row (5 sentences). However, if the other aggregation operations have a high value, PERSONAGE prefers to combine simple sentences into complex ones whenever it can, e.g., the EXTRAVERT personality example in Table 1 combines all the attributes into a single sentence by repeated use of the ALL MERGE and CONJUNCTION operations. The CONSCIENTIOUS row in Table 1 illustrates the use of the WITH-CUE aggregation operation, e.g., with a decent rating. Both the AGREEABLE and CONSCIENTIOUS rows in Table 1 provide examples of the ALSO-CUE aggregation operation. In PERSONAGE, the aggregation operations are defined as syntactic operations on the dictionary entry’s syntactic tree. Thus to mimic these operations correctly, the neural model\nmust derive latent representations that function as though they also operate on syntactic trees.\nThe pragmatic operators in the second half of Table 3 are intended to achieve particular pragmatic effects in the generated outputs: for example the use of a hedge such as sort of softens a claim and affects perceptions of friendliness and politeness (Brown and Levinson, 1987), while the exaggeration associated with emphasizers like actually, basically, really influences perceptions of extraversion and enthusiasm (Oberlander and Gill, 2004; Dewaele and Furnham, 1999). In PERSONAGE, the pragmatic parameters are attached to the syntactic tree at insertion points defined by syntactic constraints, e.g., EMPHASIZERS are adverbs that can occur sentence initially or before a scalar adjective. Each personality model uses a variety of pragmatic parameters. Figure 2 shows how these markers distribute differently across personality models, with examples in Table 1."
  }, {
    "heading": "3 Model Architectures",
    "text": "Our neural generation models build on the opensource sequence-to-sequence (seq2seq) TGen system (Dusek and Jurcı́cek, 2016a)7, implemented in Tensorflow (Abadi et al., 2016). The system is based on seq2seq generation with attention (Bahdanau et al., 2014; Sutskever et al., 2014), and uses a sequence of LSTMs (Hochreiter and Schmidhuber, 1997) for the encoder and decoder, combined with beam-search and reranking for output tuning.\nThe input to TGen are dialogue acts for each system action (such as inform) and a set of attribute slots (such as rating) and their values (such as high for attribute rating). The system integrates sentence planning and surface realization into a single step to produce natural language outputs. To preprocess the corpus of MR/utterance pairs, attributes that take on proper-noun values are delexicalized during training i.e., name and near. During the generation phase on the test set, a post-processing step re-lexicalizes the outputs. The MRs (and resultant embeddings) are sorted internally by dialogue act tag and attribute name.\nThe models are designed to systematically test the effects of increasing the level of supervision, with novel architectural additions to accommodate these changes. We use the default parameter settings from TGen (Dusek and Jurcı́cek, 2016a) with batch size 20 and beam size 10, and use 2,000\n7https://github.com/UFAL-DSG/tgen\ntraining instances for parameter tuning to set the number of training epochs and learning rate. Figure 3 summarizes the architectures.\nMODEL NOSUPERVISION. The simplest model follows the baseline TGen architecture (Dusek and Jurcı́cek, 2016b), with training using all 88K utterances in a single pool for up to 14 epochs based on loss monitoring for the decoder and reranker. MODEL TOKEN. The second model adds a token of additional supervision by introducing a new dialogue act, convert, to encode personality, inspired by the use of a language token for machine translation (Johnson et al., 2017). Unlike other work that uses a single token to control generator output (Fan et al., 2017; Hu et al., 2017), the personality token encodes a constellation of different parameters that define the style of the matching reference. Uniquely here, the model attempts to simultaneously control multiple style variables that may interact in different ways. Again, we monitor loss on the validation set and training continues for up to 14 epochs for the decoder and reranker. MODEL CONTEXT. The most complex model introduces a context vector, as shown at the top right of Figure 3. The vector explicitly encodes a set of 36 style parameters from Table 3. The parameters for each reference text are encoded as a boolean vector, and a feed-forward network is added as a context encoder, taking the vector as input to the hidden state of the encoder and making the parameters available at every time step to a multiplicative attention unit. The activations of the fully connected nodes are represented as an additional\ntime step of the encoder of the seq2seq architecture (Sutskever et al., 2014). The attention (Bahdanau et al., 2014) is computed over all of the encoder states and the hidden state of the fully connected network. Again, we set the learning rate, alpha decay, and maximum training epochs (up to 20) based on loss monitoring on the validation set."
  }, {
    "heading": "4 Quantitative Results",
    "text": "Here, we present results on controlling stylistic variation while maintaining semantic fidelity."
  }, {
    "heading": "4.1 Evaluating Semantic Quality",
    "text": "It is widely agreed that new evaluation metrics are needed for NLG (Langkilde-Geary, 2002; Belz and Reiter, 2006; Bangalore et al., 2000; Novikova et al., 2017a). We first present automated metrics used in NLG to measure how well model outputs compare to PERSONAGE input, then introduce novel metrics designed to fill the gap left by current evaluation metrics. Automatic Metrics. The automatic evaluation uses the E2E generation challenge script.8 Table 4 summarizes the results for BLEU (n-gram precision), NIST (weighted n-gram precision), METEOR (n-grams with synonym recall), and ROUGE (n-gram recall). Although the differences in metrics are small, MODEL CONTEXT shows a slight improvement across all of the metrics.\nDeletions, Repetitions, and Substitutions. Automated evaluation metrics are not informative about the quality of the outputs, and penalize models for introducing stylistic variation. We thus develop new scripts to automatically evaluate the types common types of neural generation errors: deletions (failing to realize a value), repeats (repeating a value), and substitutions (mentioning an attribute with an incorrect value).\nTable 5 shows ratios for the number of deletions, repeats, and substitutions for each model for the test set of 1,390 total realizations (278 unique MRs, each realized once for each of the 5 personalities). The error counts are split by personality, and normalized by the number of unique MRs\n8https://github.com/tuetschek/ e2e-metrics\n(278). Smaller ratios are preferable, indicating fewer errors. Note that because MODEL NOSUP does not encode a personality parameter, the error values are the same across each personality (averages across the full test set).\nThe table shows that MODEL NOSUP makes very few semantic errors (we show later that this is at the cost of limited stylistic variation). Across all error types, MODEL CONTEXT makes significantly fewer errors than MODEL TOKEN, suggesting that its additional explicit parameters help avoid semantic errors. The last row quantifies whether some personalities are harder to model: it shows that across all models, DISAGREEABLE and EXTRAVERT have the most errors, while CONSCIENTIOUS has the fewest."
  }, {
    "heading": "DELETIONS",
    "text": ""
  }, {
    "heading": "REPETITIONS",
    "text": ""
  }, {
    "heading": "SUBSTITUTIONS",
    "text": ""
  }, {
    "heading": "4.2 Evaluating Stylistic Variation",
    "text": "Here we characterize the fidelity of stylistic variation across different model outputs. Entropy. Shannon text entropy quantifies the amount of variation in the output produced by each model. We calculate entropy as − ∑ x∈S freq total ∗ log2( freq total ), where S is the set of unique words in all outputs generated by the model, freq is the frequency of a term, and total counts the number of terms in all references. Table 6 shows that the training data has the highest entropy, but MODEL CONTEXT performs the best at preserving the variation seen in the training data. Row NOSUP shows that MODEL NOSUP makes the fewest semantic errors, but produces the least varied output. MODEL CONTEXT, informed by the explicit stylistic context encoding, makes comparably few semantic errors, while producing stylistically varied output with high entropy.\nPragmatic Marker Usage. To measure whether\nthe trained models faithfully reproduce the pragmatic markers for each personality, we count each pragmatic marker in Table 3 in the output, average the counts and compute the Pearson correlation between the PERSONAGE references and the outputs for each model and personality. See Table 7 (all correlations significant with p ≤ 0.001).\nTable 7 shows that MODEL CONTEXT has the highest correlation with the training data, for all personalities (except AGREEABLE, with significant margins, and CONSCIENTIOUS, which is the easiest personality to model, with a margin of 0.01). While MODEL NOSUP shows positive correlation with AGREEABLE and CONSCIENTIOUS, it shows negative correlation with the PERSONAGE inputs for DISAGREEABLE, EXTRAVERT, and UNCONSCIENTIOUS. The pragmatic marker distributions for PERSONAGE train in Figure 2 indicates that the CONSCIENTIOUS personality most frequently uses acknowledgement-justify (i.e., “well”, “i see”), and request confirmation (i.e., “did you say X?”), which are less complex to introduce into a realization since they often lie at the beginning or end of a sentence, allowing the simple MODEL NOSUP to learn them.9 Aggregation. To measure the ability of each model to aggregate, we average the counts of each aggregation operation for each model and personality and compute the Pearson correlation between the output and the PERSONAGE training data.\nThe correlations in Table 8 (all significant with p ≤ 0.001) show that MODEL CONTEXT has a higher correlation with PERSONAGE than the two simpler models (except for DISAGREE-\n9We verified that there is not a high correlation between every set of pragmatic markers: different personalities do not correlate, e.g., -0.078 for PERSONAGE DISAGREEABLE and MODEL TOKEN AGREEABLE.\nABLE, where MODEL TOKEN is higher by 0.02). Here, MODEL NOSUP actually frequently outperforms the more informed MODEL TOKEN. Note that all personalities use aggregation, even thought not all personalities use pragmatic markers, and so even without a special personality token, MODEL NOSUP is able to faithfully reproduce aggregation operations. In fact, since the correlations are frequently higher than those for MODEL TOKEN, we hypothesize that is able to more accurately focus on aggregation (common to all personalities) than stylistic differences, which MODEL TOKEN is able to produce."
  }, {
    "heading": "5 Qualitative Analysis",
    "text": "Here, we present two evaluations aimed at qualitative analysis of our outputs."
  }, {
    "heading": "Crowdsourcing Personality Judgements.",
    "text": "Based on our quantitative results, we select MODEL CONTEXT as the best-performing model and conduct an evaluation to test if humans can distinguish the personalities exhibited. We randomly select a set of 10 unique MRs from the PERSONAGE training data along with their corresponding reference texts for each personality (50 items in total), and 30 unique MRs MODEL CONTEXT outputs (150 items in total).10 We construct a HIT on Mechanical Turk, presenting a single output (either PERSONAGE or MODEL CONTEXT), and ask 5 Turkers to label the output using the Ten Item Personality Inventory (TIPI) (Gosling et al., 2003). The TIPI is a ten-item measure of the Big Five personality dimensions, consisting of two items for each of the five dimensions, one that matches the dimension, and one that is the reverse of it, and a scale that ranges from 1 (disagree strongly) to 7 (agree strongly). To qualify Turkers for the task, we ask that they first complete a TIPI on themselves, to help ensure that they understand it.\nTable 9 presents results as aggregated counts for the number of times at least 3 out of the 5\n10Note that we use fewer PERSONAGE references simply to validate that our personalities are distinguishable in training, but will more rigorously evaluate our model in future work.\nTurkers rated the matching item for that personality higher than the reverse item (Ratio Correct), the average rating the correct item received (range between 1-7), and an average “naturalness” score for the output (also rated 1-7). From the table, we can see that for PERSONAGE training data, all of the personalities have a correct ratio that is higher than 0.5. The MODEL CONTEXT outputs exhibit the same trend except for UNCONSCIENTIOUS and AGREEABLE, where the correct ratio is only 0.17 and 0.50, respectively (they also have the lowest correct ratio for the original PERSONAGE data).\nTable 9 also presents results for naturalness for both the reference and generated utterances, showing that both achieve decent scores for naturalness (on a scale of 1-7). While human utterances would probably be judged more natural, it is not at all clear that similar experiments could be done with human generated utterances, where it is difficult to enforce the same amount of experimental control.\nGeneralizing to Multiple Personalities. A final experiment explores whether the models learn additional stylistic generalizations not seen in training. We train a version of MODEL TOKEN, as before on instances with single personalities, but such that it can be used to generate output with a combination of two personalities. The experiment uses the original training data for MODEL TOKEN, but uses an expanded test set where the MR includes two personality CONVERT tags. We pair each personality with all personalities except its exact opposite.\nSample outputs are given in Table 10 for the DISAGREEABLE personality, which is one of the most distinct in terms of aggregation and pragmatic marker insertion, along with occurrence counts (frequency shown scaled down by 100) of the operations that it does most frequently: specifically, period aggregation and expletive pragmatic markers. Rows 1-2 shows the counts and an exam-\nple of each personality on its own. The combined personality output is shown in Row 3. We can see from the table that while CONSCIENTIOUS on its own realizes the content in two sentences, period aggregation is much more prevalent in the DISAGREEABLE + CONSCIENTIOUS example, with the same content being realized in 5 sentences. Also, we see that some of the expletives originally in DISAGREEABLE are dropped in the combined output. This suggests that the model learns a combined representation unlike what it has seen in train, which we will explore in future work."
  }, {
    "heading": "6 Related Work and Conclusion",
    "text": "The restaurant domain has long been a testbed for conversational agents with much earlier work on NLG (Howcroft et al., 2013; Stent et al., 2004; Devillers et al., 2004; Gašic et al., 2008; Mairesse et al., 2010; Higashinaka et al., 2007), so it is not surprising that recent work using neural generation methods has also focused on the restaurant domain (Wen et al., 2015; Mei et al., 2015; Dusek and Jurcı́cek, 2016b; Lampouras and Vlachos, 2016; Juraska et al., 2018). The restaurant domain is ideal for testing generation models because sentences can range from extremely simple to more complex forms that exhibit discourse relations such as justification or contrast (Stent et al., 2004). Most recent work focuses on achieving semantic fidelity for simpler syntactic structures, although there has also been a focus on crowdsourcing or harvesting training data that exhibits more stylistic variation (Novikova et al., 2017; Nayak et al., 2017; Oraby et al., 2017).\nMost previous work on neural stylistic generation has been carried out in the framework of “style transfer”: this work is hampered by the\nlack of parallel corpora, the difficulty of evaluating content preservation (semantic fidelity), and the challenges with measuring whether the outputs realize a particular style. Previous experiments attempt to control the sentiment and verb tense of generated movie review sentences (Hu et al., 2017), the content preservation and style transfer of news headlines and product review sentences (Fu et al., 2018), multiple automatically extracted style attributes along with sentiment and sentence theme for movie reviews (Ficler and Goldberg, 2017), sentiment, fluency and semantic equivalence (Shen et al., 2017), utterance length and topic (Fan et al., 2017), and the personality of customer care utterances in dialogue (Herzig et al., 2017). However, to our knowledge, no previous work evaluates simultaneous achievement of multiple targets as we do. Recent work introduces a large parallel corpus that varies on the formality dimension, and introduces several novel evaluation metrics, including a custom trained model for measuring semantic fidelity (Rao and Tetreault).\nOther work has also used context representations, but not in the way that we do here. In general, these have been used to incorporate a representation of the prior dialogue into response generation. Sordoni et al. (2015) propose a basic approach where they incorporate previous utterances as a bag of words model and use a feed-forward neural network to inject a fixed sized context vector into the LSTM cell of the encoder. Ghosh et al. (2016) proposed a modified LSTM cell with an additional gate that incorporates the previous context as input during encoding. Our context representation encodes stylistic parameters.\nThis paper evaluates the ability of different neural architectures to faithfully render the semantic content of an utterance while simultaneously exhibiting stylistic variations characteristic of Big Five personalities. We created a novel parallel training corpus of over 88,000 meaning representations in the restaurant domain, and matched reference outputs by using an existing statistical natural language generator, PERSONAGE (Mairesse and Walker, 2010). We design three neural models that systematically increase the stylistic encodings given to the network, and show that MODEL CONTEXT benefits from the greatest explicit stylistic supervision, producing outputs that both preserve semantic fidelity and exhibit distinguishable personality styles."
  }],
  "year": 2018,
  "references": [{
    "title": "Tensorflow: A system for large-scale machine learning",
    "authors": ["Paul Tucker", "Vijay Vasudevan", "Pete Warden", "Martin Wicke", "Yuan Yu", "Xiaoqiang Zheng."],
    "venue": "Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation.",
    "year": 2016
  }, {
    "title": "The automated design of believable dialogues for animated presentation teams",
    "authors": ["Elisabeth André", "Thomas Rist", "Susanne van Mulken", "Martin Klesen", "Stephan Baldes."],
    "venue": "Embodied conversational agents pages 220–255.",
    "year": 2000
  }, {
    "title": "Neural machine translation by jointly learning to align and translate",
    "authors": ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio."],
    "venue": "ICLR.",
    "year": 2015
  }, {
    "title": "Evaluation metrics for generation",
    "authors": ["Srinivas Bangalore", "Owen Rambow", "Steve Whittaker."],
    "venue": "Proc. of the First International Natural Language Generation Conference (INLG2000).",
    "year": 2000
  }, {
    "title": "Comparing automatic and human evaluation of nlg systems",
    "authors": ["Anja Belz", "Ehud Reiter."],
    "venue": "EACL.",
    "year": 2006
  }, {
    "title": "Variation across speech and writing",
    "authors": ["Douglas Biber"],
    "year": 1991
  }, {
    "title": "Politeness: Some universals in language usage",
    "authors": ["Penelope Brown", "Steve Levinson."],
    "venue": "Cambridge University Press.",
    "year": 1987
  }, {
    "title": "Jurcı́cek. 2016a. A contextaware natural language generator for dialogue systems",
    "authors": ["Ondrej Dusek", "Filip"],
    "venue": "In SIGDIAL",
    "year": 2016
  }, {
    "title": "2016b. Sequenceto-sequence generation for spoken dialogue via deep syntax trees and strings",
    "authors": ["Ondrej Dusek", "Filip Jurcı́cek"],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
    "year": 2016
  }, {
    "title": "Clusterbased prediction of user ratings for stylistic surface realisation",
    "authors": ["Nina Dethlefs", "Heriberto Cuayáhuitl", "Helen Hastie", "Verena Rieser", "Oliver Lemon."],
    "venue": "EACL 2014 page 702.",
    "year": 2014
  }, {
    "title": "The french media/evalda project: the evaluation",
    "authors": ["Laurence Devillers", "Hélène Maynard", "Sophie Rosset", "Patrick Paroubek", "Kevin McTait", "Djamel Mostefa", "Khalid Choukri", "Laurent Charnay", "Caroline Bousquet", "Nadine Vigouroux"],
    "year": 2004
  }, {
    "title": "Extraversion: the unloved variable in applied linguistic research",
    "authors": ["Jean-Marc Dewaele", "Adrian Furnham."],
    "venue": "Language Learning, 49(3):509–544.",
    "year": 1999
  }, {
    "title": "Controllable abstractive summarization",
    "authors": ["Angela Fan", "David Grangier", "Michael Auli."],
    "venue": "CoRR abs/1711.05217.",
    "year": 2017
  }, {
    "title": "Controlling Linguistic Style Aspects in Neural Language Generation",
    "authors": ["Jessica Ficler", "Yoav Goldberg."],
    "venue": "Proc. of the Workshop on Stylistic Variation at EMNLP 18. pages 94–104.",
    "year": 2017
  }, {
    "title": "Style transfer in text: Exploration and evaluation",
    "authors": ["Zhenxin Fu", "Xiaoye Tan", "Nanyun Peng", "Dongyan Zhao", "Rui Yan."],
    "venue": "Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence (AAAI), pages 663–670.",
    "year": 2018
  }, {
    "title": "Training and evaluation of the his-pomdp dialogue system in noise",
    "authors": ["M. Gašic", "S. Keizer", "F. Mairesse", "J. Schatzmann", "B. Thomson", "K. Yu", "S. Young."],
    "venue": "Proc. Ninth SIGdial, Columbus, OH .",
    "year": 2008
  }, {
    "title": "Contextual lstm (clstm) models for large scale nlp tasks",
    "authors": ["Shalini Ghosh", "Oriol Vinyals", "Brian Strope", "Scott Roy", "Tom Dean", "Larry Heck."],
    "venue": "arXiv preprint arXiv:1602.06291 .",
    "year": 2016
  }, {
    "title": "A very brief measure of the big five personality domains",
    "authors": ["S.D. Gosling", "P.J. Rentfrow", "W.B. Swann."],
    "venue": "Journal of Research in Personality Vol. 37:504–528.",
    "year": 2003
  }, {
    "title": "Neural Response Generation for Customer Service based on Personality Traits",
    "authors": ["Jonathan Herzig", "Michal Shmueli-Scheuer", "Tommy Sandbank", "David Konopnicki."],
    "venue": "Proc. of the INLG.",
    "year": 2017
  }, {
    "title": "An unsupervised method for learning generation dictionaries for spoken dialogue systems by mining user reviews",
    "authors": ["Ryuichiro Higashinaka", "Marilyn A. Walker", "Rashmi Prasad."],
    "venue": "ACM Transactions on Speech and Language Processing 4(4).",
    "year": 2007
  }, {
    "title": "Long short-term memory",
    "authors": ["Sepp Hochreiter", "Jürgen Schmidhuber."],
    "venue": "Neural computation 9(8):1735–1780.",
    "year": 1997
  }, {
    "title": "Enhancing the expression of contrast in the sparky restaurant corpus",
    "authors": ["David M Howcroft", "Crystal Nakatsu", "Michael White."],
    "venue": "ENLG 2013 page 30.",
    "year": 2013
  }, {
    "title": "Towards controlled generation of text",
    "authors": ["Zhiting Hu", "Zichao Yang", "Xiaodan Liang", "Ruslan Salakhutdinov", "Eric P Xing."],
    "venue": "International Conference on Machine Learning pages 1587–1596.",
    "year": 2017
  }, {
    "title": "Extracting social meaning: Identifying interactional style in spoken conversation",
    "authors": ["Dan Jurafsky", "Rajesh Ranganath", "Dan McFarland."],
    "venue": "Proc. of",
    "year": 2009
  }, {
    "title": "A deep ensemble model with slot alignment for sequence-tosequence natural language generation",
    "authors": ["Juraj Juraska", "Panagiotis Karagiannis", "Kevin Bowden", "Marilyn Walker."],
    "venue": "Proc. of the 2018 Annual Conference of the North American",
    "year": 2018
  }, {
    "title": "Imitation learning for language generation from unaligned data",
    "authors": ["Gerasimos Lampouras", "Andreas Vlachos."],
    "venue": "Nicoletta Calzolari, Yuji Matsumoto, and Rashmi Prasad, editors, COLING. ACL, pages 1101–1112.",
    "year": 2016
  }, {
    "title": "An empirical verification of coverage and correctness for a general-purpose sentence gene rator",
    "authors": ["I. Langkilde-Geary."],
    "venue": "Proc. of the INLG.",
    "year": 2002
  }, {
    "title": "A fast and portable realizer for text generation systems",
    "authors": ["Benoit Lavoie", "Owen Rambow."],
    "venue": "Proc. of the Third Conference on Applied Natural Language Processing, ANLP97. pages 265–268.",
    "year": 1997
  }, {
    "title": "A persona-based neural conversation model",
    "authors": ["Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios P Spithourakis", "Jianfeng Gao", "Bill Dolan."],
    "venue": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics pages 994-1003.",
    "year": 2016
  }, {
    "title": "Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits",
    "authors": ["F. Mairesse", "M.A. Walker."],
    "venue": "Computational Linguistics Journal, Vol. 37 Issue 3 pages 455–488.",
    "year": 2011
  }, {
    "title": "Towards personality-based user adaptation: psychologically informed stylistic language generation",
    "authors": ["F. Mairesse", "M.A. Walker."],
    "venue": "User Modeling and User-Adapted Interaction pages 1–52.",
    "year": 2010
  }, {
    "title": "Phrase-based statistical language generation using graphical models and active learning",
    "authors": ["François Mairesse", "Milica Gašić", "Filip Jurčı́ček", "Simon Keizer", "Blaise Thomson", "Kai Yu", "Steve Young"],
    "venue": "In Proceedings of the 48th Annual Meeting of the Asso-",
    "year": 2010
  }, {
    "title": "Trainable generation of Big-Five personality styles through data-driven parameter estimation",
    "authors": ["François Mairesse", "Marilyn A. Walker."],
    "venue": "Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL).",
    "year": 2008
  }, {
    "title": "What to talk about and how? selective generation using lstms with coarse-to-fine alignment",
    "authors": ["Hongyuan Mei", "Mohit Bansal", "Matthew R. Walter."],
    "venue": "Proc. of Human Language Technologies: The 2016 Annual Conference of the North American Chap-",
    "year": 2016
  }, {
    "title": "Dependency Syntax: Theory and Practice",
    "authors": ["Igor A. Melčuk."],
    "venue": "SUNY, Albany, New York.",
    "year": 1988
  }, {
    "title": "To plan or not to plan? discourse planning in slot-value informed sequence to sequence models for language generation",
    "authors": ["Neha Nayak", "Dilek Hakkani-Tur", "Marilyn Walker", "Larry Heck."],
    "venue": "Proc. of Interspeech 2017.",
    "year": 2017
  }, {
    "title": "Why we need new evaluation metrics for NLG",
    "authors": ["Jekaterina Novikova", "Ondrej Dušek", "Verena Rieser."],
    "venue": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing.",
    "year": 2017
  }, {
    "title": "The E2E dataset: New challenges for end-toend generation",
    "authors": ["Jekaterina Novikova", "Ondrej Dušek", "Verena Rieser."],
    "venue": "Proceedings of the 18th Annual Meeting of the Special Interest Group on Discourse and Dialogue pages 201-206.",
    "year": 2017
  }, {
    "title": "Crowd-sourcing nlg data: Pictures elicit better data",
    "authors": ["Jekaterina Novikova", "Oliver Lemon", "Verena Rieser."],
    "venue": "International Conference on Natural Language Generation.",
    "year": 2016
  }, {
    "title": "Individual differences and implicit language: personality, parts-of-speech, and pervasiveness",
    "authors": ["J. Oberlander", "A. Gill."],
    "venue": "Proceedings of the 26th Annual Conference of the Cognitive Science Society, pages 1035–1040.",
    "year": 2004
  }, {
    "title": "Harvesting Creative Templates for Generating Stylistically Varied Restaurant Reviews",
    "authors": ["Shereen Oraby", "Sheideh Homayon", "Marilyn Walker."],
    "venue": "Proc. of the Workshop on Stylistic Variation at EMNLP 18. pages 28–36.",
    "year": 2017
  }, {
    "title": "LIWC: Linguistic Inquiry and Word Count",
    "authors": ["James W. Pennebaker", "L.E. Francis", "R.J. Booth"],
    "year": 2001
  }, {
    "title": "Experiments in evaluating interactive spoken language systems",
    "authors": ["Joseph Polifroni", "Lynette Hirschman", "Stephanie Seneff", "Victor Zue."],
    "venue": "Proc. of the DARPA Speech and NL Workshop. pages 28–33.",
    "year": 1992
  }, {
    "title": "Dear sir or madam, may i introduce the gyafc dataset: Corpus, benchmarks and metrics for formality style transfer",
    "authors": ["Sudha Rao", "Joel Tetreault"],
    "venue": "In Proc. of the 2018 Annual Conference of the North American Chapter of the Association for Computational Lin-",
    "year": 2018
  }, {
    "title": "Building Natural Language Generation Systems",
    "authors": ["Ehud Reiter", "Robert Dale."],
    "venue": "Cambridge University Press.",
    "year": 2000
  }, {
    "title": "Style transfer from non-parallel text by cross-alignment",
    "authors": ["Tianxiao Shen", "Tao Lei", "Regina Barzilay", "Tommi Jaakkola."],
    "venue": "Advances in Neural Information Processing Systems pages 6833–6844.",
    "year": 2017
  }, {
    "title": "Trainable sentence planning for complex information presentation in spoken dialogue systems",
    "authors": ["Amanda Stent", "Rashmi Prasad", "Marilyn Walker."],
    "venue": "Meeting of the Association for Computational Linguistics.",
    "year": 2004
  }, {
    "title": "Sequence to sequence learning with neural networks",
    "authors": ["Ilya Sutskever", "Oriol Vinyals", "Quoc V Le."],
    "venue": "Advances in neural information processing systems. pages 3104–3112.",
    "year": 2014
  }, {
    "title": "A trainable generator for recommendations in multimodal dialog",
    "authors": ["Marilyn Walker", "Rashmi Prasad", "Amanda Stent."],
    "venue": "EUROSPEECH.",
    "year": 2003
  }, {
    "title": "Semantically conditioned lstm-based natural language generation for spoken dialogue systems",
    "authors": ["Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Peihao Su", "David Vandyke", "Steve J. Young."],
    "venue": "Proceedings of the 2015 Conference on Empiri-",
    "year": 2015
  }, {
    "title": "Fish or fowl: A Wizard of Oz evaluation of dialogue strategies in the restaurant domain",
    "authors": ["Steve Whittaker", "Marilyn Walker", "Johanna Moore."],
    "venue": "Language Resources and Evaluation Conference.",
    "year": 2002
  }],
  "id": "SP:46b337cfd8d0b05fa06336b648d87d17af7ff47d",
  "authors": [{
    "name": "Shereen Oraby",
    "affiliations": []
  }, {
    "name": "Lena Reed",
    "affiliations": []
  }, {
    "name": "Shubhangi Tandon",
    "affiliations": []
  }, {
    "name": "Sharath T.S",
    "affiliations": []
  }, {
    "name": "Stephanie Lukin",
    "affiliations": []
  }, {
    "name": "Marilyn Walker",
    "affiliations": []
  }],
  "abstractText": "Natural language generators for taskoriented dialogue must effectively realize system dialogue actions and their associated semantics. In many applications, it is also desirable for generators to control the style of an utterance. To date, work on task-oriented neural generation has primarily focused on semantic fidelity rather than achieving stylistic goals, while work on style has been done in contexts where it is difficult to measure content preservation. Here we present three different sequence-to-sequence models and carefully test how well they disentangle content and style. We use a statistical generator, PERSONAGE, to synthesize a new corpus of over 88,000 restaurant domain utterances whose style varies according to models of personality, giving us total control over both the semantic content and the stylistic variation in the training data. We then vary the amount of explicit stylistic supervision given to the three models. We show that our most explicit model can simultaneously achieve high fidelity to both semantic and stylistic goals: this model adds a context vector of 36 stylistic parameters as input to the hidden state of the encoder at each time step, showing the benefits of explicit stylistic supervision, even when the amount of training data is large.",
  "title": "Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators"
}