{
  "sections": [{
    "heading": "1. Introduction",
    "text": "Crowdsourcing can be a scalable approach to collecting data for tasks that require human knowledge such as image recognition and natural language processing. Through crowdsourcing platforms such as Amazon Mechanical Turk, a large number of data tasks can be assigned to workers who are asked to give binary or multi-class labels. The goal of much of crowdsourcing research is to estimate the unknown ground truth, given that the quality of the workers can be variable. Indeed, due to the high variability of worker skills, aggregating true labels becomes a challenging problem.\n∗. This work was supported partly by the National Science Foundation Grant 1527618, the Office of Naval Research Grant N0014-18-1-2257, the Hariri Institute’s Data Science Fellowship and by a gift from the ARM corporation.\nar X\niv :1\n90 4.\n11 60\n8v 2\n[ cs\nOne straightforward approach is to directly estimate the unknown labels by majority voting from the information provided by workers. In this approach, an implicit assumption is that all workers have identical skills on each task; on the other hand, one might expect the answers from reliable workers are more likely to be accurate. In practice, the crowd is often highly heterogeneous in terms of skill levels, and downweighting unskilled workers and upweighting skilled workers can have a significant impact on the performance. Many aggregation methods ranging from the weighted majority vote to more complex schemes that incorporate worker quality and accuracy have been proposed. Theoretically, recent works (Berend and Kontorovich, 2014; Szepesvári, 2015) have investigated the importance of having precise knowledge of skill quality for accurate prediction of ground-truth labels. Moreover, accurate skill estimation can also be useful for other purposes like worker training, task assignment, or for use in worker-compensation schemes.\nThere are two challenges in estimating skills of workers given that the problem setup is unsupervised. The first challenge is to construct a skill model for each worker. Many papers achieve empirical success by applying Dawid & Skene (DS) model (Dawid and Skene, 1979), which is a simple model that parameterized by the probability of a worker answers the true label. In this paper, the basis of our works is the homogeneous DS model where each worker is assumed to have the same skill level on each class. More specifically, we focus on the single-coin (DS) model for binary crowdsourcing problem in this paper (though in Section 4, we extend our algorithm to multiclass problems).\nThe second challenge is that, in practice, workers are only available for a short period of time which means only a small subset of data is labeled by each worker. This introduces a sparse worker-task assignment (Karger et al., 2013; Dalvi et al., 2013). An additional subtle issue is the lack of diversity in terms of interactions between the workers: a worker is often grouped with a limited subset of workers across all tasks. This situation is remarkably evident on benchmark datasets: The ’Web’ dataset has 177 workers, with 3 to 20 workers/task and each worker on average interacting with about another 2.7 workers only, while the standard deviation of how many workers a worker is interacting with is 15. The ’RTE’ dataset has 164 workers, has only 10 workers/task on the average and each worker interacts with fewer than 2.5 other workers, while the standard deviation of the interaction degree is 20. This is in contrast to most existing crowdsourcing research which only considered estimate skills with nearly complete data. We are therefore motivated by the need to make spectral methods suitable for non-regular worker-task data often seen in practice.\nIn this paper, we suppose that the input comes in the form of a sparsely filled W × T worker-task label matrix. The workers possess unique unknown skills, and tasks assume unique unknown labels. The worker-task label matrix collects the random labels provided by the workers for individual tasks. The skill level of a worker is the (scaled) probability of the worker’s label matching the true unknown label for any of the tasks. The observed labels are independent of each other.\nGiven the workers’ skill levels, the optimal way (Nitzan and Paroush, 1981; Shapley and Grofman, 1984) to reconstruct the unknown labels is to use weighted majority voting where the weights assigned to the label provided by a worker is equal to the log-odds underlying the worker’s skill. Since skill levels are unknown, we follow prior works (Dalvi et al., 2013; Berend and Kontorovich, 2014; Szepesvári, 2015; Bonald and Combes, 2016) and adopt a two-step approach, whereby worker skills are first estimated and then these skills are used with the optimal weighting method to recover labels. Our main contributions are as follows:\n1. We construct a skill estimator under single-coin model as a weighted least-squares rank-one matrix completion/factorization problem. The matrix being factored is the correlation matrix among the workers, with the weights compensating for the varying accuracy in the inter-worker correlations.\n2. We show that skills can be recovered from the observation data matrix whenever the worker-worker interaction graph does not contain a bipartite connected component. In particular, for any crowdsourcing problem that has non-bipartite worker-worker interaction graph, there always exists a method to estimate true skills.\n3. In the context of minimizing the objective function, we propose to use projected gradient descent which is theoretically verified to converge to the true skills. We give natural and mild conditions on the weighting matrix under which we prove that projected gradient descent, despite the objective being non-convex, is guaranteed to find the rank-one decomposition of the true moment matrix.\n4. We extend our algorithm to multiclass case by applying the homogeneous DS model. Under this model, we prove that any multiclass problem can be formulated as a weighted least-squares rank-one problem where the unknown variable is a linear function of true skills.\nOur approach is also of independent interest, as we derive a fundamental result about symmetric rank-one matrix completion: the unobserved entries can be recovered by gradient descent in polynomial time whenever the sampling matrix is irreducible and non-bipartite. Our results for convergence of the proposed gradient descent scheme should be somewhat surprising given that the related weighted low-rank factorization problem is known to be NP-hard even for the rank-one case (Gillis and Glineur, 2011). In contrast to our approach, existing results in low-rank matrix completion require strong assumptions on the weighting matrix, typically some form of incoherence, e.g., (Ge et al., 2016)."
  }, {
    "heading": "2. Related Work",
    "text": "Discriminative Approach: In contrast to our two-step approach, several works adopt a discriminative method for label prediction. Specifically, Li and Yu (2014); Tian and Zhu (2015) directly identify true labels by various aggregation rules that incorporate worker reliability.\nSkill Estimation: As mentioned earlier, we work in the problem of estimating skills under the single-coin model. Past approaches to skill estimation are based on maximum likelihood/maximum posteriori (ML/MAP) estimation, or moment matching, or a combination of these. In particular, various versions of the EM algorithm have been proposed to implement ML/MAP estimation, starting with the work of Dawid and Skene (1979). Variants and extensions of this method, tested in various problems, include Hui and Walter (1980); Smyth et al. (1995); Albert and Dodd (2004); Raykar et al. (2010); Liu et al. (2012). A number of recent works were concerned with performance guarantees for Expectation Maximization (EM) and some of its variants (Gao and Zhou, 2013; Zhang et al., 2014; Gao et al., 2016). Another popular direction is to add priors over worker skills, labels or worker-task assignments. To properly deal with the extra information, various Bayesian methods (belief propagation, mean-field and variational methods) have been considered (Raykar et al., 2010; Karger et al., 2011; Liu et al., 2012; Karger et al., 2013, 2014). Moment matching is also widely used (Ghosh et al., 2011; Dalvi et al., 2013; Zhang et al., 2014; Gao et al., 2016; Bonald and Combes, 2016; Zhang et al., 2016). With the exception of Bonald and Combes (2016), who propose an ad-hoc method, the algorithms in these works use matrix or tensor factorization.1\nIn theory, an ML/MAP method which is guaranteed to maximize the likelihood/posterior, is the ideal method to accommodate irregular worker-task assignments. However, as far as\n1. While Ghosh et al. (2011) pioneered the matrix factorization approach, their work is less relevant to this discussion as they estimate the labels directly.\nwe know, none of the existing algorithms, unless initialized with a moment-matching-based spectral method, is proven to indeed find a satisfactory approximate maximizer of the objective that it is maximizing (Zhang et al., 2016). At the same time, moment matching methods that use spectral (and in general algebraic) algorithms implicitly assume the regularity of worker-task assignments, too. Indeed, the approach of Ghosh et al. (2011) crucially relies on the regularity of the worker-task assignment (as the method proposed uses unnormalized statistics). In particular, this method is not expected to work at all on non-regular data. Other spectral methods, being purely algebraic, implicitly treat all entries in the estimated matrices and tensors as if they had the same accuracy, which, in the case of irregular worker-task assignments, is far from the truth. In particular, the need to explicitly deal with data with unequal accuracy is a widely recognized issue that has a long history in the low-rank factorization community, going back to the work of Gabriel and Zamir (1979). Starting with this work, the standard recommendation is to reformulate the low-rank estimation problem as a weighted least-squares problem (Gabriel and Zamir, 1979; Srebro and Jaakkola, 2003). In this paper, we will also follow this recommendation.\nWhile Dalvi et al. (2013) also use a weighted least-squares objective, this is not by choice, but rather as a consequence of the need to normalize the data rather than to correct for the inaccuracy of the data. Furthermore, rather than considering the direct minimization of the resulting objective, they use two heuristic approaches that also use an unweighted spectral method.\nIn this light, our goal is to make spectral methods suitable for non-regular worker-task data often seen in practice.\nMatrix Factorization/Completion: Unlike the general matrix factorization problem arising in recommender systems (Koren et al., 2009), we are primarily concerned with a rank-one estimation of square symmetric matrices. Existing results on matrix completion (Ge et al., 2016) for square symmetric matrices are more general but require stronger assumptions on the matrix such as incoherence and random sampling.\nNotation and conventions: The set of reals is denoted by R, the set of natural numbers which does not include zero is denoted by N. For k ∈ N, [k] .= {1, . . . , k}. Empty sums are defined as zero. We will use P to denote the probability measure over the measure space holding our random variables, while E will be used to denote the corresponding expectation operator. For p ∈ [1,∞], we use ‖v‖p to denote the p-norm of vectors. Further, ‖·‖ stands for the 2-norm, ‖·‖F is the Frobenius-norm. The cardinality of a set S is denoted by |S|. For a real-valued vector x, |x| denotes the vector whose ith component is |xi|. Proofs of new results, missing from the main text are given in the appendix."
  }, {
    "heading": "3. Formal problem statement",
    "text": "We first consider binary crowdsourcing tasks where a set of workers provide {−1, 1} labels for a large number of items. LetW ∈ N be a positive integer denoting the number of workers. A problem instance θ .= (s,A, g) is given by: a skill vector s = (s1, . . . , sW ) ∈ [−1, 1]W associating the skill level sw with worker w; the worker-task assignment set A ⊂ [W ]× N, which captures which workers provide labels on which tasks; and the vector of “ground truth labels” g ∈ {±1}N, which are unknown and which we would like to estimate.\nWhen A ⊂ [W ]× [T ] for some T ∈ N, we say that θ is a finite instance with T tasks; otherwise we will say θ is an infinite instance. We allow infinite tasks to be able to discuss asymptotic identifiability.\nIt will be convenient to use ΘW to denote the set of all possible problem instances, defined as above. For any instance θ ∈ ΘW , the worker-task assignment set provides important information about worker interaction structure. Indeed, we can think of two workers as “interacting” if they provide a label for the same task. Formally, we define the interaction graph as follows.\nDefinition 1 (Interaction Graph) Let A be a worker-task assignment set. The (worker) interaction graph underlying A is an undirected graph G = GA with vertex set [W ] such that G = ([W ], E) with (i, j) ∈ E if there exists some task t ∈ N such that both (i, t) and (j, t) are elements of A.\nIn the case of infinite instance, the interaction graph is a unweighted graph where an edge does not have any weight associated with it. For finite instances, it will make sense to assign a weight on the edge (i, j) which is the number of tasks shared by workers i and j.\nOur goal is to recover the ground truth labels (gt)t given observations (Yw,t)(w,t)∈A, where Yw,t is a ±1 random variable associated with worker w and task t. According to the single-coin model, the observations are generated as Yw,t = Zw,tgt, where (Zw,t)(w,t)∈A is a collection of mutually independent random variables that satisfy E[Zw,t] = sw. Note that this is the same as assuming that worker w returns gt with probability (1 + sw)/2 and −gt with probability (1− sw)/2.\nThus a worker w with sw = 1 always returns the ground truth, while a worker with sw = −1 always return the opposite label of the ground truth; and a worker with sw = 0 will always provide a random variable Yw,t with zero expectation regardless of the ground truth, i.e., a uniformly random label.\nRemark: As will be discussed in detail later, some additional assumptions on the skill vector s will be needed for accurate estimation of ground truth labels; obviously, little can be done if s is the zero vector, i.e., if every worker returns uniformly random labels irrespective of the ground truth. Another obvious observation is, in the event that all workers agree, we cannot distinguish the possibility that s is proportional to the all ones vector (and every worker provides the right label) from the possibility that s is proportional to the negative of the all ones vector (and every worker provides the wrong label). One way to get around this problem is to assume that s > 0, i.e., all workers have at least some skill; we will make this assumption when analyzing our projected gradient descent method. A weaker approach is to assume that ∑ w sw > 0, i.e., that, on the net, the workers are collectively more prone to return correct rather than incorrect labels; as we discuss later, this is sufficient for identifiability.\nA (deterministic) inference method underlying an assignment set A takes the observations (Yw,t)(w,t)∈A and returns a real-valued score for each task in A; the signs of the scores give the label-estimates. Inference methods are aimed at working with finite assignment sets. To process an infinite assignment set, we define the notion of inference schema. In particular, an inference schema underlying an infinite assignment set A is defined as the infinite sequence of inference methods γ(1), γ(2), . . . such that γ(t) is an inference method for the first t tasks.\nWhen important, we will use the subindex θ in Pθ to denote the probability when the problem instance is θ. We will use Eθ to denote the corresponding expectation operator. With this notation, the expected loss suffered by an inference schema γ = (γ(1), γ(2), . . . ) on the first T tasks of an instance θ is\nLT (γ; θ) = 1 T Eθ [∑T t=1 I { γ (T ) t (Y )gt ≤ 0 }] .\nThe optimal inference schema for an assignment set A given the knowledge of the skill vector s ∈ [−1, 1]W is denoted by γ∗s,A. The next section gives a simple explicit form for this optimal schema. The average regret of an inference schema γ = (γ(1), γ(2), . . . ) for an instance θ ∈ Θ is its excess loss on the instance θ as compared to the loss of the optimal schema:\nRT (γ; θ) = LT (γ; θ)− LT (γ∗s,A; θ) .\nIf the average regret converges to zero, then the loss suffered by γ asymptotically converges to the loss of the optimal inference. Based on this, we define asymptotic consistency and learnability:\nDefinition 2 (Consistency and Learnability) An inference schema is said to be (asymptotically) consistent for an instance set Θ ⊂ ΘW if, for any θ ∈ Θ, lim supT→∞RT (γ) = 0. An instance set Θ ⊂ ΘW is (asymptotically) learnable if there is a consistent inference schema for it."
  }, {
    "heading": "3.1 Two-Step Plug-in Approach",
    "text": "In this work we will pursue a two-step approach based on first estimating the skill vector s and then utilizing a plug-in classifier to predict the ground-truth labels. The motivation for a two-step approach stems from existing results that characterize accuracy in terms of skill estimation errors. For the sake of exposition, we recall some of these results now.\nIt has been shown in Li and Yu (2014), the optimal classifier is log-odds weighted majority voting given by the MAP rule. Suppose the prior distribution of true labels is the uniform distribution over {−1, 1}; then the Bayes classifier is well-known to be the optimal classifier (Duda et al., 2001),i.e.,\nγ∗s,A(Yt) = argmaxl∈{+1,−1} P(gt = l|Yt, s, A) = argmaxl∈{+1,−1} P(gt = l)P(Yt|gt, s, A) = argmaxl∈{+1,−1} logP(Yt|gt, s, A)\n= argmaxl∈{+1,−1} W∑ i=1 log 1 + si 1− si I {Yi,t = l} , (1)\nwhere the third equation follows the assumption that P(gt = +1) = P(gt = −1) = 1/2, and the fourth equation, after some algebra, is compact write to write the MAP estimator. Notice that γ∗s,A is a function of only one parameter, namely the skill vector s.\nRegarding the loss of the optimal schema, we start with introducing result when skills are known in advance. In this case, Berend and Kontorovich (2014) provides an upper error bound, as well as an asymptotically matching lower bound, which are stated as follows:\nLemma 3 For any task t ∈ N, the optimal decision rule γ∗ satisfies P (γ∗t (Y ) 6= gt) ≤ exp ( −1\n2 Φ\n) ,\nP (γ∗t (Y ) 6= gt) ≥ 3\n4[1 + exp (2Φ + 4 √ Φ)] ,\nwhere Φ = ∑ i∈W si log ( 1+si 1−si ) is called committee potential.\nHowever, we do not assume that we know the skills of workers in reality, and thus the true optimal inference classifier is unknown to us. One natural way is to construct a true label inference that approximates the optimal Bayes classifier via estimating workers’ skills. Fortunately, in addition to the case of known skills, Szepesvári (2015); Berend and Kontorovich (2014) also provide an error bound when skills are only estimated:\nLemma 4 For any > 0, the loss with estimated weights v̂i = v(ŝi) satisfies\n1 T Eθ [ T∑ t=1 I {γt,ŝ(Y )gt ≤ 0} ]\n≤ 1 T Eθ [ T∑ t=1 I {γ∗(Y )gt ≤ } ] + Pθ(‖v∗ − v̂‖1 ≥ ) .\nIn turn, the error ‖v∗ − v̂‖1 can be bounded in terms of the multiplicative norm-differences in the skill estimates (see Berend and Kontorovich (2014)):\nLemma 5 Suppose 1+ŝi1+si , 1−ŝi 1−si ∈ [1− δi, 1 + δi] then |v(si)− v(ŝi)| ≤ 2|δi|.\nThese results together imply that a plug-in estimator with a guaranteed accuracy on the skill levels, in turn, leads to a bound on the error probability of predicting ground-truth labels. This motivates the skill estimation problem, which we consider in the remainder of this paper."
  }, {
    "heading": "4. Weighted Least-Squares Estimation",
    "text": "In this section, we propose an asymptotically consistent skill estimator for potentially sparse worker-task assignments. We are motivated by the scenario when, for most workers, only a very small portion of tasks are assigned to them. This induces not only an extremely sparse worker-task assignment graph, but more importantly a sparse worker-worker interaction graph.\nRecall that given a problem instance θ = (s,A, g), the data of the learner is given by the matrix (Yi,t)(i,t)∈A which is a collection of independent binary random variables such that Yi,t = gtZi,t and si = E(Zi,t). When A is finite, we define N ∈ NW×W to be the matrix whose (i, j)th entry with i 6= j gives the number of times the workers i and j labeled the same task:\nNij = |{t ∈ N : (i, t), (j, t) ∈ A}|\nand we also let Nii = 0, ∀i = 1, . . . ,W . Note that there is an edge between workers i and j in the interaction graph exactly when Nij > 0.\nWhen A is infinite, Nij may be infinite. In this case, for i 6= j we also define Nij(T ) = |{t ∈ [T ] : (i, t), (j, t) ∈ A}| to denote the number of times workers i and j provide a label for the same task in the first T tasks, and similarly we let Nii(T ) = 0 for all i.\nThe starting point of our approach is the following observation about the single coin model: the expected correlation between each pair of workers is ground-truth independent. Indeed,\nE[Yi,tYj,t] = E[gtZi,tgtZj,t] = E[Zi,tZj,t]\n=\n( 1 + si\n2 1 + sj 2 + 1− si 2 1− sj 2\n) · 1\n+\n( 1 + si\n2 1− sj 2 + 1− si 2 1 + sj 2\n) · (−1)\n= sisj ,\nwhere the second equation used that g2t = 1. This observation motivates estimating the skills using\ns̃ = argminx∈[−1,+1]W 1\n2 ∑ i,j,t | (i,t),(j,t)∈A (Yi,tYj,t − xixj)2 (2)\nNote that the number of terms containing the skill estimate xi of particular worker i in this objective scales with how many other workers this worker i works with. Intuitively, this should feel “right”: the more a worker works with others, the more information we should have about its skill level.\nAs it turns out, there is an alternative form for this objective, which is also very instrumental and which will form the basis of our algorithm and also of our analysis. To introduce this form, define Cij . = sisj and let its empirical estimation be\nC̃ij = 1\nNij\n∑ t | (i,t),(j,t)∈A Yi,tYj,t . (3)\nAn alternative form of the objective in Eq. (2) is given by the following result:\nLemma 6 Let L : [−1, 1]W → [0,∞) be defined by\nL(x) = 1\n2 ∑ (i,j)∈E Nij(C̃ij − xixj)2.\nThe optimization problem of Eq. (2) is equivalent to the optimization problem\nargminx∈[−1,+1]W L(x).\nThe proof, which is just simple algebra to show the two objective functions are equal up to a constant shift, is given in Appendix A.\nThe objective function from Lemma 6 can be seen as a weighted low-rank objective, first proposed by Gabriel and Zamir (1979). Clearly, the objective prescribes to approximate C̃ using xx>, with the error in the (i, j)th entry scaled by Nij . Note that this weighting is reasonable as the variance of C̃ij is proportional to 1/Nij and we expect from the theory of least-squares that an objective combining multiple terms where the data is heteroscedastic (has unequal variance), the terms should be weighted with the inverse of the data variances. Since Nii = 0, the weighting function N can in general be full-rank, and in this case the general weighted rank-one optimization approximation known to be NP-hard (Gillis and Glineur, 2011).\nHowever, our data has special structure, which will allow one to avoid the existing hardness results. Indeed, on the one hand, as the number of data points increases, C̃ij will be near rank-one itself; and, on the other hand, we will put natural restrictions on the weighting matrix which are in fact necessary for identifiability. These conditions will allow us to avoid the NP-hardness results of Gillis and Glineur (2011)."
  }, {
    "heading": "4.1 Plug-in Gradient Descent",
    "text": "To solve the weighted least-squares objective, the simplest algorithm is the gradient descent algorithm. We propose a Plug-in Gradient Descent (PGD) algorithm that sequentially updates the skill level based on following the (negative) gradient of the loss L at each time step:\nx̃t+1i =x t i + η ∑ (i,j)∈E Nij(C̃ij − xtixtj)xtj\nwhere Ni = |{t : (i, t) ∈ A}| = ∑W\nj=1Nij is the number of tasks labeled by worker i and τ > 0 is a tuning parameter. We do not necessarily need to explicitly enforce the constraint that x ∈ [−1, 1]n, though we have found that it helps in terms of the practical performance of the method, as we’ll remark in Section 6 where we discuss experimental results."
  }, {
    "heading": "4.2 An Extension to Multi-class Classification",
    "text": "We now briefly describe how our approach may be extended to the case when the labels are not binary. Above, we have shown how the binary case may be reduced to a noisy rank-one\nmatrix completion problem as in Lemma 6. Here we show how the same approach can be used for the multiclass case.\nAs before, we suppose that W ∈ N workers are asked to provide labels to a series of M -class classification tasks whose ground truths gt, t = 1, . . . , T are unknown. We will use a one-hot encoding of the ground truths, i.e., gt ∈ RM will be expressed as gt ∈ {[1, 0, 0, . . . , 0]T , [0, 1, 0 . . . , 0]T , . . . , [0, 0, . . . , 0, 1]T } ∈ RM .\nWe will associate a skill level with every worker using a homogeneous Dawid-Skene model, where each worker is assumed to have the same accuracy and error probabilities on each class. Formally, worker i provides label l ∈ RM with probability{\nP(Yi,t = l)) = pi if l = gt P(Yi,t = l)) = 1−piM−1 if l 6= gt.\nSimilar to binary tasks, Li and Yu (2014) showed that the optimal prediction method under homogeneous Dawid-Skene model is weighted majority voting. More specifically, when pi, ∀i = 1, . . . ,W are known, the oracle MAP rule is\nγ∗s,A(Y ) = argmaxl∈[M ] ∑\ni:(i,t)∈A\nv∗i I {Yi,t = l} ,\nwhere v∗i = log (M−1)pi\n1−pi ,∀i ∈ [W ]. The proof of this can be obtained by following the same line as in Section 3.1.\nIn order to construct the weighted majority voting model, we extend PGD algorithm to handle multi-class tasks by showing the skill estimation problem is still a rank one matrix completion problem as follows.\nLemma 7 Let us define skill levels\nsi = M\nM − 1 pi −\n1\nM − 1 ,\nand noisy covariances\nC̃ij = 1\nNij ∑ t | (i,t),(j,t)∈A 〈Yi,t, Yj,t〉.\nThen\nE [ M − 1 M C̃ − 1 M − 1 ] = ssT .\nProof Since the random vectors Yi,t and Yj,t are independent, we can write the expectation of the inner product of Yi,t and Yj,t as\nE[〈Yi,t, Yj,t〉] = pipj + 1\nM − 1 (1− pi)(1− pj).\nThis follows because the inner product is one only if Yi,t = Yj,t = l, for some label l, and the probability of this is either pipj or 1−piM−1 1−pj M−1 depending on whether l = gt or l 6= gt.\nA simple algebraic manipulation gives the following\nE[〈Yi,t, Yj,t〉] = M − 1 M\n( M\nM − 1 pi −\n1\nM − 1\n)( M\nM − 1 pj −\n1\nM − 1\n) + 1\nM .\nwhich implies\nE\n[ M\nM − 1 〈Yi,t, Yj,t〉 −\n1\nM − 1\n] = ssT .\nWe thus have\nE [ M − 1 M C̃ − 1 M − 1 ] =\nM M − 1 1\nNij ∑ t | (i,t),(j,t)∈A E〈Yi,t, Yj,t〉 − 1 M − 1\n= 1\nNij ∑ t | (i,t),(j,t)∈A ( M M − 1 E〈Yi,t, Yj,t〉 −\n1\nM − 1 ) = 1\nNij ∑ t | (i,t),(j,t)∈A ssT\n= ssT .\nAs a consequence of this lemma, if we define\nĈij = M M − 1 1\nNij ∑ t | (i,t),(j,t)∈A 〈Yi,t, Yj,t〉 − 1 M − 1 ,\nthen s can be estimated by solving a rank one matrix completion problem with objective function\ns̃ = argminx∈[− 1 M−1 ,1] W ∑ (i,j)∈E (Ĉij − xixj)2.\nAs previously, in the limit as t→∞, the rank-one problem is an exact match for the problem of recovering skills. In the case where t is finite, we will be in the “noisy” regime where Ĉ can be thought of as a noise-corrupted version of the true rank-one matrix ssT , with the amount of noise ill decaying to zero as t→∞."
  }, {
    "heading": "5. Theoretical Results",
    "text": "Up to now, we have shown how label inference can be reduced to the problem of skill estimation, and addressed the skill estimation problem as a sparse rank-one matrix factorization problem (with noise). In this section, we analyze which properties of the interaction graph ensure learnability as the number of tasks approaches infinity. Subsequently, we analyze the convergence properties of the PGD algorithm for finite tasks."
  }, {
    "heading": "5.1 Learnability",
    "text": "We start with the analysis for the infinite instance where Cij = C̃ij = sisj (see Eq. (3) for a definition). There are different ways to let the number of tasks approach infinity while keeping an interaction graph fixed.\nCase A: For a fixed interaction graph G = ([W ], E) we can consider assignment sets such that the minimum number of shared tasks, Tmin(T ) = min(i,j)∈E Nij(T ) approaches infinity. Learnability in this context is a property of the interaction graph.\nCase B: We can also consider an infinite assignment set A and define G∞A = ([W ], E) as the graph where two workers are connected by an edge if Nij = ∞. In other words, we define connectivity based on whether two workers interact finitely or infinitely many times.\nWe will follow the second approach as it is slightly more general than the first (the second approach allows assignment sets A where some workers interact only finitely many times, while the first approach does not allow such assignment sets). Thus, we fix an assignment set A, we let ΘA be the set of instances sharing assignment set A, and we will consider the learnability of subsets Θ ⊂ ΘA.\nTo express complete ignorance towards the true unknown labels assigned to tasks, we will consider Θ which are truth-complete: informally, this means that Θ places no constraints on what the ground truth could be. Formally, truth completeness means that, for any θ = (s,A, g) ∈ Θ, we require Θs,A ⊂ Θ where Θs,A = {(s,A, g) : g ∈ {−1,+1}N}. Truth-completeness expresses that there is no prior information about the unknown labels.\nAs discussed before, the inference problem is inherently symmetric: the likelihood assigned to some observed data Y under an instance θ = (s,A, g) is the same as under the instance (−s,A,−g). Thus, an instance set cannot be learnable unless somehow these symmetric solutions are ruled out.\nTo express the condition this forces us to adopt will require a few more definitions. In particular, given Θ we let S(Θ) = {s ∈ [−1, 1]W : (s,A, g) ∈ Θ} be the set of skill vectors that are present in at least one instance in Θ. For a skill vector s ∈ [−1, 1]W we let P (s) = {i ∈ [W ] : si > 0} be the set of workers whose skills are positive and we let P(s) = {P (s), P (−s)} be the (incomplete) partitioning of workers into workers with positive and negative skills; note that workers with zero skill are left out.\nWith these definitions in place, we will say that Θ is rich if there exists s ∈ [−1, 1]W and α > 1 such that ×i∈[W ]{αsi, si/α} ⊂ S(Θ) (in other words, there must exist s ∈ S(Θ) and α > 1 such that we can scale each component of s by either α or 1/α and remain in S(Θ)). This is a fairly mild condition; it is satisfied if, for instance, there is some point in s ∈ S(Θ) such that a small open-set around that point that is fully contained in Θ.\nRichness is required so that there is sufficient ambiguity about skills. Indeed, if richness is not satisfied, then either every skill vector in S(Θ) is a spammer or hammer (i.e., si ∈ {−1, 1} for all i) or S(Θ) ∩ (−1, 1)W has a specific structure. This structure could potentially be exploited by an algorithm. One might say that assuming richness requires an algorithm to be agnostic to any specific structural knowledge of skill vectors.\nWe are now ready to state our first main result, which characterizes when rich, truthcomplete sets are learnable.\nTheorem 8 (Characterization of learnability) Fix an infinite assignment set A and assume that G = G∞A is connected. Then, a rich, truth-complete set of instances Θ ⊂ ΘA over A is learnable if and only if the following hold:\n(i) For any s, s′ ∈ S(Θ) such that |s| = |s′| and P(s) = P(s′), it follows that s = s′;\n(ii) The graph G is non-bipartite, i.e, it has an odd-cycle.\nCondition (i) requires that any s ∈ Θ should be uniquely identified by |s| and knowing which components of s have the same sign and which components are zero. For example, this condition will be met if Θ is restricted so that it only contains skill vectors that have a positive sum. For an explanation of why such an assumption is needed, see the (boldfaced) remark in Section 3.\nWe remark that if the graph G is not connected, we can simply apply this theorem to each of its connected components. For example, in the situation where none of the workers 1, . . . , k have shared a task with any of the workers k + 1, . . . , n, one could try to simply recover the skills of workers 1, . . . , k from their common tasks and then the skills of k + 1, . . . , n from their common tasks. This allows us to drop the condition in the theorem that G be connected, at the expense of changing (ii) to the assertion that none of the connected components of G should be bipartite.\nThe forward direction of the theorem statement hinges upon the following result which is proved in Appendix:\nLemma 9 For any g ∈ {±1}, s ∈ [−1, 1]W and an assignment set with a connected, non-bipartite interaction graph G∞A , there exists a method to recover |s| and P(s).\nThe reverse implication in the theorem statement follows from the following result:\nLemma 10 Assume that the lengths of all cycles in G are even. Then there exists s, s′ ∈ [−1, 1]W , s 6∈ {−s′, s′} such that Cij = sisj = s′is′j.\nLearnability for Finite Tasks: We mention in passing that asymptotic learnability is a fundamental requirement, which if not met precludes any reasonable finite time result. In consequence there is no inference schema γ achieves zero regret in this case."
  }, {
    "heading": "5.2 Convergence of the PGD Algorithm",
    "text": "The previous section established that for learnability the limiting interaction graph G∞A must be a non-bipartite connected graph. We will now show that PGD under these assumptions converges to a unique minimum for both the noisy and noiseless cases.\nBy the noiseless case, we mean that in the loss L of Theorem 6, we set C̃ij = Cij = sisj for (i, j) ∈ E. That is, we have infinite number of common tasks to estimate C̃ij which will then equal the expected value Cij . However, in reality, we always suffer from the estimation error (i.e., |Cij − C̃ij |, ∀(i, j) ∈ E) which leads to a more troublesome problem than a rank one matrix completion. We also provide an analysis of our PGD algorithm in this \"noisy\" case.\nOur first step is to show that, under the condition G is connected and non-bipartite, the loss has a unique minimum and the PGD algorithm recovers the skill vector. For technical convenience, our theorem below considers recovering the absolute values of skills |s|. This is the same as recovering the vector s, as we discuss next.\nIndeed, observe that if A = ssT is rank-1, then |A| = |s||s|T is also rank-1, where the absolute value is taken elementwise. Then we can simply take the absolute value of all-revealed entries; the theorem below will ensure that the PGD method recovers |s|. Once |s| is recovered, we need to do some post-processing to recover the sign of each entry.\nIt should be natural that, because we do not assume access to any true labels, recovering s once |s| is available will require some assumption on the vector s. Indeed, even in the simplest scenario of a complete worker-task interaction graph withW −1 agents always agreeing with each other and disagreeing with agent W , we cannot distinguish between the possibilities that (s1 = s2 = · · · = sW−1 = 1, sW = −1) and (s1 = s2 = · · · = sW−1 = −1, sW = 1). In other words, we fundamentally cannot know if the W − 1 agreeing agents are lying or telling the truth. Therefore we will be assuming as before that ∑W i=1 si > 0; this is just saying that there is more truth-telling that lying in the entire system. Under this condition, a post-processing step becomes possible.\nPost-processing for sign recovery. If |s| is recovered, we recover the signs of each entry as follows. We assign a positive sign to the first worker (s1 > 0). We then inspect all the elements s1sj over j neighbors of the first worker (i.e., workers that have a joint task with the first worker) and assign a sign to them by inspecting the sign of s1sj . We then repeat this, assigning signs to all the neighbors of workers whose sign was just assigned, until the sign of every worker is assigned. Finally, we check if for the resulting vector satisfies∑\ni si > 0; if not, we flip the sign of every worker. It is immediate that this process always recovers the signs correctly, provided the underlying graph is connected and non-bipartite and ∑ i si > 0.\nTheorem 11 The PGD Algorithm with s > 0 and x(0) > 0 converges to the global minimum x = s under conditions for learnability of Theorem 8 and small enough stepsize η.\nAs above, if the underlying graph G is not connected, we can, as remarked earlier, simply apply this theorem to each of the connected components. The key requirement of\nTheorem 8 – that the underlying graph is not bipartite – then becomes the requirement that none of the connected components of G are bipartite.\nWe next consider the problem of obtaining a polynomial-time convergence rate for the problem, and moreover doing so in the noisy case. Thus we now consider the case when only the perturbed entries sisj + ∆ij are revealed. We will now make the slightly stronger assumption (discussed at more length below) that the correct answer s lies in the cube C = [κ,K]W where 0 < κ ≤ K. Without loss of generality, we can therefore assume that all revealed entries lie in this set, i.e.,\nsisj + ∆ij ∈ [κ,K] for all (i, j) ∈ Ω,\nbecause otherwise we can simply threshold the revealed entries over [κ,K] while simultaneously reducing the disturbances ∆ij .\nIt is natural to attempt to generalize our earlier PGD approach to this setting, in particular by doing gradient descent on the “perturbed” function\nf∆(x) := 1\n2 W∑ i,j=1 Nij(xixj − sisj −∆ij)2.\nWhile this is possible, we pursue a shortcut naturally adapted to this setting, by using a re-scaling of so-called exponentiated gradient method.\nSpecifically, defining ∇t by\n[∇t]i = W∑ j=1 Nij(xixj − sisj −∆ij), i = 1, . . . ,W,\nwe update as x(t+ 1) = PC [ x(t)e−α∇t ] . (4)\nWe may think of ∇t as related to, but not identical, to the gradient of the perturbed function ∇f∆(x(t)). Indeed, observe that the latter quantity will weigh each term in the definition of ∇t slightly differently. Exponentiated gradient methods of this type are common when optimizing over the simplex, where they come from regularization with the KL divergence (see Hazan (2016)). They are somewhat less common when optimizing over a cube, as we do here. All the same, the following theorem shows that this method is able to achieve polynomial-time convergence for the perturbed problem.\nBefore we state our main result on the performance of this scheme, we need to introduce some notation. Note that the condition that G is connected and non-bipartite implies that the worker-interaction count matrix N is irreducible and aperiodic. The signless Laplacian matrix is then defined as\n[Ls]ij = { Nij j 6= i∑n\nk=1Nik j = i .\nBy contrast, we will use N to denote the matrix whose i, j’th entry is Nij ; the matrix N will thus have zero diagonal.\nThe matrix Ls contrasts with the usual Laplacian because the off-diagonal elements have positive signs. It can be shown that if the graph G is not bipartite, the matrix Ls is positive definite (Desai and Rao, 1994). In fact, the following stronger assertion is true. We will use λ to denote the smallest eigenvalue of the signless Laplacian matrix of a non-bipartite graph with unit weights; we remark that it as consequence of the results of Desai and Rao (1994) that λ ≥ 1/W 3 (where, recall, W is the number of workers, so that the matrices N and Ls are W ×W ). Finally, we let Nmin be the smallest positive weight among {Nij}. Our final main result, which obtains a polynomial-time convergence rate in both the unperturbed and perturbed cases, is given in the following theorem.\nTheorem 12 Suppose s is located in the interior of [κ,K]W where 0 < κ ≤ K. Provided maxi,j |∆ij | is small enough and α = (2 √ W ||N ||2K2)−1, we have that:\n1. Eq. (4) has a limit, which we will denote by x∗∆.\n2. Convergence to any neighborhood of x∆∗ occurs in polynomial-time.\n3. x∗∆ is close to s in the following sense:\n||x∗∆ − s||2 ≤ K √ W ||N ||∞ µ max i,j |∆ij |,\nwith µ = κ2λmin(Ls)Nmin.\nIn particular, in the noiseless case when ∆ = 0, we have that x∗0 = s.\nWe note that the assumptions of Theorem 11 are slightly weaker than the assumptions of Theorem 12. While the former assumed that s > 0, the latter assumed the slightly stronger statement that mini si > κ > 0. This can always be accomplished by throwing out nodes with si ≈ 0 from the data set; such modes are making random guesses and do note contribute to the accuracy of the Bayes classifier of Eq. (1) which should assign them zero weight. A natural way to do this is to simply set to zero any Nij corresponding to correlations C̃ij whose absolute values are smaller than δ +O( √ (logW )/T ) for some small δ > 0. The advantage of this threshold is that all agents with si = 0 will, with high probability, have all their interactions Nij set to zero and thus automatically ignored by both the PGD method and the variant of exponentiated gradient proposed here. On the other hand, any pair of workers i, j with |si| and |sj | strictly larger than √ δ will have their correlation above this threshold with high probability . Finally, we discuss the key “trick” underlying the proof of this theorem. The main idea is to interpret the update of Eq. (4) as a projected gradient descent on the function\ng∆(z) = 1\n2 W∑ i,j=1 Nije zi+zj − W∑ i=1 zi n∑ j=1 Nij(sisj + ∆ij),\nafter a change of variable. The construction of this function is what allows us to bypass a lot of the technical difficulties in the analysis.\nFinite-Task Bound: Note that we can directly apply this result to obtain a finite task characterization as well. In particular consider a connected and non-bipartite interaction graph. Define dmax as the maximum degree and D as the sum of the degrees. It follows by standard Hoeffding bounds that with probability greater than (1− δ) we have max(i,j)∈E |Cij − Ĉij | ≤\nlog(D/δ)√ Nmin . We can then set ∆ = Cij − Ĉij and plug this bound into the above theorem to obtain\n||x∗∆ − s||2 ≤ K √ W ||N ||∞ µ log(D/δ)√ Nmin ."
  }, {
    "heading": "6. Experimental Results",
    "text": "In this section, we will be showing the experimental results to the PGD scheme. We will make one minor modification to the algorithm by adding a projection away from the boundary of the cube si = 1 by projecting xi onto [−1 + t/ √ Ni, 1− τ/ √ Ni] at every step, where recall Ni is the number of tasks assigned to agent i and τ is a parameter. The justification is that skills close to one or negative one have an overwhelming impact on the plug-in rule of Eq. (1). According to Hoeffding inequality, the skill estimates are expected to have an uncertainty proportional to τ/ √ Ni with probability const × e−τ\n2 . There is little loss in accuracy in confining the parameter estimates to the appropriately reduced hypercube, while in principle one could tune this parameter, we use τ = 1 in this paper.\nSynthetic Experiments: We will experiment with different graph types, increasing levels of label noise, graph-size, skill distribution, and different weighting functions on synthetic data.\nImpact of Graph Type: We consider three 11-node (# workers) irreducible, non-bipartite graphs, namely, a Clique (G1), Star with augmented odd cycle (G2), and a Ring (G3) to illustrate the impact of sparsity (Clique has dense worker interactions while Star/Ring have fewer than 3 worker interactions) and graph-type (Ring vs. Star). An illustration of the different graph types is shown in Figure 2. These graphs satisfy condition (ii) of Thm 8.\nNoise Robustness: To see the impact of noise, we vary the noise level by increasing the number of tasks, which in turn reduces the error in the correlation matrix. Tasks are randomly assigned to binary classes ±1 with total number of tasks ranging from 11 to 330. Skills are randomly assigned on a uniform grid between 0.8 and −0.32\nInfluence of Different Skill-Distribution: We randomly assign binary classes to T = 300 tasks and select five pairs of parameters. Average prediction errors are presented in Table 1 averaged over 10 independent runs. Parameters α = 5, β = 1, correspond to reliable workers leading to small prediction error; the prediction error with parameters α = 2, β = 2 and α = 0.5, α = 0.5, is almost random because of ∑ i∈[W ] si is no longer positive, which\n2. The reason for this choice is to satisfy condition (i) in Theorem 8, i.e., requiring overall skills to be positive. Aggregate skill is about 0.25.\nvalidates our theory. Similar situation arises for α = 2, β = 5 and α = 5, β = 1, because the skills are all flipped relative to our assumption that the sum of the skills is positive.\nInfluence of Graph Size: We focus on how the graph size affects the performance of PGD algorithm. Note that graph size is associated with the number of workers. Our goal is to demonstrate that for a constant amount of noise, prediction accuracy of PGD does not degrade with graph-size. We again consider the case when the worker-interaction graph is a star-graph with an odd-cycle of length 3. We increase the size of worker-interaction graph by adding nodes to the star-graph. Skills s are selected between 0.8 and −0.3 uniformly. To fix the noise level, we define Cij = sisj + ξij , ∀(i, j) ∈ E where ξij is randomly selected from [−0.2, 0.2]. Note that the noise level is quite large relative to what we expect in terms of accuracy of correlation estimates. We iteratively run PGD for 50 times. The average prediction errors with different graph size it presented in Table 2. It can be seen that the prediction error is not sensitive to the graph size compared to the Bayes error.\nInfluence of Weighting function: It is straighforward from our proof of Theorem 11 to see that PGD algorithm converges to the global optimal for any non-negative weights. Our objective is based on weighting with number of counts in Eq. 6. However, there are other options that one could consider. Dalvi et al. (2013) has suggested using B(Nij) = N2ij , while we use Nij . Another possibility is to use binary weights. We iteratively run PGD 10 times for each weighing function with T = 300 tasks for different types of task assignements. If Nij ’s are all equal, these choices produce identical results. We consider two cases: (a) Spammers are assigned a majority of tasks; (b) Positively skilled workers are assigned most\ntasks. The prediction errors are compared in Table 3. Note that quadratic weighting is quite bad in this case because it tends to ignore positively skilled workers. On the other hand unweighted case does not accurately estimate spammers and also results in poor choice.\nWe compare the average prediction error PE = 1T ∑\nt=1,...,T 1{Ŷt 6= gt} with the Majority Voting (MV) algorithm, the KOS algorithm (Karger et al., 2013), Opt-D&S algorithm (Zhang et al., 2014), the ER algorithm (Dalvi et al., 2013), the IWMV algorithm (Li and Yu, 2014), and the M3V algorithm (Tian and Zhu, 2015). The KOS algorithm is based on belief propagation, Opt-D&S uses a spectral method to initialize EM, the ER algorithm is the more successful spectral method of the paper defining it, the IWMV algorithm is an EM-style algorithm. Each algorithm is averaged over 15 trials on each dataset. The average prediction errors are presented in Figure 2. As the number of tasks grows, the average prediction error of PGD algorithm decreases. PGD is evidently robust to missing data/sparsity and graph-type. OPT-DS, which is close to PGD performance suffers significant performance degradation on sparse graphs such as rings. We can attribute this to the fact that a tensor-based method requires at least 3 worker annotations for each task Zhang et al. (2014).\nBenchmark Dataset Experiments: We illustrate the performance of PGD algorithm against state-of-art algorithms. Each algorithm is executed on five data-sets, i.e. RTE1 (Snow et al.), Temp (Snow et al.), Dogs (Deng et al., 2009), WSD (Word Sense Disambiguation) (Snow et al.),and WebSearch (Zhou et al., 2012). A summary of these data-sets is presented in Table 4. Following convention we report errors between ground-truth and recovered labels in Table 5. Note that on WSD dataset, OPT-D&S algorithm does not converge to a equilibrium point after 1000 iterations.\nInfluence of Graph Sparsification: Here we consider the scenario where fewer workers label each task on the binary classification benchmark datasets. Binary classification tasks are aligned with our theoretical results. This experiment will highlight the performance of\nstate-of-art algorithms under sparse task-assignments. We simulate this effect based on random sparsification. In particular, we sort the degree of each node on the interaction graph. To sparsify the graph we randomly delete edges starting with the highest degree node and continue this process for other nodes until we obtain an interaction graph with desired maximum degree. We also remove symmetrically remove corresponding edges of incident workers to maintain symmetry. This has the implicit effect of deleting some of the tasks as well (for instance, if a task is annotated by two workers). Higher levels of sparsification leads to fewer availability of tasks for training. We iteratively run PGD and the other algorithms for 50 Monte-Carlo trials with different desired maximum degrees. The average prediction errors are displayed in Figure 3. The reason IWMV performs poorly is that majority votes are no longer reliable, which IWMV relies on. Our PGD algorithm is surprisingly robust to sparsification of interactions and degrades gracefully relative to other schemes. This highlights the fact that PGD is capable of leveraging sparse interactions among workers and obtain fairly robust estimates of skill-levels required for accurate prediction.\nNormal gradient descent vs Eq. (4): Although we have found it convenient to use Eq. (4) for our polynomial-time convergence results, in practice we do not see much advantage of that iteration compared to normal gradient descent. Figure 4 gives a comparison in the noiseless case while Figure 5 gives a comparison in the noisy case. The results are extremely similar. Results are shown for random s and three choice of graphs; each plot is the result of a single realization. In general, all the realizations we have seen look like the plots shown, with only minor differences between the methods.\nTime Complexity: We also compare the time complexity of proposed algorithm against state-of-art algorithms. Our PGD algorithm requires fewer iterations in comparison to other iterative methods and each iteration scales linearly with W and the maximum degree, Dmax, of the worker-interaction graph which is bounded by W . Time complexity of different algorithms is summarized in Table 6 3.\n3. Opt-D&S, KOS, and ER algorithms are omitted. They employ spectral factorization and have high time complexity.\ncomponent uniformly random over [0.4, 0.6]. Starting point was x(0) = 0.6 · 1 and stepsize was taken to be 0.01 in both cases."
  }, {
    "heading": "7. Conclusions",
    "text": "We propose a new moment-matching approach with weighted rank-one approximation and propose a gradient algorithm for worker skill estimation in Crowdsourcing. In contrast to prior work, the weights are set up to correct for the spread of the measured worker-worker agreements accuracies which are typical in real-world problems where who works on the same task with whom is out of control. Our results explicitly characterize identifiability and convergence rates in terms of spectral graph theoretical quantities, revealing the importance of worker interaction graphs for skill estimation. The general problem studied here, is related to state estimation with intermittent and active sensor communications (Saligrama and Castanon, 2006; Hanawal et al., 2017), which we plan to explore in future work."
  }, {
    "heading": "Appendix A. Proof of Lemma 6",
    "text": "Recall that θ is a finite index. For each (i, j) such that Nij > 0, we have\n1\nNij ∑ t:(i,t),(j,t)∈A (Yi,tYj,t − xixj)2 = 1 Nij ∑ t:(i,t),(j,t)∈A (1− 2Yi,tYj,txixj + x2ix2j )\n= 1− 2C̃ijxixj + x2ix2j = C̃2ij − 2C̃ijxixj + x2ix2j + 1− C̃2ij = (C̃ij − xixj)2 + 1− C̃2ij .\nTherefore,\n1\n2 ∑ (i,t),(j,t)∈A (Yi,tYj,t − xixj)2 = 1 2 ∑ i,j∈[W ] Nij(C̃ij − xixj)2 + ∑ i,j∈[W ] Nij(1− C̃2ij)\nSince ∑\ni,j∈[W ]Nij(1− C̃2ij) is a constant, Eq.(2) is equivalent to the optimization problem argminx∈[−1,+1]W L(x)."
  }, {
    "heading": "Appendix B. Proof of Theorem 8",
    "text": "The proof directly follows from Lemma 9 and Lemma 10. We will next prove these Lemmas.\nProof of Lemma 9: Take any two workers i, j that are connected in G. Let t ∈ N be a task such that (i, t), (j, t) ∈ A. By assumption,\nYi,tYj,t = g 2 tZi,tZj,t = Zi,tZj,t.\nLet us define C̄ij . = lim\nT→∞\n1\nT ∑ (i,t),(j,t)∈A,t≤T Yi,tYj,t.\nBy the law of large numbers,\nC̄ij = E[Zi,tZj,t] = sisj .\nFor convenience, we define C̄ij = 0 when (i, j) 6∈ E. Next without loss of generality assume that workers 1, 2, . . . , 2k + 1 form a cycle in G. Then,\ns1 = C̄1,2k+1s −1 2k+1\n= C1,2k+1C −1 2k+1,2ks2k = C1,2k+1C −1 2k+1,2kC2k,2k−1s −1 2k−1\n...\n= C1,2k+1C −1 2k+1,2kC2k,2k−1 . . . C2,1s −1 1 ,\nwhich implies that\n|s1| = √ C1,2k+1C −1 2k+1,2kC2k,2k−1 . . . C2,1 ,\nassuming that C2,3, C4,5, . . . , C2k,2k+1 6= 0. This gives a method to recover |s1|.\nNow, since G is connected, for any worker i there exists a path from worker 1 to worker i. If this path was given by the vertices 1, 2, . . . , ` then\n|s`| =|C`,`−1| |s−1`−1| = |C`,`−1| |C −1 `−1,`−2| |s`−2|\n= · · · = |C`,`−1| |C−1`−1,`−2| · · · |C (−1)` 2,1 | |s1| (−1)`+1 .\nwhich shows how |sl| may be recovered. We conclude that |s| can be recovered. It remains to show that P(s) can be recovered. Let i, j ∈ [W ] be two different workers. Then, if π ⊂ E is any path in G from i to j, we have\nΠ(u,v)∈E sgn(Cu,v) = Π(u,v)∈E sgn(su) sgn(sv) = sgn(si) sgn(sj).\nWe emphasize this holds for all paths connecting i and j, and in particular Π(u,v)∈E sgn(Cu,v) is the same for any path connecting i and j.\nNow if i and j are such that for some path π connecting them Π(u,v)∈E sgn(Cu,v) = +1, we assign i, j to the same group; otherwise we assign them to different groups. It is easy to see that this creates exactly two groups. The resulting “partition” must match P(s).\nProof of Lemma 10: Take s, α which are used in the definition of richness of Θ. We construct two other skill vectors s′ and s′′ as follows: We set s′1 = αs1 and s′′1 = s1/α. Now, if worker i is at an even distance from worker 1 on some path in G then s′i = αsi and s ′′ i = si/α, otherwise we set s′i = si/α and s ′′ i = αsi. Note that all workers can be accessed from worker 1 because G is connected. Note that if there are multiple paths from worker 1 to some other worker then all of these have the same parity, or the graph had an odd cycle. Now, both s and s′ give rise to the same products, sisj , along any edge (i, j) ∈ E. Since both are in Θ by assumption, the result is proven.\nReverse Direction for Theorem 1: We prove this by contraposition. First, assume that (i) does not hold. We want to prove that learnability fails. If (i) does not hold, we can take s, s′ ∈ [−1, 1]W different skill vectors such that |s| = |s′| and P(s) = P(s′) and s, s′ ∈ S(Θ). It follows that s = −s′. Take any g ∈ {±1}W . Note that the instances (s,A, g) and (−s,A,−g) lead to the same joint distribution over the observed labels. Hence, no inference schema can tell these instances apart, thus any inference schema will suffer linear regret on one of these instances. Now, if (ii) does not hold, Lemma 10 gives two skill vectors s, s′ which are different and s 6= ±s′, which again give the same likelihood to any data. This again leads to that any inference schema will suffer a linear regret on one of these instances."
  }, {
    "heading": "Appendix C. Proof of Theorem 11",
    "text": "Our first step is to argue that, with sufficiently small step-size, the PGD method remains bounded. To that end, we have the following proposition.\nProposition 13 Let\nV (x) = max i=1,...,W max ( xi si , si xi ) and suppose that xt is positive and s is positive and that the positive step-size γ is small enough so that\nη||ND2s ||∞V (xt)2 ≤ 1.\nThen, it holds that V (xt+1) ≤ V (xt).\nProof Let us use the notation a./b for the elementwise ratio of vectors a and b, and define rt = xt./s. As a consequence, V (xt) = maxi=1,...,n max ( rti , 1/r t i ) . Now suppose V (xt) = Z, which is a positive number due to the assumed positivity of xt and s; this implies that\nZ−1 ≤ rti ≤ Z for all i = 1, . . . , n. (5)\nLet us fix some index j. The prove the lemma we just need to prove that Eq. (5) holds for rt+1j .\nSuppose first that rtj = βZ where β ∈ (0, 1]. Then\nxt+1j = x t j − η n∑ k=1 Njkx t k(x t kx t j − sksj)\n= xtj − η n∑ k=1 Njks 2 ksjr t k(r t kr t j − 1)\nand therefore\nrt+1j = r t j − η n∑ k=1 Njks 2 kr t k(r t kr t j − 1) (6)\nNow since rtj = βZ and r t k ≥ Z−1 for all k, we have\nrt+1j ≤ βZ − η n∑ k=1 Njks 2 kr t k(Z −1βZ − 1)\n= βZ + η(1− β) n∑ k=1 Njks 2 kr t k ≤ βZ + η(1− β)||ND2s ||∞Z ≤ βZ + (1− β)Z = Z,\nwhere we used our step-size bound as well as the fact that V (xt) ≥ 1 due to the definition of V (·). This proves the upper bound we seek.\nFor the other direction, suppose rtj = µZ −1 where now µ ∈ [1,∞). From Eq. (6), and\nusing the fact that rk ≤ Z for all k, we then have\nrt+1j ≥ µZ −1 − η n∑ k=1 Njks 2 krk(ZµZ −1 − 1)\n= µZ−1 − η(µ− 1) n∑ k=1 Njks 2 krk ≥ µZ−1 − η(µ− 1)||ND2s ||∞Z ≥ µZ−1 − η(µ− 1)Z−1||ND2s ||∞Z2 ≥ µZ−1 − (µ− 1)Z−1 = Z−1\nAs a consequence of this proposition, we have the following bound on how big the iterates xt can get.\nCorollary 14 Suppose s and x0 belong to [κ,K]W where 0 < κ ≤ K. If the step-size η of PGD algorithm satisfies\n0 ≤ η ≤ κ 2\nK2||ND2s ||∞ ,\nthen V (xt) ≤ K/κ and xt ∈ [κ2/K,K2/κ]W for all t = 1, 2, . . ..\nProof Clearly, V (x0)2 ≤ (K/κ)2 given the fact that both s and x0 belong to [κ,K]. Then, η satisfies the step-size condition of Proposition 13 at time 0. Using Proposition 13, we can conclude that V (x1) ≤ V (x0) which implies V (x1)2 ≤ V (x0)2 ≤ (K/κ)2 as well. By applying the same technique iteratively, we have V (xt) ≤ . . . ≤ V (x1) ≤ V (x0) ≤ K/κ,∀t. Since s ∈ [κ,K]W , this implies xt ∈ [κ2/K,K2/κ]W .\nA consequence of the last corollary result is that the function\nLnoiseless(x) . =\n1\n2 ∑ (i,j)∈E Nij(sisj − xixj)2.\ncan, for all practical purposes, be assumed to have a gradient which is Lipschitz. Of course, this is false over all of Rn, but since the iterates of the PGD method stay within a compact set, the gradient of Lnoiseless will be Lipschitz over the region of interest. In particular, we have the following estimate.\nProposition 15 For any y, z ∈ [0,K2/κ]W , we have that\n||∇Lnoiseless(y)−∇Lnoiseless(z)||2 ≤ L̂||y − z||2,\nwith\nL̂ = 4W ||N ||F K4\nκ2 .\nProof We begin by establishing the following claim. Claim: Suppose y, z are vectors belonging to the cube y, z ∈ [0, A]W . Then\n||N ◦ (yyT − zzT )||F ≤ 2 √ WA||N ||F ||y − z||2.\nThis proposition could be obtained by a simple algebraic manipulation as\n||N ◦ (yyT − zzT )||F = Tr(abs(N)abs(yyT − zzT )) (7) ≤ ||N ||F ||yyT − zzT ||F (8) = ||N ||F ||yyT − yzT + yzT − zzT ||F (9) ≤ ||N ||F ( ||y(y − z)T ||F + ||(y − z)zT ||F ) (10)\n≤ 2||N ||F √ WA||y − z||2 (11)\nEq. (7) follows via the inequality ||A ◦ B||F ≤ Tr(abs(A)abs(B)T ). Eq. (8) is obtained by the Cauchy-Schwarz inequality in the form of Tr(AB) ≤ ||A||F |||B||F . Eq. (9) and Eq. (10) are self-explanatory. Eq. (11) follows because every entry of the vectors y, z is at most A. This concludes the proof of the claim.\nLet Px = N ◦ (xxT − ssT ). Then ∇L(x) = Pxx and therefore\n||∇Lnoiseless(y)−∇Lnoiseless(z)||2 = ||Pyy − Pzz||2 = ||Pyy − Pyz + Pyz − Pzz||2 ≤ ||Py||2||y − z||2 + ||Py − Pz||||z||2\n≤ 2 √ W K2\nκ ||N ||F ||y − z||2||y − z||2\n+2 √ W K2\nκ ||N ||F ||y − z||2||z||2,\nwhere the last step used that the 2-norm of a matrix is upper bounded by its Frobenius norm as well as the above claim. Now using the bound ||z||2 ≤ (K2/κ) √ W and the same for ||y − z||2, we obtain the lemma.\nWe now use the standard fact that, for a function f(x) with L-Lipschitz gradient, gradient descent with step-size h < 2/L generates a sequence which satisfies\nf(xt+1) = f(xt)− h (\n1− L 2 h\n) ||∇f(xt)||22.\nIn particular, ∇f(xt)→ 0 under these conditions if f(xt) is bounded below. Clearly, Lnoiseless is bounded below by zero. Thus, to argue that gradient descent on Lnoiseless results in xt → s, we just need to argue that the only point that satisfies ∇Lnoiseless(x) = 0 is x = s.\nWe complete the proof of Theorem 11 by now proving that last statement. Observe that\n[∇Lnoiseless(x)]i = W∑ j=1 Nij(xixj − sisj)xj ,\nwhere the interaction matrix N which is nonnegative, irreducible, symmetric, and with zero diagonal. What we need to argue is that, given s > 0, there does not exist x > 0, x 6= s such that for each i = 1, . . . ,W , we have\nW∑ j=1 Nij(xixj − sisj)xj = 0. (12)\nWe begin by adopting the following notation. For a vector x, Dx will refer to the diagonal matrix with x on the diagonal. For a matrix A, diag [A] will refer to the diagonal of A stacked as a vector (note that this is an unusual notation). Also, let us refer to the set of matrices which are nonnegative, irreducible, aperiodic, symmetric and with zero diagonal as admissible.\nAssume that x satisfies Eq. (12). Then, we can multiply the ith equation of (12) by xi. Our first observation is that we may rewrite Eq. (12) as\ndiag [ DxNDx(xx T − ssT ) ] = 0. (13)\nIt suffices to argue that we cannot positive x and admissible F such that diag [ F (xxT − ssT ) ] = 0.\nNote that we were able to drop the Dxs from the equation because N is admissible if and only if DxNDx is.\nWe proceed as follows. Since xixj − sisj = si ( xi si xj sj − 1 ) sj ,\ndefining ui = xi/si, we have that u is positive and that\nxxT − ssT = Ds(uuT − 11T )Ds .\nWe must therefore argue that it is impossible to find u > 0, u 6= 1 and admissible F such that\ndiag [ DsFDs(uu T − 11T )Ds ] = 0.\nSince s > 0 it will suffice to argue that we cannot find u > 0, u 6= 1 and admissible Z such that\ndiag [ Z(uuT − 11T ) ] = 0. (14)\nWithout loss of generality, we can assume that u1 ≤ u2 ≤ · · · ≤ uW ; we can always relabel indices to make this hold.\nNow there are three possibilities:\n1. u1uW > 1.\n2. u1uW = 1.\n3. u1uW < 1.\nWe argue that in each case we cannot find a suitable u that satisfies Eq. (14). Indeed, let us consider the first possibility. In that case the last column of uuT − 11T , with entries uiuW − 1, is strictly positive, and therefore, considering that [Z(uuT − 11T )]WW = 0, we obtain that the last row of Z must be zero – contradicting irreducibility. Similarly, in case 3, the first column of uuT − 11T , with entries u1ui − 1, is negative, and, considering that [Z(uuT − 11T )]11 = 0, we see that the first row of Z must be zero, which can not hold true.\nIt remains to consider case 2. We may assume that u1 < uW (ruling out the possibility that a u proportional to the all-ones vector satisfies Eq. (14) is trivial). We break up {1, . . . ,W} into three blocks. The first block is all the indices j such that uj = u1. The third block is all the indices j such that that uj = uW . All the other indices go into block 2. Note that block 2 may be empty, for example if every entry of u is equal to u1 or uW .\nThe advantage of partitioning this way is that the matrix uuT − 11T has the following sign structure:\nuuT − 11T =  − − 0− ∗ + 0 + +  where − represents a strictly negative submatrix, + represents a strictly positive submatrix, while ∗ represents a submatrix that can have elements of any sign. The strict negativity comes from the fact that u1 < uW .\nPartitioning Z in a compatible manner, we have that\ndiag  Z11 Z12 Z13Z21 Z22 Z23 Z31 Z32 Z33  − − 0− ∗ + 0 + +  = 0. Considering the (1, 1) diagonal block of the above product, noting that Z ≥ 0, we obtain Z11 = Z12 = 0; and considering the (3, 3) diagonal block of the above product we obtain Z32 = Z33 = 0. By symmetry, also Z21 = 0 and Z33 = 0.\nFrom here we can easily derive a contradiction. Indeed, if the middle block is nonempty, the matrix is reducible; and if the second block is empty, it is periodic."
  }, {
    "heading": "Appendix D. Proof of Theorem 12",
    "text": "Let us adopt the convention that when a = (a1, . . . , an) is a vector, we will understand ea to apply to it elementwise, i.e., ea = (ea1 , . . . , ean). We will find it convenient to do our analysis in terms of the variables z(t) defined through the relation x(t) = ez(t). In terms of these variables, we can rewrite Eq. (4) as\nez(t+1) = PC [ ez(t)−α∇t ] . (15)\nObserve that projection of a vector a onto the cube C simply thresholds each ai between κ and K. Inspecting Eq. (15), we therefore see that we can move the projection inside the exponentiation if we instead project onto the cube Ω = [lnκ, lnK]W :\nez(t+1) = ePΩ[z(t)−α∇t],\nor z(t+ 1) = PΩ [z(t)− α∇t] . (16)\nThe trick that makes the proof possible is that we can construct a function so that Eq. (16) becomes a projected gradient descent iteration. To that end, we define\ng∆(z) = 1\n2 W∑ i,j=1 Nije zi+zj − W∑ i=1 zi n∑ j=1 Nij(sisj + ∆ij).\nThe key observation is that the gradient of this function is\n[∇g∆(z(t))]i = W∑ j=1 Nije zi(t)+zj(t) − n∑ j=1 Nij (sisj + ∆ij)\n= W∑ j=1 Nij(e zi(t)+zj(t) − sisj −∆ij)\n= [∇t]i,\nwhere the last step used the definition of z(t), i.e., ezk(t) = xk(t) for all k = 1, . . . ,W . Thus we have that\nz(t+ 1) = PΩ [z(t)− α∇g∆(z(t))] . (17)\nBecause we now have a projected gradient descent iteration on a convex function (it is, of course, immediate that g∆(z) is convex), it should now be clear that an analysis of this iteration in terms of z(t) id possible, provided by we can upper bound the condition number of the function g∆(z) over the region z ∈ [lnκ, lnK]W . To analyze this condition number, we argue as follows.\nFirst, because ∇2g∆(z) = Ls((Nij/2)ezi+zj ), where Ls(wij) refers to the signless Laplacian with weights wij , i.e.,\nLs(wij) = W∑ i,j=1 wij(ei + ej)(ei + ej) T .\nIt follows that λmin(Ls(wij)) is a monotonic function of the weights {wij}; this then implies that g∆(z) is a µ-strongly convex over Ω, where µ = κ2Nminλmin(Ls), where Ls is the signless Laplacian of the unweighted graph corresponding to the interaction matrix Nij and Nmin is the smallest positive Nij . We remind the reader that it was shown in Desai and Rao (1994) that λmin(Ls) ≥ 1/W 3.\nSecond, we need to argue that g∆(z) has gradient that is L-Lipschitz, along with an estimate for L. To this end, we reprise the argument we used in the proof of Theorem 11 and argue that for any a, b ∈ [lnκ, lnK]W we have:\n||∇g∆(a)−∇g∆(b)||2 = ||diag(ea)Nea − diag(eb)Neb||2 ≤ ||diag(ea)N(ea − eb)||2 + ||(diag(ea)− diag(eb))Neb||2 ≤ K||N ||2K||a− b||2 +K max\ni |ai − bi|||N ||2K\n√ W\n≤ 2||N ||2K2 √ W ||a− b||2,\nwhere we used that for vectors a, b ∈ [lnκ, lnK]W we have that\n||diag(ea)||2 ≤ K ||eb||2 ≤ K √ W\n||ea − eb||2 ≤ K||a− b||2 ||diag(ea)− diag(eb)||2 ≤ K max\ni=1,...,W |ai − bi|\nIn conclusion, we may take L = 2 √ W ||N ||2K2.\nHaving obtained bounds on L, µ, we next analyze the performance of Eq. (17). Defining,\nz∗∆ := arg min z∈Ω g∆(z),\nwe have that z(t) converges to z∗ with the choice α = 1/L; as an immediate consequence, we have that x(t)→ x∗∆ where\nx∗∆ = e z∗∆ .\nThis proves the first assertion of the theorem, that x(t) converges. To prove the second and third part, we first need to establish the following technical lemma.\nLemma 16 If s lies in the interior of [κ,K]W and maxi,j |∆ij | is small enough, then z∗∆ lies in the interior of Ω = [lnκ, lnK]W .\nProof We first argue that the unique minimizer of g0(z) (i.e., when ∆ = 0) is z∗ = ln s. Indeed, observe that ∇g0(ln s) = 0. Moreover, we have already discussed that, over the region [ln a, ln b]W , the Hessian of g0 has eigenvalues lower bounded by µ = a2Nminλmin(Ls). Since the assumption that the graph corresponding to N is connected and non-bipartite renders implies the signless Laplacian Ls is positive definite (again, see Desai and Rao (1994)), we obtain that g0(z) is strictly convex. Thus z∗ = ln s is the unique minimizer of g0 over Ω.\nIt follows that the same property holds for small enough ∆ “by continuity.” More formally, the argument is as follows. As a consequence of the function that ln s is the unique minimizer of g0(z) over Ω, we have that there is a ball B of positive radius around ln s such that the function g0(z) is strictly smaller on B than it is on any point of the boundary of the cube Ω. It follows that, for small enough ∆, the function g∆ will also be strictly smaller on B than on any point on the boundary of Ω. This implies that the minimium of g∆ occurs in the interior of Ω.\nHaving established this lemma, we now turn to an analysis of the convergence times. We have that that standard results for projected gradient descent on strongly convex functions, with the choice of of step-size α = 1/L, we have that (see Theorem 2.4 of Hazan (2016))\ng∆(z(t))− g∆(z∗) ≤ e−tµ/(4L) (g∆(z(0))− g∆(z∗)) , (18)\nwhere µ is the strong convexity coefficient. Our next step is to translate this into a convergence rate for x(t).\nFirst, using the mean value theorem, we have that for any two scalars u, vm\nmin{eu, ev}|u− v| ≤ |eu − ev| ≤ max{eu, ev}|u− v|, (19)\nand we use this in the next sequence of equations:\n||x(t)− x∗∆||22 ≤ K2||z(t)− z∗∆||22 By Eq.((19)). ≤ K2 2µ (g∆(z(t))− g∆(z ∗))\n≤ K2 2µe −tµ/(4L) (g∆(z(0))− g∆(z∗)) By Eq.((18))\nNow any function h(y) convex over a convex region R with L-Lipschitz gradient over the same region satisfies (see proof of Lemma 1.2.3 in Nesterov (2004))\nh(y1) ≤ h(y2) +∇h(y2)T (y1 − y2) + L\n2 ||y1 − y2||22,\nfor any y1, y2 ∈ R. If y2 is further chosen to be a point satisfying ∇h(y2) = 0, then we have\nh(y1)− h(y2) ≤ L\n2 ||y1 − y2||22\nWe next apply this to the function g∆, which is convex with L-Lipschitz gradient over the region Ω. By Lemma 16, the minimizer z∗∆ lies in the interior of Ω, and consequently we have ∇g∆(z∗) = 0. Therefore,\n||x(t)− x∗∆||22 ≤ K2Lµ e −tµ/(4L)||z(0)− z∗∆||22\n≤ K2 κ2 L µ e −tµ/(4L)||x(0)− x∗∆||22 By Eq.(19)\nSince ||x(0)− x∗||22 ≤WK2 because |xi(0)| ≤ K, we have that it takes\n4L µ ln WK4L µκ2\niterations until ||x(t)−x∗∆||22 ≤ . Since the quantity L/µ scales polynomially in the number of workers W , this proves the second assertion of the theorem, namely that convergence to any -neighborhood of the limit x∗∆ occurs in polynomial time. This proves the second assertion of the theorem.\nWe now turn to the last assertion of the theorem, i.e., the bound on ||x∗∆ − s||2. For this part, start with the equation\n∇g∆(z∗∆) = 0,\nwhich we argued above will hold for small enough ∆, and observe that its consequence is that\n||∇g0(z∗∆)||2 = ∣∣∣∣∣∣ ∣∣∣∣∣∣[ W∑ j=1 Nij∆ij ]i ∣∣∣∣∣∣ ∣∣∣∣∣∣ 2 ≤ √ W ||N ||∞max i,j |∆ij |. (20)\nOur final step is to argue that this implies z∗∆ is close to ln s. Indeed, let us define φ(t) = ∇g0(ln s+ t(z∗∆ − ln s)). We thus have that\n∇g0(z∗∆) = φ(1)− φ(0)\n= ∫ 1 0 φ′(u)du\n= ∫ 1 0 ∇2g0(u)(z∗∆ − ln s) du\nso, multiplying both sides by z∗∆ −− ln s, we obtain\n(z∗∆ − ln s)T∇g0(z∗∆) ≥ µ||z∆ − ln s||22,\nwhere, as before, µ = κ2Nminλmin(Ls) is a lower bound on the smallest eigenvalue of ∇2g0(u) when u ∈ [lnκ, lnK]W . Now using Cauchy-Schwarz, this implies\n||∇g0(z∗∆)||2 ≥ µ||z∗∆ − ln s||.\nPutting this together with Eq. (20), we obtain\n||z∗∆ − ln s|| ≤ √ W ||N ||∞ µ max i,j |∆ij |.\nFinally,\n||x∗∆ − s||2 = ||ez ∗ ∆ − eln s||2\n≤ K||z∗∆ − ln s||2 ≤ K √ W ||N ||∞ µ max i,j |∆ij |.\nThis concludes the proof of the theorem."
  }],
  "year": 2020,
  "references": [{
    "title": "A cautionary note on the robustness of latent class models for estimating diagnostic error without a gold",
    "authors": ["P.S. Albert", "L.E. Dodd"],
    "venue": "standard. Biometrics,",
    "year": 2004
  }, {
    "title": "Consistency of weighted majority votes",
    "authors": ["D. Berend", "A. Kontorovich"],
    "venue": "In NIPS, pages 3446–3454,",
    "year": 2014
  }, {
    "title": "Crowdsourcing: Low complexity, minimax optimal algorithms",
    "authors": ["T. Bonald", "R. Combes"],
    "venue": "arXiv preprint arXiv",
    "year": 2016
  }, {
    "title": "Aggregating crowdsourced binary ratings",
    "authors": ["N. Dalvi", "A. Dasgupta", "R. Kumar", "V. Rastogi"],
    "venue": "In WWW,",
    "year": 2013
  }, {
    "title": "Maximum likelihood estimation of observer error-rates using the EM algorithm",
    "authors": ["A.P. Dawid", "A.M. Skene"],
    "venue": "Applied Statistics,",
    "year": 1979
  }, {
    "title": "ImageNet: A Large-Scale Hierarchical Image Database",
    "authors": ["J. Deng", "W. Dong", "R. Socher", "L.-J. Li", "K. Li", "L. Fei-Fei"],
    "venue": "In CVPR09,",
    "year": 2009
  }, {
    "title": "A characterization of the smallest eigenvalue of a graph",
    "authors": ["M. Desai", "V. Rao"],
    "venue": "Journal of Graph Theory,",
    "year": 1994
  }, {
    "title": "Pattern Classification, volume xx",
    "authors": ["R.O. Duda", "P.E. Hart", "D.G. Stork"],
    "year": 2001
  }, {
    "title": "Lower rank approximation of matrices by least squares with any choice of weights",
    "authors": ["K.R. Gabriel", "S. Zamir"],
    "year": 1979
  }, {
    "title": "Minimax optimal convergence rates for estimating ground truth from crowdsourced labels",
    "authors": ["C. Gao", "D. Zhou"],
    "venue": "arXiv preprint arXiv:1310.5764,",
    "year": 2013
  }, {
    "title": "Exact exponent in optimal rates for crowdsourcing",
    "authors": ["C. Gao", "Y. Lu", "D. Zhou"],
    "venue": "In ICML,",
    "year": 2016
  }, {
    "title": "Matrix completion has no spurious local minimum",
    "authors": ["R. Ge", "J. Lee", "T. Ma"],
    "venue": "Advances in Neural Information Processing Systems",
    "year": 2016
  }, {
    "title": "Who moderates the moderators? crowdsourcing abuse detection in user-generated content",
    "authors": ["A. Ghosh", "S. Kale", "P. McAfee"],
    "venue": "In Proc. of the 12th ACM conference on Electronic commerce,",
    "year": 2011
  }, {
    "title": "Low-rank matrix approximation with weights or missing data is NP-hard",
    "authors": ["N. Gillis", "F. Glineur"],
    "venue": "SIAM J. Matrix Analysis Applications,",
    "year": 2011
  }, {
    "title": "Unsupervised sequential sensor acquisition",
    "authors": ["M. Hanawal", "C. Szepesvári", "V. Saligrama"],
    "venue": "In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics,",
    "year": 2017
  }, {
    "title": "Estimating the error rates of diagnostic tests",
    "authors": ["S.L. Hui", "S. D Walter"],
    "year": 1980
  }, {
    "title": "Iterative learning for reliable crowdsourcing systems",
    "authors": ["D.R. Karger", "S. Oh", "D. Shah"],
    "venue": "In NIPS, pages 1953–1961,",
    "year": 2011
  }, {
    "title": "Efficient crowdsourcing for multi-class labeling",
    "authors": ["D.R. Karger", "S. Oh", "D. Shah"],
    "venue": "In SIGMETRICS,",
    "year": 2013
  }, {
    "title": "Budget-optimal task allocation for reliable crowdsourcing systems",
    "authors": ["D.R. Karger", "S. Oh", "D. Shah"],
    "venue": "Operations Research,",
    "year": 2014
  }, {
    "title": "Matrix factorization techniques for recommender systems",
    "authors": ["Y. Koren", "R. Bell", "C. Volinsky"],
    "year": 2009
  }, {
    "title": "Error rate bounds and iterative weighted majority voting for crowdsourcing",
    "authors": ["H. Li", "B. Yu"],
    "year": 2014
  }, {
    "title": "Variational inference for crowdsourcing",
    "authors": ["Q. Liu", "J. Peng", "A.T. Ihler"],
    "venue": "In NIPS,",
    "year": 2012
  }, {
    "title": "Introductory Lectures on Convex Optimization",
    "authors": ["Y. Nesterov"],
    "venue": "Kluwer Academic Publishers,",
    "year": 2004
  }, {
    "title": "The characterization of decisive weighted majority rules",
    "authors": ["S. Nitzan", "J. Paroush"],
    "venue": "Economics Letters,",
    "year": 1981
  }, {
    "title": "Learning from crowds",
    "authors": ["V.C. Raykar", "S. Yu", "L.H. Zhao", "G.H. Valadez", "C. Florin", "L. Bogoni", "L. Moy"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "Reliable distributed estimation with intermittent communications",
    "authors": ["V. Saligrama", "D.A. Castanon"],
    "venue": "In Proceedings of the 45th IEEE Conference on Decision and Control,",
    "year": 2006
  }, {
    "title": "Optimizing group judgmental accuracy in the presence of interdependencies",
    "authors": ["L. Shapley", "B. Grofman"],
    "venue": "Public Choice,",
    "year": 1984
  }, {
    "title": "Inferring ground truth from subjective labelling of venus images",
    "authors": ["P. Smyth", "U. Fayyad", "M. Burl", "P. Perona", "P. Baldi"],
    "venue": "In NIPS,",
    "year": 1995
  }, {
    "title": "Weighted low-rank approximations",
    "authors": ["N. Srebro", "T. Jaakkola"],
    "venue": "In Proceedings of the 20th International Conference on Machine Learning",
    "year": 2003
  }, {
    "title": "A statistical analysis of the aggregation of crowdsourced labels",
    "authors": ["D. Szepesvári"],
    "venue": "Master’s thesis, University of Waterloo,",
    "year": 2015
  }, {
    "title": "Max-margin majority voting for learning from crowds",
    "authors": ["T. Tian", "J. Zhu"],
    "venue": "In Advances in Neural Information Processing Systems",
    "year": 2015
  }, {
    "title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing",
    "authors": ["Y. Zhang", "X. Chen", "D. Zhou", "M.I. Jordan"],
    "venue": "In NIPS,",
    "year": 2014
  }, {
    "title": "Spectral methods meet EM: A provably optimal algorithm for crowdsourcing",
    "authors": ["Y. Zhang", "Xi Chen", "Dengyong Zhou", "Michael I. Jordan"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2016
  }, {
    "title": "Learning from the wisdom of crowds by minimax entropy",
    "authors": ["D. Zhou", "S. Basu", "Y. Mao", "J.C. Platt"],
    "venue": "In NIPS,",
    "year": 2012
  }],
  "id": "SP:768f913dfe2a1736b646b30d34184da9da80827f",
  "authors": [{
    "name": "Yao Ma",
    "affiliations": []
  }, {
    "name": "Alex Olshevsky",
    "affiliations": []
  }],
  "abstractText": "We consider worker skill estimation for the single-coin Dawid-Skene crowdsourcing model. In practice, skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills are identifiable if and only if the sampling matrix (observed components) does not have a bipartite connected component. We then propose a projected gradient descent scheme and show that skill estimates converge to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP-hard in general. Next, we derive sample complexity bounds in terms of spectral properties of the signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets.",
  "title": "Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers∗"
}