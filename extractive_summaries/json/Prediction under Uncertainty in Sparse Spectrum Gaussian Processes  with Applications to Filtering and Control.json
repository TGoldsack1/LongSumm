{
  "sections": [{
    "text": "Sparse Spectrum Gaussian Processes (SSGPs) are a powerful tool for scaling Gaussian processes (GPs) to large datasets. Existing SSGP algorithms for regression assume deterministic inputs, precluding their use in many real-world robotics and engineering applications where accounting for input uncertainty is crucial. We address this problem by proposing two analytic moment-based approaches with closed-form expressions for SSGP regression with uncertain inputs. Our methods are more general and scalable than their standard GP counterparts, and are naturally applicable to multi-step prediction or uncertainty propagation. We show that efficient algorithms for Bayesian filtering and stochastic model predictive control can use these methods, and we evaluate our algorithms with comparative analyses and both real-world and simulated experiments."
  }, {
    "heading": "1. Introduction",
    "text": "The problem of prediction under uncertainty, appears in many fields of science and engineering that involve sequential prediction including state estimation (Ko & Fox, 2009; Deisenroth et al., 2012), time series prediction (Girard et al., 2003), stochastic process approximation (Archambeau et al., 2007), and planning and control (Deisenroth et al., 2015; Pan et al., 2015). In these problems, uncertainty can be found in both the predictive models and the model’s inputs. Formally, we are often interested in finding the probability density of a prediction y, given a distribution p(x) and a probabilistic model p(y|x). By marginal-\n1Georgia Institute of Technology, Atlanta, Georgia, USA 2School of Aerospace Engineering 3School of Interactive Computing. Correspondence to: Yunpeng Pan <ypan37@gatech.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nization,\np(y) = ∫ p(y|x)p(x) dx. (1)\nUnfortunately, computing this integral exactly is often intractable. In this paper, we tackle a subfamily of (1) where: 1) the probabilistic model is learned from data and specified by a sparse spectrum representation of a Gaussian process (SSGP); and 2) the input x is normally distributed. We show that analytic expressions of the moments of p(y) can be derived and that these are directly applicable to sequential prediction problems like filtering and control."
  }, {
    "heading": "1.1. Related work",
    "text": "Gaussian Process (GP) regression with uncertain inputs has been addressed by Candela et al. (2003); Girard et al. (2003), and extended to the multivariate outputs by Kuss (2006). These methods have led to the development of many algorithms in reinforcement learning (Rasmussen & Kuss, 2004; Deisenroth et al., 2015), Bayesian filtering (Ko & Fox, 2009; Deisenroth et al., 2009), and smoothing (Deisenroth et al., 2012). However, these approaches have two major limitations: 1) they are not directly applicable to large datasets, due to the polynomial time complexity for exact inference (Williams & Rasmussen, 2006); and 2) analytic moment expressions, when used, are restricted to squared exponential (SE) kernels (Kuss, 2006) and cannot be generalized to other kernels in a straightforward way.\nA common method for approximating large-scale kernel machines is through random Fourier features (Rahimi & Recht, 2007). The key idea is to map the input to a lowdimensional feature space yielding fast linear methods. In the context of GP regression (GPR), this idea leads to the sparse spectrum GPR (SSGPR) algorithm (Lázaro-Gredilla et al., 2010). SSGP has been extended in a number of ways for, e.g. incremental model learning (Gijsberts & Metta, 2013), and large-scale GPR (Dai et al., 2014; Yan et al., 2015). However, to the best of our knowledge, prediction under uncertainty for SSGPs has not been explored. Although there are several alternative approximations to exact GP inference including approximating the posterior distribution using inducing points, e.g., (Snelson & Ghahramani, 2006; Titsias, 2009; Cheng & Boots, 2016), comparing different GP approximations is not the focus of this paper."
  }, {
    "heading": "1.2. Applications",
    "text": "We consider two key problems that are widely encountered in robotics and engineering: Bayesian filtering and stochastic model predictive control.\nThe goal of Bayesian filtering is to infer a hidden system state through the recursive application of Bayes’ rule. Well-known frameworks for Bayesian filtering include unscented Kalman Filtering (UKF), particle filtering (PF), extended Kalman filtering (EKF), and assumed density filtering (ADF). GP-based Bayesian filtering with SE kernels has been developed for these frameworks by (Ko & Fox, 2009; Deisenroth et al., 2009). We extend this work with highly efficient SSGP-based EKF and ADF algorithms.\nThe goal of stochastic model predictive control (MPC) is to find finite horizon optimal control at each time instant. Due to the high computational cost of GP inference and real-time optimization requirements in MPC, most GPbased control methods (Deisenroth et al., 2015; Pan & Theodorou, 2014; Kupcsik et al., 2014) are restricted to episodic reinforcement learning tasks. To cope with this challenge, we present an SSGP-based MPC algorithm that is fast enough to perform probabilistic trajectory optimization and model adaptation on-the-fly."
  }, {
    "heading": "1.3. Our contributions",
    "text": "• We propose two approaches to prediction under un-\ncertainty in SSGPs with closed-form expressions for the predictive distribution. Compared to previous GP counterparts, our methods: 1) are more scalable, and 2) can be generalized to any continuous shift-invariant kernels with a Fourier feature representation.\n• We demonstrate successful applications of the proposed approaches by presenting scalable algorithms for 1) recursive Bayesian filtering and 2) stochastic model predictive control via probabilistic trajectory optimization.\nThe rest of the paper is organized as follows. In §2, we give an introduction to SSGPs, which serves as our probabilistic model. Derivation and expressions of the two proposed prediction methods are detailed in §3. Applications to filtering and control, and experimental results are presented in §4 and §5 respectively. Finally §6 concludes the paper."
  }, {
    "heading": "2. Sparse Spectral Representation of GPs",
    "text": "Consider the task of learning the function f : Rd → R, given IID data D = {xi, yi}ni=1, with each pair related by\ny = f(x) + , ∼ N (0, σ2n), (2)\nwhere is IID additive Gaussian noise. Gaussian process regression (GPR) is a principled way of performing Bayesian inference in function space, assuming that function f has a prior distribution f ∼ GP(m, k), with mean\nfunction m : Rd → R and kernel k : Rd × Rd → R. Without loss of generality, we assume m(x) = 0. Exact GPR is challenging for large datasets due to its O(n3) time andO(n2) space complexity (Williams & Rasmussen, 2006), which is a direct consequence of having to store and invert an n× n Gram matrix.\nRandom features can be used to form an unbiased approximation of continuous shift-invariant kernel functions, and are proposed as a general mechanism to accelerate largescale kernel machines (Rahimi & Recht, 2007), via explicitly mapping inputs to low-dimensional feature space. Based on Bochner’s theorem, the Fourier transform of a continuous shift-invariant positive definite kernel k(x, x′) is a proper probability distribution p(ω), assuming k(x, x′) is properly scaled (Rahimi & Recht, 2007):\nk(x, x′) = ∫ p(ω)ejω T (x−x′) dω\n= E(φω(x)φω(x ′)∗), ω ∼ p(ω),\n(3)\nwhere φω(x) = ejω T x, and we can see that k(x, x′) only depends on the lag vector separating x and x′: x−x′. Equation (3) leads to an unbiased finite sample approximation of k: k(x, x′) ≈ 1m ∑ φωi(x)φωi(x\n′)∗, where random frequencies {ωi}mi=1 are drawn IID from p(ω). Utilizing the fact that φω can be replaced by sinusoidal functions since both p(ω) and k(x, x′) are reals, and concatenating features {φωi}mi=1 into a succinct vector form, an approximation for k(x, x′) is expressed as\nk(x, x′) ≈ φ(x)Tφ(x′), φ(x) = [ φc(x) φs(x) ] , (4)\nφci (x) = σk cos(ω T i x), φ s i (x) = σk sin(ω T i x), ωi ∼ p(ω),\nwhere σk is a scaling coefficient. For the commonly used Squared Exponential (SE) kernel: k(x, x′) = σ2f exp(− 12‖x − x ′‖2Λ−1), p(ω) = N (0,Λ −1) and σk = σf√ m\n, where the coefficient σf and the diagonal matrix Λ are the hyperparameters, examples of kernels and corresponding spectral densities can be found in Table 1.\nIn accordance with this feature map (4), Sparse Spectrum GPs are defined as follows\nDefinition 1. Sparse Spectrum GPs (SSGPs) are GPs with kernels defined on the finite-dimensional and randomized feature map φ (4):\nk(x, x′) = φ(x)Tφ(x′) + σ2nδ(x− x′), (5)\nwhere the function δ is the Kronecker delta function.\nThe second term in (5) accounts for the additive zero mean Gaussian noise in (2), if the goal is to learn the correlation between x and y directly as in our case of learning the probabilistic model p(y|x), instead of learning the latent function f .\nBecause of the explicit finite-dimensional feature map (4), each SSGP is equivalent to a Gaussian distribution over the weights of features w ∈ R2m. Assuming that prior distribution of weights w is N (0, I) 1 and the feature map is fixed, after conditioning on the data D = {xi, yi}ni=1, the posterior distribution of w is 2\nw ∼ N (α, σ2nA−1), (6) α = A−1ΦY, A = ΦΦT + σ2nI,\nwhich can be derived through Bayesian linear regression. In (6), the column vector Y and the matrix Φ are specified by the data D: Y = [ y1 . . . yn ]T , Φ =[\nφ(x1) . . . φ(xn) ] . Consequently, the posterior distribution over the output y in (2) at a test point x is exactly Gaussian, in which the posterior variance explicitly captures the model uncertainty in prediction with input x:\np(y|x) = N (αTφ(x), σ2n + σ2n‖φ(x)‖2A−1). (7)\nThis Bayesian linear regression method for SSGP is proposed in Lázaro-Gredilla et al. (2010). Its time complexity is O(nm2 +m3), which is significantly more efficient than standard GPR’s O(n3) when m n.\nRemark It’s worth noting that the methods proposed in this paper are not tied to specific algorithms for SSGP regression such as Bayesian linear regression (LázaroGredilla et al., 2010), but able to account for any SSGP with specified feature weights distribution (6), where posterior α and A can be computed by any means. Variations on A include sparse approximations by a low rank plus diagonal matrix, or iterative solutions by optimization methods like doubly stochastic gradient descent (Dai et al., 2014)."
  }, {
    "heading": "3. Prediction under Uncertainty",
    "text": "Two methods for prediction under uncertainty are presented under two conditions: 1) the uncertain input is normally distributed: x ∼ N (µ,Σ), and 2) probabilistic models are in the form of (7) specified by SSGPs. Despite these conditions, evaluating the integral in (1) is still intractable. In this work, we approximate the true predictive distribution p(y) by a Gaussian distribution with moments that are analytically computed through: 1) exact moment matching, and 2) linearization of posterior mean function. Closed-form expressions for predictive mean, variance, covariance, and input-prediction cross-covariance are derived. We consider multivariate outputs by utilizing con-\n1I is the identity matrix with proper size. The prior covariance is identity since E (f(x)f(x)) = E ( φ(x)TwwTφ(x′) ) = φ(x)T E(wwT )φ(x′), and E (f(x)f(x′)) = φ(x)Tφ(x′) (see §2.2 in Rasmussen & Kuss (2004) for details.)\n2Conditioning on data D is omitted, e.g., in w|D, for simplicity in notation.\nditionally independent scalar models for each output dimension, i.e., assuming for outputs in different dimension ya and yb, p(ya, yb|x) = p(ya|x)p(yb|x). Discussions on this assumption can be found in Appendix §6.1. For notational simplicity, we suppress the dependency of φ(x) on x, and treat y as a scalar by default."
  }, {
    "heading": "3.1. Exact moment matching (SSGP-EMM)",
    "text": "We derive the closed-form expressions for exact moments: 1) the predictive mean E y, 2) the predictive variance Var y and covariance Cov(ya, yb), which in the multivariate case correspond to the diagonal and off-diagonal entries of the predictive covariance matrix, and 3) the cross-covariance between input and prediction Cov(x, y).\nUsing the expressions for SSGP (4), (7), and the law of total expectation, the predictive mean becomes\nE y = EE(y|x) = E ( αTφ ) = αT E\n[ φc\nφs\n] , (8)\nEφci = σk E cos(ω T i x), Eφ s i = σk E sin(ω T i x),\nwhere i = 1, . . . ,m, and in the nested expectation EE(y|x), the outer expectation is over the input distribution p(x) = N (µ,Σ), and the inner expectation is over the conditional distribution p(y|x) (7).\nBy observing (8), we see that the expectation of sinusoids under the Gaussian distribution is the key to computing the predictive mean. Thus, we state the following proposition: Proposition 1. The expectation of sinusoids over multivariate Gaussian distributions: x ∼ N (µ,Σ), x ∈ Rd, i.e., p(x) = (2π)− d 2 (det Σ)−\n1 2 exp(− 12‖x − µ‖ 2 Σ−1), can\nbe computed analytically:\nE cos(ωTx) = exp(−1 2 ‖ω‖2Σ) cos(ωTµ), E sin(ωTx) = exp(−1 2 ‖ω‖2Σ) sin(ωTµ).\nTo prove it, we invoke Euler’s formula to transform the lefthand-side to complex domain, apply identities involving quadratic exponentials, and then convert back to real numbers (see Appendix §3.2 for details). In Proposition 1, the expectations depend on the mean and variance of the input Gaussian distribution. Intuitively, after passing a Gaussian distributed input through a sinusoidal function, the expectation of the output is equal to passing the mean of the input through the sinusoid, and then scaling it by a constant exp(− 12‖ω‖ 2 Σ), which depends on the variance of the input. Expectations are smaller with larger input variance due to the periodicity of sinusoids.\nThe exact moments are then derived using Proposition 1. By the law of total variance, the predictive variance is\nVar y = EVar(y|x) + VarE(y|x) = σ2n + σ 2 nTr ( A−1Ψ ) + αTΨα− (E y)2, (9)\nwhere Ψ is defined as the expectation of the outer product of feature vectors over input distribution p(x). Specifically, we compute Ψ by applying the product-to-sum trigonometric identities:\nE ( φφT ) = Ψ =\n[ Ψcc Ψcs\nΨsc Ψss\n] ,\nΨccij = σ2k 2\n( E ( cos(ωi + ωj) Tx ) + E ( cos(ωi − ωj)Tx )) ,\nΨssij = σ2k 2\n( E ( cos(ωi − ωj)Tx ) −E ( cos(ωi + ωj) Tx )) ,\nΨcsij = σ2k 2\n( E ( sin(ωi + ωj) Tx ) −E ( sin(ωi − ωj)Tx )) ,\nwhere Ψcc,Ψss,Ψcs are m × m matrices, and i, j = 1, . . . ,m, on whose terms Proposition 1 can be directly applied.\nNext, we derive the covariance for different output dimensions for multivariate prediction. These correspond to the off-diagonal entries of the predictive covariance matrix. We show that, despite the conditional independence assumption for different outputs given a deterministic input, outputs become coupled with uncertain inputs. Using the law of total covariance, the covariance is\nCov(ya, yb) = Cov (E(ya|x),E(yb|x)) = E (E(ya|x),E(yb|x))−(E ya)(E yb) = αTaΨabαb − (αTa Eφa)(αTb Eφb), (10)\nwhere matrix Ψab is the expectation of the outer product of feature vectors corresponding to different feature maps φa, φb for outputs ya, yb, computed similarly as in (3.1) with corresponding random frequencies {ωi}, and the scaling coefficient σk (4). Vectors αa and αb are the corresponding weight vectors for ya and yb (7). Compared to the expression for the variance of a single output in (9), the term E (Cov(ya|x)Cov(yb|x)) that is included in the law of total covariance is neglected due to the assumption of conditional independence of different outputs (§2), so (10) does not have the corresponding first two terms in (9).\nFinally, we compute the cross-covariance between input and each output dimension. Invoking the law of total covariance:\nCov(x, y) = Cov(x,E(y|x)) = E (xE(y|x))− (Ex)(E y) = Υα− (E y)µ,\n(11)\nwhere matrix Υ is the expectation of the outer product of the input x and the feature vector φ(x) over input distribution x ∼ N (µ,Σ): E(xφT ) = Υ = [ Υc1 . . . Υ c m Υ s 1 . . . Υ s m ] ,\nΥci = σk E ( cos(ωTi x)x ) , Υsi = σk E ( cos(ωTi x)x ) ,\nwhere r = √ 2ν‖x−x′‖2\n` , Kν is a modified Bessel function,\nand h = 2 dπ\nd 2 Γ(ν+ d2 )(2ν) ν\nΓ(ν)`2ν .\nwhere i = 1, . . . ,m. We state the following proposition to compute each column in Υ consisting of expectations of the product sinusoidal functions and inputs.\nProposition 2. The expectation of the multiplication of sinusoids and linear functions over multivariate Gaussian distributions: x ∼ N (µ,Σ), can be computed analytically:\nE ( cos(ωTx)x ) = ( E cos(ωTx) ) µ− (E(sin(ωTx))Σω,\nE ( sin(ωTx)x ) = ( E sin(ωTx) ) µ+ ( E cos(ωTx) ) Σω,\nwhere the right-hand-side expectations have analytical expressions (Proposition 1). To prove it, we find an expression for E ( aTx cos(ωTx) ) , for any a, through the complex domain trick used to prove Proposition 1. Next, the result is extended to E ( x cos(ωTx) ) , by setting a to consist of indicator vectors (see Appendix §3.3 for details). Applying Proposition 1 and 2, we complete the derivation of Cov(x, y) in (11).\nRemark In summary, SSGP-EMM computes the exact posterior moments. This is equivalent to expectation propagation (Minka, 2001) by minimizing the Kullback-Leibler divergence between the true distribution and its Gaussian approximation with respect to the natural parameters. SSGP-EMM’s computation complexity is O ( m2k2d2 ) , where m is the number of features, k is the output dimension, and d is the input dimension. The most computationally demanding part is constructing matrices Ψab (10) for each output pair, where each requires O ( m2d2 ) .\nCompared to the multivariate moment-matching approach for GPs (GP-EMM) (Girard et al., 2003; Kuss, 2006) with O ( n2k2d2 ) time complexity, SSGP-EMM is more efficient when m n. Moreover, our approach is applicable to any positive-definite continuous shift-invariant kernel with different spectral densities (see examples in Table 1), while previous approaches like GP-EMM (Kuss, 2006) are only derived for squared exponential (SE) or polynomial kernels. Next we introduce a more computationally efficient but less accurate approach that avoids the computation of Ψab’s."
  }, {
    "heading": "3.2. Linearization (SSGP-Lin)",
    "text": "An alternative approach to computing the exact moments of the predictive distribution is based on the linearization of the posterior mean function in (7) at the input mean µ:\nm(x) = αTφ(x) ≈ m(µ) + αT Dφ(µ)︸ ︷︷ ︸ M (x− µ), (12)\nwhere Dφ(µ) denotes taking the derivative of function φ at µ. Given the definition of φ in (4), Dφ can be found by chain rule: Dφci (x) = −σk sin(ωTi x)ωTi , Dφsi (x) = σk cos(ω T i x)ω T i .\nUtilizing the linearized posterior mean function (12), the predictive moments can be approximated. The predictive mean approximation is\nE y = EE(y|x) ≈ m(µ), (13)\nand the predictive variance approximation is Var y = EVar(y|x) + VarE(y|x)\n≈ Var(y|µ) + Var(αTMx) = σ2n + σ 2 n‖φ(µ)‖2A−1 + α TMΣMTα.\n(14)\nand the approximate covariance between output dimension a and b is Cov(ya, yb) = Cov (E(ya|x),E(yb|x))\n= E ( αTaMa(x− µ)(x− µ)TMTb αb ) ≈ αTaMaΣMTb αb, (15)\nwhere Ma and Mb are defined as M in (12), except that they correspond to feature maps φa and φb. Notice that the assumption of conditional independence between different outputs is invoked here again, cf., (10).\nFinally, the cross-covariance between the input and output can be approximated as\nCov(x, y) = Cov(x,E(y|x)) ≈ E ( (x− µ)(αTM(x− µ)) ) = αTMΣ\n(16)\nUnlike SSGP-EMM, which computes exact moments (§3.1), this linearization-based approach SSGP-Lin computes an approximation of the predictive moments. In contrast to SSGP-EMM’s O ( m2k2d ) computational complexity, the computation time of SSGP-Lin is reduced to O ( m2kd ) , as a direct consequence of avoiding the construction of Ψ (3.1) in SSGP-EMM (10), which makes SSGP-Lin more efficient than SSGP-EMM, especially when the output dimension is high.\nBoth SSGP-EMM and SSGP-Lin are applicable to a general family of kernels. See Table 2 for a comparison between our methods and GP-EMM (Girard et al., 2003; Kuss, 2006). In the next section, we compare these approaches in applications of filtering and control."
  }, {
    "heading": "4. Applications",
    "text": "We focus on the application of the proposed methods to Bayesian filtering and predictive control. We begin by introducing Gauss-Markov models, which can be expressed by the following discrete-time nonlinear dynamical system:\nxt+1 = f(xt, ut) + x t ,\nx t ∼ N (0,Σ x), (17)\nyt = g(xt) + y t ,\ny t ∼ N (0,Σ y ), (18)\nwhere xt ∈ Rd is state, ut ∈ Rr is control, yt ∈ Rk is observation or measurement, xt ∈ Rd is IID process noise, yt ∈ Rk is IID measurement noise, and subscript t denotes discrete time index. We call the probabilistic models (17) and (18) the dynamics and observation models, and the corresponding deterministic functions f and g the dynamics and observation functions.\nWe consider scenarios where f and g are unknown but a dataset D = ( {(xt, ut), xt+1}n−1t=1 , {xt, yt}nt=1 ) is provided. The probabilistic models specified by SSGPs can be learned from the dataset, and then used to model the dynamics and observation (17) (18). More concretely, the dynamics model p(xt+1|xt, ut) is learned using state transition pairs {(xt, ut), xt+1}n−1t=1 , and the observation model p(yt|xt) is learned separately from state-observation pairs {xt, yt}nt=1."
  }, {
    "heading": "4.1. Bayesian filtering",
    "text": "The task of Bayesian filtering is to infer the posterior distribution of the current state of a dynamical system based on the current and past noisy observations, i.e., finding p(xt|t), where the notation xt|s denotes the random variable xt|y0, . . . , ys. Due to the Markov property of the process x, i.e., xt|x0, . . . , xt−1 = xt|xt−1, in Gauss-Markov models, p(xt|t) can be computed recursively through alternating prediction step and correction step.\n4.1.1. PREDICTION STEP (xt−1|t−1 → xt|t−1) In the prediction step, xt−1|t−1 is propagated through the dynamics model p(xt|xt−1, ut−1):\np(xt|t−1) = ∫ p(xt|xt−1, ut−1)p(xt−1|t−1) dxt−1,\nwhich can be viewed as prediction under uncertainty (1). Suppose that p(xt−1|t−1) = N (µ̂t−1|t−1, Σ̂t−1|t−1), with learned SSGP representation for the dynamics, Gaussian approximations of the output: p(xt|t−1) ≈ N (µ̂t|t−1, Σ̂t|t−1) can be obtained by either SSGP-EMM\n(§3.1) using (8), (9) and (10), or SSGP-Lin (§3.2) using (13), (14) and (15).\n4.1.2. CORRECTION STEP (xt|t−1 → xt|t) The correction step conditions xt|t−1 on the current observation yt using Bayes’ rule:\np(xt|t) = p(yt|xt|t−1)p(xt|t−1)∫ p(yt|xt|t−1)p(xt|t−1) dxt . (19)\nIn the preceding prediction step, we obtain p(xt|t−1) ≈ N (µ̂t|t−1, Σ̂t−1|t−1), which serves as a prior on xt in this correction step. Due to the intractability of the integral in the denominator, to apply Bayes’ rule we first seek Gaussian approximations for the joint distribution, as in the previous work on Bayesian filtering relying on GPs (Deisenroth et al., 2009; Ko & Fox, 2009):[\nxt|t−1 yt|t−1\n] ∼ N ([ µ̂t|t−1 µ̂y ] , [ Σ̂t|t−1 Σ̂xy Σ̂Txy Σ̂y ]) , (20)\nInvoking p(yt|t−1) = ∫ p(yt|xt|t−1)p(xt|t−1) dxt, the moments µ̂y , Σ̂y , and Σ̂xy in the joint Gaussian approximation can be computed as the predictive mean, predictive covariance, and input-prediction cross-covariance, for the observation model p(yt|xt) with input p(xt|t−1), using SSGPEMM or SSGP-Lin. Having all terms in (20) determined, we condition xt|t−1 exactly on current observation yt:\nµ̂t|t = µ̂t|t−1 + Σ̂xyΣ̂ −1 y (y − µ̂y), Σ̂t|t = Σ̂t|t−1 − Σ̂xyΣ̂−1y Σ̂xy. (21)\nThis Gaussian approximation p(xt|t) ≈ N (µ̂t|t, Σ̂t|t) is then used as input to the prediction step. Thus, we have shown that starting from p(x0) = N (µ0,Σ0), by consecutively applying prediction and correction steps presented above, we recursively obtain state estimates for xt|t−1 and xt|t. Rather than using a finite sample-based approximation such as in the GP-UKF (Ko & Fox, 2009), the Gaussian approximations of the full densities p(xt|t) and p(xt|t−1) are propagated.\nAlgorithm 1 SSGP-ADF and SSGP-EKF 1: Model learning: collect dataset D, and learn SSGP dy-\nnamics and observations models (§2.) 2: Initialization: set prior p(x0). 3: for t = 1, . . . do 4: Prediction: compute µ̂t|t−1 and Σ̂t|t−1 . by either SSGP-EMM (§3.1) or SSGP-Lin (§3.2). 5: Measurement: make an observation yt. 6: Correction: compute µ̂t|t and Σ̂t|t according to (21) by either SSGP-EMM (§3.1) or SSGP-Lin (§3.2). 7: end for\nWe summarize the resulting filtering algorithm SSGPADF (assumed density filtering) and SSGP-EKF (extended Kalman filtering), based on SSGP-EMM and SSGP-Lin, respectively, in Algorithm 1. These are analogs of GP-ADF (Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009)."
  }, {
    "heading": "4.2. Stochastic Model Predictive Control",
    "text": "The stochastic model predictive control (MPC) problem is to choose a control sequence that minimizes the expected cost, provided p(xt):\nu?t+1:t+T = argmin ut+1:t+T\nE ( h(xt+T ) + i+T∑ i l(xt+i, ut+i) ) ,\nat each time step, subject to stochastic system dynamics (17), where function h : Rd → R and l : Rd ×Rr → R are the final and running cost respectively. There are two main challenges to applying MPC in practice: 1) MPC requires an accurate dynamics model for multi-step prediction, and 2) online optimization is very computationally expensive. For clarity in presentation, we will assume that the state is fully observable henceforth.\nAlgorithm 2 MPC via probabilistic trajectory optimization (1-3: offline optimization, 4-8: online optimization)\n1: Model learning: collect dataset D, and learn SSGP dynamics model (§2). 2: Initialization: set t = 0, and estimate p(x0). 3: Trajectory optimization: perform trajectory optimiza-\ntion in belief space, obtain u?t+1:t+T . 4: repeat 5: Policy execution: apply one-step control u?t+1 to the system and move one step forward, update t = t+1. 6: Model adaptation: incorporate new data and update SSGP dynamics model. 7: Trajectory optimization: perform re-optimization\nwith the updated model. Initialize with the previously optimized trajectory and obtain new u?t+1:t+T .\n8: until Task terminated"
  }, {
    "heading": "4.2.1. MPC VIA PROBABILISTIC TRAJECTORY OPTIMIZATION",
    "text": "We address the aforementioned challenges by employing a combination of prediction under uncertainty and trajectory optimization. More precisely, we use SSGP-EMM or SSGP-Lin to efficiently obtain approximate Gaussian distribution over trajectory of states and perform trajectory optimization in the resultant Gaussian belief space based on differential dynamic programming (DDP) (Abbeel et al., 2007; Tassa et al., 2007). Note that DDP-related methods require computation of first and second order derivatives of the dynamics and cost. Our analytic moment expressions provide a robust and efficient way to compute these derivatives. Details are omitted due to space limit, but they can be found in Appendix §4.\nWithin the SSGP framework, we may incrementally update the posterior distribution over the feature weights w (6) given a new sample without storing or inverting the matrix A explicitly, Instead we keep track of its upper triangular Cholesky factor A = RTR (Gijsberts & Metta, 2013). Given a new sample, a rank-1 update is applied to\nthe Cholesky factor R, which requires O(m2) time. To cope with time-varying systems and to make the method more adaptive, we employ a forgetting factor λ ∈ (0, 1), such that the impact of the previous samples decays exponentially in time (Ljung, 1998).\nOur proposed MPC algorithm, summarized in Algorithm 2, is related to several algorithms and differs in both model and controller learning. First, SSGPs are more robust to modeling error than Locally Weighted Projection Regression (LWPR) used in iLQG-LD (Mitrovic et al., 2010). See a numerical comparison in (Gijsberts & Metta, 2013). Second, we efficiently propagate uncertainty in multi-step prediction which is crucial in MPC. In contrast, AGP-iLQR (Boedecker et al., 2014) drops the input uncertainty and uses subset of regressors (SoR-GP) which lacks a principled way to select reference points. In addition, PDDP (Pan & Theodorou, 2014) uses GPs which are computationally expensive for online optimization. Two deep neural networks are used for modeling in (Yamaguchi & Atkeson, 2016), which make it difficult to perform online incremental learning, as we do here."
  }, {
    "heading": "5. Experimental Results",
    "text": ""
  }, {
    "heading": "5.1. Bayesian filtering",
    "text": ""
  }, {
    "heading": "5.1.1. 1D ONE-STEP FILTERING",
    "text": "We consider a synthetic dynamical system with groundtruth dynamics f(x) = 12x+ 25x 1+x2 and observation g(x) = 6 sin(2x) with Σ x = 1.52 and Σ y = 1 in (17,18), in a similar setting to Deisenroth et al. (2009). We compare the performance of four filters, SSGP-ADF, SSGP-EKF, GPADF (Deisenroth et al., 2009) and GP-EKF (Ko & Fox, 2009). All models are trained using 800 samples. However, for SSGP models, only 10 random Fourier features of a SE kernel are used. Figure 1 illustrates the comparison of filtered state distribution of a typical realization. We evaluate the methods by computing NLx (the negative log-likelihood of the ground truth samples in the filtered distribution) and RMSE (root-mean-square error between filtered mean and ground truth samples). See Table 3 for a detailed comparison. Our methods SSGP-ADF and SSGPEKF are able to offer close performance with their full GP counterparts but with greatly reduced computational cost. See Appendix §6.2 for further discussions on the comparison between SSGP-ADF and SSGP-EKF."
  }, {
    "heading": "5.1.2. RECURSIVE FILTERING",
    "text": "We next consider a state estimation task in high-speed autonomous driving on a dirt track (Figure 2a). The goal is to recursively estimate the state of an autonomous rallycar given noisy measurements. The vehicle state consists of linear velocities (x and y), heading rate, and roll angle, in body frame. Controls are steering and throttle. Measurements are collected by wheel speed sensors. This filtering task is challenging because of the complex nonlinear dynamics and the amount of noise in the measurements. We do not use any prior model of the car, but learn the model from ground truth estimates of vehicle state generated by integrating GPS and IMU data via iSAM2 (Kaess et al., 2012). 50,000 samples are collected from wheel speed sensors and ground truth state estimates from iSAM2 for training. Because of the sample size, it is too computationally expensive to use GP-based filter such as GP-ADF (Deisenroth et al., 2009). Instead, we use SSGP-ADF to perform 1,200 recursive filtering steps which correspond to 30 seconds of high-speed driving. Filtered distributions using 80 features are shown in Figure 2b, and Figure 2c shows the mean and twice the standard deviation of NLx over six 30 seconds driving with different number of features. Surprisingly, only need a small number of features is necessary for satisfactory results."
  }, {
    "heading": "5.2. Model Predictive Control",
    "text": ""
  }, {
    "heading": "5.2.1. TRACKING A MOVING TARGET",
    "text": "We consider the Puma-560 robotic arm and quadrotor systems with dynamics model specified by SSGPs. For both tasks the goal is to track a moving target. In addition, the true system dynamics vary online, which necessitates both online optimization and model update, as we do here. See Appendix §5.2 for detailed task descriptions. Results in terms of cost l(xt, ut) are shown in Figure 4. Figure 4a shows that our methods outperform iLQG-LD (Mitrovic et al., 2010) and AGP-iLQR (Boedecker et al., 2014). The similarities and differences between these methods have been discussed in §4.2. Figure 4b shows that model update is necessary and more features could improve performance."
  }, {
    "heading": "5.2.2. AUTONOMOUS DRIFTING",
    "text": "We study the control of an autonomous car during extreme operating conditions (powerslide). The task is to stabilize the vehicle to a specified steady-state using purely longitudinal control during high-speed cornering. This problem has been studied in Velenis et al. (2010) where the authors developed a LQR control scheme based on a physics-based dynamics model. We apply our MPC algorithm to this task without any prior model knowledge and 2,500 data points generated by the model in Velenis et al. (2010). SSGP-Lin is used for multi-step prediction. Results and comparison to Velenis et al. (2010) are illustrated in Figure 3.\n0 100 200 300 400 500\n0 100 200 300 400 500\n0 100 200 300 400 500"
  }, {
    "heading": "6. Discussion and Conclusion",
    "text": "We introduced two analytic moment-based approaches to prediction under uncertainty in sparse spectrum Gaussian processes (SSGPs). Compared to their full GP counterparts, our methods are more general: they are applicable to any continuous shift-invariant kernel. They also scale to larger datasets by leveraging random features with frequencies sampled from the spectral density of a given kernel (see Table 1, 2). Although we adopt the name SSGP, our proposed methods are not tied to specific model learning methods such as linear Bayesian regression (LázaroGredilla et al., 2010). They can be applied to any SSGP with a specified feature weight distribution (6), and α and A can be computed via different approaches. For example, A can be iteratively computed by methods like doubly stochastic gradient descent (Dai et al., 2014). We studied the application of the proposed methods to Bayesian filtering and model predictive control. Our methods directly address the challenging aspects of these problems: model uncertainty and real-time execution constraints. We evaluated our algorithms on real-world and simulated examples and showed that SSGP-EMM (§3.1) and SSGP-Lin (§3.2) are accurate alternatives to their full GP counterparts when learning from large amounts of data."
  }, {
    "heading": "Acknowledgements",
    "text": "This work was supported by NSF NRI awards 1637758 and 1426945."
  }],
  "year": 2017,
  "references": [{
    "title": "An application of reinforcement learning to aerobatic helicopter",
    "authors": ["P. Abbeel", "A. Coates", "M. Quigley", "A.Y. Ng"],
    "venue": "flight. NIPS,",
    "year": 2007
  }, {
    "title": "Gaussian process approximations of stochastic differential equations",
    "authors": ["Archambeau", "Cedric", "Cornford", "Dan", "Opper", "Manfred", "Shawe-Taylor", "John"],
    "venue": "Gaussian Processes in Practice,",
    "year": 2007
  }, {
    "title": "Approximate real-time optimal control based on sparse Gaussian process models",
    "authors": ["J. Boedecker", "Springenberg", "JT", "J. Wulfing", "M. Riedmiller"],
    "venue": "ADPRL",
    "year": 2014
  }, {
    "title": "Propagation of uncertainty in Bayesian kernel modelsapplication to multiple-step ahead forecasting",
    "authors": ["Candela", "J. Quinonero", "A. Girard", "J. Larsen", "C.E. Rasmussen"],
    "venue": "In IEEE International Conference on Acoustics, Speech, and Signal Processing. IEEE,",
    "year": 2003
  }, {
    "title": "Incremental variational sparse Gaussian process regression",
    "authors": ["Cheng", "Ching-An", "Boots", "Byron"],
    "venue": "In Proceedings of Advances in Neural Information Processing Systems",
    "year": 2016
  }, {
    "title": "Scalable kernel methods via doubly stochastic gradients",
    "authors": ["Dai", "Bo", "Xie", "He", "Niao", "Liang", "Yingyu", "Raj", "Anant", "Balcan", "Maria-Florina F", "Song", "Le"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Gaussian processes for data-efficient learning in robotics and control",
    "authors": ["M. Deisenroth", "D. Fox", "C. Rasmussen"],
    "venue": "IEEE Transsactions on Pattern Analysis and Machine Intelligence,",
    "year": 2015
  }, {
    "title": "Analytic moment-based Gaussian process filtering",
    "authors": ["Deisenroth", "Marc Peter", "Huber", "Marco F", "Hanebeck", "Uwe D"],
    "venue": "In Proceedings of the 26th annual international conference on machine learning,",
    "year": 2009
  }, {
    "title": "Robust filtering and smoothing with Gaussian processes",
    "authors": ["Deisenroth", "Marc Peter", "Turner", "Ryan Darby", "Huber", "Marco F", "Hanebeck", "Uwe D", "Rasmussen", "Carl Edward"],
    "venue": "IEEE Transactions on Automatic Control,",
    "year": 2012
  }, {
    "title": "Real-time model learning using incremental sparse spectrum Gaussian process regression",
    "authors": ["A. Gijsberts", "G. Metta"],
    "venue": "Neural Networks,",
    "year": 2013
  }, {
    "title": "Gaussian process priors with uncertain inputs application to multiple-step ahead time series forecasting",
    "authors": ["A. Girard", "C.E. Rasmussen", "J. Quinonero-Candela", "R. MurraySmith"],
    "venue": "In NIPS,",
    "year": 2003
  }, {
    "title": "isam2: Incremental smoothing and mapping using the bayes tree",
    "authors": ["Kaess", "Michael", "Johannsson", "Hordur", "Roberts", "Richard", "Ila", "Viorela", "Leonard", "John J", "Dellaert", "Frank"],
    "venue": "The International Journal of Robotics Research,",
    "year": 2012
  }, {
    "title": "Gp-bayesfilters: Bayesian filtering using gaussian process prediction and observation models",
    "authors": ["J. Ko", "D. Fox"],
    "venue": "Autonomous Robots,",
    "year": 2009
  }, {
    "title": "Model-based contextual policy search for data-efficient generalization of robot skills",
    "authors": ["A. Kupcsik", "M.P. Deisenroth", "J. Peters", "AP Loh", "P. Vadakkepat", "G. Neumann"],
    "venue": "Artificial Intelligence,",
    "year": 2014
  }, {
    "title": "Gaussian process models for robust regression, classification, and reinforcement learning",
    "authors": ["Kuss", "Malte"],
    "venue": "PhD thesis, Technische Universität,",
    "year": 2006
  }, {
    "title": "Sparse spectrum Gaussian process regression",
    "authors": ["M. Lázaro-Gredilla", "J. Quiñonero-Candela", "C.E. Rasmussen", "A.R. Figueiras-Vidal"],
    "venue": "The Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "A family of algorithms for approximate Bayesian inference",
    "authors": ["Minka", "Thomas P"],
    "venue": "PhD thesis, Massachusetts Institute of Technology,",
    "year": 2001
  }, {
    "title": "Adaptive optimal feedback control with learned internal dynamics models",
    "authors": ["D. Mitrovic", "S. Klanke", "S. Vijayakumar"],
    "venue": "In From Motor Learning to Interaction Learning in Robots,",
    "year": 2010
  }, {
    "title": "Probabilistic differential dynamic programming",
    "authors": ["Y. Pan", "E. Theodorou"],
    "venue": "In Advances in Neural Information Processing Systems (NIPS), pp. 1907–1915,",
    "year": 2014
  }, {
    "title": "Sample efficient path integral control under uncertainty",
    "authors": ["Pan", "Yunpeng", "Theodorou", "Evangelos", "Kontitsis", "Michail"],
    "venue": "In Advances in Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Random features for large-scale kernel machines",
    "authors": ["A. Rahimi", "B. Recht"],
    "venue": "In Advances in neural information processing systems,",
    "year": 2007
  }, {
    "title": "Gaussian processes in reinforcement learning",
    "authors": ["C. Rasmussen", "M. Kuss"],
    "venue": "In NIPS,",
    "year": 2004
  }, {
    "title": "Sparse Gaussian processes using pseudo-inputs",
    "authors": ["E. Snelson", "Z. Ghahramani"],
    "venue": "NIPS, 18:1257,",
    "year": 2006
  }, {
    "title": "Receding horizon differential dynamic programming",
    "authors": ["Y. Tassa", "T. Erez", "W.D. Smart"],
    "venue": "In NIPS,",
    "year": 2007
  }, {
    "title": "Variational learning of inducing variables in sparse gaussian processes",
    "authors": ["Titsias", "Michalis K"],
    "venue": "In AISTATS,",
    "year": 2009
  }, {
    "title": "Steady-state cornering equilibria and stabilisation for a vehicle during extreme operating conditions",
    "authors": ["E. Velenis", "E. Frazzoli", "P. Tsiotras"],
    "venue": "International Journal of Vehicle Autonomous Systems,",
    "year": 2010
  }, {
    "title": "Gaussian processes for machine learning",
    "authors": ["Williams", "C.K.I", "C.E. Rasmussen"],
    "year": 2006
  }, {
    "title": "Neural networks and differential dynamic programming for reinforcement learning problems",
    "authors": ["Yamaguchi", "Akihiko", "Atkeson", "Christopher G"],
    "venue": "In 2016 IEEE International Conference on Robotics and Automation (ICRA),",
    "year": 2016
  }, {
    "title": "Large-scale Gaussian process regression via doubly stochastic gradient descent",
    "authors": ["Yan", "Xinyan", "Xie", "Bo", "Song", "Le", "Boots", "Byron"],
    "venue": "The ICML Workshop on Large-Scale Kernel Learning,",
    "year": 2015
  }],
  "id": "SP:86524b83d7e9e13a51c9ce909a749b8be06a7cd9",
  "authors": [{
    "name": "Yunpeng Pan",
    "affiliations": []
  }, {
    "name": "Xinyan Yan",
    "affiliations": []
  }, {
    "name": "Evangelos A. Theodorou",
    "affiliations": []
  }, {
    "name": "Byron Boots",
    "affiliations": []
  }],
  "abstractText": "Sparse Spectrum Gaussian Processes (SSGPs) are a powerful tool for scaling Gaussian processes (GPs) to large datasets. Existing SSGP algorithms for regression assume deterministic inputs, precluding their use in many real-world robotics and engineering applications where accounting for input uncertainty is crucial. We address this problem by proposing two analytic moment-based approaches with closed-form expressions for SSGP regression with uncertain inputs. Our methods are more general and scalable than their standard GP counterparts, and are naturally applicable to multi-step prediction or uncertainty propagation. We show that efficient algorithms for Bayesian filtering and stochastic model predictive control can use these methods, and we evaluate our algorithms with comparative analyses and both real-world and simulated experiments.",
  "title": "Prediction under Uncertainty in Sparse Spectrum Gaussian Processes  with Applications to Filtering and Control"
}