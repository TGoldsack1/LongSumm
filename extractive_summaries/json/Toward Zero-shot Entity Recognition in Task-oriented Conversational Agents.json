{
  "sections": [{
    "text": "Proceedings of the SIGDIAL 2018 Conference, pages 317–326, Melbourne, Australia, 12-14 July 2018. c©2018 Association for Computational Linguistics\n317"
  }, {
    "heading": "1 Introduction",
    "text": "In this paper we focus on user utterance understanding, where a conversational system has to interpret the content of a user dialogue turn. At this step, most of conversational systems try to capture both the intent of the utterance and the relevant entities and relations that are mentioned. As an example, given a user query like: Can I find a Canada Goose parka blue for -30?, an online shop assistant should be able to recognize that the intent of the utterance is ‘Search’ and that the following entities are mentioned: Product Category = parka; Brand = Canada Goose; Color = blue; Min temperature = -30. We are particularly interested in application domains, like e-commerce, which show specific characteristics: large variety of entity names for the same category (e.g. a black and white t-shirt, black pants, white vintage shoes\nare all names of clothes); compositionality of entity names (e.g. black pants, black short pants); utterances with multiple occurrences of the same entity category (e.g. “I would like to order a salami pizza and two mozzarella cheese sandwiches” contains two occurrences of food); strong requirements of multilinguality (e.g. scarpe bianche vintage and white vintage shoes). Finally, we are interested in domains where available repositories can only cover a portion of the possible entity names that a user can express in an interaction.\nOur working hypothesis is that, in such scenarios, current entity recognition approaches based on supervision (i.e. we call them pattern-based as they need utterances annotated with entities in the context they occur), need a huge amount of supervision to manage the variety of entity names, which would make those approaches ineffective in most practical situations. Thus, we propose an entity recognition method, we call it gazetteerbased, which takes advantage of available entity names for a certain category to train a neural model that is then applied to label new unseen entities in a user utterance. This method shares several features with recent proposals in zero-shot learning (Xie et al., 2016), as we do not assume any annotated utterances at training time, and we make use of entity names as “side information”.\nWe run several experiments on three ecommerce domains (furniture, food, clothing) and two languages (English and Italian), with different characteristics in terms of entity names, and show that: (i) the gazetteer-based approach significantly outperforms the pattern-based approach in our domains and languages; (ii) the method captures linguistic properties of the entity names related to their compositionality, which are reliable indicators of the complexity of the task.\nThe paper is structured as follows. Section 2 introduces the entity recognition task we are\naddressing. Section 3 provides background and relevant related work. Section 4 describes the gazetteer-based methodology that we adopt for entity recognition in user utterances. Finally, section 5 and 6 describe, respectively, the experimental setting and the obtained results."
  }, {
    "heading": "2 Entity Recognition for E-commerce",
    "text": "Common conversational systems adopt a slot filling approach as semantic representation of the utterance content. Usually, it is assumed that the utterance contains just one entity for each slot. In addition, typical entities corresponds to named entities (e.g. locations) or to almost closed classes (e.g. time, dates, quantities, currencies). Although this is substantially true for several popular task oriented scenarios, like flight booking (a well known dataset is ATIS – Air Travel Information Services), point of interest navigation, and calendar scheduling (for instance the dataset used in (Eric and Manning, 2017)), other conversational scenarios show different characteristics. In this section we focus on conversational agents for the e-commerce scenario, and highlight the characteristics which we believe are relevant for entity recognition.\nTask-oriented dialogue. E-commerce chat-bots are supposed to carry on a task-oriented dialogue whose goal is helping the user to select products presented in an online shop, and, ultimately, buy them. For the purposes of this paper we restrict our attention to written chat-style dialogues (i.e. voice is not considered).\nEntity names. The main focus of the interaction is on products (i.e. users search, compare, assess information on products they are interested in). Products can be referred to in several ways, including their descriptions (e.g. a round table with a marble top), proper names (e.g. Adidas Gazelle), or with a mix of them (e.g. a white Billy shelf ). Depending on the complexity of the domain, a single online shop may manage from thousands to several hundreds of thousand of different products, with hundreds of variants (e.g. size and colour for clothes). Throughout this paper, we refer to such product descriptions as entity names. As we will see, there is a high variance in the way online vendors assign and manage such names. For the purposes of this paper, it is relevant to notice that taking advantage of e-commerce website catalogs, it\nis relatively easy to download repositories of entity names for a large variety of products, and for several languages. On the other hand, a structured description of such entities - in term of slot-value pairs - is often missing. We call these repositories of entity names gazetteers.\nConversational patterns. Conversational patterns in e-commerce dialogues are relatively simple. High level user intents vary from searching for one or more products, asking to compare characteristics of products, and finalizing the purchase. Although there are just a few datasets available to support our intuition (e.g. the Frames dataset presented in (El Asri et al., 2017)), we may assume that the context in which product names appear is quite limited. Compared to other scenarios (e.g. booking hotels and flights), it is quite frequent that user mention more than one product in the same utterance (e.g. ”Please deliver at home a salami pizza, a pepperoni pizza with onions and two mozzarella cheese sandwiches”).\nMultilinguality. E-commerce is becoming more and more multilingual. The market is worldwide and vendors offer navigation in several languages. For our purposes a strong requirement is that approaches for entity recognition must be easily portable through languages."
  }, {
    "heading": "3 Background and Related Work",
    "text": "In this section we report useful context for the gazetteer based approach that will be described in Section 4. We focus on entity recognition, zeroshot learning and generation of synthetic data."
  }, {
    "heading": "3.1 Entity Recognition",
    "text": "Entity recognition has been largely approached as a sequence labeling task (see, for instance, the Conll shared tasks on named entities recognition (Tjong Kim Sang and De Meulder, 2003)). Given an utterance U = {t1, t2, ..., tn} and a set of entity categories C = {c1, c2, ..., cm}, the task is to label the tokens in U that refer to entities belonging to the categories in C. As an example, using the IOB format (Inside, Outside, Beginning) (Ramshaw and Marcus, 1995), the utterance ”I would like to order a salami pizza and two mozzarella cheese sandwiches”, would be labeled as shown in Table 1.\nWe refer to the Automatic Content Extraction program - ACE (Doddington et al., 2004), where\ntwo main entity classes are distinguished: named entities and nominal entities. We focus on the latter, as this is more relevant for utterance understanding in the e-commerce scenario. Nominal entities are noun phrase expressions describing an entity. They can be composed by a single name (e.g. pasta, carpet, parka) or by more than one token (e.g. capri sofa bed beige, red jeans skinny fit, lightweigh full frame camera, grilled pork belly tacos). Nominal entities are typically compositional, as they do allow morphological and syntactic variations (e.g. for food names, spanish baked salmon, roasted salmon and hot smoked salmon), which makes it possible to combine tokens of one entity name with tokens of another entity name to generate new names (e.g. for food names, salmon tacos is a potential food name given the existence of salmon and tacos). In addition to adjectival and prepositional modifiers, conjunctions are also very frequent (e.g. beef and bean burritos, black and white t-shirt). Compositionality is crucial in our approach, as we take advantage of it to syntethically generate negative training examples for a certain entity category, as detailed in Section 4.1."
  }, {
    "heading": "3.2 Zero-shot Learning",
    "text": "In conversational agents there is a general lack of data, both annotated and unannotated, as real conversations are still not widely available for different domains and languages. To overcome this limit, in our gazetteer-based approach we take advantage of the fact that it is relatively easy to obtain repositories of entity names for several categories (e.g. food names, locations, movie titles, names of products, etc.). We use such repositories as “side information” in zero-shot learning to recognize entity names for a certain class, even if no annotated utterances are available for that class. While similar approaches have been already proposed to improve portability across domains (e.g. (Bapna et al., 2017) uses slot names as side information), in this paper we take advantage of the zero-shot approach focusing on large repositories of compositional entity names.\nSeveral approaches have been proposed to implement zero-shot learning, including those that use multiple embeddings (Norouzi et al., 2013),\nthose that extract features that generalize through different domains (Socher et al., 2013), and those that recast zero-shot learning as a domain adaptation problem (Elhoseiny et al., 2013)."
  }, {
    "heading": "3.3 Synthetic Data Generation",
    "text": "Partly due to the need of large amounts of training data to feed neural networks, recently there has been a diffused interest on methods for automatically generate synthetic data (see (Jaderberg et al., 2014)). The effectiveness of synthetic data generation has been shown in several domains, including the generation of textual descriptions of visual scenes (Hoag, 2008), and of parallel corpora for Machine Translation (Abdul-Rauf et al., 2016). Alternative approaches to data generation for conversational agents are based on simulated conversations (Shah et al., 2018). As for the e-commerce domain, because of the dramatic scarcity of available datasets, we were forced to use synthetic generation in two cases: negative training examples for entity names, used to train our gazetteer-based approach, and lexicalization of utterances, used for testing the performance of our approach.\n4 NNg Entity Recognition\nIn our zero-shot learning assumption we propose a neural gazetteer-based approach, which includes two main components: a neural classifier (NNg) trained solely on the entity names in a gazetteer, described in Section 4.1, and the entity tagger that applies the neural classifier to a user utterance, described in Section 4.2.\n4.1 NNg Classifier\nThe NNg classifier is the core of the gazetteerbased approach. It is implemented using a multilayer bidirectional LSTM (Schuster and Paliwal, 1997) that classifies an input sequence of tokens either as entity or non-entity for a certain entity category, with a certain degree of confidence. We base our NNg classifier on the system proposed in (Lample et al., 2016), which was modified to match the peculiarities of the gazetteer-based approach: (i) we extend it as a 3-layer biLSTM with 120 units per layer and a single dropout layer\n(dropout probability of 0.5) between the third biLSTM and the output layer. This topology (see Figure 1) has been empirically defined using the train and dev portions of the synthetic gazetteers described in section 5.2. (ii) The output layer is a softmax layer – instead of a CRF layer – because the goal of NNg is to classify the whole sequence and not to tag each single token using the IOB format. The softmax layer provides the probability of a sequence being positive or negative for a certain category, based on the output from the previous layers. We use this probability as a confidence score for a sequence being positive or negative.\nThis multilayer biLSTM is meant to build an internal representation of the core compositional structure of the entity names that are listed in the gazetteer, and to generalize such structure to recognize new entity names of the same category.\nSynthetic Training Data. In order to train the NNg classifier, we need not only positive examples (i.e. entity name), but also negative ones, i.e. sub-sequences of an utterance where no entities are present or where only parts of the entity name are present. To obtain such negative examples we used the following methodology based on synthetic generation. For each entity name i in a gazetteer G, negative counterparts can be obtained either using a sub-sequence of i (making sure it is not present in the gazetteer), or by taking i and adding tokens at the beginning or end of it (or both), following the pattern t1 + i + t2, where t1 is the ending token of a random entity in G and t2 is the starting token of a random entity in G. Between these tokens and i there can be\nseparators, as a white space, a comma or the and conjunction, so to mimic how multiple entities are usually expressed in sentences. Alternatively, t1 and t2 can be tokens randomly extracted from a generic corpus, so as to mimic cases when the entity is expressed in isolation. For example, if the initial positive example is black and white t-shirt, the possible negative sub-sequences that are generate are: | black | white | black and | and white | black and white |. The sub-sequences | white tshirt | t-shirt | are not considered because they are already included in the gazetteer as positive examples. Adding tokens, using the pattern t1 + i + t2, we obtain other potential negative examples: | buy black and white t-shirt | black and white tshirt and sweater | buy black and white t-shirt and sweater |, and so on. According to this procedure, we generate more negative examples than positive. In order to avoid an unbalanced dataset, we randomly select two negative examples per positive one: a sub-sequence and an example surrounded by other words, resulting in a 1:2 proportion.\nClassifier Features. The NNg classifier combines several features: two different word embeddings (i.e. generic and specific), a char-based embedding, and seven handcrafted features. The generic word embedding is employed to capture generic language use, and it is similar to the one used in (Lample et al., 2016). For English it was trained using the English Gigaword version 5, while for Italian it was trained using a dump of the Italian Wikipedia. We use an embedding dimension of 64 for both English and Italian, a minimum word frequency cutoff of 4, and a window size of 8. The second word embedding is employed to capture language use that is specific for each domain, and it is extracted using the training gazetteer as corpus, with a dimension of 30, a minimum word frequency cutoff of 1, and a window size of 2. Finally, the char-based embedding with a dimension of 50 is still based on (Lample et al., 2016) and it is trained on the domain gazetteers. Its function is to deal with out of vocabulary terms and possible misspellings.\nHandcrafted features are meant to explicitly represent the core structure of a typical entity name. We consider seven features of an entity name: (i) the actual position of the token within an entity name; (ii) the length of the entity name under inspection; (iii) the frequency of the token in the gazetteer; (iv) the average length of the entity\nname containing a certain token; (v) the average position of the token in the entity name it appears in; (vi) the bigram probability with reference to the previous token in the entity name; (vii) the list of all the possible PoS associated to the token.\n4.2 NNg Tagger\nThe neural classifier described in the previous section is applied to all the sub-sequences of a certain utterance (see algorithm 1), in order to select candidates entity names for a certain category. After classification the algorithm takes a further step to select the actual entities, by ranking the candidates according to the confidence score provided by the classifier, and by selecting the top not overlapping candidates. As an example, the utterance “I’m looking for golden yellow shorts and dark blue shirt” contains six sub-sequences that are classified as positive by the NNg classifier (lines [1-5]): | shorts | yellow shorts | golden yellow shorts | shirt | blue shirt | dark blue shirt |, while all other sub-sequences, such as: | I’m looking | looking for a golden | shorts and dark | dark blue |, are classified as negative. Then, positive examples are ranked according to their confidence score (lines [6]): | golden yellow shorts | yellow shorts | dark blue shirt | etc. Finally, golden yellow shorts is selected while yellow shorts is discarded because the latter overlaps with the former. Likewise dark blue shirt is selected since it is not overlapping with other already selected sub-sequences while all remaining ones are discarded (lines [7-11]).\nAlgorithm 1 NNg Tagger 1: for sub-sequence in utterance do 2: if sub-sequence is an entity then 3: add sub-sequence to entity-list 4: else 5: discard sub-sequence 6: order entity-list by confidence-score 7: for element in entity-list do 8: if element not overlap previous elements\nthen 9: tag element as entity\n10: else 11: discard element"
  }, {
    "heading": "5 Experimental Setting",
    "text": "In this section we first introduce two alternative approaches for entity recognition that we used as\nAlgorithm 2 Rule-based entity recognition 1: G : tokens in Gazetteer - excluding stopwords. 2: morpho : morphological variations of token. 3: POS : possible PoS tags for the token. 4: bigram : All bi-grams in Gazetteer. 5:\n6: for token in utterance do 7: if token is in an NP chunk then 8: if IN GAZETTEER(token) then 9: tag token as entity\n10: else 11: if any(morpho[word] in G) then 12: if any(PoS[word] is noun) then 13: tag token as entity 14: for tokeni in utterance do 15: if bigram(tokeni, tokeni+1) exits then 16: tag tokeni and tokeni+1 as entity 17: Format tags to IOB notation\ncomparison with NNg, and then the datasets that are used for our experiments."
  }, {
    "heading": "5.1 Entity Recognition Algorithms",
    "text": "We have compared the NNg approach described in Section 4 with two alternative entity recognition approaches: an unsupervised rule-based algorithm, which takes advantage of both the entity gazetteer and of linguistic information about chunking, and a supervised algorithm that needs annotated sentences as training.\nRule-based entity recognition. This approach is based on (Eftimov et al., 2017), a system that uses a terminological-driven and rule-based named entity recognizer, taking advantage of both entity dictionaries and rules based on chunks. The core strategy is that a chunk in a text is recognized as belonging to a category C if any of its tokens are present in the gazetteer for category C. The approach in (Eftimov et al., 2017) is tailored to a single domain/language and involves merging successive chunks into a single one based on the rules imposed by the algorithm. We extended the approach by adding morphological features and the possible PoS of a word, for which we used TextPro (Pianta et al., 2008), (see Algorithm 2).\nWe assume that the dictionary+chunk algorithm is particularly suitable for compositional entities. In fact, actual entities in a text can still be recognized even if the perfect match is not present in the original dictionary. For example, the tar-\nget entity white t-shirt with long sleeves can be correctly identified as long as there are entities in the gazetteer that contain the tokens of interest, such as black and white t-shirt and red t-shirt with long sleeves.\nNeural pattern-based entity recognition (NNp). We used the bidirectional LSTM architecture introduced by (Lample et al., 2016) for named entity recognition. Given an input embedding for a token in the utterance, the outputs from the forward and backward LSTM are concatenated to yield the context vector for the token, which is then used by a CRF layer to classify it to the output type (O, I-, B-). There are 100 LSTM units and a dropout of 0.5 is applied to the BiLSTM layer. To train the NNp model, we used pre-trained embeddings on Wikipedia corpora. This helps the model to adapt itself to unseen words in the test data, provided they have an embedding.\nAs expected, the proposed NNp model is highly efficient to identify the context in which an entity occurs in the utterance. However, it is also prone to make errors in the sequence of the tags (i.e. tagging a token to be I- without a preceding B- tag). This is because, when trained with limited data, the entities in the training data do not cover all possible tags for a token, and also not all the possible entities (Lample’s model was trained on more than ten thousand sentences per language, but in our scenario the training data is limited to few hundred sentences). For this reason, and to highlight the model’s capability to identify the context of an entity, at test time the outputs of the model are post-processed to comply with the IOB notation; e.g. tag sequences such as O, I-, B-, I- are modified to O, B-, I-, I-."
  }, {
    "heading": "5.2 Datasets",
    "text": "We experimented entity recognition in three ecommerce domains and two languages for a total of six configurations. The three domains are respectively: food, clothing and furniture. Languages are Italian and English. In order to run our experiments the following datasets were used.\nEntity gazetteers (positive examples for NNg). We collected a gazetteer of nominal entities for each domain-language pair. To allow for consistent comparisons across languages and domains we scraped just one website per domain and extracted the English/Italian gazetteers versions. In Table 2 we describe each gazetteer, reporting its\nsize in terms of number of entity names, the average length of the names (in number of tokens), plus the length variability of such names (standard deviation, SD). We also report additional metrics that try to grasp the complexity of entity name in the gazetteer: (i) the normalized type-token ratio (TTR), as a rough measure of how much lexical diversity there is for the nominal entities in a gazetteer, see (Richards, 1987); (ii) the ratio of type1 tokens, i.e. tokens that can appear in the first position of an entity name but also in other positions, and type2 tokens, i.e. tokens appearing at the end and elsewhere; (iii) the ratio of entities that contain another entity as sub-part of their name. With these measures we are able to partially quantify how difficult it is to recognize the length of an entity, how difficult is to individuate the boundaries of an entity (ratio of type1 and type2 tokens), how much compositionality there is starting from basic entities (i.e. how many new entities can be potentially constructed by adding new tokens). Note that type1 and type2 ratios can cover cases in common with sub-entity ratio, but they model different phenomena: given white tshirt, the entity name black and white skirt represents a case of type1 token for white but without sub-entity matching, while white t-shirt with long sleeves represents a sub-entity matching without making white a type1 token.\nSynthetic Gazetteers (positive + negative examples for NNg) (SG). To train NNg, we apply the methodology described in Section 4.1 to obtain synthetic negative data. After splitting each gazetteer using a 64:16:20 ratio (train:dev:test), we created the aforementioned data sets, where – for each entity i (positive example) present in the train-dev splits – we added two negative examples obtained by randomly selecting one of the methodologies described in Section 4.1. The optimal number of negative examples was obtained during the training phase by varying their ratio.\nSynthetic Utterances (training for NNp, test data for all approaches) (SU). To test our approaches we used synthetic sentences produced by lexicalizing templates, following the idea presented in (Cheri and Bhattacharyya, 2017; He et al., 2017). These recent approaches show the feasibility of using synthetic sentences both for training and test. More generally, there’s a growing interest in using synthetic data for conversational agents, e.g. the bAbI datasets - meant to de-\nvelop learning algorithms for text understanding and reasoning - were all constructed in a synthetic way (Weston et al., 2015).\nWe created 237 templates for English and the same amount for Italian. These templates were manually designed in order to be domain independent (e.g. using terminology that can be applied to any domain), and correspond to typical intents that can be found in the e-commerce scenario (e.g. buy, add to list, rate item, etc.) and were evenly distributed in order to contain 1 to 3 entity names. A few examples are given in Table 3.\nWe split the templates in a 64:16:20 ratio (train:dev:test) before lexicalization: to lexicalize SUtrain we randomly choose entities that were in the train split of the gazetteers, while for SUtest we randomly choose entities than were in the test split of the gazetteers. It should be noted that we used this procedure to better isolate the effect of entity name and their compositional nature over learning approaches, in fact: (i) we controlled for the impact of patterns on learning by using the same patterns across data sets train and test splits. (ii) we made the task more challenging than in standard situations, since no entity present in the training can be present in the test sets as well. In this way we can assess the ability of the approaches to learn the structure of entity names and generalize it to\nnew examples. So, for example, a simple baseline that uses exact match over the train gazetteers to identify entities in the test sentences would report a F1 of 0.\nFinally, according to our zero-shot assumption, the NNg is trained using solely SG, while its performances are computed using SUtest."
  }, {
    "heading": "6 Experiments and Results",
    "text": "We run two different sets of experiments to explore the impact of compositionality on the task of entity recognition. The first set was meant to find the optimal feature configuration for NNg, and the second one was the comparison of the three main approaches over the six SU datasets.\n1. Experiments with NNg on SG. We run a set of experiments to assess the best feature configuration for the gazetteer-based approach. In Table 4 we report the overall results of NNg using different feature configurations, over the six SG data sets. The topological configuration of NNg is kept constant, as described in Section 4. As can be seen, the configuration using all features is the best one (F1 89.95), and also the one with the lowest standard deviation (4.05). This means not only that this configuration provides the best results on average but also the most consistent ones across all data sets. Interestingly, the configuration that uses no external linguistic knowledge (Gazetteer-info)\nis the second best, indicating that even in the worst case, in which no linguistic resource is available, we can still expect to obtain competitive results.\n2. Experiments and Comparison on SU. Table 5 reports the comparison among the rule-based baseline, the NNp baseline, and the NNg approach. NNg is the best approach on all domains and languages. This confirms our initial hypothesis that the structure of entity names induced by gazetteers is fundamental when having little knowledge of the context in which entities occur within utterances (i.e. having few training examples).\nIt should be noted that the effect of entity name complexity (reported in Table 2) emerges clearly from the experiments: all the approaches tend to be affected by it. In both languages we have the following order in term of performances food < furniture < clothing. While for food results are evident (the highest length-SD, TTR, type1 and type2 token ratios and high sub-entity ratio affect the performances even if the gazetteers are big) for furniture and clothing we need to look closer at the metrics in Table 2. Neglecting the possible effects of gazetteer size, we see that clothing tends to have higher ratio of type1 or type2 tokens: this is due to the large use of modifiers, such as colour, typical of the domain (depending on language the modifier is attached before or after the head white t-shirt vs maglietta bianca). Still, being the other token type almost 0, either the beginning or the end of an entity name is unambiguous, and in case of adjacent entities in a sentence this is enough to recognize the boundaries between the two.\nThe NNg version that uses only gazetteer features (i.e. no linguistic knowledge is assumed), even if not reported in Table 5, showed to perform more poorly than the version using all features. Still, it is competitive against NNp, outperforming it in five SU data sets out of six, and providing an average F1 improvement of 10 points.\nFinally, in Table 6 we report the results of an additional analysis, where we computed the F1 scores according to the number of entities present\nin the test sentences (all domain and languages). As can be seen, NNg is the least sensitive to the number of entities present in the test sentences (i.e. NNg is the most consistent in term of performance under all circumstances). This can be explained by the fact that NNg, being focused on recognizing entities rather than patterns, is less sensitive to cases of contiguous occurrences of entities that can be wrongly segmented by other approaches."
  }, {
    "heading": "7 Conclusions and Future Work",
    "text": "We have provided experimental evidence that zero-shot entity recognition based on gazetteers is highly performing. To our knowledge, this is the first time that a neural model has been applied to capture compositionality of entity names. Due to the scarcity of annotated utterances, the proposed approach is particularly recommendable for its portability through different domains and languages. Our experiments have been tested on synthetic data (i.e. utterances semi-automatically generated starting from a set of conversational patterns) in the context of e-commerce chat-bots, taking advantage of some of the characteristics of the scenario. As for the future, we intend to test the approach on natural utterances (i.e. not synthetically generated)."
  }, {
    "heading": "Acknowledgements",
    "text": "This work has been partially supported by the AdeptMind scholarship, and by the CBF EIT Digital project. The authors thank the anonymous reviewers and Hendrik Buschmeier for their help and suggestions."
  }],
  "year": 2018,
  "references": [{
    "title": "Empirical use of information retrieval to build synthetic data for SMT domain adaptation",
    "authors": ["Sadaf Abdul-Rauf", "Holger Schwenk", "Patrik Lambert", "Mohammad Nawaz."],
    "venue": "IEEE/ACM Trans. Audio, Speech & Language Processing 24(4):745–754.",
    "year": 2016
  }, {
    "title": "Towards zero shot frame semantic parsing for domain scaling",
    "authors": ["Ankur Bapna", "Gokhan Tur", "Dilek Hakkani-Tur", "Larry Heck."],
    "venue": "Interspeech 2017.",
    "year": 2017
  }, {
    "title": "Towards harnessing memory networks for coreference resolution",
    "authors": ["Joe Cheri", "Pushpak Bhattacharyya."],
    "venue": "Proceedings of the 2nd Workshop on Representation Learning for NLP. pages 37–42.",
    "year": 2017
  }, {
    "title": "The automatic content extraction (ace) program - tasks, data, and evaluation",
    "authors": ["George Doddington", "Alexis Mitchell", "Mark Przybocki", "Lance Ramshaw", "Stephanie Strassel", "Ralph Weischedel."],
    "venue": "Proceedings of the Fourth International Con-",
    "year": 2004
  }, {
    "title": "A rule-based named-entity recognition method for knowledge extraction of evidence-based dietary recommendations",
    "authors": ["Tome Eftimov", "Barbara Koroušić Seljak", "Peter Korošec."],
    "venue": "PLoS ONE 12(6):e0179488.",
    "year": 2017
  }, {
    "title": "Frames: a corpus for adding memory to goal-oriented dialogue systems",
    "authors": ["Layla El Asri", "Hannes Schulz", "Shikhar Sharma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman."],
    "venue": "Proceedings of the 18th Annual SIG-",
    "year": 2017
  }, {
    "title": "Write a classifier: Zero-shot learning using purely textual descriptions",
    "authors": ["Mohamed Elhoseiny", "Babak Saleh", "Ahmed Elgammal."],
    "venue": "Computer Vision (ICCV), 2013 IEEE International Conference on. IEEE, pages 2584–2591.",
    "year": 2013
  }, {
    "title": "Key-value retrieval networks for taskoriented dialogue",
    "authors": ["Mihail Eric", "Christopher D. Manning."],
    "venue": "CoRR abs/1705.05414. http://arxiv.org/abs/1705.05414.",
    "year": 2017
  }, {
    "title": "Generating natural answers by incorporating copying and retrieving mechanisms in sequence-tosequence learning",
    "authors": ["Shizhu He", "Cao Liu", "Kang Liu", "Jun Zhao."],
    "venue": "Proceedings of the 55th Annual Meeting of the Association for Computational",
    "year": 2017
  }, {
    "title": "Synthetic Data Generation: Theory, Techniques and Applications",
    "authors": ["Joseph E. Hoag."],
    "venue": "Ph.D. thesis, Fayetteville, AR, USA. AAI3317844.",
    "year": 2008
  }, {
    "title": "Synthetic data and artificial neural networks for natural scene text recognition",
    "authors": ["Max Jaderberg", "Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman."],
    "venue": "CoRR abs/1406.2227. http://arxiv.org/abs/1406.2227.",
    "year": 2014
  }, {
    "title": "Neural architectures for named entity recognition",
    "authors": ["Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer."],
    "venue": "CoRR abs/1603.01360. http://arxiv.org/abs/1603.01360.",
    "year": 2016
  }, {
    "title": "Zero-shot learning by convex combination of semantic embeddings",
    "authors": ["Mohammad Norouzi", "Tomas Mikolov", "Samy Bengio", "Yoram Singer", "Jonathon Shlens", "Andrea Frome", "Greg Corrado", "Jeffrey Dean."],
    "venue": "CoRR abs/1312.5650.",
    "year": 2013
  }, {
    "title": "The textpro tool suite",
    "authors": ["Emanuele Pianta", "Christian Girardi", "Roberto Zanoli."],
    "venue": "Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08). Marrakech, Morocco. Http://www.lrec-",
    "year": 2008
  }, {
    "title": "Text chunking using transformation-based learning",
    "authors": ["Lance A. Ramshaw", "Mitchell P. Marcus."],
    "venue": "CoRR cmp-lg/9505040. http://arxiv.org/abs/cmplg/9505040.",
    "year": 1995
  }, {
    "title": "Type/token ratios: What do they really tell us",
    "authors": ["Brian Richards"],
    "venue": "Journal of child language",
    "year": 1987
  }, {
    "title": "Bidirectional recurrent neural networks",
    "authors": ["M. Schuster", "K.K. Paliwal."],
    "venue": "Trans. Sig. Proc. 45(11):2673–2681. https://doi.org/10.1109/78.650093.",
    "year": 1997
  }, {
    "title": "Building a conversational agent overnight with dialogue self-play",
    "authors": ["Pararth Shah", "Dilek Hakkani-Tür", "Gökhan Tür", "Abhinav Rastogi", "Ankur Bapna", "Neha Nayak", "Larry P. Heck."],
    "venue": "CoRR abs/1801.04871.",
    "year": 2018
  }, {
    "title": "Zero-shot learning through cross-modal transfer",
    "authors": ["Richard Socher", "Milind Ganjoo", "Christopher D Manning", "Andrew Ng."],
    "venue": "Advances in Neural Information Processing Systems 26, Curran Associates, Inc., pages 935–",
    "year": 2013
  }, {
    "title": "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
    "authors": ["Erik F Tjong Kim Sang", "Fien De Meulder."],
    "venue": "Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4.",
    "year": 2003
  }, {
    "title": "Towards ai-complete question answering: A set of prerequisite toy tasks",
    "authors": ["Jason Weston", "Antoine Bordes", "Sumit Chopra", "Alexander M Rush", "Bart van Merriënboer", "Armand Joulin", "Tomas Mikolov."],
    "venue": "arXiv preprint arXiv:1502.05698 .",
    "year": 2015
  }, {
    "title": "Active zero-shot learning",
    "authors": ["Sihong Xie", "Shaoxiong Wang", "Philip S. Yu."],
    "venue": "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management. ACM, New York, NY, USA, CIKM ’16, pages 1889–1892.",
    "year": 2016
  }],
  "id": "SP:50a7d7d6b2ae35733bb94596880753e70407e8a9",
  "authors": [{
    "name": "Marco Guerini",
    "affiliations": []
  }, {
    "name": "Simone Magnolini",
    "affiliations": []
  }, {
    "name": "Vevake Balaraman",
    "affiliations": []
  }, {
    "name": "Bernardo Magnini",
    "affiliations": []
  }],
  "abstractText": "We present a domain portable zero-shot learning approach for entity recognition in task-oriented conversational agents, which does not assume any annotated sentences at training time. Rather, we derive a neural model of the entity names based only on available gazetteers, and then apply the model to recognize new entities in the context of user utterances. In order to evaluate our working hypothesis we focus on nominal entities that are largely used in ecommerce to name products. Through a set of experiments in two languages (English and Italian) and three different domains (furniture, food, clothing), we show that the neural gazetteer-based approach outperforms several competitive baselines, with minimal requirements of linguistic",
  "title": "Toward Zero-shot Entity Recognition in Task-oriented Conversational Agents"
}