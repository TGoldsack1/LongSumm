{
  "sections": [{
    "heading": "1. Introduction",
    "text": "We consider the problem of designing sample-efficient algorithms to understand properties of distributions over large discrete domains. Such statistical tests have been traditionally studied in statistics because of their importance in virtually every scientific endeavor that involves data. Recent work in the theoretical computer science community has investigated the setting where the discrete domains are large and no a priori assumptions can be made about the underlying data distribution (for example, when it cannot be assumed that the distribution is normal, Gaussian, or even smooth). In the last few years, optimal methods with sublinear sample complexity have been obtained for testing a range of properties, including whether a distribution is uniform, identical to a known distribution (testing “goodness-of-fit”),\n*Equal contribution 1CSAIL, MIT, Cambridge, MA 02139, USA 2Department of Computer Science, USC, Los Angeles, CA 90089, USA 3TAU, Tel Aviv-Yafo, Israel. Correspondence to: Maryam Aliakbarpour <maryama@mit.edu>, Ilias Diakonikolas <diakonik@usc.edu>, Ronitt Rubinfeld <ronitt@csail.mit.edu>.\nProceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).\nequivalence of two distributions (two sample testing), and independence.\nWhile statistical tests are very important for advancing science, when they are performed on sensitive data representing specific individuals, such as data describing medical or other behavioral phenomena, it may be that the outcomes of the tests reveal private information that should not be divulged. Techniques from differential privacy give us hope that one may obtain the scientific benefit of statistical tests without compromising the privacy of the individuals in the study. Concretely, differential privacy requires that similar datasets have statistically close outputs – once this property is achieved, then provable privacy guarantees can be made. Differential privacy is a rich and active area of study, in which techniques have been developed and applied to obtain private algorithms for a range of data analysis tasks.\nOur Contributions We study the general problem of hypothesis testing in the setting of differential privacy (Dwork & Roth, 2014). Our emphasis is on the sublinear regime, i.e., when the number of samples available is sublinear in the domain size of the underlying distribution(s). We obtain sample-efficient private algorithms for the problems of testing the identity and equivalence of discrete distributions. The main conceptual message of our work is that we can achieve differential privacy with only a small increase in the sample complexity compared to the non-private case. Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing. Our experimental evaluation illustrates that our testers achieve small type I and type II errors with a sublinear number of samples when the domain size is large. The sample complexity of our private identity tester significantly outperforms the sample complexity of recently proposed methods for this problem. For both identity and equivalence testing, our experiments show that differential privacy can be achieved essentially for free, i.e., with a very mild increase in sample complexity.\nTechnical Overview We now provide a brief overview of our techniques. We start by observing that there is a simple generic method to convert a non-private tester into a private tester with a multiplicative overhead in the sample complexity. This method is known in differential privacy, but for the sake of completeness we describe it in Appendix B. It will\nbe useful to contrast the sample complexity of the generic method with the (substantially better) sample complexity of our testers (Sections 3-5). For convenience, throughout our theoretical analysis, we obtain testing algorithms that have failure probability at most 1/3. As shown in Appendix C, this is without loss of generality: we can achieve error probability at the expense of a log(1/ ) multiplicative increase in the sample complexity, even in the differentially private setting.\nOur algorithm for identity testing is obtained via the following modular approach: First, we adapt a recently discovered reduction of identity testing to uniformity testing (Goldreich, 2016), building on (Diakonikolas & Kane, 2016). We show (Section 3) that this reduction can be adapted to work in the private setting as well. Therefore, we can translate any private uniformity tester to a private identity tester without increasing the sample size by more than a constant factor. It remains to develop sample-efficient private uniformity testers. We develop two such private methods (Section 4): Our first method is a private version of (Paninski, 2008), which relies on the number of domain elements that appear in the sample exactly once. This statistic has low sensitivity, allowing a translation to the private setting via standard techniques. The sample complexity of our aforementioned uniformity tester is\n⇥( p n/✏ 2 + p n/(✏ p ⇠)) , (1)\nwhere n is the domain size, ✏ is the accuracy of the tester, and ⇠ is the privacy parameter. Our experimental results illustrate that this private tester performs exceptionally well in practice, significantly outperforming recently proposed private algorithms for identity testing (see Section 6).\nWe note that the uniformity tester of (Paninski, 2008) is known to completely fail when the sample size is larger than the domain size (even in the non-private setting). To obtain a uniformity tester that works for the non-sparse regime, we develop our second algorithm: a private version of the collisions-based tester of (Goldreich & Ron, 2000). A collision refers to the event that two random samples drawn from the underlying distribution correspond to the same domain element. The collisions-based tester was recently shown to be sample-optimal in the non-private setting (Diakonikolas et al., 2016). The main difficulty in turning this non-private tester into a private tester is that the underlying statistic (number of collisions) has very high worst-case sensitivity. Hence, the standard approach of adding Laplace noise to the statistic fails in this setting. To overcome this obstacle, we add an appropriate pre-processing step to our tester that rejects when there is a single element that appears many times in the sample. (We note that a similar idea was independently used in (Cai et al., 2017), though the details are somewhat different.) This step allows us to reduce the effective sensitivity of the statistic and can be shown to yield\na sample-efficient private tester. Specifically, the sample complexity of our collisions-based private tester is\nÕ p n/✏ 2 + p n/(✏⇠) + 1/(✏2⇠) . (2)\nFor the problem of equivalence testing, we build on the recently developed chi-square tester of (Chan et al., 2014), which is sample-optimal in the non-private testing. We show that this statistic has bounded sensitivity. Hence, developing a sample-efficient private version can be achieved by adding Laplace noise. A careful analysis shows that the noisy statistic is still accurate without substantially increasing the sample complexity. Specifically, the sample complexity of our private equivalence tester is\nO ⇣p n/✏ 2 + n2/3/✏4/3 + p n/( p ⇠✏) + 1/(⇠✏2) ⌘ . (3)\nWe note that the effect of the privacy constraint on the sample complexity of our testers is in some sense additive, as opposed to multiplicative. In particular, for each case, the sample complexity of the private tester equals the sample complexity of the corresponding non-private tester plus a term that depends on the privacy parameter. For reasonable settings of the privacy parameter, this additive term can be negligible compared to the first term, in which case we obtain differential privacy essentially for free. As a concrete example, the second term in (1) is dominated by the first term (which is provably necessary for any identity tester, even in the non-private setting (Paninski, 2008)), as long as ⇠ ✏2. This phenomenon is confirmed in our experimental evaluation.\nRelated Work During the past two decades, distribution property testing (Batu et al., 2000) – whose roots lie in statistical hypothesis testing (Neyman & Pearson, 1933; Lehmann & Romano, 2005) – has received considerable attention by the computer science community, see (Rubinfeld, 2012; Canonne, 2015) for two recent surveys. The majority of the early work in this field has focused on characterizing the sample size needed to test properties of arbitrary distributions of a given support size. After two decades of study, this “worst-case” regime is well-understood: for many properties of interest there exist sample-optimal testers (matched by information-theoretic lower bounds) (Paninski, 2008; Daskalakis et al., 2013; Chan et al., 2014; Valiant & Valiant, 2014; Diakonikolas et al., 2015b;c; Acharya et al., 2015; Diakonikolas & Kane, 2016; Canonne et al., 2016; Diakonikolas et al., 2016; Canonne et al., 2017; Diakonikolas et al., 2017b).\nA recent line of work (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017; Kakizaki et al., 2017; Cai et al., 2017) has studied distribution testing with privacy constraints. The majority of these works (Wang et al., 2015; Gaboardi et al., 2016; Kifer & Rogers, 2017) only obtain\ntype I error guarantees subject to the privacy constraint, which is a significantly weaker guarantee than ours. The recent work by Cai et al. (Cai et al., 2017) provides an identity tester with finite sample guarantees and bounded type I and type II errors. Specifically, (Cai et al., 2017) give a private identity tester with sample complexity\nÕ ⇣p n/✏ 2 + p n/(✏3/2⇠) + n1/3/(✏5/3⇠2/3) ⌘ . (4)\nThe above bound is always asymptotically worse than (1) and worse than (2) for most parameter settings. We remind the reader that (Cai et al., 2017) does not consider the more general problem of equivalence testing, and that ours are the first results in this setting. Finally, (Diakonikolas et al., 2015a) has provided differentially private algorithms for learning various families of discrete distributions. For the case of unstructured discrete distributions, as the ones considered here, such algorithms inherently require sample size at least linear in the domain size, even for constant values of the approximation parameter.\nIndependent and concurrent work (Acharya et al., 2017) obtained similar upper bounds for private identity and closeness testing. In addition, they obtained nearly matching sample lower bounds in some regimes."
  }, {
    "heading": "2. Preliminaries",
    "text": "Notation and Basic Definitions. We use [n] to denote the set {1, 2, . . . , n}. We say that p is a distribution over [n] if p : [n] ! [0, 1] is a function such that Pn i=1 p(i) = 1, where p(i) denotes the probability of element i. For a set S ✓ [n], p(S) denotes the total probability of the elements in S (i.e., p(S) = P i2S p(i)). For any integer k > 0, the `k-norm of p is equal to Pn\ni=1 |p(i)|k 1\nk , and it is denoted by kpkk. The `k-distance between two distributions p and q over [n] is equal to Pn i=1 |p(i) q(i)|k 1 k . We use Lap(b) to denote a random variable that is drawn from a Laplace distribution with parameter b and mean zero.\nThe problem of identity testing (or goodness-of-fit) is the following: Given sample access to an unknown distribution p over [n] and an explicit distribution q over [n], we want to distinguish, with probability at least 2/3, between the cases that p = q (completeness) and kp qk1 ✏ (soundness). (If kp qk1 ✏, we will say that p and q are ✏-far from each other.) The special case of this problem when q = Un, the uniform distribution over [n], is called uniformity testing. The generalization of identity testing when both p and q are unknown and only accessible via samples is called equivalence testing.\nDifferential Privacy. In our context, a dataset is a multiset of samples drawn from a distribution over [n]. We say that X and Y are neighboring datasets if they differ in exactly\none element.\nDefinition 2.1. A randomized algorithm A : [n]s ! R, is ⇠-differentially private if for any S ✓ R and any neighboring datasets X,Y , we have that Pr[A(X) 2 S]  e ⇠ ·Pr[A(Y ) 2 S] .\nWe will say that a tester is (✏, ⇠)-private, to mean that ✏ is the accuracy parameter, ⇠ is the privacy parameter, and the tester outputs the right answer with probability at least 2/31. For conciseness, we use the term ⇠-private instead of ⇠-differentially private. We provide more details about general techniques in differential privacy in Appendix A."
  }, {
    "heading": "3. Private Identity Testing: Reduction to Private Uniformity Testing",
    "text": "In this section, we provide a reduction of private identity testing (against a fixed distribution) to its special case of private uniformity testing. Specifically, we prove that a recent reduction (Goldreich, 2016) of (non-private) identity testing to (non-private) uniformity testing can be adapted to work in the private setting as well.\nSuppose we want to test identity between an unknown distribution p over [n] and an explicit distribution q. The reduction of (Goldreich, 2016) transforms the distribution p into a new distribution p0, over a domain of size O(n), such that if p = q then p0 is the uniform distribution, and if p is far from q, p0 is also far from uniform. Specifically, the reduction defines a randomized mapping of a sample i 2 [n] from p to a sample (j, a) from p0 that depends only on the explicit distribution q. This property is crucial as it allows us to show that the transformation preserves differential privacy, as the following theorem states:\nTheorem 3.1. Given an (✏, ⇠)-private uniformity tester using s(n, ✏, ⇠) samples, there exists an (✏, ⇠)-private tester for identity using s = s(6n, ✏/3, ⇠) samples.\nThe detailed proof of the theorem is deferred to Appendix D."
  }, {
    "heading": "4. Private Uniformity Testing",
    "text": "In this section, we provide two sample-efficient private uniformity testers. Our testers are private versions of two well-studied (non-private) testers, due to Goldreich and Ron (Goldreich & Ron, 2000) and Paninski (Paninski, 2008). Paninski’s uniformity tester (Paninski, 2008) relies on the number of unique elements in the sample, while (Goldreich & Ron, 2000) relies on the number of collisions. Both testers are known to be sample-optimal in the non-private setting (Paninski, 2008; Diakonikolas et al., 2016).\n1We emphasize that the confidence probability 2/3 can be increased to 1 at the expense of a log(1/ ) multiplicative increase in the sample complexity. See Appendix C.\nAlgorithm 1 Private Uniformity Testing via Unique Elements: Private-Unique-Elements-Uniformity\n1: Input: Sample access to p, n, ✏, ⇠ 2: s 5 p n/(✏ p ⇠) + 6 p n/✏ 2 3: C s✏ 2\np n\n4: x1, x2, . . . , xs s samples drawn from p 5: K the number of unique elements in\n{x1, x2, . . . , xs} 6: K 0 K + Lap(2/⇠) 7: T EU [K] C2/(2✏2) {where EU [K] equals to\ns · 1 1n s 1} 8: if K 0 < T then 9: Output reject.\n10: end if 11: Output accept.\nWe give private versions of both of these algorithms. The sample complexity of our private Paninski uniformity tester is O( p n/✏ 2 + p n/(✏ p ⇠)) . Therefore, as long as ⇠ = ⌦(✏2), the privacy requirement increases the sample complexity by at most a constant factor.\nUnfortunately, the aforementioned tester only succeeds when its sample size is smaller than the domain size n. To be able to handle the entire range of parameters, we develop a private version of the collisions-based tester from (Goldreich & Ron, 2000). Our private version of the collisions tester has sample complexity Õ p n/✏ 2 + p n/(✏⇠) + 1/(✏2⇠) . Similarly, the effect of the privacy is mild as long as ⇠ = ⌦(✏)."
  }, {
    "heading": "4.1. Private Uniformity Tester via Unique Elements",
    "text": "We provide a private tester for uniformity based on the number of unique elements. The number of unique elements is (negatively) related to the number of collisions and the ` 2-norm of the distribution. Therefore, the greater the number of unique elements is, the more the distribution appears uniform. To make the algorithm private, we use the Laplace mechanism which adds a small amount of noise to the number of unique elements. Then, we compare the number of unique elements with a threshold to decide if the distribution is uniform or far from uniform. The noise rate is chosen appropriately so that the following conflicting goals are simultaneously achieved: (1) the algorithm is guaranteed to be private, and (2) the accuracy of the tester does not significantly decrease. This is formalized in Theorem 4.1. The algorithm is described in the following pseudocode:\nTheorem 4.1. Given s = O( p n/(✏ p ⇠)+ p n/✏\n2) samples from a distribution p over [n], Algorithm 1 is an (✏, ⇠)- private uniformity tester, if s is sufficiently smaller than the\ndomain size n.\nLet K be the number of unique elements in the sample set. Since changing one sample in the sample set can change the number of unique elements by no more than two, adding Laplace noise with parameter 2/⇠ to K makes it ⇠-private. Using the composition theorem of differential privacy, we conclude that the overall algorithm is ⇠-private. To show that the algorithm is an ✏-tester, we prove that the statistic K\n0 concentrates well around its expectation in both the completeness and soundness cases. To establish this, we exploit the fact that the variance introduced by the added noise is sufficiently small. Since there is a non-trivial gap between the expected values of K 0 in the two cases, the proof follows by an application of Chebyshev’s inequality. See Appendix E for the formal details."
  }, {
    "heading": "4.2. Private Uniformity Tester via Collisions",
    "text": "In this subsection, we describe the private version of our collisions-based uniformity tester. Recall that a collision refers to the event that two random samples drawn from the underlying distribution correspond to the same domain element. The main difficulty in turning this into a private tester is that the underlying statistic (number of collisions) has very high worst-case sensitivity. Specifically, if the sample set contains s copies of a given domain element, by changing just one of the copies to another element, the number of collisions drops by an additive s. So, if we add enough noise to the statistic to cover the sensitivity of s, the tester accuracy substantially degrades.\nTo overcome this obstacle, we add a pre-processing step to our tester. We notice that the sensitivity of the number of collisions, f(X), for sample set X , depends on the maximum frequency of any element in the sample set. Let ni(X) denote the number of occurrences of element i in the sample set X , and let nmax(X) denote the maximum ni(X). We note that for two neighboring sample sets X and Y , the difference of the number of collisions, |f(X) f(Y )|, is at most nmax(X). Therefore, the sensitivity of f is high on X’s with large nmax(X). If the underlying distribution is uniform, we do not expect any particular element to show up very frequently. Hence, if nmax(X) is high, the algorithm can output reject regardless of f(X). So, the final output of the algorithm does not change drastically on X and Y , while the number of collisions varies a lot.\nThis simple idea forms the basis for our modified tester. The algorithm uses two statistics: nmax and f (or more precisely the noisy version of them, n̂max and f̂ ). If n̂max is too large, it outputs reject. Otherwise, f̂(X) determines the output. In the second case, since nmax is not too large, f has bounded sensitivity. Therefore, we can make it private by adding a small amount of noise to it.\nTo prove the privacy guarantee, note that if f(X) has lowsensitivity, then f̂(X) is easily seen to be private. By the\nAlgorithm 2 Private uniformity tester based on the number of collisions: Private-Collisions-Uniformity\n1: Input: Sample access to p, n, ✏, ⇠ 2: s ⇥ ✓p\nn ✏2 + p n logn ✏ ⇠1/2\n+ p nmax(1,log 1/⇠)\n✏ ⇠ + 1 ✏2 ⇠\n◆ .\n3: Let X = {x1, x2, . . . , xs} be a multiset of s samples drawn from p\n4: ni(X) |{j|xj 2 x and xj = i}|\n5: nmax(X) max i ni(X) 6: n̂max(X) nmax(X) + Lap(2/⇠)\n7: f(X) collisions(X)\n8: ⌘f max 3s 2n , 12 e 2 ln 24n\n+ (2 ln 12)/⇠ + 2max(ln 3, ln 3/⇠)/⇠\n9: T max 3s 2n , 12 e 2 ln 24n + (2 ln 12)/⇠\n10: f̂(X) f(X) + Lap(2 ⌘f/⇠)\n11: if n̂max(X) < T & f̂(X) < 6+✏ 2\n6n s 2 then\n12: O accept.\n13: else\n14: O reject.\n15: end if 16: With probability 1/6, O {accept, reject} \\O. hhflip\nthe answer with probability 1/6.ii 17: Output O.\ncomposition theorem of differential privacy (Lemma A.3), in this case the overall algorithm will be private. The difficulty appears in the complementary case, i.e., when f(X) is highly sensitive. In this case, nmax(X) has to be large. From that we can deduce, that it is very unlikely (over the random noise) that n̂max is small. Given the above and the fact that our algorithm flips its answer with probability 1/6 in the last step, we can compute a closed form formula for the probability that our tester accepts, which allows us to directly prove the privacy guarantee. With a similar argument, we show the privacy guarantee holds for the case that our tester rejects.\nThe detailed procedure is explained in Algorithm 2. We have the following (see Appendix F for the proof):\nTheorem 4.2. Algorithm 2 is an (✏, ⇠)-private tester for uniformity.\nRemark 4.3. Recent work (Diakonikolas et al., 2017a) has obtained an optimal (non-private) uniformity tester based on the `1-distance of the empirical distribution from the uniform distribution. Since this new tester is Lipschitz, we can make it private by adding Laplace noise to the distribution.\nThe simple proof of this fact will appear in a revised version of this paper. A similar observation was made independently in (Acharya et al., 2017)."
  }, {
    "heading": "5. Private Equivalence Testing",
    "text": "In this section, we give a private algorithm for testing equivalence of two unknown discrete distributions. Our tester relies on the chi-squared type sample-optimal (non-private) equivalence tester of (Chan et al., 2014). The equivalence tester relies on the following statistic:\nZ := X\ni\n(Xi Yi)2 Xi Yi Xi + Yi ,\nwhere Xi is the number of occurrences of element i in the sample set from p, and Yi is the number of occurrences of element i in the sample set from q. The statistic Z is chosen in a way so that its expected values in the completeness and soundness cases differ substantially. The challenging part of the analysis involves a tight upper bound on the variance, which allows to show that Z is well-concentrated after an appropriate number of samples. More precisely, the following statements were shown in (Chan et al., 2014):\nE[Z] = X\ni\n(p(i) q(i))2\np(i) + q(i) m\n✓ 1 1 e m(p(i)+q(i))\nm(p(i) + q(i))\n◆\nm 2\n4n+ 2m kp qk21 . (5)\nand\nVar[Z]  2min{m,n}+ X\ni\n5m (p(i) q(i))2\np(i) + q(i) . (6)\nThe private version of the above statistic is simple: We add noise to the random variable Z and work with the noisy statistic, denoted by Z 0. We need to show that we still can infer the correct answer from Z 0, and the noise does not incapacitate our tester. The main reason that this is indeed possible is because the statistic Z has bounded sensitivity.\nAlgorithm 3 is our private equivalence tester and we prove its correctness in Theorem 5.1. Theorem 5.1. Given sample access to two distributions p\nand q, Algorithm 3 is an (✏, ⇠)-private tester for equivalence of p and q.\nSince the sensitivity of Z is small, we can add a small amount of noise to it to make it private, using the Laplace mechanism. Then, we show that adding the noise to Z does not increase its variance drastically. Finally, we prove by the Chebyshev inequality that, with high probability, Z concentrates well around its expected value given the size of the sample set. The proof of the theorem is in Appendix G.\nAlgorithm 3 Private Equivalence Tester: PrivateEquivalence-Test\n1: Input: Sample access to p and q, n, ✏, ⇠ 2: m C ·max ✓p n\n✏2 , n 2/3 ✏4/3 , p np ⇠✏ , 1 ⇠✏2 ◆\n3: Draw m samples from distributions p and q. 4: Xi the number of occurrences of the i-th element in\nthe samples from p 5: Yi the number of occurrences of the i-th element in\nthe samples from q\n6: Z P i (Xi Yi)2 Xi Yi Xi + Yi hhfor Xi + Yi 6= 0.ii 7: ⌘ Lap(8/⇠)\n8: Z 0 = Z + ⌘\n9: T m 2 ✏ 2\n8n+ 4m\n10: if Z 0  T then 11: Output accept. 12: else 13: Output reject. 14: end if"
  }, {
    "heading": "6. Experiments",
    "text": "We provide an empirical evaluation of the proposed algorithms on synthetic data. All experiments were performed on a computer with a 1.6 GHz Intel(R) Core(TM) i5-4200U CPU and 3 GB of RAM.\nBefore we describe our methodology and experimental results in detail, we make two crucial remarks. First, as we explain in more detail below, we note that our synthetic datasets include the provably hardest instances of the corresponding testing problems in the non-private setting. That is, we provide as input to our algorithms sets of samples from pairs of discrete distributions that are the hardest to distinguish information-theoretically. The related work (Cai et al., 2017) evaluated the empirical performance of their identity tester on essentially identical synthetic inputs. Second, since theoretical sample upper bounds in distribution testing typically use big-O notation, the practical performance of the various algorithms depends on the hidden absolute constants in these bounds (which are notoriously hard to pin-down theoretically). As a result, our experimental evaluation reveals phenomena which are not directly implied by our theoretical upper bounds.\nWe now briefly describe our methodology. To measure the accuracy of our algorithms, we empirically estimate the error probability, i.e., the probability that our algorithms output the wrong answer. We run our algorithms on input of s samples from a distribution q (or a pair of distributions) that either satisfies the property (completeness) or is ✏-far\nin `1-distance from satisfying the property. We denote the distribution q in these two cases by q+ and q respectively. We repeatedly run our algorithm r times and compute the ratio of the incorrect answers among these r trials for both q + and q . This gives as estimates for the type I and II errors of our algorithm. We want to understand how fast the error probability converges to 0 as the sample size increases.\nFor the case of uniformity testing, we observe that PrivateUnique-Elements-Uniformity (Algorithm 1) performs significantly better on our datasets than algorithm PrivateCollisions-Uniformity (Algorithm 2), especially when the domain size n is very large (Figure 1). For the case of private identity testing, we show (Figures 3 and 4) that our identity tester obtained by combining our reduction with Private-Unique-Elements-Uniformity significantly outperforms all previous algorithms for this problem. Finally, for the case of equivalence testing, our experiments illustrate (Figure 5) that we can obtain differential privacy essentially for free.\nPrivate Uniformity Testing. We implemented PrivateUnique-Elements-Uniformity (Algorithm 1) and PrivateCollisions-Uniformity (Algorithm 2) to test the uniformity of a distribution in `1-distance.\nLet q+ be the uniform distribution on [n] and q be a distribution that has probability (1 + ✏)/n on half of the domain and probability (1 ✏)/n on the other half. Note that q is ✏-far from uniform in `1-distance. It is known that q is the hardest distribution to distinguish from uniform among all distributions that are ✏-far (Paninski, 2008), without losing any constant factor (Diakonikolas et al., 2017a).\nWe run our two algorithms using samples from q+ and q with the following parameters: n = 800, 000, ✏ = 0.3, r = 300, and ⇠ = 0.2. We estimate how the empirical error probability of the tester changes by increasing the number of samples. As shown in Figure 1, for such a large domain, the algorithm Private-Unique-Elements-Uniformity reaches empirical error of almost zero with sample size sublinear in the size of the domain. We emphasize that none of the previous algorithms in this setting was able to obtain meaningful guarantees in this sparse sample regime.\nAs predicted by our theoretical bounds, the tester PrivateUnique-Elements-Uniformity completely fails if it uses more samples than the domain size. This fact is important when the domain size n and accuracy ✏ are such that the quantity p n/✏\n2 is comparable to the domain size n. For example, if n = 1000 and ✏ = 0.1, Private-UniqueElements-Uniformity is unable to provide any meaningful guarantees, hence we need to resort to Private-CollisionsUniformity. This is illustrated in Figure 2.\nA plausible interpretation for the apparent superiority of Private-Unique-Elements-Uniformity in the sparse regime\nis that: (1) The non-private version of this tester is known to achieve optimal constants in the big-O of the sample complexity (Huang & Meyn, 2013). (2) The non-private tester has low sensitivity, hence we do not require a preprocessing phase (as in Private-Collisions-Uniformity) to obtain a private algorithm.\nPrivate Identity Testing. We now describe our two private identity testers and experimentally compare them to previous private identity testers developed in the recent literature. As explained in Section 3, we proceed to reduce private identity testing to private uniformity testing. More specifically, our identity testers work by first mapping the sample set S to\na new set S0 on a somewhat larger domain, and then testing uniformity on the new domain using samples in S0. Since we have two uniformity testers, Private-Unique-ElementsUniformity and Private-Collisions-Uniformity, we thus obtain two identity testers based on which uniformity tester we use. We term these two private identity testers PrivateUnique-Elements-Identity and Private-Collisions-Identity respectively.\nWe compare our algorithms with the two recent algorithms: Priv’IT proposed in (Cai et al., 2017) and MCGOF proposed in (Gaboardi et al., 2016). It should be noted that our algorithms (and those of (Cai et al., 2017)) provides significantly stronger guarantees compared to (Gaboardi et al., 2016). More specifically, (Gaboardi et al., 2016) only provides type I error guarantees: the algorithm outputs reject with small probability when the distribution is identical to the given distribution. In contrast, our identity testers provably provide small type I and type II error probabilities.\nWe evaluate the various identity testers on two different pairs of distributions: (1) q+1 is the uniform distribution on [n], while q 1 assigns probability (1+✏)/n on half of the domain and probability (1 ✏)/n on the other half. (2) q+2 is a 4- histogram distribution, i.e., the probability mass function is piecewise constant with 4 pieces, and q 2 is obtained from q + 2 by perturbing the probability of each element by ±✏/n. Testing uniformity is a special case of identity testing, and it is known to be essentially the hardest instance of this more general problem.\nFor (1), we explicitly give the uniform distribution, q+1 , to our identity testing algorithm, and draw samples from q+1 or q 1 . We use the parameters n = 800, 000, ✏ = 0.3, and ⇠ = 0.2. We vary the sample size staring from 50, 000 and up to 3 ⇥ 106, increasing it by 50, 000 at each step, and repeat the algorithm for r = 200 times to estimate the maximum of type I and type II errors. We repeat the same process for all the testers we compared against. The results are shown in Figure 3.\nFor (2), we use the same methodology on input the 4- histogram distribution q+2 with interval pieces I1, I2, I3, I4 each of size n/4 such that q+2 (I1) = 4q + 2 (I4), q + 2 (I2) = 3q+2 (I4), and q + 2 (I3) = 2q + 2 (I4). The results are shown in Figure 4.\nIn both cases, we observe that our identity tester PrivateUnique-Elements-Identity converges much faster than all other algorithms.\nWe remind the reader that (Gaboardi et al., 2016) did not provide any type II error guarantees for their tester MCGOF. We included two different curves in our plots illustrating the empirical type I and type II errors of the (Gaboardi et al., 2016) tester.\nPrivate Equivalence Testing. The focus of the experimental evaluation for equivalence testing is as follows: For a range of increasing domain sizes, n, we want to find the smallest sample size such that the error probability (maximum of type I and type II errors) drops below 1/3.\nWe implemented Algorithm 3 to test equivalence of two unknown distributions. We show that for sufficiently large domain size n, our private algorithm succeeds with a sublinear number of samples.\nFor given domain size n, to find the (approximately) minimum number of samples such that the error probability of the algorithm drops below 1/3, we proceed as follows: We start with an initial number of samples s. Then, we estimate the empirical error of the algorithm for these sample sets. If it is more than 1/3, we increase s appropriately and repeat the process until we find s that results in an error of at most 1/3.\nWe choose our input distributions to be the informationtheoretically hardest distributions to distinguish in the nonprivate setting (Batu et al., 2013; Chan et al., 2014). In particular, p is defined to be the distribution such that n2/3 of the domain elements have probability (1 ✏/2)/n2/3 (the “heavy elements”) and n/4 “light” elements have probability 2✏/n. (The rest of the domain elements have mass 0.) Similarly, q is defined to be be a distribution that has probability (1 ✏/2)/n2/3 on the same set of heavy elements as p, and for a disjoint set of n/4 light elements assigns probability 2✏/n. Since the light elements are disjoint, it is clear that p is ✏-far from q.\nTo evaluate the sample complexity of our algorithm, we use the tester to distinguish the following pairs: (q, q) and (p, q).\nWe set ✏ = 0.3, r = 200, and ⇠ = 0.2. We calculate the required number of samples of this tester in order to achieve accuracy at least 2/3, for n raging from 104 up to 2⇥ 106, increasing n by 104 at each step.\nAs a point of comparison, we also implemented the nonprivate equivalence tester of (Chan et al., 2014). As shown in Figure 5, the sample complexities of private and non-private equivalence testing are very close to each other. This result was expected given the theoretical sample complexity of our equivalence tester, since the dependence on the privacy parameter ⇠ appears in an additive term, and is dominated by the other term, when ⇠ is a constant."
  }, {
    "heading": "Acknowledgements",
    "text": "M.A. and R.R. were supported by the National Science Foundation Award under Grant No. CCF-1733808, CCF1650733, and IIS-1741137. In addition, R.R. was supported by National Science Foundation Award under Grant No. CCF-1740751, and ISF grant 1536/14. I.D. was supported by National Science Foundation Award No. CCF-1652862 (CAREER) and a Sloan Research Fellowship."
  }],
  "year": 2018,
  "references": [{
    "title": "Optimal testing for properties of distributions",
    "authors": ["J. Acharya", "C. Daskalakis", "G. Kamath"],
    "venue": "In Conference on Neural Information Processing Systems,",
    "year": 2015
  }, {
    "title": "Differentially private testing of identity and closeness of discrete distributions",
    "authors": ["J. Acharya", "Z. Sun", "H. Zhang"],
    "venue": "CoRR, abs/1707.05128,",
    "year": 2017
  }, {
    "title": "Testing that distributions are close",
    "authors": ["T. Batu", "L. Fortnow", "R. Rubinfeld", "W.D. Smith", "P. White"],
    "venue": "In IEEE Symposium on Foundations of Computer Science, FOCS, pp",
    "year": 2000
  }, {
    "title": "Testing closeness of discrete distributions",
    "authors": ["T. Batu", "L. Fortnow", "R. Rubinfeld", "W.D. Smith", "P. White"],
    "venue": "Journal of the ACM,",
    "year": 2013
  }, {
    "title": "Priv’it: Private and sample efficient identity testing",
    "authors": ["B. Cai", "C. Daskalakis", "G. Kamath"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2017
  }, {
    "title": "Testing shape restrictions of discrete distributions",
    "authors": ["C. Canonne", "I. Diakonikolas", "T. Gouleakis", "R. Rubinfeld"],
    "venue": "In Theoretical Aspects of Computer Science, STACS,",
    "year": 2016
  }, {
    "title": "Testing bayesian networks",
    "authors": ["C. Canonne", "I. Diakonikolas", "D.M. Kane", "A. Stewart"],
    "venue": "In Conference on Learning Theory, COLT, pp",
    "year": 2017
  }, {
    "title": "A survey on distribution testing: Your data is big. but is it blue",
    "authors": ["C.L. Canonne"],
    "venue": "Electronic Colloquium on Computational Complexity (ECCC),",
    "year": 2015
  }, {
    "title": "Optimal algorithms for testing closeness of discrete distributions",
    "authors": ["S. Chan", "I. Diakonikolas", "P. Valiant", "G. Valiant"],
    "venue": "In ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2014
  }, {
    "title": "Testing k-modal distributions: Optimal algorithms via reductions",
    "authors": ["C. Daskalakis", "I. Diakonikolas", "R. Servedio", "G. Valiant", "P. Valiant"],
    "venue": "In ACM-SIAM Symposium on Discrete Algorithms,",
    "year": 2013
  }, {
    "title": "A new approach for testing properties of discrete distributions",
    "authors": ["I. Diakonikolas", "D.M. Kane"],
    "venue": "In IEEE Symposium on Foundations of Computer Science,",
    "year": 2016
  }, {
    "title": "Optimal algorithms and lower bounds for testing closeness of structured distributions",
    "authors": ["I. Diakonikolas", "D.M. Kane", "V. Nikishkin"],
    "venue": "In IEEE Symposium on Foundations of Computer Science,",
    "year": 2015
  }, {
    "title": "Collision-based testers are optimal for uniformity and closeness",
    "authors": ["I. Diakonikolas", "T. Gouleakis", "J. Peebles", "E. Price"],
    "venue": "Electronic Colloquium on Computational Complexity (ECCC),",
    "year": 2016
  }, {
    "title": "Sample-optimal identity testing with high probability",
    "authors": ["I. Diakonikolas", "T. Gouleakis", "J. Peebles", "E. Price"],
    "venue": "Electronic Colloquium on Computational Complexity (ECCC),",
    "year": 2017
  }, {
    "title": "Nearoptimal closeness testing of discrete histogram distributions",
    "authors": ["I. Diakonikolas", "D.M. Kane", "V. Nikishkin"],
    "venue": "In International Colloquium on Automata, Languages, and Programming,",
    "year": 2017
  }, {
    "title": "The algorithmic foundations of differential privacy",
    "authors": ["C. Dwork", "A. Roth"],
    "venue": "Foundations and Trends in Theoretical Computer Science,",
    "year": 2014
  }, {
    "title": "Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing",
    "authors": ["M. Gaboardi", "H.W. Lim", "R.M. Rogers", "S.P. Vadhan"],
    "venue": "In International Conference on Machine Learning,",
    "year": 2016
  }, {
    "title": "On testing expansion in bounded-degree graphs. Technical Report TR00-020",
    "authors": ["O. Goldreich", "D. Ron"],
    "venue": "Electronic Colloquium on Computational Complexity (ECCC),",
    "year": 2000
  }, {
    "title": "Generalized error exponents for small sample universal hypothesis testing",
    "authors": ["D. Huang", "S. Meyn"],
    "venue": "IEEE Trans. Inf. Theor.,",
    "year": 2013
  }, {
    "title": "A new class of private chi-square hypothesis tests",
    "authors": ["D. Kifer", "R. Rogers"],
    "venue": "In International Conference on Artificial Intelligence and Statistics, AISTATS,",
    "year": 2017
  }, {
    "title": "Testing statistical hypotheses",
    "authors": ["E.L. Lehmann", "J.P. Romano"],
    "year": 2005
  }, {
    "title": "Containing Papers of a Mathematical or Physical Character",
    "authors": ["A London. Series"],
    "venue": "doi: 10.1098/rsta.1933.0009. URL http://rsta.royalsocietypublishing",
    "year": 1933
  }, {
    "title": "A coincidence-based test for uniformity given very sparsely-sampled discrete data",
    "authors": ["L. Paninski"],
    "venue": "IEEE Transactions on Information Theory,",
    "year": 2008
  }, {
    "title": "Taming big probability distributions",
    "authors": ["R. Rubinfeld"],
    "venue": "XRDS, 19(1):24–28,",
    "year": 2012
  }, {
    "title": "An automatic inequality prover and instance optimal identity testing",
    "authors": ["G. Valiant", "P. Valiant"],
    "venue": "In IEEE Symposium on Foundations of Computer Science,",
    "year": 2014
  }, {
    "title": "Differentially private hypothesis testing, revisited",
    "authors": ["Y. Wang", "J. Lee", "D. Kifer"],
    "venue": "CoRR, abs/1511.03376,",
    "year": 2015
  }],
  "id": "SP:8229bac336ae2bacdfbad6186482fcad4f677890",
  "authors": [{
    "name": "Maryam Aliakbarpour",
    "affiliations": []
  }, {
    "name": "Ilias Diakonikolas",
    "affiliations": []
  }, {
    "name": "Ronitt Rubinfeld",
    "affiliations": []
  }],
  "abstractText": "We study the fundamental problems of identity and equivalence testing over a discrete population from random samples. Our goal is to develop efficient testers while guaranteeing differential privacy to the individuals of the population. We provide sample-efficient differentially private testers for these problems. Our theoretical results significantly improve over the best known algorithms for identity testing, and are the first results for private equivalence testing. The conceptual message of our work is that there exist private hypothesis testers that are nearly as sample-efficient as their non-private counterparts. We perform an experimental evaluation of our algorithms on synthetic data. Our experiments illustrate that our private testers achieve small type I and type II errors with sample size sublinear in the domain size of the underlying distributions.",
  "title": "Differentially Private Identity and Equivalence Testing of Discrete Distributions"
}