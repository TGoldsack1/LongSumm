{
  "sections": [{
    "heading": "Introduction",
    "text": "The success of recurrent neural network (RNN) models in complex tasks like machine translation and audio synthesis has inspired immense interest in learning from sequence data (Eck & Schmidhuber, 2002; Graves, 2013; Sutskever et al., 2014; Karpathy, 2015). Comprised of elements s\nt P S , which are typically symbols from a discrete vocabulary, a sequence x “ ps1, . . . , sT q P X has length T which can vary between different instances. Sentences are a popular example of such data, where each s\nj is a word from the language. In many domains, only a tiny fraction of X (the set of possible sequences over a given vocabulary) represents sequences likely to be found in nature (ie.\n1MIT Computer Science & Artificial Intelligence Laboratory. Correspondence to: J. Mueller <jonasmueller@csail.mit.edu>.\nProceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).\nthose which appear realistic). For example: a random sequence of words will almost never form a coherent sentence that reads naturally, and a random amino-acid sequence is highly unlikely to specify a biologically active protein.\nIn this work, we consider applications where each sequence x is associated with a corresponding outcome y P R. For example: a news article title or Twitter post can be associated with the number of shares it subsequently received online, or the amino-acid sequence of a synthetic protein can be associated with its clinical efficacy. We operate under the standard supervised learning setting, assuming availability of a dataset D\nn “ tpx i , y i qun i“1 iid„ p XY\nof sequence-outcome pairs. The marginal distribution p X\nis assumed as a generative model of the natural sequences, and may be concentrated in a small subspace of X . Throughout this paper, p denotes both density and distribution functions depending on the referenced variable.\nAfter fitting models to D n , we are presented a new sequence x0 P X (with unknown outcome), and our goal is to quickly identify a revised version that is expected to have superior outcome. Formally, we seek the revised sequence:\nx˚ “ argmax xPC\nx0\nErY | X “ xs (1)\nHere, we want the set C x0 of feasible revisions to ensure that x˚ remains natural and is merely a minor revision of x0. Under a generative modeling perspective, these two goals are formalized as the following desiderata: p\nX px˚q is not too small, and x˚ and x0 share similar underlying latent characteristics. When revising a sentence for example, it is imperative that the revision reads naturally (has reasonable likelihood under the distribution of realistic sentences) and retains the semantics of the original.\nThis optimization is difficult because the constraint-set and objective may be highly complex and are both unknown (must be learned from data). For many types of sequence such as sentences, standard distance measures applied directly in the space of X or S (eg. Levenshtein distance or TF-IDF similarity) are inadequate to capture meaningful similarities, even though these can be faithfully reflected by a simple metric over an appropriately learned space of continuous latent factors (Mueller & Thyagarajan, 2016). In this work, we introduce a generative-modeling framework which transforms (1) into a simpler differentiable optimiza-\ntion by leveraging continuous-valued latent representations learned using neural networks. After the generative model has been fit, our proposed procedure can efficiently revise any new sequence in a manner that satisfies the aforementioned desiderata (with high probability)."
  }, {
    "heading": "Related Work",
    "text": "Unlike imitation learning, our setting does not require availability of improved versions of a particular sequence. This prevents direct application of a sequence-to-sequence model (Sutskever et al., 2014). Similar to our approach, Gómez-Bombarelli et al. (2016) also utilize latent autoencoder representations in order to propose novel chemical structures via Bayesian optimization. However, unlike sequential bandit/reinforcement-learning settings, our learner sees no outcomes outside of the training data, neither for the new sequence it is asked to revise, nor for any of its proposed revisions of said sequence (Mueller et al., 2017). Our methods only require an easily-assembled dataset of sequence-outcome pairs and are thus widely applicable.\nCombinatorial structures are often optimized via complex search heuristics such as genetic programming (Zaefferer et al., 2014). However, search relies on evaluating isolated changes in each iteration, whereas good revisions of a sequence are often made over a larger context (ie. altering a phrase in a sentence). From the vast number of possibilities, such revisions are unlikely to be found by search-procedures, and it is generally observed that such methods are outperformed by gradient-based optimization in high-dimensional continuous settings. Unlike combinatorial search, our framework leverages gradients in order to efficiently find good revisions at test time. Simonyan et al. (2014) and Nguyen et al. (2015) also proposed gradientbased optimization of inputs with respect to neural predictions, but work in this vein has been focused on conditional generation (rather than revision) and is primarily restricted to the continuous image domain (Nguyen et al., 2016)."
  }, {
    "heading": "Methods",
    "text": "To identify good revisions, we first map our stochastic combinatorial optimization problem into a continuous space where the objective and constraints exhibit a simpler form. We assume the data are generated by the probabilistic graphical model in Figure 1A. Here, latent factors Z P Rd specify a (continuous) configuration of the generative process for X,Y (both sequences and outcomes), and we adopt the prior p\nZ “ Np0, Iq. Relationships between these variables are summarized by the maps F,E,D which we parameterize using three neural networks F ,E ,D trained to enable efficient approximate inference under this model.\nThe first step of our framework is to fit this model to D n\nby learning the parameters of these inference networks: the encoder E , the decoder D , and the outcome-predictor F . A good model that facilitates high-quality revision under our framework will possess the following properties: (1) Y can efficiently be inferred from Z and this relationship obeys a smooth functional form, (2) the map D produces a realistic sequence x given any z with reasonable prior probability, (3) the distribution of natural sequences is geometrically simple in the latent Z-space. We explicitly encourage (1) by choosing F as a fairly simple feedforward network, (2) by defining D as the most-likely x given z, and (3) by endowing Z with our simple Np0, Iq prior. Another characteristic desired of our Z-representations is that they encode meaningful sequence-features such that two fundamentally similar sequences are likely to have been generated from neighboring z-values. Applied to image data, VAE models similar to ours have been found to learn latent representations that disentangle salient characteristics such as scale, rotation, and other independent visual concepts (Higgins et al., 2016). The latent representations of recurrent architectures trained on text (similar to the models used here) have also been shown to encode meaningful semantics, with a strong correlation between distances in the latent space and human-judged similarity between texts (Mueller & Thyagarajan, 2016). By exploiting such simplified geometry, a basic shift in the latent vector space may be able to produce higher-quality revisions than attempts to directly manipulate the combinatorial space of sequence elements.\nAfter fitting a model with these desirable qualities, our strategy to revise a given sequence x0 P X is outlined in Figure 1B. First, we compute its latent representation z0 “ Epx0q using a trained encoding map. As the latent representations z are continuous, we can employ efficient gradient-based optimization to find a nearby local optimum z˚ of F pzq (within a simple constraint-set around z0 defined later on). To z˚, we subsequently apply a simple decoding map D (defined with respect to our learned model) in order to obtain our revised sequence x˚. Under our\nassumed model, the optimization in latent representationspace attempts to identify a generative configuration which produces large values of Y (as inferred via F ). The subsequent decoding step seeks the most likely sequence produced by the optimized setting of the latent factors."
  }, {
    "heading": "Variational Autoencoder",
    "text": "For approximate inference in the X,Z relationship, we leverage the variational autoencoder (VAE) model of Kingma & Welling (2014). In our VAE, a generative model of sequences is specified by our prior over the latent values z combined with a likelihood function p\nD px | zq which our decoder network D outputs in order to evaluate the likelihood of any sequence x given z P Rd. Given any sequence x, our encoder network E outputs a variational approximation q\nE pz | xq of the true posterior over the latent-values ppz | xq9 p\nD px | zqp Z pzq. As advocated by Kingma & Welling (2014) and Bowman et al. (2016), we employ the variational family q\nE pz | xq “ Npµ z|x,⌃z|x) with diag-\nonal covariance. Our revision methodology employs the encoding procedure Epxq “ µ\nz|x which maps a sequence to the maximum a posteriori (MAP) configuration of the latent values z (as estimated by the encoder network E ). The parameters of E ,D are learned using stochastic variational inference to maximize a lower bound for the marginal likelihood of each observation in the training data:\nlog p X pxq • ´ “ Lrecpxq ` Lpripxq ‰ (2) Lrecpxq “ ´E q\nE pz|xq rlog pDpx | zqs Lpripxq “ KLpqEpz | xq|| pZq\nDefining z|x “ diagp⌃z|xq, the prior-enforcing KullbackLeibler divergence has a differentiable closed form expression when q\nE , p Z are diagonal Gaussian distributions. The reconstruction term Lrec (ie. negative log-likelihood under the decoder model) is efficiently approximated using just one Monte-Carlo sample z „ q\nE pz | xq. To optimize the variational lower bound over our data D\nn with respect to the parameters of neural networks E ,D , we use stochastic gradients of (2) obtained via backpropagation and the reparameterization trick of Kingma & Welling (2014).\nThroughout, our encoder/decoder models E ,D are recurrent neural networks (RNN). RNNs adapt standard feedforward neural networks for sequence data x “ ps1, . . . , sT q, where at each time-step t P t1, . . . , T u, a fixed size hiddenstate vector h\nt P Rd is updated based on the next element in the input sequence. To produce the approximate posterior for a given x, our encoder network E appends the following additional layers to the final RNN hidden-state (parameterized by W\nµ\n,W ,W v , b µ , b , b v ):\nµ z|x “ WµhT ` bµ P Rd\nz|x “ expp´|W v ` b |q, v “ ReLUpWvhT ` bvq (3)\nThe (squared) elements of z|x P Rd form the diagonal of our approximate-posterior covariance ⌃ z|x. Since Lpri is minimized at z|x “ ~1 and Lrec is likely to worsen with additional variance in encodings (as our posterior approximation is unimodal), we simply do not consider\nz|x values that exceed 1 in our variational family. This restriction results in more stable training and also encourages the encoder and decoder to co-evolve such that the true posterior is likely closer to unimodal with variance § 1. To evaluate the likelihood of a sequence, RNN D computes not only its hidden state h\nt\n, but also the additional output:\n⇡ t “ softmaxpW ⇡ h t ` b ⇡ q (4)\nAt each position t, ⇡ t estimates pps t | s1, . . . , st´1q by relying on h\nt to summarize the sequence history. By the factorization pps1, . . . , sT q “ ± T\nt“1 ppst | st´1, . . . , s1q, we have p\nD px | zq “ ±T t“1 ⇡trsts, which is calculated by\nspecifying an initial hidden-state h0 “ z and feeding x “ ps1, . . . , sT q into D . From a given latent configuration z, our revisions are produced by decoding a sequence via the most-likely observation, which we denote as the map:\nDpzq “ argmax xPX p D px | zq (5)\nWhile the most-likely decoding in (5) is itself a combinatorial problem, beam search can exploit the sequentialfactorization of ppx | zq to efficiently find a good approximate solution (Wiseman & Rush, 2016; Sutskever et al., 2014). For x˚ “ Dpzq P X , this decoding strategy seeks to ensure neither p\nX\npx˚q nor ppz | x˚q is too small."
  }, {
    "heading": "Compositional Prediction of Outcomes",
    "text": "In addition to the VAE component, we fit a compositional outcome-prediction model which uses a standard feed forward neural network F to implement the map F : Rd Ñ R. It is assumed that F pzq “ ErY | Z “ zs under our generative model. Rather than integrating over Z to compute ErY | X “ xs “ ≥ F pzqq\nE pz | xqdz, we employ the first-order Taylor approximation F pEpxqq, where the approximation-error shrinks the more closely F resembles an affine transformation. To ensure this approximateinference step accurately estimates the conditional expectation, we jointly train E and F with the loss:\nLmsepx, yq “ ry ´ F pEpxqqs2 (6)\nIf the architecture of networks E ,F is specified with sufficient capacity to capture the underlying conditional relationship, then we should have F pEpxqq « ErY | X “ xs after properly learning the network parameters from a sufficiently large dataset (even F is a nonlinear map).\nEnforcing Invariance\nIn theory, it is possible that some dimensions of z pertain solely to the outcome y and do not have any effect on the decoded sequence Dpzq. Happening to learn this sort of latent representation would be troubling, since subsequent optimization of the inferred y with respect to z might not actually lead to a superior revised sequence. To mitigate this issue, we carefully ensure the dimensionality d of our latent Z does not significantly exceed the bottleneck capacity needed to produce accurate outcome-predictions and VAE reconstructions (Gupta et al., 2016). We explicitly suppress this undesirable scenario by adding the following loss to guide training of our neural networks:\nLinv “ Ez„p Z\n“ F pzq ´ F pEpDpzqqq ‰2 (7)\nWhen optimizing neural network parameters with respect to this loss, we treat the parameters of D and the lefthand F pzq term as fixed, solely backpropagating Monte-Carlo estimated gradients into E ,F . Driving Linv toward 0 ensures our outcome-predictions remain invariant to variation introduced by the encoding-decoding process (and this term also serves as a practical regularizer to enforce additional smoothness in our learned functions)."
  }, {
    "heading": "Joint Training",
    "text": "The parameters of all components of this model (q E , p D , and F ) are learned jointly in an end-to-end fashion. Training is done via stochastic gradient descent applied to minimize the following objective over the examples in D\nn\n:\nLpx, yq “ Lrec ` priLpri ` mse 2 Y Lmse ` inv 2 Y Linv (8)\nwhere 2 Y denotes the (empirical) variance of the outcomes, and the • 0 are constants chosen to balance the relative weight of each goal so that the overall framework produces maximally useful revisions. By setting mse “ inv “ 0 at first, we can optionally leverage a separate large corpus of unlabeled examples to initially train only the VAE component of our architecture, as in the unsupervised pretraining strategy used successfully by Kiros et al. (2015); Erhan et al. (2010).\nIn practice, we found the following training strategy to work well, in which numerous mini-batch stochastic gradient updates (typically 10-30 epochs) are applied within every one of these steps:\nStep 1: Begin with inv “ pri “ 0, so Lrec and Lmse are the only training objectives. We found that regardless of the precise value specified for mse, both Lrec and Lmse were often driven to their lowest possible values during this joint optimization (verified by training individually against each objective).\nStep 2: Grow pri from 0 to 1 following the sigmoid annealing schedule proposed by Bowman et al. (2016), which is needed to ensure the variational sequence to sequence model does not simply ignore the encodings z (note that the formal variational lower bound is attained at pri “ 1). Step 3: Gradually increase inv linearly until Linv becomes small on average across our Monte-Carlo samples z „ p\nZ . Here, p\nD is treated as constant with respect to Linv, and each mini-batch used in stochastic gradient descent is chosen to contain the same number of Monte-Carlo samples for estimating Linv as (sequence, outcome) pairs."
  }, {
    "heading": "Proposing Revisions",
    "text": "While the aforementioned training procedure is computationally intensive, once learned, our neural networks can be leveraged for efficient inference. Given user-specified constant ↵ ° 0 and a to-be-revised sequence x0, we propose the revision x˚ output by the following procedure.\nREVISE Algorithm Input: sequence x0 P X , constant ↵ P p0, |2⇡⌃ z|x0 |´ 1 2 q Output: revised sequence x˚ P X 1) Use E to compute q\nE pz | x0q 2) Define C\nx0 “ z P Rd : q E pz | x0q • ↵ (\n3) Find z˚ “ argmax zPC\nx0\nF pzq (gradient ascent)\n4) Return x˚ “ Dpz˚q (beam search)\nIntuitively, the level-set constraint C x0 Ñ Rd ensures that z˚, the latent configuration from which we decode x˚, is likely similar to the latent characteristics responsible for the generation of x0. Assuming x0 and x˚ share similar latent factors implies these sequences are fundamentally similar according to the generative model. Note that z˚ “ Epx0q is always a feasible solution of the latent-factor optimization over z P C\nx0 (for any allowed value of ↵). Furthermore, this constrained optimization is easy under our Gaussian approximate-posterior, since C\nx0 forms a simple ellipsoid centered around Epx0q. To find z˚ in Step 3 of the REVISE procedure, we use gradient ascent initialized at z “ Epx0q, which can quickly reach a local maximum if F is parameterized by a simple feedforward network. Starting the search at Epx0q makes most sense for unimodal posterior approximations like our Gaussian q\nE . To ensure all iterates remain in the feasible region C\nx0 , we instead take gradient steps with respect to a penalized objective F pzq ` µ ¨ Jpzq where:\nJpzq “ log ” K ´ pz ´ Epx0qqT ⌃´1 z|x0pz ´ Epx0qq ı\nK “ ´2 logrp2⇡qd{2|⌃ z|x|1{2↵s (9)\nand 0 † µ ! 1 is gradually decreased toward 0 to en-\nsure the optimization can approach the boundary of C x0 . In terms of resulting revision quality, we found this log barrier method outperformed other standard first-order techniques for constrained optimization such as the projected gradient and Franke-Wolfe algorithms.\nIn principle, our revision method can operate on the latent representations of a traditional deterministic autoencoder for sequences, such as the seq2seq models of Sutskever et al. (2014) and Cho et al. (2014). However, the VAE offers numerous practical advantages, some of which are highlighted by Bowman et al. (2016) in the context of generating more-coherent sentences. The posterior uncertainty of the VAE encourages the network to smoothly spread the training examples across the support of the latent distribution. In contrast, central regions of the latent space under a traditional autoencoder can contain holes (to which no examples are mapped), and it is not straightforward to avoid these in our optimization of z˚. Furthermore, we introduce an adaptive variant of our decoder in §S1 which is designed to avoid poor revisions in cases where the initial sequence is already not reconstructed properly: DpEpx0qq ‰ x0."
  }, {
    "heading": "Theoretical Properties of Revision",
    "text": "Here, we theoretically characterize properties of revisions obtained via our REVISE procedure (all proofs are relegated to §S3 in the Supplementary Material). Our results imply that in an ideal setting where our neural network inference approximations are exact, the revisions proposed by our method are guaranteed to satisfy our previously stated desiderata: x˚ is associated with an expected outcome-increase, x˚ appears natural (has nontrivial probability under p\nX whenever x0 is a natural sequence), and x˚ is likely to share similar latent characteristics as x0 (since x˚ is the most likely observation generated from z˚ and q\nE pz˚ | x0q • ↵ by design). Although exact approximations are unrealistic in practice, our theory precisely quantifies the expected degradation in the quality of proposed revisions that accompanies a decline in either the accuracy of our approximate inference techniques or the marginal likelihood of the original sequence to revise.\nTheorems 1 and 2 below ensure that for an initial sequence x0 drawn from the natural distribution, the likelihood of the revised sequence x˚ output by our REVISE procedure under p\nX has lower bound determined by the user-parameter ↵ and the probability of the original sequence p\nX px0q. Thus, when revising a sequence x0 which looks natural (has substantial probability under p\nX ), our procedure is highly likely to produce a revised sequence x˚ which also looks natural. The strength of this guarantee can be precisely controlled by choosing ↵ appropriately large in applications where this property is critical.\nIn each high probability statement, our bounds assume the\ninitial to-be-revised sequence x0 stems from the natural distribution p\nX , and each result holds for any fixed constant ° 0. We first introduce the following assumptions: (A1) For ° 0,↵ ° 0, there exists 0 † § 1 such that:\ni. With probability • 1 ´ {2 (over x „ p X ):\nppz | xq • ¨ q E pz | xq whenever q E pz | xq • ↵\nii. PrpZ R B R{2p0qq • ¨ Prp rZ R BR{2p0qq\nwhere Z „ Np0, Iq, and rZ „ q Z\n, the average encoding distribution defined by Hoffman & Johnson (2016) as:\nq Z pzq “ E x„p\nX\nrq E pz | xqs (10) B\nR p0q “ tz P Rd : ||z|| § Ru denotes the Euclidean ball centered around 0 with radius R defined here as: R “ maxtR1, R2u (11) with R1 “ a ´8 logr↵ ¨ p2⇡qd{2s\nR2 “ maxt rR2, 2u, rR2 “ c 8 ´ 14d log ´ 8 ¯\n(A2) There exists ⌘ ° 0 (depends on ) such that with probability • 1 ´ {2 (over x0 „ pX ): ppz˚ | x˚q § ⌘ This means the latent posterior is bounded at x˚, z˚ (as defined in REVISE), where both depend upon the initial tobe-revised sequence x0. Theorem 1. For any ° 0, (A1) and (A2) imply:\np X px˚q • ↵ ⌘ ¨ p X\npx0q with probability • 1 ´ (over x0 „ pX ).\nCondition (A1) forms a generalization of absolute continuity, and is required since little can be guaranteed about our inference procedures if the variational posterior is too inaccurate. Equality holds in (A1) with probability 1 if the variational distributions q\nE exactly represent the true posterior ( Ñ 1 as the variational approximations become more accurate over the measure p\nX ). In practice, minimization of the reverse KL divergence (Lpri) used in our VAE formulation ensures that q\nE pz | xq is small wherever the true posterior ppz | xq takes small values (Blei et al., 2017). While the bound in Theorem 1 has particularly simple form, this result hinges on assumption (A2). One can show for example that the inequality in (A2) is satisfied if the posteriors ppz | x˚q are Lipschitz continuous functions of z at z˚ (sharing one Lipschitz constant over all possible x˚). In general however, (A2) heavily depends on both the data distribution p\nX and decoder model p D . Therefore, we provide a similar lower bound guarantee on the likelihood of our revision x˚ under p\nX , which instead only relies on weaker assumption (A3) below.\n(A3) There exists L ° 0 such that for each x P X : p D px | zq is a L-Lipschitz function of z over B R`1p0q.\nHere, L depends on (through R), and we assume L • 1 without loss of generality. (A3) is guaranteed to hold in the setting where we only consider sequences of finite length § T . This is because the probability output by our decoder model, p\nD px | zq, is differentiable with bounded gradients over all z P B\nR p0q under any sequence-to-sequence RNN architecture which can be properly trained using gradient methods. Since B\nR`1p0q Ä Rd is a closed interval, p D\npx | zq must be Lipschitz continuous over this set, for a given value of x. We can simply define L to be the largest Lipschitz constant over the |S|T possible choices of x P X (|S| “ size of the vocabulary). In the next theorem below, user-specified constant ↵ ° 0 is defined in REVISE, and L, , R all depend on . Theorem 2. For any ° 0, if (A1) and (A3) hold, then with probability • 1 ´ (over x0 „ pX ):\np X\npx˚q • Ce ´R\nLd ¨\n“ ¨ ↵ ¨ p\nX px0q ‰ d`1\nwhere constant C “ ⇡ d{2 pd2 ` 1q ¨ pd ` 1q d pd ` 2qd`1\nOur final result, Theorem 3, ensures that our optimization of z˚ with respect to F is tied to the expected outcomes at x˚ “ Dpz˚q, so that large improvements in the optimization objective: F pz˚q ´ F pEpx0qq imply that our revision procedure likely produces large expected improvements in the outcome: ErY | X “ x˚s ´ ErY | X “ x0s. For this result, we make the following assumptions:\n(A4) For any ° 0, there exists  ° 0 such that PrpX P Kq • 1 ´ {2, where we define:\nK “ tx P X : x0 “ x ùñ pXpx˚q • u (12)\nas the subset of sequences whose improved versions produced by our REVISE procedure remain natural with likelihood • . Note that either Theorem 1 or 2 (with the corresponding assumptions) ensures that one can suitably define  such that (A4) is satisfied (by considering a sufficiently large finite subset of X ).\n(A5) For any  ° 0, there exists ✏mse ° 0 such that PrpX P Emseq ° 1 ´ , where we define:\nEmse“ tx P X : |F pEpxqq ´ ErY |X “ xs| § ✏mseu (13)\n(A6) For any ° 0, there exists ✏inv ° 0 such that:\n|F pzq ´ F pEpDpzqqq| § ✏inv for all z P BRp0q Ä Rd\nwhere R is defined in (11) and depends on .\nHere, ✏mse and ✏inv quantify the approximation error of our neural networks for predicting expected outcomes and ensuring encoding-decoding invariance with respect to F .\nStandard learning theory implies both ✏mse, ✏inv will be driven toward 0 if we use neural networks with sufficient capacity to substantially reduce Lmse and Linv over a large training set. Theorem 3. For any ° 0, if conditions (A1), (A4), (A5), and (A6) hold, then with probability • 1 ´ ´ :\nz ˚ ´ ✏ § F pz˚q ´ F pEpx0qq § z ˚ ` ✏ (14)\nwhere\nz ˚ “ ErY | X “ x˚s ´ ErY | X “ x0s ✏ “ ✏\ninv ` 2✏ mse\nHere, , ✏inv are defined in terms of as specified in (A4), (A6), and ✏mse is defined in terms of  as specified in (A5)."
  }, {
    "heading": "Experiments",
    "text": "All of our RNNs employ the Gated Recurrent Unit (GRU) of Cho et al. (2014), which contains a simple gating mechanism to effectively learn long-range dependencies across a sequence. Throughout, F is a simple feedforward network with 1 hidden layer and tanh activations (note that the popular ReLU activation is inappropriate for F since it has zero gradient over half its domain). Decoding with respect to p\nD is simply done entirely greedily (ie. a beam-search of size 1) to demonstrate our approach is not reliant on search heuristics. §S2 contains additional details for each analysis."
  }, {
    "heading": "Simulation Study",
    "text": "To study our methods in a setting where all aspects of performance can be quantified, we construct a natural distribution p\nX over sequences of lengths 10-20 whose elements stem from the vocabulary S “ tA,B, . . . , I, Ju. Each sequence is generated via the probabilistic grammar of Table S1. For each sequence, the associated outcome y is simply the number of times A appears in the sequence (a completely deterministic relationship). Since A often follows C and is almost always followed by B under p\nX , a procedure to generate natural revisions cannot simply insert/substitute A symbols at random positions.\nTable 1 compares various methods for proposing revisions. Letting\nY denote the standard deviation of outcomes in D\nn , we evaluate each proposed x˚ using a rescaled version of the actual underlying outcome-improvement:\nY px˚q “ ´1 Y pErY | X “ x˚s ´ ErY | X “ x0sq. Except where sample size is explicitly listed, all models were trained using n “ 10, 000 (sequence, outcome) pairs sampled from the generative grammar. Wherever appropriate, the different methods all make use of the same neural network components with latent dimension d “ 128. Other than ↵, all hyperparameters of each revision method described below were chosen so that over 1000 revisions, the Levenshtein (edit) distance dpx˚, x0q « 3.3 on average.\nAll three results above the line in Table 1 are based on the full model described in our joint training procedure, with new sequences proposed via our REVISE algorithm (using the setting log↵ “ ´10000). In the latter two results, this model was only trained on a smaller subset of the data. We also generated revisions via this same procedure with the more conservative choice log↵ “ ´1. ADAPTIVE denotes the same approach (with log↵ “ ´10000), this time using the adaptive decoding D\nx0 introduced in §S1, which is intended to slightly bias revisions toward x0. The model with inv “ pri “ 0 is a similar method using a deterministic sequence-to-sequence autoencoder rather than our probabilistic VAE formulation (no variational posterior approximation or invariance-enforcing) where the latent encodings are still jointly trained to predict outcomes via F . Under this model, a revision is proposed by starting at Epx0q in the latent space, taking 1000 (unconstrained) gradient steps with respect to F , and finally applying D to the resulting z.\nThe above methods form an ablation study of the various components in our framework. SEARCH is a different combinatorial approach where we randomly generate 100 revisions by performing 4 random edits in x0 (each individual edit is randomly selected as one of: substitution, insertion, deletion, or no change). In this approach, we separately learn a language-model RNN L on our training sequences (Mikolov et al., 2010). Sharing the same GRU architecture as our decoder model, L directly estimates the likelihood of any given sequence under p\nX . Of the randomly generated revisions, we only retain those sequences x for which Lpxq • 1|S|Lpx0q (in this case, those which are not estimated to be † 10 times less likely than the original sequence x0 under pX ). Finally, we score each remaining candidate (including x0) using the outcome-prediction model F pEpxqq, and the best is chosen as x˚. Table 1 shows that our probabilistic VAE formulation outperforms the alternative approaches, both in terms of outcome-improvement achieved as well as ensuring revi-\nsions follow p X . For comparison, ´ log p X px0q had an average value of 26.8 (over these 1000 starting sequences), and changing one randomly-selected symbol in each sequence to A results in an average negative log-probability of 32.8. Thus, all of our revision methods clearly account for p\nX to some degree. We find that all components used in our REVISION procedure are useful in achieving superior revisions. While individual standard deviations seem large, nearly all average differences in\nY or ´ log p X values produced by different methods are statistically significant considering they are over 1000 revisions.\nFrom Supplementary Figure S1, it is clear that ↵ controls how conservative the changes proposed by our REVISE procedure tend to be, in terms of both ´ log p\nX px˚q and the edit distance dpx0, x˚q. The red curve in Figure S1A suggests that our theoretical lower bounds for p\nX px˚q are overly stringent in practice (although only the averagecase is depicted in the figure). The relationship between log p\nX px0q and log pXpx˚q (see Figure S1B) is best-fit by a line of slope 1.2, indicating that the linear dependence on p\nX px0q in the Theorem 1 bound for pXpx˚q is reasonably accurate. Figure S1C shows that the magnitude of changes in the latent space (arising from z-optimization during our REVISE procedure) only exhibits a weak correlation with the edit distance between the resulting revision and the original sequence. This implies that a fixed shift in different directions in the latent space can produce drastically different degrees of change in the sequence space. To ensure a high-quality revision, it is thus crucial to carefully treat the (variational) posterior landscape when performing manipulations of Z."
  }, {
    "heading": "Improving Sentence Positivity",
    "text": "Next, we apply our model to „1M reviews from BeerAdvocate (McAuley et al., 2012). Each beer review is parsed into separate sentences, and each sentence is treated as an individual sequence of words. In order to evaluate methods using an outcome that can be obtained for any proposed revision, we choose y P r0, 1s as the VADER sentiment compound score of a given sentence (Hutto & Gilbert,\n2014). VADER is a complex rule-based sentiment analysis tool which jointly estimates polarity and intensity of English text, and larger VADER scores correspond to text that humans find more positive with high fidelity.\nWe applied all aforementioned approaches to produce revisions for a held-out set of 1000 test sentences. As p\nX\nunderlying these sentences is unknown, we report estimates thereof obtained from a RNN language-model L learned on the sentences in D\nn . Table 2 demonstrates that our VAE approach achieves the greatest outcome-improvement. Moreover, Tables 3 and S2 show that our probabilisticallyconstrained VAE revision approach produces much more coherent sentences than the other strategies."
  }, {
    "heading": "Revising Modern Text in the Language of Shakespeare",
    "text": "For our final application, we assemble a dataset of „100K short sentences which are either from Shakespeare or a more contemporary source (details in §S2.3). In this training data, each sentence is labeled with outcome y “ 0.9\nif it was authored by Shakespeare and y “ 0.1 otherwise (these values are chosen to avoid the flat region of the sigmoid output layer used in network F ). When applied in this domain, our REVISE procedure thus attempts to alter a sentence so that the author is increasingly expected to be Shakespeare rather than a more contemporary source.\nTables 4 and S3 show revisions (of held-out sentences) proposed by our REVISE procedure with adaptive decoding (see §S1), together with sentences generated by applying the adaptive decoder at various points along an unconstrained gradient-ascent path in latent Z space (following gradients of F ). Since the data lack similar versions of a sentence written in both contemporary and Shakespearean language, this revision task is an ambitious application of our ideas. Without observing a continuous spectrum of outcomes or leveraging specially-designed style transfer features (Gatys et al., 2016), our REVISE procedure has to alter the underlying semantics in order to nontrivially increase the expected outcome of the revised sentence under F . Nevertheless, we find that many of the revised sentences look realistic and resemble text written by Shakespeare. Furthermore, these examples demonstrate how the probabilistic constraint in our REVISE optimization prevents the revision-generating latent Z configurations from straying into regions where decodings begin to look very unnatural."
  }, {
    "heading": "Discussion",
    "text": "This paper presents an efficient method for optimizing discrete sequences when both the objective and constraints are stochastically estimated. Leveraging a latent-variable generative model, our procedure does not require any examples of revisions in order to propose natural-looking sequences with improved outcomes. These characteristics are proven to hold with high probability in a theoretical analysis of VAE behavior under our controlled latent-variable manipulations. However, ensuring semantic similarity in textrevisions remains difficult for this approach, and might be improved via superior VAE models or utilizing additional similarity labels to shape the latent geometry."
  }, {
    "heading": "Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau,",
    "text": "D., Bougares, F., Schwenk, H., and Bengio, Y. Learning phrase representations using rnn encoder-decoder for statistical machine translation. Empirical Methods on Natural Language Processing, 2014.\nEck, D. and Schmidhuber, J. A first look at music composition using lstm recurrent neural networks. IDSIA Technical Report, 2002.\nErhan, D., Bengio, Y., Courville, A., Manzagol, P., Vincent, P., and Bengio, S. Why does unsupervised pretraining help deep learning? Journal of Machine Learning Research, 11:625–660, 2010."
  }, {
    "heading": "Gatys, L. A., Ecker, A. S., and Bethge, M. Image style",
    "text": "transfer using convolutional neural networks. Computer Vision and Pattern Recognition, 2016."
  }, {
    "heading": "Gómez-Bombarelli, R., Duvenaud, D., Hernández-Lobato,",
    "text": "J. M., Aguilera-Iparraguirre, J., , Hirzel, T., Adams, R. P., and Aspuru-Guzik, A. Automatic chemical design using a data-driven continuous representation of molecules. arXiv:1610.02415, 2016.\nGraves, A. Generating sequences with recurrent neural networks. arXiv:1308.0850, 2013.\nGupta, P., Banchs, R. E., and Rosso, P. Squeezing bottlenecks: Exploring the limits of autoencoder semantic representation capabilities. Neurocomputing, 175:1001– 1008, 2016.\nHiggins, I., Matthey, L., Glorot, X., Pal, A., Uria, B., Blundell, C., Mohamed, S., and Lerchner, A. Early visual concept learning with unsupervised deep learning. arXiv:1606.05579, 2016."
  }, {
    "heading": "Hoffman, M. D. and Johnson, M. J. Elbo surgery: yet",
    "text": "another way to carve up the variational evidence lower bound. NIPS Workshop on Advances in Approximate Bayesian Inference, 2016.\nHutto, C.J. and Gilbert, E. Vader: A parsimonious rulebased model for sentiment analysis of social media text. Eighth International Conference on Weblogs and Social\nMedia, 2014.\nKarpathy, A. The unreasonable effectiveness of recurrent neural networks. Andrej Karpathy blog, 2015. URL karpathy.github.io."
  }, {
    "heading": "Kingma, D. P. and Welling, M. Auto-encoding variational",
    "text": "bayes. International Conference on Learning Representations, 2014.\nKiros, R., Zhu, Y., Salakhutdinov, R., Zemel, R. S., Torralba, A., Urtasun, R., and Fidler, S. Skip-thought vectors. Advances in Neural Information Processing Systems, 2015.\nMcAuley, J., Leskovec, J., and Jurafsky, D. Learning attitudes and attributes from multi-aspect reviews. IEEE International Conference on Data Mining, 2012."
  }, {
    "heading": "Mikolov, T., Karafiat, M., Burget, L., Cernocky, J., and",
    "text": "Khudanpur, S. Recurrent neural network based language model. Interspeech, 2010.\nMueller, J. and Thyagarajan, A. Siamese recurrent architectures for learning sentence similarity. Proc. AAAI Conference on Artificial Intelligence, 2016.\nMueller, J., Reshef, D. N., Du, G., and Jaakkola, T. Learning optimal interventions. Artificial Intelligence and Statistics, 2017.\nNguyen, A., Yosinski, J., and Clune, J. Deep neural networks are easily fooled: High confidence predictions for unrecognizable images. Computer Vision and Pattern Recognition, 2015."
  }, {
    "heading": "Nguyen, A., Dosovitskiy, A., Yosinski, J., Brox, T., and",
    "text": "Clune, J. Synthesizing the preferred inputs for neurons in neural networks via deep generator networks. Advances in Neural Information Processing Systems, 2016."
  }, {
    "heading": "Simonyan, K., Vedaldi, A., and Zisserman, A. Deep inside",
    "text": "convolutional networks: Visualising image classification models and saliency maps. ICLR Workshop Proceedings, 2014.\nSutskever, I., Vinyals, O., and Le, Q.V. Sequence to sequence learning with neural networks. Advances in Neural Information Processing Systems, 2014.\nWiseman, S. and Rush, A. M. Sequence-to-sequence learning as beam-search optimization. Empirical Methods in Natural Language Processing, 2016."
  }, {
    "heading": "Zaefferer, M., Stork, J., Friese, M., Fischbach, A., Naujoks,",
    "text": "B., and Bartz-Beielstein, T. Efficient global optimization for combinatorial problems. Genetic and Evolutionary Computation Conference, 2014."
  }],
  "year": 2017,
  "references": [{
    "title": "Variational inference: A review for statisticians",
    "authors": ["D.M. Blei", "A. Kucukelbir", "J.D. McAuliffe"],
    "venue": "Journal of the American Statistical Association,",
    "year": 2017
  }, {
    "title": "Generating sentences from a continuous space",
    "authors": ["S.R. Bowman", "L. Vilnis", "O. Vinyals", "A.M. Dai", "R. Jozefowicz", "S. Bengio"],
    "venue": "Conference on Computational Natural Language Learning,",
    "year": 2016
  }, {
    "title": "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
    "authors": ["K. Cho", "B. van Merrienboer", "C. Gulcehre", "D. Bahdanau", "F. Bougares", "H. Schwenk", "Y. Bengio"],
    "venue": "Empirical Methods on Natural Language Processing,",
    "year": 2014
  }, {
    "title": "A first look at music composition using lstm recurrent neural networks",
    "authors": ["D. Eck", "J. Schmidhuber"],
    "venue": "IDSIA Technical Report,",
    "year": 2002
  }, {
    "title": "Why does unsupervised pretraining help deep learning",
    "authors": ["D. Erhan", "Y. Bengio", "A. Courville", "P. Manzagol", "P. Vincent", "S. Bengio"],
    "venue": "Journal of Machine Learning Research,",
    "year": 2010
  }, {
    "title": "Image style transfer using convolutional neural networks",
    "authors": ["L.A. Gatys", "A.S. Ecker", "M. Bethge"],
    "venue": "Computer Vision and Pattern Recognition,",
    "year": 2016
  }, {
    "title": "Automatic chemical design using a data-driven continuous representation of molecules",
    "authors": ["R. Gómez-Bombarelli", "D. Duvenaud", "J.M. Hernández-Lobato", "J. Aguilera-Iparraguirre", "T. Hirzel", "R.P. Adams", "A. Aspuru-Guzik"],
    "year": 2016
  }, {
    "title": "Generating sequences with recurrent neural networks",
    "authors": ["A. Graves"],
    "year": 2013
  }, {
    "title": "Squeezing bottlenecks: Exploring the limits of autoencoder semantic representation capabilities",
    "authors": ["P. Gupta", "R.E. Banchs", "P. Rosso"],
    "year": 2016
  }, {
    "title": "Early visual concept learning with unsupervised deep learning",
    "authors": ["I. Higgins", "L. Matthey", "X. Glorot", "A. Pal", "B. Uria", "C. Blundell", "S. Mohamed", "A. Lerchner"],
    "year": 2016
  }, {
    "title": "Elbo surgery: yet another way to carve up the variational evidence lower bound",
    "authors": ["M.D. Hoffman", "M.J. Johnson"],
    "venue": "NIPS Workshop on Advances in Approximate Bayesian Inference,",
    "year": 2016
  }, {
    "title": "The unreasonable effectiveness of recurrent neural networks",
    "authors": ["A. Karpathy"],
    "venue": "Andrej Karpathy blog,",
    "year": 2015
  }, {
    "title": "Auto-encoding variational bayes",
    "authors": ["D.P. Kingma", "M. Welling"],
    "venue": "International Conference on Learning Representations,",
    "year": 2014
  }, {
    "title": "Learning attitudes and attributes from multi-aspect reviews",
    "authors": ["J. McAuley", "J. Leskovec", "D. Jurafsky"],
    "venue": "IEEE International Conference on Data Mining,",
    "year": 2012
  }, {
    "title": "Recurrent neural network based language model",
    "authors": ["T. Mikolov", "M. Karafiat", "L. Burget", "J. Cernocky", "S. Khudanpur"],
    "year": 2010
  }, {
    "title": "Siamese recurrent architectures for learning sentence similarity",
    "authors": ["J. Mueller", "A. Thyagarajan"],
    "venue": "Proc. AAAI Conference on Artificial Intelligence,",
    "year": 2016
  }, {
    "title": "Learning optimal interventions",
    "authors": ["J. Mueller", "D.N. Reshef", "G. Du", "T. Jaakkola"],
    "venue": "Artificial Intelligence and Statistics,",
    "year": 2017
  }, {
    "title": "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images",
    "authors": ["A. Nguyen", "J. Yosinski", "J. Clune"],
    "venue": "Computer Vision and Pattern Recognition,",
    "year": 2015
  }, {
    "title": "Synthesizing the preferred inputs for neurons in neural networks via deep generator networks",
    "authors": ["A. Nguyen", "A. Dosovitskiy", "J. Yosinski", "T. Brox", "J. Clune"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2016
  }, {
    "title": "Deep inside convolutional networks: Visualising image classification models and saliency maps",
    "authors": ["K. Simonyan", "A. Vedaldi", "A. Zisserman"],
    "venue": "ICLR Workshop Proceedings,",
    "year": 2014
  }, {
    "title": "Sequence to sequence learning with neural networks",
    "authors": ["I. Sutskever", "O. Vinyals", "Q.V. Le"],
    "venue": "Advances in Neural Information Processing Systems,",
    "year": 2014
  }, {
    "title": "Sequence-to-sequence learning as beam-search optimization",
    "authors": ["S. Wiseman", "A.M. Rush"],
    "venue": "Empirical Methods in Natural Language Processing,",
    "year": 2016
  }, {
    "title": "Efficient global optimization for combinatorial problems",
    "authors": ["M. Zaefferer", "J. Stork", "M. Friese", "A. Fischbach", "B. Naujoks", "T. Bartz-Beielstein"],
    "venue": "Genetic and Evolutionary Computation Conference,",
    "year": 2014
  }],
  "id": "SP:ce1a0c396251be282e5d805443f0d32f0d858bf8",
  "authors": [{
    "name": "Jonas Mueller",
    "affiliations": []
  }, {
    "name": "David Gifford",
    "affiliations": []
  }, {
    "name": "Tommi Jaakkola",
    "affiliations": []
  }],
  "abstractText": "We present a model that, after learning on observations of (sequence, outcome) pairs, can be efficiently used to revise a new sequence in order to improve its associated outcome. Our framework requires neither example improvements, nor additional evaluation of outcomes for proposed revisions. To avoid combinatorial-search over sequence elements, we specify a generative model with continuous latent factors, which is learned via joint approximate inference using a recurrent variational autoencoder (VAE) and an outcome-predicting neural network module. Under this model, gradient methods can be used to efficiently optimize the continuous latent factors with respect to inferred outcomes. By appropriately constraining this optimization and using the VAE decoder to generate a revised sequence, we ensure the revision is fundamentally similar to the original sequence, is associated with better outcomes, and looks natural. These desiderata are proven to hold with high probability under our approach, which is empirically demonstrated for revising natural language sentences. Introduction The success of recurrent neural network (RNN) models in complex tasks like machine translation and audio synthesis has inspired immense interest in learning from sequence data (Eck & Schmidhuber, 2002; Graves, 2013; Sutskever et al., 2014; Karpathy, 2015). Comprised of elements s t P S , which are typically symbols from a discrete vocabulary, a sequence x “ ps1, . . . , sT q P X has length T which can vary between different instances. Sentences are a popular example of such data, where each s j is a word from the language. In many domains, only a tiny fraction of X (the set of possible sequences over a given vocabulary) represents sequences likely to be found in nature (ie. MIT Computer Science & Artificial Intelligence Laboratory. Correspondence to: J. Mueller <jonasmueller@csail.mit.edu>. Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s). those which appear realistic). For example: a random sequence of words will almost never form a coherent sentence that reads naturally, and a random amino-acid sequence is highly unlikely to specify a biologically active protein. In this work, we consider applications where each sequence x is associated with a corresponding outcome y P R. For example: a news article title or Twitter post can be associated with the number of shares it subsequently received online, or the amino-acid sequence of a synthetic protein can be associated with its clinical efficacy. We operate under the standard supervised learning setting, assuming availability of a dataset D",
  "title": "Sequence to Better Sequence: Continuous Revision of Combinatorial Structures"
}