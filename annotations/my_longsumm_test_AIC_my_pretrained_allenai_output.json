{
    "0": "we present beat, a set of practical byzantine for completely asynchronous environments. beat is flexible, versatile, and extensible, consisting of five asynchronous bft designed to are designed different performance metrics, different scenarios). due to modularity in its design, of these protocols can be mixed to achieve even more meaningful trade-offs functionality and performance for various applications. through a 92-instance, five-continent deployment of beat on amazon ec2, we show that beat beat is efficient: roughly, all our beat instances significantly outperform, in terms of both latency and throughput, honeybadgerbft, honeybadgerbft, and the most efficient asynchronous bft known. machine",
    "1": "to operate reliably in real-world traffic, an autonomous car must evaluate the consequences of its potential actions by anticipating the uncertain intentions of other traffic participants. this paper presents an integrated behavioral inference and decision-making approach that models vehicle for both our vehicle and nearby vehicles as a discrete set of closedloop policies that react to the actions of other agents. each policy a distinct high-level behavior and intention, such as driving along a lane or turning at an intersection. we first employ bayesian changepoint detection on the observed history of states states states states of nearby to estimate to estimate to estimate estimate the each",
    "2": "abductive reasoning is inference inference to the most jenny for example, if jenny in a mess when she returns from work, and remembers that she left a window open, she can hypothesize that a thief into her and caused the mess, as as as explanation. while abduction has while long been considered to be at the core of be at at the core of how people interpret and read between the lines in (hobbs et al., has been relatively little research in support of abductive abductive natural language inference and generation. we present the first",
    "3": "efficient maximum inner inner product search (mips) is an important task that has a wide wide applicability in recommendation systems and classification with a large number of classes. solutions based on hashing (lsh) as well as tree-based solutions have been investigated in the recent to perform approximate mips in sublinear this paper, we compare these to another extremely extremely simple approach for solving solving approximate mips, based on variants of the k-means clustering algorithm. we propose to train a spherical kmeans, reduced the mips problem having having to problem to a maximum cosine (mcss). experiments on two standard",
    "4": "most recent datacenter designs have focused on performance properties such as latency and throughput. in this paper, we explore a new dimension, management complexity, which attempts to understand the complexity of deploying a topology and expanding it. by analyzing practice in lifecycle management, we devise complexity metrics for lifecycle management, and show that existing topology have low lifecycle management complexity by management complexity by some but not by others. motivated by this, we design design a new class of topologies, fatclique, that, while performance-equivalent to existing topologies, is to, or to, or better them by all our them our lifecycle management complexity metrics. over the past our",
    "5": "performance of in-memory in-memory key-value continues to be of great importance as modern kvs goes beyond the traditional object-caching workload and becomes a key infrastructure to main-memory in data centers. recent years have witnessed a rapid increase of network bandwidth in data centers, shifting the bottleneck of most kvs from the network to network to the cpu. rdma-capable partly alleviates the problem, but the primitives provided by rdma abstraction are rather are rather meanwhile, nics become in data centers, centers, paper, we present kv-direct, kv-direct, kv-direct, present a processing. in this paper, we present a high kvs that programmable to extend rdma primitives and",
    "6": "networks are a fundamental tool tool for understanding and modeling complex systems in physics, neuroscience, engineering, and social science. many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. edges. however, organization of complex networks\u2014at the level of network subgraphs\u2014 remains largely unknown. here we develop a generalized framework for we develop a generalized framework connectivity patterns. this framework provides mathematical guarantees on the optimality clusters and scales to networks to networks with billions billions of edges. the framework a number of number of in propagation units in neuronal networks and structure in transportation structure transportation structure in",
    "7": "we a new training methodology for generative adversarial networks. the key idea is to grow both the generator and discriminator starting from a low resolution, we layers that model layers that as training progresses. this both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented e.g., celeba images at 1024. we also propose also a simple way to simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised cifar10. we describe several implementation details that are discouraging unhealthy competition between between the generator and discriminator. finally, we between suggest suggest a new metric we suggest a metric metric we suggest",
    "8": "class we describe the class of convexified convolutional neural networks (ccnns), which capture the parameter sharing of convolutional neural networks in a convex manner. by representing the nonlinear convolutional filters as vectors in a kernel hilbert space, the cnn parameters can be as a low-rank matrix, which can be relaxed to obtain a convex problem. for learning two-layer convolutional we prove that the generalization error obtained by a convexified converges to that of cnn converges to that of the cnn. for learning deeper we ccnns train ccnns in a layer-wise manner. empirically, empirically, ccnns trained performance competitive with cnns cnns",
    "9": "the of intelligent intelligent machines is one of the biggest unsolved challenges in computer in this paper, we some fundamental properties these machines should have, focusing in particular on in and learning. we discuss a simple environment that could be used to incrementally teach a machine the basics of natural-language-based communication, as a prerequisite to more complex interaction with human human users. we also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment. a machine capable of performing complex tasks without requiring requiring without would be in almost endeavor, almost human human endeavor, from performing",
    "10": "teaching teaching machines to read natural language documents remains an elusive challenge. machine reading systems can be tested on their ability to answer questions posed on the contents of documents documents that they have but until now large training and test have been missing for this type of evaluation. in this work we define a new methodology that resolves this bottleneck and provides large supervised reading comprehension data. this allows us to develop develop a class of attention based deep networks that learn to read real and answer complex questions with minimal minimal prior knowledge of questions with minimal the path from of language",
    "11": "modern online services come with stringent quality requirements in terms of response time tail latency. because of their their decomposition into fine-grained communicating software layers, a user request fans out into a plethora of short, faster inter-server in reaction to communication. in reaction to that need, we are witnessing a technological transition characterized by the emergence of hardware-terminated user-level (e.g., infiniband/rdma) and (e.g., architectures with network interfaces (nis). such interfaces architectures offer offer a unique opportunity for a new ni-driven for a new approach to balancing rpcs among the cores of manycore tail yielding tail latency rpcs. we introduce rpcvalet, introduce ni-driven an ni-driven \u03bcs-scale rpcs. of tail latency of major",
    "12": "databases databases can provide by by partitioning data across several several servers. servers. multi-operation transactional access is often expensive, employing coordination-intensive coordination-intensive mechanisms. accordingly, many realworld systems mechanisms that provide useful semantics for multi-partition this leads to incorrect for a large class of including secondary indexing, indexing, foreign key enforcement, and view maintenance. in this we identify a materialized this work, we identify a new model\u2014read atomic matches the requirements of these use cases by ensuring atomic visibility: either all or none of each transaction\u2019s of each transaction\u2019s updates are observed by other transactions. we present other algorithms for read that enforce that enforce",
    "13": "we are seeing an explosion of uncertain data\u2014i.e., data data\u2014i.e., data that is more properly by probability distributions estimated values with error rather than values\u2014from in iot, sampling-based approximate computations and machine learning algorithms. in many cases, performing computations computations on uncertain data as if it were exact leads to were exact leads to incorrect results. unfortunately, developing for uncertain data is a major challenge from both the mathematical and performance perspectives. this paper proposes and for tackling this dag-based data processing systems. we present a framework for uncertainty propagation (up) (up) propagation that allows developers effort. of dag dag to implementations of modest effort. to process uncertain with effort. to process uncertain uncertain inputs",
    "14": "many organizations today have more than very large databases; databases; they have databases that without limit at a rate of several million records per day. these continuous data streams brings also challenges. this paper and vfdt, an anytime system that builds decision trees using constant using constant memory and per example. vfdt can incorporate tens of incorporate tens of of examples per second using off-the-shelf hardware. it uses hoeffding bounds to guarantee that its output is nearly identical to that of a conventional learner. we study study vfdt\u2019s properties and demonstrate its utility utility through an extensive set of experiments on synthetic data. we apply vfdt to mining the continuous",
    "15": "a critical of existing inverse inverse reinforcement learning (irl) methods is their inability outperform outperform the demonstrator. this is because irl typically seeks a reward function that makes the demonstrator near-optimal, rather than inferring the underlying intentions of the demonstrator that may have been practice. in this paper, we introduce a novel reward-learning-from-observation this paper, we introduce a novel reward-learning-from-observation reward extrapolation that extrapolates beyond a set of (approximately) ranked demonstrations in order to infer high-quality reward functions from a set of potentially poor when combined with reinforcement learning, t-rex outperforms state-of-the-art imitation learning and irl methods on multiple atari tasks and achieves performance that and achieves performance",
    "16": "learning interpretable and transferable and transferable subpolicies and performing single, complex task is difficult. some traditional hierarchical reinforcement techniques enforce this decomposition in a top-down while meta-learning techniques a task distribution at hand to learn such decompositions. this paper presents a framework for using diverse suboptimal models to decompose complex task solutions into simpler modular subpolicies. this framework performs automatic decomposition of a single source task in a bottom up manner, concurrently learning the required modular learning as as a controller to coordinate we perform perform a series of experiments on high dimensional continuous action tasks to demonstrate the effectiveness of this",
    "17": "we a new framework for estimating generative models via an adversarial process, process, in which we simultaneously train two generative model g that captures the data distribution, and a discriminative model that estimates the probability that a sample came from the training data rather than g. the training procedure for g is to maximize the probability of making a mistake. this framework corresponds a mistake. a minimax game. in the space of arbitrary functions g and d, a unique solution exists, with g recovering the training data distribution and equal to 1 in to in the case where g and by multilayer defined",
    "18": "among among the numerous alternative cryptocurrencies derived from bitcoin, zcash is often often touted as the one with the anonymity due to its well-regarded in this paper, we examine the extent to which anonymity is achieved in the anonymity is achieved in the deployed version of zcash. we investigate all facets of anonymity in zcash\u2019s from its transparent transactions to the interactions with and within its its privacy feature, feature, a shielded pool a shielded pool that as the anonymity set for users wishing to spend privately. we conclude that while while it is that in possible to in a private way, it",
    "19": "virtual virtual democracy is an approach to automating decisions, by learning models of the preferences of individual people, and, at runtime, aggregating the predicted preferences of those people on the dilemma at hand. one of the key questions is which aggregation method or voting rule \u2014 to use; we offer offer a novel statistical viewpoint that provides guidance. we seek voting rules that are robust to prediction errors, in that their output on people\u2019s true preferences is likely to coincide with output on noisy estimates thereof. we prove that the classic borda count rule is robust in this whereas any voting rule belonging to the wide family of pairwisemajority is"
}