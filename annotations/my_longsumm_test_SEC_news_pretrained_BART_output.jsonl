{
    "0": "Networks are a fundamental tool for understanding and modeling complex systems in physics, biology, neuroscience, engineering, and social science. Many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. Here we develop Higher-order organization of complex networks is largely unknown. Here we develop a framework for clustering networks based on higher-order connectivity patterns. This framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. The framework reveals higher- The method is based on the graph Laplacian and cut and volume measures for sets of vertices in a graph. We then define network motifs in Section S1.2 and generalize the notions of cut andvolume to motifs. Finally, we relate conductance on the weighted graph defined by Equation S19. When |A| = 3, the motif cut and motif volume are both equal to half. For any motif with three anchor nodes, conductance is equal to the motif conductance. Theorem 5 says that the set of nodes S is within a quadratic factor of optimal. The second result provides a lower bound on the optimal motif conductance in terms of the eigenvalue. We use this bound to show that certain motifs do not provide the exact conductance with an additional penalty for splitting the four anchor nodes into two groups of two. This follows from Lemmas 1 and 8. When |A| > 4, we can derive similar penalized approximations to \u03c6(G)M (S We first provide a theoretical analysis of the computational complexity, which depends on motif. After, we empirically analyze the time to find clusters for triangular motifs on a variety of real-world networks. Finally, we show that we can practically compute the motif adjacency For several motifs, the motif adjacency matrix WM (Equation S19) has a simple formula. Table S6 lists the formula of WM for motifs M1, M2, M3, M4, M5, M6, and M For our experiments, we compare our spectral motif-based custering to the following methods:. Standard, edge-based spectral clustering. Infomap, which is based on the map equation (62) and the Louvain method (63) C. elegans network. In this network, the nodes are neurons and the edges are synapses. The network data was downloaded from suppl/celegans131.zip. The original network has 131 nodes and 764 edges. The largest connected component of the motif The nodes in the transportation reachability network are airports in the United States and Canada. There is an edge from city i to city j if the estimated travel time from i to j is less than some threshold (23). The network is not symmetric. The network with We next use motif-based clustering to analyze several additional networks. Motifs model energy flow patterns between several species. Low motif conductance (high-quality) clusters only exist for motif M6. Clusters based on motifs M5 or M8 have All data is available at our project web site at The web site includes links to datasets used for experiments throughout the supplementary material. See the Supplementary Material.",
    "1": "KV-Direct leverages programmable NIC to extend RDMA primitives and enable remote direct key-value access to the main host memory. Compared with CPU based K We develop several novel techniques to maximize the throughput and hide the latency of the PCIe connection between the NIC and the host memory. Combined, these mechanisms allow a single NIC K In-memory key-value store (KVS) is a key distributed system component in many data centers. Historically, KVS such as Memcached gained popularity as Historically, KVS such as Memcached gained popularity as an object caching system for web services. The workload shifts from object cache to generic data structure store implies several High-performance KVS systems fall into three categories: on the CPU of KVS server, on KVS clients or on a hardware accelerator. In high performance KVS Programmable NICs with FPGA now witness large-scale deployment in datacenters. People are now turning to domain-specific architectures (DSAs) for better KV-Direct moves KV processing from the CPU to the programmable NIC in the server. The NIC accesses host memory via PCIe, a packet switched network with KV-Direct enables remote direct key-value access. The programmable NIC on KVS server is an FPGA reconfigured as a KV processor. KV-Direct extends one-sided RDMA operations to key-value operations. It supports two types of vector operations: Sending a scalar to the NIC on the KV storage is partitioned into two parts: a hash table and dynamically allocated memory. To minimize the number of memory accesses, small KV pairs are stored in Our hardware platform is built on an Intel Stratix V FPGA based programmable NIC (\u00a72.3) Our KV processor is implemented in 11K lines We evaluate KV-Direct in a testbed of eight servers and one Arista DCS-7060CX-32S switch. Each server equips two There are two free parameters in our hash table design: (1) inline threshold, (2) ratio of hash index in the entire memory space. When hash index ratio KV-Direct is 10x more power efficient than CPU-based systems. It is able to reach the clock frequency bound of 180 Mops under read-intensive workload PCIe has 29% TLP header and padding overhead for 64B DMA operations. The DMA engine may not have enough parallelism to saturate the PCIe With 10 KV-Direct NICson a server, the one billion KV op/s performance is readily achievable with a commodity server. Figure 20 shows that K The goal of KV-Direct is to leverage existing hardware in data centers to offload an important workload (KV access) We use programmable NICs, which A large body of distributed KVS are based on CPU. KV-Direct comes with a new hash table and memory management mechanism specially designed for FPGA to minimize KV-Direct is another exercise in leveraging reconfigurable hardware to accelerate an important workload. It is able to obtain superior performance by carefully co-designing hardware and We would like to thank Kun Tan, Ningyi Xu, Ming Wu, Jiansong Zhang and Anuj Kalia for all technical discussions and valuable comments. We\ufffd",
    "2": "An autonomous car must evaluate the consequences of its potential actions by anticipating the uncertain intentions of other traffic participants. This paper presents an integrated behavioral inference and Decision-making for autonomous driving is hard due to uncertainty on the continuous state of nearby vehicles. We present an integrated behavioral anticipation and decision- Despite the probabilistic nature of the anticipation problem, some approaches in the literature assume no uncertainty on the future states of other participants. Such an The POMDP model provides a mathematically rigorous formulation of the decision making problem in dynamic, uncertain scenarios. Finding an optimal solution to most P We first formulate the problem of decision making in dynamic, uncertain environments as a multiagent POMDP. We then show how we exploit autonomous driving Let V denote the set of vehicles interacting in a local neighborhood of our vehicle. At time t, a vehicle v can take an action avt We make the following approximations to sample from the likely interactions of traffic agents. At any given time, both our vehicle and other vehicles are In this section, we describe how we infer the probability of the policies executed by other cars and their parameters. Our behavioral anticipation method is based on To segment a target car\u2019s history of observed states, we adopt the recently proposed CHAMP algorithm by Niekum et al. In contrast with other anticipation approaches in the literature, here we compute the likelihood of each latent policy by leveraging changepoint detection on the history of observed The time-series segmentation obtained via changepoint detection allows us to perform online detection of anomalous behavior not modeled by our policies. Anomal Algorithm 1 implements the formulation and approximations given in \u00a7III by leveraging the anticipation scheme from \u00a7IV. The algorithm begins by drawing a There are many possible design choices for engineering the set of available policies in our approach, which we wish to explore in future work. However, in A lower-fidelity simulation can capture the necessary interactions between vehicles to make reasonable choices. In practice, we use a simplified simulation model for each The reward function for evaluating the outcome of a rollout \u03a8 involving all vehicles is a weighted combination of metrics. The construction of a reward function based To evaluate our behavioral anticipation method and our multipolicy sampling strategy, we use traffic-tracking data collected using our autonomous vehicle platform. We evaluate our To collect the traffic-tracking dataset we use in this work, we have used our autonomous vehicle platform. The vehicle uses prior maps of the area For our system, we are interested in correctly identifying the behavior of target vehicles by associating it to the most likely policy according to the observations. We now qualitatively explore the performance of our anomaly detection test. We recorded three additional trajectories corresponding to two bikes and a bus. The bikes To show that our approach makes decision-making tractable, we assess the sampling performance in terms of the likelihood of the samples using the recorded intersection We tested the full decision-making algorithm with behavioral prediction in a simulated environment with a multi-lane highway scenario involving two nearby cars. This simulation By explicitly modeling reasonable behaviors of both our vehicle and other vehicles as policies, we make informed high-level behavioral decisions that account for the consequences of This work was supported in part by a grant from Ford Motor Company. The authors are sincerely grateful to Patrick Carmody for his help in collecting the",
    "3": "Efficient Maximum Inner Product Search (MIPS) is an important task that has a wide applicability in recommendation systems and classification with a large number of classes. We propose to train a spherical kmeans, after having reduced the MIPS problem to a Maximum Cosine Similarity Search (MCSS) This simple approach yields The Maximum Inner Product Search (MIPS) problem has recently received increased attention, as it arises naturally in many large scale tasks. MIPS is related to nearest neighbor search (NNS), and to maximum similarity search. It is considered a harder problem because the inner product neither satisfies the triangular inequality as usually do. There are two common types of solution for MIPS in the literature: tree-based methods and hashingbased methods. Tree- based methods are data dependent (i.e. first trained to adapt to the specific data set) While hash-based method are mostly data independent. We follow the previous work by Shrivastava and Li (2015) for reducing the MIPS problem to the MCSS problem by ingeniously rescaling the vectors and adding new components. We then apply two mappings P and Q, one on the data points and another on the query vector. To find the one vector In this section we will evaluate the proposed algorithm for approximate MIPS. We analyze the following characteristics: speedup, compared to the exact full linear search, of retrieving top-K items with largest inner product, and robustness of retrieved results to noise in the query. We have used 2 collaborative filtering datasets and 1 word embedding dataset. Given the user-item matrix Z, we follow the pureSVD procedure described in (Cremonesi et al., 2010) to generate user and movie vectors. We consider 60,000 randomly selected users as queries. We consider the following baselines to compare with. PCA-Tree (Bachrach et al., 2014) is the state-of-the-art tree-based method. SRP-Hash: This is the signed random projection hashing method for MIPS proposed in Shrivastava and Li (2015) K-means and PCA-Tree algorithms were tested on Movielens-10M and Netflix datasets. Hashing-based methods perform better with lower speedups. But their performance decrease rapidly after 10x speedup. In this experiment, we consider a word embedding retrieval task. We take 2,000 random word embeddings from the database and corrupt them random Gaussian noise. We vary the scale of the noise from 0 to 0.4 and plot the performance. We can see that k-means always performs better than other In this paper, we have proposed a new and efficient way of solving approximate K-MIPS based on a simple clustering strategy. We regard the simplicity of this approach as one of its strengths. Empirical results on three real-world datasets show that this simple approach clearly outperforms the other families of techniques. The authors would like to thank the developers of Theano (Bergstra et al., 2010) for developing such a powerful tool. Samsung, NSERC, Calcul Quebec, Compute Canada, the Canada Research Chairs and CIFAR.",
    "4": "The development of intelligent machines is one of the biggest unsolved challenges in computer science. In this paper, we propose some fundamental properties these machines should have, focusing in particular on communication and learning. We discuss a simple environment A machine capable of performing complex tasks without requiring laborious programming would be tremendously useful in almost any human endeavor. Given the current availability of powerful hardware and large amounts of machine-readable data, the times should be ripe Rather than attempting to formally characterize intelligence, we propose here a set of desiderata we believe to be crucial for a machine to be able to autonomously make itself helpful to humans. The guiding principles we implicitly considered Intelligent machines must be able to communicate with us. We propose language as the general interface to the machine. We are agnostic about the nature of the machine\u2019s internal representations. We believe it is uncontroversial that a machine supposed to be helping us in a variety of scenarios, many unforeseen by its developers, should be endowed with the capability of learning. A machine that does not learn cannot adapt In this section, we describe a simulated environment designed to teach the basics of linguistic interaction to an intelligent machine. The simulated ecosystem should be seen as a \u201ckindergarten\u2019 providing basic education to intelligent We propose a dynamic ecosystem akin to that of a computer game. The Learner (the system to be trained) is an actor in this ecosystem. The Teacher assigns tasks and rewards the Learner for desirable behaviour. We show how the Teacher guides the Learner from these basic skills to being able to solve relatively sophisticated Environment navigation problems by exploiting interactive communication. The tasks we describe are incrementally structured, starting with learning to issue Environment An intelligent machine schooled in our ecosystem could later make itself useful in the real world. We consider a scenario in which the machine works as an assistant to Alice, an elderly person living alone. The range of tasks In this section, we will outline some of our ideas about how to build intelligent machines that would benefit from the learning environment we described. While we do not have a concrete proposal yet about how exactly such machines should be There are many types of behavior that we collectively call learning, and it is useful to discuss some of them first. To master basic communication skills, the machine will have to understand the concept of positive and negative reward. Long-term memory should be able to store facts and algorithms corresponding to learned skills, making them accessible on demand. Even the ability to learn should be seen as a set of skills that are stored in the memory. We are convinced that such model should be unrestricted, that is, able to represent any pattern in the data. We are not interested in building the intelligent machine around the concept of the Turing machine; we just aim to We share Turing\u2019s goal of developing a child machine capable of independent communication through natural language. We also diverge with respect to the imitation game, since the purpose of our intelligent machine is not to fool human We defined basic desiderata for an intelligent machine, stressing learning and communication as its fundamental abilities. We proposed a simulated environment that requires the intelligent machine to acquire new facts and skills through communication. In this environment, We thank the Facebook AI Research team for stimulating discussions. An early version of this proposal has been discussed in several research groups since 2013 under the name Incremental learning of algorithms.",
    "5": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively. This both Generative methods that produce novel samples from high-dimensional data distributions, such as images, are finding widespread use. Currently the most prominent approaches are Our primary contribution is a training methodology for GANs. We start with low-resolution images, and then progressively increase the resolution by adding layers Salimans et al. (2016) suggest \u201cminibatch discrimination\u2019 as a solution. We simplify this approach drastically while also GANs are prone to the escalation of signal magnitudes as a result of unhealthy competition between the two networks. Most if not all earlier solutions discourage We deviate from the current trend of careful weight initialization. We instead use a trivial N (0, 1) initialization and then explicitly scale the To disallow the scenario where the magnitudes in the generator and discriminator spiral out of control as a result of competition, we normalize the In order to compare the results of one GAN to another, one needs to investigate a large number of images. We noticed that existing methods such In this section we discuss a set of experiments that we conducted to evaluate the quality of our results. We will distinguish between the network structure (e We use sliced Wasserstein distance (SWD) and multi-scale structural similarity (MSSSIM) to evaluate the importance our individual contributions Figure 4 illustrates the effect of progressive growing in terms of the SWD metric and raw image throughput. We observe that the progressive variant offers two main To meaningfully demonstrate our results at high output resolutions, we need a sufficiently varied high-quality dataset. To this end, we created a high Figure 6 shows a purely visual comparison between our solution and earlier results in LSUN BEDROOM. Figure 7 gives selected examples from seven very The best inception scores for CIFAR10 (10 categories of 32 \u00d7 32 RGB images) we are aware of are 7.90 for un While the quality of our results is generally high compared to earlier work on GANs, there is a long way to true photorealism. We would like to thank Mikael Honkavaara, Tero Kuosmanen, and Timi Hietanen for the compute Table 2 shows network architectures of the full-resolution generator and discriminator that we use with the CELEBA-HQ dataset. Both networks consist In this section we describe the process we used to create the high-quality version of the CELEBA dataset, consisting of 30000 images in Figure 9 shows non-curated images generated in the unsupervised setting. Table 3 compares against prior art in terms of inception scores. We Metz et al. (2016) describe a setup where a generator synthesizes MNIST digits simultaneously to 3 color channels. The digits are classified Figure 10 shows the nearest neighbors found for our generated images. Figure 11 gives additional generated examples from CELEBA-HQ. We enabled mirror aug Figures 12\u201317 show representative images generated for all 30 LSUN categories. A separate network was trained for each category using identical parameters. All Figure 18 shows larger collections of images corresponding to the non-converged setups in Table 1. The training time was intentionally limited to make the",
    "6": "Abductive reasoning is inference to the most plausible explanation. We present the first study that investigates the viability of language-based abductive reasoning. On Abductive NLI, the best Abductive reasoning is inference to the most plausible explanation for incomplete observations. Study of abductive reasoning in narrative text has very rarely appeared in the NLP literature. Most previous work on abduct Abductive Natural Language Inference is a problem of multiple choice problems. Each instance in ART is defined as follows: O1: The observation at time t1. O2: A distinct feature of the \u03b1NLI task is that it requires jointly considering all available observations and their commonsense implications, to identify the correct hypothesis. We formulate a set of probabilistic ART is the first large-scale benchmark dataset for studying abductive reasoning in narrative texts. It consists of 20K narrative contexts with over 200K explanatory hypotheses. We crowdsourced the plausible and We now present our evaluation of finetuned state-of-the-art pre-trained language models on the ART dataset. Since \u03b1NLI is framed as a binary classification problem, Crowdsourcing tasks are complex and require creative writing. BERT (Devlin et al., 2018) and GPT (Radford, 2018) have recently been shown to achieve state There is enough scope for considerably scaling up the dataset based on ROCStories. The learning curve in Figure 5 shows that the performance of the best model plateaus after 10,000 instances We train GPT2 conditioned on the tokens of the two observations O1 and O2. ATOMIC (Sap et al., 2019) is a repository of inferential if- Since abduction is fundamentally concerned with plausible chains of cause-and-effect, our work draws inspiration from previous works that deal with narratives. Rather than learning prototypical scripts or narrative chains, we We present the first study that investigates the viability of language-based abductive reasoning. We create and introduce a new challenge dataset, ART, which consists of 20,000 commonsense narratives. We thank the anonymous reviewers for their insightful feedback. This research was supported in part by NSF (IIS-1524371), the National Science Foundation Graduate Research Fellowship under Grant No. Crowdsourcing was used to assess human performance. Participants were asked to write a probable middle sentence that explains why the second observation should follow after the first one. They were then asked to The warmup proportion was set to 0.2, and cross-entropy was used for computing the loss. The best performance was obtained with a batch size of 4, learning rate of The SVM classifier is trained on simple features like word length, overlap and sentiment features to select one of the two hypothesis choices. The bag-of-words baseline computes the average We use BERT (Devlin et al., 2018) as the adversary and introduce a temperature parameter that controls the maximum number of instances that can be modified in each iteration of AF. In ATOMIC (Sap et al., 2019) represents commonsense knowledge as a graph with events are nodes and the following nine relations as edges. Table 8 describes the format of input to each variation of the generative model evaluated.",
    "7": "We describe the class of convexified convolutional neural networks (CCNNs) CCNNs capture the parameter sharing of convolved neural networks in a convex manner. Convolutional neural networks (CNNs) have proven successful across many tasks in machine learning and artificial intelligence. The standard approach to training CNNs is based on solving a non In this section, we formalize the class of convolutional neural networks to be learned and describe the associated nonconvex optimization problem. At a high level, a two-layer CNN1 is a particular type of function that maps an input vector x to an output vector y. This mapping is formed in the following Average pooling and multiple channels are also an integral part of CNNs. We describe a relaxation of the class Fcnn that allows us to obtain a convex formulation of the We now turn to the development of the class of convexified CNNs. We begin in Section 3.1 by illustrating the procedure for the special case of the linear activation function In Section 3, we describe iterative algorithms that can be used to solve this form of convex program in the more general setting of nonlinear activation functions. We propose to minimize For nonlinear activation functions \u03c3, we relax the class of CNN filters to a reproducing kernel Hilbert space (RKHS) Such filters are parametrized by a The algorithm for learning a two-layer CCNN is summarized in Algorithm 1. It is a formalization of the steps described in Section 3.2. In order to solve In this section, we upper bound the generalization error of Algorithm 1. We focus on the binary classification case where the output dimension is d2 = 1. The learning of In this section, we describe a heuristic method for learning CNNs with more layers. The idea is to estimate the parameters of the convolutional layers incrementally from bottom to In this section, we compare the CCNN approach with other methods. The results are reported on the MNIST dataset and its variations for digit recognition, and on the CIFAR We train twolayer and three-layer models respectively. Each convolutional layer is constructed on 5 \u00d7 5 patches with unit stride, followed by 2\u00d7 2 average pooling In order to test the capability of CCNN in complex classification tasks, we report its performance on the CIFAR-10 dataset. We train CNN and CCNN models with two With the empirical success of deep neural networks, there has been an increasing interest in theoretical understanding. Bengio et al. showed how to formulate neural network training as a convex optimization In this paper, we have shown how convex optimization can be used to efficiently optimize CNNs. For the two-layer CCNN, we proved that its generalization error conver In this appendix, we describe the properties of the two types of kernels. We prove that the associated reproducing kernel Hilbert Spaces (RKHS) of these kernels contain filters. The filter is parametrized by an infinite-dimensional vector wj . Our next step is to reduce the original ERM problem to a finite-dimensional one. In order Theory of Rademacher complexity plays an important role in empirical process theory. We refer the reader to Bartlett and Mendelson [4] for an introduction to the theoretical properties",
    "8": "Zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well-regarded Zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well-regarded Since the introduction of Bitcoin in 2008, cryptocurrencies have become increasingly popular. Despite the growing number of legitimate users there are We consider as related all work that has focused on the anonymity of cryptocurrencies, either by building solutions to achieve stronger anonymity Zcash (ZEC) is an alternative cryptocurrency developed as a (code) fork of Bitcoin. In Bitcoin, In this section we describe four types of participants who interact in the Zcash network. Founders took part in the initial We used the zcashd client to download the Zcash blockchain, and loaded a database representation of it into Apache Across all blocks, there were 2,242,847 transactions. The vast majority of transactions are public (i Across all transactions, there have been 1,740,378 distinct t-addresses used. Of these, 8 As discussed in Section 4, a large proportion of the activity on Zcash does not use the shielded pool. This Zcash is a direct fork of Bitcoin and the standard client has the same behavior. In terms of false positives, Given that Zcash is still relatively new, there are not many different types of services that accept Zcash. We Running Heuristic 1 resulted in 560,319 clusters, of which 97,539 contained more than a single address Four out of the top five clusters belong to popular exchanges. Top five clusters accounted for 11.21% of all Although mining pools and founders account for a large proportion of the activity in Zcash, many re-use the same We identified three large organizations that accept Zcash donations: the Internet Archive, torservers.net, and This section explores interactions with the pool at its endpoints, meaning the deposits into (t-to-z) After comparing the list of founder addresses against the outputs of all coingen transactions, we found that 14 of them had The Zcash protocol specifies that all newly generated coins are required to be put into the shielded pool before they can be We gathered 19 t-addresses associated with Zcash mining pools. Figure 10 plots the value of their deposits into Mining pool payouts in Zcash are similar to how many of them are in Bitcoin [27, 18]. Once the miners and founders have been identified, we can assume the remaining transactions belong to more general entities. In this Z-to-z transactions form a crucial part of the anonymity core of Zcash. Our analysis identified 6, The Shadow Brokers (TSB) are a hacker collective that has been active since the summer of 2016. T In May 2017, TSB announced that they would be accepting Zcash for their monthly dump service. To identify potential Before the first TSB blog post in May, we found only a single matching transaction. After the blog post, This paper has provided the first in-depth exploration of Zcash, with a particular focus on its anonymity guarantees. We would like to thank Lustro, the maintainer of the Zchain explorer, for answering specific questions we asked",
    "9": "A critical flaw of existing inverse reinforcement learning (IRL) methods is their inability to significantly outperform the demonstrator Trajectoryranked Reward EXtrapolation (T-REX) uses ranked demonstrations to extrapolate a user's The goal of our work is to achieve improvements over a suboptimal demonstrator in high-dimensional reinforcement learning tasks Inverse reinforcement learning (IRL) seeks to find a reward function that models the intention of the demonstrator. Torabi et al. (2018a) propose a state-of-the-art model-based approach to Very little work has tried to learn good policies from highly suboptimal demonstrations. Grollman & Billard ( Tucker et al. (2018) tested state-of-the-art IRL methods on the Atari domain We model the environment as a Markov decision process (MDP) consisting of a set of states S, actions Trajectory-ranked Reward EXtrapolation (T-REX) is an algorithm for using ranked subopt We first evaluated our proposed method on three robotic locomotion tasks using the Mujoco simulator. In all three tasks To generate demonstrations, we trained a Proximal Policy Optimization (PPO) agent with the ground-truth We trained the reward network using 5,000 random pairs of partial trajectories of length 50. To prevent overfitting Learned Policy Performance We measured the performance of the policy learned by T-REX by measuring the forward distance traveled We next evaluated T-REX on eight Atari games shown in Table 1. To obtain a variety of subopt We used four convolutional layers with sizes 7x7, 5x5, 3x3, and 3 T-REX outperformed both BCO and GAIL in 7 out of 8 games. GAIL was unable The above results used synthetic demonstrations generated from an RL agent. We also tested T-REX when given ground- All experiments described thus far have had access to ground-truth rankings. To explore the effects of noisy rankings we first T-REX is able to infer a meaningful reward function even when noisy, time-based rankings are provided. T-REX is the first IRL algorithm that is able to significantly outperform the demonstrator without additional external This work has taken place in the Personal AutonomousRobotics Lab (PeARL) at The University of Texas Code as well as supplemental videos are available at ICML2019-TREX. Table 1 shows the full results for the MuJoCo experiments. The T-REX (time-ordered) To build the inverse transition models used by BCO we used 20,000 steps of a random policy to collect transitions We used the OpenAI Baselines implementation of PPO with default hyperparameters. We used 9 parallel workers when In this section, we examine the ability of prior work on active preference learning to exceed the performance of the demonstrator We used the Atari Grand Challenge data set (Kurin et al., 2017) to collect actual human demonstrations for We generated attention maps for the learned rewards for the Atari domains. We used the method proposed by Greydanus et",
    "10": "Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen. Until now large scale training and test datasets have been missing. Teaching machines to read natural language documents remains an elusive challenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen. Until now large scale training and test datasets have been missing. Traditional approaches to machine reading and comprehension have been based on either hand engineered grammars or information extraction methods. Supervised machine learning approaches have largely been absent from this space due to the lack of large scale training datasets. We have collected two new corpora of roughly a The reading comprehension task naturally lends itself to a formulation as a supervised learning problem. We seek to estimate the conditional probability p(a|c, q), where c is a context document, q a query relating to that document, and a the answer to that query. Note that the focus of this paper is to provide a corpus for evaluating a model\u2019s ability to read and comprehend a single document, not world knowledge or co-occurrence. To understand that distinction consider for instance the following Cloze form queries (created from headlines So far we have motivated the need for better datasets and tasks to evaluate the capabilities of machine reading models. We proceed by describing a number of baselines, benchmarks and new models to evaluate against this paradigm. The majority baseline (maximum frequency) picks the entity most frequently observed Traditionally, a pipeline of NLP models has been used for attempting question answering, that is models that make heavy use of linguistic annotation, structured world knowledge and semantic parsing. We develop a benchmark thatmakes use of frame-semantic annotations which we obtained by parsing Neural networks have successfully been applied to a range of tasks in NLP. This includes classification tasks such as sentiment analysis or POS tagging. We propose three neural models for estimating the probability of word type a from document d answering query q. Our hypothesis is that neural models should in principle be well suited for this task. We argued that simple recurrent models such as the LSTM probably have insufficient expressive power for solving tasks that require complex inference. We expect that the attention-based models would therefore outperform the The Attentive and Impatient Readers are able to propagate and integrate semantic information over long distances. The attention mechanism that we have employed is just one instantiation of a very general idea which can be further exploited. There are still many queries requiring complex inference and long range The precise hyperparameters used for the various attentive models are as in Table 6. All models were trained using asynchronous RmsProp [20] with a momentum of 0.9. To understand how the model performance depends on the size of the context, we plot performance versus document lengths in Figures 4 and 5. The first figure (Fig. 4) plots a sliding window of performance across document length, showing that performance of the attentive models degrades slightly We consider examples from the Attentive Reader as well as the Impatient Reader in this appendix. Figures 6 and 9 show examples of queries that require reasonable levels of lexical generalisation and co-reference in order to be answered. Figures 10\u201313 shows how the",
    "11": "We propose a new framework for estimating generative models via an adversarial process. We simultaneously train two models: a generative model G and a discriminative model D. The training procedure for G is to maximize the probability of D making a mistake. We propose a new framework for estimating generative models via an adversarial process. We simultaneously train two models: a generative model G and a discriminative model D. The training procedure for G is to maximize the probability of D making a mistake. The promise of deep learning is to discover rich, hierarchical models that represent probability distributions over the kinds of data encountered in artificial intelligence applications. So far, the most striking successes in deep learning have involved discriminative models. We propose a new generative model estimation procedure that sidesteps these difficulties. Deep belief networks (DBNs) are hybrid models containing a single undirected layer and several directed layers. In many interesting generative models with several layers of latent variables, it is not even possible to derive a tractable unnormalized probability density. The adversarial modeling framework is most straightforward to apply when the models are both multilayer perceptrons. To learn the generator\u2019s distribution pg over data x, we define a prior on input noise variables pz(z) We train D to maximize the probability of assigning the correct label to both training examples and samples The generator G implicitly defines a probability distribution pg as the distribution of the samples G(z) obtained when z \u223c pz. We would like Algorithm 1 to converge to a good estimator of pdata, if given enough capacity and training time. We will show in section 4.1 that this minimax game has Proposition 2. IfG andD have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given G, and pg is updated so as to improve the criterion, then pg converges to pdata. We trained adversarial nets an a range of datasets including MNIST[23], the Toronto Face Database (TFD) and CIFAR-10. The generator nets used a mixture of rectifier linear activations and sigmoid activations, while the discriminator net used maxout [10] activations. Drop This new framework comes with advantages and disadvantages relative to previous modeling frameworks. The advantages are that Markov chains are never needed, only backprop is used to obtain gradients, no inference is needed during learning, and a wide variety of functions can be incorporated into the model. The disadvantages are primarily that there is no explicit representation This framework admits many straightforward extensions: A conditional generative model p(x | c) can be obtained by adding c as input to both G and D. Learned approximate inference can be performed by training an auxiliary network to predict zgiven x. We would like to acknowledge Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume Alain and Jason Yosinski for helpful discussions. Yann Dauphin shared his Parzen window evaluation code with us. We would also like to thank CIFAR, and Canada Research",
    "12": "This paper presents a framework for using diverse suboptimal world models to decompose complex task solutions. This framework performs automatic decomposition of a single source task in a bottom up manner. We perform a series of experiments on high dimensional continuous action control tasks to demonstrate the effectiveness Model Primitive Hierarchical Lifelong Reinforcement Learning. In Proc. of the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019), Montreal, Canada, May 13\u201317, 2019. In the lifelong learning setting, we want our agent to solve a series of related tasks drawn from some task distribution rather than a single, isolated task. We draw on the idea of modularity. While learning to perform a complex task, we force the agent to break its We assume the standard reinforcement learning (RL) formulation: an agent interacts with an environment to maximize the expected reward. In a lifelong learning setting, the agent must interact with multiple tasks and successfully solve each of them. The fundamental question in lifelong learning is to determine what knowledge This section outlines the Model Primitive Hierarchical Reinforcement Learning (MPHRL) framework to address the problem of effective piecewise functional decomposition for transfer across a distribution of tasks. The key assumption in MPHRL is access to several diverse world models of the environment dynamics. We use the term model primitives to refer to these approximate world models. The goal of the MPHRL framework is to use these suboptimal predictions to decompose the task space We have shown how MPHRL can decompose a single complex task solution into different functional components. Complex tasks often share structure and can be decomposed into similar sets of subtasks. We transfer the subpolicies to learn target tasks, but not the gating controller or Our experiments aim to answer two questions: (a) can model primitives ensure task decomposition? (b) does such decomposition improve transfer for lifelong learning? We evaluate our approach in two challenging domains: a MuJoCo [29] ant navigating different mazes We focus on two single-task learning experiments where MPHRL learns a number of interpretable subpolicies to solve a single task. Both the L-Maze and D-maze tasks require the ant to learn to walk and reach the green goal within a finite To evaluate MPHRL\u2019s performance in lifelong learning, we generate a family of 10 random mazes for the MuJoCo Ant environment. The agent has a maximum of 3 \u00d7 107 timesteps to reach 80% success rate in each of the 10 tasks. We conduct ablation experiments to answer the following questions. Can MPHRL learn the task decomposition even when the model primitives are quite noisy or when the source task does not cover all \u201ccases\u201d? When does MPHRL fail to decompose the solution? We showed how imperfect world models can be used to decompose a complex task into simpler ones. Our approach does not require access to accurate world models. The recently introduced Neural Processes can potentially be an efficient approach to build upon. We are thankful to Kunal Menda and everyone at SISL for useful comments and suggestions. We are also grateful for the support from Google Cloud in scaling our experiments.",
    "13": "Virtual democracy is an approach to automating decisions, by learning models of the preferences of individual people. One of the key questions is which aggregation method \u2014 or voting rule \u2014 to use. We seek voting rules that are robust to prediction errors. Noothigattu et al. are motivated by the challenge of automating ethical decisions. Their approach consists of three steps: first, collect preferences from voters on exam-related dilemmas. Second, learn models of their preferences, which general Mallows (1957) model is an unusually good fit with our problem. In our setting each voter has a (possibly different) true ranking. The voter\u2019s predicted ranking \u03c3i is drawn from a Mallows distribution around \ufffd A number of recent papers have explored the idea of automating ethical decisions via machine learning and social choice. Our work is motivated by the food bank application of the virtual democracy framework, where the number of voters is small and speed is not of the essence We deal with a set of alternatives A such that |A| = m. Preferences over A are represented via a ranking \u03c3. We denote by \u03c3(j) the alternative ranked in position j in \u03c3, where position 1 is the A voting rule (formally known as a social welfare function) is a function f : Ln \u2192 L, which receives a preference profile as input, and returns a \u2018consensus\u2019 ranking of the alternatives. We are especially interested in In the Mallows (1957) model, there is a ground truth ranking \u03c3?, which induces a probability distribution over perceived rankings. The repeated insertion model (Doignon et al., 2004) provides a convenient alternative way of reasoning about the In the virtual democracy framework, we are faced at runtime with a dilemma that induces a set of alternatives A. For each voter i, we obtain a predicted ranking \u03c3i drawn from a Mallows distribution. The Mallows model itself, because it In this section, we rigorously establish the robustness of Borda count to prediction error by showing that it satisfies a formal version of the desired property stated in Section 1. We do this by building on the machinery developed in Section 3, as well Theorem 1 shows that Borda count is robust against noisy perturbations of the preference profile. We show that there exist profiles in which the pairwise majority graph is acyclic and all edge weights are large. With high probability, the In Section 4 we have established that Borda count is robust to prediction error. However, our positive theoretical result, Theorem 1, only provides asymptotic guarantees. For our evaluation metric, we consider the probability of the rule flipping alternatives when Given n voters, m alternatives, a Mallows parameter \u03c6, and a probability p, we generate a true profile \u03c3? = (\u03c3?1 , . . . , \u03c3 ? n) from a mixture of Mallows models. Throughout our experiments, we let n = 100, m = 40, and p = 1. We plot the average probability of flipping the order of alternatives as a function of the difference in average Borda scores. At a high level, error rate decreases Our theoretical and empirical results identify Borda count as an especially attractive voting rule for virtual democracy, from a statistical viewpoint. Borda counts is also compelling in terms of usability and explainability. In our implemented donor-recipient matching system, clicking on",
    "14": "RPCValet is an NI-driven load-balancing design for architectures with hardware-terminated protocols and integrated NIs. It delivers near-optimal tail latency. RPCValet is an NI-driven RPC load-balancing design for architectures with hardware-terminated protocols and integrated NIs. It delivers near-optimal tail latency Tail-tolerant computing is one of the major ongoing challenges in the datacenter space. The growing number of cores on server-grade CPUs exacerbates the challenge of Modern online services are decomposed into deep hierarchies of mutually reliant tiers, which typically interact using RPCs. Fine-grained RPCs exacerbate the tail latency challenge for services with To study the effect of load balancing across cores on tail latency, we conduct a first-order analysis using basic queuing theory. We model a hypothetical 16-core server after a A subtlety not captured by our queuing models is the practical overhead associated with sharing resources. In a manycore CPU, allowing all the cores to pull incoming network messages from a We design RPCValet for emerging architectures featuring fully integrated NIs and hardware-terminated transport protocols. An important class of online services exhibits RPCs with service times that are frequently The NI\u2019s integration on the same piece of silicon as the CPU is the key enabler for handling \u00b5s-scale events. An integrated NI can, with proper Our design goal is to break the tradeoff between the load imbalance inherent in multi-queue systems and the synchronization associated with pulling load from a single queue. We retain the VIA soNUMA enables rapid remote memory access through a lean hardware-terminated protocol and on-chip NI integration. The conventionally monolithic NI is split into two heterogeneous We devise a lightweight implementation of native messaging as a required building block for dynamic load-balancing decisions at the NI. A key difficulty to overcome is support for multi-packet RPCValet is a single-queue queuing system. It uses a single NI dispatcher to handle message dispatch to all available cores. The dispatch frequencies are modest enough for a We model a single tiled 16-core chip implementing soNUMA with a Manycore NI. The modeled chip is part of a 200-node cluster, with remote nodes Fig. 7a shows the performance of HERD with each of the three evaluatedNI-driven load-balancing configurations. 1 \u00d7 16 consistently delivers the best performance, thanks to Fig. 8 compares the performance of RPCValet to a software implementation. Software requires a synchronization primitive (in our case, an MCS lock) for cores to atomically pull Our results in \u00a76.1 qualitatively meet the expectations set by the queuing analysis presented in \u00a72.2. We now quantitatively compare the obtained results to the ones RPCValet improves tail latency by minimizing the effect of queuing. Queuing is only one of many sources of tail latency, which lie in all layers of the server\ufffd RPCValet is anNI-driven dynamic load-balancing mechanism for\u00b5s-scale RPCs. It behaves like a singlequeue system, without incurring the We thank Edouard Bugnion, James Larus, Dmitrii Ustiugov, Virendra Marathe, Dionisios Pnevmatik",
    "15": "VFDT is an anytime system that builds decision trees using constant memory and constant time per example. VFDT can incorporate tens of thousands of examples per second using off-the-shelf hardware. Categories and Subject Descriptors H.2.8 [Database Management]: Database Applications\u2014 data mining ; I.5.2 [Pattern Recognition]: Design Methodology\u2014classifier design and evaluation. Hoeffding trees can be learned in constant time per example, while being nearly identical to the trees a conventional batch learner would produce, given enough examples. VFDT is I/O bound in the sense that it mines examples in less time than it takes The classification problem is generally defined as follows. A set of N training examples of the form (x, y) is given. The goal is to produce from these examples a model y = f(x) that will predict the classes y of future examples x with high We have implemented a decision-tree learning system based on the Hoeffding tree algorithm. VFDT allows the use of either information gain or the Gini index as the attribute evaluation measure. It includes a number of refinements to the algorithm. A system like VFDT is only useful if it is able to learn more accurate trees than a conventional system, given similar computational resources. In this section we test this empirically by comparing VF DT with C4.5 release 8 on a series of synthetic datasets We conducted a series of lesion studies to evaluate the effectiveness of some of the components and parameters of the VFDT system. Figure 6 shows the accuracy of the learners on the (0.25, 0.00, 25209, 12605) data set. We are currently applying VFDT to mining the stream of Web page requests emanating from the whole University of Washington main campus. One purpose this data can be used for is to improve Web caching. The key to this is predicting as accurately as possible which hosts and pages will Previous work on mining large databases using subsampling methods includes the following. VFDT combines the best of both worlds, accessing data sequentially. It can potentially require much less than one scan, as opposed to many. This allows it to scale to larger databases than VFDT may outperform SPRINT/SLIQ even in fully disk-resident datasets. VFDT\u2019s speed and anytime character make it ideal for interactive data mining. We plan to study its application in this context (see [18]). This paper introduced Hoeffding trees, a method for learning online from the high-volume data streams that are increasingly common. VFDT\u2019s application to a high-speed stream of Web log data is under way. This research was partly funded by an NSF CAREER award to the first author. Machine Learning on Very Large Databases. Megainduction: Machine Learning on very large Databases, University of Sydney, Sydney, Australia.",
    "16": "We present BEAT, a set of practical Byzantine fault-tolerant (BFT) protocols for completely asynchronous environments. BEAT is flexible, versatile, and extensible, consisting of five asynchronous B CCS CONCEPTS \u2022 Security and privacy \u2192 Systems security; Distributed systems security; Computer systems organization. Reliability; Availability;KEYWORDS Byzantine fault tolerance, BFT, asynchronous BFT State machine replication (SMR) is a fundamental software approach to enabling highly available services. Byzantine fault-tolerant SMR (BFT) has recently regained its prominence. BFT has been regarded State machine replication is a technique to provide a fault-tolerant services using a number of server replicas. In SMR, the servers need to communicate with each other and run an interactive consensus protocol Timing assumptions. Distributed systems can be roughly divided into three categories according to their timing assumption: asynchronous, synchronous, or partially synchronous. We consider Byzantine fault-tolerant state machine replication This section reviews the cryptographic and distributed systems building blocks for BEAT. We review robust labeled threshold cryptosystem (i.e., threshold encryption) where a public key is associated with the system and a HoneyBadgerBFT is the most efficient asynchronous BFT protocol known. It favors throughput over latency by aggressively batching client transactions. It can outperform PBFT when the number of servers exceeds 16 This section describes BEAT0, our baseline protocol that uses a set of generic techniques to improve HoneyBadgerBFT. Instead of using CPA/CCA-secure threshold encryption that does not support This section presents two latency-optimized protocols in BEAT: BEAT1 and BEAT2. Most of latency comes from threshold encryption and threshold signatures. When the load is small and there is low BEAT3 significantly improves all performancemetrics that we know of \u2014 latency, bandwidth, storage overhead, throughput, and scalability. BEAT3 can be used for blockchain applications that need append-only This section presents a general optimization for erasure-coded BEAT instances that significantly reduce read bandwidth. Our technique relies on a novel erasures-coded reliable broadcast protocol, AVID-FP-Pyramid HoneyBadgerBFT is 100% Python, and uses the zfec library to implement the Reed-Soloman code, an MDS erasure code. In BEAT, we instead use We deploy and test our protocols on Amazon EC2 utilizing up to 92 nodes from ten different regions in five different continents. We evaluate the protocols under different network sizes (number of replicas) and contention levels We implemented six new protocols (BEAT instances andHB-Bracha) Whilemany of these protocols use similar components, maintaining, deploying, and comparing different BEAT instances takes tremendous effort. We describe the design and implementation of BEAT, a family of practical asynchronous BFT protocols. BEAT protocols are significantly more efficient than HoneyBadgerBFT. We also develop new distributed system ingredients, The authors are indebted to our shepherd Haibo Chen and the CCS reviewers for their helpful comments. Theorem 9.2. Termination is simple, as in AVID-FP. If a correct server initiates disperse, the server erasures codes the transaction, and sends fragments and the fingerprinted",
    "17": "Multi-partition, multi-operation transactional access is often expensive, employing coordination-intensive locking, validation, or scheduling mechanisms.  distributed databases increasingly split their data across multiple servers, or partitions. This strategy succeeds in allowing near-unlimited scalability for operations that In this paper, we consider the problem of making transactional updates atomically visible to readers. The classic strategy for providing atomic visibility is Many database schemas contain information about relationships between records in the form of foreign key constraints. With RAMP transactions, applications can bundle relevant In this section, we formalize Read Atomic isolation and, to capture scalability, formulate a pair of strict scalability criteria: synchronization A system provides Read Atomic isolation (RA) if it prevents fractured reads anomalies and also prevents transactions from reading uncommitted, aborted, or RA does not prevent concurrent updates or provide serial access to data items. RA is an incorrect choice for an application that wishes to maintain positive We consider databases that are partitioned, with the set of items in the database spread over multiple servers. Each item has a single logical Given specifications for RA isolation and scalability, we present algorithms for achieving both. We first focus on providing read-only and write-  RAMP-Fast stores metadata in the form of write sets (overhead linear in transaction size) Each write contains a timestamp that uniquely RAMP-Small uses constant-size metadata but always requires two RTT for reads. In RAMP-S, if a transaction RAMP-H strikes a compromise between RAMP-F andRAMP-S write protocols. Instead of storing the entire write set The RAMP algorithms allow readers to safely race writers without requiring either to stall. RAMP-F is optimized for fast reads, RAM  RAMP transactions rely on multi-versioning to allow readers to access versions that have not yet committed and/or have been overwritten RAMP transactions operate in a distributed setting, which poses challenges due to latency, partial failure, and network partitions. Synchronization independence RAMP algorithms also allow several possible optimizations. Faster commit detection. Metadata garbage collection. One-phase writes. We proceed to experimentally demonstrate RAMP transaction scalability as compared to existing transactional and non-transactional mechanisms. RAMP To demonstrate the effect of concurrency control on performance and scalability, we implemented several concurrence control algorithms in a partitioned,  RAMP performance scales well with increased load and incurs little overhead. With few concurrent clients, there are few concurrent updates and therefore few We also evaluated the overhead of blocked writes in our implementation of the Cooperative Termination Protocol. To simulate blocked writes, we artificially dropped a  RAMP-F achieves slightly under 7.1 million operations per second, or 1.79 million transactions per second on a set of Replicated databases offer a broad spectrum of isolation guarantees at varying costs to performance and availability. At the strong end of the isolation spectrum is This paper described how to achieve atomically visible multipartition transactions without incurring the performance and availability penalties of traditional algorithms. By leveraging The paper is based on a paper by D. Agrawal and V. Krishnaswamy from MIT. The authors argue that We formalize criteria for atomic (read) sets of versions in the form of companion sets. Each write in RAMP-F contains",
    "18": "We are seeing an explosion of uncertain data from sensors in IoT, sampling-based approximate computations and machine learning algorithms. In many cases, performing computations on uncertain data Uncertainty Propagation in Data Processing Systems. In Proceedings of ACM Symposium on Cloud Computing, Carlsbad, CA, USA, October 11\u2013 Data is being produced and collected at a tremendous pace. For many applications, uncertain data should be represented as probability distributions or estimated values with error bounds rather than exact values. Approximate computing is an emerging source of approximation uncertainty. In this setting, it may be possible for the user to tradeoff precision against execution time and/or energy In this section we introduce our proposed methods for handling uncertain inputs at a DAG node. We discuss how to (approximately) compute Y = f (X), where f We use first-order Differential Analysis to approximate the first two moments of Y, i.e., mean and variance, for functions f that are continuous and differentiable We can leverage the above approach for semi-continuous functions when the support of each Xi in X falls mostly or entirely within a continuous and differentiable part of the function We use Monte Carlo simulation to approximate Y for functions f that do not meet (or the developers to not know whether they meet) the requirements for DA. We evaluate f We now discuss how to apply the UP techniques introduced in the last section to data processing DAGs. Figure 3 shows a small example DAG, where uncertainty is introduced As a proof of concept, we extend Hadoop MapReduce to include the above UP techniques. We first show how our approach can be applied to the MapRed In MapReduce, each program runs in two phases, Map and Reduce. In the Map phase, a user-written map() function is invoked per each input ( We implement UP-MapReduce as an extension of Apache Hadoop 2.7. The extension comprises three Mapper and three Reducer classes. Developers must choose We have built a toolbox of common operations (e.g., sum) and modified ten common data processing applications using UP-MapReduce to process uncertain data. In this section, we evaluate UP-MapReduce by studying it\u2019s accuracy, performance, and scalability. We begin by exploring the two applications, t We leverage real datasets for the two approximate applications under study. We evaluate tsocial using the Facebook social structure from SNAP social circles and latency using traceroute measurements from i We leverage UP-MapReduce to build two multi-stage approximate workflows (tsocial and latency) Both first sample their initial dataset and produce uncertain intermediate values. UP-MapReduce estimates the means with very low bias, especially when the input relative errors are small. We observe that input uncertainties can be relatively stable, contract, We explore the scalability of UP-MapReduce by running applications 3-11 on a cluster of 512 servers. We choose the following input sizes: linreg ( In this paper, we showed how Differential Analysis can be used to propagate uncertainties through DAG nodes. Our approach falls back to Monte Carlo simulation of nodes otherwise, but This work was partially supported by NSF grant CCF-1319755.",
    "19": "Most recent datacenter topology designs have focused on performance properties. FatClique attempts to understand the complexity of deploying a performance properties such as latency and throughput. Life cycle management complexity attempts to understand the complexity of deploying a topology and expanding it Lifecycle management is the process of building a network, physically deploying it on a data-center floor, and expanding it Data centers are often designed for high throughput, low latency and resilience. Existing data center designs can be broadly classified into the Deployment is the process of realizing a physical topology in a data center space. Deployment complexity can be reduced by careful Packaging of a topology involves careful arrangement of switches into racks. Placement of switches on the datacenter floor can Based on the previous discussion, we identify several metrics that quantify the complexity of the two aspects of datacenter topology deployment The two topology classes are qualitatively different by these metrics. Jellyfish only needs a little over half the switches compared to The second important component of topology lifecycle management is expansion. Datacenters are rarely deployed to maximal capacity in one shot Expansion is carried out in steps, where at each step, the capacity of the topology is guaranteed to be at least Figure 2 shows an example of Clos expansion. To maintain 87.5% capacity at each pod, only one link is We identify two metrics that quantify expansion complexity and use these metrics to identify differences between Clos and Jellyfish. Number of Expansion Jellyfish requires 3 steps, while Clos twice the number of steps. To understand why Jellyfish requires fewer steps, Clos uses fewer bundle types and patch panels. Jellyfish has significantly lower switch counts. FatClique answers this question affirm FatClique combines the hierarchical structure in Clos with the edge expansion in expander graphs to achieve lower lifecycle management complexity FatClique has fat edges, which allows draining more and more links at each step of the expansion. At each step, FatClique achieves low lifecycle management complexity while ensuring full-bisection bandwidth. It ensures high edge expansion, resulting in In this section, we compare three classes of topologies, Clos, expander graphs and FatClique by our complexity We evaluate complexity across three different topology sizes based on the number of servers they support: small, medium, and large. The placement of patch panels is determined both by the structure of the topology and its scale. For small and medium scale Cl In this section, we evaluate our different topologies by our three measures of deployment complexity (\u00a73.2) Number of In this section, we evaluate topologies by our two measures of expansion complexity (\u00a74.3): number of expansion steps We find that FatClique is the best at most scales by all our complexity metrics. It uses 50% fewer switches and Previous topology designs have focused on cost effective, high capacity and low diameter datacenter topologies like [6, 35 Lifecycle management consists of network deployment and expansion. As the management complexity of networks increases, the importance of designing for manage Algorithm can only generate non-modular topologies as shown in Figure 13. Topology is composed of heterogenous building"
}