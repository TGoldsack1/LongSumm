{
    "0": "We present BEAT, a set of practical Byzantine fault-tolerant (BFT) protocols for completely asynchronous environments. Asynchronous BFT ensures liveness of the protocol without depending on any timing assumptions, which is prudent when the network is controlled by an adversary. HoneyBadgerBFT has significantly higher latency and lower throughput, in part due to its use of expensive threshold cryptography. We show that BEAT is efficient: roughly, all our BEAT instances significantly outperform, in terms of both latency and throughput, Honey badger BFT. There are also new opportunities for asynchronous BFT with the rise of blockchains. We present our findings in CCS \u201918, October 15\u201319, 2018, Toronto, ON, Canada \u00a9 2018 Association for Computing Machinery. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.",
    "1": "Decision-making for autonomous driving is hard due to uncertainty on the continuous state of nearby vehicles. In this paper, we present an integrated behavioral anticipation and decision-making system that models behavior for both our vehicle and nearby vehicles as the result of closed-looppolicies. Each policy is designed to capture a different high-level behavior, such as following a lane, changing lanes, or turning at an intersection. We propose a statistical test based on changepoint detection to identify anomalous behavior of other vehicles. We evaluate our approach using real-world traffic-tracking data from our autonomous vehicle platform, and present decision- making results in simulation involving highway traffic scenarios. The central contributions of this paper are: A changepoint-based behavioral prediction approach that thatleverages the history of actions of a target vehicle to infer the possible behavior of its possible interactions online. An algorithm that evaluates outcomes of modeled actions to account for the likelihood of modeled future actions. An evaluation of the proposed system using both traffic data and simulated scenarios.",
    "2": "Abductive reasoning is inference to the most plausible explanation. For example, if Jenny finds her house in a mess when she returns from work, she can hypothesize that a thief broke into her house and caused the mess. While abduction has long been considered to be at the core of how people interpret and read between the lines in natural language, there has been relatively little research in support of abductive natural language inference and generation. We present the first study that investigates the viability of language-based abductive reasoning. We introduce a challenge dataset, ART, that consists of over 20k commonsense narrative contexts and 200k explanations. On Abductive NLI, the best model achieves 68.9% accuracy, well below human performance of 91.4%. On Ab abductive NLG, the current best language generators struggle even more, as they lack reasoning capabilities that are trivial for humans. Our analysis leads to new insights into the types of reasoning that deep pre-trained language models fail to perform\u2014despite their strong performance on the related but more narrowly defined task of entailment NLI.",
    "3": "Efficient Maximum Inner Product Search (MIPS) is an important task that has a wide applicability in recommendation systems and classification with a large number of classes. We propose to train a spherical kmeans, after having reduced the MIPS problem to a Maximum Cosine Similarity Search (MCSS) This simple approach yields much higher speedups, for the same retrieval precision, than current state-of-the-art hashing-based and tree-based methods. This simple method also yields more robust retrievals when the query is corrupted by noise. All methods discussed in this article are based on the notion of the K-MIPS problem. There is no guarantee that these methods will provide us with candidate sets that are both smaller and related to the actual maximum MIPS vectors. There are no guarantees that the inner product of the candidate sets with the actual KPS is much faster than that of the actual MIPS. We will do an exact K- MIPS, making its computation much faster.",
    "4": "Lifecycle management is the process of building a network, physically deploying it on a data-center floor, and expanding it over several years. With datacenters living on for years, sometimes up to a decade, their lifecycle costs can be high. A data center design that is hard to deploy can stall the rollout of services for months. FatClique is a new class of topologies that, while being performance-equivalent to existing topologies, is comparable to, or better than them by all our lifecycle management complexity metrics. We find that neither class dominates the other, but the other class leads to a more uniform design that leads to fewer bundling (and expander) requirements. We design and synthesize a practical and practical class of FatCliques compared to a novel class of datacenter topologies called Closetric Closets. We show that Closet Closettes have lower overall complexity, and better expansion properties because they have fewer edges to achieve the same network capacity.",
    "5": "In-memory key-value store (KVS) is a key distributed system component in many data centers. KVS enables access to a shared key- Value hash table among distributed clients. With 10 programmable NIC cards in a commodity server, we achieve 1.22 billion KV operations per second. This is almost an order-of-magnitude improvement over existing systems. This approach achieves better performance but degrades performance for PUT operations. We present KV-Direct, a high performance KVS that leverages programmable. NIC to extend RDMA primitives and enable remote direct. access to the main host memory. Compared with CPU based KVS implementation, Kv-Direct improves power efficiency by 3x, while keeping tail latency below 10 \u03bcs. We achieve near linear scalability with multiple NICs. With this approach, the KVS built with this approach is not a perfect fit for building a KVS with RDMA abstraction. Due to the lack of transactional support, the abstraction provided by RDMA is not efficient for building KVS.",
    "6": "Networks are a fundamental tool for understanding and modeling complex systems. Here we develop a generalized framework for clustering networks based on higher-order connectivity patterns. This framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. The framework reveals higher- order organization in a number of networks including information propagation units in neuronal networks and hub structure in transportation networks. We refer to \u03c6(S) as the conductance of S that minimizes the exact set of nodes with respect to M . To minimize the infeasible number of nodes in S that reside in M, we refer to M as \u03c6M(S), or the \u201cM\u2019s\u201d of S (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 84,. 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 94,. 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 111, 116, 113.",
    "7": "We describe a new training methodology for generative adversarial networks. The key idea is to grow both the generator and discriminator progressively. Starting from a low resolution, we add new layers that model increasingly fine details as training progresses. This both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality. We also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised CIFAR10. We suggest a new metric for evaluating GAN results, both in terms of image quality and variation. As an additional contribution, we construct a higher-quality version of the CELEBA dataset. The GAN does not explicitly require the entire training data to be represented by the resulting image quality. The tradeoff is that there is a tradeoff between training quality and conventional image wisdom. We will discuss this in Section 2 of the paper, where we will discuss the formulation of the GAN.",
    "8": "Convexified convolutional neural networks (CCNNs) capture the parameter sharing of CNNs in a convex manner. CCNNs achieve performance competitive with CNNs trained by backpropagation, SVMs, fully-connected neural networks, stacked denoising auto-encoders, and other baseline methods. We prove an oracle inequality on generalization error achieved by our class of CCNNS, showing that it is upper bounded by the best possible performance achievable by a two-layer CNN. We then apply a greedy layer-wise training method to the MNIST handwritten digit dataset as well as four variation datasets. On the CIFAR-10 dataset, we find that CCNN\u2019s outperform CNNs of the same depths, but do not involve the same non-conformity as other methods. For more information, visit: http://www.cs.stanford.edu.uk/news/2013/01/28/convex-convolution-neighboring-network-training-class-ccNNs.html.",
    "9": "In this paper, we propose some fundamental properties these machines should have, focusing in particular on communication and learning. We discuss a simple environment that could be used to incrementally teach a machine the basics of natural-language-based communication. We also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment. A machine capable of performing complex tasks without requiring laborious programming would be tremendously useful in almost any human endeavor, from performing menial jobs for us to helping the advancement of basic and applied research. Given the current availability of powerful hardware and large amounts of machine-readable data, we believe the times should be ripe for the development of intelligent machines. We believe that all aspects of intelligence should be holistically addressed within a single system. Our goal is to build a machine that can learn new concepts through communication at a similar rate as a human with similar prior knowledge. We show that current methods are far from adequate, and we must strive to develop non-incrementally novel techniques.",
    "10": "Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen. Until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure. Our results indicate that the neural models achieve a higher accuracy, and do so without any specific encoding of the document or query structure. The supervised paradigm for training machine reading and comprehension models provides a promising avenue for making progress on the path to building full natural language understanding systems. There are still many queries requiring complex inference and long range reference resolution that our models are not yet able to answer. As such our data provides a scalable challenge that should support NLP research into the future. Further, significantly bigger training data sets can be acquired using the techniques we have described, undoubtedly allowing us to train more expressive and accurate models.",
    "11": "RPCValet is an NI-driven load-balancing design for architectures with hardware-terminated protocols and integrated NIs. It delivers near-optimal tail latency. The design improves throughput under tight tail latency goals by up to 1.4\u00d7. Tail-tolerant computing is one of the major ongoing challenges in the datacenter space, as long-tail events are rare and rooted in convoluted hardware-software interactions. The focus of optimization will shift to efficiently handling RPCs at the endpoints, as soon as they are delivered as delivered by BlueFields or Mellanox\u2019s BlueField SmartNICs. The net result of rapid advancements in the networking world is that inter-tier communication will be even lower latency, the authors say. The research was published in ACM's 2019 Architectural Support for Programming Languages and Operating Systems (ASPLOS \ufffd\u201919), April 13\u201317, 2019, Providence, RI, USA. For confidential support call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org.",
    "12": "We present algorithms for Read Atomic MultiPartition (RAMP) transactions that enforce atomic visibility while offering excellent scalability. RAMP transactions correctly mediate atomic visibility of updates and provide readers with snapshot access to database state by using limited multi-versioning. We demonstrate that, in contrast with existing algorithms, RAMP Transactions incur limited overhead\u2014even under high contention\u2014and scale linearly to 100 servers. We subsequently develop three new, scalable, non-serializable isolation model called Read Atomic (RA) Transactions. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Copyright is held by the owner/author(s). Publication rights licensed to ACM 978-1-4503-2376-5/14/06 ...$15.00. The proliferation of non-transactional multi-item operations is symptomatic of a widespread \u201cfear of multi- item operations\u201d at scale.",
    "13": "We are seeing an explosion of uncertain data from sensors in IoT, sampling-based approximate computations and machine learning algorithms. In many cases, performing computations on uncertain data as if it were exact leads to incorrect results. We present a framework for uncertainty propagation (UP) that allows developers to modify precise implementations of DAG nodes to process uncertain inputs with modest effort. We implement this framework in a system called UP-MapReduce, and use it to modify ten applications, including AI/ML, image processing and trend analysis applications. Our evaluation shows that UP- mapReduce propagates uncertainties with high accuracy and, in many cases,. low performance overheads. The results demonstrate that our UP framework presents a compelling approach for handling uncertain data in DAG processing, we say. The framework is based on techniques that allow programmers to modify DAG computation nodes to handle uncertain inputs. It then runs applications on clusters of servers, transparently handling issues such as task scheduling, data movement, and fault tolerance.",
    "14": "VFDT can incorporate tens of thousands of examples per second using off-the-shelf hardware. It uses Hoeffding bounds to guarantee that its output is asymptotically nearly identical to that of a conventional learner. We apply VFDT to mining the continuous stream of Web access data from the whole University of Washington main campus. We describe and evaluate a decision-tree based on VF DT, and evaluate and evaluate another system based on Hoefding trees. It is an algorithm in the sense that it is an anytime algorithm in a sense that I/O is ready to be stored. It does not store any examples (or parts thereof) in main memory, requiring only space proportional to the size of the tree and associated statistics. It can learn from each example only once, therefore does not require an online stream to ever be ready. It takes less time than it takes to mines examples in less time to take them from input to output. We demonstrate its utility through an extensive set of experiments on synthetic data.",
    "15": "Inverse reinforcement learning (IRL) typically seeks a reward function that makes the demonstrator appear near-optimal. In this paper, we introduce a novel reward-learning-from-observation algorithm, Trajectory-ranked Reward EXtrapolation (T-REX), that extrapolates beyond a set of (approximately) ranked demonstrations. When combined with deep reinforcement learning, T-REx outperforms state-of-the-art imitation learning and IRL methods on multiple Atari and MuJoCo benchmark tasks and achieves performance that is often more than twice the performance of the best demonstration. We also demonstrate that T- REX is robust to ranking noise and can accurately extrapolate intention by simply watching a learner noisily improve at a task over time. The paper will be presented at the 36 th International Conference on Machine Learning, Long Beach, California, PMLR 97, 2019. For. confidential support, call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit www.suicidepreventionlifeline.org.",
    "16": "This paper presents a framework for using diverse suboptimal world models to decompose complex task solutions. This framework performs automatic decomposition of a single source task in a bottom up manner. The same model primitives are used to learn a gating controller to select, improve, adapt, and sequence the various subpolicies to solve a given task. We hypothesize that many complex tasks are heavily structured and hierarchical in nature. The likelihood of transfer of an agent\u2019s solution increases if it can capture such shared structure. We propose an architecture to jointly train task decompositions in the context of a specific task-based reward structure. To summarize our contributions, we propose an amhodethod architecture to train task decomposed structures. We will present our findings at the 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019), May 13\u201317, 2019, Montreal, Canada. We hope to see you at the conference in Montreal, May 13-17.",
    "17": "We propose a new framework for estimating generative models via an adversarial process. We simultaneously train two models: a generative model G that captures the data distribution and a discriminative model D that estimates the probability that a sample came from the training data rather than G. This framework corresponds to a minimax two-player game. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples. This paper has demonstrated the viability of the adversarial modeling framework, suggesting that these research directions could prove useful in the field of artificial intelligence. The paper has been published in the open-source journal CIFAR, which can be downloaded for free at: http://www.cifar.org/cgi-bin/CIFAR/2013/01/26/13/14/1314/1414/15/1315/1415/1515/1115/12/12.html. All code and hyperparameters are available at X.R.V.I.P. (X-R-V-I-P-P)",
    "18": "Among the now numerous alternative cryptocurrencies derived from Bitcoin, Zcash is often touted as the one with the strongest anonymity guarantees. In this paper, we examine the extent to which anonymity is achieved in the deployed version of Zcash. While it is possible to use Zcash in a private way, it is also possible to shrink its anonymity set considerably by developing simple heuristics based on identifiable patterns of usage. We conclude that the vast majority of activity in the transparent part of the Zcash blockchain is in fact in the same way as in the public part of Bitcoin. We provide the first empirical analysis of these claims in order to examine these claims and more generally provide a longitudinal study of how Zcash has evolved and who its main participants are. We also provide a general examination of the general Zcash chain, from which we observe that the majority of transactions in Zcash are typically developed for Bitcoin and have been typically used for exchanges with other cryptocurrencies such as Monero, Dash, and others.",
    "19": "Virtual democracy is an approach to automating decisions, by learning models of the preferences of individual people, and, at runtime, aggregating the predicted preferences of those people on the dilemma at hand. One of the key questions is which aggregation method \u2014 or voting rule \u2014 to use. We seek voting rules that are robust to prediction errors, in that their output on people\u2019s true preferences is likely to coincide with their noisy estimates thereof. We prove that the classic Borda count rule is robust in this sense, whereas any voting rule belonging to the wide family of pairwisemajority consistent rules is not. We have been building on this approach in a collaboration with a Pittsburgh-based non-profit, 412 Food Rescue, that provides on-demand food donation distribution services. The goal is to design and deploy an algorithm that would automatically make the decisions they most frequently face: given an incoming food donation, which recipient organization (such as a housing authority or food pantry) should receive it?"
}