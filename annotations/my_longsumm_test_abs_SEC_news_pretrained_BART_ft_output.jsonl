{
    "0": "The paper presents some general characteristics that intelligent machines should have, focusing in particular on communication and learning. Ability to Communicate  The intelligent agents should be able to communicate with humans, preferably using language based communication The paper presents some general characteristics that intelligent machines should possess and a roadmap to develop such intelligent machines in small, realistic steps. Ability to Communicate  The intelligent agents should be able to communicate with humans, preferably at This paper presents a set of desiderata that we believe are crucial for an agent to be able to make its own decisions and to assist humans in their endeavors. The underlying idea is that by learning these des The paper presents a learning environment for learning how to communicate with humans via natural language. The learning environment is designed to emphasize the interactive nature of communication and the transfer of communication across different channels. Link to the The main flaw in \u201cgood old\u201d symbolic AI research is the assumption that it would be possible to program an intelligent machine largely by hand. We believe it is uncontroversial that a machine supposed to be The paper describes an ecosystem to teach the basics of linguistic interaction to an intelligent machine and how to use it to operate in the world. The ecosystem is seen as a \u201ckindergarten\u201d providing basic The Learner (the system to be trained) is an actor in this ecosystem. The Teacher assigns tasks and rewards the Learner for desirable behaviour, and it also provides helpful information, both spontaneously and in response to The Learner has to learn to pay attention to the Teacher, to identify the basic units of language and to develop sequence repetition and manipulation skills. The Teacher guides the Learner from these basic skills to be able The paper provides an example how an intelligent machine could be used in the real world. The machine is an assistant to Alice, an elderly person living alone. The input to the system is a sequence of questions about This paper presents some ideas about how to build intelligent machines that would benefit from the learning environment we described in the previous section. While we do not have a concrete proposal yet about how exactly such machines should be implemented, The goal is to build an intelligent machine that can translate between languages. The machine will have to understand the concept of positive and negative reward, and develop complex strategies to deal with novel linguistic inputs. Let\u2019s The paper presents a new learning skill for intelligent machines, i.e. a compositional learning skill with the capability of producing new structures in its long-term memory. The Learner can learn new structures The intelligent machine should be based on a Turing-complete computational model. That is, it has to be able to represent any algorithm in fixed length, just like the Turing machine. \u2026 we are not interested in building The paper presents a roadmap for learning tasks based on imitation in an imitation game setting. The goal is to develop a machine that is able to interact with other agents through various communication channels (i.e. The paper presents a simulated ecosystem for learning new facts and skills through communication. In this environment, the machine must learn to perform increasingly more ambitious tasks, being naturally induced to develop complex linguistic and reasoning abilities. The environment This paper presents a framework for fine-tuning a neural network architecture by leveraging the latent space of hidden units in a network. Bottou, LeCun, & Synnaeve, 2017  The",
    "1": "The basic idea is to introduce a curriculum into the GAN training procedure. One starts by training the generator to produce 4 x 4 images, progressively What  Currently, the most common approaches are autoregressive (i.e. use a VAE) and generative adversarial What  They suggest a progressive growing method for GANs where at each timestep, the generator starts with a low resolution image and What  They suggest \"minibatch discrimination\" where the discriminator learns a large tensor (similar to activation matrix) that projects the GANs prone to the escalation of signal magnitudes as a result of unhealthy competition between the two networks. Most if not all earlier solutions discourage this This paper proposes a radical change in the traditional weight initialization scheme. Instead of using a careful weight initialization, the authors use a trivial N What  They normalize the feature vector in each pixel of the generator (layer i) so that it doesn't spiral out of control What  The paper samples patches from the Laplacian pyramid representation of images and compares them with each other in an GAN. This section describes the following experiments:  Network structure (e.g. convolutional layers, resizing, multiple normalization layers What  They generate images using LSUN BEDROOM and LeakyReLUs. They place a DNN in charge of generating What  Progressive growing is a method to train CNNs at higher resolutions (e.g. 2x, 4x, 8x This paper presents a high-quality version of the CELEBA dataset consisting of 30000 of the images at 1024 \u00d7 1024 resolution. The authors What  They compare LSUN bedrooms with each other. The goal is to find a solution that improves the overall quality of the images. They The paper uses the WGAN-GP in the unsupervised setting to achieve the best CIFAR-10 inception score (7 What  The paper reports that for the CIFAR component of the GAN, for the first time a model has been trained to The paper thanks Mikael Honkavaara, Tero Kuosmanen, and Timi Hietanen for their contributions to What  They suggest a simple architecture for GANs, similar to previous work by Gulrajani et al (2017)  What  The paper describes the process of creating the high-quality version of CELEBA dataset, with 30000 images in 1024x What  Inception score computed from the logarithm of the images generated in an unsupervised setting. Comparison with prior art in What  They describe a setup where a generator synthesizes MNIST digits simultaneously to 3 colour channels and concatenates them into a number in [ What  The paper samples images from Google Maps and uses various features like Wasserstein distance (SWD), Freaky Inception Distance What  They generate an image dictionary for all 30 LSUN categories (30 of them in total) and train a network for each category The training time was intentionally limited to show the differences between methods and to make them more visible.",
    "2": "This paper describes a convexified neural network (CCNN) that can be used in a layer-wise manner to train deeper networks. Benefits  Convolutions between layers Convolutional Neural Networks have been successful in many domains such as image classification, speech recognition, text classification and game playing. The paper proposes a new model class called This section describes how CNNs are used in classical optimization algorithms and how they can be used in a non-convex optimization problem. Convolutional Neural Networks  What  They suggest a method to get cumulative/aggregated gradients from a patch of vectors (each with a different weight vector) to an output vector of the same What  Assume that we have an input-output pair (x, y) and a CNN f (of different classes) and let L(f(x; The paper describes a convexification procedure for nonlinear activation functions, corresponding to the special case of the linear activation function. Convolutions  Learn how to embed the What  The basic idea is to have a given function f(x) = (x - 1) and for each x in a set of patches $x$, define a What  The paper shows that for non-linear activation functions \u03c3, the class of CNN filters can be reduced to a reproducing kernel Hilbert space (RKHS What  The given problem is to learn a two-layer CCNN. The network is either composed of feedforward networks (one forward network per image) or feedforward conv This paper considers networks that have a binary classification problem and proposes a special case of softmax. The paper shows that for a given network, there is a kernel function K What  The heuristic method for learning CNNs with more layers is called Algorithm 2. The basic idea is to estimate the parameters of the convolutional layers in CCNN  Computes an MNIST dataset containing images and their variations for digit recognition and CIFAR-10 classification. Shows a consistent performance across all the datasets. Notes What  They consider variations of the classic convolutional learning rate method, i.e. they consider methods where the learning rate doesn't depend on the number of filters What  They train a model on CIFAR-10, for classification problems. The model has layers of (two, three, four) convolutional layers. Each conv This paper discusses an ensemble of methods to learn fully connected neural networks, in the unsupervised setting. The method is based on the idea of a convex optimization problem What  They suggest a method to optimize CNNs and to understand them statistically. Their method is based on nuclear norm relaxation and RKHS relaxation. How  Convolutions This paper presents a duality of kernels \u2014 the inverse polynomial kernel and the Gaussian RBF kernel. The authors show that the associated reproducing kernel Hilbert Spaces ( This paper presents a derivation of the relaxation of non-linear activation functions using the identity activation function \u03c3. The underlying idea is that if the loss function Q is Consider a function class Fccnn with the RKHS formulation of the activation function \u03c3. The paper shows that fccnn is an empirical risk minimizer within",
    "3": "This paper presents a new approach to automating decisions in the virtual democracy setting by learning the preferences of individual people and aggregating the predicted preferences of those people on the given dilemma. The key question here is which aggregation method \u2014 or voting rule The paper proposes a method to predict the preferences of voters in an ethical dilemma using a model of their preferences and then aggregate those predicted preferences to arrive at a decision. The method is referred to as \u2018virtual democracy\u2019 because the idea This paper presents the idea of using the classic Mallows model for ranking alternatives in the knowledge distribution setting. This knowledge distribution is parameterized by a parameter \u03c6 (synthesized version of the Kendall Tau distance) and is related to This paper presents a general question about the foundations of virtual democracy. Specifically, they pose a new question: \u201cwhat does virtual democracy look like in the context of a food bank?\u201d Their work is motivated by the food bank application of Consider a set of alternatives to each other such that  |A| = m. We want to say that x is preferred to y according to \u03c3 (i.e. x < y) where \u03c3 is the ranking factor. We denote What  A voting rule is a function f : Ln \u2192 Ln and produces a \u2018consensus\u2019 ranking of the alternatives in preference profile \u03c3. Each such rule is defined by a score vector (\u03b11, \u2026 Let the Kendall tau distance between two rankings \u03c3, \u03c3\u2032 and L be  The basis for the paper is two ranking models, called as Mallows and PPO. In the Mallows model, there is a ground truth ranking \ufffd This paper presents a new twist on theymmetric voting distribution in the context of a food bank system. The setting is the task of predicting a ranking  over a set of alternatives in order to receive a donation. Each voter  has a The paper shows that Borda count to prediction error theorem satisfies a formal version of the desired property stated in Section 1. The theorem bounds the probability that the noisy Borda ranking (based on the sampled profile) would disagree with the true Bord Theorem 1:  Borda count is robust to noisy perturbations in the preference profile  Theorem 2:  Any voting rule that belongs to the important family of PMC rules is not robust in a similar sense  Recall that under Theorem 1:  Borda count is robust to prediction error  Theorem 1 - Theorem guarantees that for any given Borda operation, there exists a version of the Borda code that can tolerate incorrect predictions. However, this proof Given n voters, m alternatives, a Mallows parameter \u03c6, and a true profile \u03c3? = ( \u03c6 * \u03c3 ? n) with probability p (with base ranking x1, \u2026, xm ) and parameter The paper tests the following hypothesis, about the average probability of flipping an alternative over a given alternative in the face of an average Borda score difference:  $$P(\\text{subset } Y) = \\frac{det(L Borda Count  An especially attractive voting rule for virtual democracy, from a statistical viewpoint. Borda count is also compelling in terms of usability and explainability. In more detail, in our implemented donor-recipient matching system, clicking on a",
    "4": "What  BEAT is a collection of five asynchronous BFT protocols (for completely asynchronous environments) that are designed to work well in an asynchronous environment. They present a 92-instance, five-continent CCS CONCEPTS: State and privacy in the context of distributed systems security, reliability, availability, and interoperability. Today\u2019s paper choice won a best paper award at the recent AC HoneyBadgerBFT: Artistic justification for an asynchronous BFT protocol Zhuo et al., CCS\u201918  We\u2019re transitioning to look at a selection of papers The (subtle) differences between BFT SMRand (BFT) and BEAT4  State machine replication (SMR) is a general technique to provide a fault-tolerant services What  BFT protocols are composed of two parts:  A service that maintains a key-value store and a replica that updates the value of the key. If a request is submitted to such a service This section reviews the cryptographic and distributed systems building blocks for BEAT. We review robust labeled threshold encryption (i.e. threshold encryption) where a public key is associated with the system and a decryption What  HoneyBadgerBFT is an efficient BFT protocol with an asynchronous common subset (ACS). It uses RBC and a binary agreement (ABA) to achieve high throughput and low This paper describes BEAT0, a secure and efficient threshold encryption protocol that includes a direct implementation of threshold coin flipping and more flexible and efficient erasure-coding support. Benefits over previous models  Faster This section presents two BEAT protocols - BEAT1 and BEAT2 - optimized for low contention and high throughput. Most of the latency in BEAT comes from threshold encryption and threshold signatures, This BEAT3 system is like HoneyBadgerBFT, but uses an ABA protocol instead of a reliable broadcast. Benefits  Faster than AVID-CT, but with less throughput and This paper presents an erasure-coded reliable broadcast protocol, AVID-FP-Pyramid, that reduces read bandwidth for BEAT instances. A demonstration lemma and the benefits of having different data What  They implement six BFT protocols, including five BEAT protocols and one HB-Bracha-based implementation. The six protocols themselves involve 6,000 to 8,000 lines of code in Python The BEAT4 and BEAT3 protocols are compared with each other in the Amazon EC2 dataset using up to 92 nodes from ten different regions across five continents. Each node is a general pur What  BEAT is like  It\u2019s been a while since we gave formal introduction to BEAT and the subsequent work since then has been published. In short:  We implemented six new The BEAT family of asynchronous BFT protocols \u2013 Golan-Gueta et al. 2016  BEAT is a family of practical asynchronous B FT protocols that are efficient, flexible, versatile, and ext The authors are indebted to our shepherd Haibo Chen and the CCS reviewers for their helpful comments that greatly improve our paper. The paper has been extensively rewritten and improved upon. The work has also Theorem  If a correct server initiates disperse, the server erasures codes the transaction and sends fragments and the fingerprinted cross-checksum to all servers. Each server will eventually receivem + \ufffd",
    "5": "The paper proposes a new inverse RL (IRL) method, called as Trajectory-ranked Reward EX The paper proposes a new inverse RL (IRL) algorithm, called as Trajectory-ranked Reward The paper presents a method to train a Deep RL agent online without using a hand-specified reward function or supervision. In the traditional heirarchical policy learning approach, the goal is to learn a policy that imitates the actions taken Torabi, et al., 2018  There is a shift towards learning from observations in which the actions taken The paper explores the problem of learning good policies from highly suboptimal demonstrations. One possible approach is to minim This paper presents Ibarz et al. (2018) a new deep learning algorithm for Atari games. This paper presents a method for ranking trajectories in the MDP setting using a mixture of Markov Decision Process The proposed idea is to use ranked suboptimal demonstrations to learn a reward function that can predict which trajectory The paper proposes a method to train RL agent in 3 tasks within OpenAI Gym - HalfCheetah The paper demonstrates how Proximal Policy Optimization (PPO) can be used for optimization. Implementation  Bas The reward function r*(s) is represented by an ensemble of five deep neural networks, each having The paper tests the learned policy of T-REX against Behavior Cloning from Observations (BCO The paper evaluates T-REX on 12 Atari games (All games except Enduro) using PPO policies The paper used an Adam reward function with four convolutional layers with strides 3, 2, 1, The average performance of T-REX under the ground-truth reward function and the best and average performance The paper uses human demonstrations from the Atari Grand Challenge Dataset to evaluate the capabilities of T-REX The paper explores the effect of noisy human rankings on the Atari Hopper task. Evaluation  Start with a The paper tests if T-REX can work without explicit rankings like those used in Mujoco tasks. Test T-REX is an IRL algorithm that can learn to extrapolate intent from suboptimal ranked demonstrations. This work has taken place in the Personal Autonomous Robotics Lab (PeARL) at The University of Texas at Code as well as supplemental videos are available at ICML\u201919-TREX. All the code is The paper visualizes the T-REX (Time-ordered Experimental Policy Learning) for HalfCheetah What  They suggest a new inverse transition model for BCO. Their model predicts actions given state transitions and What  They suggest a modified PPO algorithm for Enduro. Their algorithm uses 9 parallel workers and has a learning The paper tests if a DQf-A neural network can learn a policy that outperforms the demonstration The paper used the Atari Grand Challenge data set to collect actual human demonstrations for five Atari games. We used the ground What  They generate attention maps of the learned rewards for the Atari domains using the 3x3 mask method",
    "6": "This paper presents a new model of vehicle policy evolution in highway traffic. The model makes use of a discrete set of closed-loop policies This paper presents a behavioral anticipation and decision-making system that models the behavior of both our vehicle and nearby vehicles. The system is trained Despite the probabilistic nature of the anticipation problem, some approaches in the literature assume no uncertainty on the future states of other participants in The paper presents a new model of decision making in the context of a self-driving car, based on the 2007 DARPA Urban Challenge This paper presents a multi-agent POMDP based on the problem of decision making in an uncertain environment with tightly coupled interactions between multiple This paper presents a simple, yet effective approach for modeling the dynamics of vehicles in an environment. The motivation behind the paper is to investigate The paper makes approximations to sample from the likely interactions of traffic agents. At any point in time, both our vehicle and other vehicles are This paper provides a detailed look at a neural network architecture used to predict the policies of other cars based on the history of observed states of What  CHAMP is an algorithm to segment a target car\u2019s history of observed states. Ith segment consists of observations z This paper presents a method to estimate the latent probability  of each latent policy by leveraging changepoint detection on the history of observed vehicle states. Specifically What  They define two criteria for anomalous behavior:  (1) Unlikelihood against available policies. (2) Ambiguity among policies This paper presents a policy selection procedure for our car, inspired by the trajectory prediction algorithm from Section IV, Automobile Policy Optimization in A lane-nominal, drive in the current lane and maintain distance to the car directly in front policy  lane-change-right/ What  They suggest a lower-fidelity simulation of vehicle interactions between vehicles that assumes an idealized steering controller. This simplified simulation can The reward function for a rollout involving all vehicles is a weighted combination of metrics mq( \u00b7) \u2208 M with weights wq The paper uses traffic-tracking data collected using Uber\u2019s autonomous vehicle platform to evaluate its prediction and anomaly detection algorithm and the performance What  The paper describes a traffic-tracking dataset of trajectories recorded in an urban area. Of the 67 trajectories, 18 are \ufffd For our system, we are interested in correctly identifying the behavior of target vehicles by associating it to the most likely policy according to the The test covers three additional trajectories of two bikes and a bus. The bikes crossed the intersection from the sidewalk while the bus made a significantly The paper presents a sampling strategy similar to an uninformed sampling strategy where the decision of whether to yield or go straight is decided at the The paper tests the full decision-making algorithm with behavioral prediction in a simulated highway scenario involving two nearby cars. Policy choice is made instantaneous This paper presents a principled framework for integrated behavioral anticipation and decision-making in environments with extensively coupled interactions between agents. By explicitly modeling the behaviors of This work was supported in part by a grant from Ford Motor Company via the Ford-UM Alliance and DARPA. The authors are sincerely",
    "7": "This paper proposes a simple approach to solve the optimization problem of Maximum Inner Product Search (MIPS) in recommendation systems and classification systems with a large number of classes. The approach is based on the k-means clustering algorithm. Specifically, they train a spherical kmeans network to predict the similarity scores of This paper presents a simple yet effective approach for solving the K-MIPS problem in recommendation systems where the input to the system is a list of items to be recommended and the goal is to rank the items on the basis of their similarity to other items in the same set. The problem is challenging because the inner product What  They suggest a simple k-means clustering based solution for approximate MIPS. The method is based on a combination of tree-based and hash-based methods. How  They base their system on an MIPS system  They have two components in their network:  Ball Tree:  They use a ball This paper follows in the footsteps of  [ref]  and extends the Bailis-Shrivastava-Li algorithm for spherical k-means clustering (which uses a boosting method to increase the similarity between points in a dataset). The method can be extended to find the k-best matching points The paper presents a proposed algorithm for approximate MIPS which has the following characteristics:  speedup, compared to the exact full linear search, of retrieving top-K items with largest inner product, and robustness of retrieved results to noise in the query. What  They describe a dataset of 10677 movies with 10,677 movies and 69,888 users. They build a database of word embedding vectors for each movie. They consider 60,000 randomly selected users as queries. How  They compute an SVD approximation of the user-item matrix Z with its top What  They suggest a new base that converts MIPS to NNS by appending an extra component to the vectors. The extra component is appended to ensure that they are of the same norm. Then the principal directions are learnt and the data is projected using these principal directions. How  Architecture  They use PC The paper takes two common K-MIPS algorithms, k-means and PCA-Tree, and compares the speedup provided by each algorithm with respect to the total cost of the other algorithms. Speedup is defined as the time taken by Algorithm A0 for processing the inner product with all training items The paper considers a word embedding retrieval task using a query set of 2,000 embeddings. Note that while a query is thus present in the database, it is not guaranteed to correspond to the top-1 MIPS result. Top-10 and top-100 MIPS performance:  Algorithms which perform The paper presented a simple approach to solve approximate K-MIPS (aka, off-line learning objective) for large datasets. The approach achieved a larger speedup while maintaining precision and is more robust to input corruption, as the query test points were expected to not be exactly equal to training data points. Clustering The authors would like to thank the developers of Theano (Bergstra et al., 2010) for developing such a powerful tool. We acknowledge the support of the following organizations for research funding and computing support: Samsung, NSERC, Calcul Quebec, Compute Canada, the Canada Research Chairs and CIFAR.",
    "8": "VFDT: A system for learning by iterating over streams of data \u2013 Gog et al. 2009  VFDT is a anytime system that builds decision trees using constant memory and constant time per example. It can incorporate tens of thousands of examples per The paper introduces:  (1) Decision trees, Hoeffding bounds, incremental learning, diskbased algorithms, subsampling  (2) Subject Descriptors  The paper also describes a methodology for evaluating the results of a given classifier or This paper presents a tree learning algorithm for large datasets \u2013 in the sense that it uses up to 10K unique (and potentially very large) examples in a batch setting. This is in contrast to many other data mining applications where the computational resources for a massive search The paper presents a classification problem where the input is a sequence of N training examples and the goal is to produce from these examples a model that predicts the classes y of future examples x with high accuracy. The problem is designed so that the number of examples per node What  They suggest a version of the Hoeffding tree algorithm they call VFDT (Very Fast Decision Tree learner) that also learns an evaluation measure called the Gini index. That evaluation measure is used to decide whether two attributes have very similar G\ufffd Comparing VFDT with C4.5: Learning trees with similar number of nodes to VF-boot on a fraction of the nodes \u2013 Catlett et al. 2014  Today\u2019s paper choice studies methods for learning trees faster than VF The paper tests different aspects of VFDT and shows that they improve over time. Some of the reasons are:  Noise around the nodes leads to lower accuracy. The leafs are not very informative, because they only produce 0.5-1% higher accuracy. What  They extract a one-week anonymized trace of web page requests from the University of Washington main campus. The trace contains 82.8 million requests averaging 17,400 per minute. Each request is tagged with an anonymized organization ID that associates the request with This paper presents a heuristic method to extend RAM based batch decisiontree learners with up to hundreds of thousands of examples. The method, VFDT, combines the best of both worlds, accessing data sequentially and using subsampling to potentially require much less than one What  They compare VFDT with SPRINT and SLIQ in terms of speed and cost. Speed = 0, while SLIQ requires multiple times the number of scans. Cost = M*(sparsely-assembled-data) / summing over This paper introduces Hoeffding trees, a method to learn online data streams in small, constant time per example and with high asymptotic similarity to corresponding batch trees. VFDT is a high-performance data mining system based on the idea of This research was partly funded by an NSF CAREER award to the first author. The paper describes a scenario in which a neural network is used to predict the output of neural networks, and then these predictions are used to train and fine tune neural networks for specific What  The paper introduces a new approach to classify data using regression trees. The approach is based on the observation that if two components of a dataset are involved in a classification process, they should be grouped in a similar way. The paper uses progressive sampling to compute",
    "9": "Learning to read natural language documents Bhattacherjee et al., ICLR 2017  Today\u2019s paper choice is short and sweet, but thought provoking nonetheless. To a man with a hammer (sticker), everything looks like a puzzle. There\ufffd Learning to read natural language documents Bhattacherjee et al., ICLR 2017  Today\u2019s paper choice is short and sweet, but thought provoking nonetheless. To a man with a hammer (sticker), everything looks like a puzzle. There\ufffd The paper presents a new approach to building a supervised reading comprehension data set. The paper shows that the proposed model, coined corpora, outperforms a wide variety of baselines and heuristic models without any specific encoding of the document or query structure. Idea  Use of The paper presents a method to generate large scale supervised training data for machine comprehension models. The method is based on extracting information from online newspaper articles and their matching summaries. Idea  Two machine reading corpora (mCPC) are created - one for CNN and The paper presents a new ngram language model trained on the Daily Mail website for the task of answering the above two questions. Note that the focus of this paper is to provide a corpus for evaluating the model\u2019s ability to read and comprehend a single document This paper describes a number of baselines, benchmarks and new models to evaluate the capabilities of machine reading models. The baselines  Most Frequent Majority baseline  Maximizes the entity most frequently observed in the context document while the exclusive majority (exclusive frequency) chooses Problem Statement  Given a question and a context document d, produce an answer to the question using a number of rules. The authors pretend that all PropBank triples are of the form (e1, V, e2) to extract the information about \u201cwho The paper proposes three neural models for predicting the probability of word type a from document d for any given query q. Each model is fed one word at a time into a Deep LST-CNN network and the end result is a vector representation of q and d The paper tests different attention mechanisms used by machine translation models for reading comprehension task and shows that they perform competitively against systems based on language modelling capabilities of neural models. Experimental Setup  Two datasets - DailyMail Dataset  Subjectively more questions per question than The paper demonstrates how Attentive and Impatient Readers (A&IM) can be used in a multi-document query setting to train a machine translation model. Most important observation is that the model can propagate and integrate semantic information over long distances. Attention and Embedd The precise hyperparameters used for the various attentive models are summarised in the table below. All models were trained using asynchronous RmsProp with a momentum of 0.9 and a decay of 95. A typical hyperparameter used is the element-wise The paper plots the performance of CNN\u2019s attention models for documents up to a certain amount of length. The figure below shows a sliding window of performance across document length, with increasing scale indicating that the models\u2019 performance degrades slightly as documents increase in length What  They provide examples of queries that require both lexical generalization and co-reference in order to be answered. The final positive example (also in Figure 7) demonstrates the fearlessness of our model. Examples from Attentive Reader and Impatient Reader",
    "10": "This paper introduces a new generative model, G, that estimates the probability that a sample came from the training data rather than from G.  It also introduces a discriminative model D that makes predictions based on the likelihood of G coming from a different distribution. Both models are trained simultaneously and the training procedure is optimized This paper introduces a new generative model, G, that estimates the probability that a sample came from the training data instead of from G.  G is a one-off feature extractor. D is a discriminative model that makes predictions based on data samples. The training procedure is to maximise the probability This paper presents a new generative model, based on the backpropagation and dropout algorithms, but where the discriminative model is pitted against an adversary that can determine whether the input is from the model distribution or the data distribution. In short, the adversarial net is like a team of counterfeiters trying This paper considers the problem of training directed graphical models with latent variables in an unnormalized setting (i.e. without a Markov chain). It starts from the observation that the log-likelihood distribution $p(x)$ is intractable, so one can derive a tractable, unnormal The paper describes a two-player minimax game where the goal is to minimize a log-likelihood of assigning the correct label to either the training example or the randomly sampled from the training set. The game is designed so that the discriminator is unable to differentiate between the two distributions and so that momentum is carried along in What  The paper proposes a method to train a neural network generative model based on the maximization of the log probability of a sample of the network's output. The network produces noise samples and then updates the discriminator by ascending its stochastic gradient. The method converges to a global optimum in the sense Consider V (G,D) = U(pg, D) as a function of pg. Let x be the discriminator's output. Let d(x) be the parameters of some optimizer g.  We want to optimize G(z; \u03b8g) so that it is convex in What  They suggest a new architecture for GANs. The architecture is based on a combination of linear activations and sigmoid activations. The activations are mostly based on dropout. How  They use a Gaussian Parzen window to estimate the log-likelihood of generated samples under the Ga This new framework comes with advantages and disadvantages relative to previous modeling frameworks. The disadvantages are primarily that there is no explicit representation of pg(x) and that D must be synchronized well with G during training (in particular, G must not be trained too much without updatingD, much as the negative chains of a Boltzmann This paper discusses an extension of the GAN framework that can be used for semi-supervised learning. The motivation behind this extension is to investigate whether using a family of conditional models that share parameters can speed up training by learning approximations to be fed to a classifier. This paper has demonstrated the viability of This paper is a collaboration between Theano Canada and Pylearn2. The paper thanks its contributors for their time and effort in preparing for a paper submission to Google\u2019s open source community in March 2014. We would also like to thank CIFAR and Canada Research Chairs for funding, and Compute",
    "11": "This paper presents a framework for dealing with uncertain data in a data processing system. Uncertain data comes from sensors in IoT, sampling based approximate computations and from machine learning Uniform uncertainty propagating in data processing systems Manousakis, et al., SoCC \u201918  Uncertainty Propagation in Data Processing Systems: This paper presents a general framework for processing uncertain data processing applications in data processing systems such as MapReduce, Spark and Scope. The framework is based on techniques This paper presents a list of approximate methods that generate uncertainty as a byproduct of the approximation. This includes systems where precise measurement uncertainty is introduced in some way, such as This paper presents an approach for dealing with uncertain inputs at a DAG node. Specifically, they discuss how to (approximately) compute Y = f (X) where f What  They suggest a method to approximate the mean and variance of a function f using first-order Differential Analysis (DA) for continuous and differentiable functions This paper presents a semi-continuous function detector for continuous functions called as the Chebyshev\u2019s inequality (Cheb)  [ref] What  They generate n samples of data under the condition that they are an approximation of the true distribution Y. Then they generate an n-dimensional vector representation of the What  The paper describes a dynamic, recursive implementation of differential analysis (differential analysis) for data processing DAGs. In brief, the goal is to What  The paper describes a mapReduce implementation called UP-MapReduce. The implementation is an extension of Hadoop MapReduce that includes the The basic idea in UP-MapReduce is simple; each input (key, value) pair in a program is encoded as a set of intermediate (key What  They suggest a few new Reducer classes for Hadoop 2.7 called UP-MC, UP-DA and UP-LU for continuous functions This paper presents a toolbox of operations that can be used with UP-MapReduce to process uncertain data. The applications are different from each other in some The paper evaluates UP-MapReduce by studying it\u2019s accuracy, performance, and scalability. Two applications considered as part of the evaluation are tsocial What  They generate synthetic input data sets of varying sizes and uncertainty for each application. (n = 104 runs of a precise application)  They evaluate tsocial using What  They suggest a two-stage approach to compute outputs for a query in BlinkDB. The first step is to sample some locations in the network. The second and The paper explores the accuracy and performance of UP-MapReduce estimation of the means using a sensitivity analysis. Shows that the accuracy is highly accurate in most cases The paper explores the scalability of UP-MapReduce applications 3-11 on a cluster of 512 servers. It also runs copies of the applications from previous versions This paper showed how Differential Analysis can be used to propagate data uncertainties through DAGs using Monte Carlo simulation of nodes without overheads. The approach also allows This work was partially supported by NSF grant CCF-1319755. The paper describes a scenario in which a neural network is used to predict sentiment scores for",
    "12": "Boosted RDMA access to main memory Bau et al., SOSP \u201917  KVS is a key infrastructure in data centers. Performance of in-memory KV-Direct: high-performance in-memory key-value store with programmable NIC Li et al., SOSP \u201917  Key-value KV-Direct: In-memory key-value store for web services Li et al., FAST\u201918  (** corrected spelling of Li et KVS: a data structure store for low-latency computation Tian et al., ICSE\u201918  Many data structures can be expressed in a key-value Boosting High-Performance KVS \u2013 Yang et al 2013  The 7th IEEE/ACM International Conference on Utility and Cloud Computing is coming to London in a couple Boosted NICs with FPGA: A case study in high-performance networking and low-latency NICs for datacenters Yadwadkar What  KV-Direct moves KV processing from the CPU to the programmable NIC in the server (like RDMA)  How  The goal is KV-Direct enables remote direct key-value access bypassing the CPU. The programmable NIC on KVS server is an FPGA reconfigured into KV-Direct: Stream processing on vectors using user-defined update functions \u2013 Golan-Gueta et al. 2015  Today\u2019s paper introduces a Hash Table  FPGA KV processor receives packets from the network, decodes vector operations and buffers KV operations in the reservation station. Next, the out What  The hardware platform is built on top of Intel Stratix V FPGA based programmable NICs (partner in the open source community)  The What  KV-Direct is a high-performance hyper-threaded Intel processor platform. The authors evaluate it with eight servers and one Arista DCS Hash Table Analysis  Comparison of KV-Direct, Cuckoo Hashing, Hopscotch Hashing and FaRM Hashing \u2013 Andersen et al What  The authors test KV-Direct on YCSB uniform and long tail workloads. They use a packet generator to generate batched KV operations, PCIe has 29% TLP header and padding overhead for 64B DMA operations and the DMA engine may not have enough parallelism to saturate the PCIe Overview  One billion KV op/s in a server with 10 KV-Direct NICs on a server  The benchmark server used in the paper is The goal of KV-Direct is to leverage existing hardware in data centers to offload an important workload (KV access), instead of designing a special hardware Overview  A large body of distributed key-value store systems are based on CPU. A new approach to reduce the computation cost of such systems is to use two- KVDirect: Fast, In-memory key-value store \u2013 Golan-Gueta et al. 2014  The 7th IEEE/ACM International conference We would like to thank Kun Tan, Ningyi Xu, Ming Wu, Jiansong Zhang and Anuj Kalia for all technical discussions and valuable comments.",
    "13": "TuckER is a simple, yet powerful linear model that uses Tucker decomposition for the task of link prediction in knowledge graphs. Paper  Implementation  Knowledge Graph as a Tensor  Let H = Height, W = Width, T = Batch size  We want RReL: Model Primitive Hierarchical Lifelong Reinforcement Learning \u2013 Wu, Kochenderfer, & Gupta 2019  AAMAS\u201919  The 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2019 This paper presents a simple yet effective approach for learning the hierarchical task over a sequence of tasks. The underlying idea is that the agent must learn to solve a series of tasks that are related to each other and must be able to transfer knowledge from previous tasks to improve on This paper presents the lifelong RL agent with a Markov Decision Process (MDP) over the reward-transition function $S$ (synthesized over time steps) and a momentum policy $r$ that selects actions that maximize the expected reward over the This section outlines the Model Primitive Hierarchical Reinforcement Learning (MPHRL) framework which can be used to solve the problem of effective piecewise functional decomposition for transfer across a distribution of tasks. Architecture  The idea is to represent the problem as The key assumption in MPHRL is access to several diverse world models of the environment dynamics. Model primitives  We use the term model primitives to refer to these approximate world models. The goal of the MPHRL framework is to use these suboptimal predictions from different What  The paper describes a learning algorithm for continuous action optimization, with a focus on how it integrates with the gating controller. The standard policy (SP) optimization objective is:  maximizes the policy gradient E by factorizing into:  \u03b8 - The paper tests if model primitives can ensure task decomposition and if such decomposition improves transfer for lifelong learning. Setup  Two tasks are considered - MuJoCo ant navigating different mazes and a Stacker arm picking up and placing different boxes. Both tasks use Ga The paper presents experiments on two tasks where the agent needs to learn a number of interpretable subpolicies to solve a single task. The tasks are L-Maze and D-Mazes. The paper reports that using model primitives like E, W The paper introduces a family of 10 random mazes for MuJoCo Ant environment called as the 10-Maze taskset (synthesized version of Ant Environment). The family of mazes has a maximum of 10 goal locations and only 3 goal locations The paper explores the following questions:  How much gain in sample efficiency is achieved by transfer-ring subpolicies? Can MPHRL learn the task decomposition even when the model primitives are quite noisy or when the source task does not cover all \u201ccases\ufffd What  They showed how imperfect world models can be used to decompose a complex task into simpler ones. The paper also demonstrated how the decomposition avoids negative transfer and catastrophic interference, a major concern for lifelong learning systems. How  Architecture  They start with two This work was supported in part by DARPA under agreement number D17AP00032. The authors are grateful to Kunal Menda and everyone at SISL for useful comments and suggestions. We are also grateful for the support from Google Cloud in scaling our",
    "14": "Overview  Most recent datacenter topology designs have focused on performance properties such as latency and throughput. In this This paper introduces a new dimension, life cycle management complexity, that attempts to understand the complexity of deploying a topology and fact sheet: assessing lifecycle management costs in a network Tzimpragos et al., USENIX Symposium What  They compare various data center topologies, specifically Clos and Expander graphs. The families are:  Clos What is deployed? Deployment is the process of realizing a physical topology in a data center space (e.g What  They suggest a method to pack individual switch cables into racks (for efficiency). The method is based on a combination of What  The authors identify several metrics that quantify the complexity of datacenter topology deployment: packaging and placement. What  They compare the Clos and Jellyfish topologies and compare how they compare on port-hiding, The second important component of topology lifecycle management is expansion. Datacenters are rarely deployed to maximal capacity in one shot  expanding a topology in two phases: (a) procuring new switches, servers, and cables and laying them What happens during a step of Clos expansion? Each spine and aggregation block are connected by two links (green and red) What  They identify two metrics that quantify expansion complexity and use these metrics to identify differences between Clos and Jellyfish. Number What  The authors compare Clos and Jellyfish network architectures and compare the number of links per patch panel in Jelly What  FatClique answers the question \u201cIs there a family of topologies which are comparable to, or What  FatClique combines the hierarchical structure of Clos with the edge expansion in expander graphs to achieve lower Re-wiring during expansion of FatClique topology \u2013 Golan-Gueta et al. 2014  Yesterday we Achieving low complexity with FatClique \u2013 Gupter et al 2014  Today\u2019s paper choice is inspired Comparing three architectures, Clos, expander graphs and fatclique by complexity metrics Lange et al., ASPLOS Comparing Clos, Xpander, Jellyfish, and FatClique topologies \u2013 Golan-Gueta What  The placement of patch panels is determined both by the structure of the topology and its scale (e.g What  The authors compare the number of switches used by different topologies (small and large) on various scales. They find The paper evaluates the expansion of symmetric Clos topologies using two measures of expansion complexity: number of expansion steps required and What  FatClique is the best network architecture at most scales, according to a recent study by the USenix This paper explores the design of topology designs for efficiency and cost efficiency in the context of a datacenter. Overview  This paper tries to characterize the complexity of lifecycle management of datacenter topologies. The management complexity of What  The authors want a fast way to generate Clos topologies, similar to the design of Jupiter. They base their",
    "15": "This paper presents a generalized approach for clustering networks based on higher-order connectivity patterns. This framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. Link to the code  Setup  Information propagation units (IS) are Higher-order organization of complex networks \u2013 Aaronson et al. 2015  This is the last paper we\u2019ll be looking at this year, so I\u2019ve chosen something a little more reflective to leave you with (The Morning Paper will return on The paper presents a method to derive the notions of cut and volume measures for defined network motifs in a graph. The method is inspired from the graph Laplacian and its application to directed graphs. Formally, the notion of a motif is defined by conductance on the weighted graph defined by Equation S19. When |A| = 3, the motif cut and motif volume are both equal to half the motif length. Theorem 6. Motif Cheeger Inequality  Theorem states that for any The paper discusses the idea of motif Cheeger inequality for network motifs with four or more nodes. The result follows from Theorem 5 and the standard Cheeger ineqaulity. The first result says that the set of nodes S is within a quadratic factor Theorem 1 and 3  Theorem 2  If we have a collection of k x k motifs M, and we want to cluster them into k clusters (each having different size), then we can have a discussion on how to weight these clusters using the Theorem 6: Theorem adjacency matrix WM - complexity of the algorithm for finding clusters of triangular motifs in a graph G. We now analyze the computation of the higher-order clustering method, in terms of the time to access edges in a The formula for the motif adjacency matrix WM has a simple formulation where A = A while B = A and U = A\u2212B. Note that in all cases, WM is symmetric. The central computational kernel in these computations is (X \u00b7 What  They compare the results of edge-based spectral clustering with the method of Infomap. The method is a special case of motif-based cluster-inducing. How  Let x be the adjacency matrix for a graph. Let f(x) What  The cluster found by Algorithm 1 consists of a total of 131 nodes and 764 edges. The nodes are neurons and the edges are synapses. The largest connected component of the motif adjacency matrix for motif Mbifan contains 112 nodes. The What  The paper describes a method to embed the spectral map of airports in the United States and Canada into a transport reachability network. The network is not symmetric so the authors estimate the travel times between nodes using a likelihood ratio estimator. They compare the The paper uses the motif based clustering framework to analyze the organization of networks. Motifs are considered a building block for food webs and energy sources for some species. Analysis of higher-order modular organization on the Florida Bay ecosystem food web  Motif M What  The paper describes a model based on the Laplacian family of proteins. The model is optimized so that each node in the network gets a fixed size eigenvector W.  The eigenvalue of W is the spectral norm of the whole",
    "16": "Read atomic (RA) isolation: atomic visibility in the context of multi-partition, multi-operation transactional access Read Atomic Multi-partition: Isolation for transactional visibility in a database Davis et al. SIGMOD \u201914  Athena et al., ICSE\u201918  We consider the problem of making transactional updates atomically visible to There are at least two basic scenarios for using Read Atomic isolation:  Foreign Key Constraint  If two users become \u201cfriends In this section, we formalize Read Atomic isolation and, to capture scalability, formulate a pair of strict scalability criteria: Read Atomic Isolation (RA) is a restriction on write visibility\u2014if all or none of a transaction\u2019s updates are performed Read-only and write-only transactions are the best choices for many applications, but RA is not sufficient for all applications. Because it The goal in this paper is to provide robust and scalable transactional functionality, and so we first define criteria for \u201cscalability Read-only and write-only transactions with a \u201clast writer wins\u201d overwrite policy Ramasubramanian et What  RAMP-Fast is an algorithm for fast writes, with one RTT for reads and two RTTs for writes What  RAMP-Fast Server-side Data Structures (RAMP-Fast) is a fast data structure implementation of RAM What  RAMP-H is a hybrid between RAMP and RAMp-S.  It stores an entire write set The RAMP algorithms allow readers to safely race writers without requiring either to stall. More specifically, readers do not interfere with other readers, What  RAMP transactions rely on multi-versioning to allow readers to access versions that have not yet committed and/or have been CTP: Cooperative Termination Protocol for Multi-Bit Transactions \u2013 Golan-Gueta et al. 2014  This is the What  RAMP algorithms provide the following performance improvements over Paxos Commit:  Faster commit detection. If a server returns a RamP-F, RAMP-H, RAMp-S: scalability vs transactional and non-transact The paper implemented a multi-versioned, main memory database prototype using Kryo 2.20 for serialization using a distributed The RAMP algorithms achieve low latency (on average) and low overhead compared to lock based and E-PCI techniques. We also evaluated the overhead of blocked writes in the implementation of the Cooperative Termination Protocol (CTP) We artificially lowered a We deployed an increasing number of servers within the us-west-2 EC2 region and, to mitigate the effects of hot items A very short primer on Isolation  There are three main categories of isolation guarantees in modern database systems:  Serializability This paper describes how to achieve atomically visible multi-version transactions without incurring the performance and availability penalties of traditional algorithms. The A very topical choice for today\u2019s paper choice. The paper looks at a wonderful example of distributed database systems supporting transaction The paper formalizes the concept of a companion set in the RAMP-F database, and shows that the two-round",
    "17": "RPCValet: NI-driven tail-Aware balancing of mcp-scale RPCs Daglis et al., ASPLOS \u201919  We are RPCValet: NI-Driven Tail-Aware Balancing of \u00b5s-Scale RPCs Daglis et al., ASPLOS \u201919  Today we\ufffd Dynamic load balancing at scale: tail-tolerant computing for online services Yoon et al., EPFL\u201918  We\u2019re seeing a shift towards  NI integration: handling \u00b5s-scale RPCs with fine-grained communication Bau et al., SoCC\u201918  (If you don\u2019t What  The paper proposes a queuing system with Q FIFOs (with a variable number of input queues and 16 serving units) and U serving units per FIFO What  The authors present a new load-balancing algorithm for Double DAGs, inspired by the work  [ref]  and their previous work on multi- CPC-RPCVet: optimized for short-scale service processing at the \u00b5s level \u2013 Golan-Gueta et al. 2015  Today\u2019 The NI\u2019s integration on the same piece of silicon as the CPU is the key enabler for handling \u00b5s-scale events. By leveraging the fact that such What  They describe an architecture for multi-queue messaging based on the VIA QP (International Queue Accessories Association of America) principles. (VIA is soNUMA: Fast, Scalable Memory Access for Manycore CPUs \u2013 Golan-Gueta et al. 2014  SoNUma is another research project, this What  They devise a lightweight implementation of native messaging as a required building block for dynamic load-balancing at the NI. A key difficulty to overcome is support for multi- Dynamic load balancing at the NI dispatcher \u2013 Golan-Gueta et al. 2014  Today we\u2019re temporarily pausing our tour through some of the OSDI\u2019 The paper describes a method to evaluate the performance of RPCValet with a single tiled 16-core chip implementing soNUMA with a Manycore NI. The What  HERD with 1 \u00d7 16 delivers 29x higher throughput than 4 \u00d7 4 and 16x 1x 1 at SLO. Up to 4x lower tail latency What  They compare the performance of RPCValet with a software implementation, both of which implement the same theoretically optimal queuing system (i.e. 1 \u00d7 16). What  The paper compares the results of RPCValet with results from purely theoretical queuing systems, in order to determine the performance gap between the two systems. The results show Controling Tail Latency at Scale \u2013 Joachims et al 2014  Today\u2019s paper choice won a best paper award at the recent ACM Symposium on Cloud Computing Dynamic load-balancing for scale-scale RPCs \u2013 Golan-Gueta et al. 2014  Today\u2019s paper choice combines the benefits of a single-queue This paper presents a high-level look at an architecture for massively parallel distributed systems. The architecture is independent of any company, but under the supervision of the ISO standards body",
    "18": "The paper explores the feasibility of language-based abductive reasoning for predicting the most plausible explanation in natural language. Two tasks are introduced \u2013 Abductive NLI: multiple-choice question The paper presents a new dataset of 20K narratives accompanied by over 200K explanatory hypothesis (ART) for the task of Abductive Natural Language Generation (\u03b1NLG) and Abductive Natural Language Inference (\u03b1NLI) is the task of generating a valid hypothesis h+ given the two observations O1 and O2. Formally, the task requires A Probabilistic Framework for \u03b1NLI \u2013 Christiano et al. 2014  Today\u2019s paper choice is part of the work of the SyncFree European research project on large The paper presents a new dataset, ART, for the task of ABDUCTIVE reasoning in narrative text. The dataset consists of  (20K - 200K) narratives with over This paper presents an evaluation of finetuned versions of the state-of-the-art pre-trained language models on the ART dataset. In the \u03b1NLI setting, What  The paper describes three different approaches to train language models for the task of inference on the ART dataset. The models are BERT, GPT and ESIM+ELMo What  The paper uses the GPT model to train a neural network adversary network. The paper shows that the performance of the best GPT network plateaus after about 10,000 This paper presents a generative model based on the ATOMIC transformer that generates nine commonsense inferences of events in natural language. The knowledge is a natural source of background commons This paper presents a novel approach to reasoning about plausible sequences of events in a narrative setting. Rather than learning about plausible scripts or narrative chains, the authors instead reason about the most plausible events conditioned The paper explores the feasibility of language-based abductive reasoning in a new task, Abductive Natural Language Inference (\u03b1NLI) \u2013 a task focused on abductive This research was supported in part by NSF (IIS-1524371) and the National Science Foundation Graduate Research Fellowship under Grant No. DGE 1256082. We thank the The paper presents a three-part story consisting of an initial observation (O1), a middle sentence (h+, called a \u201cmiddle sentence\u201d, and a final observation What  The paper fine-tunes BERT using a grid search with the following set of hyper-parameters:  batch size: 4  learning rate: 5e-5 What  They train an SVM classifier and a bag-of-words model using GloVe embeddings. Both models achieve accuracies close to 50%. How  Architecture What  The paper proposes a version of Adversarial Filtering (AF) where the adversary only chooses plausible and implausible hypotheses and uses a different, human-generated distractor for What  The goal is to represent commonsense knowledge as a graph with events as nodes and relations as edges. The input to the graph is the current event. The output is the Table 8 describes the format of input to each variation of the generative model evaluated in the paper. Each variation is represented by a vector representing the form (x1, null),",
    "19": "Overview  Zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well- Overview  Zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well- A first look at Zcash for anonymity and pseudonymous transactions Baltes et al., USENIX Security Sym This paper links together the transactions used to shield anonymity in the Bitcoin ecosystem, based on a heuristic about What  ZEC is an alternative cryptocurrency developed as a (code) fork of Bitcoin that aims to break Overview of participants in Zcash ecosystem  We\u2019ll focus on the individuals and entities that interact with What  The Zcash blockchain has been evolving since the inception of zcash on September 27th, 2017 Overview of transactions over time  Zcash had 2,242,847 transactions across all blocks in 2014. What  Last week we looked at some of the amazing properties of Bitcoin\u2019s block reward system ( As discussed in Section 4, a large proportion of the activity on Zcash does not use the shielded pool. This Identifying transparent addresses in Zcash using multi-input heuristic Leis et al., CCS\u201918 Identifying Zcash exchanges and assigning names to them Guo et al., USENIX Security Symposium What  They generated a cluster of 560,319 clusters, of which 97,539 contained more than Identifying exchanges for ZEC users  The paper conducted a clustering analysis of the top 5 clusters in Although mining pools and founders account for a large proportion of the activity in Zcash (as we explore in Section 6 The Internet Archive, torservers.net and Wikileaks We are able to identify 31 donations to the Internet Archive This section explores the deposits and withdrawals into (and out of) Zcash\u2019s shielded pool, Overview  The paper examined the following patterns in the usage of the addresses in a bitcoin co-ingeniation The Zcash protocol specifies that all newly generated coins are required to be put into the shielded pool before they can be What  We split the category of miners into individual miners, who operate on their own, and mining pools, What  The authors conducted a heuristic analysis of z-to-t transactions in Zcash, focusing Identifying entities in the shielded pool Cui et al., Zcash\u201917  We ran the This section considers z-to-z transactions (8,444 vJoinSplits in Zcash) and provides TSB: A t-to-z guide to identifying transactions that could represent payments to The Shadow Bro Identifying transactions associated with TSB Blunsom et al., USenix Security Symposium (USen Overview  The number of transactions matching our requirements up until 17 January 2018 is summarized in Table 6. Before the first This paper explores the privacy and anonymity guarantees of Zcash, with a particular focus on its shielded pool. The paper contains an extensive Q&A section with questions and answers to common questions about the Zchain explorer"
}