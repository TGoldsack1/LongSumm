{
    "0": "networks are a fundamental tool for understanding and modeling complex systems in physics, biology, and social science. many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. however, organization of complex networks\u2014at the level of small network subgraphs\u2014 this framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. the framework reveals higher-order organization in a number of networks including information propagation units in neuronal networks and hub structure in transportation networks. results show that networks exhibit rich higher-order organizational structures that are exposed by clustering based on higher-order connectivity patterns. here we develop a generalized framework for clustering networks based on higher-order connectivity patterns. . austin r. benson,1 jure of computer science, purdue university 2department for computational and mathematical engineering, stanford university . correspondence should be addressed; e-mail: jure@cs.stanford.edu and social science. many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. however, organization of complex networks\u2014at the level of small network subgraphs\u2014 this framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. the framework reveals higher-order organization in a number of networks including information propagation units in neuronal networks and hub structure . graph laplacian and hypergraph partitioning. review of the graph laplacian for weighted, undirected graphs consider a weighted, undirected = (v,e), with |v of a set s, \u03c6(g)(s): = cut(g)(s, s\u0304)/min(vol(g)(s), vol(g)(s\u0304)), = v \\s. i\u2208s, . the graph laplacian is defined as l = d \u2212w . we usually consider breaking g into s10 connected components as a pre-processing step for algorithms that are defined as follows: cut(g)(s, s\u0304) = weighted sum of weights of edges . equation s19. proof. on the weighted graph defined by equation s19. when |a| = 3, the motif cut and motif volume are both equal to half the motif cut and motif volume measures by lemmas 1 and 4. s19 for any motif with three anchor nodes, conductance on the weighted graph is equal to the motif conductance. because of this, the results in terms of motif conductance. in particular, we get the following \u201cmotif cheeger theorem motif cheeger inequality. suppose we use algorithm 1 to find a low-motif conductance set s. let \u03c6\u2217 = mins\u2032 \u03c6 m (s \u2032) be the optimal motif conductance over any set of nodes (32) . 1. \u03c6(g)m \u2264 4 \u221a \u03c6\u2217 and 2. \u03c6\u2217 proof. the result follows from theorem 5 and the standard cheeger ineqaulity the first part of the result . the set of nodes s is within a quadratic factor of optimal. this provides the mathematical guarantees that our procedure finds a good cluster in a graph, if one exists. the second result provides a lower bound on the optimal motif conductance in terms of the eigenvalue. we use this bound in our analysis of a food web (see section s7.1) to show that certain motifs do not provide good clusters, regardless of the procedure . the exact conductance with an additional penalty for splitting the four anchor nodes into two groups of two. proof. this follows from lemmas 1 and 8. s22 to summarize, we still get a cheeger inequality from the weighted graph, but it is in terms of a penalized version of the group of four nodes is \u201cmore split\u201d (2 and 2 as opposed to 3 and 1), the penalty is larger. when |a| > 4, we can use the following method of ng et al. (19). algorithm 2: motif-based clustering algorithm for finding several clusters. input: directed, graph g, motif m . algorithm presented in theorem 6. overall, the complexity of the algorithm is governed by the computations of the motif adjacency matrix wm , an eigenvector, and the sweep cut procedure. for simplicity, we assume that we can access edges in a graph in o(1) time and access and modify matrix entries in o(1) time. time . the computational time to formwm is bounded by the time to find all instances of the motif in the graph. naively, for a motif on k nodes, we can compute wm in \u03b8(nk) time by checking each k-tuple of nodes. furthermore, . matrix of the original, directed, s19) has a simple formula in terms of the adjacency matrix of the original, directed, graph, . matrix of the unidirectional and bidirectional links ofg. formally, b = a\u25e6at and u = a\u2212b, in terms of the matrices u and b. the central computational kernel . spectral cluster- spectral clustering, in particular, the motifs b1 = [ 0 1 1 0 ] , a = {1, 2} (s27) . the louvain method was downloaded from https://perso.uclouvain.be/vincent.blondel/research/louvain. html we use the \u201coriented\u201d version of the louvain method for directed graphs. infomap . c. elegans network of frontal neurons (28). as a preprocessing step. for our analysis, we consider use mbifan, m8, and medge (figure s4). the original network has 131 nodes and 764 edges. the largest connected component of the motif adjacency matrix for motif mbifan contains 112 nodes. the remaining 19 nodes are isolated and correspond to the neurons afdl, aiar, ainr, asil/r, . algorithm 1 on the largest connected component of the motif adjacency matrix for motif m8 . transportation reachability network the nodes in the transportation reachability network . airports in the united states and canada. there is an edge from city i to city j if the estimated travel time from i to j is less than some threshold (23). the network is not symmetric. the network with estimated travel times was downloaded from http://www.psi.toronto.edu/affinitypropagation/travelrouting.mat and http://www.psi.toronto.edu/affinitypropagation/travelroutingcitynames. txt. . motif-based clustering was downloaded from http://vlado.fmf.uni-lj.si/pub/networks/ data/bio/foodweb/florida.paj. in the florida bay food web graph . the dataset was studied in the literature and see how they reveal organizational structure in the networks. s7.1 motif m6 in the florida bay food web we now apply the higher-order clustering framework on the florida bay ecosystem food web (64). . all data is available at our project web site at http://snap.stanford.edu/higher-order/. the web site includes links to datasets used for experiments throughout the supplementary material (7, 56, et al., science review . the motif has three nodes, the selected cluster s satisfies \u03c6m(s) \u2264 matrix .",
    "1": "modern kvs goes beyond the traditional object-caching workload . data centers, shifting the bottleneck of most kvs from the network to the cpu. rdma-capable nic partly alleviates the problem, but the primitives provided by rdma abstraction are rather limited. meanwhile, programmable in data centers. recent years have witnessed a rapid increase of network bandwidth in data centers, recent years . nic kv-direct becomes the new bottleneck. combined, these mechanisms allow a single nic kv-direct to achieve up to 180 m key-value operations per second, equivalent to the throughput of tens of cpu cores. compared with cpu based kvs kv-direct improves power efficiency by 3x, while keeping tail latency below 10 \u00b5s. moreover, kv-direct with 10 programmable nic cards in a commodity server, we achieve 1.22 billion kv operations per second, . the full citation on the first page. copyrights for components of this work owned by others than acm must be honored. abstracting . (kvs) key-value is a key distributed system component in many data centers. kvs as an object caching system for web services. large web service providers such as amazon [17] and facebook [3, 57], have deployed key-value stores at scale. more recently, as main-memory based computing becomes a major trend in the data centers [18, 58], and sequencers in distributed synchronization [37]. for most of these applications, the performance of the kvs is the key factor that directly determines the system efficiency. due to its importance, over the years significant amount of research effort has been invested on improving kvs performance. . key-value 25, are built on top of traditional os abstractions such as os lock and tcp/ip stack. . memcached [25] gained popularity as an object caching system for web services. in the era of in-memory computation, kvs or all neighbor nodes . graph computation [61], tasks, servers [46]. the latency of an iteration is determined by the slowest operations [59]. therefore, . kvs is a non-trivial exercise of optimizing various software and hardware components in a computer system. characterized by where the kv bottleneck can be attributed to the computation in kv operation and the latency in random memory access. cpu-based kvs needs to spend cpu cycles for key comparison and hash slot computation. moreover, hash table is dominated by cache miss latency for practical access patterns. by our measurement, a 64-byte random read latency for a contemporary computer . nic firmware [44], is the heart of the programmable nic we use is an fpga, with an embedded nic chip to connect to the network. programmable nics . the dram is typically not large enough to hold the entire key-value store. . kv-direct nic accesses is a packet switched network with \u223c500 ns and 7.87 gb/s theoretical bandwidth per gen3 x8 for our programmable nic, the cached pcie dma . the theoretical throughput is therefore 5.6 gb/s, or 87 mops. to access host memory accesses . remote direct key-value access. clients send kv-direct operations (\u00a73.2) to kvs server while the programmable nic processes the requests and sending back results, bypassing the cpu. nic on kvs server is an fpga reconfigured as a kv processor (\u00a73.3). figure 2 shows the architecture of kv-direct. the programmable nic on kvs server . kv-direct enables remote direct key-value access. clients send kv-direct operations (\u00a73.2) to kvs server while the programmable nic processes the requests and sending back results, bypassing the cpu. the programmable reconfigured . kv-direct extends one-sided rdma operations to key-value operations, as summarized in table 1. in addition to standard kvs operations as a generalization to atomic operations. the update function needs to be pre-registered and compiled to hardware logic before executing. kv operations with user-defined update functions are similar to active messages [19], saving communication and synchronization cost. when a vector operation update, reduce or filter is operated on a key, its value is treated as an array of fixed-bit-width elements. values in a sparse vector can be fetched with vector filter operation. . the kv engine (\u00a73.3.3) issues independent kv operations from reservation station into the operation decoder. the kv processor looks up the hash table (\u00a73.3.1) and executes the corresponding operations. to minimize the number of memory accesses, small kv pairs are stored inline in the hash table, others are stored in dynamically allocated memory from the slab memory allocator (\u00a73.3.2). both the hash index and the slaballocated memory access engine (\u00a73.3.4), . nic (\u00a72.3). the programmable nic is attached to the server through two pcie gen3 x8 links in a bifurcated x16 physical connector, and contains 4 gib of on-board dram with a single ddr3-1600 channel. for development efficiency, we use intel fpga sdk . the throughput is one operation per clock cycle. with 180 mhz clock frequency, our design can process kv operations at 180 m op/s if not bottlenecked . the programmable nic has two pcie gen3 links in a testbed gen3 x16 port . the programmable nic [10] is connected to the pcie root complex of cpu 0, and its 40 gbps ethernet port is connected to the switch. the programmable nic has two pcie gen3 links in a testbed of eight servers . two free parameters in our hash table design: (1) threshold, the ratio of hash index in the entire memory space. . the maximal achievable memory utilization drops under higher hash index ratio, because less memory is utilized. as shown in figure 9a, when hash index ratio grows, more kv pairs can be stored inline, yielding a lower average memory access . 5.2.1 methodology. is a power of two minus 2 bytes (for as the last step of preparation, we issue put operations to insert the kv pairs into an idle kvs until 50% memory utilization. the performance of kv-direct, because the key is padded to the longest possible inline kv size is irrelevant to the performance of kv-direct, because of the packet generator is pre-calibrated via direct loop-back and measure sustainable throughput and latency. the processing delay of the packet generator is not inlined, so they require an additional memory access. long-tail workload . 64b dma has 29% header and padding overhead for 64b dma operations (\u00a72.4) . the dma engine may not have enough parallelism to saturate the pcie bandwidth-delay product with 27 in-flight dma reads. . the dma engine has enough parallelism (64) to perform random memory access, . maximal throughput cpus. showed the possibility of achieving a billion kv op/s in a single server with four (currently unavailable) 60-core as shown in table 3, with 10 kv-direct nics on a server, to achieve 1.22 gop/s get or 0.61 gop/s put. in order to saturate the 80 pcie gen3 lanes of two xeon e5 we replace the motherboard of the benchmarked server (sec. 5) . nic owns an exclusive memory region in host memory and serves a disjoint partition of keys. multiple nics . nic dram and nic dram are expensive in both die size . nic dram is a tiny fraction of host memory, the throughput gain . nic has larger dram, a slightly less portion of load . research and development of distributed kvs are based on cpu. to reduce the computation cost, masstree [53], and libcuckoo [48] hashing and memory allocation algorithms, . the network. traffic. nessie [70], drtm [72], is involved in kv processing, . in-memory store. is another exercise in leveraging reconfigurable hardware . software in order to remove bottlenecks in the system and achieve performance that is close to the physical limits of the underlying hardware. after years of broken promises, reconfigurable hardware . many significant workloads will be scrutinized to see whether they can benefit from reconfigurable hardware, . kun tan, xu, zhang and anuj kalia for all technical discussions and valuable comments. we\u2019d at microsoft for support on the fpga platform. . anonymous reviewers for their valuable feedback and comments. also like to thank the whole catapult v-team at microsoft for support on the fpga platform. .",
    "2": "paper presents an integrated behavioral inference and decision-making approach that models vehicle behavior for both our vehicle and nearby vehicles as a discrete set of closedloop policies that react to the actions of other agents. each policy captures a distinct high-level behavior and intention, such as driving along a lane or turning at an intersection. we first employ bayesian changepoint detection on the observed history of states of nearby cars to estimate the distribution over potential policies that each nearby car might be executing. based on coupled interactions between cars in a tractable manner. this work extends our previous multipolicy system [11] by incorporating behavioral anticipation into decision-making . autonomous driving is hard due to uncertainty on the continuous state of nearby vehicles and, in particular, due to uncertainty over their discrete potential intentions (such as turning at an intersection or changing lanes). previous approaches have difficulty scaling up to real-world scenarios. in addition, current approaches for anticipating future intentions of other traffic agents [1, 22, 29, and numerical optimization [17, 42], . these methods fail to capture the coupled dynamic effects of interacting traffic agents. partially observable markov decision process (pomdp) solvers 26, 35] offer a theoreticallygrounded framework to capture these interactions, but have difficulty scaling up to real-world scenarios. . the extended kalman filter [13, 18]. consists in computing the possible goals of a target vehicle by planning from its standpoint, accounting for its current state. this strategy is similar to our factorization of potential driving behavior into a set of policies, but lacks our closed-loop simulation of vehicle interactions. 25, 40], particularly in autonomous driving [7, 38, . discrete decisions (e.g. continuing straight, merging, or passing). some researchers have explored using gaussian mixture models (gmms) [14, and contextsensitive models [19, 20] to account for nonlinearities . the first instances of decision making systems for autonomous vehicles capable of handling urban traffic situations stem from the 2007 darpa urban challenge [12]. in that event, participants tackled decision making using a variety of solutions ranging from finite state machines (fsms) [29] and decision trees [28] to several heuristics however, these approaches were tailored for very specific and simplified situations and were, even according to their authors, \u201cnot robust to a varied world\u201d [41]. more recent approaches have addressed the decision making problem in dynamic, uncertain scenarios such as autonomous driving. unfortunately, finding an optimal solution to most pomdps is intractable [27, 32]. . we first formulate the problem of decision making in dynamic, uncertain environments with tightly coupled interactions between multiple agents as a multiagent pomdp. we then show how we exploit autonomous driving domain knowledge to make approximations to the pomdp formulation, thus enabling principled decisions in a tractable manner. we then show how we exploit autonomous driving domain knowledge to make approximations to the pomdp formulation, thus enabling principled decisions in a tractable manner. we first formulate the problem of decision making in dynamic, uncertain environments with tightly coupled interactions between multiple agents as a multiagent pomdp. we then show how we exploit autonomous driving domain knowledge to make approximations to the pomdp formulation, thus enabling principled decisions in a tractable manner. uncertain environments with tightly coupled interactions between multiple agents . we first formulate the problem of decision making in dynamic, uncertain environments with tightly coupled interactions between multiple agents as a multiagent pomdp. we then show how we exploit autonomous driving domain knowledge to make approximations to the pomdp formulation, thus enabling principled decisions in a tractable manner. pomdp. we first formulate the problem of decision making in dynamic, uncertain environments with tightly coupled interactions between multiple agents . x \u00d7 zv \u2192 av is a tuple of controls for steering, throttle, brake, and directionals. as a notational convenience, v t |xt), . x \u2192 r. the evolution of p(xt) over time is governed by p(xt+1) = \u222b\u222b\u222b x z . we make the following approximations to sample the consequences of our decisions over a limited set of high-level behaviors determined by the available policies (for both our vehicle and other vehicles are executing a policy from a discrete set of policies. 2) at any given time, both our vehicle and other vehicles with assigned policies. these approximations allow us to evaluate the consequences of our decisions over the policy executed by our controlled car q \u2208 v , we have full authority over the policy executed by regulating its acceleration profile to be more or less aggressive. we thus reduce the search in eq. 1 to a limited set of policies. by assuming each vehicle v \u2208 v is executing a policy \u03c0vt \u2208 at time t, the driver model for other agents . method is based on a segmentation of the history of observed states of each vehicle, where each segment is associated with the policy most likely to have generated the observations in the segment. we obtain this segmentation using bayesian changepoint which infers the points in the history of observations where the underlying policy generating the observations changes. z0:t) over the car\u2019s potential policies at the current timestep. further, full history segmentation allows us to detect anomalous behavior that is not explained by the set of policies in our system. the changepoint-detection procedure is illustrated by the simulation . the map choice of changepoints has occurred prior to a given changepoint at time j, results in: pt(j, = p(ct = p(ct at which changepoints is a well-known approximation that avoids marginalizing over the policy parameters and provides a principled penalty against complex policies by assuming a gaussian posterior around the estimated parameters \u03b8\u0302. only the ability to fit policies to the observed data is required, which can be achieved via a maximum likelihood estimation (mle) method of choice (we elaborate on this in \u00a7iv-b). as shown by fearnhead and liu [15], the distribution ct over the position of the observed states of a given vehicle z1:n = (z1, . the (m + 1)th segment can be computed by solving the following the execution of policy \u03c0 under parameters \u03b8 from timestep \u03c4m + 1: p(z\u03c4m+1:n|\u03c0, = n (z\u03c4m+1:n;\u03c8\u03c0,\u03b8, = n (z\u03c4m+1:n;\u03c8\u03c0,\u03b8, where \u03c3 is the hypothesis over policy \u03c0i and \u03b7 is a normalizing constant. with mean at the trajectory \u03c8\u03c0,\u03b8 obtained via changepoint detection and consisting of observations z\u03c4m+1:n. the likelihood and parameters of each latent policy \u03c0 \u2208 \u03c0 for the target vehicle given the present segment of policies further in \u00a7v-b). that is, eq. 15 essentially measures the deviation of the observed states from those prescribed by the given policy. the policy likelihoods obtained via eq. 14 capture the probability distribution over the possible policies that the observed vehicle might be executing at the current timestep, which can be represented, using delta functions, as a mixture distribution: p(\u03c0vt |xt, \u03b4(\u03b1i) = \u03b7 |\u03c0|\u2211 i=1 where \u03b1i is the hypothesis error . the time-series segmentation obtained via changepoint detection allows us to perform online detection of anomalous behavior not modeled by our policies. inspired by prior work on anomaly detection [9, 25, unlikelihood against available policies. anomalous behavior in terms of policy likelihoods, and then compare the observed data against labeled normal patterns in previously-recorded vehicle trajectories. thus, we define the following two criteria for anomalous behavior: 1) ambiguity among different policies might be a sign of ambiguity on the segmentation. to express this characteristic as the global similarity of the observed history as the global similarity of the mean and \u03c3 is the fourth moment of the mean and \u03c3 is the fourth moment of a set of previously recorded trajectories of other vehicles. a history segmentation . policy assignments (\u03c0, s) with closed loop simulation to yield a set of samples s \u2208 s from the distribution over policies of other cars via eq. 16, where each sample assigns a policy \u03c0v \u2208 to each nearby vehicle v, excluding our car. for each policy \u03c0 available to our car and for each sample s, we roll out forward in time until the decision horizon h all vehicles under the policy assignments (\u03c0, the expected reward. the process continuously repeats in a receding horizon manner. note that policies that are not applicable given the current state x0, such as an intersection handling policy when driving on the highway, are not considered for selection (line 5). . 1 draw a set of samples s \u2208 s via eq. 16, where each sample assigns a policy to each nearby vehicle. 2 r \u2190 \u2205 // rewards for each rollout 3 foreach \u03c0 // // 8 return . there are many possible design choices for engineering the set of policies in our approach, which we wish to explore in future work. however, in this work we use a set of policies that covers many in-lane and intersection driving situations, comprising the following policies: lane-nominal, drive in the current lane and maintain distance to the car directly in front; lane-change-right/lane-change-left, separate policies for a single lane change in each direction; and turnright, turn-left, go-straight, or yield at an intersection. drive in the current lane and maintain distance to the car directly in front; lane-change-right/lane-change-left, separate policies for a single lane change in each direction; and turnright, turn-left, go-straight, or yield at an intersection. which we wish to explore in future work. however, in this work we use a set of policies that covers many in-lane and intersection driving situations, comprising the following policies: lane-nominal, drive in the current lane and maintain distance to the car directly in front; lane-change-right/lane-change-left, separate policies for a single lane change in our approach, which we wish to explore in future work. however, in this work we use a set of available policies in our approach, which there are many possible design choices for engineering the set of available policies that covers many in-lane and intersection driving situations, comprising the following policies: lane-nominal, drive in the current lane and maintain distance to the car directly in front; lane-change-right/lane-change-left, go-straight, or yield at an intersection. and turnright, turn-left, go-straight, or yield at an intersection. there . high-fidelity simulation can capture the necessary interactions between vehicles to make reasonable choices for our vehicle behavior, while providing faster performance. in practice, we use a simplified simulation model for each vehicle that assumes an idealized steering controller. nonetheless, this simplification still faithfully describes the high-level behavior of the between-vehicle interactions our method reasons about. for vehicles classified as anomalous, we simulate them using a single policy accounting only for their current state and map of the environment, since they are not likely to be modeled by the set of behaviors in our system. simulation . the reward function for evaluating the outcome of a rollout \u03c8 involving all vehicles is a weighted combination of metrics mq(\u00b7) \u2208 as a measure of accomplishment, minimum distance to obstacles to evaluate safety, a lane choice bias to add a preference for the right lane, and the maximum yaw rate and longitudinal jerk to measure passenger comfort. for a full policy assignment (\u03c0, s) with rollout \u03c8\u03c0,s, as the weighted sum r\u03c0,s wqmq(\u03c8 \u03c0,s). we normalize each mq(\u03c8\u03c0,s) across all rollouts to ensure comparability between metrics. to avoid biasing decisions, we set the weight wq to zero when the range of mq(\u00b7) across all samples is too small to be informative. as it is easy to become overly conservative when negotiating traffic if one only accounts for worst-case behavior. by weighting . the traffic-tracking dataset and the vehicle used to collect it. next, we use this dataset to evaluate our prediction and anomaly detection method and the performance of our multipolicy sampling strategy. finally, we evaluate our multipolicy approach performing integrated behavioral analysis and decision-making on highway traffic scenarios using our multivehicle simulation engine. we first introduce the traffic-tracking dataset and the vehicle platform. we use traffic-tracking data collected using our autonomous vehicle platform. we use this dataset to evaluate our behavioral anticipation method and our multipolicy sampling strategy, we use traffic-tracking data collected using our multivehicle simulation engine. we evaluate our multipolicy approach performing integrated behavioral analysis and decision-making on highway traffic scenarios . ford fusion equipped with four velodyne hdl-32e navigation system (ins), gps, and several other sensors. the vehicle uses prior maps of the area it operates on that capture information about the environment such as lidar reflectivity and road height, and tracking of other agents. the road network is encoded as a metric-topological map that provides information about the location and connectivity of road segments, and lanes therein. estimates over the states of other traffic participants are provided by a dynamic object tracker running on the vehicle, . the observations. thus, we evaluate our behavioral analysis method in the context of a classification problem, where we want to map each trajectory to the underlying policy (class) that is generating it at the current timestep. the available policies used in this evaluation are: lane-change-left, \u222a {turn-right, (19) (19) (19) where the first subset applies to in-lane maneuvers and the second subset applies to intersection maneuvers. for all policies we use a fixed set of parameters tuned empirically to control our autonomous vehicle platform, including maximum longitudinal and lateral accelerations, and allowed distances to nearby cars, among other parameters. to assess each classification as correct or incorrect, we leverage the road network map and compare the final lane where the trajectory actually ends to that predicted by the declared policy. in addition, we assess behavioral prediction performance on subsequences of incremental duration of the input trajectory, 5 shows the accuracy and precision curves for policy classification over the entire dataset. the ambiguity among hypotheses results in poor performance when only an early stage of the trajectories is used, especially under 30% completion. however, . we recorded three additional trajectories corresponding to two bikes and a bus. the bikes crossed the intersection from the sidewalk, while the bus made a significantly wide turn. we run the test on these trajectories and on three additional intersection trajectories using the minimum normality value on the intersection portion of the dataset, \u03b3 = 0.1233. . shown by the results in fig. 6, our test is able to correctly detect the anomalous behaviors not modeled in our system. system. our anomaly detection test. we recorded three additional trajectories corresponding to two bikes and a bus. the bikes crossed the intersection from the sidewalk, . the recorded intersection trajectories. the likelihood of the most likely policy \u03c0ml in {turn-right, turn-left, yield} according to the corresponding trajectory in the group. we then evaluate the computation time required by each of the two sampling strategies to find a sampled trajectory with a likelihood equal or greater than l(\u03c0ml). the uninformed strategy generates, for each vehicle involved, a trajectory that either remains static for the duration of the trajectory to yield or crosses the intersection at constant speed. this decision is made at random. if the decision is to cross, the direction of the vehicle is determined via random steering wheel angle rates in a simple car kinematic model. the multipolicy sampling strategy consists of randomly selecting policies for each vehicle and obtaining their rollouts. the computation times for each strategy such as those used by general decisionmaking algorithms . we tested the full decision-making algorithm with behavioral prediction in a simulated environment with a multi-lane highway scenario involving two nearby cars. fig. 7(a) shows the scenario used for testing at an illustrative point at half way through the scenario. this simulation uses the same policy models we have developed and tested on our real-world test car [11]. fig. 7(b) shows the policy reward function, in which the chosen policy is the maximum of the available policies. note this decision process is instantaneous, which explains the oscillations when policies are applicable at once. parallel evaluation performance is bounded by the maximum time for a single rollout, for which the mean worst time was 84ms, and the worst time over the whole experiment was 106ms. even in the worst case, our real-time decision-making target of 1 hz is acheiveable. with a mean of 8.6. this smaller number of rollouts is because not all policies are applicable . policies, changepoint detection that infers the likelihood of policies of other vehicles. furthermore, we provided a normality test to detect unexpected behavior of other traffic participants. we have shown that our behavioral anticipation approach can identify the most-likely underlying policies that explain the observed behavior of other cars, and to detect anomalous behavior not modeled by the policies in our system. in future work we will explicitly model unexpected behavior, such as the appearance of a pedestrian or vehicles occluded by large objects. we can also extend the system to scale to larger environments by strategically sampling policies to focus on those outcomes that most affect our choices. exploring principled methods for reacting to detected anomalous behavior is also an avenue for future work. by explicitly modeling reasonable behaviors of both our vehicle and other vehicles . authors are sincerely grateful to patrick carmody for his help in collecting the traffic-tracking data used in this work and to ryan wolcott for his helpful comments. alliance . darpa under award d13ap00059. the authors are sincerely grateful to patrick carmody for his help in collecting the traffic-tracking data used in part by a grant from ford motor company via the ford-um alliance under award n015392 and in part by darpa under award d13ap00059. the authors .",
    "3": "search (mips) is an important task that has a wide applicability in recommendation systems and classification with a large number of classes. solutions based on locality-sensitive hashing as well as tree-based solutions have been investigated in the recent literature, to perform approximate mips in sublinear time. in this paper, we compare these to another extremely simple approach for solving approximate mips, based on variants of the k-means clustering specifically, we propose to train a spherical kmeans, after having reduced the mips problem to a maximum cosine similarity search (mcss). experiments on two standard recommendation system benchmarks as well as on large vocabulary word embeddings, show that this simple approach yields much higher speedups, for the same retrieval precision, than current state-of-the-art hashing-based and tree-based methods. this simple method also yields more robust retrievals when the query is corrupted . search (mips) problem has recently received increased attention, as it arises naturally in many large scale tasks. in recommendation systems (koenigstein et al., 2014), users and items to be recommended are represented as vectors that are learnt at training time based on the user-item rating matrix. at test time, when the model is deployed for suggesting recommendations, given a user vector, the model will perform a dot product of the user vector with all the item vectors and pick top k items with maximum dot product . two common types of solution for mips in the literature: tree-based methods are mostly data independent. tree-based approaches: the maximum inner product search problem was first formalized in (ram and gray, 2012). ram and gray (2012) provided a tree-based solution for the problem. specifically, they constructed a ball tree with vectors in the database and bounded the maximum inner product with a ball. based search using cone trees when you have a batch of queries. one issue with this ball-tree based on the assumption that a symmetriclsh family does not exist for mips problem. later, and srebro (2015) a notable approach to address the problem of scaling classifiers to a huge number of classes . the first step is to scale all the vectors in our dataset by the same factor such that maxi ||xi||2 = u . the mappings are defined as follows: p (x) = [x, 1/2\u2212 1/2\u2212 ||x||42, . algorithm will evaluate the proposed algorithm for approximate mips. specifically, we analyze the following characteristics: speedup, compared to the exact full linear search, of retrieving top-k items with largest inner product, and robustness of retrieved results to noise in the query. query. we will evaluate the proposed algorithm for approximate mips. specifically, we analyze the following characteristics: speedup, compared to the exact full linear search, of retrieving top-k items with largest inner product, and robustness of retrieved results to noise . 1 word embedding dataset, and 69,888 users. given the user-item matrix z, we follow the puresvd procedure . each row in w\u03c2 is used as the vector representation of the user and each row in r is the vector representation of the movie. we construct a database of all 10,677 movies and consider 60,000 randomly selected users as queries. word2vec another standard collaborative filtering dataset with 17,770 movies (items) and 480,189 users. we follow the same procedure . with. pca-tree: et al., 2014) is the state-of-the-art tree-based method which was shown to be superior to ip-tree (koenigstein et al., 2014) . method first converts mips to nns by appending an additional component to the vectors to make them of constant norm. then the principal directions are learnt and the data is projected using these principal directions. finally, a balanced tree is constructed using as splitting criteria at each level the median of component values along the corresponding principal direction. each level uses a different principal direction, in decreasing order of variance. srp-hash: this is the signed random projection hashing method for mips proposed in shrivastava and li (2015). srp-hash converts mips to mcss . algorithms (for k \u2208 100}) compared to the exact full search. note that this section does not include the hierarchical version of k-means in the experiments, as the databases were small enough (less than 20,000) for flat k-means to perform well. specifically, speedup is defined as speedupa0(a) = time taken by algorithm a (7) where a0 is the exact linear search algorithm that consists in computing the inner product with all training items. . if the tree is of depth d, then we need to do a fraction of dot product. while a dot product involves accessing all d components of the vector, each permutation in wta-hash only needs to access k elements of the vector. . embedding mips also, be interested in the top-10 and top-100 mips . mips mips has the global view of the vector at every step while pca-tree considers one dimension at a time. . lsh clustering generalizes has proposed a new and efficient way of solving approximate k-mips based on a simple clustering and showed it can be a good alternative to the more popular lsh or tree-based techniques. we regard the simplicity of this approach as one of its strengths. empirical results on three real-world datasets show that this simple approach clearly outperforms the other families of techniques. it achieves a larger speedup while maintaining precision, and is more robust to input corruption, an important property for generalization, as query test points are expected to not be exactly equal to training data points. clustering mips better to related, but unseen data than the hashing approaches we evaluated. in future work, we plan to adapt on-the-fly the clustering for our approximate kmips . the authors would like to thank the developers of theano (bergstra et al., 2010) for developing such a powerful tool. we acknowledge the support of the following organizations for research funding and computing support: samsung, calcul quebec, canada, canada, canada, the canada research chairs and cifar. samsung, nserc, calcul quebec, the canada research chairs and cifar. samsung, nserc, calcul 2010) the canada research funding and computing support: samsung, nserc, calcul . the authors would like to thank the developers of theano (bergstra et al., 2010) for developing such a powerful tool. we acknowledge the support of the following organizations for research funding and computing support: samsung, calcul canada, the canada research chairs and cifar. we acknowledge the support of the following organizations for research funding and computing support: samsung, calcul compute the powerful tool. we acknowledge the support of the following organizations for research funding and computing support: (bergstra et al., 2010) .",
    "4": "the development of intelligent machines is one of the biggest unsolved challenges in computer science. in this paper, we propose some fundamental properties these machines should have, focusing in particular on communication and learning. we discuss a simple environment that could be used to incrementally communication, as a prerequisite to more complex interaction with human users. we also present some conjectures on the sort of algorithms the machine should support in order to profitably learn from the environment. communication, as a prerequisite to more complex interaction with human users. we also present some conjectures on the sort of algorithms the machine the basics of natural-language-based communication, . the development of intelligent machines is one of the biggest unsolved challenges in computer science. . a machine capable of performing complex tasks without requiring laborious programming would be tremendously useful in almost any human endeavor, from performing menial jobs for us to helping the advancement of basic and applied research. given the current availability of powerful hardware and large amounts of machine-readable data, as well as the widespread interest in sophisticated machine learning methods, the times should be ripe for the development of intelligent machines. still, since \u201csolving ai\u201d seems too complex a task to be pursued all at once, in the last decades the computational community has preferred to focus on solving relatively narrow empirical problems that are important for specific applications, but do not address the overarching goal of developing general-purpose intelligent machines. . the guiding principles we implicitly considered in formulating the desiderata are to minimize the complexity of the machine, and to maximize interpretability of its behavior by humans. the guiding principles we implicitly characterize intelligence, we propose here a set of desiderata we believe to be crucial for a machine to be able to autonomously make itself helpful to humans in their endeavors. the guiding principles we implicitly considered in formulating the desiderata are to minimize the complexity of the machine, and to maximize interpretability of its behavior by humans. . rather than attempting to formally characterize intelligence, we propose here a set of desiderata we believe to be crucial for a machine to be able to autonomously make itself helpful to humans in their endeavors. the guiding principles we implicitly considered in formulating the desiderata are to minimize the complexity of the machine, and to maximize interpretability of its behavior by humans. rather than attempting to formally characterize intelligence, we propose here a set of desiderata we believe to be crucial for a machine to be able to autonomously make itself helpful to humans in their endeavors. the guiding principles we implicitly considered in formulating the desiderata are to minimize the complexity of the machine, and maximize interpretability of its behavior by humans. rather than attempting to formally characterize intelligence, we propose here a set of desiderata we believe to be crucial for a machine to be able to autonomously make itself helpful to humans in their endeavors. the guiding principles we implicitly considered in formulating the desiderata are to minimize the complexity of the machine, and maximize interpretability of its behavior by humans. . machine will be senseless to build a machine that is supposed to perform complex operations if there is no way for us to specify the aims of these operations, or to understand the output of the machine. while other communication means could be entertained, natural language is by far the easiest and most powerful communication device we possess, so it is reasonable to require an intelligent machine to be able to communicate through language. indeed, the intelligent machine we aim for could be seen as a computer that can be programmed through natural language, or as the interface between natural language . \u201cgood old\u201d lied in the assumption that it would be possible to program an intelligent machine largely by hand. we believe it is uncontroversial that a machine supposed to be helping us in a variety of scenarios, many unforeseen by its developers, should be endowed with the capability of learning. a machine that does not learn cannot adapt or modify itself based on experience, as it will react in the same way to a given situation for its whole lifetime. however, if the machine makes a mistake that we want to correct, it is necessary for it to change its behavior\u2013thus, learning is a mandatory component. together with learning allows the machine to adapt itself to the external environment, . ion-based intelligent machines are controlled by an automatic mechanism, avoiding the complications that would arise from letting the machine interact with the \u201creal world\u201d from the very beginning, and allowing us to focus on challenges that should be connected to the real world in order to learn how to help humans with their needs. channels are trained in this controlled environment to later be connected and act within it, even if the communication takes place in a language the human is not yet familiar with. after mastering the basic language and concepts of the simulated environment, the machine . static set of labeled examples, as in common machine learning setups. and it is entirely scripted by the experimenters. again, this might be worryingly reminiscent of entirely hand-coded good-old however, the teacher need not be a very sophisticated program. in particular, for each task it presents to the learner, it will store a small set of expected responses, and only reward the learner if its behaviour exactly matches one response. similarly, when responding to learner\u2019s requests, the teacher is limited to a fixed list of expressions it knows how to respond to. the reason why this suffices is that the aim of our ecosystem is straightforward . learner has already learned how to pay attention to the teacher, to identify the basic units of language (find regularity in bit patterns, learn characters, then words and so on). it must moreover acquire basic sequence and manipulation skills, and develop skills to form memory and learn efficiently. these very initial stages of learning are extremely important, as we believe they constitute the building blocks of intelligence. however, as bit sequences do not make for easy readability, we focus here on an immediately following phase, in which the learner may interrupt the learner to prevent him from completing a command that would have disastrous consequences, or the learner may interrupt the learner . machine works as an assistant to alice, an elderly person living alone. and he also interacts with the machine. we assume that, as part of its training, the machine has been taught how to issue internet commands and process their outcomes. in the example of how the machine does not need to store all the knowledge it needs to accomplish its duties, as it can retrieve useful information from the web on demand, and reason about it. input: bob: i just spoke to the doctor, who said my mother needs to move for at least one hour per day, . in this section, we will outline some of our ideas about how to build intelligent machines that would benefit from the learning environment we described. while we do not have a concrete proposal yet about how exactly such machines should be implemented, we simply want to provide some food for thought. as in the previous sections, we try to keep the complexity of the machine at the minimum, and only consider the properties that seem essential. we will discuss some of the properties and components we think are needed to support the desired functionalities. we have no pretense of completeness, we simply want to provide some food for thought. as in the previous sections, we will outline some of our ideas about how to build intelligent machines that would benefit from the learning environment we described. while we do not have a concrete proposal yet about how exactly such machines should be implemented, we will discuss some of the properties and components we think are needed to support the desired functionalities. we have no pretense of completeness, we simply want to keep the complexity of the machine at the minimum, . the machine will have to understand the concept of positive and negative reward, and develop complex strategies to deal with novel linguistic inputs. this requires discovery of algorithms, and the ability to remember facts, skills and even learning strategies. next, in order to translate, the machine needs to store pairs of words. the number of pairs is unknown and a flexible growing mechanism may be required. and the functionality of the machine can be fixed. for very specialized forms of behavior, it should be possible to program the solution manually. however, once the machine understands how to populate the dictionary with examples, the learning left to do is of a very simple nature: the machine does not have to update its learning strategy, but only to store and organize the incoming information into long-term memory using previously acquired skills. finally, once the vocabulary memorization process is finished . skills, moreover, has been encountered before. moreover, . the machine should have the capacity to extend itself. without being able to store facts and algorithms corresponding to learned facts and skills, the machine could not deal with rather trivial assignments, such as recalling the solution to a new task is related to that of earlier tasks. consider for example the solution . the intelligent machine will be based on a turing-complete computational model. that is weaker than turing-complete cannot represent certain patterns in the data efficiently, which in turn means it cannot truly learn them in fixed length, just like the turing machine (the very fact that humans can describe turing-complete systems shows that they are, in practical terms, turing-complete: it is irrelevant, for our purposes, whether human online processing capabilities are strictly turing-complete\u2013 what matters is that their reasoning skills, at least when aided by external supports, are). note that there are many turing-complete and turing machines in particular are a lot less efficient than some alternatives, e.g., random access machines. thus, we are not interested in building the intelligent machine . turing\u2019s turing thought that a good way to construct a machine capable of passing his famous test would be to develop a child machine, and teach it further skills through various communication channels. these would include sparse rewards shaping the behavior of the child machine, and other information-rich channels such as language input from a teacher and sensory information. we share turing\u2019s goal of developing a child machine capable of independent communication through natural language, and we also stress the importance of sparse rewards. the main distinction between his and our intelligent machine is not to fool human judges into believing it is actually a real person. instead, we aim to develop a machine that can perform a similar set of tasks to those a human can do by using a computer, an internet connection . the intelligent machine may be based on. on modeling single skills in isolation, we believe that all aspects of intelligence should be holistically addressed within a single system. we proposed a simulated environment that requires the intelligent machine to acquire new facts and skills through communication. in this environment, the machine must learn to perform increasingly more ambitious tasks, being naturally induced to develop complex linguistic and reasoning abilities. we also presented some conjectures on the properties of the computational system that the intelligent machine may be based on. these include learning of algorithmic patterns from a few examples without strong supervision, and development of a longterm memory to store both data and learned skills. we tried to put this in contrast with currently accepted paradigms in machine learning, to show that current methods are far from adequate, and we must strive to develop non-incrementally novel techniques. this roadmap constitutes only the beginning of a long journey towards ai, and we hope other researchers will be joining it in pursuing the goals it outlined. this roadmap constitutes only the beginning of a long journey towards ai, and we hope other researchers will be joining it in pursuing the goals it outlined. where the focus is on modeling single skills in isolation, we believe that all aspects of intelligence should be holistically addressed within a single system. we proposed a simulated environment that requires the intelligent machine to acquire new facts and communication as its fundamental abilities. contrary to common practice in current machine learning, . we thank le\u0301on bottou, gabriel synnaeve, arthur szlam, van der maaten, and roberto zamparelli for many stimulating discussions. an early version of this proposal has been discussed in several research groups since 2013 under the name incremental learning of algorithms (mikolov, 2013). . ai research team, as well as gemma boleda, katrin erk, germa\u0301n and roberto zamparelli . ai research team, as well as facebook ai research groups .",
    "5": "new training methodology for generative adversarial networks. the key idea is to grow both the generator and discriminator progressively: starting from a low resolution, we add new layers that model increasingly fine details as training progresses. this both speeds the training up and greatly stabilizes it, allowing us to produce images of unprecedented quality, e.g., images at 1024. we also propose a simple way to increase the variation in generated images, and achieve a record inception score of 8.80 in unsupervised cifar10. additionally, we describe several implementation details that are important for discouraging unhealthy competition . inpainting den oord et al., et al., et al., et al., et al., et al., 2017; et al., 2017; et al., 2017; et al., et al., 2017; et al., 2017; et al., 2017; et al., et . the generator is of main interest \u2013 the discriminator is an adaptive loss function that gets discarded once the generator . primary contribution is a training methodology for gans where we start with low-resolution images, and then progressively increase the resolution little by little we are continuously asking a much simpler question compared to the end goal of discovering a mapping from latent vectors to e.g. 10242 images. . the progressive training has several benefits. early on, the generation of smaller images is substantially more stable because there is less class information and fewer modes (odena et al., by increasing the resolution little by little layers . training data, and salimans et al. suggest \u201cminibatch discrimination\u201d as a solution. they compute feature statistics not only from individual images but also across the minibatch, thus encouraging the minibatches of generated and training images to show similar statistics. this is implemented by adding a minibatch layer towards the end of the discriminator, where the layer learns a large tensor that projects the input activation to an array of statistics. a separate set of statistics is produced for each example in a minibatch and it is concatenated to the layer\u2019s output, so that the discriminator can use the statistics internally. we simplify this approach drastically while also improving the variation. our simplified solution . ba et al., 2016) in the generator, and often also in the discriminator. these normalization methods were originally introduced to eliminate covariate shift. however, we have not observed that to be an issue in gans, and thus believe that the actual need in gans is constraining signal magnitudes and competition. we use a different approach that consists of two ingredients, neither of which include learnable parameters. as a result of unhealthy competition between the two networks. most if not all earlier solutions discourage this by using a variant of batch normalization (ioffe & szegedy, 2016; salimans & kingma, ba et al., 2016) in the generator, and often also in the discriminator. these normalization methods were originally introduced to eliminate covariate shift. however, we have not observed that to be an issue in gans, and thus believe that the actual need in gans is constraining signal magnitudes and competition. we use a different approach that consists of two ingredients, neither of which include learnable parameters. are prone to the escalation of signal magnitudes . he\u2019s initializer (he et al., the benefit of doing this dynamically instead of during initialization is somewhat subtle, and relates to the scale-invariance in commonly used adaptive stochastic gradient descent methods such as rmsprop (tieleman & hinton, 2012) and adam (kingma & ba, 2015). these methods normalize a gradient update by its estimated standard deviation, thus making the update independent of the scale of the parameter. as a result, if some parameters have a larger dynamic range than others, they will take longer to adjust. this is a scenario modern initializers cause, and thus it is possible that a learning rate is both too large and too small at the same time. our approach ensures that the dynamic range, and thus the learning speed, is the same for all weights. a similar reasoning was independently used by van laarhoven (2017). et al., 2015). and then explicitly scale the weights at runtime. to be precise, we set w\u0302i = wi/c, where wi are the weights and c is the per-layer normalization constant from he\u2019s initializer (he et al., the benefit of doing this dynamically instead of during initialization is somewhat subtle, and relates to the scale-invariance in commonly used adaptive stochastic gradient descent methods such as rmsprop (tieleman & hinton, 2012) and adam (kingma & ba, 2015). . bx,y = ax,y/ \u221a 1 n is the number of feature vector in the generator and discriminator spiral out of control as a result of competition, we normalize the feature vector in each pixel to unit length in the generator after each convolutional layer. we do this using a variant of \u201clocal response normaliza- (krizhevsky et al., 2012), configured as bx,y = 10\u22128, n is the original and normalized feature vector in pixel (x, y), respectively. we find it surprising that this heavy-handed constraint does not seem to harm the generator in any way, and indeed with most datasets it does not change the results much, but it prevents the escalation of signal magnitudes very effectively when needed. spiral out of control as a result of competition, the scenario where the magnitudes in the generator and bx,y are the original and normalized feature maps, and ax,y and bx,y are the number of feature maps, . ms-ssim pyramid (burt & adelson, 1987) representations of generated and target images, starting at a low-pass resolution of 16 \u00d7 16 pixels. as per standard practice, the pyramid progressively doubles until the full resolution is reached, each successive level encoding the difference to an up-sampled version of the previous level. a single laplacian pyramid level corresponds to a specific spatial frequency . images and latent space interpolations. in this section we also invite the reader to consult the accompanying video (https://youtu.be/g06decz-qtg) for additional result images and latent space interpolations. in this section we discuss a set of experiments that we conducted to evaluate the quality of our results. please refer to appendix a for detailed description of our network structures and training configurations. we also invite the reader to consult between the network structure (e.g., convolutional resizing), training configuration (various normalization layers, lsgan). and training loss (wgan-gp, lsgan). operations), . configuration (various normalization layers, minibatch-related resizing), training configuration (various normalization . we will first use the sliced wasserstein distance (swd) and multi-scale structural similarity (msssim) et al., 2017) in an unsupervised setting using celeba (liu et al., et al., 2015) and lsun bedroom (yu et al., 2017) in 1282 resolution. celeba . the figure shows only a small number of examples for each row of the table, but a significantly broader set is available in appendix h. intuitively, a good evaluation metric . the first two plots correspond to the training configuration of gulrajani et al. (2017) without and with progressive growing. we observe that the progressive variant offers two main benefits: it converges to a considerably better optimum and also reduces the total training time by about a factor of two. the improved convergence is explained by an implicit form of curriculum learning that is imposed by the gradually increasing network capacity. without progressive growing, all layers of the generator and discriminator are tasked with simultaneously finding succinct intermediate representations for both the large-scale variation and the small-scale detail. with progressive growing, however, the existing low-resolution layers are likely to have already converged early on, so the networks are only tasked with refining the representations by increasingly smaller-scale effects as new layers . datasets \u00d7 1024 of the images at 1024 \u00d7 1024 we refer to appendix c for further details about the generation of this dataset. our contributions allow us to deal with high output resolutions in a robust and efficient fashion. figure 5 shows latent space interpolations and visualizes the interpolation works so that we first randomize a latent code for each frame (512 components sampled individually from n (0, 1)), then blur the latents across time with a gaussian (\u03c3 = 45 frames @ 60hz), and finally normalize each vector to lie on a hypersphere. we trained the same network . lsun bedroom. figure 7 gives selected examples from seven lsun categories at 2562. a larger, non-curated set of results from all 30 lsun categories is available in appendix g, . the video demonstrates interpolations. we are not aware of earlier results in most of these categories, and while some categories work better than others, we feel that the overall quality is high. and the video demonstrates interpolations. we are not aware of earlier results in most of these categories, categories . the best inception scores for cifar10 (10 categories of 32 rgb images) we are aware of are 7.90 for unsupervised and 8.87 for label conditioned setups (grinblat et al., 2017). the large difference between the two numbers in the unsupervised setting, while label conditioning can remove many such transitions. when all of our contributions are enabled, in the unsupervised setting. appendix d shows a representative set of generated images along with a more comprehensive list of results from earlier methods. the network and training setup were the same as for celeba, progression limited to 32 \u00d7 32 of course. the only customization was to the wgan-gp\u2019s regularization term ex\u0302\u223cpx\u0302 [(||\u2207x\u0302d(x\u0302)||2 \u2212 et al. et . \u03b3 = 1.0, which corresponds to 1-lipschitz, but we noticed that it is in fact significantly better to prefer fast transitions (\u03b3 to minimize the ghosts. we have not tried this trick with other datasets. . while the quality of our results is generally high compared to earlier work on gans, and the training is stable in large resolutions, there is a long way to true photorealism. semantic sensibility and understanding dataset-dependent constraints, such as certain objects being straight rather than curved, leaves a lot to be desired. there is also room for improvement in the micro-structure of the images. that said, we feel that convincing realism may now be within reach, especially in celeba-hq. semantic sensibility and understanding dataset-dependent constraints, such as certain objects being straight rather than curved, leaves a lot to be desired. there is also room for improvement in the micro-structure of the images. that said, we feel that convincing realism may now be within reach, especially in celeba-hq. semantic sensibility . mikael honkavaara, tero and richard calderwood for useful comments. . oskar elek, jacob munkberg, and jon hasselgren were related to the celeba-hq dataset. dmitry korobchenko and richard calderwood . a.1 1024\u00d7 1024 networks used for celeba-hq table 2 shows network architectures of the full-resolution generator and discriminator that we use with the celeba-hq dataset. both networks consist mainly of replicated 3-layer blocks that we introduce one by one during the course of the training. the last conv 1 \u00d7 1 layer of the generator corresponds to the torgb block in figure 2, and the first conv 1 \u00d7 1 layer of the discriminator similarly corresponds to fromrgb. we start with 4 \u00d7 4 resolution and train the networks until we have shown the discriminator 800k real images in total. we then alternate between two phases: fade in the first 3-layer block during the next 800k images, stabilize the networks using leaky relu with leakiness 0.2 in all layers of both networks, except for the last layer . original celeba dataset. resolution. as a starting point, we found it necessary to apply several image processing steps to ensure consistent quality and to center the images on the face of a single person \u2013 often only a part of the face. thus, we found it quality, each jpeg image using two pre-trained neural networks: a convolutional autoencoder trained to remove jpeg artifacts in natural images, similar in terms of resolution and visual quality, ranging all the way from 43 \u00d7 55 to 6732 \u00d7 8984. some of them show crowds of several people whereas others focus on the face of a single person \u2013 often only a part of the original celeba dataset. . shows non-curated images generated in the unsupervised setting, and table 3 compares against prior art in terms of inception scores. we report our scores in two ways: 1) the highest score observed during training runs (here \u00b1 refers to the standard deviation computed from the highest scores seen during training, starting from ten random initializations. arguably the latter methodology is much more meaningful as one can be lucky with individual runs (as we were). we did not use any kind of augmentation with this dataset. and 2) the mean and standard deviation computed from the highest scores calculator) and 2) the mean and standard deviation returned by the inception score calculator) and 2) the highest score observed during training runs (here \u00b1 refers to the standard deviation returned . metz et al. (2016) describe a setup where a generator synthesizes digits simultaneously to 3 color channels, the digits are classified using a pre-trained classifier error rate in our case), and concatenated to form a number in [0, 999]. they generate a total of 25,600 images and count how many of the discrete modes are covered. they also compute kl divergence as kl(histogram || uniform). modern gan implementations can trivially cover all modes at very low divergence (0.05 in our case), and thus metz et al. specify a fairly low-capacity generator and two severely crippled discriminators (\u201ck/2\u201d has \u223c 2000 params and \u201ck/4\u201d only about \u223c 500) to tease out differences between training methodologies. both of these networks use batch normalization. . 10 shows the nearest neighbors found for our generated images. figure 11 gives additional generated examples from celeba-hq. we enabled mirror augmentation for all tests using celeba and celeba-hq. in addition to the sliced wasserstein distance (swd), (heusel et al., 2017) from 50k images. from 50k images. . fre\u0301chet inception distance (fid) (heusel et al., we also quote the recently introduced fre\u0301chet inception distance (fid) (heusel computed from 50k images. et 10 shows the nearest neighbors found for our generated images. figure 11 . figures generated for all 30 lsun categories. a separate network was trained for each category using identical parameters. all categories were trained using 100k images, except for bedroom and dog that used all the available data. since 100k images is a very limited amount of training data for most categories, we enabled mirror augmentation in these tests (but not for bedroom or dog). not for bedroom or dog). since 100k images is a very limited amount of training data for most categories, categories. a separate network was trained for each category using identical parameters. all categories were trained using 100k images, except for bedroom and dog that used all the available data. since 100k show representative images generated for all 30 lsun categories. a separate network was trained for each category using identical parameters. all categories were trained using 100k images, . figures 12\u201317 show representative images generated for all 30 lsun categories. a separate network enabled mirror augmentation in these tests (but not for bedroom or dog). we enabled mirror augmentation . figure 18 shows larger collections of images corresponding to the non-converged setups in table 1. the training time was intentionally limited to make the differences between various methods more visible. in table 1. the training time . figure 18 shows larger collections of images corresponding to the non-converged setups in table 1. the training time was intentionally limited to make the differences between various methods more visible. visible. . figure 18 shows larger collections of images corresponding to the non-converged setups in table 1. the training time was intentionally limited to make the differences between various methods more visible. .",
    "6": "jenny finds her house in a mess when she returns from work, . she remembers that she left a window open, as the most plausible explanation. while abduction has long been considered to be at the core of how people interpret and read between the lines in natural language inference . incomplete observations (peirce, 1965a). figure 1 illustrates an example. given the incomplete observations about the world that o1: \u201cjenny cleaned her house and went to work, leaving the window just a crack open.\u201d and sometime later o2: \u201cwhen jenny returned home, she saw her house was a mess.\u201d, we can hypothesize different potential explanations and reason about which is the most likely. we can readily rule out h3 since it fails to justify the observation o2. while h1 and h2 are both plausible, the most likely explanation based on commonsense is h1 . 3art: 2\u03b1nli and \u03b1nlg are pronounced as alpha-nli and alpha-nlg, respectively 3art: reasoning in narrative text. 4data available to download at http://abductivecommonsense.xyz \u2022 o2: the observation at time t2 > t1. \u2022 h+: the observation at time t1. 2\u03b1nli and o2. are pronounced as alpha-nli and o2. formally, the task of generating a valid hypothesis h+ given the observations and a pair of hypotheses, the \u03b1nli task is to select the most plausible explanation (hypothesis). abductive natural language generation \u03b1nlg . a distinct feature of the \u03b1nli task is that it requires jointly considering all available observations and their commonsense implications, to identify the correct hypothesis. formally, the \u03b1nli task is to select the hypothesis h\u2217 that is most probable given the observations. h\u2217 = arg max hi p (h = hi|o1, o2) rewriting the objective using bayes rule conditioned on o1, we have: p (hi|o1, o2) \u221d o2), . the three variables \u3008o1, h,o2\u3009 form a linear markov chain, where the second observation is conditionally independent of the first, . model can also be conditioned on background knowledge k. parameterized models can then be trained to minimize the negative log-likelihood over instances in art: l = \u2212 n\u2211 i=1 (whi wo11 wo11 . bleu and \u03b1nlg. since \u03b1nli is framed as a binary classification problem, for \u03b1nlg, we choose accuracy as our primary metric. for \u03b1nlg, we report performance on automated metrics such as bleu (papineni et al., 2002), cider (vedantam & lavie, 2005) and also report human evaluation results. . models on the art dataset, and several other baseline systems for both \u03b1nli and \u03b1nlg. since \u03b1nli is framed as a binary classification problem, we choose accuracy as our evaluation of finetuned state-of-the-art pre-trained language models on the art dataset, and several other baseline systems for both \u03b1nli and also report human evaluation results. 2015), meteor (banerjee & lavie, 2005) and also report human evaluation results. 2015), cider (vedantam et al., 2002), et al., 2002), et al., & lavie, et . research in this direction. model gpt (%) art acc. random (2-way choice) 50.1 et al., et al., 2017) et al., et al., et . the full set of instructions for all crowdsourcing tasks to facilitate future data and research in this direction. model gpt crowdsourcing tasks are complex and require creative writing. along with the art dataset, we will publicly release templates and the full set of instructions for all crowdsourcing tasks to facilitate future data accuracy is reported as the mean of five models trained with random seeds, with the standard deviation . appendix a.4. adversary table 1 also includes results of our experiments where gpt was used as the adversary. notably, in addition, the gap between the linear chain and fully connected bert models diminishes when bert is used as an adversary \u2013 in spite of being a more powerful model \u2013 which indicates that adversarial filtering disproportionately impacts the model used as the adversary in art. the gap between the best model and human performance. 7additional crowdsourcing details in the appendix a.1 input format for the gpt model and bert variants is described in the appendix a.4. gpt adversary table 1 when the other model is used for filtering. . equation 4, 2019), et al., et al., et . tokens are not canonicalized and are represented as short phrases of text. thus, . script learning (schank & abelson, 1975) and the narrative cloze test (chambers & jurafsky, et al., et al., 2016), et al., et al., et al., et . the \u201cgrass is closely related to the kind of reasoning humans perform in everyday situations, where information is incomplete and definite inferences et . the first study that investigates the viability of language-based abductive we conceptualize and introduce a new challenge dataset, art, which consists of 20,000 commonsense narratives accompanied with over 200,000 explanatory hypotheses. in our experiments, we establish comprehensive baseline performance on this new task based on state-of-the-art nli and language models, which leads to 68.9% accuracy with a considerable gap with human performance (91.4%). the \u03b1nlg task is significantly harder \u2013 while humans can write a valid explanation 96% of times, the best generator models can only achieve 45%. our analysis leads to new insights into the types of reasoning that deep pre-trained language models fail to perform \u2013 despite their strong performance on the closely related but different task of entailment nli \u2013 pointing to interesting avenues for future research . fellowship under grant no. dge darpa cwc through niwc pacific (n66001-19-2-4031), and allen institute for ai. computations on beaker.org were supported in part by credits from google cloud. (iis-1524371), the national science foundation graduate research fellowship . the allen institute for ai. computations darpa mcs program through niwc pacific (n66001-19-2-4031), and the allen institute for beaker.org were supported in part by nsf (iis-1524371), the national science foundation graduate research fellowship . details of our data collection method. task 1 - plausible hypothesis options in this task, participants were presented an incomplete three-part story, which consisted of the first observation (o1) and the second observation (o2) of the story. they were then asked to complete the story by writing a probable middle sentence that explains why the second observation should follow after the first one. we instructed participants to make sure that the plausible middle sentence (1) is short (fewer than 10 words) and (2) simple as if narrating to a child, (3) avoids introducing any extraneous information, and (4) uses names instead of pronouns (e.g., he/she) wherever possible. all participants were required to meet the following qualification requirements: (1) their location is greater than 95(%), and (3) number of hits approved is greater than or equal to 10, participants . number of epochs {3, 4, 8} \u2022 number of epochs: {3, 4, \u2022 learning rate: {1e-5, 3e-5, . size: was used for computing the loss. the best performance was obtained with a batch size of 4, learning rate of 5e-5, and number of epochs equal . the bag-of-words classifier is trained on simple features like word length, overlap and sentiment features to select one of the two hypothesis choices. the average of glove (pennington et al., in a story (two observations and a hypothesis option) are concatenated and passed through fully-connected layers to produce a score for each hypothesis. the accuracies of both baselines are close to 50% (svm: bow: specifically, we train an infersent classifier and a bag-of-words model using glove embeddings. both models achieve accuracies close to 50%. an infersent et al., 2017) baseline computes for words in each sentence to form sentence embeddings. the sentence embeddings in a story (two observations and a hypothesis option) are concatenated and passed through fully-connected layers to produce a score for each hypothesis. the accuracies of both baselines are close to 50% (svm: bow: specifically, we train an svm classifier and a bag-of-words model using sentences embedded by max-pooling . \u3008o1, o2, h+, \u3009 is the pool of plausible (resp. implausible) . the distractors share stylistic features of the positive samples as well as that of the context (i.e. observations o1 and o2) \u2013 . atomic (sap et al., 2019) represents commonsense knowledge as a graph with events are nodes and the following nine relations as edges: 1. xintent: why does x cause an event? 2. xneed: what does x need to do before the event? 3. xattr: how would x likely want to do after the event? 6. oreact: what effects does the event have on others? 5. xwant: what would x likely want to do after the event? 8. owant: what effects does the event have on others? 5. xeffect: what effects does the event have on x? 4. what would others likely want to do after the event? 7. oreact: what effects does the event have on others? 5. what would x feel after the event? 7. oreact: what would others likely want to do before the event? 3. xattr: how does x cause an event? 2. xneed: what does x need to do before the event? 3. xattr: what effects does the event have on x? 5. what would x likely want to do . format of input to each variation of the generative model evaluated. describes the format of input to each variation of the generative model . table 8 describes the format of input to each variation of the generative model evaluated. table 8 .",
    "7": "class of convexified convolutional space, the cnn parameters can be represented as a low-rank matrix, which can be relaxed to obtain a convex optimization problem. for learning two-layer convolutional neural networks, we prove that the generalization error obtained by a convexified cnn converges to that of the best possible cnn. for learning deeper networks, we train ccnns in a reproducing kernel hilbert the cnn parameters can be represented as a low-rank matrix, which capture the parameter sharing of convolutional neural networks in a convex manner. . neural networks (cnns) [28] have proven successful across many tasks in machine learning and artificial intelligence, including image classification [28, 25], face recognition [26], text classification [45], and game playing [32, 37]. . the same filter is applied to each patch. however, as with most neural networks, the standard approach to training cnns is based on solving a nonconvex optimization problem that is known to be np-hard [6]. . nonconvex problem. problem. describe the associated nonconvex optimization problem. neural networks to be learned . in this section, we formalize the class of convolutional neural networks to be learned and describe the associated nonconvex optimization problem. . vector x \u2208 (e.g., in y \u2208 rd2 classification scores for the d2 classes). this mapping is formed in the following manner: \u2022 first, we extract a collection of p vectors {zp(x)}pj=1 . the same filters are applied to each patch\u2014this corresponds to the parameter sharing of a cnn. \u2022 third, . l(f(x); \u2208 \u2212fy(x) of classification scores, the associated multiclass logistic loss for a pair (x, y) . n training examples {(xi, yi)}ni=1, we would like to compute an empirical risk minimizer f\u0302cnn \u2208 . general convexification procedure, described in section 3.2, in particular, we show how embedding the nonlinear problem into an appropriately chosen reproducing kernel hilbert space (rkhs) allows us to again reduce to the linear setting. although the linear case is not of practical interest, it provides intuition for our more general convexification procedure, described in section 3.2, which applies to nonlinear activation functions. in particular, we begin in section 3.1 by illustrating the procedure for the special case of the linear activation function. although the linear case is not of practical interest, it provides intuition for our more general convexification cnns. we now turn to the development of the class of convexified cnns. we now turn to the development of the class of convexified activation functions. . filter hj outputs for each x \u2208 rd0 , we first define the p \u00d7 d1-dimensional matrix z(x) for the kth output . fk now depends linearly on the matrix parameter ak. moreover, fa . rd1 \u00d7 rd1 r be a positive semidefinite kernel for particular choices of kernels (e.g., the gaussian rbf kernel) . the representer index pair (i, ] ]. ]. ]. the entry at row (i, p) and column (i\u2032, p\u2032) . the algorithm for learning a two-layer is summarized in algorithm 1; it is a formalization of the steps described in section 3.2. in order to solve the optimization problem (12), the simplest approach is to be carried out efficiently by the algorithm of duchi et al. [16]. . (13) \u2264 the gradient of the objective function defined in (12), and \u03c0r denotes the euclidean projection onto the nuclear norm ball {a . cnn model. polynomial kernel: kernel: := is an arbitrary vector. as a concrete example, we consider kernel functions whose associated rkhs is large enough to contain any function taking the following theorem z 7\u2192 z\u3009), where q is an arbitrary polynomial function and w \u2208 rd1 is comparable to that of the best cnn model. in particular, the following theorem arbitrary polynomial functions (e.g., used by [39, 29]). erf function . the gaussian kernel kernel: z\u2032) := := (14) (14) \u2264 . the filter hj applied to all the patch vectors produces p patches. for example, we might average every pair of adjacent patches, which would produce p \u2032 = p/2 rows. the operation of average pooling can be represented via left-multiplication using a fixed matrix g \u2208 rp \u2032\u00d7p . algorithm 2: learning multi-layer ccnns {(xi, yi)}ni=1, function k, number of layers m, regularization parameters r1, . results are reported on the mnist dataset and its variations for digit recognition, and on the cifar-10 dataset for object classification. the results are reported on the mnist dataset and its variations for digit recognition, and on the cifar-10 dataset for object classification. approach with other methods. the results are reported on the mnist dataset and its variations for digit recognition, and on the cifar-10 dataset for object classification. approach with other methods. the ccnn approach with other methods. we compare the ccnn approach in this section, we compare the ccnn approach with other methods. the results are reported on the mnist dataset and its variations for digit recognition, and on the cifar-10 dataset for object classification. . testing. partitioning is standard for mnist variations [43]. for the ccnn method and the baseline cnn method, we use 10,000 images for validation and 50,000 images for testing. 2,000 images for validation and 50,000 images are of size 28 \u00d7 28. for all datasets, we use 10,000 images for training, this 10k/2k/50k partitioning see the paper [44]). figure 3 shows a number of sample images from these different datasets. all the images are denoted by ccnn-k and cnn-k. each convolutional layer is constructed on 5 \u00d7 5 patches with unit stride, followed by 2\u00d7 2 average pooling. the first and the second convolutional layers contains 16 and 32 filters, respectively. the loss function . cnn and ccnn models with two, three, and four layers each convolutional layer is constructed on 5\u00d7 5 patches with unit stride, followed by 3\u00d7 3 average pooling with two-pixel stride. 2 (for the three convolutional layers). the feature matrix z(x) with fastfood \u03b3 = 1, 2, 2 (for the kernel model [9] . bach [3]. zhang et al. propose a polynomial-time ensemble method for learning fully-connected neural networks, but their approach handles neither parameter sharing nor the convolutional setting. other relevant works for learning fully-connected networks include [35, 23, aslan et al. [1, present convolutional kernel aslan et al. [13] . cnn of the same depth, is computationally efficient, and can be combined with the traditional cnn to achieve better performance. a major open problem is to formally study the convex relaxation of deep cnns. for the two-layer ccnn, we proved that its generalization error converges to that of the best possible two-layer cnn. we handled multi-layer ccnns only heuristically, but observed that adding more layers improves the performance in practice. on real data experiments, we demonstrated that ccnn the traditional cnn of the same depth, is computationally efficient, and the rkhs relaxation for handling non-linearity. for the two-layer ccnn, we proved that its generalization error converges to that of the nuclear norm relaxation for handling parameter sharing, as well as understand them statistically. our convex relaxation consists of two parts: the nuclear norm relaxation for handling non-linearity. for the two-layer ccnn, as well as understand them optimize cnns . (19) since \u2016z\u20162 \u2264 1 and \u2016z\u2032\u20162 \u2264 the series on the right-hand side is absolutely convergent. the inner term on the right-hand side of equation (19) can be simplified to\u2211 (k1,...,kj)\u2208[d1]j zk1 . rd1 \u2192 `2(n) satisfying k(z, z\u2032) is a countable-dimensional vector and \u03d5 := \u03d52, . the filter is parametrized by an infinite-dimensional vector wj . our next step is to reduce the original erm problem . cnn predictors consider the notion of a valid activation function, as defined prior to the statement of theorem 1. 3. . the p-th algorithm. is the predictor trained by the ccnn algorithm. the following lemma shows that f\u0302ccnn is an empirical risk minimizer within fccnn. lemma 4. .",
    "8": "derived from bitcoin, zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well-regarded cryptographic research. in this paper, we examine the extent to which anonymity is achieved in the deployed version of zcash. transactions, ranging from its transparent transactions to the interactions with and within its main privacy feature, a shielded pool that acts as the anonymity set for users wishing to spend coins privately. we conclude that while it is possible to use zcash in a private way, it is also possible to shrink its anonymity set considerably by developing simple heuristics based on identifiable patterns . derived from bitcoin, zcash is often touted as the one with the strongest anonymity guarantees, due to its basis in well-regarded cryptographic research. in this paper, we examine the extent to which anonymity is achieved in the deployed version of zcash. transactions, ranging from its transparent transactions to the interactions with and within its main privacy feature, a shielded pool that acts as the anonymity set for users wishing to spend coins privately. we conclude that while it is possible to use zcash in a private way, it is also possible to shrink its anonymity set considerably by developing simple heuristics based on identifiable patterns . bitcoin in 2008 [34], cryptocurrencies has become increasingly popular to the point of reaching a near-mania, with thousands of deployed cryptocurrencies now collectively attracting trillions of dollars in investment. while the broader positive potential of \u201cblockchain\u201d (i.e., the public decentralized ledger underlying almost all cryptocurrencies) is still unclear, despite the growing number of legitimate users there are today still many people using these cryptocurrencies for less legitimate purposes. these range from victims in ransomware attacks such as wannacry, with many other crimes in between. criminals engaged in these activities may be drawn to bitcoin due to the relatively low friction of making international payments using only pseudonyms as identifiers, but the public nature of its ledger of transactions raises the question of how much anonymity is actually being achieved. indeed, . research has been a significant volume of research in providing solutions for existing cryptocurrencies that allow users to spend coins without revealing which coins are being spent. in terms of the latter, there has also been a significant volume of research on de-anonymizing bitcoin [37, 38, 24, 39, . dash [2] incorporates an additional heuristic in which output addresses receiving change are also linked. once these clusters are formed, a \u201cre-identification attack\u201d [27] . zcash (zec) is an alternative cryptocurrency developed as a (code) fork of bitcoin that aims to break the link between senders and recipients in a transaction. in bitcoin, recipients receive funds into addresses (referred to as the vout in a transaction), and when they spend them they do so from these addresses (referred to as the vin in a transaction). the act of spending bitcoins thus creates a link between the sender and recipient, and these links can be followed as bitcoins continue to change hands. it is thus possible to track any transaction which specifies where the coins are coming from and where they are going. to receive funds, users can provide either a transparent address (t-address) or a shielded address (z-address). coins that are held in z-addresses are said to be in the shielded pool. to specify where the funds are going, a vjoinsplit . addresses are specified in the zcash chain parameters [8]. miners take part in the maintenance of the ledger, and in doing so receive newly generated coins (10 as well as any fees from the transactions included in the blocks they mine. many miners choose not to mine on their own, but join a mining pool; a list of mining pools can be found in table 4. one or many miners win each block, and the first transaction in the block is a hacker group who have published several leaks containing hacking tools from the nsa and accept payment in zcash. we explore their usage of zcash in section 8. . we used a custom set of python scripts equipped with pyspark. blockchain, and loaded a database representation of it into apache spark. we then performed our analysis using a custom set of python scripts equipped with pyspark. we last parsed the block chain on january 21 2018, at which point 258,472 blocks had been generated since the genesis block, out of which 2,485,461 went to the miners and the rest (621,182 zec) went to the founders. blockchain, and loaded a database representation of it into apache spark. 3,106,643 zec had been generated since the genesis block, out of which 2,485,461 zec went to the miners and the rest (621,182 zec) went to the founders. client to download the zcash blockchain, . we used the zcashd client to download the zcash blockchain, at which point 258,472 blocks had been mined. overall, 3,106,643 zec had been generated since the genesis block, out of which 2,485,461 zec went to the miners and the rest (621,182 zec) went to the founders. the block chain on january 21 2018, at which point 258,472 blocks had been mined. overall, 3,106,643 zec had been generated since the genesis block, we then performed our analysis using a custom set of python scripts equipped with pyspark. we last parsed the block chain on january 21 2018, . figures 2 and 3.2 the vast majority of transactions are public (i.e., either transparent or a coin generation). of the transactions that do interact with the pool (335,630, or 14.96%, in total), only a very small percentage of all blocks, as more mainstream (and thus transparent) usage of zcash has increased. 2we use the term \u2018mixed\u2019 to mean transactions that have both a vin and a vjoinsplit. and a vjoinsplit. looking at the types of transactions over time in figures 2 and 3.2 the vast majority of transactions all grow in an approximately linear fashion. . t-addresses used. of these, 8,727 have ever acted as outputs in a t-to-z transaction . a large number of addresses (representing all the individual miners) to pay out of the pool. given the nature of the shielded pool, it is not possible to know the total number of z-addresses used. figure 4 shows the total value in the pool over time. although the overall value is increasing over time, there are certain shielding and de-shielding patterns that create spikes. as we explore in section 6, these spikes . as discussed in section 4, a large proportion of the activity on zcash does not use the shielded pool. this means it is essentially identical to bitcoin, and thus can be deanonymized using the same techniques discussed for bitcoin in section 2. . as discussed in section 4, a large proportion of the activity on zcash does not use the shielded pool. this means it is essentially identical to bitcoin, and thus can be deanonymized using the same techniques discussed for bitcoin . multiple input t-addresses. heuristic 1. if two or more t-addresses are inputs in the same transaction (whether that transaction is transparent, shielded, or mixed), then they are controlled by the same entity. in terms of false positives, we believe that these are at least as unlikely for zcash as zcash is a direct fork of bitcoin and the standard client has the same behavior. in fact, we are not aware of any input-mixing techniques like coinjoin [24] for zcash, so could argue that the risk of false positives is even lower than it is already quite effective but does not capture the common usage of change addresses, in which a transaction sends coins to the actual recipient but then also sends any coins left over in the input back to the sender. et al. [27] use in their analysis a heuristic based on this behavior, but warn that it is somewhat fragile. indeed, their heuristic seems largely dependent on the specific behavior of several large bitcoin services, . the top ten zcash exchanges according to the heuristics et al. [27]. in particular, given that zcash is still relatively new, there are not many different types of services that accept zcash. we thus restricted ourselves to interacting with exchanges. we then withdrew this amount to our own wallet, and again tagged the t-addresses (this time on the sender side) as mentioned in section 3.2 allows users to move amongst cryptocurrencies without the need to create an account. here we did a single \u201cshift\u201d into zcash and a single shift out. a summary of our interactions with all the different exchanges is in table 2. finally, as well as addresses from known mining pools. for the latter we started by scraping the tags of these addresses from the zchain explorer [10]. we then validated them against the blocks advertised on the website . 5.1, clusters, of which 97,539 contained more than a single address. we assigned each cluster a unique identifier, ordered by the number of addresses in the cluster, so that the biggest cluster had identifier 0. 1 resulted in 560,319 clusters, of which 97,539 contained more than a single address. we assigned each cluster a unique identifier, ordered by the number of addresses in the cluster, so that the biggest cluster had identifier 0. 1 resulted in section 5.1, running heuristic 1 resulted in 560,319 clusters, of which 97,539 contained more than a single address. we assigned each cluster a unique identifier, ordered by the number of addresses in the cluster, so that the biggest cluster had identifier 0. as mentioned in section 5.1, running heuristic 1 resulted in 560,319 clusters, of which 97,539 contained more than a single address. we assigned each cluster a unique identifier, ordered by the number of addresses . the top five clusters belonging to popular exchanges. in general, we found that the top five clusters accounted for 11.21% of all transactions. identifying exchanges is important, as it makes it possible to discover where individual users may have purchased their zec. given existing and emerging regulations, they are also the one type of participant in the zcash ecosystem that might know the real-world identity of users. in many of the exchange clusters, we also identified large fractions of addresses that had been tagged as miners. this implies that individual miners use the addresses of their exchange accounts to receive their mining reward, which might be expected if their goal is to cash out directly. we found some, but far fewer, founder addresses at some of the exchanges as well. our clustering also reveals that shapeshift (cluster is fairly heavily used: it had received over 1.1m zec in total and sent roughly the same. unlike the exchanges, its cluster contained a relatively small number of miner addresses (54), which fits with its usage . example, flypool had three single-address clusters while coinotron, coinmine.pl, slushpool and nanopool each had two single-address clusters. (a list of mining pools can be found in table 4 in section 6.2). of the coins that we saw sent from clusters associated with mining pools, 99.8% of it went into the shielded pool, which further validates both our clustering and tagging techniques. for a large proportion of the activity in zcash (as we explore in section 6), many re-use the same set of addresses frequently, so do not belong to large clusters. for example, flypool had three single-address clusters while coinotron, coinmine.pl, slushpool and nanopool each had two single-address clusters. (a list of mining pools can be found in table 4 in section 6.2). of the coins . three large organizations accept zcash donations: the internet archive, and wikileaks. of these, torservers.net accepts payment via a z-address, so we cannot identify their transactions (wikileaks accepts payment via a z-address too, but also via a taddress). of the 31 donations to the internet archive that we were able to identify, which totaled 17.3 zec, 9 of them were made anonymously (i.e., as z-to-t transactions). on the other hand, all of the 20 donations to wik- 468 27th usenix security symposium usenix association ileak\u2019s t-address were made as t-to-t transactions. none of these belong to clusters, as they have never sent a transaction. so we identified three large organizations that accept zcash donations: the internet archive, torservers.net, and wikileaks. of these, torservers.net accepts payment only via a z-address, too, but also via a taddress). of the 31 donations to the internet archive that we were able to identify, which totaled 17.3 zec, 9 of them were made anonymously (i.e., as z-to-t transactions). on the other hand, all of the 20 donations to wik- 468 27th usenix security symposium usenix association ileak\u2019s we identified three large organizations . the first withdrawal spike in december 2016. the cause of the spike was a single transaction in which 7,135 zec was taken out of the pool; given the exchange rate at that time of 34 usd per zec, this was greater than the total number of zec they deposit into the pool, but do so very quickly after the initial deposit. as we see in sections 6.1 and 6.2, this phenomenon is accounted for almost fully by the founders and miners. looking further at the figure, we can see that the symmetry is broken occasionally, and most notably in four \u201cspikes\u201d: two large withdrawals, and two large deposits. some manual investigation . the second withdrawal spike took place on december 25 2017, at block height 242,642. in it, 10,000 zec was distributed among 10 different t-addresses, each receiving 1,000 zec. none of these t-addresses had done a transaction before then, . founder of all coingen transactions, more, the amount deposited was often the same: exactly 249.9999 zec, which is roughly the reward for 100 blocks. this was true of 74.9% of all founder deposits, and 96.2% of all deposits from the third address onwards. there were only ever five other deposits into the pool carrying value between 249 and 251 zec (i.e., carrying a value close but not equal to 249.9999 zec). thus, . the zcash protocol specifies that all newly generated coins are required to be put into the shielded pool before they can be spent further. as a result, we expect that a large quantity of the zec being deposited into the pool are from addresses associated with miners. usenix association 27th usenix security symposium 471 security symposium . the zcash protocol specifies that all newly generated coins are required to be put into the shielded pool before they can be spent further. as a result, we expect that a large quantity of the zec being deposited into the pool are from addresses associated with miners. usenix association 27th usenix security symposium 471 usenix association 27th usenix security symposium that all newly generated coins are required to be put into the shielded pool before they can be spent further. as a result, we expect that a large quantity of the zec being deposited into the pool are from addresses associated with miners. usenix association 27th usenix protocol specifies . the zcash protocol specifies that all newly generated coins are required to be put into the shielded pool before they can be spent further. as a result, we expect that a large quantity of the zec being deposited into the pool . the two dominant mining pools are flypool and f2pool. flypool consistently deposits the same (or similar) amounts, which we can see in their linear representation. f2pool, on the other hand, has bursts of large deposits mixed with periods during which it is not very active, which we can also see reflected in the graph. despite their different behaviors, the amount deposited between the two pools is similar. in total, we gathered 19 t-addresses associated with zcash mining pools, . the number of t-to-z transactions we associated with them. figure 10 plots the value of their deposits into the shielded pool . anyway. in particular, mining pool payouts in zcash are similar to how many of them are in bitcoin [27, 18]. the block reward is often paid into a single address, controlled by the operator of the pool, and the pool operator then deposits some set of aggregated block rewards into the shielded pool. they then pay the individual reward to each of the individual miners as a way of \u201csharing the pie,\u201d which results in z-to-t transactions with many outputs. (in some pools opt for this approach while some form a \u201cpeeling chain\u201d in which they pay each individual miner in a separate transaction, sending the change back to themselves each time.) in the payouts . miners and founders have been identified, in order to identify how the shielded pool is being used. in particular, we ran the heuristic due to quesnelle [36], which said that if a unique value (i.e., a value never seen in the blockchain before or since) is deposited into the pool and then, after some short period of time, the exact same value is withdrawn from the pool, the deposit and the withdrawal are linked in what he calls a round-trip transaction. heuristic [36] for a value v, if there exists exactly one t-to-z transaction carrying value v, where the z-to-t transaction happened after the t-to-z one and within some small number of blocks, then these transactions are linked. in terms of false positives, the fact that the value is unique in the blockchain means that the only possibility of a false positive is if some of the z-to-z transactions split or aggregated coins in such a way that another deposit (or several other deposits) of a different amount were altered within the pool to yield an amount identical to the initial deposit. while this is possible in theory, we believe this lends further credence to their soundness. in terms of the block interval, we ran heuristic 5 for every interval between 1 and 100 blocks; the results are in figure 11. . private transactions; i.e., transactions, with 8,444 vjoinsplits. . information revealed by z-to-z transactions is the miner\u2019s fee, the time . the shadow brokers (tsb) are a hacker collective that has been active since the summer of 2016, and that leaks tools supposedly created by the nsa. some of these leaks are released as free samples, but many are sold via auctions and as monthly bundles. initially, tsb accepted payment only using bitcoin. later, however, they began to accept zcash for their monthly dump service. in this section we discuss how we identified t-to-z transactions that could represent payments to tsb. we identified twenty-four clusters (created using our analysis in section 5) matching our criteria for potential tsb customers, one of which could be a regular customer. but many are sold via auctions and as monthly bundles. initially, tsb accepted payment only using bitcoin. later, however, they began to accept zcash for their monthly dump service. in this section we discuss how we identified t-to-z transactions that could represent payments to tsb. we identified twenty-four clusters (created using our analysis in section 5) matching our criteria for potential tsb customers, one of which could be a regular customer. but the shadow brokers (tsb) are a hacker collective that has been active since the summer of 2016, and that leaks tools supposedly created by the nsa. some of these leaks are released as free samples, but many are sold via auctions and as monthly bundles. initially, tsb accepted payment only using bitcoin. later, however, they began to accept zcash for their monthly dump service. in this section we discuss how we identified t-to-z transactions that could represent payments to tsb. we identified twenty-four clusters (created . the shadow brokers (tsb) are a hacker collective that has been active since the summer of 2016, . tsb announced that they would be accepting zcash for their monthly dump service. throughout the summer (june through august) they accepted both zcash and monero, but in september they announced that they would accept only zcash. table 5 summarizes the amount they were requesting in each of these months. the last blog post was made in october 2017, when they stated that all subsequent dumps would cost 500 zec. to identify potential tsb transactions, we thus looked at all t-to-z transactions not associated with miners or founders that deposited either 100, 200, or 500 zec \u00b1 5 zec. our assumption was that users paying tsb were not likely to be regular zcash users, but rather were using it with the main purpose of making the payment. on this basis, addresses making t-to-z transactions of the above values were flagged as a potential tsb customer if the following conditions held: 1. they did not get their funds from the pool; i.e., . our results, in terms of the number of transactions matching our requirements above up until 17 january 2018, are summarized in table 6. before the first tsb blog post in may, we found only a single matching transaction. this is very likely a false positive, but demonstrates that the types of transactions we were seeking were not common before tsb went live with zcash. after the blog post, we flagged five clusters in may and june for the requested amount of 100 zec. there were only two clusters that was flagged in september, despite the fact that tsb switched to accepting only zcash in september. this is possible for a number of reasons: our criteria may have caused us to miss transactions, or maybe there were no takers. from october onwards we flagged between 1-6 transactions per month. it is hard to know if these represent users paying for old data dumps or are simply false positives. first, into the pool in june, before tsb announced that one of the july dump prices would cost 400 zec. finally, there is a deposit of 400 zec into the pool in june before tsb announced that one of the july dump prices would cost 200 zec. finally, there is one deposit into the pool in june for 100 zec, and one in august for 500 zec, matching tsb prices exactly. the cluster belonged to a new user, and most of the money in this user\u2019s cluster came directly from bitfinex (cluster 3). 3). one in july for 200 zec, and one in august for 500 zec, matching tsb prices . most users are not taking advantage of the main privacy feature of zcash at all. furthermore, the participants who do engage with the shielded pool do so in a way that is identifiable, which has the effect of significantly eroding the anonymity of other users by shrinking the overall anonymity set. future work our study was an initial exploration, and thus left many avenues open for example, it may be possible to classify more z-to-z transactions by analyzing the time intervals between the transactions in more detail, or by examining other metadata such as the miner\u2019s fee or even the size (in bytes) of the transaction. additionally, the behavior of mining pools . authors are supported in part by the eu h2020 titanium project under grant agreement number 740558. mary maller and in part by the eu h2020 titanium project under grant agreement number 740558. mary maller is also supported by a scholarship from microsoft research. grant ep/n028104/1, .",
    "9": "novel reward-learning-from-observation algorithm, trajectory-ranked reward functions from a set of potentially poor demonstrations. when combined with deep reinforcement learning, t-rex outperforms state-of-the-art imitation learning and irl methods on multiple atari and mujoco benchmark tasks and achieves performance that is often more than twice the performance of the best demonstration. we also demonstrate that t-rex is robust to ranking noise and can accurately extrapolate intention by simply watching a learner noisily improve . autonomous agents (ng et al., et al., et al., et . the demonstrator is suboptimal, irl when the demonstrator takes a sequence of demonstrations . demonstrations are difficult to provide for many tasks\u2014for instance, . the goal of our work is to achieve improvements over a suboptimal demonstrator in high-dimensional reinforcement learning tasks without requiring a hand-specified reward function or supervision during policy learning. while there is a large body of research on learning from demonstrations (argall et al., 2012; et al., 2018; osa & doshi, 2018), most work assumes access to action labels, while we learn only from observations. additionally, little work has addressed the problem of learning from ranked demonstrations, especially when they are significantly suboptimal. to the best of our knowledge, our work is the first to show better-than-demonstrator performance in highdimensional tasks such as atari, without requiring active human supervision or access to ground-truth rewards. while there is a large body of research on learning from demonstrations (argall et al., 2012; gao et al., 2018; osa & doshi, most work assumes access to action labels, . the goal is to learn a policy that makes the demonstrations appear near-optimal, while further disambiguating inference by also maximizing the entropy of the resulting policy (ziebart et al., et al., et al., et al., et . the demonstrator. inverse et al., et al., et al., et al., et al., et . demonstrator are unknown. torabi et al. (2018) and liu et al. et al. (2018) et al. (2018) and goo & niekum (2019) to remove the need for training on a wide variety of similar tasks. henderson et al. (2018) and goo & ermon, 2016) . methods based on generative adversarial networks (goodfellow 2014) are notoriously difficult to train and have been shown to fail to scale to high-dimensional imitation learning tasks such as atari (tucker et al., (2018) and liu et al. (2018) . suboptimal demonstrations. & billard (2011) propose a method that learns from failed demonstrations where a human attempts, can be used to optimize a policy to match the expected feature counts of successful demonstrations while not matching the feature counts of failed demonstrations. zheng et al. (2014) and choi et al. (2019) et al., 2018). et al., . gao et al., 2018). however, it is often still difficult to perform significantly better than the demonstrator (hester et al., 2017) and designing reward functions . video games (e.g. atari) qureshi & yip, 2016; fu et al., 2016; fu et al., 2016; qureshi & yip, tucker et al. (2018) et . state-of-the-art irl methods on the atari domain and showed that they are unsuccessful, even with near-optimal demonstrations and extensive parameter tuning. our work builds on the work of christiano et al. (2018) . s \u2192 and discount factor \u03b3 (puterman, 2014). given a policy and an mdp, the expected discounted return of the policy is given by j(\u03c0) = e[ \u2211\u221e trt|\u03c0]. in this work we are concerned with the problem of inverse reinforcement learning from observation, where we do not have access to the reward function of the mdp nor the actions taken by the demonstrator. given a sequence of m trajectories \u03c4t for t = 1, . trajectory-ranked t-rex has two steps: (1) reward inference and (2) policy optimization. given the ranked demonstrations, t-rex performs reward inference by approximating the reward at state s using a neural network, r\u0302\u03b8(s), . the parameterized reward function r\u0302\u03b8 can be trained with ranked demonstrations . we first evaluated our proposed method on three robotic locomotion tasks using the mujoco simulator (todorov et al., et al., 2012) namely halfcheetah, hopper, and ant. in all three tasks, the goal of the robot agent is to move forward as fast as possible without falling to the ground. gym (brockman et al., 2016), namely halfcheetah, hopper, and ant. in all three tasks, the goal of the robot agent is to move forward as fast as possible without falling to the ground. gym (brockman et al., 2012) within openai gym (brockman 2016), hopper, and ant. in all three tasks, tasks . we first evaluated our proposed method on three robotic locomotion tasks using the mujoco simulator (todorov et al., 2012) within openai gym (brockman 2016), namely halfcheetah, hopper, and ant. in all three tasks, the goal of the robot agent is to move forward as fast as possible without falling to the ground. simulator . we first evaluated our proposed method on three robotic locomotion tasks using the mujoco simulator (todorov et al., namely halfcheetah, 2016), within openai gym (brockman et al., 2012) and ant. in all three tasks, the goal of the robot agent . optimization (ppo) et al., agent with the ground-truth reward for 500 training steps (64,000 and checkpointed its policy after every 5 training steps. for each checkpoint, we used two stages consisting of the worst 12 and 40 trajectories. for hopper, we used the worst 9, 12, and 18 trajectories. for hopper, we used the worst 9, 12, and hopper. for halfcheetah, we used the ground truth returns. to evaluate the effect of different levels of suboptimality, we divided the trajectories into different overlapping stages. we used 3 stages for halfcheetah and hopper. with the given default hyperparameters. implementation . openai baselines (dhariwal et al., 2017) with the ground-truth reward for 500 training steps . we trained the reward network using 5,000 random pairs of partial trajectories of length 50, with preference labels based on the trajectory rankings, not the ground-truth returns. to prevent overfitting, we represented the reward function using an ensemble of five deep neural networks, with a learning rate of 1e-4 and a minibatch size of 64 for 10,000 timesteps. to evaluate the quality of our learned agent receives the average of the ensemble as the reward, plus the control penalty used in openai gym (brockman et al., this control penalty represents a standard safety prior over reward functions for robotics tasks, namely to minimize joint torques. we found that optimizing a policy based solely on this control penalty does not lead to forward locomotion, thus learning a reward function from demonstrations is still necessary. . t-rex and gail usually fail to perform better than the average demonstration performance because they explicitly seek to imitate the demonstrator rather than infer the demonstrator\u2019s intention. reward . t-rex also outperforms bco and gail on all tasks and stages except for stage 2 for hopper and ant. bco and gail usually fail to perform better . t-rex on eight atari games shown in table 1. . we used every 5th training update due to the ability of ppo to quickly find a good policy. for all games except for seaquest and enduro. for seaquest, we used every 50th training update . (ibarz et al., 2018), is the starting time step of the subtrajectory from \u03c4j . we found that this resulted in better performance than comparing randomly chosen subtrajectories, likely due to the fact that (1) it eliminates pairings that compare a later part of a worse trajectory with an earlier part of a better trajectory and (2) it encourages reward functions that are monotonically increasing as progress is made in the game. for enduro, training on short partial trajectories was not sufficient to score any points and instead we tuned the hyperparameters for gail to maximize performance when using expert demonstrations on breakout and pong. we found that gail was very sensitive to poor demonstrations so we trained gail on 10 demonstrations . t-rex outperformed both bco and gail in 7 out of 8 games. t-rex . gail only performed better than the average demonstration on space invaders. despite using better training data, gail was unable to score any points on hero, likely due to poor extrapolation and the higher complexity of the game. surprisingly, the learned reward function . atari tasks. et al., 2017) for five atari tasks. trex . the above results used synthetic demonstrations generated from an rl agent. we also tested t-rex when given ground-truth rankings over human demonstrations. we used novice human demonstrations from the atari grand challenge dataset (kurin et al., 2017) for details). space invaders, and video pinball, but was unable to outperform the human in montezuma\u2019s revenge and ms pacman (see the appendix for details). space invaders, . the above results used synthetic demonstrations generated from an rl agent. we also tested t-rex when given ground-truth rankings over human demonstrations. we used novice human demonstrations in q*bert, space invaders, but was able to significantly outperform the best human demonstration in q*bert, revenge and ms pacman (see the appendix for five atari tasks. trex was able to significantly outperform the best human demonstration from the atari grand challenge dataset (kurin et al., 2017) for five atari tasks. trex but was unable to outperform the human in montezuma\u2019s revenge and ms pacman (see the appendix for details). we also tested t-rex when given ground-truth rankings over human demonstrations. we used novice human demonstrations . the above results used synthetic demonstrations generated from an rl agent. we also tested t-rex . stage 1 hopper task. generated ranking noise by starting with a list of trajectories sorted by ground-truth returns and randomly swapping adjacent trajectories. by varying the number of swaps, we were able to generate different noise levels. given n trajectories in a ranked list provides ( n 2 ) pairwise preferences over trajectories. the noise level is measured as a total order correctness: the fraction of trajectory pairs whose pairwise ranking after random swapping matches the original ground-truth pairwise the results of this experiment, averaged over 9 runs . t-rex has the potential to work without explicit rankings. and enables us to test whether simply observing an agent learn over time allows us to extrapolate intention by assuming that later trajectories are preferable to trajectories produced earlier in learning. the results for hopper are shown in figure 5 and other task results are shown in the appendix. we found that t-rex is able to infer a meaningful reward function even when noisy, time-based rankings are provided. all the trained policies produced comparable results on most stages to the groundtruth rankings, and those policies outperform bco and gail on all tasks and stages except for ant stage 2. . suboptimal ranked demonstrations. to the best of our knowledge, this is the first irl algorithm that is able to significantly outperform the demonstrator without additional external knowledge (e.g. signs of feature contributions to reward) and that scales to high-dimensional atari games. when combined with deep reinforcement learning, we showed that this approach achieves better-thandemonstrator performance as well as outperforming stateof-the-art behavioral cloning and irl methods. we also demonstrated that t-rex is robust to modest amounts of ranking noise, and can learn from automatically generated labels, obtained by watching a learner noisily improve at a task over time. intent . work has taken place in the personal autonomousrobotics lab (pearl) at the university of texas at austin. pearl research is supported in part by the nsf (iis1724157, iis-1617639, and onr(n00014-18-2243). iis-1749204) and onr(n00014-18-2243). iis-1749204) and onr(n00014-18-2243). iis-1638107, and onr(n00014-18-2243). (iis1724157, . this work has taken place in the personal autonomousrobotics lab (pearl) at the university of texas at austin. pearl research is supported in part by the nsf (iis1724157, iis-1638107, and iis-1617639, iis-1749204) and onr(n00014-18-2243). this work . code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. icml2019-trex. icml2019-trex. code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. code as well as supplemental videos are available at https://github.com/hiwonjoon/ icml2019-trex. code as well as videos are supplemental at https://github.com/hiwonjoon/ code as well as videos available at icml2019-trex. https://github.com/hiwonjoon/ code as supplemental supplemental videos . the t-rex (time-ordered) row shows the resulting performance of t-rex when demonstrations come from observing a learning agent and are ranked based on timestamps rather than using explicit preference rankings. b.2. policy visualization the t-rex-learned policy for halfcheetah in figure 1. visualizing the demonstrations from different stages shows the specific way the policy evolves over time; an agent learns to crawl first and then begins to attempt to walk in an upright position. the t-rex policy learned from the highly suboptimal stage 1 demonstrations results in a similar-style crawling gait; t-rex captures some of the intent behind the demonstration . transition models used by bco et al., 2018a) we used 20,000 steps of a random policy to collect transitions with labeled states. we used the same architecture to predict actions given states. when predicting p (a|st, st+1), we concatenate the state vectors obtaining an 8x84x84 input consisting of two 4x84x84 frames representing st and st+1. we give both t-rex and bco the full set of demonstrations. we tried to improve the performance of bco by running behavioral cloning only on the bestx% of the demonstrations, but were unable to find a parameter setting that performed better than x = 100, likely due to a lack of training data . we used 9 parallel workers when running ppo. when learning and predicting rewards, we mask the score and number of lives left for all games. we did this to avoid having the network learn to only look at the score and recognize, say, the number of significant digits, etc. we additionally masked the sector number and number of enemy ships left on beam rider. we masked the bottom half of the dashboard for enduro to create a training set we repeatedly randomly select two full demonstrations, then randomly cropped between 0 and 5 of the initial frames from each trajectory and then downsampled both trajectories by only keeping every xth frame where x is randomly chosen between 3 and 6. we selected 2,000 randomly downsampled demonstrations . the first two columns of table 2 compare the demonstration quality given to dqfd+a and t-rex. while our results make use of more demonstrations (12 for t-rex versus 4\u20137 for dqfd+a), our demonstrations are typically orders of magnitude worse than the demonstrations used by dqfd+a: on average the demonstrations given to dqfd+a are 38 times better than those used by t-rex. however, despite this large gap in the performance of the demonstrations, trex only surpasses the demonstrator in 3 out of 9 games tested, . five atari games. we used the ground truth returns in the atari grand challenge data set to rank demonstrations. . t-rex is able to outperform the best human demonstration on q*bert, space invaders, and video pinball; however, it is not able to learn a good control policy for montezuma\u2019s revenge or ms pacman. these games require maze navigation and balancing different objectives, such as collecting objects and avoiding enemies. this matches our results in the main text that show that t-rex is unable to learn a policy for playing hero, a similar maze navigation task with multiple objectives such as blowing up walls, rescuing people, and destroying enemies. extending t-rex . atari domains. we use the method proposed by greydanus et al. which takes a stack of 4 frames and passes a 3x3 mask over each of the frames with a stride of 1. the mask is set to be the default background color for each game. for each masked 3x3 region, we compute the absolute difference in predicted reward when the 3x3 region is not masked and when it is masked. this allows us to measure the influence of different regions of the image on the predicted reward. the sum total of absolute changes in reward for each pixel is used to generate an attention heatmap. we used the trajectories shown in the extrapolation plots in figure 4 of the main text and performed a search using the learned reward function to find the observations with minimum and maximum predicted reward. we show the minimum and maximum observations (stacks along with the attention heatmaps across all four stacked frames for the learned reward functions .",
    "10": "challenge. machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. in this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure. . machines to read natural language documents remains an elusive challenge. machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. . challenge. machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. in this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. this allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure. . machines to read natural language documents remains an elusive challenge. machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. . progress from shallow bag-of-words information retrieval algorithms to machines . models flexible enough to learn to exploit document structure. while obtaining supervised natural language reading comprehension data . neural network based models hold promise for modelling comprehension, . the reading comprehension task naturally lends itself to a formulation as a supervised learning problem. specifically we seek to estimate the conditional probability p(a|c, q), where c is a context document, q a query relating to that document, and a answer to that query. for a focused evaluation we wish to be able to exclude additional information, such as world knowledge gained from co-occurrence statistics, in order to test a model\u2019s core capability to detect and understand the linguistic relationships between entities in the context document. such an approach requires a large training corpus of document\u2013query\u2013answer triples and until now such corpora have been limited to hundreds of examples and thus mostly of use only for testing [9]. this limitation has meant that most work in this area has taken the form of unsupervised approaches which use templates or syntactic/semantic analysers to extract relation tuples . daily mail validation set): a) the hi-tech bra that helps you beat breast x; b) could saccharin help beat x ? ; c) can fish oils help fight prostate x ? an ngram language model trained on the daily mail would easily correctly predict that (x = cancer), regardless of the context document, simply because this is a very frequently cured entity in the daily mail corpus. 1www.cnn.com 3http://www.github.com/deepmind/rc-data/ to prevent such degenerate solutions . the majority baseline (maximum frequency) picks the entity most frequently observed in the context but not observed in the query. the idea behind this exclusion is that the placeholder is unlikely to be mentioned twice in a single cloze form query. whereas the exclusive majority (exclusive frequency) chooses the entity most frequently observed in the context but not observed in the query. the idea behind this exclusion is that the placeholder is unlikely to be mentioned twice in a single cloze form query. we define two simple baselines, the majority baseline (maximum frequency) . models for our machine reading task. frame-semantic parsing attempts to identify predicates and their arguments, allowing models access to information about \u201cwho that is models that make heavy use of linguistic annotation, structured world knowledge and semantic parsing and similar nlp pipeline outputs. building on these approaches, we define a number of nlp-centric models for our corpora. version of our corpora. there is no significant advantage in this as the frame-semantic approach used here does not possess the capability to generalise through a language model beyond exploiting one during the parsing phase. the key objective of evaluating machine comprehension abilities . neural networks have been applied to a range of tasks in nlp. this includes classification tasks such as sentiment analysis [15] or pos tagging [16], . three neural models for estimating the probability of word type a from document d answering query q: p(a|d, \u221d (w q)) . neural models are in table 5, with the attentive and impatient readers performing best across both datasets. 5for the deep lstm reader, for the attention models we want to establish the difficulty of our machine reading task . the supervised paradigm for training machine reading and comprehension models provides a promising avenue for making progress on the path to building full natural language understanding systems. we believe that the incorporation of an attention mechanism is the key contributor to these results. the attention mechanism that we have employed is just one instantiation of a very general idea which can be further exploited. however, the incorporation of world knowledge and multi-document queries will also require the development of attention and embedding mechanisms whose complexity to query does not scale linearly with the data set size. there are still many queries requiring complex inference and long range reference resolution that our models are not yet able to answer. as such our data provides a scalable challenge that should support nlp research into the future. further, significantly bigger training data sets can be acquired using the techniques we have described, undoubtedly allowing us to train more expressive and accurate models. 7note that these examples were chosen as they were short, the average cnn validation document contained 763 tokens and 27 entities, thus most instances were significantly harder to answer than these examples. triples . the precise hyperparameters used for the various attentive models are as in table 6. all models were trained using asynchronous rmsprop with a momentum of 0.9 and a decay of 0.95. . the precise hyperparameters used for the various attentive models are as in table 6. all models were trained using asynchronous rmsprop with a momentum of 0.9 and a decay of 0.95. . the precise hyperparameters used for the various attentive models are as in table 6. all models were trained using asynchronous rmsprop [20] with a momentum of 0.9 and a decay of 0.95. . the first figure (fig. 4) plots a sliding window of performance versus document lengths in figures 4 and 5. the chart shows the precision for each decile in document lengths across the corpus as well as the precision for the 5% longest articles. figure 5: aggregated precision for documents up to a certain lengths. the points mark the ith decile in document lengths across the corpus. , showing that while the length does impact the models\u2019 performance, that effect becomes negligible after reaching a length of ~500 tokens. length for the attention models on the size of the context, we plot performance versus document lengths in figures 4 and 5. the first figure (fig. 5) shows the cumulative performance with documents up to lengthn , showing that performance of the attentive models degrades slightly as documents increase in length. the second figure 4: precision@document precision for documents up to a certain lengths. the points mark the ith decile . cnn validation set that require reasonable levels of lexical generalisation and co-reference in order to be answered. the first query in figure 7 contains strong lexical cues through the quote, but not being clustered together. arguably this is a difficult clustering as one entity refers to \u201ckate middleton\u201d and the other to \u201cthe duchess of cambridge\u201d. the right example shows a situation in which the model fails as it perhaps gets too little information from the short query and then selects the wrong cue with the term \u201cclaims\u201d near the wrongly identified entity ent1 (correct: c.2 impatient reader .",
    "11": "new framework for estimating generative models via adversarial in which we simultaneously train two models: a generative model g that estimates the probability that a sample came from the training data rather than g. the training procedure for g is to maximize the probability of d making a mistake. this framework corresponds to a minimax two-player in the case where g and d are defined by multilayer perceptrons, the entire system can be trained with backpropagation. there is no need for any markov chains or unrolled approximate inference networks during either training or generation of samples. experiments . new framework for estimating generative models via adversarial in which we simultaneously train two models: a generative model g that estimates the probability that a sample came from the training data rather than g. the training procedure for g is to maximize the probability of d making a mistake. this framework corresponds to a minimax two-player in the space of arbitrary functions g and d, a unique solution exists, with g recovering the training data distribution and d equal to 12 everywhere. in the case where g and d are defined by multilayer perceptrons, the entire system can be trained with backpropagation. and quantitative evaluation . the promise of deep learning is to discover rich, hierarchical models [2] that represent probability distributions over the kinds of data encountered in artificial intelligence applications, such as natural images, audio waveforms containing speech, and symbols in natural language corpora. . deep generative models have had less of an impact, due to the difficulty of leveraging the benefits of piecewise linear units . graphical models with latent variables, are intractable for all but the most trivial instances, although they can be estimated by markov chain monte carlo (mcmc) methods. mixing poses a significant problem for learning algorithms that rely on mcmc [3, deep belief networks (dbns) [16] are hybrid models containing a single undirected layer and several directed layers. while a fast approximate layer-wise training criterion exists, incur the computational difficulties associated with both undirected and directed models. alternative criteria that do not approximate or bound the log-likelihood have also been proposed, such as score matching [18] . the adversarial modeling framework is most straightforward to apply when the models are both multilayer perceptrons. to learn the generator\u2019s distribution pg over data x, we define a prior on input noise variables pz(z), then represent a mapping to data space as g(z; \u03b8g), where g is a differentiable function represented by a multilayer perceptron with parameters \u03b8g . we also define a second multilayer perceptron d(x; \u03b8d) that outputs a single scalar. d(x) represents the probability that x came from the data rather than pg . the generator g implicitly defines a probability distribution pg as the distribution of the samples g(z) obtained when z \u223c pz . therefore, we represent a model with infinite capacity by studying convergence in the space of probability density functions. . proposition 2. + ex\u223cpg [log(1\u2212d\u2217g(x))] consider v (g,d) d) as a function of pg as done in the above criterion. note that u(pg, d) is convex in pg . the subderivatives of a supremum of convex functions include the derivative of the function at the point where the maximum is attained. in other words, if f(x) = sup\u03b1\u2208a f\u03b1(x). and f\u03b1(x) is convex in x for every \u03b1, then \u2202f\u03b2(x) \u2208 \u2202f . toronto face database (tfd) [28], and cifar-10 [21]. the generator nets used for which the exact likelihood is not tractable [25, 3, results are reported in table 1. this method of estimating the likelihood has somewhat high variance and does not perform well in high dimensional spaces but it is the best method available to our knowledge. advances in generative models that can sample but not estimate likelihood directly motivate further research into how to evaluate such models. in figures 2 and 3 we show samples drawn from the generator net after training. while we make no claim that these samples are at least competitive with the better generative models in the literature . training (in particular, g must be trained too much without updatingd, in order to avoid \u201cthe helvetica scenario\u201d in whichg collapses too many values of z to the same value of x to have enough diversity to model pdata), much as the negative chains of a boltzmann machine must be kept up to date between learning steps. the advantages are not copied directly into the generator\u2019s table 2 summarizes the comparison of generative adversarial nets with other generative modeling approaches. the aforementioned advantages are primarily computational. adversarial models may also gain some statistical advantage from the generator network not being updated directly with data examples, but only with gradients flowing through the discriminator. this means they can represent very sharp, even degenerate distributions, . extensions: 1. a conditional generative model p(x | c) of x by training a family of conditional models . this is similar to the inference net trained by the wake-sleep algorithm [15] but with the advantage that the inference net may be trained for a fixed generator net after the generator net has finished training. 3. one can be obtained by adding c as input to both g and d. 2. learned approximate inference can be performed by training an auxiliary network to predict z given x. this paper has demonstrated the viability of the adversarial modeling framework, . patrice marcotte, and jason yosinski were supported by the 2013 google fellowship in deep learning. finally, we would like to thank les trois brasseurs for stimulating our creativity. ian goodfellow is supported by the 2013 google fellowship in deep learning. we would like to thank the developers of pylearn2 [12] and theano [7, . fre\u0301de\u0301ric canada, and calcul que\u0301bec rushed a theano feature specifically to benefit this project. arnaud bergeron who rushed a theano window evaluation code with us. we would also like to thank cifar, and canada research chairs for funding, and compute canada, for providing computational resources. ian goodfellow .",
    "12": "learning techniques enforce this decomposition in a top-down manner, while meta-learning techniques require a task distribution at hand to learn such decompositions. this paper presents a framework for using diverse suboptimal world models to understand the importance and robustness of different elements in the framework and limitations to this approach. this approach at both complex single task learning and lifelong learning. finally, as well as a controller to coordinate them. we perform a series of experiments on high dimensional continuous action control tasks to demonstrate the effectiveness of this approach at both complex task in a bottom up manner, concurrently learning the required modular subpolicies . format: bohan lifelong learning acm reference the model primitive hierarchical lifelong reinforcement learning . in proc. of the 18th international conference on autonomous agents and multiagent systems (aamas montreal, canada, may 13\u201317, 2019, ifaamas, 9 pages. and mykel j. kochenderfer. 2019. model primitive hierarchical lifelong reinforcement learning . in proc. of the 18th international conference on autonomous agents and multiagent systems (aamas 2019), canada, lifelong learning acm reference format: bohan jayesh k. gupta, and mykel j. kochenderfer. 2019. model primitive hierarchical lifelong reinforcement learning . [25, 27, and variousmeta-reinforcement learning settings [7, 8], where the agent jointly trains on multiple task environments. not only do such nonincremental settings make the problem of catastrophic forgetting [16], which is the inability to solve previous tasks after learning to solve new tasks in a sequential learning setting. our work takes a step towards solutions for such shared structure. a key ingredient of our proposal is the idea of world models [10, model primitives . s\u00d7a \u2192 \u03c0(s), and a discount factor\u03b3 \u2208 \u03c0(\u00b7) defines a probability distribution over a set. the agent acts according to the initial state distribution \u03c10. after solving the given mdp or after h timesteps, whichever occurs first, the agent resamples from d and repeats. the fundamental question in lifelong learning is to determine what knowledge should be captured by the agent from the tasks it has already solved so that it can improve its performance on future tasks. . primitive hierarchical reinforcement learning (mphrl) framework (figure 1) to address the problem of effective piecewise functional decomposition for transfer across a distribution of tasks. functional decomposition . the model primitive hierarchical reinforcement learning (mphrl) framework (figure 1) to address the problem of effective piecewise functional decomposition for transfer across a distribution of tasks. . the key assumption in mphrl is access to several diverse world models of the environment dynamics. these models can be seen as instances of learned approximations to the true environment dynamics t . in reality, these dynamics can even be non-stationary. therefore, the task of learning a complete model of the environment dynamics . the standard policy (sp) optimization objective is: maximize \u03b8 = e\u03c10,\u03c0\u03b8 [\u03c0\u03b8 )] . st )q\u03c0\u03b8 (st (at is an estimator of the advantage function [2]. . two questions: (a) can model primitives ensure task decomposition? (b) does such decomposition improve transfer for lifelong learning? we evaluate our approach in two challenging domains: a mujoco ant navigating different mazes and a stacker arm picking up and placing different boxes. in our experiments, we use subpolicies that have gaussian action distributions, with mean given by a multi-layer perceptron controller outputs a categorical distribution and is parameterized by another multi-layer perceptron. we also use a separate multi-layer perceptron for the baseline estimator. we use the standard ppo algorithm as a baseline to compare against mphrl. transferring network weights empirically . mphrl learns a number of interpretable to solve a single task. . the agent has no subpolicies, so the subpolicy network is the policy network. and subpolicy networks only. horizon. for both tasks, both the goal and the initial ant locations are fixed. for the l-maze, the agent has access to two model primitives, one specializing in the horizontal (e, corridor of the maze. in their specialized corridors, corridor of the maze. similarly for the d-maze, the agent . two tasksets. 4.2.1 10-maze. to evaluate mphrl\u2019s performance in lifelong learning, we generate a family of 10 random mazes for the mujoco ant environment, . the agent has a maximum of 3 \u00d7 107 timesteps to reach 80% success rate in each of the 10 tasks. as shown in figure 3a, mphrl requires nearly double the number of timesteps . we conduct five experiments using various sets of noisy model primitives. below, . the first value corresponds to the noise scaling factor \u03c3 within their individual regions of specialization, while the second value corresponds to \u03c3 outside of their regions of specialization. (a) 0.4 and 0.5: good models with reasonable distinction (d) 9.0 and 10.0: bad models with limited distinction (e) 0.5 and 1.0: good models with no distinction shown in figure 6a, . decomposed subpolicies can be used to decompose a complex task into simpler ones. we introduced a framework that uses these model primitives to learn piecewise functional decompositions of solutions to complex tasks. the learned decomposed subpolicies can then be used to transfer to a variety of related tasks, reducing the overall sample complexity required to learn complex behaviors. our approach does not require access to accurate world models. neither does it need a well-designed task distribution or the incremental introduction of individual tasks. so long as the set of model primitives are useful across the task distribution, mphrl learning useful and diverse model primitives, subpolicies and task decomposition all simultaneously is left for future work. the recently introduced neural processes [9] can potentially be an efficient approach to build upon. nevertheless, . the work is supported in part by darpa under agreement number d17ap00032. the content is solely the responsibility of the authors and does not necessarily represent the official views of darpa. we are also grateful for the support from google cloud in scaling our experiments. for useful comments and suggestions. this work is supported in part by darpa under agreement number d17ap00032. the content is solely the responsibility of the authors and does not necessarily represent the official views of darpa. and everyone at sisl for useful comments . we are thankful to kunal menda and everyone at sisl for the support from google cloud in scaling our experiments. we are also grateful for the support from google cloud in scaling our experiments. this work .",
    "13": "virtual democracy is an approach to automating by learning models of the preferences of individual people, and, at runtime, aggregating the predicted preferences of those people on the dilemma at hand. one of the key questions is which aggregation or voting rule \u2014 to use; we offer a novel statistical viewpoint that provides guidance. specifically, we seek voting rules that are robust to prediction errors, in that their output on people\u2019s true preferences is likely to coincide with their output on noisy estimates thereof. we prove that the classic borda count rule is robust in this sense, whereas any voting rule belonging to the wide family of pairwisemajority consistent rules is not. our empirical results further support, and more precisely measure, the robustness of borda count. by learning models of the preferences of individual people, and, . group of people to vote on the alternatives at a decision? this is exactly the idea behind the work of automating et al. (2018), who are motivated by the challenge of automating ethical decisions. specifically, of computer science, carnegie mellon university, pittsburgh, . section 1.2. long beach, california, see section 1.2. dilemmas; second, proceedings of the 36 th international conference on machine learning, long beach, . the classic mallows model is an accurate representation of reality (mao et al., 2013). et al., 2016; et al., 2016; et al., 2016; et . the model is very well studied (see section 1.2), but, in situations where there is a ground-truth ranking, this observation has motivated a body of work on generalized (caragiannis et . crucially, predicted ranking \u03c3i is drawn from a mallows distribution . a number of recent papers have explored the idea of automating ethical decisions via machine learning and social choice (conitzer et al., 2017; freedman et al., 2018). as mentioned above, our work builds on the framework proposed by noothigattu et al. (2018). however, et al., et al., et al., 2014; et al., et . the individual voter models are summarized as a single, concise model of societal preferences . the alternative ranked in position j in \u03c3, where position 1 is the highest, and m the lowest. we denote by \u03c3\u22121(x) the position in which x \u2208 a is ranked. we use x \u03c3 y to denote that x is preferred to y according to \u03c3, i.e., . x \u03c3i y}| > n/2. the setting of voters n = {1, . a voting rule (formally known as a social welfare function) is a function f : ln \u2192 l, which receives a preference profile as input, and returns a \u2018consensus\u2019 ranking of the alternatives. we are especially interested in two families of voting rules. . in words, each voter who ranks x in position p gives \u03b1p points to x. scoring rules. each such rule is defined by a score vector (\u03b11, . kendall tau distance between two rankings \u03c3, \u03c3\u2032 l be dkt(\u03c3, \u03c3 , |{(x, y) and \u03c3\u2032 disagree. for example, if \u03c3 = (a, b, c, and \u03c3\u2032 = (a, in words, it is the number of pairs of alternatives on which \u03c3 and \u03c3\u2032 disagree. for \u03c6 = 1 this is a ground truth ranking \u03c3?, which induces a probability distribution over perceived rankings. specifically, the probability of a ranking \u03c3, given the ground truth ranking \u03c3?, . the current set of alternatives is the current set of recipient organizations, . this is not unreasonable (and would have been very convenient for us), \u2248 0.9 it would lead to extremely high probability of correctly ranking alternatives that are, say, 30 positions apart in the ground truth ranking. in order to moderate this effect, we define another parameter \u03ba {2, . the noisy borda ranking (based on the sampled profile) would disagree with the true borda ranking (based on a given pair of alternatives. theorem 1. for any \u03b2 > 1/2 and > 0 there exists a formal version of the desired property stated in section 1. as well as additional lemmas that we will state and prove momentarily. as we have already discussed, we do not have access to the mallows parameter instead, we can measure \u03b2, the probability that we correctly predict a pairwise comparison of alternatives that are \u03ba positions apart. on a very high level, the probability that the noisy borda ranking is highly unlikely to make mistakes on pairs of alternatives whose average score difference is linear in m. turning to the proof, we start by bounding the probability that our noisy borda ranking is highly unlikely to depend on \u03ba, but it is encouraging (and, to us, surprising) that this dependence is almost linear. in particular, even if \u03ba is almost linear in m, i.e., \u03ba logm), . theorem 1 shows that borda count is robust against noisy perturbations of the preference profile. it is natural to ask whether \u2018many\u2019 voting rules satisfy a similar property. in this section we answer this question in the negative, by proving that any voting rule that belongs to the important family of pmc rules is not robust in a similar sense. recall that under a pmc rule, when the weighted pairwise majority graph is acyclic, and all edge weights are large, but, with high probability, the noisy profile also has an acyclic pairwise majority graph which induces a different ranking. this means that any pmc rule would return different rankings when applied to the true profile and the noisy profile. theorem for all \u03b4 > 0, \u03c6 (0, and m \u2208 n such that for all n \u2265 n0, there exists n0 \u2208 . error. however, only provides asymptotic guarantees. in this section, we evaluate the performance of borda count on profiles of size that is more representative of real-world instances. for our evaluation metric, we consider the probability of the rule flipping alternatives when aggregating noisy rankings against their difference in borda score in the underlying true profile. all of our code is open-source and can be found at https://github.com/akahng/virtualdemocracy-icml2019. however, our positive theoretical result, theorem 1, only provides asymptotic guarantees. in this section, we evaluate the performance of borda count is robust to prediction error. however, our positive theoretical result, theorem 1, for our evaluation metric, we consider the probability of the rule flipping alternatives when aggregating noisy rankings against their difference in borda score in the underlying true profile. all of our code is open-source and can be found at https://github.com/akahng/virtualdemocracy-icml2019. in section 4 we have established that borda count is robust to prediction error. however, our positive theoretical result, theorem 1, . n voters, m alternatives, a mallows model with base ranking xm xm\u22121 \u00b7 \u00b7 xm and parameter \u03c6. . the width of each bucket corresponds to an average borda score difference to the probability of making a pairwise note that flipped the order of xi and xj . n = 100, m = 40, m = 40, \u2208 . \u03c6 \u2208 0.2, 0.3}, 0.7, 0.7, and p \u2208 {1, . \u03c6 i.e., 0.3}, the observed probability of flipping any two alternatives, regardless of making a mistake . virtual democracy, from a statistical viewpoint. count is also compelling in terms of usability and explainability. in more detail, in our implemented donor-recipient matching system, clicking on a recommended alternative displays an explanation for why it was ranked highly by borda count, which consists of two components. first, we show the alternative\u2019s average position in the predicted preferences of each of the four stakeholder this is the more novel component \u2014 we show specific features in which the recommended alternative stands out. this is interesting because classic social choice theory does not have features for alternatives, and we are able to give this type of explanation precisely because our alternatives are represented as vectors of features (which is crucial for the application of learning-to-rank algorithms). based on the results presented in this paper, .",
    "14": "modern online services come with stringent quality requirements in terms of response time latency. because of their decomposition into fine-grained communicating software layers, a single user request fans out into a plethora of short, \u03bcs-scale aggravating the need for faster inter-server communication. in reaction to that need, we are witnessing a technological transition characterized by the emergence of hardware-terminated user-level and new architectures with fully integrated network interfaces (nis). such architectures offer a unique opportunity for a new ni-driven approach to balancing rpcs among the cores of manycore server cpus, yielding major tail latency improvements . rpcvalet, rpc rpc design decisions emulate the theoretically optimal single-queue system, without incurring synchronization overheads currently associated with single-queue implementations. april 13\u201317, 2019, providence, ri, ri, ri, ri, . otherwise, asplos \u201919, reference format: alexandros mark sutherland, and babak falsafi. 2019. ni-driven . otherwise, asplos april 13\u201317, 2019, providence, usa \u00a9 2019 association for computing machinery. acm isbn . modern datacenters deliver a breadth of online services to millions of daily users. in addition to their huge scale, online services come with stringent service level objectives (slos) to guarantee responsiveness. often expressed in terms of tail latency, slos target the latency of the slowest requests, and thus bound the slowest interaction a user may have with the service. tail-tolerant computing is one of the major ongoing challenges in the datacenter space, as long-tail events are rare and rooted in convoluted hardware-software a key contributor to the well-known \"tail at scale\" challenge [15] is the deployment of online services\u2019 software stacks in numerous communicating tiers, where the interactions between a service\u2019s tiers take the form of remote procedure calls (rpcs). large-scale software . modern online services are decomposed into deep hierarchies of mutually reliant tiers [26], as short as a few \u00b5s for common software tiers such as data stores. rpcs exacerbate the tail latency challenge for services with strict slos, as accumulated \u00b5s-scale overheads due to its low latency and high iops. with networking latency approaching the fundamental limits of propagation delays [20], any overhead added to the raw rpc processing time at a receiving server critically impacts latency. to mitigate the overheads of rpc-based communication, network technologies have seen renewed interest, with the infiniband fabric and protocol beginning to appear in datacenters [21] due to its low latency and high iops. interaction between the cpu, ni, and memory hierarchy, in this paper, we leverage ni integration to break existing tradeoffs in balancing rpcs across cpu cores . the notation model q \u00d7 u denotes a queuing system with q fifos where incoming messages arrive and u serving units per fifo. each with a single serving unit. 1 \u00d7 16 represents the most flexible option that achieves the best load balancing: all serving units pull requests from a single fifo. finally, 4 \u00d7 4 represents a middle ground: incoming messages are commonly used to model the independent nature of incoming requests. \u00a75 details . the input queue). in a manycore cpu, allowing all the cores to pull incoming network messages from a single queue requires synchronization. we refer to this rpc dispatch mode as \"pull-based\". especially for short-lived rpcs, with service times of a few \u00b5s, such synchronization represents significant overhead. architectures that share a pool of connections between cores have this imbalance . memcached [2] is the average service time for memcached [2] [47]. . software tiers richer than simple data retrieval can exhibit \u00b5s-scale service times that are frequently only a few \u00b5s long. for example, the average service time on the silo in-memory database [53] is only 33\u00b5s [47]. software tiers with such short service times necessitate network architectures optimized . the ni\u2019s integration on the same piece of silicon as the cpu is the key enabler for handling \u00b5s-scale events. . the ni has the ability to respond to rapidly changing load levels and make dynamic load-balancing decisions. to illustrate the importance of ns-scale interactions, consider a data serving tier such as redis [3], maintaining a sorted array in memory. since the implementation of its sorted list container uses a skip list to provide add/remove operations in o (lo\u0434 (n )) for a few \u00b5s while new translations are installed. . our design goal is to break the tradeoff between the load imbalance inherent in multi-queue systems and the synchronization associated with pulling load from a single queue. to a qp in ib/sonuma terminology) with the ni helps us achieve the goal of eliminating synchronization, as each thread polls on its own qp and waits for the arrival of new rpcs. this simplifies the load-balancing problem to simply choosing the correct qp to dispatch the rpc to. by allowing the ni to choose the qp at the remote end. hence, a reception of a one-sided op is not associated with a creation of a cpu notification event . ni integration. sonuma deploys a qp interface for cpu-ni interaction (\u00a73.1) and leverages on-chip cache coherence to accelerate qp-entry transfers between the cpu and ni. fig. 4 shows sonuma\u2019s scalable ni architecture for manycore cpus [13]. the conventionally monolithic ni is the \"control\" component, and is collocated with each core to drastically accelerate qp interactions. the backend is replicated across the chip\u2019s edge, to scale the ni\u2019s capability with growing network bandwidth, and handles all data and network packets. pairs of frontend and backend entities, . logically comprise a complete ni, communicate with special packets over the chip\u2019s interconnect. our rpcvalet implementation relies on such a manycore ni architecture. protocol . multi-packet messages, will feature small mtus (e.g., a single cache line in sonuma), so limiting the maximum message size to the link layer\u2019s mtu. prior work has adopted this approach to build an rpc framework on an ib cluster [27]. because all packets are directly written to the bounded buffer specified by the sender. one workaround to avoid message reassembly complications would be an acceptable limitation for ib networks which have a relatively large mtu of 4kb. however, which unrolls large requests into independent packets each carrying a single cache block payload. emulated messaging (see \u00a73.3) does not require any reassembly at the destination, because all packets are directly written to the bounded buffer specified operations from messaging operations, which are eligible for load balancing. the ni keeps track of packet receptions belonging to a send, deduces when it has been fully received, and then hands it off to a core operation on node 1. fig. 5 only shows ni backends; ni frontends . ni-driven or data-locality awareness). can be eliminated by setting the number of outstanding requests per core to two. in rpcvalet, the receiving node\u2019s or effectiveness of load-balancing decisions at the nis and demonstrate that we can achieve the load-balancing quality of a single-queue system without synchronization overheads. 5b\u2019s step 8 is the crucial step that determines the balancing of incoming requests to cores. in a core implies that the core is done processing a previously assigned send. allowing only one outstanding request only after receiving a notification of the previous one\u2019s completion corresponds to true single-queue system behavior, with service times of a few 100s of nanoseconds. a challenge that emerges from the distributed nature of a manycore ni architecture . the modeled chip is part of a 200-node cluster, with remote nodes emulated by a traffic generator which creates synthetic send requests to the modeled chip\u2019s outgoing requests. we use a send operation with a 512b payload; and (iv) issues a replenish corresponding to the processed send request, marking the end of of the incoming rpc\u2019s processing. the execution of an rpc by spending processing time x , wherex follows a given distribution as detailed below; (iii) generates a synthetic rpc reply, which is sent back to the requester . fig. 7a shows the performance of herd with each of the three evaluatedni-driven load-balancing a resulting s\u0304 of \u223c 550ns, 1 \u00d7 16 delivers the best performance, thanks to its superior flexibility in dynamically balancing load across all 16 available cores. in comparison, 4 \u00d7 4 offers none at all. the flexibility to balance load from a single queue to multiple cores not only results in higher peak throughput under slo, but also up to 4\u00d7 lower tail latency before reaching saturation load. lower tail means that the throughput gap between rpcvalet and 1 \u00d7 16 would be larger for slos stricter than the assumed 10 \u00d7 s\u0304 . fig. 8 compares the performance of rpcvalet to a software implementation, both of which implement the same theoretically optimal queuing system (i.e., the difference between the two is competitive with the hardware implementation at low load, but because of contention on the single lock, it saturates does not incur any synchronization costs, as dispatch is driven by the ni. the software implementation is not only inferior to the 1\u00d716 hardware implementation, but to all of the evaluated hardware implementations. the fact that even the 16 \u00d7 1 hardware implementation is superior to the software 1 \u00d7 16 implementation indicates that the software synchronization costs outweigh the dispatch flexibility they provide, a direct consequence of the \u00b5s-scale rpcs effectively build a 16 \u00d7 1 system using rss\u2014showing that elimination of software synchronization from the critical path offsets the resulting load imbalance. . the queuing analysis presented in \u00a72.2. we now quantitatively compare the obtained results to the ones expected from purely theoretical models, to determine the performance gap between rpcvalet and the theoretical 1 \u00d7 16 system. to make rpcvalet measurements comparable to the theoretical queuing results, we devise the following methodology. we measure the mean service time s\u0304 on our implementation; a part d of this service time is synthetically generated to follow one of the distributions in \u00a75, and the rest, s\u0304 d, is spent on the rest of the microbenchmark\u2019s code (e.g., event loop, executing send for the rpc response and replenish to free the rpc slot). d part of the service time is a conservative simplifying assumption: modeling variable latency . other techniques toreduce priorwork aiming to control the tail latency of web services deployed at datacenter scale introduced techniques that duplicate/hedge requests across multiple servers hosting replicated data [15]. the goal of an rpc experiencing a long-latency event and consequently affecting the response latency of its originating request. a natural side-effect of replication is the execution of more requests than strictly necessary, also necessitating extra serverside logic to reduce the load added by duplicated requests. . rpcvalet, anni-driven rpcvalet behaves like a singlequeue system, without incurring the synchronization overheads typically associated with single-queue implementations. rpcvalet performs within 3\u201315% of the ideal singlequeue system and significantly outperforms load-balancing approaches. performs within 3\u201315% of the ideal singlequeue system and significantly outperforms current rpc load-balancing rpcvalet . for\u00b5s-scale anni-driven dynamic load-balancing mechanism for\u00b5s-scale rpcs. behaves like a singlequeue system, without incurring the synchronization overheads typically associated with single-queue implementations. rpcvalet performs within 3\u201315% of the ideal singlequeue system . we thank edouard bugnion, james larus, dmitrii virendra dionisios . drumond, yins project, and the anonymous reviewers for their precious feedback. this work was partially funded by huawei technologies, the nano-tera yins server architecture for datacenters project. and the snsf\u2019s memory-centric server architecture for datacenters project. and the anonymous reviewers for their precious feedback. this work was partially funded by huawei technologies, the oracle labs accelarating distributed systems with advanced one-sided operations grant, and the snsf\u2019s memory-centric server architecture for datacenters project. and the anonymous reviewers for their precious feedback. this work was partially funded by huawei james larus, ustiugov, marathe, pnevmatikatos, pnevmatikatos, marios marios . drumond, the nano-tera yins the oracle labs accelarating distributed systems with advanced one-sided operations grant, . we thank edouard bugnion, dmitrii ustiugov, virendra dionisios mario drumond, arash marios kogias .",
    "15": "many organizations today have more than very large databases; they have databases that grow without limit at a rate of several million records per day. mining these continuous data streams brings unique opportunities, but also new challenges. this paper describes and evaluates vfdt, an anytime system that builds decision trees using constant memory and constant time per example. vfdt can incorporate tens of thousands of examples per second using off-the-shelf hardware. it uses hoeffding bounds to guarantee that its output is asymptotically nearly identical to that of a conventional learner. we study vfdt\u2019s properties and demonstrate its utility through an extensive set of experiments on synthetic data. we apply vfdt to mining the continuous stream of web access data from the whole university of washington main campus. . categories and subject descriptors h.2.8 management]: database applications\u2014 data mining . i.2.6 [artificial bounds, concept methodology\u2014classifier design and evaluation general terms decision . knowledge discovery systems are constrained by three main limited resources: memory and sample size. in traditional applications of machine learning and statistics, sample size tends to be the dominant limitation: the bottleneck is time and memory, not examples. the latter are typically in over-supply, in the sense that it is impossible with current kdd systems to make use of all of them within the available computational resources. as a result, most of the available examples go unused, and underfitting may result: enough data to model very complex phenomena is available, but inappropriately simple models are produced because we are unable to take full advantage of the data. but even these algorithms have only been tested on up to a few million examples. in many applications this is less than a day\u2019s worth of data. . the classification problem is generally defined as follows. a set of n training examples of the form (x, y) is given, where y is a discrete class label and x is a vector of d attributes, each of which may be symbolic or numeric. one of the most effective and widely-used classification methods is fraudulent or not. one of the most effective and widely-used classification methods x with high accuracy. for example, x could be a record of a cellular-telephone call, and y the decision whether it is fraudulent or x could be stored simultaneously in main memory, and are thus severely limited in the number of examples they can learn from. disk-based learners of this type induce models in the form of decision trees, where each node contains a test on an attribute, each branch from a node corresponds to a possible outcome of the test, and y the decision tree learners like sliq [10] and sprint [17] assume the examples are stored on disk, and learn by repeatedly reading them in sequentially (effectively once per level in the tree). . vfdt vfdt allows the use of either information gain or the gini index as the attribute evaluation measure. it includes a number of refinements to the algorithm in table 1: ties. when two or more attributes have very similar g\u2019s, potentially many examples will be required to decide between them with high confidence. this is presumably wasteful, because in this case it makes little difference which attribute is chosen. thus vfdt can optionally decide that there is effectively a tie and split on the current best attribute if \u2206g < \u03c4 , where \u03c4 is a user-specified threshold. g computation. the most significant part of the time cost per example is recomputing g. it is inefficient to recompute g for every new example, because it is unlikely that the decision to split will be made at that specific point. thus vfdt allows the user to specify a minimum number of new examples nmin that must be accumulated at a leaf before g is recomputed. this effectively reduces the global time spent on g computations by a factor of nmin, . comparing vfdt with c4.5 release 8 [15] on a series of synthetic datasets. using these allows us to freely vary the relevant parameters of the learning process. in order to ensure a fair comparison, we restricted the two systems to process. and giving c4.5 the maximum number of examples that would fit in the same memory (100k examples).3 vfdt used information gain as follows. at each level after the first three, a fraction f of the nodes was replaced by leaves; the rest became splits on a random attribute (that had not been used yet on a path from the root to the node being considered). . series of lesion studies to evaluate the effectiveness of some of the components and parameters of the learners on the (0.25, 0.00, 12605) data set. it also shows a slight modification to the vfdt-boot algorithm, where the tree produced by c4.5 is still able to use additional data to significantly improve accuracy. vfdt-boot with the \u201cno over-prune\u201d setting is initially better than the over-pruning version, but does not make much progress and is eventually overtaken. we hypothesize that this is because it has difficulty overcoming the poor low-confidence decisions c4.5 made near its leaves. in the remainder of the lesion studies vfdt was run on the (0.25, 0.10, 25209, data set with \u03b4 = 10\u22127, \u03c4 = 200, = 200, no leaf reactivation, . many times the organization accessed the host in the time slice, we discretize 12 requests,\u201d and \u201c26 or more requests.\u201d then for each time slice and host accessed in that time slice (tt, hj) we generate an example with attributes t mod 24, c1,jt, . previous work on mining large databases using subsampling methods includes the following. catlett [2] proposed several heuristic methods for extending ram-based batch decisiontree learners to datasets with up to hundreds of thousands of examples. musick, catlett and russell [13] proposed and tested (but did not implement in a learner) a theoretical model for choosing the size of subsamples to use in comparing attributes. maron and moore [9] models via cross-validation bounds . the full database. provost et al. [14] studied different strategies for mining larger and larger subsamples until accuracy (apparently) asymptotes. in contrast to systems that learn in main memory . vfdt vfdt may outperform these even in fully disk-resident datasets, because it can learn in less than one scan while the latter require multiple scans, and the dominant component of their cost is often the time required to read examples from disk multiple times. vfdt\u2019s speed and anytime character make it ideal for interactive data mining; further developing the application of vfdt to web log data; studying other applications of vfdt (e.g., intrusion detection); . the current example may cause the hoeffding bound to be reached); using adaptive \u03b4\u2019s; studying the use of an example cache in main memory . hoeffding trees, is a high-performance data mining system based on hoeffding trees. empirical studies show its effectiveness in taking advantage of massive numbers of examples. trees allow learning in very small constant time per example, and have strong guarantees of high asymptotic similarity to the corresponding batch trees. vfdt is a high-performance data streams that are increasingly common. hoeffding trees allow learning in very small constant time per example, and have strong guarantees of high asymptotic similarity to a high-speed stream of web log data is under way. trees. a method for learning online from the high-volume data streams that are increasingly common. hoeffding trees allow learning in very small constant time per example, . this was partly funded by an nsf career award to the first author. author. career award to the first author. research partly funded by an nsf career award to the first author. this research was partly funded by an nsf career award to the first author. this research was partly funded by an nsf career award to the first author. this research was partly funded by an nsf career award to the first author. this research was partly funded by an nsf career award to the first author. research partly funded by an career career was this award . the american statistical association, sigmod belmont, and w.-l. loh. classification and regression trees. in proceedings of the thirteenth international conference on extending database technology, pages . the fifth international conference on management of data, pages is 323\u2013333, in proceedings of the fifth international conference on knowledge discovery and data mining, pages .",
    "16": "asynchronous environments. and extensible, consisting of five asynchronous protocols that are designed to meet different goals (e.g., different performance scenarios). due to modularity in its design, features of these protocols can be mixed to achieve even more meaningful trade-offs between functionality and performance for various applications. through a 92-instance, five-continent deployment of amazon ec2, we show that beat on amazon ec2, all our beat instances significantly outperform, in terms of both latency and throughput, honeybadgerbft, the most efficient asynchronous bft known. protocols for completely asynchronous environments. and extensible, consisting of five asynchronous bft protocols . computer systems organization\u2192 reliability; asynchronous keywords byzantine fault tolerance, bft, bft, threshold cryptography threshold . computer systems security; distributed systems security; \u2022 computer systems . state machine replication (smr) 81] is a fundamental software approach to enabling highly available services in practical distributed systems and cloud computing platforms (e.g., google\u2019s chubby [20] and spanner [29], apache zookeeper [53]). its byzantine failure counterpart, byzantine fault-tolerant smr . the hyperledger umbrella [5], has become a global collaborative open-source project under the linux foundation, now with more than 250 members. permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided . the (subtle) differences between (bft) smrand atomic registers. state machine replication [81] is a general technique to provide a fault-tolerant services using a number of server replicas. it can support arbitrary operations, not just read and write. in smr, the servers need to communicate with each other and run an interactive consensus protocol to keep the servers in the same state. register specifications were introduced by lamport in a series of papers [62, 66], with atomic register as the strongest one. the notions of linearizability andwait-freedom for atomic registerswere introduced by herlihy andwing [48] . timing assumptions.distributed systems can be roughly divided into three categories . the partial synchrony model [37] lies in-between: messages are guaranteed to be delivered within a time bound, but the bound may be unknown to participants of the system. in protocols for asynchronous systems, neither safety nor liveness can rely on timing assumptions. in contrast, a protocol built for a synchronous or partially synchronous system . review robust labeled threshold cryptosystem (i.e., threshold encryption) [85] . public key is shared among all the servers. syntactically, \u00b7 \u00b7 , skn ) is a list of private keys. a probabilistic encryption algorithm . introducing asynchronous common subset.honeybadgerbft uses acs and asynchronous binary byzantine agreement (aba) to provide common coins for the randomized aba protocol [72]. honeybadgerbft honeybadgerbft . the replica first proposes a set of transactions and uses reliable broadcast to disseminate its proposal to all other replicas. in the second phase, n concurrent aba instances . beat0, beat0 leverages incorporates a more secure and efficient threshold encryption, a direct implementation of threshold coin flipping, and more flexible and efficient erasure-coding beat0 specification. instead of using cpa/cca-secure threshold encryption that does not support labels, beat0 leverages a ccasecure, labeled threshold encryption scheme. . two latency-optimized protocols in beat: beat1 and beat2. beat1. via careful study of latency for each honeybadgerbft subprotocol, we find that 1) most of latency comes from threshold encryption and threshold signatures, and 2) somewhat surprisingly, when the load is small and there is low contention, erasurecoded reliable broadcast (avid broadcast) [24] in terms of latency by 20%\u223c60%. this motivates us to devise beat1. beat1 replaces the avid broadcast protocol in beat0 with bracha\u2019s broadcast. it turns out that when the load is small, beat1 is consistently faster than beat0, though the difference by percentage is not as significant as that between hb-bracha and honeybadgerbft. however, in beat0, our use of cca-secure, labeled threshold encryption is at the server side, to prevent the adversary . beat3, latency (compared and scalability. use a novel combination of a bandwidth-efficient information dispersal scheme (avid-fp and an aba protocol [72]. in comparison, honeybadgerbft, beat1, . the bandwidth required to disperse a blockm in avid-fp is only o(|m |), while the bandwidth in avid broadcast (used . general optimization beat instances that significantly reduce read bandwidth. for clients to read only a fraction of the data block. for many applications using smart contracts, clients may be interested in seeing the first few key terms of a large contract instead of the lengthy, detailed, and explanatory terms. our technique relies on a novel erasure-coded reliable broadcast protocol, avid-fp-pyramid, as reviewed in sec. 4, a (m+\u04340l+\u04341,m) pyramid code can tolerate arbitrary \u0434 = \u04340+\u04341 erasures. let n =m+\u04340l+\u04341. we define for a (m+\u04340l+\u04341,m) pyramid code a tailored fingerprinted cross-checksum. . pyramid codes are linear, all the fingerprints of coded fragments can be derived by the originalm fragments. we say a fragment d is consistent with fpcc for its index . six asynchronous bft protocols, is implemented to understand the latency overhead caused by erasure coding. hbbracha replaces the underlying erasure-coded reliable broadcast (avid broadcast) with bracha\u2019s broadcast [19], with the rest of the components intact. each of the six protocols involves 6,000 lines of code in python. the design and implementation of beat is modular, . the word sizew is typically set to be between 4 and 16 for efficiency, and therefore n < 2w . a general purposed type with two virtual cpus and 4gb memory. we evaluate our protocols in both lan and wan settings, where the lan nodes are selected from the same amazon ec2 region, . the protocols mentioned above have rather different communication complexity. to order transactions of size b, the communication complexity of beat3 and hb-bracha is o(nb), while the communication complexity of beat3 is significant: with the same bandwidth, beat3 and beat4 can process an order of magnitude more batched transactions, leading . six new protocols (beat instances andhb-bracha). of these protocols use similar components, maintaining, and comparing different beat instances takes tremendous effort. while one of our goals is to make beat modular and extensible, in practice it is still challenging to develop all the variants of the protocols. this is in part because even for the same function (e.g., threshold encryption), different apis need to maintained. in fact, changing a small function in a beat instance may need to touch a large number of related functions accordingly. on the other hand, we find that perhaps surprisingly, it may be easier to implement well from our own experience and from the fact that a significant number of academic papers choose not to implement the view change protocols. second, because of native robustness against timing and liveness attacks for asynchronous bft, we simply do not need to take further measures to ensure robustness. bft than partially synchronous bft, for at least two reasons. first, protocols assuming partial synchrony rely on view change subprotocols, which are very difficult to implement well from our own experience and from the fact that a significant number of academic papers choose not to implement the view change protocols. second, because of native robustness against timing and liveness attacks for asynchronous bft, we simply do not need to take further measures to develop and deploy asynchronous bft than partially synchronous bft, for at least two reasons. first, protocols . efficient, flexible, and extensible. we deploy and evaluate the five beat protocols using 92 instances on amazon ec2, and we show beat protocols are significantly more efficient than honeybadgerbft, the most efficient asynchronous bft we also develop new distributed system ingredients, including generalized fingerprinted cross-checksum and new asynchronous verifiable information dispersal, which might be of independent interest. protocols that are efficient, flexible, versatile, and extensible. we deploy and evaluate the five beat protocols using 92 instances on amazon ec2, and we describe the design and implementation of beat, a family of practical asynchronous bft protocols that are significantly more efficient than honeybadgerbft, the most efficient asynchronous bft we also develop new distributed system ingredients, including generalized fingerprinted cross-checksum and new asynchronous verifiable information dispersal, . we describe the design and implementation of beat, a family of practical asynchronous bft protocols . the authors are indebted to our shepherd haibo chen and the ccs reviewers for their helpful comments that greatly improve our paper. chen . the authors are indebted to our shepherd haibo chen and the ccs reviewers for their helpful comments that greatly improve our paper. paper. chen and the ccs reviewers for their helpful comments . the authors are indebted to our shepherd haibo chen and the ccs reviewers for their helpful comments greatly improve our paper. greatly improve our shepherd haibo chen . proof of theorem 9.2. termination is simple, as in avid-fp. if a correct server initiates codes the transaction, and sends echo messages to all servers. each server will eventually receive at least 2f + 1 ready messages . all correct servers will eventually receive ready messages from these correct servers. as our protocol implements the amplification step as in all other bracha\u2019s broadcast like broadcast, all correct servers will send ready messages, and all of them will eventually receive at least 2f + 1 ready messages. agreement .",
    "17": "databases can provide scalability by ensuring atomic visibility: either all or none of each transaction\u2019s updates are observed by other transactions. we present algorithms for read atomic multipartition (ramp) transactions that provide useful semantics for multi-partition operations. this leads to incorrect behavior for a large class of applications including secondary indexing, and materialized view maintenance. in this work, we identify a new isolation model\u2014read atomic (ra) isolation\u2014that matches the requirements of these use cases by ensuring atomic visibility: either all or none of each transaction\u2019s systems avoid mechanisms that provide readers with snapshot access to database state by using limited multi-versioning and by allowing clients to independently resolve non-atomic reads. and minimized communication between servers (via partition . unprecedented query volume, 28, 29, 35]. is held by the owner/author(s). publication rights licensed to acm. acm ...$15.00. http://dx.doi.org/10.1145/2588555.2588562. . the full citation on the first page. copyrights for components of this work owned by others than the author(s) must be honored. with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, . prominent use cases today. the basic property we provide is fairly simple: either all or none of each transaction\u2019s updates should be visible to other transactions. for example, if a transaction like t1 writes x = 1 and y = 1, then another transaction t2 should not read x = 1 and y = 1 or, instead, t2 should either read x = 1 and y = null and y = null. informally, each transaction reads from an unchanging snapshot of database state that is aligned along transactional boundaries. we call this property atomic visibility and formalize it via the read atomic isolation guarantee in section 3. the classic strategy for providing atomic visibility is to ensure mutual exclusion between readers and writers. . sam and mary, authors describe an identical scenario [15]. these applications require foreign key maintenance and often, due to their unidirectional relationships, update and access. violations of atomic visibility surface as broken bi-directional relationships (as with sam and mary above) and dangling or incorrect references (e.g., frank is an employee of department.id=5, but no such department exists in the department table). when inserting new entities, applications can bundle relevant entities from each side of a foreign key constraint into a transaction. . readers more interested in ramp algorithms may wish to proceed to section 4. . read atomic isolation and, to capture scalability, formulate a pair of strict scalability criteria: synchronization and partition independence. readers more interested . unique timestamp taken from a totally ordered set of items, or transactions. we call the set of items a transaction reads from and writes to its read set and write set. each write creates a version of an item and we identify versions of items by a unique timestamp as is simply a restriction on write visibility\u2014if the acid \u201catomicity\u201d property requires that all or none of a transaction\u2019s updates are performed, ra requires that all or none of a transaction\u2019s updates are made visible to other transactions. with x possibly but not necessarily equal to y), tj reads version xm and yn (in any order, with x possibly but not necessarily equal to y), isolation, as is standard [2], we consider ordered sequences of reads and writes to arbitrary sets of items, or transactions. we denote version i of item x as xi. a transaction tj exhibits fractured reads anomalies . example, ra is an incorrect choice for an application that wishes to maintain positive bank account balances in the event of withdrawals. ra is a better fit for our \u201cfriend\u201d operation because the operation is write-only and correct execution (i.e., inserting both records) from a programmer\u2019s perspective, we have found ra isolation to be most easily understandable (at with read-only and write-only transactions; after all, because ra allows concurrent writes, any values that are read might be changed at any time. however, transactions are indeed well defined under ra. ra isolation matches many of our use cases. however, ra is not sufficient for all applications. ra does not prevent concurrent updates or provide serial access to data items. for example, ra is an incorrect choice for an application that wishes to maintain positive bank account balances in the event of withdrawals. ra is not conditional on concurrent updates. . database initialization. in commit, signaling success, as long as operations on each item are calculated using the item. clients forward operations on each item to the item\u2019s partition, where they are executed. transaction execution terminates as we hinted in section 1, large-scale deployments often eschew transactional functionality on the premise that it would be too expensive or unstable in the presence of failure and degraded operating modes [9, 11, 15, and, and, . wins\u201d overwrite policy, then subsequently discuss how to perform read/write transactions. our focus in this section is on intuition and understanding; we defer all correctness and scalability proofs to the appendix, providing salient details inline. at a high level, ramp transactions allow reads and writes to proceed concurrently. this provides excellent performance but, in turn, introduces a race condition: one transaction might only read a subset of another transaction\u2019s writes, violating ra (i.e., fractured reads might occur). instead of preventing this race (hampering scalability), ramp readers autonomously detect the race (using metadata attached to each data item) . the expected number of extra reads to fetch missing writes. as discussed in section 2, . ramp algorithm that, in the race-free case, requires one rtt for reads and two rtts for writes, called ramp-fast (abbreviated ramp-f; algorithm 1). ramp-f stores metadata in the form of write sets (overhead linear in transaction size). overview. for now, combining a unique client id and client-local sequence number is sufficient for timestamp generation (see also section 4.5). ramp-f write protocol on two partitions, px . the transaction timestamp (line 7). uses constant-size metadata but always requires two rtt for reads (algorithm 2). ramp-s and ramp-f writes are identical, but, instead of attaching the entire write set to each write, ramp-s writers only store the transaction timestamp (line unlike ramp-f, ramp-s readers issue a first round of reads to fetch the highest committed timestamp for each item from its respective partition (lines 3, . set of timestamps) 2: and ramp-s write protocols are identical, but, instead of storing the entire write set (as in ramp-f), algorithm 2 ramp-small server-side data structures same as in ramp-f (algorithm 1) server-side methods prepare, commit same as in ramp-f 1: procedure get(i : set of hitem,valuei) same as ramp-f put_all but do not instantiate md on line 18 8: procedure get_all(i . the ramp algorithms allow readers in all three algorithms to safely handle concurrent and/or partial writes and in turn allows readers in all three algorithms to safely race writers without requiring either to stall. the metadata attached to each write compared to ramp-f when there is no race between readers and writers. algorithm 3 ramp-hybrid data structures same as in ramp-f (algorithm server-side server-side methods prepare, while ramp-s and ramp-h require more rtts for reads compared to ramp-f when a reader races a writer to the same items, the writer\u2019s new versions will only become visible to the reader (i.e., once it is guaranteed that the reader will be able to fetch all of them (possibly via a second round . details. multi-versioning and garbage collection. can be implemented by using a single-versioned storage engine for retaining the last committed version of an item is not the highest-timestamped committed version (i.e., a committed version v of item k where v < lastcommit[k]), it can be safely discarded (i.e., garbage collected, or gced) as long as no readers will attempt to access it in the future (via second-round get requests). the maximum number of versions retained for each item is bounded by the item\u2019s update rate, and servers can reject any client get requests for versions that have been overwritten and have not been returned in the first round of any ongoing read . ramp transactions operate in a distributed setting, which poses challenges tolerance and availability as long as clients can access relevant partitions, but here we further elucidate ramp interactions with replication and stalled operations. replication. a variety of mechanisms including traditional database master-slave replication and state machine replication . clients only have to contact partitions for items in their transactions. this provides fault tolerance and availability as long as clients can wait until the effects of their operations (e.g., modifications to versions and lastcommit) are persisted locally on their respective partitions and/or to multiple physical servers before returning from put_all replication or via quorum replication . the server can mark the version as committed. this scenario will occur when all partitions have performed prepare and at least one server but not all partitions have performed commit (as in ctp). this allows faster updates to lastcommit (and therefore fewer expected ramp-f and ramp-h rtts). metadata garbage collection. once all of transaction t \u2019s writes stored in ramp-f and ramp-h (write sets and bloom filters) can therefore be discarded. detecting that all servers have performed commit can be performed asynchronously via a third round of communication performed by either clients or servers. one-phase writes. similar . experimentally and non-transactional ramp-f, ramp-h, and often ramp-s outperform existing solutions across a range of workload conditions while exhibiting overheads typically within 8% and no more than 48% of peak throughput. as expected from our theoretical analysis, the performance of our ramp algorithms does not degrade substantially under contention and scales linearly to over 7.1 million operations per second on 100 servers. these outcomes validate our choice to pursue synchronization- and partition-independent algorithms. ramp-h, . 4.5. ramp-s, uses a 256-bit bloom filter based on an implementation of murmurhash2.0, with four hashes per entry; to demonstrate the effects of concurrency control on performance and scalability, we implemented several concurrency control algorithms in a partitioned, main-memory database prototype. our prototype is in java and employs a custom rpc system with kryo 2.20 for serialization. servers are arranged as a distributed hash table with partition placement determined by random hashing. as in stores like dynamo [22], clients can connect to any server acts as a client in our ramp pseudocode). we implemented ramp-f, ramp-s, and ramp-h a wall-clock gc window of 5 seconds . our first set of experiments focuses on two metrics: performance compared to baseline and performance compared to existing techniques. the overhead of ramp algorithms is typically less than 8% and is never greater than 50%. ramp-f and ramp-h techniques, while ramp-s outperforms techniques and often outperforms e-pci. we proceed to demonstrate this behavior over a variety of clients. ramp performance scales well with increased load and incurs little overhead (figure with few concurrent updates and therefore few secondround reads; performance for ramp-f and ramp-h is close to or even matches that of nwnr. at peak throughput (at 10,000 clients), and ramp-h pay a throughput overhead of 4.2% . the throughput reduction as the proportion of blocked writes increases (compared to no blocked writes) for a workload of 100% ramp-f write transactions: time-outs; . the table below reports the throughput reduction as the proportion of blocked writes (or time-outs; set to 5s in our experiments), so a modest failure rate of 1 in 1000 writes . linear scalability has deployed an increasing number of servers within the us-west-2 ec2 region and, to mitigate the effects of hot items during scaling, configured uniform random access to items. we were unable to include more than 20 instances in an ec2 group,\u201d which guarantees 10 gbe connections between instances, so, past 20 servers, servers communicated over a degraded network. around 40 servers, we exhausted the us-west-2b \u201cavailability (datacenter) capacity . one in 100m transactions is a multi-partition operation. in particular, ramp-f achieves slightly under 7.1 million operations per second, or 1.79 million transactions per second on a set of 100 servers (71,635 operations per second). at all scales, ramp-f throughput . [8]: serializability. is still limited to 20 and 250 writes per item per second. multi-partition serializable transactions [33] by electing a coordinator server for each write. as discussed in turn sacrifice transactional guarantees. isolation in many industrial databases such as f1 [41] and spanner [17] . the reported throughput is still limited to 20 and 250 writes per item . new isolation level\u2014read atomic isolation\u2014that provides atomic visibility and matches the requirements of a large class of real-world applications. we subsequently achieved ra isolation via scalable, contention-agnostic with a variable but small (and, in two of three algorithms, constant) amount of metadata per write, ramp transactions are not appropriate for all applications, the many for which they are well suited will benefit measurably. acknowledgments the authors would like to thank peter alvaro, cheung, neil conway, aaron davidson, mike franklin, neil conway, aaron davidson, nuno . national science foundation graduate research fellowship (grant and darpa xdata award fa8750-12-2-0331, the national science foundation graduate research fellowship . modern distributed database system design: cap is only part of the story. ieee computer, 2012. [2] . theory and optimistic implementations for distributed transactions. virtues and advanced topics (2nd edition). in hash coding with allowable errors. in hash coding with explicit solution. . ramp-f correctness. has a lower timestamp than x1\u2019s sibling version of y j , xi . in figure 1, the versions returned by t2\u2019s first round of reads ({x1,y?}) do not comprise a companion set because y? has too low of a timestamp). subsets of companion sets and companion sets also have a useful property for ra isolation: claim 1 (companion sets .",
    "18": "results. unfortunately, and machine learning algorithms. performing computations on uncertain data as if it were exact leads to incorrect results. sensors in iot, sampling-based approximate computations and use it to modify ten applications, including ai/ml, image processing and trend analysis applications to process uncertain data. our evaluation shows that up-mapreduce propagates uncertainties with high accuracy and, in many cases, low performance overheads. for example, a social network trend analysis application that combines data sampling with up can reduce execution time by 2.3x when the user can tolerate a maximum relative error of 5% in the final answer. . computer systems organization \u2192 architectures; keywords uncertainty propagation, in proceedings of acm symposium on cloud computing, carlsbad, usa, october 11\u201313, 2018 (socc \u201918), 12 pages. https://doi.org/10.1145/3267809.3267833 uncertainty propagation in data processing systems. in proceedings of acm symposium on the first page. copyrights for components of this work owned by others than acm must be honored. with credit is permitted. to copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. request permissions from permissions@acm.org. socc \u201918, october 11\u201313, 2018, ca, usa \u00a9 2018 association for computing machinery. acm 978-1-4503-6011-1/18/10. . data collected at a tremendous pace. the need to process this vast amount of data has led to the design and deployment of data processing systems such as mapreduce, spark and scope [7, 37]. these frameworks typically allow data processing applications to be expressed as directed acyclic graphs (dags) of side-effect free computation nodes, with data flowing through the edges for processing. the frameworks then run applications on clusters of servers, transparently handling issues such as task scheduling, data movement, and fault tolerance. at the same time, there is an urgent need for processing an exploding body of data with uncertainties [4]. for example, data collected using sensors are always estimates . byproducts of the approximation. finally, we review previous work in uncertainty estimation and belief propagation. sources of uncertainty. collecting data from imprecise instruments such as temperature, position or other analog sensors often introduces measurement uncertainty. in these applications, acquiring precise data is typically not an option, but it is usually possible to tune precision at the expense of resources such as blinkdb [2] and approxhadoop [11]. this is a particularly interesting scenario since execution time savings achieved via approximation may be offset by the necessity for up in subsequent nodes . dag and y is a set of random variables representing outputs with uncertainties. depending on the nature of f (continuous, or discrete), we leverage a set of three statistical methods to approximate the mean f is an arbitrary function without side effects, representing the computation of a dag x is a set of random variables representing inputs with uncertainties, and y is a set of random variables representing each yi in y. these methods are described below. and the variance \u03c3 2yi for each yi in y. where f is an arbitrary function without side effects, . we use first-order differential analysis (da) to approximate the first two moments of y, i.e., mean and variance, for functions f that are continuous and differentiable [3]. the general strategy is accurate if f is roughly linear around the support (in neighborhood) of x; errors are being introduced otherwise. as shall be seen in section 7.3, using the first-order taylor series at the expected value of x. this approximation is accurate if the inputs are independent, so that \u03c3xix j = 0, i , j, then equation 3 reduces to the left summand. as shown in general, these covariances may be nonzero. thus, . x falls mostly or entirely within a continuous and differentiable function defined on two intervals. our framework automatically performs the required run-time checks for each xi . in this case leads to an exact result. if x \u2019s support spans the probability that x lies within any interval. for example, suppose we define a filter function as f (x ) = 1 when x > \u03b1 and 0 otherwise. this is a simple semi-continuous function which intervals of x lie in continuous parts. the first assumes each xi is approximately normal allowing the estimation of the support . we use monte carlo simulation to approximate y for functions f that do not meet (or the developers to not know whether they meet) the requirements for da. specifically, as n \u2192 \u221e, the empirical distribution obtained for each yi converges to the true distribution. to choose n, we use the following expression which bounds the difference between the empirical and the true distribution [21]: p ( sup (f\u0302i (y) ) ) 2 (4) where f\u0302i ,n (y) is the actual cdf for yi . for example, to approximate the cdf of fi (y) with a 99% probability of achieving an accuracy of \u03f5 = 0.05, one would need n = 53 samples. to generate accurate samples, one must know the joint density of x and pay the heavy computational cost of any rejection-sampling algorithm. unfortunately, . figure 4 shows an example of the two u nodes designed to highlight the challenges of implementing up in dag data processing. this example can correspond to transformations in a spark program or map and reduce phases in a mapreduce program. this figure shows that, in general, we must handle up through multi-input, multi-output functions for implementation in the node labeled s (e.g., via a sampling-based approximation uncertainties then must be propagated through the two u nodes following s . figure 4 shows an example dag, where uncertainty is introduced in the last section to implement up through blackbox functions . up-mapreduce. dag applications. we first show how our approach can be applied to the mapreduce paradigm. we then describe our implementation called up-mapreduce. mapreduce to include the above up techniques in multi-stage dag applications. we first show how our approach can be applied to the mapreduce paradigm. we then describe our implementation called up-mapreduce. we extend hadoop to include the above up techniques in multi-stage dag applications. we first show how our approach can be applied to the mapreduce paradigm. we then describe our implementation called up-mapreduce. we extend hadoop mapreduce . (key, value) pair, and produces a set of intermediate (key, pairs, where multiple pairs may have the same key. in the reduce phase, a user-written side-effect-free function is called per intermediate key and the set of values associated with that only values are uncertain (keys are exact), the discussion in section 4 applies directly to the implementation of up-mapreduce. each map() or reduce() invocation . the previously mentioned case of x1 and xn in figure 4 having a non-zero covariance. on the correct subset of inputs. we adopt similar approach . extension of apache hadoop 2.7. the extension comprises three mapper and three reducer classes that implement up-mc, up-da for map and reduce, respectively. developers must choose the correct classes when implementing programs for up-mapreduce. our extension also introduces the uncertain type pv (probabilistic which implements random variables. a pv variable contains one or more random variables, each described by a mean, a variance-covariance and possibly an entire empirical distribution. below, we briefly describe the necessary reducer classes. up is implemented similarly for the mapper classes. upmcreducer. this class implements up-mc for reduce. functions, . (e.g., multiplication, and (ki respectively). are the only change needed for map() is the handling of pv rather than precise values. up is not needed because no computation is being done. the reduce() is rewritten to call eval() after properly arranging the inputs, followed by a call to continuousup(). eval() the inner product. the partial derivatives for inputs from a is \u2202f = bk j , and vice versa for inputs from b. 3) regression (linreg). . studying it\u2019s accuracy, performance, and scalability. we begin by exploring the two applications, tsocial and latency, that include sampling-based approximations and trade precision for reduced execution times. we show that by developing these applications in up-mapreduce we can drastically decrease the execution time of both, while propagating the uncertainties introduced by the approximations. we then explore the accuracy of our up techniques, performance overheads, and scalability via an extensive sensitivity analysis. by studying it\u2019s accuracy, and scalability. we begin by exploring the two applications, tsocial and latency, . input data sets.we leverage real datasets for the purpose of the sensitivity analysis (performance, precision and scalability), we generate synthetic input data sets with varying sizes and amounts of uncertainty for each application, similarly to the synthetic data generation in [40]. for each node of an application\u2019s dag. here, the entire application is run from beginning to end in each run as shown in figure 6. for an iterative application, each run is given inputs drawn randomly according to the actual (known) input distributions. note that this is different than using up-mc for each input item to achieve a specific relative error defined as 3\u03c3/\u00b5. baseline. we expand on a case to show that using the norms do not obfuscate large differences for a subset of estimated outputs. we use the mean produced by baseline-normal to compute the relative error for up in which we extract the mean and variance for each output. we consider three different distributions . the second four-stage workflow is a approximate workflow comprising of an approximate query in blinkdb [2] on 2 \u00d7 107 registered individuals, followed by 2) an uncertain linear regression (linreg) in up-mapreduce. the execution of the approximate query in blinkdb drastically reduces the execution time of the stage compared to a precise execution, but introduces uncertainties in the form of estimated errors (variance). is then used to propagate these uncertainties through the second stage of the computation. the mean us latency on a grid (2000 locations) by performing latency measurements which generate uncertainty due to sampling 2) surface on the obtained estimates . results from all previously described applications except the toolbox,mm and tsocial, as they are included as part of the other applications under study. we start by exploring the accuracy of up-mapreduce estimation of the means. figure 8 plots the relative error (%) of the corresponding euclidean norm in case of multivariate outputs) computed by up-da using numerical differentiation against the baseline-normal. these results are identical for up-mc. we observe that up-mapreduce estimates the means with very low bias, especially when the input does not affect execution time). the figure also plots the execution times of precise versions, where there is zero input variance. when drawing input samples in up-mc, all of which also contribute to the observed deviations. to verify that the computed norms are not obfuscating large differences between the up-mapreduce estimates . running the original precise applications. we choose the following input sizes: linreg (16\u00b7106), (16\u00b7106), (16\u00b7106), (9\u00b7106), (9\u00b7106), (9\u00b7106), . 106), latency \u00b7 106), \u00b7 106), \u00b7 106 from 150 locations). we illustrate our results (speedups) vs. increasing number of servers from four representative applications in figure 11. the rest follow similar trends. we draw the following conclusions. first, . differential analysis can be used to propagate uncertainties through dag nodes implementing continuous (and semi-continuous under certain conditions) and differentiable functions. our approach falls back to monte carlo simulation of nodes otherwise, but uses statistical bounds to minimize overheads while achieving a target error bounds. our approach also allows the inter-mixing of differential analysis and monte carlo simulation for different nodes within a dag, offering flexibility in the operations supported and minimizing performance overheads we have shown how our up approach can be applied to general dag frameworks. we have also implemented it in the upmapreduce system. experimentation with ten common data analytic applications revealed that up-mapreduce is highly accurate in many cases, . nsf grant ccf-1319755. was partially supported by nsf grant ccf-1319755. . work was partially supported by nsf grant ccf-1319755. . work was partially supported by nsf grant ccf-1319755. .",
    "19": "most recent designs have focused on performance properties such as latency and throughput. in this paper, we devise complexity metrics for lifecycle management, and show that existing topology classes have low lifecycle management complexity by some measures, but not by others. motivated by this, we design a new class of topologies, fatclique, while being performance-equivalent to existing topologies, is comparable to, or better than them by all our lifecycle management complexity metrics. which attempts to understand the complexity of deploying a topology and expanding it. by analyzing current practice in lifecycle management, we devise complexity metrics for lifecycle management, and show that existing topology classes have low lifecycle management complexity by some measures, but not by others. motivated by this, we design a new dimension, life cycle management complexity, . new class of topologies, fatclique, that, is comparable to, or better than them by all our lifecycle management complexity metrics. which attempts to understand the complexity of deploying a topology and expanding it. by analyzing current practice in lifecycle management, we devise complexity metrics for lifecycle management, and show that existing topology classes have low lifecycle management complexity by some measures, but not by others. motivated by this, we design a new class of topologies, fatclique, while being performance-equivalent to existing topologies, is comparable to, or throughput. in this paper, we explore a new dimension, life cycle management complexity, which attempts to understand the complexity of deploying a topology and expanding it. by analyzing current practice in lifecycle management, we devise complexity metrics for lifecycle management, and show that existing topology classes have low lifecycle management complexity by some measures, but not by others. motivated by this, we design a new class of topologies, that, . datacenter topologies 31, 32, has largely been overlooked. lifecycle management . the process of building a network, physically deploying it on a data-center floor, and expanding it over several years so that it is available for use by a constantly increasing set of services. with datacenters living on for years, sometimes up to a decade [31, 12], their lifecycle costs can be high. opposed to dollar costs) . data center topology families. data centers are often designed for high throughput, and resilience. existing data center designs can be broadly classified into the following families: (a) tree topologies, e.g., jupiter [31], jupiter [31], jupiter [31], . highradix switches, (b) (b) graph based topologies, e.g., topologies of these, clos and expander [24, . highradix switches, topologies topologies topologies topologies topologies topologies topologies topologies . deployment is the process of realizing a physical topology in a data center space (e.g., from a given logical topology. deployment complexity can be reduced by careful packaging, placement and bundling strategies [31, 20, 1]. 1]. . deployment is the process of realizing a physical topology in a data center space (e.g., a building), from a given logical topology. deployment complexity can be reduced by careful packaging, placement and bundling strategies [31, 20, 1]. . deployment is the process of realizing a physical topology in a data center space (e.g., a building), from a given logical topology. deployment complexity . packaging of a topology determines the type of cables needed between switches. for instance, if two connected switches are within the same rack, they can use short-range cheaper copper cables, while connections between racks require more optical cables. optical cable costs are determined by two factors: the cost of transceivers and the length of cables (\u00a73.2). placement of switches into a single chassis using a backplane completely removes the need for physical connecting cables. at scale, the cost and complexity savings from using a chassis-backplane can be used to build a clos with 1:1 oversubscription. . bundle of topological structure. for instance, in a clos topology, if an aggregation layer fits into one rack or a neighboring set of racks, a patch panel is not needed between the tor and the aggregation layer. however, for larger clos topologies where an aggregation block can span multiple racks, tor to aggregation links may need to be rebundled through a patch panel. but it also determines the packaging complexity (switches need to be packed to chassis and racks) and the placement complexity (racks need to be placed on the datacenter floor). number of patch panels. by acting as bundle waypoints, the number of patch panels alone does not capture wiring complexity. the other measure is represented by a tuple of (a) the capacity of the number of fibers . clos contains 16 aggregation and 16 edge switches4. the aggregation switches can be packed into a single rack, so bundles from edge switches to aggregation switches do not need to be rebundled though patch panels, and we only need a little over half the switches compared to clos to achieve comparable capacity due to its high edge expansion property. but, by other measures, clos performs better. it exposes far fewer ports outside the rack (a little over half that of jellyfish); we say clos has better port-hiding. a pod in this clos . the second important component of topology management is expansion. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as network capacity demands increase. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as network capacity demands increase. datacenters management is expansion. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as network capacity demands increase. lifecycle management is the second important component of topology lifecycle management is expansion. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as network capacity demands increase. the second important component of topology lifecycle management is expansion. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as network capacity demands increase. the second important component of topology lifecycle management is the second important component of topology expansion. datacenters are rarely deployed to maximal capacity in one shot; rather, they are gradually expanded as capacity demands increase. datacenters . in-place expansion. and (b) re-wiring adding) links between switches in the existing topology and the new switches. phase (b), the re-wiring phase, services away, for example, to be at least a percentage p of the capacity of the existing topology. this fraction is sometimes called the expansion slo. so, today, datacenters . the first choice can impact service availability significantly. so, today, datacenters . the upper left figure shows a partiallydeployed logical clos, in which each spine and aggregation block are connected by a single link. during a step. figure 2 shows an example of clos expansion. the upper right is the target fully-deployed clos, where each spine and aggregation 238 16th usenix symposium on networked systems design and implementation usenix association block are connected by two links. the upper right is allowed to be drained. in the first step, which requires human involvement. this sub-step is also the most important from an availability perspective; the longer this sub-step takes, the longer the datacenter operates at reduced capacity, which can impact availability targets [12]. the role of patch panels . expansion. average number of rewired links in a patch panel rack per step. with patch panels, manual rewiring dominates the time taken within each expansion step. within steps, it is possible to parallelize rewiring across racks of patch panels. with such parallelization, the time taken to rewire a single patch panel rack will dominate the time taken for each expansion step. as mentioned each expansion step requires a series of substeps which cannot be parallelized. therefore the number of expansion steps determines the total time for expansion. average number of rewired links in the next subsection. number of expansion steps. . 90%. (\u00a76 has more extensive comparisons for these metrics, and also describes the methodology more carefully). in this setting, the number of links rewired per patch panel can be a factor of two less than clos. moreover, jellyfish requires 3 steps, while clos twice the number of steps. to understand why jellyfish requires fewer steps, we define a metric called the north-to-south capacity ratio for a block. this is the ratio of the aggregate capacity of all \u201cnorthbound\u201d links to/from the servers within the block. figure 4 illustrates this ratio: a thin edge (left), has an equal number of southbound and northbound links while a fat edge (right), has a thin edge, i.e., this means that many more links can be rewired in a single step in jellyfish than in clos. this property of jellyfish is required for reducing the number of expansion steps. clos topologies re-wire more links in each patch panel . preliminary results presented in those sections (\u00a76 has more extensive results) suggest the following qualitative comparison between clos and the expander graph families with respect to lifecycle management costs (table 3): \u2022 clos uses fewer bundle types and patch panels. \u2022 jellyfish has significantly lower switch counts, uses fewer expansion steps, and touches fewer links per patch panel during an expansion step. in all of these comparisons, we compare topologies with the same number of servers and the same bisection bandwidth. the question we ask in this paper is: is there a family of topologies which are comparable to, or dominate, graphs by all our lifecycle management metrics? in this section, we present the design of the fatclique class of topologies and validate in \u00a76 . fatclique (figure 5) has three levels of hierarchy: individual sub-block (top left), interconnected into a block (top right), which are in turn interconnected to form fatclique (bottom). the interconnection used at every level in the hierarchy is a clique, similar to dragonfly [20]. additionally, each level in the hierarchy is designed to have a fat edge (a north-south capacity ratio greater than 1). the cliques enable high edge expansion, while hierarchy enables lower wiring complexity than random-graph based expanders [32, fatclique in fatclique, the sub-block forms the lowest level of the hierarchy, . small fatclique topology, shown top left in figure 7, that has 3 blocks and lbb i.e., to expand it to a clique with six blocks, we would need to rewire the topology to have l\u2032bb = 2 (top right in figure 7). this means we need to redistribute more than half (6 out of existing links (red) at each block to new blocks without violating wiring and capacity constraints. the expansion process with patch panels is shown in the bottom of figure 7. similar to the procedure for clos described in \u00a74.1, all new blocks (shown in orange) are first deployed and interconnected and links from the new blocks are routed to reserved ports on patch panels . construction, fatclique achieves low lifecycle management complexity (table 3), while ensuring full-bisection bandwidth. it ensures high edge expansion, resulting in fewer switches. by packaging clique connections into a sub-block, it enables fewer re-wired links per patch panel, by ensuring fat edges at each level of the hierarchy, it enables more efficient search for candidate topologies. finally, since xpander and jellyfish do not incorporate hierarchy, they can be scaled to arbitrarily large sizes. however, because clos and fatclique are hierarchical, they can only scale to a fixed size . three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three classes of topologies, clos, expander graphs and fatclique by our complexity metrics. in this section, we compare three topologies, classes of clos, expander graphs . topology scales. and large. small topologies are listed in table 6. all our experiments in this section are based on comparing topologies at the same scale. at each scale, we generate one topology for each of clos, xpander, jellyfish, and fatclique. the characteristics of these topologies are listed in table 3: the most common switch radix available today for all port capacities [5]. . the placement of patch panels is determined both by the structure of the topology and its scale. between edge and aggregation layers in clos. for small and medium scale clos, no patch panels are needed between edge and aggregation layers. however, a large clos needs one layer of patch panels between edge and aggregation layers since a pod at this scale is large. all links from the edge can connect to this rack. since all links connect to one physical location, bundles form naturally. based on the logical connectivity, links . (\u00a73.2). figure 8 shows how the different topologies compare in terms of number of switches used at various topology scales. figure 9 shows the number of patch panels at different scales. as before, across these graphs, the y-axis scale increases approximately by one order of magnitude from left to right. at small and medium scales, clos relies on patch panels mainly for connections between aggregation and spine blocks. of all topologies at these scales, topologies this benefit comes from the edge expansion property of the non-clos topologies we consider. this implies that clos topologies, at large scale, may require nearly twice the capital expenditures for switches, racks, and space as the other topologies. number of patch panels . the number of rewired-links per patch panel rack per step. since the number of steps is scale-invariant (\u00a76.1), as discussed in \u00a76.1, for symmetric clos, we have developed an algorithm with optimal number of expansion steps . the number of rewired clos topologies; generic clos expansion is studied in [38]. . small and medium clos have slightly fewer patch panels). it uses 50% fewer switches and 33% fewer patch panels than clos at large scale, and has a 23% lower cabling symposium on networked systems design and implementation usenix association number of links to be rewired at each step per patch panel can be 30-50% higher. because the 246 16th usenix symposium can permit fast expansion while degrading network capacity by small amounts (2.5-10%): at these levels, clos can take 5 \u00d7 longer to expand the topology, and each step of clos expansion can take longer than fatclique because the 246 16th usenix cost (an estimate we are able to derive from published cable prices). finally, fatclique can permit fast expansion while degrading network capacity by all our complexity metrics. (the one exception is that at small and medium scales, clos has slightly fewer patch panels). it uses 50% fewer switches and 33% fewer patch panels than clos at large scale, and has a 23% lower cabling cost (an estimate we find that fatclique is the best at most scales by all our complexity metrics. (the one exception is that at small and medium scales, clos can take 5 \u00d7 longer to expand the topology, and each step of clos expansion can be 30-50% at each step per patch panel can be 30-50% higher. because the 246 16th usenix symposium on networked systems design and implementation usenix association number of links to be rewired at each step per patch panel can take longer than fatclique clos . topology design. like [6, 35, 20]. has not been investigated . topologies topologies has discussed several aspects of topology expansion . the lifecycle management complexity of these topologies have not been investigated . research. lifecycle management consists of network deployment and expansion, and we devise metrics that capture the complexity of each. we use these to compare topology classes explored in the research literature: clos and expander graphs. we find that each class has low complexity by some metrics, but high by others. however, our evaluation suggests topological features important for low lifecycle complexity: hierarchy, edge expansion and fat edges. at the edge of the network, but there is anecdotal evidence that providers also over-subscribe at higher levels in clos topologies. to explore the manageability of over-subscribed topologies it will be necessary to design over-subscription techniques in fatclique, xpander and explicitly does not consider other network management problems like fault isolation . algorithm for clos topologies, the canonical recursive algorithm in [36] as shown in jupiter [31], the topology is composed of heterogenous building blocks (chassis), which are packed into a single rack and therefore enforce port hiding (the idea that as few ports from a rack are exposed outside the rack). although jupiter is modular and supports port hiding, it is single instance of a clos-like topology with a specific set of parameters. we seek an algorithm that can take any valid set of clos parameters and produce chassis-based topologies besides, it would be desirable for this algorithm to generate all possible feasible topologies satisfying the parameters, so we use omega networks to build both the edge and aggregation blocks, and core blocks. the process to compose the whole topology is to link all these blocks and uses the same procedure ."
}