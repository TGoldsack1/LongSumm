{
  "sections": [{
    "text": "268 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com\nNetworks are on our minds nowadays.Sometimes we fear their power — and withgood reason. On 10 August 1996, a fault intwo power lines in Oregon led, through acascading series of failures, to blackouts in 11 US states and two Canadian provinces, leaving about 7 million customers without power for up to 16 hours1. The Love Bug worm, the worst computer attack to date, spread over the Internet on 4 May 2000 and inflicted billions of dollars of damage worldwide.\nIn our lighter moments we play parlour games about connectivity. ‘Six degrees of Marlon Brando’ broke out as a nationwide fad in Germany, as readers of Die Zeit tried to connect a falafel vendor in Berlin with his favourite actor through the shortest possible chain of acquaintances2. And during the height of the Lewinsky scandal, the New York Times printed a diagram3 of the famous people within ‘six degrees of Monica’.\nMeanwhile scientists have been thinking about networks too. Empirical studies have shed light on the topology of food webs4,5, electrical power grids, cellular and metabolic networks6–9, the World-Wide Web10, the Internet backbone11, the neural network of the nematode worm Caenorhabditis elegans12, telephone call graphs13, coauthorship and citation networks of scientists14–16, and the quintessential ‘old-boy’ network, the overlapping boards of directors of the largest companies in the United States17 (Fig. 1). These databases are now easily accessible, courtesy of the Internet. Moreover, the availability of powerful computers has made it feasible to probe their structure; until recently, computations involving million-node networks would have been impossible without specialized facilities.\nWhy is network anatomy so important to characterize? Because structure always affects function. For instance, the topology of social networks affects the spread of information and disease, and the topology of the power grid affects the robustness and stability of power transmission.\nFrom this perspective, the current interest in networks is part of a broader movement towards research on complex systems. In the words of E. O. Wilson18, “The greatest challenge today, not just in cell biology and ecology but in all of science, is the accurate and complete description of complex systems. Scientists have broken down many kinds of systems. They think they know most of the elements and forces. The next task is to reassemble them, at least in mathematical models that capture the key properties of the entire ensembles.”\nBut networks are inherently difficult to understand, as the following list of possible complications illustrates. 1. Structural complexity: the wiring diagram could be an\nintricate tangle (Fig. 1). 2. Network evolution: the wiring diagram could change\nover time. On the World-Wide Web, pages and links are created and lost every minute. 3. Connection diversity: the links between nodes could have different weights, directions and signs. Synapses in\nExploring complex networks Steven H. Strogatz\nDepartment of Theoretical and Applied Mechanics and Center for Applied Mathematics, 212 Kimball Hall, Cornell University, Ithaca, New York 14853-1503, USA (e-mail: strogatz@cornell.edu)\nThe study of networks pervades all of science, from neurobiology to statistical physics. The most basic issues are structural: how does one characterize the wiring diagram of a food web or the Internet or the metabolic network of the bacterium Escherichia coli? Are there any unifying principles underlying their topology? From the perspective of nonlinear dynamics, we would also like to understand how an enormous network of interacting dynamical systems — be they neurons, power stations or lasers — will behave collectively, given their individual dynamics and coupling architecture. Researchers are only now beginning to unravel the structure and dynamics of complex networks.\nDynamical systems can often be modelled by differential equations dx/dt4v(x), where x(t)4(x1(t), …, xn(t)) is a vector of state variables, t is time, and v(x)4(v1(x), …, vn(x)) is a vector of functions that encode the dynamics. For example, in a chemical reaction, the state variables represent concentrations. The differential equations represent the kinetic rate laws, which usually involve nonlinear functions of the concentrations.\nSuch nonlinear equations are typically impossible to solve analytically, but one can gain qualitative insight by imagining an abstract n-dimensional state space with axes x1, …, xn. As the system evolves, x(t) flows through state space, guided by the ‘velocity’ field dx/dt4v(x) like a speck carried along in a steady, viscous fluid.\nSuppose x(t) eventually comes to rest at some point x*. Then the velocity must be zero there, so we call x* a fixed point. It corresponds to an equilibrium state of the physical system being modelled. If all small disturbances away from x* damp out, x* is called a stable fixed point — it acts as an attractor for states in its vicinity.\nAnother long-term possibility is that x(t) flows towards a closed loop and eventually circulates around it forever. Such a loop is called a limit cycle. It represents a self-sustained oscillation of the physical system.\nA third possibility is that x(t) might settle onto a strange attractor, a set of states on which it wanders forever, never stopping or repeating. Such erratic, aperiodic motion is considered chaotic if two nearby states flow away from each other exponentially fast. Long-term prediction is impossible in a real chaotic system because of this exponential amplification of small uncertainties or measurement errors\nBox 1 Nonlinear dynamics: terminology and concepts97\n© 2001 Macmillan Magazines Ltd\nthe nervous system can be strong or weak, inhibitory or excitatory. 4. Dynamical complexity: the nodes could be nonlinear dynamical systems. In a gene network or a Josephson junction array, the state of each node can vary in time in complicated ways. 5. Node diversity: there could be many different kinds of nodes. The biochemical network that controls cell division in mammals consists of a bewildering variety of substrates and enzymes6, only a few of which are shown in Fig. 1c. 6. Meta-complication: the various complications can influence each other. For example, the present layout of a power grid depends on how it has grown over the years — a case where network evolution (2) affects topology (1). When coupled neurons fire together repeatedly, the connection between them is strengthened; this is the basis of memory and learning. Here nodal dynamics (4) affect connection weights (3). To make progress, different fields have suppressed certain complications while highlighting others. For instance, in nonlinear dynamics we have tended to favour simple, nearly identical dynamical systems coupled together in simple, geometrically regular ways. Furthermore we usually assume that the network architecture is static. These simplifications allow us to sidestep any issues of structural complexity and to concentrate instead on the system’s potentially formidable dynamics. Laser arrays provide a concrete example19–24. In the single-mode approximation, each laser is characterized by its time-dependent gain, polarization, and the phase and amplitude of its electric field. These evolve according to four coupled, nonlinear differential equations. We usually hope the laser will settle down to a stable state, corresponding to steady emission of light, but periodic pulsations and even chaotic intensity fluctuations can occur in some cases19. Now suppose that many identical lasers are arranged side by side in a regular chain20 or ring21, interacting with their neighbours by evanescent coupling or by overlap of their electric fields22. Will the lasers lock their phases together spontaneously, or break up into a standing wave pattern, or beat each other into incoherence? From a technological standpoint, self-synchronization would be the most desirable outcome, because a perfectly coherent array of N lasers would\nNATURE | VOL 410 | 8 MARCH 2001 | www.nature.com 269\nReplication\nSkp1 CBF3\nprimase\np68\nPol α\nP\nPCNA\nRPA\nc y c E\np 2 7P\nc y c D\nPT286\nc d k 4 / 6\nP P\np 1 6\nc y c A\nc y c B\ncdk1\nPT14Y15\np 2 1\nc d c 2 5 A\nP\nPT380\ncdk2\nP\ncdc25C\nPS216\nC-TAK1\nChk1\nWee1\nP\nPT161\nMyt1\nPY15\nSkp2\n14-3-3\nCyclin box\nDMP1\nP\nCks1\nP\nC1\nC2\nC2\nC3\nC4\nC5\np 5 7\nC7\nC6\nC8 C9\nC10\nC11\nC12\nC13\nC15\nC16\nC17\nC18\nC19\nC20\nC21\nC22\nC23\nC24\nC25\nPS76 C28\nC29\nS9\nGadd45\nC30\nCycH Cdk7\nP\np 5 3\nM d m 2\nP R2\nP\nC26\nR1\nC14\np53 box P\nC32 C34\nC35 Myc:Max\nC36\nSL1\nP\nSL1\nC37 C38\nC39C40\nAPC P\nPlk1\nC37\nC41\nC41\nC41\nP26\nR11\nR 6\nC11a C11b\np19ARF\nP42\ncyclins, pol α\np19ARF\nD M\nP 1\nE 2\nF\np53\nF o\ns\nE20\nC31\nPCNA\nC27\nTranscription\nC42\nC42\n?\nC14\ncd k\ncdk1\np68\np68\nR P\nA\nCycD p21/Gadd45\nC26\nCycE CycA\nR2\nR2\nR11 R10\nS9 CycA\nCycA\np R\nb\nE 2\nF\nD P\n1\nC11b\np16\nC43\nCAK\nR2\nP 4 4 P 4 3\nP48\na\nb c\nFigure 1 Wiring diagrams for complex networks. a, Food web of Little Rock Lake, Wisconsin, currently the largest food web in the primary literature5. Nodes are\nfunctionally distinct ‘trophic species’ containing all taxa that share the same set of predators and prey. Height indicates trophic level with mostly phytoplankton at the bottom and fishes at the top. Cannibalism is shown with self-loops, and omnivory (feeding on more than one trophic level) is shown by different coloured links to consumers. (Figure provided by N. D. Martinez). b, New York State electric power grid. Generators and substations are shown as small blue bars. The lines connecting them are transmission lines and transformers. Line thickness and colour indicate the voltage level: red, 765 kV and 500 kV; brown, 345 kV; green, 230 kV; grey, 138 kV and below. Pink dashed lines are transformers. (Figure provided by J. Thorp and H. Wang). c, A portion of the molecular interaction map for the regulatory network that controls the mammalian cell cycle6. Colours indicate different types of interactions: black, binding interactions and stoichiometric conversions; red, covalent modifications and gene expression; green, enzyme actions; blue, stimulations and inhibitions. (Reproduced from Fig. 6a in ref. 6, with permission. Figure provided by K. Kohn.)\n© 2001 Macmillan Magazines Ltd\nproduce N2 times as much power as a single one. But in practice, semiconductor laser arrays are notoriously prone to both spatial and temporal instabilities20,21. Even for a simple ring geometry, this problem is dynamically complex.\nThe first part of this article reviews what is known about dynamical complexity in regular networks of nonlinear systems. I offer a few rules of thumb about the impact of network structure on collective dynamics, especially for arrays of coupled limit-cycle oscillators.\nThe logical next step would be to tackle networks that combine dynamical and structural complexity, such as power grids or ecological webs. Unfortunately they lie beyond our mathematical reach — we do not even know how to characterize their wiring diagrams. So we have to begin with network topology.\nBy a happy coincidence, such architectural questions are being pursued in other branches of science, thanks to the excitement about the Internet, functional genomics, financial networks, and so on. The second part of this article uses graph theory to explore the structure of complex networks, an approach that has recently led to some encouraging progress, especially when combined with the tools of statistical mechanics and computer simulations.\nNeedless to say, many other topics within network science deserve coverage here. The subject is amazingly rich, and apologies are offered to those readers whose favourite topics are omitted.\nRegular networks of coupled dynamical systems Networks of dynamical systems have been used to model everything from earthquakes to ecosystems, neurons to neutrinos25–32. To impose some order on this list, consider the dynamics that each node would exhibit if it were isolated. Assuming it is a generic dynamical\nsystem, its long-term behaviour is given by stable fixed points, limit cycles or chaotic attractors (Box 1).\nIf we now couple many such systems together, what can be said about their collective behaviour? The answer is not much — the details matter. But I will propose some rough generalizations anyway.\nIf the dynamical system at each node has stable fixed points and no other attractors, the network tends to lock into a static pattern. Many such patterns may coexist, especially if the nodes have competing interactions. In that case the network may become frustrated and display enormous numbers of locally stable equilibria. This kind of complex static behaviour is seen in models of spin glasses, associative memory neural networks and combinatorial optimization problems33.\nAt the opposite extreme, suppose each node has a chaotic attractor. Few rules have emerged about the effect of coupling architecture on dynamics in this case. It is known that networks of identical chaotic systems can synchronize their erratic fluctuations, a curious phenomenon with possible applications to private communications34,35. For a wide range of network topologies, synchronized chaos requires that the coupling be neither too weak nor too strong; otherwise spatial instabilities are triggered34. Related lines of research deal with networks of identical chaotic maps, lattice dynamical systems and cellular automata. These systems have been used mainly as testbeds for exploring spatiotemporal chaos and pattern formation in the simplest mathematical settings, rather than as models of real physical systems."
  }, {
    "heading": "Identical oscillators",
    "text": "The intermediate case where each node has a stable limit cycle has turned out to be particularly fruitful. Much of the research has been inspired by biological examples, ranging from the mutual synchronization of cardiac pacemaker cells, to rhythmically flashing fireflies and chorusing crickets, to wave propagation in the heart, brain, intestine and nervous system25.\nArrays of identical oscillators often synchronize, or else form patterns that depend on the symmetry of the underlying network36. Other common modes of organization are travelling waves in one spatial dimension, rotating spirals in two dimensions and scroll waves in three dimensions25,26. For fully connected networks where each node is coupled equally to all the others, the completely synchronized state becomes likely.\nThese heuristics apply to systems coupled by smooth interactions akin to diffusion. But many biological oscillators communicate by sudden impulses: a neuron fires, a firefly flashes, a cricket chirps. Hence the recent interest in pulse-coupled oscillators37. This thread began with Peskin’s model of the sinoatrial node, the heart’s natural pacemaker, as a collection of N identical integrate-and-fire oscillators38. For the simple case where each oscillator is connected to all the others, Peskin conjectured that they would all end up firing in unison, no matter how they started. He gave a proof for N42 oscillators; it was later demonstrated39 that the conjecture holds for all N. Peskin also conjectured that synchronization would occur even if the oscillators were not quite identical, but that problem remains unproven.\nPeskin’s model has been used as a caricature of coupled neurons40–42 by including synaptic delays, refractory periods, inhibition and local coupling; these realistic features also remove some of the undesirable discontinuities in the mathematics. In an example of scientific cross-fertilization, Hopfield43 pointed out that the locally coupled version of the model is closely related to slider-block models of earthquakes and should therefore display self-organized criticality. That observation suggested intriguing links among neurobiology, geophysics, synchronization and self-organized criticality, and sparked a burst of research activity, as reviewed in ref. 37."
  }, {
    "heading": "Non-identical oscillators",
    "text": "While modelling populations of biological oscillators, Winfree discovered a new kind of cooperative phenomenon, the temporal\n270 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com\nFigure 2 Spontaneous synchronization in a network of limit-cycle oscillators with distributed natural frequencies. The state of each oscillator is represented\ngeometrically as a dot in the complex plane. The amplitude and phase of the oscillation correspond to the radius and angle of the dot in polar coordinates. Colours code the oscillators’ natural frequencies, running from slowest (red) to fastest (violet). In the absence of coupling, each oscillator would settle onto its limit cycle (circle) and rotate at its natural frequency. However, here all the oscillators are also pulled towards the mean field that they generate collectively (shown as an asterisk at the centre of the population). Time increases from left to right, and from top to bottom. Starting from a random initial condition, the oscillators self-organize by collapsing their amplitudes; then they sort their phases so that the fastest oscillators are in the lead. Ultimately they all rotate as a synchronized pack, with locked amplitudes and phases. The governing equations describe a mean-field model of a laser array23. (Simulation provided by R. Oliva.)\n© 2001 Macmillan Magazines Ltd\nanalogue of a phase transition44. He proposed a mean-field model of nearly identical, weakly coupled limit-cycle oscillators and showed that when the coupling is small compared to the spread of natural frequencies, the system behaves incoherently, with each oscillator running at its natural frequency. As the coupling is increased, the incoherence persists until a certain threshold is crossed — then a small cluster of oscillators suddenly ‘freezes’ into synchrony. For still greater coupling, all the oscillators become locked in phase and amplitude (Fig. 2).\nKuramoto26 refined this connection between nonlinear dynamics and statistical physics. He proposed an exactly solvable model of collective synchronization, given by\n} d d u t i}4vi&}N K } ^ N\nj41\nsin(uj1ui), i41, …, N\nwhere ui(t) is the phase of the ith oscillator and vi is its natural frequency, chosen at random from a lorentzian probability density\ng(v)4} p[g2&( g v1v0) 2] }\nof width g and mean v0. Using an ingenious self-consistency argument, Kuramoto solved for the order parameter\nr(t)4*}N1} ^ N\nj41 eiuj(t)* (a convenient measure of the extent of synchronization) in the limit N→÷ and t→÷. He found that\n0, K < Kcr45Ï11(Kcw/K)w, KàKc where Kc42g. In other words, the oscillators are desynchronized completely until the coupling strength K exceeds a critical value Kc. After that, the population splits into a partially synchronized state\nNATURE | VOL 410 | 8 MARCH 2001 | www.nature.com 271\nba\nc\nd\nFigure 3 Schematic illustration of regular and random network architectures. a, Ring of ten nodes connected to their nearest neighbours. b, Fully connected network of ten nodes. c, Random graph constructed by placing n nodes on a plane, then joining pairs of them together at random until m links are used. Nodes may be chosen more than\nonce, or not at all. The resulting wiring diagram (not shown) would be a snarl of crisscrossed lines; to clarify it, I have segregated the different connected components, coloured them, and eliminated as many spurious crossings as possible. The main topological features are the presence of a single giant component, as expected51–53 for a random graph with m > n/2 (here n4200, m4193), and the absence of any dominant hubs. The degree, or number of neighbours, is Poisson distributed across the nodes; most nodes have between one and four neighbours, and all have between zero and six. d, Scale-free graph, grown by attaching new nodes at random to previously existing nodes. The probability of attachment is proportional to the degree of the target node; thus richly connected nodes tend to get richer, leading to the formation of hubs and a skewed degree distribution with a heavy tail. Colours indicate the three nodes with the most links (red, k433 links; blue, k412; green, k411). Here n4200 nodes, m4199 links. Figure provided by D. Callaway. Network visualization was done using the Pajek program for large network analysis (http://vlado.fmf.uni-lj.si/pub/networks/pajek/pajekman.htm).\nFigure 4 Solvable model of a small-world network. The model starts with a ring lattice of n nodes, each connected to its neighbours out to some range k (here n424 and\nk43). Shortcut links are added between random pairs of nodes, with probability f per link on the underlying lattice. In the limit n @ 1, the average path length between nodes can be approximated analytically. (Adapted from ref. 75.)\n© 2001 Macmillan Magazines Ltd\nconsisting of two groups of oscillators: a synchronized group that contributes to the order parameter r, and a desynchronized group whose natural frequencies lie in the tails of the distribution g(v) and are too extreme to be entrained. With further increases in K, more and more oscillators are recruited into the synchronized group, and r grows accordingly.\nTwenty-five years later, the Kuramoto model continues to surprise us (see ref. 45 for a review). First, the incoherent state with r40 was found to be neutrally stable below threshold, despite its apparent stability in simulations; the analysis reveals a connection to Landau damping in plasmas. Second, the square-root critical behaviour of r, almost a cliché for mean-field models in statistical mechanics, turns out to be non-generic; if the sinusoidal coupling is replaced by a periodic function with second harmonics, the scaling changes to r ~ K1Kc. Third, although the model was motivated originally by biological oscillators, it has appeared in such far-flung settings as the flavour evolution of neutrinos32, and arrays of Josephson junctions27 and semiconductor lasers24. The main unsolved problem is the stability of the partially synchronized state for K > Kc. Numerical simulations indicate that it is globally stable, in the sense that it attracts almost all solutions, but even the linear stability problem has yet to be solved. Another issue concerns the extension of the model to nearest-neighbour coupling on a d-dimensional cubic lattice. Simulations46 and renormalization arguments47 indicate that the synchronization phase transition persists for dà3 and vanishes for d41; the results are ambiguous for d42. All of this awaits a mathematical resolution.\nIn contrast to the mean-field models of Winfree and Kuramoto, Ermentrout and Kopell’s classic work deals with one-dimensional chains of oscillators, first in connection with neuromuscular rhythms in the mammalian intestine48, and later in their model of the central pattern generator for the lamprey eel49,50. The main phenomena here involve travelling waves, rather than the synchrony found in mean-field models. This is not accidental, as wave propagation is essential for the generation of peristalsis in the intestine, and for the creation of the swimming rhythm in lamprey.\nErmentrout and Kopell introduced several deep mathematical innovations, but perhaps their most impressive result is a counterintuitive biological prediction. Their lamprey model suggested that the tail-to-head neural connections along the spinal cord would be stronger than those running from head to tail, despite the fact that the wave associated with swimming travels from head to tail. To\neveryone’s delight, that prediction was later confirmed by their experimental collaborators50."
  }, {
    "heading": "Complex network architectures",
    "text": "All the network topologies discussed so far — chains, grids, lattices and fully-connected graphs — have been completely regular (Fig. 3a, b). Those simple architectures allowed us to focus on the complexity caused by the nonlinear dynamics of the nodes, without being burdened by any additional complexity in the network structure itself. Now I take the complementary approach, setting dynamics aside and turning to more complex architectures. A natural place to start is at the opposite end of the spectrum from regular networks, with graphs that are completely random."
  }, {
    "heading": "Random graphs",
    "text": "Imagine n @1 buttons strewn across the floor51. Pick two buttons at random and tie them together with thread. Repeat this process m times, always choosing pairs of buttons at random. (If m is large, you might eventually select buttons that already have threads attached. That is certainly allowed; it merely creates clusters of connected buttons.) The result is a physical example of a random graph with n nodes and m links (Fig. 3c). Now slowly lift a random button off the floor. If it is tied to other buttons, either directly or indirectly, those are dragged up too. So what happens? Are you likely to pull up an isolated button, a small cluster or a vast meshwork?\nErdös and Rényi52 studied how the expected topology of this random graph changes as a function of m. When m is small, the graph is likely to be fragmented into many small clusters of nodes, called components. As m increases, the components grow, at first by linking to isolated nodes and later by coalescing with other components. A phase transition occurs at m4n/2, where many clusters crosslink spontaneously to form a single giant component. For m > n/2, this giant component contains on the order of n nodes (more precisely, its size scales linearly with n, as n→÷), while its closest rival contains only about log n nodes. Furthermore, all nodes in the giant component are connected to each other by short paths: the maximum number of ‘degrees of separation’ between any two nodes grows slowly, like log n.\nIn the decades since this pioneering work, random graphs have been studied deeply within pure mathematics53. They have also served as idealized coupling architectures for dynamical models of gene networks, ecosystems and the spread of infectious diseases and computer viruses29,51,54,55."
  }, {
    "heading": "Small-world networks",
    "text": "Although regular networks and random graphs are both useful idealizations, many real networks lie somewhere between the extremes of order and randomness. Watts and Strogatz56,57 studied a simple model that can be tuned through this middle ground: a regular lattice\n272 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com\n0.001 0.01 0.1 1 10 100 1,000 10,000 nkφ\n0.0\n0.1\n0.2\n0.3\nl/ n\nFigure 5 Average path length, normalized by system size, is plotted as a function of the average number of shortcuts. The circles are results from simulations of the model with range k41 and size up to n4107 nodes. The solid line is given by the formula in the text. (Adapted from ref. 75.)\n© 2001 Macmillan Magazines Ltd\nNATURE | VOL 410 | 8 MARCH 2001 | www.nature.com 273\na b\n© 2001 Macmillan Magazines Ltd\nshortcuts). Figure 5 shows that it also gives the correct qualitative behaviour for nkf ≈ 1. Barbour and Reinert76 improved this result by proving a rigorous distributional approximation for ø, along with a bound on the error."
  }, {
    "heading": "Scale-free networks",
    "text": "In any real network, some nodes are more highly connected than others are. To quantify this effect, let pk denote the fraction of nodes that have k links. Here k is called the degree and pk is the degree distribution.\nThe simplest random graph models52,53 predict a bell-shaped Poisson distribution for pk. But for many real networks, pk is highly skewed and decays much more slowly than a Poisson. For instance, the distribution decays as a power law pk ~ k\n1g for the Internet backbone11, metabolic reaction networks9, the telephone call graph13 and the World-Wide Web10 (Fig. 6a). Remarkably, the exponent g ≈ 2.1–2.4 for all of these cases. Taken literally, this form of heavy-tailed distribution would imply an infinite variance. In reality, there are a few nodes with many links (Fig. 3d). For the World-Wide Web, think Yahoo; for metabolic networks, think ATP. Barabási, Albert and Jeong77,78 have dubbed these networks ‘scale-free’, by analogy with fractals, phase transitions and other situations where power laws arise and no single characteristic scale can be defined.\nThe scale-free property is common but not universal62. For coauthorship networks of scientists, pk is fit better by a power law with an exponential cutoff14 (Fig. 6b); for the power grid of the western United States, pk is an exponential distribution\n62 (Fig. 6c); and for a social network of Mormons in Utah79, pk is gaussian 62 (Fig. 6d).\nNevertheless, the scale-free case has stimulated a great deal of theorizing. The earliest work is due to Simon80,81 in 1955, now independently rediscovered by Barabási, Albert and Jeong77,78. They showed that a heavy-tailed degree distribution emerges automatically from a stochastic growth model in which new nodes are added continuously and attach themselves preferentially to existing nodes, with probability proportional to the degree of the target node. Richly connected nodes get richer, and the result is pk ~ k\n13. More sophisticated models82–84 include the effects of adding or rewiring links, allowing nodes to age so that they can no longer accept new links, or varying the form of preferential attachment. These generalized models predict exponential and truncated power-law pk in some parameter regimes, as well as scale-free distributions.\nCould there be a functional advantage to scale-free architecture? Albert, Jeong and Barabási85 suggested that scale-free networks are resistant to random failures because a few hubs dominate their topology (Fig. 3d). Any node that fails probably has small degree (like most nodes) and so is expendable. The flip side is that such networks are vulnerable to deliberate attacks on the hubs. These intuitive ideas have been confirmed numerically10,85 and analytically86,87 by examining how the average path length and size of the giant component depend on the number and degree of the nodes removed. Some possible implications for the resilience of the Internet79–81, the design of therapeutic drugs9, and the evolution of metabolic networks9,59 have been discussed."
  }, {
    "heading": "Generalized random graphs",
    "text": "As mentioned above, the simplest random graph predicts a Poisson degree distribution, and so cannot accommodate the other types of distribution found in real networks. Molloy and Reed88,89 introduced a more flexible class of random graphs in which any degree distribution is permitted. Given a sequence of non-negative integers {dk}, where dk denotes the number of nodes with degree k, consider the ensemble of all graphs with that prescribed degree sequence, and weight them all equally when computing statistical averages of interest. For this class of graphs, Molloy and Reed derived a simple condition for the birth of the giant component88, and they also found an implicit formula for its size as a fraction of n, the total number of nodes89. Specifically, let n @ 1 and define\nQ4^ ÷\nk41\npkk(k12)\nwhere pk4dk/n. If Q < 0, the graph consists of many small components. The average component size diverges as Q→0 from below, and a giant component exists for Q > 0. (In technical terms, these results hold ‘almost surely’; that is, with probability tending to 1 as n→÷.)\nAiello, Chung and Lu90 applied these results to a random graph model for scale-free networks. For pk of power-law form, the condition on Q implies that a giant component exists if and only if g < 3.47, which holds for most scale-free networks measured so far. If g < 1, there are so many high-degree hubs that the network forms one huge, connected piece. They also proved theorems about the number and size of small components outside the giant component, and compared these to a real graph of about 47 million telephone numbers and the calls between them in one day. They found that the data are best fit by an exponent g ≈ 2.1, which predicts correctly that the call graph is not connected but has a giant component.\nThe papers by Molloy and Reed88,89 and Aiello et al.90 are mathematically rigorous. Newman, Strogatz and Watts91 recently developed a more heuristic approach based on generating functions. By handling the limit n→÷ in an intuitive way, their approach yields elementary derivations of the earlier results, along with new exact results for graphs with additional structure, such as directed or bipartite graphs.\n274 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com\nM = 4\nN = 11\nD E F G H I J K\n1 2 3 4\nCB\nB\nD\nA\nC\nE\nF\nG\nH\nI\nJ\nK\nA\na\nb\nFigure 7 Bipartite versus unipartite representations of the corporate director network. a, In the bipartite approach, directors and boards are treated as distinct kinds of\nnodes. The schematic example shows 11 directors and 4 boards. Links indicate which people sit on which boards. By definition there are no links between pairs of people, or between pairs of boards. b, The more familiar unipartite representation depicts the people as nodes, with links between those on the same board, forming cliques. This approach discards important information and can conflate different structures. For example, the triangle FHI corresponds to board number 3, as seen in a, whereas the similar-looking triangle FGI does not correspond to any single board. Another confusing effect is the large number of cliques that occur automatically in this projection of the full bipartite graph. Such cliques account for much of the high clustering observed in real affiliation networks58. The random graph model teases out this generic source of clustering from that indicative of more interesting social interactions. (Adapted from ref. 91.)\n© 2001 Macmillan Magazines Ltd\nThe bipartite case is especially interesting for applications58. By definition, in a bipartite graph there are two types of nodes, with links running only between different kinds (Fig. 7). For example, consider the network of the boards of directors of the Fortune 1,000 companies, the largest US corporations ranked according to revenues. This network is fascinating because the boards ‘interlock’ — some important people sit on several of them — and this overlap knits virtually all large US firms together into a giant web of corporate governance17.\nLet pj denote the probability that a director sits on exactly j boards, and let qk denote the probability that a board consists of k directors. Figure 8 shows that pj is approximately exponential, with most directors sitting on only one board, whereas qk is strongly peaked around k410, indicating that most boards have about ten members. As a null hypothesis, assume that the Fortune 1,000 network is a random member of the ensemble of all bipartite graphs with the same pj and qk. Then generating functions yield predictions for various quantities of interest91. For example, suppose we want to calculate rz , the probability that a random director works with a total of z other co-directors, summed over all the boards on which he or she serves. Let\nf0(x)4^ ÷\nj40\npjx j\ng0(x)4^ ÷\nk40\nqkx k\nbe the generating functions associated with the empirical degree distributions pj and qk. If we now choose a random edge on the bipartite graph and follow it to the board at one of its ends, the distribution of the number of other edges leaving that board can be shown to be generated by g1(x)4g08(x)/n, where n4g08(1). Then for a randomly chosen director, the generating function for z is given by G0(x)4f0(g1(x)). If we expand G0 in a series as\nG0(x)4^ ÷\nz40\nrzx z,\nthe coefficients rz are exactly the quantities we seek. They can be extracted by repeated differentiation: rz4(1/z!)(d zG0/dx z)äx40.\nFigure 8c shows that the predicted rz agrees almost perfectly with the actual distribution. Similarly, the clustering coefficient56 predicted for the directors lies within 1% of the observed value (Table 1). Clearly the random model captures much of the structure of the real network.\nHowever, for two other bipartite graphs — film actors and the movies they appeared in, and biomedical scientists and the papers they coauthored — the model91 underestimates the clustering coefficients by half (Table 1). The reason is that the random model quantifies only the generic portion of the clustering; it reflects the cliques that are formed automatically whenever a bipartite collaboration graph is projected onto the space of people, as in Fig. 7b. For the corporate board data, those cliques account for essentially all the clustering (simply because most directors sit on only one board, thus preventing clustering across boards). But for the scientists and actors, some further mechanisms must be at work. One possible explanation is that scientists tend to introduce pairs of their collaborators to each other, engendering new collaborations.\nIn this way the random model allows us to disentangle the generic features of bipartite graphs from those that could reflect sociological effects. Beyond their benchmarking role, generalized random graphs provide a promising new class of substrates on which dynamical processes can be simulated and even approached analytically. Using this approach, Watts92 has given an intriguing explanation of fads and\nnormal accidents as the natural consequence of cascade dynamics on sparse interaction networks.\nOutlook In the short run there are plenty of good problems about the nonlinear dynamics of systems coupled according to small-world, scale-free or generalized random connectivity. The speculations that these architectures are dynamically advantageous (for example, more synchronizable or error-tolerant) need to be sharpened, then confirmed or refuted mathematically for specific examples. Other ripe topics include the design of self-healing networks, and the relationships among optimization principles, network growth rules and network topology82–84,93–96.\nIn the longer run, network thinking will become essential to all branches of science as we struggle to interpret the data pouring in from neurobiology, genomics, ecology, finance and the World-Wide Web. Will theory be able to keep up? Time to log back on to the Internet... n\n1. Western Systems Coordinating Council (WSCC). Disturbance Report for the Power System Outage\nthat Occurred on the Western Interconnection on August 10th, 1996 at 1548 PAST <http://www.wscc.com> (October 1996).\n2. Anonymous. Media: Six degrees from Hollywood. Newsweek 11 October 1999, 6 (1999). 3. Kirby, D. & Sahre, P. Six degrees of Monica. New York Times 21 February 1998, op. ed. page (1998). 4. Cohen, J. E., Briand, F. & Newman, C. M. Community Food Webs: Data and Theory (Springer, Berlin, 1990). 5. Williams, R. J. & Martinez, N. D. Simple rules yield complex food webs. Nature 404, 180–183 (2000). 6. Kohn, K. W. Molecular interaction map of the mammalian cell cycle control and DNA repair systems.\nMol. Biol. Cell 10, 2703–2734 (1999).\nNATURE | VOL 410 | 8 MARCH 2001 | www.nature.com 275\n0 5 10 Number of boards j\n10-4\n10-2\n100\nP ro\nb ab\nili ty\np j\n0 10 20 30 Number of members k\n10-3\n10-2\n10-1\nP ro\nb ab\nili ty\nq k\n0 10 20 30 40 Number of co-directors z\n0.00\n0.05\n0.10\nP ro\nb ab\nili ty\nr z\na\nc\nb\nFigure 8 Structural properties of the Fortune 1,000 network of corporate directors for 1999. The data shown here comprise 7,673 directors and 914 boards. Most directors serve on the board of only one company, but about 20% sit on two or more boards,\nthereby creating interlocked directorates. This has potentially important consequences for business practices in the United States17. a, Distribution of the number of boards per director. The probability pj that a director sits on exactly j boards decreases roughly exponentially with j. b, Distribution of the number of directors per board. The probability qk that a board has k members is approximately lognormally distributed, with a typical board size around k410 members. c, Distribution of each director’s total number of co-directors, summed over all the boards on which the director sits. The probability rz of serving with z other co-directors is a complicated function of z, with a long tail and a secondary shoulder near z420, yet the theoretical prediction (solid line) agrees almost perfectly with the actual distribution (green circles). (Adapted from ref. 91.)\n© 2001 Macmillan Magazines Ltd\n7. Hartwell, L. H., Hopfield, J. J., Leibler, S. & Murray, A. W. From molecular to modular cell biology.\nNature 402, C47–C52 (1999).\n8. Bhalla, U. S. & Iyengar, R. Emergent properties of networks of biological signalling pathways. Science\n283, 381–387 (1999).\n9. Jeong H., Tombor, B., Albert, R., Oltavi, Z, N. & Barabási, A.-L. The large-scale organization of\nmetabolic networks. Nature 407, 651–654 (2000).\n10.Broder, A. et al. Graph structure in the web. Comput. Netw. 33, 309–320 (2000). 11.Faloutsos, M., Faloutsos, P. & Faloutsos, C. On power-law relationships of the internet topology.\nComp. Comm. Rev. 29, 251–262 (1999).\n12.Achacoso, T. B. & Yamamoto, W. S. AY’s Neuroanatomy of C. elegans for Computation (CRC Press,\nBoca Raton, FL, 1992).\n13.Abello, J., Buchsbaum, A. & Westbrook, J. A functional approach to external graph algorithms. Lect.\nNotes Comput. Sci. 1461, 332–343 (1998).\n14.Newman, M. E. J. The structure of scientific collaboration networks. Proc. Natl Acad. Sci. USA 98,\n404–409 (2001).\n15.Seglen, P. O. The skewness of science. J. Am. Soc. Inform. Sci. 43, 628–638 (1992). 16.Redner, S. How popular is your paper? An empirical study of the citation distribution. Eur. J. Phys. B\n4, 131–134 (1998).\n17. Davis, G. F. The significance of board interlocks for corporate governance. Corp. Govern. 4, 154–159 (1996). 18.Wilson, E. O. Consilience p.85 (Knopf, New York, 1998). 19.Weiss, C. O. & Vilaseca, R. Dynamics of Lasers (VCH, Weinheim, 1991). 20.Winful, H. G. & Wang, S. S. Stability of phase locking in coupled semiconductor laser arrays. Appl.\nPhys. Lett. 53, 1894–1896 (1988).\n21. Li, R. D. & Erneux, T. Preferential instability in arrays of coupled lasers. Phys. Rev. A 46, 4252–4260 (1992). 22.Fabiny, L., Colet, P., Roy, R. & Lenstra, D. Coherence and phase dynamics of spatially coupled solid-\nstate lasers. Phys. Rev. A 47, 4287–4296 (1993).\n23.Kourtchatov, S. Yu., Likhanskii, V. V., Naparotovich, A. P., Arecchi, F. T. & Lapucci, A. Theory of phase\nlocking of globally coupled laser arrays. Phys. Rev. A 52, 4089–4094 (1995).\n24.Kozyreff, G., Vladimirov, A. G. & Mandel, P. Global coupling with time delay in an array of\nsemiconductor lasers. Phys. Rev. Lett. 85, 3809–3812 (2000).\n25.Winfree, A. T. The Geometry of Biological Time (Springer, New York, 1980). 26.Kuramoto, Y. Chemical Oscillations, Waves, and Turbulence (Springer, Berlin, 1984). 27.Wiesenfeld, K., Colet, P. & Strogatz, S. H. Frequency locking in Josephson arrays: connection with the\nKuramoto model. Phys. Rev. E 57, 1563–1569 (1998).\n28.Turcotte, D. L. Fractals and Chaos in Geology and Geophysics 2nd edn (Cambridge Univ. Press,\nCambridge, 1997).\n29.May, R. M. Stability and Complexity in Model Ecosystems (Princeton Univ. Press, Princeton, 1973). 30.Levin, S. A., Grenfell, B. T., Hastings, A. & Perelson, A. S. Mathematical and computational challenges\nin population biology and ecosystem science. Science 275, 334–343 (1997).\n31. Arbib, M. (ed.) The Handbook of Brain Theory and Neural Networks (MIT Press, Cambridge, MA, 1995). 32.Pantaleone, J. Stability of incoherence in an isotropic gas of oscillating neutrinos. Phys. Rev. D 58,\n3002 (1998).\n33.Stein, D. L. (ed.) Lectures in the Sciences of Complexity (Addison-Wesley, Reading, MA, 1989). 34.Pecora, L. M., Carroll, T. L., Johnson, G. A., Mar, D. J. & Heagy, J. F. Fundamentals of synchronization\nin chaotic systems: concepts and applications. Chaos 7, 520–543 (1997).\n35.VanWiggeren, G. D. & Roy, R. Communication with chaotic lasers. Science 279, 1198–1200 (1998). 36.Collins, J. J. & Stewart, I. Coupled nonlinear oscillators and the symmetries of animal gaits. J. Nonlin.\nSci. 3, 349–392 (1993).\n37.Pérez, C. J., Corral, A., Diáz-Guilera, A., Christensen, K. & Arenas, A. On self-organized criticality\nand synchronization in lattice models of coupled dynamical systems. Int. J. Mod. Phys. B 10, 1111–1151 (1996).\n38.Peskin, C. S. Mathematical Aspects of Heart Physiology 268–278 (Courant Institute of Mathematical\nSciences, New York, 1975).\n39.Mirollo. R. E. & Strogatz, S. H. Synchronization of pulse-coupled biological oscillators. SIAM J. Appl.\nMath. 50, 1645–1662 (1990).\n40.Abbott, L. F. & van Vreeswijk, C. Asynchronous states in neural networks of pulse-coupled oscillators.\nPhys. Rev. E 48, 1483–1490 (1993).\n41.Bressloff, P. C. Mean-field theory of globally coupled integrate-and-fire neural oscillators with\ndynamic synapses. Phys. Rev. E 60, 2160–2170 (1999).\n42.Golomb, D. & Hansel, D. The number of synaptic inputs and the synchrony of large, sparse neuronal\nnetworks. Neural Comput. 12, 1095–1139 (2000).\n43.Hopfield, J. J. Neurons, dynamics, and computation. Phys. Today 47, 40–46 (1994). 44.Winfree, A. T. Biological rhythms and the behavior of populations of coupled oscillators. J. Theor.\nBiol. 16, 15–42 (1967).\n45.Strogatz, S. H. From Kuramoto to Crawford: exploring the onset of synchronization in populations of\ncoupled oscillators. Physica D 143, 1–20 (2000).\n46.Sakaguchi, H., Shinomoto, S. & Kuramoto, Y. Local and global self-entrainments in oscillator lattices.\nProg. Theor. Phys. 77, 1005–1010 (1987).\n47.Daido, H. Lower critical dimension for populations of oscillators with randomly distributed\nfrequencies: a renormalization-group analysis. Phys. Rev. Lett. 61, 231–234 (1988).\n48.Ermentrout, G. B. & Kopell, N. Frequency plateaus in a chain of weakly coupled oscillators. SIAM J.\nMath. Anal. 15, 215–237 (1984).\n49.Kopell, N. & Ermentrout, G. B. Symmetry and phaselocking in chains of weakly coupled oscillators.\nCommun. Pure Appl. Math. 39, 623–660 (1986).\n50.Sigvardt, K. A. & Williams, T. L. Models of central pattern generators as oscillators: the lamprey\nlocomotor CPG. Semin. Neurosci. 4, 37–46 (1992).\n51.Kauffman, S. At Home in the Universe (Oxford, New York, 1995). 52. Erdös, P. & Rényi, A. On the evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci. 5, 17–61 (1960). 53.Bollobás, B. Random Graphs (Academic, London, 1985). 54.Kauffman, S. A. Metabolic stability and epigenesis in randomly constructed genetic nets. J. Theor.\nBiol. 22, 437–467 (1969).\n55.Kephart, J. O. & White, S. R. in Proc. 1991 IEEE Comput. Soc. Symp. Res. Security Privacy 343–359\n(IEEE Computer Society Press, Los Alamitos, CA, 1991).\n56. Watts, D. J. & Strogatz S. H. Collective dynamics of ‘small-world’ networks. Nature 393, 440–442 (1998). 57.Watts, D. J. Small Worlds (Princeton Univ. Press, Princeton 1999). 58.Wasserman, S. & Faust. K. Social Network Analysis: Methods and Applications (Cambridge Univ. Press,\nNew York, 1994).\n59.Wagner, A. & Fell, D. The small world inside large metabolic networks. Preprint available at\n<http://www.santafe.edu/sfi/publications/Abstracts/00-07-041abs.html> (2000).\n60.Adamic, L. The small world web. Lect. Notes Comput. Sci. 1696, 443–452 (Springer, New York, 1999). 61.Kogut, B. & Walker, G. Small worlds and the durability of national networks: ownership and\nacquisitions in Germany. Am. Sociol. Rev. (in the press).\n62.Amaral, L. A. N., Scala, A., Barthélémy, M. & Stanley, H. E. Classes of behavior of small-world\nnetworks. Proc. Natl Acad. Sci. USA 97, 11149–11152 (2000).\n63.Stephan, K. E. et al. Computational analysis of functional connectivity between areas of primate\nvisual cortex. Phil. Trans. R. Soc. Lond. B 355, 111–126 (2000).\n64. Sporns, O., Tononi, G. & Edelman, G. M. Theoretical neuroanatomy: relating anatomical and\nfunctional connectivity in graphs and cortical connection matrices. Cereb. Cortex 10, 127–141 (2000).\n65.Walsh, T. in Proc. 16th Int. Joint Conf. Artif. Intell. 1172–1177 <http://dream.dai.ed.ac.uk/group/\ntw/papers/wijcai99.ps>\n66.Kleinberg, J. M. Navigation in a small world. Nature 406, 845 (2000). 67.Milgram, S. The small world problem. Psychol. Today 2, 60–67 (1967). 68.Wallinga, J., Edmunds, K. J. & Kretzschmar, M. Perspective: human contact patterns and the spread of\nairborne infectious diseases. Trends Microbiol. 7, 372–377 (1999).\n69.Ball, F., Mollison, J. & Scalia-Tomba, G. Epidemics with two levels of mixing. Ann. Appl. Probab. 7,\n46–89 (1997).\n70.Keeling, M. J. The effects of local spatial structure on epidemiological invasions. Proc. R. Soc. Lond. B\n266, 859–867 (1999).\n71.Boots, M. & Sasaki, A. ‘Small worlds’ and the evolution of virulence: infection occurs locally and at a\ndistance. Proc. R. Soc. Lond. B 266, 1933–1938 (1999).\n72.Lago-Fernandez, L. F., Huerta, R., Corbacho, F. & Sigüenza, J. Fast response and temporal coherent\noscillations in small-world networks. Phys. Rev. Lett. 84, 2758–2761 (2000).\n73.Barthélémy, M. & Amaral, L. A. N. Small-world networks: evidence for a crossover picture. Phys. Rev.\nLett. 82, 3180–3183 (1999).\n74.Newman, M. E. J. Models of the small world: a review. J. Stat. Phys. 101, 819–841 (2000). 75.Newman, M. E. J., Moore, C. & Watts, D. J. Mean-field solution of the small-world network model.\nPhys. Rev. Lett. 84, 3201–3204 (2000).\n76. Barbour, A. D. & Reinert, G. Small worlds. Preprint cond-mat/0006001 at <http://xxx.lanl.gov> (2000). 77.Barabási, A. L. & Albert, R. Emergence of scaling in random networks. Science 286, 509–512 (1999). 78.Barabási, A.-L., Albert, R. & Jeong, H. Mean-field theory for scale-free random networks. Physica A\n272, 173–197 (1999).\n79.Bernard, H. R., Killworth, P. D., Evans, M. J., McCarty, C. & Shelley, G. A. Studying social relations\ncross-culturally. Ethnology 27, 155–179 (1988).\n80.Simon, H. A. On a class of skew distribution functions. Biometrika 42, 425–440 (1955). 81.Bornholdt, S. & Ebel, H. World-Wide Web scaling exponent from Simon’s 1955 model. Preprint\ncond-mat/0008465 at <http://xxx.lanl.gov> (2000).\n82.Albert, R. & Barabási, A.-L. Topology of evolving networks: local events and universality. Phys. Rev.\nLett. 85, 5234–5237 (2000).\n83.Dorogovtsev, S. N. & Mendes J. F. F. Evolution of networks with aging of sites. Phys. Rev. E 62,\n1842–1845 (2000).\n84.Krapivsky, P. L., Redner, S. & Leyvraz, F. Connectivity of growing random networks. Phys. Rev. Lett.\n85, 4629–4632 (2000).\n85.Albert, R., Jeong, H. & Barabasi, A.-L. Error and attack tolerance of complex networks. Nature 406,\n378–382 (2000).\n86.Cohen, R., Erez, K., ben-Avraham, D. & Havlin, S. Resilience of the Internet to random breakdowns.\nPhys. Rev. Lett. 85, 4626–4628 (2000).\n87.Callaway, D. S., Newman, M. E. J., Strogatz, S. H. & Watts, D. J. Network robustness and fragility:\npercolation on random graphs. Phys. Rev. Lett. 85, 5468–5471 (2000).\n88.Molloy, M. & Reed, B. A critical point for random graphs with given degree sequence. Random Struct.\nAlgorithms 6, 161–179 (1995).\n89.Molloy, M. & Reed, B. The size of the giant component of a random graph with given degree\nsequence. Combinatorics Probab. Comput. 7, 295–305 (1998).\n90.Aiello, W., Chung, F. & Lu, L. A random graph model for power law graphs. Exp. Math. (in the press);\npreprint available at <http://math.ucsd.edu/~fan/power.pdf>.\n91.Newman, M. E. J., Watts, D. J. & Strogatz, S. H. Random graphs with arbitrary degree distribution\nand their applications. Preprint cond-mat/0007235 at <http://xxx.lanl.gov> (2000).\n92.Watts, D. J. A simple model of fads and cascading failures. Preprint available at\n<http://www.santafe.edu/sfi/publications/Abstracts/00-12-062abs.html> (2000).\n93.Cherniak, C. Component placement optimization in the brain. J. Neurosci. 14, 2418–2427 (1994). 94.Mitchison, G. Neuronal branching patterns and the economy of cortical wiring. Proc. R.. Soc. Lond. B\n245, 151–158 (1991).\n95.West, G. B., Brown, J. H. & Enquist, B. J. The fourth dimension of life: fractal geometry and the\nallometric scaling of organisms. Science 284, 1677–1679 (1999).\n96.Banavar, J. R., Colaiori, F., Flammini, A., Maritan, A. & Rinaldo, A. Topology of the fittest\ntransportation network. Phys. Rev. Lett. 84, 4745–4748 (2000).\n97.Strogatz, S. H. Nonlinear Dynamics and Chaos (Perseus, New York, 1994).\nAcknowledgements Thanks to J. Ariaratnam, A.-L. Barabasi, N. Martinez, M. E. J. Newman, D. Watts and A. Winfree for their comments on a draft of the manuscript, and to R. Albert, L. Amaral, M. Amin, W. Blake, A. Broder, D. Callaway, J. Collins, G. Davis, H. Ebel, K. Kohn, N. Martinez, R. Oliva, M. E. J. Newman, J. Thorp, D. Watts, J. Wiener, A. Winfree and H. Wang for providing data, figures and information. Research supported in part by the National Science Foundation, Department of Defense, and Electric Power Research Institute.\n276 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com© 2001 Macmillan Magazines Ltd"
  }],
  "year": 2001,
  "references": [{
    "title": "Six degrees from Hollywood",
    "authors": ["Anonymous. Media"],
    "venue": "Newsweek 11 October 1999, 6",
    "year": 1999
  }, {
    "title": "Six degrees of Monica",
    "authors": ["D. Kirby", "P. Sahre"],
    "venue": "New York Times",
    "year": 1998
  }, {
    "title": "Simple rules yield complex food webs",
    "authors": ["R.J. Williams", "N.D. Martinez"],
    "venue": "Nature 404,",
    "year": 2000
  }, {
    "title": "Molecular interaction map of the mammalian cell cycle control and DNA repair systems",
    "authors": ["K.W. Kohn"],
    "venue": "Mol. Biol. Cell 10,",
    "year": 1999
  }, {
    "title": "From molecular to modular cell biology",
    "authors": ["L.H. Hartwell", "J.J. Hopfield", "S. Leibler", "A.W. Murray"],
    "venue": "Nature 402,",
    "year": 1999
  }, {
    "title": "Emergent properties of networks of biological signalling pathways",
    "authors": ["U.S. Bhalla", "R. Iyengar"],
    "venue": "Science 283,",
    "year": 1999
  }],
  "id": "SP:e0f984468e3bd5badc7e43547bd675c407a23857",
  "authors": [{
    "name": "Steven H. Strogatz",
    "affiliations": []
  }],
  "abstractText": "268 NATURE | VOL 410 | 8 MARCH 2001 | www.nature.com Networks are on our minds nowadays. Sometimes we fear their power — and with good reason. On 10 August 1996, a fault in two power lines in Oregon led, through a cascading series of failures, to blackouts in 11 US states and two Canadian provinces, leaving about 7 million customers without power for up to 16 hours. The Love Bug worm, the worst computer attack to date, spread over the Internet on 4 May 2000 and inflicted billions of dollars of damage worldwide. In our lighter moments we play parlour games about connectivity. ‘Six degrees of Marlon Brando’ broke out as a nationwide fad in Germany, as readers of Die Zeit tried to connect a falafel vendor in Berlin with his favourite actor through the shortest possible chain of acquaintances. And during the height of the Lewinsky scandal, the New York Times printed a diagram of the famous people within ‘six degrees of Monica’. Meanwhile scientists have been thinking about networks too. Empirical studies have shed light on the topology of food webs, electrical power grids, cellular and metabolic networks, the World-Wide Web, the Internet backbone, the neural network of the nematode worm Caenorhabditis elegans, telephone call graphs, coauthorship and citation networks of scientists, and the quintessential ‘old-boy’ network, the overlapping boards of directors of the largest companies in the United States (Fig. 1). These databases are now easily accessible, courtesy of the Internet. Moreover, the availability of powerful computers has made it feasible to probe their structure; until recently, computations involving million-node networks would have been impossible without specialized facilities. Why is network anatomy so important to characterize? Because structure always affects function. For instance, the topology of social networks affects the spread of information and disease, and the topology of the power grid affects the robustness and stability of power transmission. From this perspective, the current interest in networks is part of a broader movement towards research on complex systems. In the words of E. O. Wilson, “The greatest challenge today, not just in cell biology and ecology but in all of science, is the accurate and complete description of complex systems. Scientists have broken down many kinds of systems. They think they know most of the elements and forces. The next task is to reassemble them, at least in mathematical models that capture the key properties of the entire ensembles.” But networks are inherently difficult to understand, as the following list of possible complications illustrates. 1. Structural complexity: the wiring diagram could be an intricate tangle (Fig. 1). 2. Network evolution: the wiring diagram could change over time. On the World-Wide Web, pages and links are created and lost every minute. 3. Connection diversity: the links between nodes could have different weights, directions and signs. Synapses in Exploring complex networks",
  "title": "Exploring complex networks"
}